[
  {
    "name": "ㅍㅍㅅㅅ",
    "category": "큐레이팅",
    "posts": []
  },
  {
    "name": "C++ Team Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Facebook Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "eBay Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Twitter Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "JetBrains: Developer Tools for Professionals and Teams – Company Blog | JetBrains",
    "category": "기업",
    "posts": [
      {
        "creator": "Cheuk Ting Ho",
        "title": "Faster Python: Concurrency in async/await and threading",
        "link": "https://blog.jetbrains.com/pycharm/2025/06/concurrency-in-async-await-and-threading/",
        "pubDate": "Tue, 10 Jun 2025 11:57:58 +0000",
        "content:encodedSnippet": "If you have been coding with Python for a while, especially if you have been using frameworks and libraries such as Fast API and discord.py, then you have probably been using async/await or asyncio. You may have heard statements like “multithreading in Python isn’t real”, and you may also know about the famous (or infamous) GIL in Python. In light of the denial about multithreading in Python, you might be wondering what the difference between async/await and multithreading actually is – especially in Python programming. If so, this is the blog post for you!\nWhat is multithreading?\nIn programming, multithreading refers to the ability of a program to execute multiple sequential tasks (called threads) concurrently. These threads can run on a single processor core or across multiple cores. However, due to the limitation of the Global Interpreter Lock (GIL), multithreading in Python is only processed on a single core. The exception is nogil (also called thread-free) Python, which removes the GIL and will be covered in part 2 of this series. For this blog post, we will assume that the GIL is always present.\nWhat is concurrency?\nConcurrency in programming means that the computer is doing more than one thing at a time, or seems to be doing more than one thing at a time, even if the different tasks are executed on a single processor. By managing resources and interactions between different parts of a program, different tasks are allowed to make progress independently and in overlapping time intervals.\nBoth asyncio and threading appear concurrent in Python\nLoosely speaking, both the asyncio and threading Python libraries enable the appearance of concurrency. However, your CPUs are not doing multiple things at the exact same time. It just seems like they are.\nImagine you are hosting a multi-course dinner for some guests. Some of the dishes take time to cook, for example, the pie that needs to be baked in the oven or the soup simmering on the stove. While we are waiting for those to cook, we do not just stand around and wait. We will do something else in the meantime. This is similar to concurrency in Python. Sometimes your Python process is waiting for something to get done. For example, some input/output (I/O) processes are being handled by the operating system, and in this time the Python process is just waiting. We can then use async to let another Python process run while it waits.\n\n\n\n\nThe difference is who is in charge\nIf both asyncio and threading appear concurrent, what is the difference between them? Well, the main difference is a matter of who is in charge of which process is running and when. For async/await, the approach is sometimes called cooperative concurrency. A coroutine or future gives up its control to another coroutine or future to let others have a go. On the other hand, in threading, the operating system’s manager will be in control of which process is running.\nCooperative concurrency is like a meeting with a microphone being passed around for people to speak. Whoever has the microphone can talk, and when they are done or have nothing else to say, they will pass the microphone to the next person. In contrast, multithreading is a meeting where there is a chairperson who will determine who has the floor at any given time. \nWriting concurrent code in Python\nLet’s have a look at how concurrency works in Python by writing some example code. We will create a fast food restaurant simulation using both asyncio and threading.\nHow async/await works in Python\nThe asyncio package was introduced in Python 3.4, while the async and await keywords were introduced in Python 3.5. One of the main things that make async/await possible is the use of coroutines. Coroutines in Python are actually generators repurposed to be able to pause and pass back to the main function.\nNow, imagine a burger restaurant where only one staff member is working. The orders are prepared according to a first-in-first-out queue, and no async operations can be performed:\nimport time\n\n\ndef make_burger(order_num):\n    print(f\"Preparing burger #{order_num}...\")\n    time.sleep(5) # time for making the burger\n    print(f\"Burger made #{order_num}\")\n\n\ndef main():\n    for i in range(3):\n        make_burger(i)\n\n\nif __name__ == \"__main__\":\n    s = time.perf_counter()\n    main()\n    elapsed = time.perf_counter() - s\n    print(f\"Orders completed in {elapsed:0.2f} seconds.\")\n\n\n\n\nThis will take a while to finish:\nPreparing burger #0...\n\nBurger made #0\n\nPreparing burger #1...\n\nBurger made #1\n\nPreparing burger #2...\n\nBurger made #2\n\nOrders completed in 15.01 seconds.\nNow, imagine the restaurant brings in more staff, so that it can perform work concurrently:\nimport asyncio\n\nimport time\n\nasync def make_burger(order_num):\n\n    print(f\"Preparing burger #{order_num}...\")\n\n    await asyncio.sleep(5) # time for making the burger\n\n    print(f\"Burger made #{order_num}\")\n\nasync def main():\n\n    order_queue = []\n\n    for i in range(3):\n\n        order_queue.append(make_burger(i))\n\n    await asyncio.gather(*(order_queue))\n\nif __name__ == \"__main__\":\n\n    s = time.perf_counter()\n\n    asyncio.run(main())\n\n    elapsed = time.perf_counter() - s\n\n    print(f\"Orders completed in {elapsed:0.2f} seconds.\")\nWe see the difference between the two:\nPreparing burger #0...\n\nPreparing burger #1...\n\nPreparing burger #2...\n\nBurger made #0\n\nBurger made #1\n\nBurger made #2\n\nOrders completed in 5.00 seconds.\nUsing the functions provided by asyncio, like run and gather, and the keywords async and await, we have created coroutines that can make burgers concurrently.\nNow, let’s take a step further and create a more complicated simulation. Imagine we only have two workers, and we can only make two burgers at a time.\nimport asyncio\n\nimport time\n\norder_queue = asyncio.Queue()\n\ndef take_order():\n\n  for i in range(3):\n\n      order_queue.put_nowait(make_burger(i))\n\nasync def make_burger(order_num):\n\n  print(f\"Preparing burger #{order_num}...\")\n\n  await asyncio.sleep(5)  # time for making the burger\n\n  print(f\"Burger made #{order_num}\")\n\nclass Staff:\n\n  def __init__(self, name):\n\n      self.name = name\n\n  async def working(self):\n\n      while order_queue.qsize() > 0:\n\n          print(f\"{self.name} is working...\")\n\n          task = await order_queue.get()\n\n          await task\n\n          print(f\"{self.name} finished a task...\")\n\nasync def main():\n\n  staff1 = Staff(name=\"John\")\n\n  staff2 = Staff(name=\"Jane\")\n\n  take_order()\n\n  await asyncio.gather(staff1.working(), staff2.working())\n\nif __name__ == \"__main__\":\n\n  s = time.perf_counter()\n\n  asyncio.run(main())\n\n  elapsed = time.perf_counter() - s\n\n  print(f\"Orders completed in {elapsed:0.2f} seconds.\")\nHere we will use a queue to hold the tasks, and the staff will pick them up.\nJohn is working...\n\nPreparing burger #0...\n\nJane is working...\n\nPreparing burger #1...\n\nBurger made #0\n\nJohn finished a task...\n\nJohn is working...\n\nPreparing burger #2...\n\nBurger made #1\n\nJane finished a task...\n\nBurger made #2\n\nJohn finished a task...\n\nOrders completed in 10.00 seconds.\nIn this example, we use asyncio.Queue to store the tasks, but it will be more useful if we have multiple types of tasks, as shown in the following example.\nimport asyncio\n\nimport time\n\ntask_queue = asyncio.Queue()\n\norder_num = 0\n\nasync def take_order():\n\n   global order_num\n\n   order_num += 1\n\n   print(f\"Order burger and fries for order #{order_num:04d}:\")\n\n   burger_num = input(\"Number of burgers:\")\n\n   for i in range(int(burger_num)):\n\n       await task_queue.put(make_burger(f\"{order_num:04d}-burger{i:02d}\"))\n\n   fries_num = input(\"Number of fries:\")\n\n   for i in range(int(fries_num)):\n\n       await task_queue.put(make_fries(f\"{order_num:04d}-fries{i:02d}\"))\n\n   print(f\"Order #{order_num:04d} queued.\")\n\n   await task_queue.put(take_order())\n\nasync def make_burger(order_num):\n\n   print(f\"Preparing burger #{order_num}...\")\n\n   await asyncio.sleep(5)  # time for making the burger\n\n   print(f\"Burger made #{order_num}\")\n\nasync def make_fries(order_num):\n\n   print(f\"Preparing fries #{order_num}...\")\n\n   await asyncio.sleep(2)  # time for making fries\n\n   print(f\"Fries made #{order_num}\")\n\nclass Staff:\n\n   def __init__(self, name):\n\n       self.name = name\n\n   async def working(self):\n\n       while True:\n\n           if task_queue.qsize() > 0:\n\n               print(f\"{self.name} is working...\")\n\n               task = await task_queue.get()\n\n               await task\n\n               print(f\"{self.name} finish task...\")\n\n           else:\n\n               await asyncio.sleep(1) #rest\n\nasync def main():\n\n   task_queue.put_nowait(take_order())\n\n   staff1 = Staff(name=\"John\")\n\n   staff2 = Staff(name=\"Jane\")\n\n   await asyncio.gather(staff1.working(), staff2.working())\n\nif __name__ == \"__main__\":\n\n   s = time.perf_counter()\n\n   asyncio.run(main())\n\n   elapsed = time.perf_counter() - s\n\n   print(f\"Orders completed in {elapsed:0.2f} seconds.\")\nIn this example, there are multiple tasks, including making fries, which takes less time, and taking orders, which involves getting input from the user. \nNotice that the program stops waiting for the user’s input, and even the other staff who are not taking the order stop working in the background. This is because the input function is not async and therefore is not awaited. Remember, control in async code is only released when it is awaited. To fix that, we can replace:\ninput(\"Number of burgers:\")\nWith \nawait asyncio.to_thread(input, \"Number of burgers:\")\nAnd we do the same for fries – see the code below. Note that now the program runs in an infinite loop. If we need to stop it, we can deliberately crash the program with an invalid input.\nimport asyncio\n\nimport time\n\ntask_queue = asyncio.Queue()\n\norder_num = 0\n\nasync def take_order():\n\n   global order_num\n\n   order_num += 1\n\n   print(f\"Order burger and fries for order #{order_num:04d}:\")\n\n   burger_num = await asyncio.to_thread(input, \"Number of burgers:\")\n\n   for i in range(int(burger_num)):\n\n       await task_queue.put(make_burger(f\"{order_num:04d}-burger{i:02d}\"))\n\n   fries_num = await asyncio.to_thread(input, \"Number of fries:\")\n\n   for i in range(int(fries_num)):\n\n       await task_queue.put(make_fries(f\"{order_num:04d}-fries{i:02d}\"))\n\n   print(f\"Order #{order_num:04d} queued.\")\n\n   await task_queue.put(take_order())\n\nasync def make_burger(order_num):\n\n   print(f\"Preparing burger #{order_num}...\")\n\n   await asyncio.sleep(5)  # time for making the burger\n\n   print(f\"Burger made #{order_num}\")\n\nasync def make_fries(order_num):\n\n   print(f\"Preparing fries #{order_num}...\")\n\n   await asyncio.sleep(2)  # time for making fries\n\n   print(f\"Fries made #{order_num}\")\n\nclass Staff:\n\n   def __init__(self, name):\n\n       self.name = name\n\n   async def working(self):\n\n       while True:\n\n           if task_queue.qsize() > 0:\n\n               print(f\"{self.name} is working...\")\n\n               task = await task_queue.get()\n\n               await task\n\n               print(f\"{self.name} finish task...\")\n\n           else:\n\n               await asyncio.sleep(1) #rest\n\nasync def main():\n\n   task_queue.put_nowait(take_order())\n\n   staff1 = Staff(name=\"John\")\n\n   staff2 = Staff(name=\"Jane\")\n\n   await asyncio.gather(staff1.working(), staff2.working())\n\nif __name__ == \"__main__\":\n\n   s = time.perf_counter()\n\n   asyncio.run(main())\n\n   elapsed = time.perf_counter() - s\n\n   print(f\"Orders completed in {elapsed:0.2f} seconds.\")\nBy using asyncio.to_thread, we have put the input function into a separate thread (see this reference). Do note, however, that this trick only unblocks I/O-bounded tasks if the Python GIL is present.\nIf you run the code above, you may also see that the standard I/O in the terminal is scrambled. The user I/O and the record of what is happening should be separate. We can put the record into a log to inspect later. \nimport asyncio\n\nimport logging\n\nimport time\n\nlogger = logging.getLogger(__name__)\n\nlogging.basicConfig(filename='pyburger.log', level=logging.INFO)\n\ntask_queue = asyncio.Queue()\n\norder_num = 0\n\nclosing = False\n\nasync def take_order():\n\n   global order_num, closing\n\n   try:\n\n       order_num += 1\n\n       logger.info(f\"Taking Order #{order_num:04d}...\")\n\n       print(f\"Order burger and fries for order #{order_num:04d}:\")\n\n       burger_num = await asyncio.to_thread(input, \"Number of burgers:\")\n\n       for i in range(int(burger_num)):\n\n           await task_queue.put(make_burger(f\"{order_num:04d}-burger{i:02d}\"))\n\n       fries_num = await asyncio.to_thread(input, \"Number of fries:\")\n\n       for i in range(int(fries_num)):\n\n           await task_queue.put(make_fries(f\"{order_num:04d}-fries{i:02d}\"))\n\n       logger.info(f\"Order #{order_num:04d} queued.\")\n\n       print(f\"Order #{order_num:04d} queued, please wait.\")\n\n       await task_queue.put(take_order())\n\n   except ValueError:\n\n       print(\"Goodbye!\")\n\n       logger.info(\"Closing down... stop taking orders and finish all tasks.\")\n\n       closing = True\n\nasync def make_burger(order_num):\n\n   logger.info(f\"Preparing burger #{order_num}...\")\n\n   await asyncio.sleep(5)  # time for making the burger\n\n   logger.info(f\"Burger made #{order_num}\")\n\nasync def make_fries(order_num):\n\n   logger.info(f\"Preparing fries #{order_num}...\")\n\n   await asyncio.sleep(2)  # time for making fries\n\n   logger.info(f\"Fries made #{order_num}\")\n\nclass Staff:\n\n   def __init__(self, name):\n\n       self.name = name\n\n   async def working(self):\n\n       while True:\n\n           if task_queue.qsize() > 0:\n\n               logger.info(f\"{self.name} is working...\")\n\n               task = await task_queue.get()\n\n               await task\n\n               task_queue.task_done()\n\n               logger.info(f\"{self.name} finish task.\")\n\n           elif closing:\n\n               return\n\n           else:\n\n               await asyncio.sleep(1) #rest\n\nasync def main():\n\n   global task_queue\n\n   task_queue.put_nowait(take_order())\n\n   staff1 = Staff(name=\"John\")\n\n   staff2 = Staff(name=\"Jane\")\n\n   print(\"Welcome to Pyburger!\")\n\n   logger.info(\"Ready for business!\")\n\n   await asyncio.gather(staff1.working(), staff2.working())\n\n   logger.info(\"All tasks finished. Closing now.\")\n\nif __name__ == \"__main__\":\n\n   s = time.perf_counter()\n\n   asyncio.run(main())\n\n   elapsed = time.perf_counter() - s\n\n   logger.info(f\"Orders completed in {elapsed:0.2f} seconds.\")\nIn this final code block, we have logged the simulation information in pyburger.log and reserved the terminal for messages for customers. We also catch invalid input during the ordering process and switch a closing flag to True if the input is invalid, assuming the user wants to quit. Once the closing flag is set to True, the worker will return, ending the coroutine’s infinite while loop.\nHow does threading work in Python?\nIn the example above, we put an I/O-bound task into another thread. You may wonder if we can put all tasks into separate threads and let them run concurrently. Let’s try using threading instead of asyncio.\nConsider the code we have as shown below, where we create burgers concurrently with no limitation put in place:\nimport asyncio\n\nimport time\n\nasync def make_burger(order_num):\n\n    print(f\"Preparing burger #{order_num}...\")\n\n    await asyncio.sleep(5) # time for making the burger\n\n    print(f\"Burger made #{order_num}\")\n\nasync def main():\n\n    order_queue = []\n\n    for i in range(3):\n\n        order_queue.append(make_burger(i))\n\n    await asyncio.gather(*(order_queue))\n\nif __name__ == \"__main__\":\n\n    s = time.perf_counter()\n\n    asyncio.run(main())\n\n    elapsed = time.perf_counter() - s\n\n    print(f\"Orders completed in {elapsed:0.2f} seconds.\")\n\n```\n\nInstead of creating async coroutines to make the burgers, we can just send functions down different threads like this:\n\n```\n\nimport threading\n\nimport time\n\ndef make_burger(order_num):\n\n   print(f\"Preparing burger #{order_num}...\")\n\n   time.sleep(5) # time for making the burger\n\n   print(f\"Burger made #{order_num}\")\n\ndef main():\n\n   order_queue = []\n\n   for i in range(3):\n\n       task = threading.Thread(target=make_burger, args=(i,))\n\n       order_queue.append(task)\n\n       task.start()\n\n   for task in order_queue:\n\n       task.join()\n\nif __name__ == \"__main__\":\n\n   s = time.perf_counter()\n\n   main()\n\n   elapsed = time.perf_counter() - s\n\n   print(f\"Orders completed in {elapsed:0.2f} seconds.\")\nIn the first for loop in main, tasks are created in different threads and get a kickstart. The second for loop makes sure all the burgers are made before the program moves on (that is, before it returns to main).\nIt is more complicated when we have only two staff members. Each member of the staff is represented with a thread, and they will take tasks from a normal list where they are all stored.\nimport threading\n\nimport time\n\norder_queue = []\n\ndef take_order():\n\n   for i in range(3):\n\n       order_queue.append(make_burger(i))\n\ndef make_burger(order_num):\n\n   def making_burger():\n\n       print(f\"Preparing burger #{order_num}...\")\n\n       time.sleep(5)  # time for making the burger\n\n       print(f\"Burger made #{order_num}\")\n\n   return making_burger\n\ndef working():\n\n     while len(order_queue) > 0:\n\n         print(f\"{threading.current_thread().name} is working...\")\n\n         task = order_queue.pop(0)\n\n         task()\n\n         print(f\"{threading.current_thread().name} finish task...\")\n\ndef main():\n\n   take_order()\n\n   staff1 = threading.Thread(target=working, name=\"John\")\n\n   staff1.start()\n\n   staff2 = threading.Thread(target=working, name=\"Jane\")\n\n   staff2.start()\n\n   staff1.join()\n\n   staff2.join()\n\nif __name__ == \"__main__\":\n\n s = time.perf_counter()\n\n main()\n\n elapsed = time.perf_counter() - s\n\n print(f\"Orders completed in {elapsed:0.2f} seconds.\")\nWhen you run the code above, an error may occur in one of the threads, saying that it is trying to get a task from an empty list. You may wonder why this is the case, since we have a condition in the while loop that causes it to continue only if the task_queue is not empty. Nevertheless, we still get an error because we have encountered race conditions.\nRace conditions\nRace conditions can occur when multiple threads attempt to access the same resource or data at the same time and cause problems in the system. The timing and order of when the resource is accessed are important to the program logic, and unpredictable timing or the interleaving of multiple threads accessing and modifying shared data can cause errors.\nTo solve the race condition in our program, we will deploy a lock to the task_queue:\nqueue_lock = threading.Lock()\nFor working, we need to make sure we have access rights to the queue when checking its length and getting tasks from it. While we have the rights, other threads cannot access the queue:\ndef working():\n\n   while True:\n\n       with queue_lock:\n\n           if len(order_queue) == 0:\n\n               return\n\n           else:\n\n               task = order_queue.pop(0)\n\n       print(f\"{threading.current_thread().name} is working...\")\n\n       task()\n\n       print(f\"{threading.current_thread().name} finish task...\")\n\n```\n\nBased on what we have learned so far, we can complete our final code with threading like this:\n\n```\n\nimport logging\n\nimport threading\n\nimport time\n\nlogger = logging.getLogger(__name__)\n\nlogging.basicConfig(filename=\"pyburger_threads.log\", level=logging.INFO)\n\nqueue_lock = threading.Lock()\n\ntask_queue = []\n\norder_num = 0\n\nclosing = False\n\ndef take_order():\n\n   global order_num, closing\n\n   try:\n\n       order_num += 1\n\n       logger.info(f\"Taking Order #{order_num:04d}...\")\n\n       print(f\"Order burger and fries for order #{order_num:04d}:\")\n\n       burger_num = input(\"Number of burgers:\")\n\n       for i in range(int(burger_num)):\n\n           with queue_lock:\n\n               task_queue.append(make_burger(f\"{order_num:04d}-burger{i:02d}\"))\n\n       fries_num = input(\"Number of fries:\")\n\n       for i in range(int(fries_num)):\n\n           with queue_lock:\n\n               task_queue.append(make_fries(f\"{order_num:04d}-fries{i:02d}\"))\n\n       logger.info(f\"Order #{order_num:04d} queued.\")\n\n       print(f\"Order #{order_num:04d} queued, please wait.\")\n\n       with queue_lock:\n\n           task_queue.append(take_order)\n\n   except ValueError:\n\n       print(\"Goodbye!\")\n\n       logger.info(\"Closing down... stop taking orders and finish all tasks.\")\n\n       closing = True\n\ndef make_burger(order_num):\n\n   def making_burger():\n\n       logger.info(f\"Preparing burger #{order_num}...\")\n\n       time.sleep(5)  # time for making the burger\n\n       logger.info(f\"Burger made #{order_num}\")\n\n   return making_burger\n\ndef make_fries(order_num):\n\n   def making_fries():\n\n       logger.info(f\"Preparing fried #{order_num}...\")\n\n       time.sleep(2)  # time for making fries\n\n       logger.info(f\"Fries made #{order_num}\")\n\n   return making_fries\n\ndef working():\n\n   while True:\n\n       with queue_lock:\n\n           if len(task_queue) == 0:\n\n               if closing:\n\n                   return\n\n               else:\n\n                   task = None\n\n           else:\n\n               task = task_queue.pop(0)\n\n       if task:\n\n           logger.info(f\"{threading.current_thread().name} is working...\")\n\n           task()\n\n           logger.info(f\"{threading.current_thread().name} finish task...\")\n\n       else:\n\n           time.sleep(1)  # rest\n\ndef main():\n\n   print(\"Welcome to Pyburger!\")\n\n   logger.info(\"Ready for business!\")\n\n   task_queue.append(take_order)\n\n   staff1 = threading.Thread(target=working, name=\"John\")\n\n   staff1.start()\n\n   staff2 = threading.Thread(target=working, name=\"Jane\")\n\n   staff2.start()\n\n   staff1.join()\n\n   staff2.join()\n\n   logger.info(\"All tasks finished. Closing now.\")\n\nif __name__ == \"__main__\":\n\n   s = time.perf_counter()\n\n   main()\n\n   elapsed = time.perf_counter() - s\n\n   logger.info(f\"Orders completed in {elapsed:0.2f} seconds.\")\nIf you compare the two code snippets using asyncio and threading, they should have similar results. You may wonder which one is better and why you should choose one over the other.\nPractically, writing asyncio code is easier than multithreading because we don’t have to take care of potential race conditions and deadlocks by ourselves. Controls are passed around coroutines by default, so no locks are needed. However, Python threads do have the potential to run in parallel, just not most of the time with the GIL in place. We can revisit this when we talk about nogil (thread-free) Python in the next blog post.\nBenefiting from concurrency\nWhy do we want to use concurrency in programming? There’s one main reason: speed. Like we have illustrated above, tasks can be completed faster if we can cut down the waiting time. There are different types of waiting in computing, and for each one, we tend to use different methods to save time.\nI/O-bound tasks\nA task or program is considered input/output (I/O) bound when its execution speed is primarily limited by the speed of I/O operations, such as reading from a file or network, or waiting for user input. I/O operations are generally slower than other CPU operations, and therefore, tasks that involve lots of them can take significantly more time. Typical examples of these tasks include reading data from a database, handling web requests, or working with large files.\nUsing async/await concurrency can help optimize the waiting time during I/O-bound tasks by unblocking the processing sequence and letting other tasks be taken care of while waiting.\nAsync/await concurrency is beneficial in many Python applications, such as web applications that involve a lot of communication with databases and handling web requests. GUIs (graphical user interfaces) can also benefit from async/await concurrency by allowing background tasks to be performed while the user is interacting with the application.\nCPU-bound tasks\nA task or program is considered CPU-bound when its execution speed is primarily limited by the speed of the CPU. Typical examples include image or video processing, like resizing or editing, and complex mathematical calculations, such as matrix multiplication or training machine learning models.\nContrary to I/O-bound tasks, CPU-bound tasks can rarely be optimised by using async/await concurrency, as the CPU is already busy working on the tasks. If you have more than one CPU in your machine, or if you can offload some of these tasks to one or more GPUs, then CPU-bound tasks can be finished faster by creating more threads and performing multiprocessing. Multiprocessing can optimise how these CPUs and GPUs are used, which is also why many machine learning and AI models these days are trained on multiple GPUs.\nThis, however, is tough to perform with pure Python code, as Python itself is designed to provide abstract layers so users do not have to control the lower-level computation processes. Moreover, Python’s GIL limits the sharing of Python resources across multiple threads on your computer. Recently, Python 3.13 made it possible to remove the GIL, allowing for true multithreading. We will discuss the GIL, and the ability to go without it, in the next blog post.\nSometimes, none of the methods we mentioned above are able to speed up CPU-bound tasks sufficiently. When that is the case, the CPU-bound tasks may need to be broken into smaller ones so that they can be performed simultaneously over multiple threads, multiple processors, or even multiple machines. This is parallel processing, and you may have to rewrite your code completely to implement it. In Python, the multiprocessing package offers both local and remote concurrency, which can be used to work around the limitation of the GIL. We will also look at some examples of that in the next blog post.\nDebugging concurrent code in PyCharm\nDebugging async or concurrent code can be hard, as the program is not executed in sequence, meaning it is hard to see where and when the code is being executed. Many developers use print to help trace the flow of the code, but this approach is not recommended, as it is very clumsy and using it to investigate a complex program, like a concurrent one, isn’t easy. Plus, it is messy to tidy up after.\nMany IDEs provide debuggers, which are great for inspecting variables and the flow of the program. Debuggers also provide a clear stack trace across multiple threads. Let’s see how we can track the task_queue of our example restaurant simulation in PyCharm.\nFirst, we will put down some breakpoints in our code. You can do that by clicking the line number of the line where you want the debugger to pause. The line number will turn into a red dot, indicating that a breakpoint is set there. We will put breakpoints at lines 23, 27, and 65, where the task_queue is changed in different threads.\n\n\n\n\n\n\n\n\nThen we can run the program in debug mode by clicking the little bug icon in the top right.\n\n\n\n\nAfter clicking on the icon, the Debug window will open up. The program will run until it hits the first breakpoint highlighted in the code.\n\n\n\n\nHere we see the John thread is trying to pick up the task, and line 65 is highlighted. At this point, the highlighted line has not been executed yet. This is useful when we want to inspect the variables before entering the breakpoint.\nLet’s inspect what’s in the task_queue. You can do so simply by starting to type in the Debug window, as shown below.\n\n\n\n\nSelect or type in “task_queue”, and then press Enter. You will see that the take_order task is in the queue.\n\n\n\n\nNow, let’s execute the breakpoint by clicking the Step in button, as shown below.\n\n\n\n\nAfter pressing that and inspecting the Special Variables window that pops up, we see that the task variable is now take_order in the John thread.\n\n\n\n\nWhen querying the task_queue again, we see that now the list is empty.\n\n\n\n\nNow let’s click the Resume Program button and let the program run.\n\n\n\n\nWhen the program hits the user input part, PyCharm will bring us to the Console window so we can provide the input. Let’s say we want two burgers. Type “2” and press Enter.\n\n\n\n\nNow we hit the second breakpoint. If we click on Threads & Variables to go back to that window, we’ll see that burger_num is two, as we entered.\n\n\n\n\nNow let’s step into the breakpoint and inspect the task_queue, just like we did before. We see that one make_burger task has been added.\n\n\n\n\nWe let the program run again, and if we step into the breakpoint when it stops, we see that Jane is picking up the task.\n\n\n\n\nYou can inspect the rest of the code yourself. When you are done, simply press the red Stop button at the top of the window.\n\n\n\n\nWith the debugger in PyCharm, you can follow the execution of your program across different threads and inspect different variables very easily.\nConclusion\nNow we have learned the basics of concurrency in Python, and I hope you will be able to master it with practice. In the next blog post, we will have a look at the Python GIL, the role it plays, and what changes when it is absent.\nPyCharm provides powerful tools for working with concurrent Python code. As demonstrated in this blog post, the debugger allows the step-by-step inspection of both async and threaded code, helping you track the execution flow, monitor shared resources, and detect issues. With intuitive breakpoints, real-time variable views, seamless console integration for user input, and robust logging support, PyCharm makes it easier to write, test, and debug applications with confidence and clarity.\nDownload PyCharm Now",
        "dc:creator": "Cheuk Ting Ho",
        "content": "If you have been coding with Python for a while, especially if you have been using frameworks and libraries such as Fast API and discord.py, then you have probably been using async/await or asyncio. You may have heard statements like “multithreading in Python isn’t real”, and you may also know about the famous (or infamous) [&#8230;]",
        "contentSnippet": "If you have been coding with Python for a while, especially if you have been using frameworks and libraries such as Fast API and discord.py, then you have probably been using async/await or asyncio. You may have heard statements like “multithreading in Python isn’t real”, and you may also know about the famous (or infamous) […]",
        "guid": "https://blog.jetbrains.com/?post_type=pycharm&p=571165",
        "categories": [
          "how-tos",
          "tutorials",
          "web-development",
          "concurrency",
          "python"
        ],
        "isoDate": "2025-06-10T11:57:58.000Z"
      },
      {
        "creator": "Irina Mariasova",
        "title": "Text Blocks in Java: Perfect for Multiline Strings",
        "link": "https://blog.jetbrains.com/idea/2025/06/text-blocks-in-java-perfect-for-multiline-strings/",
        "pubDate": "Tue, 10 Jun 2025 11:28:36 +0000",
        "content:encodedSnippet": "You’ve likely used String variables to store values that span multiple lines, such as LLM prompts, JSON, HTML, XML, code snippets, and other such values.\nSome of these, such as a JSON value, include double quotes as part of the data. Imagine the inconvenience of using backslashes (\\) to escape those quotes, indenting lines using newlines, tabs, or spaces, and adding a concatenation operator at the end of each line. Coding such string values is a nightmare. The resulting string is not just hard to write, but also hard to read. Language-specific errors, like a missing comma in a JSON value, can easily creep in.\nDon’t worry, there’s already a solution. Java 15 introduced Text Blocks, multiline strings that make it easier to define data that spans multiple lines. Text Blocks remove the need for concatenation operators or escape sequences when working with HTML, XML, JSON, or SQL queries stored as strings. The values are easier to read, and it’s simpler to spot issues like missing spaces in SQL queries or a missing comma in a JSON value.\nLet’s understand the benefits of using Text Blocks with an example.\nAn example – what are the existing pain points\nImagine you need to store the following JSON text in your Java code:\n{\n    \"name\": \"Sonam Wangchuk\"\n    \"movement\": \"#ILiveSimply\",\n    \"result\": \"Let planet simply live\"\n}\nThis JSON value can be stored as a multi line String value (without using a TextBlock) as follows:\n\n\n\nString myJson = \"{\\n\" +\n                \"    \\\"name\\\": \\\"Sonam Wangchuk\\\"\\n\" +\n                \"    \\\"movement\\\": \\\"#ILiveSimply\\\",\\n\" +\n                \"    \\\"result\\\": \\\"Let planet simply live\\\"\\n\" +\n                \"}\";\n\n\n\nWriting the preceding code manually can be a nightmare. Escape characters and concatenation operators make it hard to write and read. To include double quotes within a string, you must escape them using a backslash (since ” is also a string delimiter). To preserve the formatting of the JSON object, you need to add whitespace such as new lines, tabs, or spaces.\n\n\n\nWith all that formatting overhead, you probably missed that the JSON above is missing a comma at the end of the first line. This missing comma can cause a parsing error later if you try to convert the string into a JSON object.\n\n\n\nLet’s see how Text Blocks can help.\n\n\n\nUsing Text Blocks\n\n\n\nTextBlocks are multiline Strings (their type is java.lang.String). By using Text Blocks, you can store the previous String value, as follows:\n\n\n\nString myJson = \"\"\"\n                {\n                    \"name\": \"Sonam Wangchuk\"\n                    \"movement\": \"#ILiveSimply\",\n                    \"result\": \"Let planet simply live\"\n                }\"\"\";\n\n\n\nText Blocks are simple to create, read, and edit. They eliminate the need for concatenation operators and (most) escape sequences when working with String values that span more than one line, as shown below:\n\n\n\n\n\n\n\n\nThe next section covers the syntax details of text blocks. If you’re already familiar with them, feel free to skip ahead.\n\n\n\nSyntax of TextBlocks\n\n\n\nHere are a couple of syntax rules to follow when you are working with Text Blocks.\n\n\n\nOpening and closing delimiter – \"\"\"\n\n\n\nUnlike the single double quotes (\") used for regular String values, Text Blocks use three double quotes (\"\"\") as their opening and closing delimiters. The opening delimiter can be followed by zero or more whitespaces, but it must be followed by a line terminator. A Text Block value begins after this line terminator.\n\n\n\nIf a Text Block doesn’t include a newline character immediately after the opening \"\"\", IntelliJ IDEA can detect this and prompt you to correct it:\n\n\n\n\n\n\n\n\nIncidental white spaces\n\n\n\nWhat rules does the compiler follow to include or exclude leading and trailing whitespace in a Text Block? Before we answer this question, let’s first understand what whitespaces are. When we talk about a whitespace in Java Text Blocks, it can refer to different types of characters, such as:\n\n\nA space – The standard space character we use to separate words\nTabs – The popular Tab characters, that is, ('\\t'). Wars have been fought over whether to use tabs or space to indent code :)\nLine breaks – Newline characters ('\\n' on Unix/Linux/macOS, or '\\r\\n' on Windows)\nCarriage returns – ('\\r')\n\n\nFirst, let’s talk about how the leading white spaces are handled in a Text Block.\n\n\n\nLeading spaces\n\n\n\nWhy do you need leading spaces? You would usually add tabs or spaces to values, such as a JSON, to align them vertically in your code. In Text Blocks, the leftmost non-whitespace character on any of the lines or the leftmost closing delimiter defines where meaningful white space begins. IntelliJ IDEA helps you view this position – using a vertical line – a feature that I absolutely love about Text Block’s support in IntelliJ IDEA.\n\n\n\nHere’s how the vertical bar in IntelliJ IDEA lets you visualize the starting position of your Text Block values:\n\n\n\n\n\n\n\n\nJust in case you can’t view the vertical green line shown in the preceding image, use Shift+Shift, Find ‘Show indent guides’, and enable it in IntelliJ IDEA.\n\n\n\nThe following image shows another way to understand which leading spaces are included in your text blocks – blue rectangles represent the spaces that are not part of your textblock and the light green rectangles represent the leading spaces that are included in your text block:  \n\n\n\n\n\n\n\n\nIf you move the closing triple quotes to the left, the white spaces included in the textblock changes, as shown in the following image:\n\n\n\n\n\n\n\n\nTrailing white spaces\n\n\n\nBy default, the trailing white spaces are removed in Text Block values. IntelliJ IDEA can detect when you add trailing white spaces in your textblocks. It would highlight those spaces (to ensure you didn’t add them by mistake). \n\n\n\nWhen you click Alt + Enter, it could prompt you to either ‘Escape trailing whitespace characters’, or ‘Remove trailing whitespace characters’. If you choose the former option, IntelliJ IDEA will add \\s at the end (\\s represents a single space), as shown in the following gif:\n\n\n\n\n\n\n\n\nWhere would you use a trailing white space?\n\n\n\nImagine you are using a method from a library that reads the first 40 characters of a line to extract two values from it, and store it in a Map, as follows:\n\n\n\npublic Map<String, String> parseFixedWidthData(String fixedWidthData) {\n    Map<String, String> result = new HashMap<>();\n    String[] lines = fixedWidthData.split(\"\\n\");\n    for (String line : lines) {\n        String field1 = line.substring(0, 19).trim();\n        String field2 = line.substring(20, 39).trim();\n        result.put(field1, field2);\n    }\n    return result;\n}\n\n\n\nIf you are using a textblock to pass value to the method parseFixedWidthData, you should define it as follows, escaping the trailing whitespaces, so the the preceding method doesn’t throw an IndexOutOfBounds exception:\n\n\n\nString fixedWidthData = \"\"\"\n                        CUSTOMER_NAME       JOHN DOE           \\s\n                        ACCOUNT_NUMBER      12345678-9879      \\s\n                        AGE                      45            \\s\"\"\";\n\n\n\nContinuation char – \\\n\n\n\nWhen you place your text on a new line in a text block, a new line char is added to your String value. Imagine using a textblock to store a store long URL so that it is easy to read, as follows:\n\n\n\nString apiUrl = \"\"\"\n        https://www.alamy.com/stock-photo-abstract-geometric-pattern-hipster-fashion-design-print-hexagonal-175905258.html?\n        imageid=0DF26DE9-AC7B-4C78-8770-E1AC9EC8783A\n        &p=379271\n        &pn=1\n        &searchId=8cf93ae4926578c6f55e3756c4010a71&searchtype=0\"\"\";\n\n\n\nHowever, if you use the preceding text block to connect to a URL and retrieve a response, the code will throw an exception. Inclusion of \\n in the URL makes it an invalid URL. To address it, you can use the continuation character, that is, \\ at the end of a line in your text block (so that the resulting string doesn’t include a new line character):\n\n\n\nString apiUrl = \"\"\"\n        https://www.alamy.com/stock-photo-abstract-geometric-pattern-hipster-fashion-design-print-hexagonal-175905258.html?\\\n        imageid=0DF26DE9-AC7B-4C78-8770-E1AC9EC8783A\\\n        &p=379271\\\n        &pn=1\\\n        &searchId=8cf93ae4926578c6f55e3756c4010a71&searchtype=0\"\"\";\n\n\n\nMore about TextBlocks\n\n\n\nWith the syntax rules under your belt, let’s learn more about Text blocks.\n\n\n\nNot a String variation\n\n\n\nJava isn’t adding a variation of type String with Text Blocks. They are compiled to regular String instances (java.lang.String). You can think of Textblocks as syntactic sugar that allows you to write Strings without using the concatenating operators and escape sequences. If you decompile a class that defines a text block, you’ll see that they are compiled to regular strings with single pair of double quotes as the delimiter, as shown in the following gif (the top bar mentions that you are viewing a Decompiled .class file):\n\n\n\n\n\n\n\n\nCall any String method on a text block\n\n\n\nSince there is just one java.lang.String type (not a variation for Text blocks), it means that you can call all String methods on text blocks:\n\n\n\n\n\n\n\n\nConvert a text block to a regular string\n\n\n\nImagine you are migrating your codebase to a development environment that doesn’t support Textblocks (Java 14 or earlier versions). In such case, you can invoke Context Actions to convert a Text Block to a regular String literal:\n\n\n\n\n\n\n\n\nLanguage Injections in Textblocks\n\n\n\nInjecting a language into Text Blocks in IntelliJ IDEA enables syntax highlighting and real-time error detection, helping to catch issues such as unclosed JSON values or HTML tags, missing or mismatched quotes in attributes, inconsistent indentation, and unescaped special characters. You also get IntelliJ IDEA’s support like code completion, and value validation. \n\n\n\nThe following gif shows how you can inject JSON as a language in a text block (language injection in IntelliJ IDEA applies to regular strings too):\n\n\n\n\n\n\n\n\nAs you can see, the language injection option enables you to choose from multiple options (including JSON).\n\n\n\nPractical examples – where to use Text Blocks\n\n\n\nApart from using Textblocks to store JSON data (as shown in the preceding sections), you can think of using Text Blocks to store values that usually span multiple lines such as XML, HTML data, or code snippets written in other programming languages. This section highlights the practical examples where you can use text blocks.\n\n\n\n1. ASCII Art\n\n\n\nYou can use textblock to store and output ASCII art, such as the following:\n\n\n\nString textblock = \"\"\"\n        ╔═══════════════════════════════════════════════════════════════════════════════════════╗\n        ║                                                                                       ║\n        ║    ████████╗███████╗██╗  ██╗████████╗    ██████╗ ██╗      ██████╗  ██████╗██╗  ██╗    ║\n        ║    ╚══██╔══╝██╔════╝╚██╗██╔╝╚══██╔══╝    ██╔══██╗██║     ██╔═══██╗██╔════╝██║ ██╔╝    ║\n        ║       ██║   █████╗   ╚███╔╝    ██║       ██████╔╝██║     ██║   ██║██║     █████╔╝     ║\n        ║       ██║   ██╔══╝   ██╔██╗    ██║       ██╔══██╗██║     ██║   ██║██║     ██╔═██╗     ║\n        ║       ██║   ███████╗██╔╝ ██╗   ██║       ██████╔╝███████╗╚██████╔╝╚██████╗██║  ██╗    ║\n        ║       ╚═╝   ╚══════╝╚═╝  ╚═╝   ╚═╝       ╚═════╝ ╚══════╝ ╚═════╝  ╚═════╝╚═╝  ╚═╝    ║\n        ║                                                                                       ║\n        ╠═══════════════════════════════════════════════════════════════════════════════════════╣\"\"\";\n\n\n\n\n\n\n\n\n\n2. Logging data\n\n\n\nImagine while working with an online shopping application, you need to log a message with order details, if the quantity for a product in an order is 0 or negative. It is common to create a String that includes literals, such as, ‘Invalid order’, and order details that can be accessed using variables like orderId, etc. Here’s a sample code to accomplish this (focus on the concatenated String):\n\n\n\npublic void processOrder(int orderId, String product, int qty, LocalDate orderDate) {\n   if (qty <= 0) {\n       String errorMessage = \"Invalid order quantity:\" + qty + \n                             \"for product\" + product + \",order ID\" + orderId;\n       logger.error(errorMessage);\n       return;\n   }\n   //.. Remaining code\n}\n\n\n\nThe code seems harmless. However, I’ve often missed adding spaces before and after the literal text values in similar code, generating a log message similar to the following that is hard to read:\n\n\n\nInvalid order quantity: -5for productWidget,order ID12345\n\n\n\nA safer bet would be to use textblocks for this logging message that can help you spot the missing spaces. Even if you miss adding spaces, the new line characters can space out the log messages:\n\n\n\npublic void processOrder(int orderId, String product, int qty, LocalDate orderDate) {\n        if (qty <= 0) {\n            String errorMessage = (\"\"\"\n                                   Invalid order quantity:%d\n                                   for product %s, \n                                   order ID %d\"\"\").formatted(qty, product, orderId);\n            logger.info(errorMessage);\n            System.out.println(errorMessage);\n            return;\n        }\n        //.. Remaining code\n    }\n\n\n\n3. XML or HTML data\n\n\n\nHere’s an example of a Text Block storing a HTML value:\n\n\n\nString html = \"\"\"\n        <HTML>\n           <BODY>\n               <P>Stop generating 6 million tons of plastic waste</P>\n               <UL>\n                   <LI>Keep a spoon, fork, knife in your bag.</LI> \n                   <LI>Avoid using single use plastic cutlery.</LI>\n               </UL>\n           </BODY>\n        </HTML>\n        \"\"\";\n\n\n\n4. Complex JSON data\n\n\n\nIn the beginning of this blog post, I covered how text blocks can help eliminate the clutter. The clutter increases manifolds, when you start working with more complex JSON objects, as follows:\n\n\n\nString json = \"{\\n\" +\n              \"  \\\"cod\\\": \\\"200\\\",\\n\" +\n              \"  \\\"city\\\": {\\n\" +\n              \"    \\\"id\\\": 524901,,,,\\n\" +\n              \"    \\\"name\\\": \\\"GreatCity\\\",\\n\" +\n              \"    \\\"country\\\": \\\"AwesomeCountry\\\",\\n\" +\n              \"    \\\"coord\\\": {\\n\" +\n              \"      \\\"lat\\\": 55.7522,\\n\" +\n              \"      \\\"lon\\\": 37.6156\\n\" +\n              \"    }\\n\" +\n              \"  }\\n\" +\n              \"}\";\n\n\n\nWith textblocks, the cognitive load reduces, as you can see in the following code snippet:\n\n\n\nString json = \"\"\"\n              {\n                \"cod\": \"200\",\n                \"city\": {\n                  \"id\": 524901,,,,\n                  \"name\": \"GreatCity\",\n                  \"country\": \"AwesomeCountry\",\n                  \"coord\": {\n                    \"lat\": 55.7522,\n                    \"lon\": 37.6156\n                  }\n                }\n              }\"\"\";\n\n\n\nPerhaps you can inject language in the preceding text block and determine the syntax errors with the JSON value.\n\n\n\n5. Multiline String values\n\n\n\nHere’s just a long line of String, stored using Text Blocks: \n\n\n\nString aLongString = \"\"\"\n                     I'm a long String value, which can't fit on a \n                     Single line. \n                     \"Hey!\", would you prefer a cup of coffee?\n                     \"Yes, please\".\n                     \"\"\";\n\n\n\nText Blocks take off the visual clutter from multiline strings which existed in the form of concatenation operators and escape sequences. \n\n\n\n6. SQL Queries\n\n\n\nImagine using the following code to store a SQL query:\n\n\n\nString query = \n  \"SELECT name, age\" +\n  \"FROM EMP\" + \n  \"WHERE name = \\'John\\'\" +\n  \"AND age > 20\";\n\n\n\nThe preceding code represents an invalid query. Due to missing spaces at the end of each line, this query will be interpreted as the following:\n\n\n\nSELECT name, ageFROM EMPWHERE name = 'John'AND age > 20\nYou can address these issues by using text blocks:\nString query = \"\"\"\n  SELECT name, age\n  FROM EMP\n  WHERE name = 'John'\n    AND age > 20\n  \"\"\";\n\n\n\n7. Email templates – multiline string values with literal and variable values\n\n\n\nWhen concatenating string literals with variable values, it is easy to miss adding a single space in string literal, right before or after a variable value. It could result in poorly formatted output, or output that is not-so-readable. It could also result in displaying output you didn’t expect due to those missing spaces. Consider the following code that uses a combination of string literals and variable values to send a text to a customer:\n\n\n\nString username = \"Alice\";\n    String topic = \"Java Records\";\n    String previousContext = \"We were discussing immutable data classes.\";\n        \n    String email = \"Hi\" + username + \",\\n\\n\" +\n            \"Let's continue our discussion about \" + topic + \".\\n\" +\n            \"For context, \" + previousContext + \"\\n\\n\" +\n            \"Can you tell me more about what specific aspects of\" + topic + \"you're interested in?\";\n\n\n\nYou could use TextBlock and formatted(), so that the variable substitution is cleaner:\n\n\n\nString email = \"\"\"\n                Hi %s,\n                \n                Let's continue our discussion about %s.\n                For context, %s\n                \n                Can you tell me more about what specific aspects of %s you're interested in?\n                \"\"\".formatted(username, topic, previousContext, topic);\n\n\n\n\n\n   \n\n\n\n8. Creating simple bills \n\n\n\nYou can create simple bills (such as the following) to print using textblocks:\n\n\n\n--------------------------------------------------------------------------------------\n                            Your Neighbourhood Art Supplies Store\n--------------------------------------------------------------------------------------\nDate:               2023-10-20                               Invoice Number:     12345                 \nCustomer Details\nName:               John Smith            \nAddress:            123 Main Street       \nCity:               Smallville            \nPhone:              555-123-4567          \n--------------------------------------------------------------------------------------\nS.No.           Item Name                  Quantity        Unit Price($)      Total($)\n--------------------------------------------------------------------------------------\n1        Acrylic Paint Set                       1             20.00             20.00\n2        Watercolor Brushes                      5             15.00             75.00\n3        Sketchbook                             12             10.00            120.00\n4        Oil Paints Set                          1             25.00             25.00\n5        Canvas Panels (5-pack)                  6             12.00             72.00\n--------------------------------------------------------------------------------------\nSubtotal:       $82.0\nSales Tax (6%): $4.92\nTotal Amount:   $86.92;\n--------------------------------------------------------------------------------------\n                            Thank you for shopping with us!\n--------------------------------------------------------------------------------------\n\n\n\n\n\nCode Migrations – using text blocks instead of a regular string\n\n\n\nThe release of Java 25, the next LTS version, is around the corner. If you plan to migrate your existing codebases using JDK version 14 or earlier to a newer version, you can start using Text Blocks in your code.\n\n\n\nTo migrate all eligible multiline String values currently stored across multiple lines using concatenation operators to Text Blocks, you can proceed in two ways. The first approach is to run the inspection “Text blocks can be used” on your entire project or selected directories. In the Problems view window that opens, you can apply these changes individually or in a batch.\n\n\n\nTo demonstrate this feature, I forked an open-source project from GitHub, JSON-java, and ran the inspection “Text blocks can be used,” as shown in the following GIF:\n\n\n\n\n\n\n\n\nThe second approach is to create a new profile in Settings, say, ‘Migrate to 24’, and add all the migration inspections to this profile. Then, you can execute the ‘Inspect Code…’ command and run this inspection profile on your codebase. Use the Problems view window to accept multiple changes at once or review them individually.\n\n\n\nSummary\n\n\n\nText blocks in Java are syntactic sugar to make it easy for you to create string values that span multiple lines, without needing to use concatenation operators or escape sequences. This makes it easier to read and write such values, reducing cognitive load for us developers. Since the values are clutter-free, you can also spot syntax errors in these multiline values, such as a missing quote or comma. By injecting a language or a reference into these text blocks, IntelliJ IDEA can help you further by highlighting these errors and even suggesting how to fix them.\n\n\n\nText blocks start and end with three double quotes. By default, trailing whitespaces are ignored in text blocks. To include—or in other words, escape—the trailing whitespaces, use \\s. To join two lines, add a backslash (\\) at the end of the first line.\n\n\n\nText blocks are quite useful when you’re working with data that usually spans multiple lines, such as JSON, SQL queries, HTML, XML, and others. You could use text blocks to output beautiful line art, format log messages, or even generate simple bills for your neighbourhood stores.\n\n\n\nThe release of Java 25 is around the corner. If you’re still working with an older version of the JDK, such as 8 or 11, I recommend moving to a newer version so you can benefit from newer features like text blocks.\n\n\n\nHappy coding!",
        "dc:creator": "Irina Mariasova",
        "content": "You’ve likely used String variables to store values that span multiple lines, such as LLM prompts, JSON, HTML, XML, code snippets, and other such values. Some of these, such as a JSON value, include double quotes as part of the data. Imagine the inconvenience of using backslashes (\\) to escape those quotes, indenting lines using [&#8230;]",
        "contentSnippet": "You’ve likely used String variables to store values that span multiple lines, such as LLM prompts, JSON, HTML, XML, code snippets, and other such values. Some of these, such as a JSON value, include double quotes as part of the data. Imagine the inconvenience of using backslashes (\\) to escape those quotes, indenting lines using […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=573133",
        "categories": [
          "tutorials",
          "java",
          "textblocks"
        ],
        "isoDate": "2025-06-10T11:28:36.000Z"
      },
      {
        "creator": "Alyona Chernyaeva",
        "title": "Kotlin for Server-Side Development: Community Content Roundup #2",
        "link": "https://blog.jetbrains.com/kotlin/2025/06/kotlin-for-server-side-development-community-content-roundup-2/",
        "pubDate": "Tue, 10 Jun 2025 11:06:26 +0000",
        "content:encodedSnippet": "The Kotlin community keeps delivering valuable content for server-side development. From gRPC best practices to hands-on Ktor tutorials and Spring integrations, here are the latest highlights.\n📖 [Article] Kotlin Tips and Tricks You May Not Know: #6 — Inject Functions in Spring Boot – Elena van Engelen-Maslova shares how to inject functions in Spring Boot for cleaner and more flexible Kotlin code. A simple trick with real impact.\n📖 [Article] Learning Ktor Through a Spring Boot Lens. Part 1 – Rafał Maciak compares Spring Boot and Ktor to help developers familiar with Spring get up to speed with Kotlin-first backend development.\n🎥 [Video] Spring for GraphQL with Kotlin Coroutines – Piotr Wolak walks you through building reactive GraphQL APIs with Spring for GraphQL and Kotlin coroutines.\n📖 [Article series] Kotlin + gRPC by Lucas Fugisawa – A comprehensive series covering real-world practices for building gRPC services in Kotlin:\nBuild your first service in four steps\nEnhance Protobuf schema design with Optional, Repeated, Maps, Enums, Oneof and backwards compatibility\nNesting, Composition, Validations, and Idiomatic Builder DSL\nStreaming, Deadlines, and Structured Error Handling\nTooling, CI/CD, and Architectural Practices\n🎥 [Video] Ktor Server Full Crash Course For Beginners | Build a REST Api in Ktor with JWT Auth | Blog CRUD Api – Sunil Kumar shares a complete beginner-friendly guide to building a secure REST API with Ktor and JWT authentication.\nWant to be featured next?\nIf you’re building backends with Kotlin and sharing your knowledge – whether it’s a blog post, video, or sample project – tag it with #KotlinServerSide.\nWe regularly browse community content and highlight the most useful picks on our blog, @Kotlin X, and Kotlin Slack (get an invite here).\nKeep sharing, and we’ll keep amplifying.",
        "dc:creator": "Alyona Chernyaeva",
        "content": "The Kotlin community keeps delivering valuable content for server-side development. From gRPC best practices to hands-on Ktor tutorials and Spring integrations, here are the latest highlights. 📖 [Article] Kotlin Tips and Tricks You May Not Know: #6 — Inject Functions in Spring Boot – Elena van Engelen-Maslova shares how to inject functions in Spring Boot [&#8230;]",
        "contentSnippet": "The Kotlin community keeps delivering valuable content for server-side development. From gRPC best practices to hands-on Ktor tutorials and Spring integrations, here are the latest highlights. 📖 [Article] Kotlin Tips and Tricks You May Not Know: #6 — Inject Functions in Spring Boot – Elena van Engelen-Maslova shares how to inject functions in Spring Boot […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=574026",
        "isoDate": "2025-06-10T11:06:26.000Z"
      },
      {
        "creator": "Lena Morozova",
        "title": "How PhpStorm Helps Maintain PHP Open-Source Projects: Interviews and Real-World Examples",
        "link": "https://blog.jetbrains.com/blog/2025/06/10/how-phpstorm-helps-maintain-php-open-source-projects-interviews-and-real-world-examples/",
        "pubDate": "Tue, 10 Jun 2025 10:00:00 +0000",
        "content:encodedSnippet": "The PHP ecosystem is driven by passionate developers building tools that power everything from content management systems right the way through to testing libraries and database layers. Behind each project is a dedicated team working to modernize code, improve performance, and move the ecosystem forward.\nThe fact that many of these teams choose PhpStorm to support their work is a source of pride for all of us at JetBrains and serves as proof of the positive impact on the wider PHP community of our free and discounted license program for open-source contributors. This post highlights standout PHP projects and the people behind them. Whether they’re debugging complex systems or maintaining test suites, PhpStorm helps streamline workflows, reduce friction, and free up time for what matters most – building.\nPHPUnit\nSebastian Bergmann started PHPUnit as a university project, prompted by a discussion with a professor who thought that a tool like JUnit could not be implemented for PHP. Since then, PHPUnit has been the backbone of PHP testing for over two decades and has shaped how PHP developers write and maintain tests. It remains the go-to testing framework for PHP projects of all sizes.\nI tried every PHP IDE until I got my hands on PhpStorm – the first one that made me more productive, not less. It felt like home right away. I can’t imagine working without its code navigation and refactoring tools.\n— Sebastian Bergmann, PHPUnit creator\nThe latest release, PHPUnit 12, prioritizes code clarity. A major improvement is the clear distinction between test stubs and mock objects via dedicated APIs. This architectural shift simplifies test code maintenance and readability.\nLooking ahead, PHPUnit will introduce support for the Open Test Reporting format – a modern, extensible alternative to JUnit XML. Initial support is planned for PHPUnit 12.2 (June 2025), with JUnit XML being deprecated in PHPUnit 13 and removed in PHPUnit 14.\nDoctrine DBAL\nDoctrine DBAL is a widely used database abstraction layer that gives PHP developers a portable, object-oriented API to interact with SQL databases. It powers a wide range of applications and frameworks across the PHP ecosystem.\nI use PhpStorm daily to run PHPUnit tests locally with various configurations, interact with different databases, manage Docker containers, and run static analysis.\n— Sergei Morozov, Doctrine DBAL maintainer\nWhile the project is mature and provides most of the essential functionality, ongoing work includes a fundamental rework of schema management, addressing limitations of the original architecture, and ensuring better support for evolving SQL standards and database platforms.\nCodeIgniter\nCodeIgniter was created as a lightweight, high-performance PHP framework that prioritizes simplicity and developer freedom. It empowers developers to build on their own terms without rigid conventions – a core philosophy that continues to define its appeal.\nCodeIgniter v4 maintains the core principles of its predecessor while embracing modern software development practices, such as robust testing and integration with tools like PHPStan, Psalm, and Rector.\nOne of CodeIgniter v4’s key strengths is its alignment with PHP best practices, allowing PhpStorm to work seamlessly out of the box – no extra plugins needed. The IDE instantly understands CodeIgniter’s patterns and conventions, offering intelligent code completion that streamlines development. This built-in compatibility creates an exceptionally productive experience for our contributors.\n— Matt Gatner, CodeIgniter contributor\nThe team continues to evolve CI4, focusing on performance, modularity, and a smooth developer experience. Upcoming releases aim to stabilize task and queue packages, expand the modular package library, and improve compatibility with the latest PHP versions – all while maintaining the project’s original vision.\nJoomla!\nJoomla! is a powerful open-source content management system sustained by a global community of volunteers. Its mission is to provide a multilingual, flexible, and secure platform that empowers individuals, small businesses, and nonprofits to publish and collaborate online – all without the steep learning curve of alternative systems.\nPhpStorm’s static code analyzer helped me clean up docblocks and better manage the framework. It understands Joomla deeply, making development smoother.\n— Hannes Papenberg, Joomla Maintainer\nPhpStorm shows me how files are connected, catches syntax errors early, and allows me to focus on actual client needs. It gives me a massive advantage over other web developers who don’t see the value of using it in their daily processes.\n— Adam Melcher, Joomla Contributor\nAs a Joomla core developer, PhpStorm has helped me in so many ways. The step debugger, which I use pretty much every single day, helps track down bugs, understand code flows, and generally, seeing what is going on under the hood is precious. The Joomla plugin adds an extra layer of usability as it understands the Joomla codebase and makes navigating the code a lot easier.\n— Roland Dalmulder, Joomla Contributor\nLooking ahead, Joomla 6 is scheduled for release on October 14, 2025. It will bring further codebase modernization, better SEO tools, and a built-in health checker – continuing Joomla’s mission to make publishing on the web more inclusive and flexible.\nThese projects represent just a small part of the global open-source effort, but they reflect the values we admire most: curiosity, craftsmanship, and care for the developer community.\nWhile each project has its own focus, they all rely on consistent, powerful workflows to maintain high standards and move forward with clarity – and JetBrains is proud to support them in this endeavor. If you’re an open-source developer, you might be eligible for a free or discounted PhpStorm license – read more about the available options to see if you qualify.\nWhat’s more, we’re also delighted to be able to host a celebration of the passion and progress of the PHP community in the form of PHPverse 2025 – a free online event taking place on June 17, 2025, where PHP’s most influential voices will share their insights on the language’s evolution and its future. Join us for inspiring talks, discussions, Q&As, and a special PHP anniversary merch giveaway.\nSign Up for Free",
        "dc:creator": "Lena Morozova",
        "content": "The PHP ecosystem is driven by passionate developers building tools that power everything from content management systems right the way through to testing libraries and database layers. Behind each project is a dedicated team working to modernize code, improve performance, and move the ecosystem forward. The fact that many of these teams choose PhpStorm to [&#8230;]",
        "contentSnippet": "The PHP ecosystem is driven by passionate developers building tools that power everything from content management systems right the way through to testing libraries and database layers. Behind each project is a dedicated team working to modernize code, improve performance, and move the ecosystem forward. The fact that many of these teams choose PhpStorm to […]",
        "guid": "https://blog.jetbrains.com/?post_type=blog&p=568864",
        "categories": [
          "community",
          "community-support",
          "open-source-program",
          "oss-projects"
        ],
        "isoDate": "2025-06-10T10:00:00.000Z"
      },
      {
        "creator": "Rachel Appel",
        "title": "SQL and NoSQL Query langauge support come to ReSharper!",
        "link": "https://blog.jetbrains.com/dotnet/2025/06/10/sql-and-nosql-query-langauge-support-come-to-resharper/",
        "pubDate": "Tue, 10 Jun 2025 08:46:00 +0000",
        "content:encodedSnippet": "ReSharper’s query language support for SQL and NoSQL provides C# developers with a more convenient way to work with SQL and NoSQL code directly in Visual Studio with ReSharper, supporting multiple SQL dialects beyond just T-SQL. It includes syntax highlighting, code analysis, auto-completion, and quick fixes to boost efficiency and catch issues early.\nBased on DataGrip\nThe SQL and NoSQL support now available in ReSharper integrates with Visual Studio’s SQL editor. Visual Studio runs the query, but ReSharper is the tool that helps you write it. Whether you’re doing DBA work or just querying a database, query language support in ReSharper goes along with your workflow just like other beloved JetBrains tools. Additionally, the query language features include formatting and quick fixes to give you a smooth and low-friction development experience. All these features are made possible because of the integration between ReSharper and DataGrip!\nLive templates\nLive Templates are a powerful productivity feature that allows you to quickly insert commonly used code snippets or boilerplate snippets into your code. By typing a predefined abbreviation and pressing the Tab key, Live Templates expand into a block of useful code, saving time and reducing errors. While you code, ReSharper highlights relevant Live Templates by displaying an icon next to applicable code blocks. Live Templates are a great way to optimize your coding workflows. Here you can see both code completions and live templates in action.\n\n\n\n\nCode Completion\nReSharper’s code completion feature remains one of its most powerful tools for developers, and it continues to evolve with each release. ReSharper offers context-aware suggestions that adapt to the specifics of your database. ReSharper’s code completion doesn’t just save you time by predicting what you need; it actively helps reduce errors by understanding code structure, usage patterns, and project-specific nuances.\n\n\n\n\nCode completion works when you’re creating SQL in C# strings too!\n\n\n\n\nCode inspections\nThis release features many SQL code inspections in ReSharper. While you code, look for the status indicators (blue squiggly underlines). When you encounter one, press Alt+Enter to show and then choose an option from the list of available intention actions.\nFor example, SQL Server uses quoted identifiers to allow the use of reserved keywords or special characters as object names (e.g., column or table names) only by enclosing them in quotation marks or square brackets. If you try to use reserved keywords when creating or updating SQL objects, you’ll be notified so that they can be quoted for use. \n\n\n\n\nCode completion and inspections are effective because you can choose the SQL dialect to target the type of database you’re using.\nNoSQL as well as SQL\nNoSQL support enables developers to work with non-relational databases such as MongoDB or Cassandra. Though these databases do not follow traditional RDBMS table structures, ReSharper provides many code completion and inspections for NoSQL databases. This makes working with unstructured or semi-structured data more efficient, bridging the gap between NoSQL systems and developer productivity.\nConfiguration & SQL Dialects\nModern development databases are about more than just SQL Server. So we’ve included options to configure SQL & NoSQL, and they’re found under the Extensions | ReSharper | Options | SQL menu. \nGeneral configuration options\nOnce in ReSharper’s options dialog, you can set options to enable SQL syntax highlighting and SQL code inspections, and how SQL inspections integrate with Visual Studio. Navigate to Code Inspection | SQL | General to enable SQL syntax highlighting, SQL Code inspections, and more.\n\n\n\n\nSQL Dialects configuration\nReSharper might be a Visual Studio plugin, but we support more than just Microsoft’s T-SQL! You can choose the SQL dialect for the entire current solution, or choose custom dialects to apply to individual files or folders. Once you do so, ReSharper detects the dialect of SQL and then applies the appropriate inspections and quick fixes for that dialect. From within the options dialog, you can configure SQL Dialects by navigating to Code Inspection | SQL  | SQL Dialects. \n\n\n\n\nFinal Notes\nEmbrace your data! ReSharper integrates DataGrip’s SQL and NoSQL support into Visual Studio, providing features like syntax highlighting, code analysis, and auto-completion. It supports various SQL dialects and NoSQL databases like MongoDB and Cassandra, allowing configuration of database-specific settings. These features are available for DotUltimate subscribers only, however, you can download a trial version for individual ReSharper licenses.",
        "dc:creator": "Rachel Appel",
        "content": "ReSharper’s query language support for SQL and NoSQL provides C# developers with a more convenient way to work with SQL and NoSQL code directly in Visual Studio with ReSharper, supporting multiple SQL dialects beyond just T-SQL. It includes syntax highlighting, code analysis, auto-completion, and quick fixes to boost efficiency and catch issues early. Based on [&#8230;]",
        "contentSnippet": "ReSharper’s query language support for SQL and NoSQL provides C# developers with a more convenient way to work with SQL and NoSQL code directly in Visual Studio with ReSharper, supporting multiple SQL dialects beyond just T-SQL. It includes syntax highlighting, code analysis, auto-completion, and quick fixes to boost efficiency and catch issues early. Based on […]",
        "guid": "https://blog.jetbrains.com/?post_type=dotnet&p=572572",
        "categories": [
          "net-tools",
          "data",
          "datagrip",
          "eap",
          "nosql",
          "query-language",
          "resharper",
          "sql"
        ],
        "isoDate": "2025-06-10T08:46:00.000Z"
      },
      {
        "creator": "Dmitry Pogrebnoy",
        "title": "Inside Ruby Debuggers: TracePoint, Instruction Sequence, and CRuby API",
        "link": "https://blog.jetbrains.com/ruby/2025/06/inside-ruby-debuggers/",
        "pubDate": "Tue, 10 Jun 2025 07:34:53 +0000",
        "content:encodedSnippet": "Hello, Ruby developers!\nDebugging is a key part of software development, but most developers use debuggers without knowing how they actually work. The RubyMine team has spent years developing debugging tools for Ruby, and we want to share some of the insights we’ve gained along the way.\nIn this post, we’ll explore the main technologies behind Ruby debuggers — TracePoint, Instruction Sequence, and Ruby’s C-level debugging APIs. \nWe’ll begin with TracePoint and see how it lets debuggers pause code at key events. Then we’ll build a minimal debugger to see it in action. Next, we’ll look at Instruction Sequences to understand what Ruby’s bytecode looks like and how it works with TracePoint. Finally, we’ll briefly cover Ruby’s C-level APIs and the extra power they offer.\nThis blog post is the second in a series based on the Demystifying Debuggers talk by Dmitry Pogrebnoy, RubyMine Team Leader, presented at EuRuKo 2024 and RubyKaigi 2025. If you haven’t read the first post yet, it’s a good idea to start there. Prefer video? You can also watch the original talk here.\nReady? Let’s start!\nThe core technologies behind any Ruby debugger\nBefore diving into the debugger internals, it’s essential to understand the two core technologies that make Ruby debugging possible: TracePoint and Instruction Sequence. Regardless of which debugger you use, they all rely on these fundamental features built into Ruby itself. In the following sections, we’ll explore how each of them works and why they’re so important.\nTracePoint: Hooking into Code Execution\nLet’s begin with TracePoint, a powerful instrumentation technology introduced in Ruby 2.0 back in 2013. It works by intercepting specific runtime events such as method calls, line executions, or exception raises and executing custom code when these events occur. TracePoint works in almost any Ruby context, and it works well with Thread and Fiber. However, it currently has limited support for Ractor.\nLet’s take a look at the example and see how TracePoint works.\ndef say_hello\n puts \"Hello Ruby developers!\"\nend\n\n\nTracePoint.new(:call) do |tp|\n puts \"Calling method '#{tp.method_id}'\"\nend.enable\n\n\nsay_hello\n# => Calling method 'say_hello'\n# => Hello Ruby developers!\n\n\n\n\nIn this example, we have a simple say_hello method containing a puts statement, along with a TracePoint that watches events of the call type. Inside the TracePoint block, we print the name of the method being called using method_id. Looking at the output in the comments, we can see that our TracePoint is triggered when entering the say_hello method, and only after that do we see the actual message printed by the method itself.\nThis example demonstrates how TracePoint lets you intercept normal code execution at specific points where special events occur, allowing you to execute your own custom code. Whenever your debugger stops on a breakpoint, TracePoint is in charge. This technology is valuable for more than just debugging. It is also used in performance monitoring, logging, and other scenarios where gaining runtime insights or influencing program behavior is necessary.\nBuilding the simplest Ruby debugger with TracePoint\nWith just TracePoint technology, you can build what might be the simplest possible Ruby debugger you’ll ever see.\ndef say_hello\n puts \"Hello Ruby developers!\"\nend\n\n\nTracePoint.new(:call) do |tp|\n puts \"Call method '#{tp.method_id}'\"\n while (input = gets.chomp) != \"cont\"\n   puts eval(input)\n end\nend.enable\n\n\nsay_hello\nThis is almost the same code as in the TracePoint example, but this time the TracePoint code body is slightly changed.\nLet’s examine what’s happening here. The TracePoint block accepts user input via gets.chomp, evaluates it in the current context using the eval method, and prints the result with puts. That’s really all there is to it — a straightforward and effective debugging mechanism in just a few lines of code. \nThis enables one of the core features of a debugger — the ability to introspect the current program context on each method invocation and modify the state if needed. You can, for example, define a new Ruby constant, create a class on the fly, or change the value of a variable during execution. Simple and powerful, right? Try to run it by yourself!\nClearly, this isn’t a complete debugger — it lacks exception handling and many other essential features. But when we strip away everything else and look at the bare bones, this is the fundamental mechanism that all Ruby debuggers are built upon.\nThis simple example demonstrates how TracePoint serves as the foundation for Ruby debuggers. Without TracePoint technology, it would be impossible to build a modern Ruby debugger.\nInstruction Sequence: Ruby’s bytecode revealed\nAnother crucial technology for Ruby debuggers is Instruction Sequence.\nInstruction Sequence, or iseq for short, represents the compiled bytecode that the Ruby Virtual Machine executes. Think of it as Ruby’s “assembly language” — a low-level representation of your Ruby code after compilation into bytecode. Since it’s closely tied to the Ruby VM internals, the same Ruby code can produce a different iseq in different Ruby versions, not just in terms of instructions but even in their overall structure and relationships between different instruction sequences.\nInstruction Sequence provides direct access to the low-level representation of Ruby code. Debuggers can leverage this feature by toggling certain internal flags or even modifying instructions in iseq, effectively altering how the program runs at runtime without changing the original source code. \nFor example, a debugger might enable trace events on a specific instruction that doesn’t have one by default, causing the Ruby VM to pause when that point is reached. This is how breakpoints in specific language constructions and stepping through chains of calls work. The ability to instrument bytecode directly is essential for building debuggers that operate transparently, without requiring the developer to insert debugging statements or modify their code in any way.\nLet’s take a look at how to get an Instruction Sequence in Ruby code.\ndef say_hello\n puts \"Hello Ruby developers 💎!\"\nend\n\n\nmethod_object = method(:say_hello)\niseq = RubyVM::InstructionSequence.of(method_object)\n\n\nputs iseq.disasm\nLet’s examine this code more closely. First, we have our familiar say_hello method containing a puts statement. Then, we create a method object from it using method(:say_hello). Finally, we get the Instruction Sequence for this method and print out its human-readable form using disasm. This lets us peek under the hood and see the actual bytecode instructions that Ruby will execute.\nLet’s examine the output and see what it looks like.\n== disasm: #&lt;ISeq:say_hello@iseq_example.rb:1 (1,0)-(3,3)>\n0000 putself                                                          (   2)[LiCa]\n0001 putchilledstring                       \"Hello Ruby developers 💎!\"\n0003 opt_send_without_block                 &lt;calldata!mid:puts, argc:1, FCALL|ARGS_SIMPLE>\n0005 leave                                                            (   3)[Re]\nThe first line shows metadata about our Ruby entity. Specifically, the say_hello method defined in iseq_example.rb with a location range (1,0)-(3,3). Below that are the actual instructions that the Ruby VM will execute. Each line represents a single instruction, presented in a human-readable format. You can easily spot the “Hello Ruby developers 💎!” string argument preserved exactly as it appears in the source code, without any encoding or decoding complexity, even with non-ASCII symbols. Such transparency makes it easier for you to understand what’s happening at the bytecode level.\nInstruction Sequence plays a critical role in Ruby debugging by marking key execution points in the bytecode. In bracket notation in the output, you can notice markers like Li for line events, Ca for method calls, and Re for returns. These markers tell the Ruby VM when to emit runtime events. TracePoint relies on these markers to hook into the running program — it listens for these events and steps in when they happen. This tight connection between two technologies is what makes it possible for debuggers to pause execution and inspect the state.\nGoing deeper: Ruby’s C-level debugging API\nSo far, we’ve looked at the two core technologies behind Ruby debuggers — TracePoint and Instruction Sequence. These are enough to build a working Ruby debugger. However, if you want to implement advanced features like those offered by RubyMine, such as smart stepping or navigating back and forth through the call stack, TracePoint and Instruction Sequence alone won’t cut it. To support such capabilities, you need to go a level deeper and tap into the low-level debugging APIs provided by Ruby itself.\nCRuby exposes a number of internal methods that fill the gaps left by the public Ruby APIs. These methods are defined in C headers such as vm_core.h, vm_callinfo.h, iseq.h, and debug.h, among others. These internal interfaces can unlock powerful capabilities that go beyond what’s possible with the public API, but they come with important trade-offs.\nSince they are specific to CRuby, debuggers using them won’t work with other implementations like JRuby or TruffleRuby. Another downside is that these APIs are not public or stable across Ruby versions. Even minor updates can break them, which means any debugger depending on these methods needs constant attention to keep up with Ruby’s changes. Still, it’s worth exploring a few of these internal methods to get a better idea of what this low-level API looks like and what it provides for debugger tools.\nLet’s start with rb_tracepoint_new(...):\nVALUE rb_tracepoint_new(VALUE target_thread_not_supported_yet, rb_event_flag_t events, void (*func)(VALUE, void *), void *data);\nThis method works like creating a trace point in Ruby code, but with more flexibility for advanced use. It’s especially helpful for low-level debuggers written as C extensions that need deeper access to the Ruby VM. In the RubyMine debugger, this approach allows more precise control over when and where to enable or disable trace points, which is essential for implementing smart stepping.\nAnother useful method is rb_debug_inspector_open(...):\nVALUE rb_debug_inspector_open(rb_debug_inspector_func_t func, void *data);\nThis C-level API lets you inspect the call stack without changing the VM state. The func callback receives a rb_debug_inspector_t struct, which provides access to bindings, locations, instruction sequences, and other frame details. In the RubyMine debugger, it’s used to retrieve the list of frames and implement the ability to switch between them back and forth on the call stack when the program is suspended by the debugger. Without this API, frame navigation and custom frame inspection in Ruby would be much more difficult.\nThe final example is a pair of methods for working with iseq objects. The method rb_iseqw_to_iseq(...) converts an iseq from a Ruby value to a C value, while rb_iseq_original_iseq(...) converts it back from C to Ruby. These let Ruby debuggers switch between Ruby and C-extension code when precise, low-level control is needed. In the RubyMine debugger, they are actively used in the implementation of smart stepping, helping determine which code should be stepped into during debugging.\nThese low-level APIs offer powerful tools for building advanced debugging features — the kind that aren’t possible with TracePoint and Instruction Sequence alone. But they come with a cost: platform lock-in to CRuby and a high maintenance burden due to their instability across Ruby versions. Despite that, they remain essential for debuggers that need deep integration with the Ruby VM.\nConclusion\nIn this post, we explored the foundational technologies that power Ruby debuggers — TracePoint and Instruction Sequence. These two components form the basis for how modern Ruby debuggers observe and interact with running Ruby code. TracePoint enables hooks into specific runtime events like method calls and line execution, while Instruction Sequence provides low-level access to the compiled Ruby VM bytecode.\nWe also took a brief look at how low-level CRuby C APIs exert even more precise control over code execution, offering insight into how debuggers like RubyMine implement advanced features. While we didn’t dive into full debugger implementations here, this foundation lays the groundwork for understanding how these tools operate.\nStay tuned — in a future post, we’ll go further into how modern debuggers are built on top of this foundation.\nHappy coding, and may your bugs be few and easily fixable!\nThe RubyMine team",
        "dc:creator": "Dmitry Pogrebnoy",
        "content": "Hello, Ruby developers! Debugging is a key part of software development, but most developers use debuggers without knowing how they actually work. The RubyMine team has spent years developing debugging tools for Ruby, and we want to share some of the insights we’ve gained along the way. In this post, we’ll explore the main technologies [&#8230;]",
        "contentSnippet": "Hello, Ruby developers! Debugging is a key part of software development, but most developers use debuggers without knowing how they actually work. The RubyMine team has spent years developing debugging tools for Ruby, and we want to share some of the insights we’ve gained along the way. In this post, we’ll explore the main technologies […]",
        "guid": "https://blog.jetbrains.com/?post_type=ruby&p=573824",
        "categories": [
          "rubymine"
        ],
        "isoDate": "2025-06-10T07:34:53.000Z"
      },
      {
        "creator": "Olga Bedrina",
        "title": "What Is Penetration Testing? Types, Processes, Tools, And Why It’s All Worth It",
        "link": "https://blog.jetbrains.com/teamcity/2025/06/what-is-penetration-testing/",
        "pubDate": "Mon, 09 Jun 2025 14:03:04 +0000",
        "content:encodedSnippet": "Penetration testing (or “pen testing”) is an authorized, simulated cyberattack designed to test the security of a production system.\nEthical hackers perform penetration tests, emulating the behavior of cybercriminals to evaluate your software’s security and identify any weaknesses. During a pen test, these cybersecurity specialists use a range of techniques to attack a system. \n\nOnce they have gained access, their goal is to demonstrate the potential damage that somebody could do during a real attack.\nPenetration testing is an effective way to identify and prioritize security flaws in your software, protecting both your organization and users from cyberattacks.\n💡 See also: SAST vs DAST: Differences And When to Use\nWhy is penetration testing important?\nCybercriminals typically seek to steal sensitive data, such as company IP, financial information, or users’ data, and/or disrupt operations. A successful cyberattack can result in serious reputational and financial damage (enough to jeopardize the future of your business) and may also expose you to liability and regulatory penalties.\nWith cyberattacks becoming increasingly common, the importance of software security cannot be overstated. A penetration test provides a realistic assessment of how well your system will withstand a cyberattack and identifies weaknesses that you should address.\n❓ Why penetration testing matters: risk vs. resilience\n\nWithout penetration testingWith penetration testing\n❌ Unknown vulnerabilities remain hidden in your code or infrastructure✅ Known exploits are identified before attackers can abuse them\n⚠️ High risk of data breaches, IP theft, or operational disruption🛡️ Stronger defenses built around real attack simulations\n💸 Financial losses from fines, lawsuits, or ransom demands💼 Demonstrated compliance with ISO27001, HIPAA, and other standards\n📉 Reputational damage after publicized incidents📈 Customer trust reinforced through visible due diligence\n⏳ Delayed response to incidents you didn’t anticipate🚀 Faster remediation guided by expert pen test reports\n\n\n\n\n\nAn external penetration testing service will provide a detailed report of the attempted attacks, the exploits found, and the potential harm that could be inflicted.\nAs a proven security testing technique, penetration testing is recommended by several security standards and regulations, including ISO27001 and HIPAA. Running regular pen tests (and acting on the findings) can be used to demonstrate due diligence and compliance with these standards.\nBlack box, white box, and gray box penetration testing\nDepending on your goals, you can run penetration tests using a black box, white box, or gray box approach. The different approaches refer to the amount of information provided to the pen testers in advance of the exercise.\nBlack box testing\nAlso known as opaque box or blind testing, this approach simulates an attack by an outsider. In a black box test, the pen testers are given only the name of the organization or product under test. It’s then up to them to glean whatever information they can to mount an attack.\nTo make the test even more realistic, you can run a double-blind pen test, in which employees of your organization are unaware that the test is happening.\n\nGray box testing\nIn a semi-opaque or gray box test, pen testers are given some information in advance. This might include system diagrams or design documents, or potentially credentials for a part of the system or a related service. Taking a gray box approach simulates an attack following a leak of confidential information or the actions of a disgruntled employee.\nWhite box testing\nWith a transparent or white box approach, pen testers have access to all the source code, binaries, containers, and any other artifacts of the system. While not a realistic attack, a white box penetration test is the quickest way to conduct this type of test and can be useful if you want rapid feedback so you can address security flaws quickly. \nOnce you have addressed any issues, you may want to follow up with a black box test to ensure nothing has been missed.\nVulnerability scanning vs. penetration testing\nAn effective cybersecurity strategy should involve multiple levels of security testing. This includes both automated vulnerability scans, such as Static Application Security Testing (SAST) and Dynamic Application Security Testing (DAST), as well as manual techniques like pen testing.\nVulnerability scanners check your source code or software systematically for known security flaws. Because they are reasonably quick to run and require no manual intervention, they are ideal for inclusion in your automated CI/CD pipeline. \n🧪 Vulnerability scanning vs. penetration testing\n\nAspectVulnerability scanningPenetration testing\nTypeAutomatedManual\nTechniquesSAST, DAST, predefined rule setsSimulated real-world attacks by ethical hackers\nScopeSource code, known vulnerabilitiesEntire system: code, infrastructure, social engineering, physical security\nDetection abilityFast and repeatable; ideal for frequent useSlow; time-intensive due to human effort\nCostLow; can run in every CI/CD cycleHigh; typically done a few times a year\nIdeal use caseContinuous feedback in CI/CD pipelineIn-depth analysis for high-risk releases or compliance needs\nLimitationsDoesn’t test exploit feasibility or user behaviorNot scalable for every build; limited frequency\nBest when combined withPenetration testing for real-world attack simulationAutomated scans for consistent baseline coverage\n\n\n\n\n\nThis ensures you get regular and rapid feedback on each set of code changes, allowing you to address any new security issues quickly and efficiently.\nOn the other hand, automated security scans can only ever discover the issues they’ve been programmed to detect. As a result, they cannot identify new vulnerabilities or combinations of exploits. The fully automated process also carries a higher risk of false positives. This is where pen testing can offer advantages.\nPenetration testing is a form of manual security testing that involves skilled individuals mounting realistic attacks on your system. In addition to checking for common vulnerabilities, pen testers often chain exploits together, leveraging each small weakness in the same way an attacker would to gain access to a system.\nPen testers also look beyond the codebase, exploiting social engineering tactics and physical security gaps to compromise systems. As a result, penetration tests can reveal flaws in your defenses that might go unnoticed by automated security tests.\nThe downside of pen tests is that they are expensive and time-consuming to run. How frequently you run penetration tests will depend on your risk profile and budget, but it is typically a few times a year or less.If you’re releasing changes frequently, penetration testing alone is not enough to defend against cyberattacks. \nHowever, by combining pen testing with vulnerability scans and other automated security tests, you can leverage the benefits of each approach. \n💡 Find out more about automated testing from our CI/CD guide.\nTypes of penetration testing\nPen testing can involve a range of methods. Rather than focusing on a particular type to the exclusion of others, pen testers combine different methods according to the system under test and the organization’s requirements.\nExternal vs. internal\nIn an external penetration test, the simulated attack starts from outside the organization’s network. The initial target might be a router, external servers, employee computers, or cloud-hosted services. The pen tester aims to find a way in and then see what else they can access and what damage they can do.\nBy contrast, an internal test starts from inside the network. You can use this to simulate an attack by a rogue employee or an attack that could follow a successful phishing attempt.\nApplication testing\nApplication testing involves looking for vulnerabilities in deployed software, such as web apps, mobile apps, APIs, and IoT devices. Pen testers will look for common security flaws, such as SQL injection, broken authentication, and others listed in the OWASP Top 10.\nAlthough vulnerability scans can detect these types of issues, fixes are sometimes deprioritized if they are not considered a significant threat. However, minor exploits can be chained together by a creative pen tester to reveal a viable attack vector.\nSocial engineering\nSocial engineering targets the individuals working at an organization. Attack vectors include phishing emails and phone calls to extract valuable information and credentials, tailgating staff entering the building, or cloning office badges (often with the help of photos on social media) and masquerading as an employee or contractor.\nPhysical security\nPhysical security can involve searching for vulnerabilities in hardware, such as unpatched servers, or simply gaining entry to premises and then plugging a device into a network socket. \nOnce a pen tester has gained access to the network in this way, they can seek to access key systems with the help of malware or key loggers, and then download or take screenshots of sensitive data.\nHow to do penetration testing\nMost pen testers will follow a process that includes the following steps.\n\n\n\n\nRules of engagement\nBefore starting, the pen testers should agree on a brief with the organization that defines the test’s target and the rules of engagement. This should include what forms of testing are acceptable and what is off the table (such as phishing attempts on staff or forcing entry to premises), as well as the contact to inform of progress. \nThe brief should also provide any additional context (in the case of a white or gray box test) and specify whether employees are aware that a pen test is being run.\nPlanning and reconnaissance\nBased on the brief, the pen testing team will collect as much information as possible about the software. This may include scouring public websites, published documentation, social media accounts, and public repositories to learn more about the software architecture and how it’s hosted. \nThey will also gather intelligence about the organization and look for ways to get into the network so they can access key systems and data.\nOnce the reconnaissance is complete, the pen testers identify potential attack vectors and prioritize them, while considering how to evade detection at all stages of the exercise.\nGaining access\nThe pen testing team then attempts to gain access to the system through any means allowed in the brief. During this stage, they may use various tools to automate specific elements of the process, including vulnerability scanners, credential cracking tools, port scanners, and network analyzers.\nIf permitted by the rules of engagement, they may use social engineering techniques to gain access to premises and attempt to install malware on devices within the network so they can continue the attack remotely.\nMaintaining access\nOnce inside, pen testers attempt to escalate privileges and access critical systems or demonstrate the potential to disrupt them.\nRemaining undetected throughout this process is crucial – if somebody discovered a real hacker, they could avert the attack. The longer a pen tester can remain undetected, the higher the risk that an advanced persistent threat could be carried out.\nCovering tracks\nBefore concluding, pen testers remove all traces of their activity. This both tests the organization’s ability to detect intrusions and ensures nothing remains for real attackers to exploit. This might involve removing any hardware or malware they have planted, and reverting any configurations to their original state.\nReporting\nFinally, the pen testers will write a report detailing what they attempted, the defenses that worked, how they managed to gain access, and the damage they could have caused. \nThey may provide evidence of how far they penetrated the defenses by placing a file in a secure location or taking a screenshot of sensitive data. They will also suggest recommendations on how you can enhance your security and prevent similar attacks in the future.\nPopular penetration testing tools\nAlthough penetration testing is a form of manual security testing, pen testers typically use many tools to simulate an attack, just as a malicious actor would. By using these tools on your systems, you can also detect potential vulnerabilities and address them before they’re exploited.\nReconnaissance tools\nDuring the reconnaissance phase, pen testers may use network scanners, like Nmap, to scan IP addresses and ports to find out more about the system design and identify potential entry points. \nNetwork packet analyzers, such as Wireshark, are used to gain a deeper understanding of the systems in use and look for sensitive data or credentials being transmitted without encryption.\nCredential cracking\nTools designed to crack encryption protocols or mount brute force attacks, such as Hydra and John the Ripper, are frequently used to try to gain access to systems. Other options include installing key loggers on employees’ devices or using phishing emails to trick users into divulging their credentials.\nExploitation tools\nTools such as Metasploit, Burp Suite, and OWASP ZAP enable pen testers to automate common attacks including SQL injection, cross-site scripting, and fuzzing. Having identified a vulnerability, pen testers may then chain several exploits together to mount a more sophisticated attack.\nBusiness perspective: the ROI of penetration testing\nPenetration testing is often seen as a technical requirement, but it can also be viewed as a business safeguard. A successful cyberattack can lead to downtime, reputational damage, regulatory fines, or loss of sensitive data. In some cases, the financial impact may exceed the cost of a structured penetration testing program.\nWhile vulnerability scans are useful for identifying known issues, penetration testing simulates how an attacker might exploit multiple weaknesses in combination. This type of testing can uncover risks that are difficult to detect through automation alone.\nFor organizations operating in regulated industries, penetration testing may also support compliance with standards such as ISO27001, HIPAA, and PCI DSS. In this context, it can be used to demonstrate due diligence and reduce legal exposure.\nWhen penetration testing pays for itself\nAlthough penetration tests can be expensive to run, they are often justified in scenarios with elevated risk. \nThese include:\nLaunching a new product or major architectural change\nStoring or processing sensitive information, such as personal data or payment details\nPreparing for a security certification or compliance audit\nFollowing a publicized security incident affecting a competitor or similar company\nExpanding into new infrastructure environments, such as third-party APIs or cloud services\nIn such cases, the cost of remediation after a breach may significantly outweigh the cost of identifying and fixing issues earlier through targeted testing.\nCombining pen testing with automated security scanning\nPenetration testing offers detailed insight into your security posture, but it is not designed for continuous use. To maintain security at scale, it’s best used in combination with automated tools.\nFor example, vulnerability scanners can be integrated into your CI/CD pipeline to provide regular feedback on source code and deployed software. This allows you to identify common issues quickly, without the need for manual intervention.\n💡Read also: What Is a CI/CD Pipeline?\nPen testers, on the other hand, can focus on exploring complex attack paths, misconfigurations, or issues that are specific to your architecture. This combination ensures broader coverage while making efficient use of internal or third-party security resources.\nTools such as OWASP ZAP or Snyk can be added to your build process, while platforms like TeamCity allow you to automate scanning tasks and generate reports at each deployment stage.\nSetting up TeamCity Snyk plugin",
        "dc:creator": "Olga Bedrina",
        "content": "Penetration testing (or “pen testing”) is an authorized, simulated cyberattack designed to test the security of a production system. Ethical hackers perform penetration tests, emulating the behavior of cybercriminals to evaluate your software&#8217;s security and identify any weaknesses. During a pen test, these cybersecurity specialists use a range of techniques to attack a system. Once [&#8230;]",
        "contentSnippet": "Penetration testing (or “pen testing”) is an authorized, simulated cyberattack designed to test the security of a production system. Ethical hackers perform penetration tests, emulating the behavior of cybercriminals to evaluate your software’s security and identify any weaknesses. During a pen test, these cybersecurity specialists use a range of techniques to attack a system. Once […]",
        "guid": "https://blog.jetbrains.com/?post_type=teamcity&p=573662",
        "categories": [
          "security",
          "testing",
          "best-practices"
        ],
        "isoDate": "2025-06-09T14:03:04.000Z"
      },
      {
        "creator": "Irina Mariasova",
        "title": "Java Annotated Monthly – June 2025",
        "link": "https://blog.jetbrains.com/idea/2025/06/java-annotated-monthly-june-2025/",
        "pubDate": "Fri, 06 Jun 2025 14:07:43 +0000",
        "content:encodedSnippet": "Hi there, Java fans! It’s a new month, which means we’ve got a new batch of hot news, deep dives, and tasty tidbits from the Java world for you to enjoy. In this edition, Piotr Przybył joins us in the Featured Content section to share his cultivated list of content finds. We’re also testing a new, more concise format that is faster to read but still packed with value. Let us know if you like it or miss the old style. \nReady? Let’s go!\nFeatured Content\nPiotr Przybył\nPiotr Przybył – Notorious engineer at work and after hours, tracing the meanders of the art of software engineering. Remote Software Gardener, mostly working in web-oriented Java gardens. Java Champion. Testcontainers Champion. Programming usually in Java (since 1.3), Scala, and Go, but in other languages too. A fan of agility, seen mostly as choosing the right tools and approaches after asking the right questions. Developer, trainer, and conference speaker, currently working for Elastic as a Senior Developer Advocate.\nGreetings, fellow Java developers! It’s a pleasure to be here. It’s exciting to be in the Java community, for a language that celebrated its 30th anniversary, which has been proclaimed to be dead so many times, and it’s still doing surprisingly well. We can see that with all the exciting stuff happening around Java 25, and changes in the ecosystem at large.\nI’m humbled and honoured to be here. It’s great to see the community and the ecosystem evolve, especially given that I’ve been a part of it since (checks notes…) 2003 ;-)\nI was first exposed to Java at my alma mater, Wrocław University of Science and Technology. Recently, there’s been one more reason to be a proud alumnus: “Odra 5”!\n“Odra 5” is the name of Poland’s first quantum computer, recently launched at the Wrocław University of Science and Technology. It’s a five-qubit machine, developed by Finnish company IQM Quantum Computers, that represents a significant milestone in the advancement of quantum computing in Central and Eastern Europe. I find the name cute and not without meaning for local IT history fans. You can read more about it here at the University’s official page. Also, “Odra” is the Polish name for the Oder river, and… computers manufactured in Wrocław in the 1960s.\nLet’s get back from general Computer Science to Java. Unless you have been living in total wilderness, I think you might have heard a thing or two about the AI (r)evolution happening recently. ;-) Contrary to some rumours, Java is a very decent language that benefits from improvements in this area, and with the release of Spring AI 1.0, things will get even easier! The article by Josh Long, Philipp Krenn, and Laura Trotta (I know, and have lots of respect for all of them) will let you understand how to start with your own RAG quickly, benefiting from features of Spring AI, Elasticsearch, and more. Oh, and if you’d like to learn more about stuff like vector search or searching in general, AI, and so on, Elasticsearch Labs might be a good place to start.\nSpeaking about Java itself, there’s of course the 30th anniversary of Java! It’s a big thing, although it might be disturbing to some that the language that keeps dying is still pretty much alive and actively developed. Right now, there are 17 active Java Enhancement Proposals targeting Java 25, which in my opinion proves that despite its size and legacy, the Java ecosystem is still evolving fast. I couldn’t resist, and wrote about Java’s Structured Concurrency, Elasticsearch Java client, DevEx, and a Developer Advocate’s job on my personal page, touching on all of this.\nI think that some reasons why our ecosystem is still robust are that we can learn from our past mistakes. While some of them are irreversible, many of them can shape how we think and evolve our systems and our daily jobs. A great example is the Allegro folks sharing how to avoid mistakes in Gradle, because with flexibility comes responsibility. And also, our tech stack and our jobs are not only the language, the SDK, the frameworks, and build/CI/CD tools, but predominantly our mindset. That’s something we shall all keep improving!\nJava News\nCheck out the most recent news from the Java world: \nJava News Roundup 1, 2, 3, 4\nJava at 30: A Retrospective on a Language That Has Made a Big Impact \nFoojay Podcast #71: Celebrating 30 Years of Java with James Gosling\nJava 30 by JetBrains\nHappy 30th Birthday, Java!\nJava’s 30th Birthday\nJava at 30: The Genius Behind the Code That Changed Tech\nStrings Just Got Faster\nJEP targeted to JDK 25: 511: Module Import Declarations\nJEP targeted to JDK 25: 512: Compact Source Files and Instance Main Methods\nJEP targeted to JDK 25: 505: Structured Concurrency (5th Preview)\nJEP targeted to JDK 25: 513: Flexible Constructor Bodies\nJava 25 Introduces Stable Values API for Deferred Immutability and Improved Application Startup \nInstance Main Methods Move from Preview to Final in JDK 25\nJEP 510: Key Derivation Function API\nStructured Concurrency Revamp in Java 25 – Inside Java Newscast #91\nJava Tutorials and Tips\nLearn new things and enjoy unique insights from industry experts: \nEpisode 35 “Stream Gatherers” with Viktor Klang\nOracle’s new certification exam engine\nAdoption of the Model Context Protocol Within the Java Ecosystem\nPresentation: Stream All the Things — Patterns of Effective Data Stream Processing\nJavaFX 24 and Beyond\nGarbage Collection in Java: The Performance Benefits of Upgrading\nMastering JVM Memory Troubleshooting – From OutOfMemoryErrors to Leaks\nEpisode 36 “Ahead of Time Computation” with Dan Heidinga\nJava 24, Faster Than Ever\nStructured Concurrency in Action\nPattern Matching in Java: Better Code, Better APIs\nTowards a JSON API for the JDK\nKotlin Corner\nEverything you might have missed about Kotlin in May:\nKotlinConf 2025 Unpacked: Upcoming Language Features, AI-Powered Development, and Kotlin Multiplatform Upgrades\nMeet Koog: Empowering Kotlin Developers to Build AI Agents \nStrengthening Kotlin for Backend Development: A Strategic Partnership With Spring Present and Future of Kotlin for Web \nAmper Update, May’25 \nHow to Use Kotlin Notebooks for Productive Development \nStructuring Ktor Projects Using Domain-Driven Design (DDD) Concepts \nKotlin LSP – The launch of the pre-Alpha Kotlin LSP and VS Code plugin. \nAI\nLearn more about the most recent AI news, innovations, problems, and predictions:\nA Practical Guide on Effective AI Use – AI as Your Peer Programmer\nWorking with Junie in legacy code\nHelp Predict the Future of AI in Software Development!\nVibe coding an MCP server with Micronaut, LangChain4j, and Gemini\nJava for AI\nBuild AI Apps and Agents in Java: Hands-On with LangChain4j\nFrom Architecture to Deployment: How AI-Powered Toolkits Are Unifying Developer Workflows\nPodcast: How To Improve the Quality of the Gen AI-Generated Code And Your Team’s Dynamics\nGenAI blood, sweat, and tears: Loading data to Pinecone\nMeet Koog: Empowering Kotlin Developers to Build AI Agents\nJetBrains AI Assistant – Now in Visual Studio Code\nWrite AI agents in Java — Agent Development Kit getting started guide\nHow to send prompts in bulk with Spring AI and Java Virtual Threads\nBeyond the chatbot or AI sparkle: a seamless AI integration\nAI Test Generation: A Dev’s Guide Without Shooting Yourself in the Foot\nThings you never dared to ask about LLMs — Take 2\nEthics in AI’s Wild West: Biases & Responsibilities\nContext Collection Competition by JetBrains and Mistral AI\nBrokk: AI for Large (Java) Codebases \nLanguages, Frameworks, Libraries, and Technologies\nGet to know programming technologies and frameworks better:\nThis Week in Spring 1, 2, 3, 4\nHow to send prompts in bulk with Spring AI and Java Virtual Threads\nDynamic Tool Updates in Spring AI’s Model Context Protocol\nGradle Best Practices – A Path to Build Happiness\nSemantic Search with Spring Boot & Redis\nLocal AI with Spring: Building Privacy-First Agents Using Ollama\nA Bootiful Podcast: V Körbes on security from the platform on up\nWhat is RAG, and How to Secure It\nConferences and Events\nHere are some of the must-attend online and offline events in June:\nIntelliJ IDEA Conf – Online, June 3–4\nJ-Spring – Utrecht, Netherlands, June 5; Anton Arhipov is a speaker. \nLe Paris JUG Java Day – Paris, France, June 5\nJConf Méx – Nuevo México, Mexico, June 7\nDevoxx Poland – Krakow, Poland, June 11–13; Anton Arhipov and Marit van Dijk are the speakers. \nDevConf – Brno, Czechia, June 12–14\nJSail Unconference – Hemelum, Netherlands, June 23–27\nVoxxed Days Luxembourg – Mondorf-les-Bains, Luxembourg, June 19–20\nCulture and Community\nTake some time to think about the non-tech topics that are of significance to tech people at the moment:\nImposter Syndrome in Tech\nAchieving Sustainable Mental Peace in Software Engineering with Help from Generative AI\nBe a Distinguished Java Engineer in the Age of Vibe Coding\nBuilt to Outlast: Cultivating a Culture of Resilience\nBook Review: Raising Young Coders\nFrom Code to Charisma: Emotional Mastery for Tech Leaders\n97 Jokes Every Programmer Should Know\nConversations I’ve had with Code\nWhat Can AI Do to Improve Diversity in the Tech Community?\nAnd Finally…\nDon’t miss the latest updates from the IntelliJ IDEA team: \nSources, Bytecode, Debugging\nDo You Really Know Java?\nCoding Guidelines for Your AI Agents\nFinding Your Tribe – JUGs Unveiled \nThe IntelliJ IDEA 2025.2 Early Access Program Is Open!\nTry Declarative Gradle EAP3 in IntelliJ IDEA\nBuilding Cloud-Ready Apps Locally: Spring Boot, AWS, and LocalStack in Action\nThat’s it for today! We’re always collecting ideas for the next Java Annotated Monthly – send us your suggestions via email or X by June 20. Don’t forget to check out our archive of past JAM issues for any articles you might have missed!",
        "dc:creator": "Irina Mariasova",
        "content": "Hi there, Java fans! It’s a new month, which means we’ve got a new batch of hot news, deep dives, and tasty tidbits from the Java world for you to enjoy. In this edition, Piotr Przybył joins us in the Featured Content section to share his cultivated list of content finds. We’re also testing a [&#8230;]",
        "contentSnippet": "Hi there, Java fans! It’s a new month, which means we’ve got a new batch of hot news, deep dives, and tasty tidbits from the Java world for you to enjoy. In this edition, Piotr Przybył joins us in the Featured Content section to share his cultivated list of content finds. We’re also testing a […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=573599",
        "categories": [
          "news",
          "ai",
          "java",
          "java-annotated-monthly"
        ],
        "isoDate": "2025-06-06T14:07:43.000Z"
      },
      {
        "creator": "Maria Kosukhina",
        "title": "IntelliJ IDEA 2025.1.2 Is Out!",
        "link": "https://blog.jetbrains.com/idea/2025/06/intellij-idea-2025-1-2/",
        "pubDate": "Wed, 04 Jun 2025 14:08:58 +0000",
        "content:encodedSnippet": "IntelliJ IDEA 2025.1.2 has arrived with several valuable fixes.\nYou can update to this version from inside the IDE, using the Toolbox App, or using snaps if you are a Ubuntu user. You can also download it from our website.\nHere are the most notable updates included in this version:\nThe IDE no longer fails to start if a plugin defines an action with unresolved message bundle keys, and it now provides a report identifying the problematic plugin. [IJPL-185981]\nThe IDE no longer produces the false positive “Package is declared in module which is not in the module graph” warning. [IDEA-371051]\nThe IDE once again correctly takes compilerArgs from pom.xml into account when building Maven projects. [IDEA-371747]\nThe GitLab code review mode now functions as expected, correctly displaying changes with proper highlighting. [IJPL-186195]\nWorking directories are once again preserved upon restart when working with the new terminal. [IJPL-163552]\nInspections in Terraform can now be suppressed again. [IJPL-149116]\nFont size rescaling for the Quick Documentation popup works as expected. [IJPL-184559]\nThe Git option now appears correctly in the context menu when right-clicking a file or folder in a project located on a path that includes a symbolic link. [IJPL-181017]\n\n\n\n\nTo find out more details about the issues resolved, please refer to the release notes.\nIf you encounter any bugs, please report them to our issue tracker.\nHappy developing!",
        "dc:creator": "Maria Kosukhina",
        "content": "IntelliJ IDEA 2025.1.2 has arrived with several valuable fixes. You can update to this version from inside the IDE, using the&#160;Toolbox App, or using snaps if you are a Ubuntu user. You can also download it from our&#160;website. Here are the most notable updates included in this version: To find out more details about the [&#8230;]",
        "contentSnippet": "IntelliJ IDEA 2025.1.2 has arrived with several valuable fixes. You can update to this version from inside the IDE, using the Toolbox App, or using snaps if you are a Ubuntu user. You can also download it from our website. Here are the most notable updates included in this version: To find out more details about the […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=572979",
        "categories": [
          "releases",
          "bug-fix-update",
          "intellij-idea-2025-1",
          "intellij-idea-2025-1-2-2"
        ],
        "isoDate": "2025-06-04T14:08:58.000Z"
      },
      {
        "creator": "Yanina Ledovaya",
        "title": "Hidden Truths About Developer Experience: Three Key Insights From Our Research",
        "link": "https://blog.jetbrains.com/research/2025/06/hidden-truths-about-developer-experience-three-key-insights-from-our-research/",
        "pubDate": "Wed, 04 Jun 2025 13:04:55 +0000",
        "content:encodedSnippet": "Developer experience (DevEx) and developer productivity (DP) are hot topics. Many companies are already working actively to measure and improve them, while others, if not already doing this, are at least aware of them. However, what we’re interested in is what’s really happening inside companies when it comes to DevEx and DP.\nTo get a clearer picture, we incorporated a range of questions on DevEx and DP into our annual Developer Ecosystem Survey (about 20,000 developers all over the world have submitted responses to this survey). The results are rather revealing. While there’s growing awareness of these topics, especially within larger companies, our research uncovered some gaps and blind spots. We believe that understanding what these are and how to overcome them will prove useful for our users and customers.\nHere are three key insights from our research:\nHow developers really feel about being measured? Most developers are generally okay with their productivity assessments as long as they are done transparently and fairly.\nDeveloper satisfaction with tools: desired but not measured. 55% of developers either don’t have their satisfaction with tools measured, or don’t know if it’s being measured.\nTeam leads are carrying the burden of DevEx and DP, but should they? 51% of developers and 67% of tech leads agree that team leads are the primary drivers of DevEx and DP measurement.\nHow developers really feel about being measured\nIt’s easy to assume that developers might feel uncomfortable about the fact that their productivity and developer experience are being measured. After all, who enjoys being evaluated? But here’s the good news: most developers are generally okay with these assessments as long as they are done transparently and fairly.\nOur research shows that 42% of developers feel comfortable with productivity assessments, while 40% report neutral feelings on the subject. That means only a small percentage actively dislike being assessed. And even then, the real problem isn’t measurement itself, it’s how it’s done.\n\n\n\n\nThe most common frustration? A lack of transparency.\nDevelopers want to know how their work is being evaluated, why and what decision will be made based on it. Yet our data suggests that nearly half of developers (46%) don’t fully understand how their productivity data is used in decision-making. Without this clarity, these efforts risk being perceived as arbitrary or unfair.\nAmong other issues are a lack of constructive feedback following assessments and the use of methods and metrics that are sub-optimal from developers’ perspective.\nDevelopers want actionable insights based on the results of evaluations so they can grow and improve. And many companies still solely rely on activity-based measurements like counting commits or code changes, that provide a limited overview of productivity and offer little value for meaningful feedback.\n\n\n\n\nDeveloper satisfaction with tools: desired but not measured\nWhat’s one of the biggest contributors to a great developer experience? Good tools. When tools are smooth, functionable, and reliable, developer frictions are minimized. When tools are slow, hard to use and unstable, developer frictions (long feedback loops, high cognitive load, inability to get into the flow state) flourish.\nYet, our research shows that 55% of developers either don’t have their satisfaction with tools measured, or don’t know if it’s being measured. This is upsetting. If companies aren’t paying attention to satisfaction with tools, how can they improve developer experience?\n\n\n\n\nWhy is this a problem?\nDevelopers spend hours every day working with their tools. Small inefficiencies add up quickly. And frustration with tools potentially leads to lower productivity and even attrition. If a developer struggles with inefficient workflows for too long, feeling unproductive and not cared about, they may eventually just leave for a company that prioritizes developer experience and cares about developers.\nTeam leads are carrying the burden of DevEx and DP, but should they?\nWhen it comes to developer productivity and developer experience, who is actually responsible? In most companies, regardless of size, team leads take (or are expected to take) ownership of these efforts. Our data shows that 51% of developers and 67% of tech leads agree that team leads are the primary drivers of DevEx and DP measurement.\nThis looks as a logical choice, team leads work closely with developers and understand their challenges. But there’s a question: are team leads actually ready to take on this responsibility? How well-equipped and trained are they for this task, do they have real authority to influence company-wide decisions regarding tools, DP, and DevEx? Or has this responsibility been pushed onto them without real sufficient support?\nIn large companies, dedicated specialists (30%) and platform engineering teams (28%) are becoming important players in measuring and improving DevEx and DP, according to tech leads. In smaller companies, these roles are less common, with only 16% and 17% of tech leads respectively naming them as responsible.\n\n\n\n\n\n\n\n\nFinal thoughts\nOur research shows that while developer experience and productivity are in the focus for many companies, some of them still face challenges in measuring, understanding, and improving them.\nTransparency and clarity in DevEx and DP assessment matters\nDevelopers aren’t against being measured, but they need to understand the “how” and “why” behind the process and get constructive, useful feedback based on it.\nThe right tools make all the difference, but how can you be sure a tool is right for your developers if you don’t ask them?\nPoor and unsuitable tooling creates friction, yet many companies fail to track developer satisfaction with their tools.\nDeveloper experience isn’t just the responsibility of team leads\nWhile team leads currently play an essential role in measuring DevEx and DP, over-relying on them without support from dedicated teams and a broader, structured approach can lead to inconsistent efforts across teams within the company and team lead burnout.\nOur series exploring how market and user research is done at JetBrains continues. Want to learn more about research insights and take part in future JetBrains studies? Join our JetBrains Tech Insights Lab!",
        "dc:creator": "Yanina Ledovaya",
        "content": "Developer experience (DevEx) and developer productivity (DP) are hot topics. Many companies are already working actively to measure and improve them, while others, if not already doing this, are at least aware of them. However, what we’re interested in is what’s really happening inside companies when it comes to DevEx and DP. To get a [&#8230;]",
        "contentSnippet": "Developer experience (DevEx) and developer productivity (DP) are hot topics. Many companies are already working actively to measure and improve them, while others, if not already doing this, are at least aware of them. However, what we’re interested in is what’s really happening inside companies when it comes to DevEx and DP. To get a […]",
        "guid": "https://blog.jetbrains.com/?post_type=research&p=573039",
        "categories": [
          "research",
          "developer-experience",
          "jetbrains-deveco"
        ],
        "isoDate": "2025-06-04T13:04:55.000Z"
      }
    ]
  },
  {
    "name": "Visual Studio Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Simona Liao",
        "title": "Next edit suggestions available in Visual Studio GitHub Copilot",
        "link": "https://devblogs.microsoft.com/visualstudio/next-edit-suggestions-available-in-visual-studio-github-copilot/",
        "pubDate": "Mon, 09 Jun 2025 15:00:39 +0000",
        "content:encodedSnippet": "GitHub Copilot code completions, or gray text, are specialized in autocompleting unfinished code or providing helpful template code. In reality, coding activities are more diverse than writing new code. What if Copilot could better assist your coding not only with code generation, but your code editing activities as well?\nWe are excited to announce next edit suggestions, or NES for short, is now available in Visual Studio 2022 17.14 to further improve your coding experience. NES leverages the previous edits made and predicts the next edit to come, whether it’s an insertion, deletion, or mix of both. Unlike Copilot completions which are limited to generating suggestions at your caret location, NES can support you anywhere in your file, where the next edit is most likely to occur.\nExample usage scenarios\nNext edit suggestions can be helpful in a variety of scenarios, not only making obvious repetitive changes like renaming, but also more logical changes when you are adding/removing variables or changing the intention of a method. Here are some examples:\n1. Refactoring a 2D Point class to 3D Point:\ndocument.createElement('video');\nhttps://devblogs.microsoft.com/visualstudio/wp-content/uploads/sites/4/2025/06/Point3-26-1.mp4\n\n2. Update the code syntax to modern C++ using STL:\nNote that NES is not just making repetitive changes to updating all “printf() “ to “std::cout“, but also updating other syntax such as “fgets()“.\nhttps://devblogs.microsoft.com/visualstudio/wp-content/uploads/sites/4/2025/06/Migration3-28-1.mp4\n\n3. Make logical changes in response to a newly added variable:\nNES responds quickly to the new variable, which adds the maximum number of guesses a player can make in a game, and Copilot Completions also jumps in to help.\nhttps://devblogs.microsoft.com/visualstudio/wp-content/uploads/sites/4/2025/06/AddingVariable3-28.mp4\n\n\nGetting started with next edit suggestions\nEnable NES via Tools > Options > GitHub > Copilot > Copilot Completions > Enable Next Edit Suggestions.\nLike completions, all you need to do to get NES is to start coding!\nWhen there is an available edit suggestion, it could be presented in a diff view where the red diff indicates the original code you had, and the green indicates the new one suggested by Copilot to clearly shows any replacement or deletion of your original code.\nIf the edit is on a different line than the one you are on now, it will suggest you Tab to Navigate to the corresponding line first. The arrow in the hint bar indicates where the next edit is located. You won’t need to manually search for related edits anymore; NES will lead the way!\n\nAfter you are on the same line as the edit, you can Tab to Accept the suggestion.\n\nIn addition to the hint bars, an arrow in the gutter also pops up to indicate that there is an edit suggestion available. You can click on the arrow to explore the edit suggestion menu. This menu allows you to interact with NES using a mouse, when you don’t want to press the Tab key.\n\nSee next edit suggestions explained step-by-step:\n\nPlease give NES a try today to let it assist you in your logical editing flow! If you have any feedback, our team would love to hear from you through Developer Community to help us keep iterating on and improving NES!\nCheck out the new Visual Studio Hub\nStay connected with everything Visual Studio in one place! Visit the Visual Studio Hub for the latest release notes, YouTube videos, social updates, and community discussions.\nAppreciation for your feedback\nYour feedback helps us improve Visual Studio, making it an even more powerful tool for developers. We are immensely grateful for your contributions and look forward to your continued support. By sharing your thoughts, ideas, and any issues you encounter through Developer Community, you help us improve and shape the future of Visual Studio.\nThe post Next edit suggestions available in Visual Studio GitHub Copilot appeared first on Visual Studio Blog.",
        "enclosure": {
          "url": "https://devblogs.microsoft.com/visualstudio/wp-content/uploads/sites/4/2025/06/Point3-26-1.mp4",
          "length": "4636352",
          "type": "video/mp4"
        },
        "dc:creator": "Simona Liao",
        "comments": "https://devblogs.microsoft.com/visualstudio/next-edit-suggestions-available-in-visual-studio-github-copilot/#comments",
        "content": "<p>GitHub Copilot code completions, or gray text, are specialized in autocompleting unfinished code or providing helpful template code. In reality, coding activities are more diverse than writing new code. What if Copilot could better assist your coding not only with code generation, but your code editing activities as well? We are excited to announce next [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/next-edit-suggestions-available-in-visual-studio-github-copilot/\">Next edit suggestions available in Visual Studio GitHub Copilot</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "GitHub Copilot code completions, or gray text, are specialized in autocompleting unfinished code or providing helpful template code. In reality, coding activities are more diverse than writing new code. What if Copilot could better assist your coding not only with code generation, but your code editing activities as well? We are excited to announce next […]\nThe post Next edit suggestions available in Visual Studio GitHub Copilot appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=253452",
        "categories": [
          "Artificial Intelligence",
          "GitHub Copilot",
          "Productivity",
          "Visual Studio",
          "Copilot",
          "Next Edits Suggestion"
        ],
        "isoDate": "2025-06-09T15:00:39.000Z"
      },
      {
        "creator": "David Li, Moyo Okeremi",
        "title": "How to filter C++ Build Insights by project",
        "link": "https://devblogs.microsoft.com/visualstudio/how-to-filter-c-build-insights-by-project/",
        "pubDate": "Thu, 05 Jun 2025 15:37:33 +0000",
        "content:encodedSnippet": "Visual Studio 2022 version 17.14 comes with quality-of-life improvements to its C++ Build Insights integration that will make it easier for you to navigate large multi-project traces and handle long file names for your build inputs and artifacts.\n\nWhat is C++ Build Insights?\nC++ Build Insights is a powerful tool that lets you visualize and optimize the build process of your C++ projects. It leverage MSVC’s trace capture technology and uses the Windows ETW framework to collect detailed information about every build event, such as compilation, linking, code analysis, and more. You can then view and analyze this data in many ways, such as a timeline, a flame graph, or a tree map. As of Visual Studio 2022 version 17.7, C++ Build Insights is integrated into Visual Studio.\nC++ Build Insights can help you identify and fix bottlenecks, dependencies, and inefficiencies in your build system, resulting in faster and more reliable builds. You can also compare different builds and see how your changes affect the build performance over time. To learn more, read how Activision used Build Insights to cut Call of Duty’s Build Time by 50% on the Microsoft Game Dev Blog.\nHow to Filter C++ Build Insights by Project\nOne of the new features in Visual Studio 2022 is the ability to filter your C++ Build Insights results for Visual Studio solutions by project. This can be particularly useful if you have a large solution with multiple projects and you want to focus on one of them. To do this, simply run Build Insights on your solution by selecting Build > Run Build Insights on Solution and then either Build or Rebuild, depending on whether you want to measure the build from scratch. This will generate an ETL (event trace log) trace, which Visual Studio will automatically open to visualize the data collected. Select the project that you want to filter by selecting the funnel next to the Project column and narrowing down the set of projects for which you want to view the data.\nHow to Filter C++ Build Insights by File Paths\nIn addition to project filtering, Build Insights now also supports file path filtering, which gives you fine-grained control over which files are included in your analysis. This is especially helpful in large codebases where build data from third-party libraries or generated code can clutter your view. With the File Path Filter, you can use glob patterns to focus on specific directories or file types—helping you isolate and investigate the build performance of just the parts you care about. Whether you’re narrowing your focus during a regression investigation or simply trying to understand the build cost of a particular code change, file path filtering helps you get answers faster.\nTo do this, simply run Build Insights on your solution by selecting Build > Run Build Insights on Solution and then either Build or Rebuild, depending on whether you want to measure the build from scratch. This will generate an ETL (event trace log) trace, which Visual Studio will automatically open to visualize the data collected. Select the project that you want to filter by selecting the funnel next to the File Path column and typing in the glob pattern you want to focus on or ignore.\nHow to see the file names and paths of build inputs and artifacts\nAnother improvement in Visual Studio is the way Build Insights displays the file names and paths of your build inputs and artifacts, such as source files, object files, libraries, and executables. Instead of showing the full path, which can be quite long and hard to read, Build Insights now shows the relative path and the file name, separated by a backslash. This makes it easier to find your build artifacts, especially if you have a complex folder structure.\nYou can see the file names and paths of your build inputs and artifacts in any view that shows them, such as the Included Files view, which shows the files that are included by each source file during compilation. You can also hover over any build event to see more details, including the file name and path.\nWe hope you find these quality-of-life improvements useful and that they help you optimize your C++ build process. We are always working on making Visual Studio better for developers, and we appreciate your continuous feedback and suggestions. Please tell us what you think of these features and what else you want in Build Insights.\nThe post How to filter C++ Build Insights by project appeared first on Visual Studio Blog.",
        "dc:creator": "David Li, Moyo Okeremi",
        "comments": "https://devblogs.microsoft.com/visualstudio/how-to-filter-c-build-insights-by-project/#respond",
        "content": "<p>Visual Studio 2022 version 17.14 comes with quality-of-life improvements to its C++ Build Insights integration that will make it easier for you to navigate large multi-project traces and handle long file names for your build inputs and artifacts. What is C++ Build Insights? C++ Build Insights is a powerful tool that lets you visualize and [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/how-to-filter-c-build-insights-by-project/\">How to filter C++ Build Insights by project</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "Visual Studio 2022 version 17.14 comes with quality-of-life improvements to its C++ Build Insights integration that will make it easier for you to navigate large multi-project traces and handle long file names for your build inputs and artifacts. What is C++ Build Insights? C++ Build Insights is a powerful tool that lets you visualize and […]\nThe post How to filter C++ Build Insights by project appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=253442",
        "categories": [
          "Debug",
          "Performance",
          "Visual Studio",
          "C++"
        ],
        "isoDate": "2025-06-05T15:37:33.000Z"
      }
    ]
  },
  {
    "name": "Instagram Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Dropbox Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Joshua",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권재명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김석기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권진호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강대명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권정혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "줌구",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수보",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김시은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "곽민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민서",
    "category": "개인",
    "posts": []
  },
  {
    "name": "I am not Okay",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권창현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권기호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강태욱",
    "category": "개인",
    "posts": [
      {
        "title": "높은 성능의 AI 에이전트 구현을 위한 Gemma3 Function call 파인튜닝",
        "link": "http://daddynkidsmakers.blogspot.com/2025/06/ai-gemma3-function-call.html",
        "pubDate": "2025-06-06T10:33:00.000Z",
        "author": "Daddy Maker",
        "content": "<div style=\"text-align: left;\">이 글은&nbsp;높은 성능의 AI 에이전트 구현을 위한 Gemma3 Function call 파인튜닝 방법을 설명한다.</div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEjAmUYxlpxmCzXUtSnR5zlSouTuYUC8BsO7MJKdZC54cxj1vVFR1BGoZmySiw5MJLXTim-E9qsKse6SEu8k5FiPu4qZPMICMpLceAADnSrgc5FVr2-zzAoJ_39a-sFm6SdQGdKWyPtCil4y14tWxsdGgCvnejYvdmyZAJM1XVvZTM2dhge0TLg14d-rl0qn\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"1231\" data-original-width=\"2000\" height=\"280\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEjAmUYxlpxmCzXUtSnR5zlSouTuYUC8BsO7MJKdZC54cxj1vVFR1BGoZmySiw5MJLXTim-E9qsKse6SEu8k5FiPu4qZPMICMpLceAADnSrgc5FVr2-zzAoJ_39a-sFm6SdQGdKWyPtCil4y14tWxsdGgCvnejYvdmyZAJM1XVvZTM2dhge0TLg14d-rl0qn=w455-h280\" width=\"455\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\">AI 에이전트에서 Function Call 개념</div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\"><b>준비물</b></div><div style=\"text-align: left;\">이 글은 gemma3를 이용해 function call 데이터셋을 튜닝한다. 해당 모델과 파일은 다음 링크를 참고한다.</div><div style=\"text-align: left;\"><ul style=\"text-align: left;\"><li><a href=\"https://huggingface.co/google/gemma-3-4b-it\">google/gemma-3-4b-it · Hugging Face</a></li><li><div><div class=\"separator\" style=\"clear: both; text-align: left;\"><a href=\"https://huggingface.co/datasets/Salesforce/xlam-function-calling-60k\">Salesforce/xlam-function-calling-60k · Datasets at Hugging Face</a></div></div></li></ul></div><div style=\"text-align: left;\">모델을 사용하기 전에 google로부터 다음과 같이 사용 허가(grant)를 얻는다.</div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEhoVumWE1rWlw4UKS4SlI762E5kdqoExvsJuEuFHY-6JZp57UPKHaCWaAdO2vPtQznnXE1yRllDBE_YCjDo9OFt0udjHLIrbE-AvjAAQQB7gnmxkMFrpLeUaQVOfHlMws4JsopYWsHw6CEnMMfP7YoeGZ__KTT4jgCxbloEC1i_0jK85xFrvd2I2EAd-nXE\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"529\" data-original-width=\"1371\" height=\"154\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEhoVumWE1rWlw4UKS4SlI762E5kdqoExvsJuEuFHY-6JZp57UPKHaCWaAdO2vPtQznnXE1yRllDBE_YCjDo9OFt0udjHLIrbE-AvjAAQQB7gnmxkMFrpLeUaQVOfHlMws4JsopYWsHw6CEnMMfP7YoeGZ__KTT4jgCxbloEC1i_0jK85xFrvd2I2EAd-nXE=w400-h154\" width=\"400\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://huggingface.co/google/gemma-3-4b-it\" style=\"text-align: left;\">google/gemma-3-4b-it · Hugging Face</a></div></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\">터미널에서 다음처럼 패키지 설치한다.</div><div style=\"text-align: left;\"><div>pip install \"torch&gt;=2.4.0\" tensorboard flash-attn</div><div>pip install git+https://github.com/huggingface/transformers@v4.49.0</div><div>pip install --upgrade datasets==3.3.2 accelerate==1.4.0 evaluate==0.4.3&nbsp; bitsandbytes==0.45.3 trl==0.15.2 peft==0.14.0 protobuf==3.20.3&nbsp; sentencepiece</div></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\">혹시 윈도우에서 다음과 같이 에러 발생하면 긴파일명 에러가 발생한 것이다.</div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEjCvr5FEe7WS-o5VGhNwoqOmfekbwIYyVK2jkbVmHnrC68Hxu4o-PL7eyYQ_eLMvV1WuHRpCMIdTGle-ARqstKZnhlsIMzpU97CJs0O-P5-nQbEPWU7WkjQIxpsjZdJHuSoH6MUmLPS73NnObZ0ehnZnLU1ZcMC5C8jXcKxY0vBAZKlqW5MURZ7p7ytCX9H\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"240\" data-original-width=\"1123\" height=\"68\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEjCvr5FEe7WS-o5VGhNwoqOmfekbwIYyVK2jkbVmHnrC68Hxu4o-PL7eyYQ_eLMvV1WuHRpCMIdTGle-ARqstKZnhlsIMzpU97CJs0O-P5-nQbEPWU7WkjQIxpsjZdJHuSoH6MUmLPS73NnObZ0ehnZnLU1ZcMC5C8jXcKxY0vBAZKlqW5MURZ7p7ytCX9H\" width=\"320\" /></a></div><br /><div>regedit 실행해 다음 레지스트리에서 오른쪽에서 LongPathsEnabled를 더블 클릭한 후 값(Data)을 1로 변경하고 확인한다.</div></div><div style=\"text-align: left;\"><div>HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\FileSystem</div><div><br /></div></div><div style=\"text-align: left;\"><b>펑션콜 데이터셋 구조</b></div><div style=\"text-align: left;\">다음은 펑션콜 CoT 구조 데이터셋 예시이다.</div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEhMbuBEMTjD9bpQtWY9EOWWz3z5fEb-JNie2kdG9PFA57mI237JDfLGnMD3Da0Mjr_X4ZWl8oSO5IBzuVtVTLKLyrKrUrPADYXHFxCAeiSTtAJH6Z_xqYpx2cZZDpi7xcOf4e4oq0qUrhBCJ0Gi_qmA5CVvCtxBBSj6qLljPaWpkjyWfmYJlmOsK7_yBnVB\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"1231\" data-original-width=\"2535\" height=\"293\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEhMbuBEMTjD9bpQtWY9EOWWz3z5fEb-JNie2kdG9PFA57mI237JDfLGnMD3Da0Mjr_X4ZWl8oSO5IBzuVtVTLKLyrKrUrPADYXHFxCAeiSTtAJH6Z_xqYpx2cZZDpi7xcOf4e4oq0qUrhBCJ0Gi_qmA5CVvCtxBBSj6qLljPaWpkjyWfmYJlmOsK7_yBnVB=w604-h293\" width=\"604\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://huggingface.co/datasets/Salesforce/xlam-function-calling-60k\">Salesforce/xlam-function-calling-60k · Datasets at Hugging Face</a></div></div><div style=\"font-weight: bold; text-align: left;\"><b><br /></b></div><div style=\"font-weight: bold; text-align: left;\">모델 튜닝 코드 구현</div><div style=\"text-align: left;\">튜닝 코드를 다음과 같이 코딩한다. 우선, 라이브러리를 임포트한다.</div><div style=\"text-align: left;\"><div style=\"background-color: #1f1f1f; color: #cccccc; font-family: Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; line-height: 16px; white-space: pre;\"><div><span style=\"color: #c586c0;\">import</span> torch, json, gc, os</div><div><span style=\"color: #c586c0;\">from</span> transformers <span style=\"color: #c586c0;\">import</span> AutoTokenizer, Gemma3ForConditionalGeneration, BitsAndBytesConfig, set_seed</div><div><span style=\"color: #c586c0;\">from</span> datasets <span style=\"color: #c586c0;\">import</span> load_dataset</div><div><span style=\"color: #c586c0;\">from</span> trl <span style=\"color: #c586c0;\">import</span> SFTTrainer, SFTConfig</div><div><span style=\"color: #c586c0;\">from</span> peft <span style=\"color: #c586c0;\">import</span> LoraConfig, PeftModel, PeftConfig</div><div><span style=\"color: #c586c0;\">from</span> enum <span style=\"color: #c586c0;\">import</span> Enum</div><div><span style=\"color: #c586c0;\">from</span> huggingface_hub <span style=\"color: #c586c0;\">import</span> login</div><div><span style=\"color: #c586c0;\">from</span> dotenv <span style=\"color: #c586c0;\">import</span> load_dotenv</div></div></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\">API키, 모델 경로 등 기본 설정한다. 단, API키는 프로젝트에 .env 파일을 추가하고 HF_API_KEY=&lt;허깅페이스 API KEY&gt;가&nbsp; 내용에 포함되어 있어야 한다. 모델은 본인의 VRAM 크기를 고려해 설정한다. 참고로, 이 코드는 가장 작은 VRAM 을 사용하는 gemma-3-4b-it를 사용한다.</div><div style=\"text-align: left;\"><div style=\"background-color: #1f1f1f; color: #cccccc; font-family: Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; line-height: 16px; white-space: pre;\"><div>load_dotenv()</div><div>hf_token <span style=\"color: #d4d4d4;\">=</span> os.getenv(<span style=\"color: #ce9178;\">\"HF_API_KEY\"</span>)</div><div>login(<span style=\"color: #9cdcfe;\">token</span><span style=\"color: #d4d4d4;\">=</span>hf_token)</div><br /><div>os.environ[<span style=\"color: #ce9178;\">\"PYTORCH_CUDA_ALLOC_CONF\"</span>] <span style=\"color: #d4d4d4;\">=</span> <span style=\"color: #ce9178;\">\"expandable_segments:True\"</span></div><br /><div>seed <span style=\"color: #d4d4d4;\">=</span> <span style=\"color: #b5cea8;\">42</span></div><div>set_seed(seed)</div><br /><div>torch_dtype <span style=\"color: #d4d4d4;\">=</span> torch.bfloat16 <span style=\"color: #c586c0;\">if</span> torch.cuda.get_device_capability()[<span style=\"color: #b5cea8;\">0</span>] <span style=\"color: #d4d4d4;\">&gt;=</span> <span style=\"color: #b5cea8;\">8</span> <span style=\"color: #c586c0;\">else</span> torch.float16</div><div>device <span style=\"color: #d4d4d4;\">=</span> torch.device(<span style=\"color: #ce9178;\">\"cuda\"</span> <span style=\"color: #c586c0;\">if</span> torch.cuda.is_available() <span style=\"color: #c586c0;\">else</span> <span style=\"color: #ce9178;\">\"cpu\"</span>)</div><br /><div>model_name <span style=\"color: #d4d4d4;\">=</span> <span style=\"color: #ce9178;\">\"google/gemma-3-4b-it\"</span></div><div>dataset_name <span style=\"color: #d4d4d4;\">=</span> <span style=\"color: #ce9178;\">\"Salesforce/xlam-function-calling-60k\"</span></div></div></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\">모델 튜닝 파라메터를 설정한다. attn_implementation은 트랜스포머 어텐션 연산의 성능을 개선하기 위한 옵션이다. 적절히 선택하되, 환경 상 해당 알고리즘이 동작되지 않는다면 eager 옵션을 선택한다.</div><div style=\"text-align: left;\"><div style=\"background-color: #1f1f1f; color: #cccccc; font-family: Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; line-height: 16px; white-space: pre;\"><div>model_kwargs <span style=\"color: #d4d4d4;\">=</span> <span style=\"color: #4ec9b0;\">dict</span>(</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">attn_implementation</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #ce9178;\">\"flash_attention_2\"</span>, <span style=\"color: #6a9955;\"># \"eager\", \"sdpa\", \"flash_attention\", \"flash_attention_2\"</span></div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">torch_dtype</span><span style=\"color: #d4d4d4;\">=</span>torch_dtype,</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">device_map</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #ce9178;\">\"auto\"</span>,</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">quantization_config</span><span style=\"color: #d4d4d4;\">=</span>BitsAndBytesConfig(</div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #9cdcfe;\">load_in_4bit</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #569cd6;\">True</span>,</div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #9cdcfe;\">bnb_4bit_use_double_quant</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #569cd6;\">True</span>,</div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #9cdcfe;\">bnb_4bit_quant_type</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #ce9178;\">'nf4'</span>,</div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #9cdcfe;\">bnb_4bit_compute_dtype</span><span style=\"color: #d4d4d4;\">=</span>torch_dtype,</div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #9cdcfe;\">bnb_4bit_quant_storage</span><span style=\"color: #d4d4d4;\">=</span>torch_dtype,</div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #9cdcfe;\">llm_int8_enable_fp32_cpu_offload</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #569cd6;\">True</span></div><div>&nbsp; &nbsp; )</div><div>)</div><br /><div>model <span style=\"color: #d4d4d4;\">=</span> Gemma3ForConditionalGeneration.from_pretrained(model_name, <span style=\"color: #d4d4d4;\">**</span>model_kwargs)</div></div></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\">함수호출을 위한 모델 튜닝에 필요한 특수 토큰을 정의한다.</div><div style=\"text-align: left;\"><div style=\"background-color: #1f1f1f; color: #cccccc; font-family: Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; line-height: 16px; white-space: pre;\"><div><span style=\"color: #569cd6;\">class</span> <span style=\"color: #4ec9b0;\">ToolCallSpacialTokens</span>(<span style=\"color: #4ec9b0;\">str</span>, <span style=\"color: #4ec9b0;\">Enum</span>):</div><div>&nbsp; &nbsp; tools <span style=\"color: #d4d4d4;\">=</span> <span style=\"color: #ce9178;\">\"&lt;tools&gt;\"</span></div><div>&nbsp; &nbsp; eotools <span style=\"color: #d4d4d4;\">=</span> <span style=\"color: #ce9178;\">\"&lt;/tools&gt;\"</span></div><div>&nbsp; &nbsp; think <span style=\"color: #d4d4d4;\">=</span> <span style=\"color: #ce9178;\">\"&lt;think&gt;\"</span></div><div>&nbsp; &nbsp; eothink <span style=\"color: #d4d4d4;\">=</span> <span style=\"color: #ce9178;\">\"&lt;/think&gt;\"</span></div><div>&nbsp; &nbsp; tool_call<span style=\"color: #d4d4d4;\">=</span><span style=\"color: #ce9178;\">\"&lt;tool_call&gt;\"</span></div><div>&nbsp; &nbsp; eotool_call<span style=\"color: #d4d4d4;\">=</span><span style=\"color: #ce9178;\">\"&lt;/tool_call&gt;\"</span></div><div>&nbsp; &nbsp; tool_response<span style=\"color: #d4d4d4;\">=</span><span style=\"color: #ce9178;\">\"&lt;tool_response&gt;\"</span></div><div>&nbsp; &nbsp; eotool_response<span style=\"color: #d4d4d4;\">=</span><span style=\"color: #ce9178;\">\"&lt;/tool_response&gt;\"</span></div><div>&nbsp; &nbsp; pad_token <span style=\"color: #d4d4d4;\">=</span> <span style=\"color: #ce9178;\">\"&lt;pad&gt;\"</span></div><div>&nbsp; &nbsp; eos_token <span style=\"color: #d4d4d4;\">=</span> <span style=\"color: #ce9178;\">\"&lt;eos&gt;\"</span></div><br /><div>&nbsp; &nbsp; <span style=\"color: #dcdcaa;\">@</span><span style=\"color: #4ec9b0;\">classmethod</span></div><div>&nbsp; &nbsp; <span style=\"color: #569cd6;\">def</span> <span style=\"color: #4ec9b0;\">list</span>(<span style=\"color: #9cdcfe;\">cls</span>):</div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #c586c0;\">return</span> [c.value <span style=\"color: #c586c0;\">for</span> c <span style=\"color: #c586c0;\">in</span> <span style=\"color: #569cd6;\">cls</span>]</div><br /><div>tokenizer <span style=\"color: #d4d4d4;\">=</span> AutoTokenizer.from_pretrained(</div><div>&nbsp; &nbsp; model_name,</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">pad_token</span><span style=\"color: #d4d4d4;\">=</span>ToolCallSpacialTokens.pad_token.value,</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">additional_special_tokens</span><span style=\"color: #d4d4d4;\">=</span>ToolCallSpacialTokens.list()</div><div>)</div></div></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\">토큰 엠베딩 차원을 리사이즈한다.</div><div style=\"text-align: left;\"><div style=\"background-color: #1f1f1f; color: #cccccc; font-family: Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; line-height: 16px; white-space: pre;\"><div>tokenizer.chat_template <span style=\"color: #d4d4d4;\">=</span> <span style=\"color: #ce9178;\">\"\"\"</span><span style=\"color: #569cd6;\">{{</span><span style=\"color: #ce9178;\"> bos_token </span><span style=\"color: #569cd6;\">}}</span><span style=\"color: #ce9178;\">{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{{ '&lt;start_of_turn&gt;' + message['role'] + '</span><span style=\"color: #d7ba7d;\">\\n</span><span style=\"color: #ce9178;\">' + message['content'] | trim + '&lt;end_of_turn&gt;&lt;eos&gt;</span><span style=\"color: #d7ba7d;\">\\n</span><span style=\"color: #ce9178;\">' }}{% endfor %}{% if add_generation_prompt %}{{'&lt;start_of_turn&gt;model</span><span style=\"color: #d7ba7d;\">\\n</span><span style=\"color: #ce9178;\">'}}{% endif %}\"\"\"</span></div><br /><div>model.resize_token_embeddings(<span style=\"color: #dcdcaa;\">len</span>(tokenizer))</div><div>model.to(device)</div><br /></div></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\">모델튜닝을 위해 학습데이터를 모델에 맞게 전처리한다.</div><div style=\"text-align: left;\"><div style=\"background-color: #1f1f1f; color: #cccccc; font-family: Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; line-height: 16px; white-space: pre;\"><div><span style=\"color: #569cd6;\">def</span> <span style=\"color: #dcdcaa;\">preprocess</span>(<span style=\"color: #9cdcfe;\">sample</span>):</div><div>&nbsp; &nbsp; <span style=\"color: #c586c0;\">try</span>:</div><div>&nbsp; &nbsp; &nbsp; &nbsp; tools <span style=\"color: #d4d4d4;\">=</span> json.loads(sample[<span style=\"color: #ce9178;\">\"tools\"</span>])</div><div>&nbsp; &nbsp; &nbsp; &nbsp; answers <span style=\"color: #d4d4d4;\">=</span> json.loads(sample[<span style=\"color: #ce9178;\">\"answers\"</span>])</div><div>&nbsp; &nbsp; &nbsp; &nbsp; user_query <span style=\"color: #d4d4d4;\">=</span> sample[<span style=\"color: #ce9178;\">\"query\"</span>]</div><div>&nbsp; &nbsp; <span style=\"color: #c586c0;\">except</span> <span style=\"color: #4ec9b0;\">Exception</span> <span style=\"color: #c586c0;\">as</span> e:</div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #dcdcaa;\">print</span>(<span style=\"color: #ce9178;\">\"Error decoding JSON:\"</span>, sample)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #c586c0;\">raise</span> e</div><br /><div>&nbsp; &nbsp; messages <span style=\"color: #d4d4d4;\">=</span> [</div><div>&nbsp; &nbsp; &nbsp; &nbsp; {</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #ce9178;\">\"role\"</span>: <span style=\"color: #ce9178;\">\"user\"</span>,</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #ce9178;\">\"content\"</span>: (</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #ce9178;\">\"You have access to the following tools:</span><span style=\"color: #d7ba7d;\">\\n\\n</span><span style=\"color: #ce9178;\">\"</span></div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #d4d4d4;\">+</span> <span style=\"color: #ce9178;\">\"</span><span style=\"color: #d7ba7d;\">\\n\\n</span><span style=\"color: #ce9178;\">\"</span>.join(<span style=\"color: #569cd6;\">f</span><span style=\"color: #ce9178;\">\"- </span><span style=\"color: #569cd6;\">{</span>tool[<span style=\"color: #ce9178;\">'name'</span>]<span style=\"color: #569cd6;\">}</span><span style=\"color: #ce9178;\">: </span><span style=\"color: #569cd6;\">{</span>tool[<span style=\"color: #ce9178;\">'description'</span>]<span style=\"color: #569cd6;\">}</span><span style=\"color: #ce9178;\">\"</span> <span style=\"color: #c586c0;\">for</span> tool <span style=\"color: #c586c0;\">in</span> tools)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #d4d4d4;\">+</span> <span style=\"color: #ce9178;\">\"</span><span style=\"color: #d7ba7d;\">\\n\\n</span><span style=\"color: #ce9178;\">User query:</span><span style=\"color: #d7ba7d;\">\\n</span><span style=\"color: #ce9178;\">\"</span> <span style=\"color: #d4d4d4;\">+</span> user_query</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; )</div><div>&nbsp; &nbsp; &nbsp; &nbsp; },</div><div>&nbsp; &nbsp; &nbsp; &nbsp; {</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #ce9178;\">\"role\"</span>: <span style=\"color: #ce9178;\">\"assistant\"</span>,</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #ce9178;\">\"content\"</span>: <span style=\"color: #ce9178;\">\"</span><span style=\"color: #d7ba7d;\">\\n</span><span style=\"color: #ce9178;\">\"</span>.join(</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #569cd6;\">f</span><span style=\"color: #ce9178;\">\"&lt;function_call&gt;</span><span style=\"color: #d7ba7d;\">\\n</span><span style=\"color: #569cd6;\">{</span>json.dumps(answer)<span style=\"color: #569cd6;\">}</span><span style=\"color: #d7ba7d;\">\\n</span><span style=\"color: #ce9178;\">&lt;/function_call&gt;\"</span></div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #c586c0;\">for</span> answer <span style=\"color: #c586c0;\">in</span> answers</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; )</div><div>&nbsp; &nbsp; &nbsp; &nbsp; }</div><div>&nbsp; &nbsp; ]</div><br /><div>&nbsp; &nbsp; <span style=\"color: #c586c0;\">return</span> {</div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #ce9178;\">\"text\"</span>: tokenizer.apply_chat_template(messages, <span style=\"color: #9cdcfe;\">add_generation_prompt</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #569cd6;\">True</span>, <span style=\"color: #9cdcfe;\">tokenize</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #569cd6;\">False</span>)</div><div>&nbsp; &nbsp; }</div><br /><div>dataset <span style=\"color: #d4d4d4;\">=</span> load_dataset(dataset_name)</div><div>dataset <span style=\"color: #d4d4d4;\">=</span> dataset[<span style=\"color: #ce9178;\">\"train\"</span>].map(preprocess, <span style=\"color: #9cdcfe;\">remove_columns</span><span style=\"color: #d4d4d4;\">=</span>[<span style=\"color: #ce9178;\">\"id\"</span>, <span style=\"color: #ce9178;\">\"query\"</span>, <span style=\"color: #ce9178;\">\"answers\"</span>, <span style=\"color: #ce9178;\">\"tools\"</span>])</div><div>dataset <span style=\"color: #d4d4d4;\">=</span> dataset.train_test_split(<span style=\"color: #b5cea8;\">0.1</span>)</div><div><span style=\"color: #dcdcaa;\">print</span>(dataset)</div><br /><div><span style=\"color: #dcdcaa;\">print</span>(dataset[<span style=\"color: #ce9178;\">\"train\"</span>][<span style=\"color: #b5cea8;\">19</span>][<span style=\"color: #ce9178;\">\"text\"</span>])</div></div></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\">파인튜닝을 위해 LoRA와 SFT 설정한다.</div><div style=\"text-align: left;\"><div style=\"background-color: #1f1f1f; color: #cccccc; font-family: Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; line-height: 16px; white-space: pre;\"><div>peft_config <span style=\"color: #d4d4d4;\">=</span> LoraConfig(</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">lora_alpha</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #b5cea8;\">16</span>,</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">lora_dropout</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #b5cea8;\">0.05</span>,</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">r</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #b5cea8;\">16</span>,</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">bias</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #ce9178;\">\"none\"</span>,</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">target_modules</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #ce9178;\">\"all-linear\"</span>,</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">task_type</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #ce9178;\">\"CAUSAL_LM\"</span>,</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">modules_to_save</span><span style=\"color: #d4d4d4;\">=</span>[<span style=\"color: #ce9178;\">\"lm_head\"</span>, <span style=\"color: #ce9178;\">\"embed_tokens\"</span>] <span style=\"color: #6a9955;\"># make sure to save the lm_head and embed_tokens as you train the special tokens</span></div><div>)</div><br /><div>training_arguments <span style=\"color: #d4d4d4;\">=</span> SFTConfig(</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">output_dir</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #ce9178;\">\"gemma-3-4b-it-thinking-function_calling-V0\"</span>,</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">per_device_train_batch_size</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #b5cea8;\">1</span>,</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">per_device_eval_batch_size</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #b5cea8;\">1</span>,</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">gradient_accumulation_steps</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #b5cea8;\">32</span>,</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">save_strategy</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #ce9178;\">\"epoch\"</span>,</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">eval_strategy</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #ce9178;\">\"epoch\"</span>,</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">logging_steps</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #b5cea8;\">50</span>,</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">learning_rate</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #b5cea8;\">3e-4</span>,</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">max_grad_norm</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #b5cea8;\">0.3</span>,</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">weight_decay</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #b5cea8;\">0.1</span>,</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">warmup_ratio</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #b5cea8;\">0.03</span>,</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">lr_scheduler_type</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #ce9178;\">\"constant\"</span>,</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">report_to</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #569cd6;\">None</span>,</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">bf16</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #569cd6;\">True</span>,</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">optim</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #ce9178;\">\"paged_adamw_8bit\"</span>,</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">torch_compile</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #569cd6;\">False</span>,</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">push_to_hub</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #569cd6;\">False</span>,</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">num_train_epochs</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #b5cea8;\">3</span>,</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">gradient_checkpointing</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #569cd6;\">True</span>,</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">gradient_checkpointing_kwargs</span><span style=\"color: #d4d4d4;\">=</span>{<span style=\"color: #ce9178;\">\"use_reentrant\"</span>: <span style=\"color: #569cd6;\">False</span>},</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">packing</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #569cd6;\">False</span>,</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">max_seq_length</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #b5cea8;\">512</span>,</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">dataset_kwargs</span><span style=\"color: #d4d4d4;\">=</span>{</div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #ce9178;\">\"add_special_tokens\"</span>: <span style=\"color: #569cd6;\">False</span>,</div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #ce9178;\">\"append_concat_token\"</span>: <span style=\"color: #569cd6;\">True</span>,</div><div>&nbsp; &nbsp; }</div><div>)</div><br /><div>torch.cuda.empty_cache()</div><div>torch.cuda.ipc_collect()</div><div>gc.collect()</div></div></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\">학습하고 결과를 저장한다.</div><div style=\"text-align: left;\"><div style=\"background-color: #1f1f1f; color: #cccccc; font-family: Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; line-height: 16px; white-space: pre;\"><div>trainer <span style=\"color: #d4d4d4;\">=</span> SFTTrainer(</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">model</span><span style=\"color: #d4d4d4;\">=</span>model,</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">args</span><span style=\"color: #d4d4d4;\">=</span>training_arguments,</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">train_dataset</span><span style=\"color: #d4d4d4;\">=</span>dataset[<span style=\"color: #ce9178;\">\"train\"</span>],</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">eval_dataset</span><span style=\"color: #d4d4d4;\">=</span>dataset[<span style=\"color: #ce9178;\">\"test\"</span>],</div><div>&nbsp; &nbsp; # <span style=\"color: #9cdcfe;\">tokenizer</span><span style=\"color: #d4d4d4;\">=</span>tokenizer,</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">peft_config</span><span style=\"color: #d4d4d4;\">=</span>peft_config,</div><div>)</div><br /><div>trainer.train()</div><div>trainer.save_model()</div></div></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\"><div>정상적으로 실행되면, 다음과 같이 함수 호출 데이터셋을 학습할 것이다.</div><div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEhp9zwsfY91KDldzkSOxDbn9HzX_vUXCzLy2sufa-HWGvPg2YHt3R96TA_amasuuCqwzXmUpfo6sFVIkKtM-s_inmlG8c2ILH3naLsrCf6XwSI-dFv6nXALbEYtWueDSnnXLW_hkDsU-w3dcJUYCCDoBRn-rxTceLLTQ81YQV8ApyxaN9Gs5MvlwfrqcDjb\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"635\" data-original-width=\"1581\" height=\"216\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEhp9zwsfY91KDldzkSOxDbn9HzX_vUXCzLy2sufa-HWGvPg2YHt3R96TA_amasuuCqwzXmUpfo6sFVIkKtM-s_inmlG8c2ILH3naLsrCf6XwSI-dFv6nXALbEYtWueDSnnXLW_hkDsU-w3dcJUYCCDoBRn-rxTceLLTQ81YQV8ApyxaN9Gs5MvlwfrqcDjb=w536-h216\" width=\"536\" /></a></div><br /></div></div><div style=\"text-align: left;\">HF에 파인튜닝된 모델을 업로드한다. 그리고, 다시 다운로드하여 평가모드로 모델을 오픈한다.</div><div style=\"text-align: left;\"><div style=\"background-color: #1f1f1f; color: #cccccc; font-family: Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; line-height: 16px; white-space: pre;\"><div><div style=\"line-height: 16px;\"><div>trainer.push_to_hub(<span style=\"color: #569cd6;\">f</span><span style=\"color: #ce9178;\">'mac999/gemma-3-4b-it-thinking-function_calling-V0-</span><span style=\"color: #569cd6;\">{</span>seed<span style=\"color: #569cd6;\">}</span><span style=\"color: #ce9178;\">'</span>, <span style=\"color: #9cdcfe;\">commit_message</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #ce9178;\">\"Pushing fine-tuned model with function calling capabilities\"</span>)</div><br /><div>tokenizer.eos_token <span style=\"color: #d4d4d4;\">=</span> <span style=\"color: #ce9178;\">\"&lt;eos&gt;\"</span></div><div>tokenizer.push_to_hub(<span style=\"color: #569cd6;\">f</span><span style=\"color: #ce9178;\">\"mac999/\"</span>, <span style=\"color: #9cdcfe;\">token</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #569cd6;\">True</span>)</div><br /><div>peft_model_id <span style=\"color: #d4d4d4;\">=</span> <span style=\"color: #569cd6;\">f</span><span style=\"color: #ce9178;\">\"mac999/gemma-3-4b-it-thinking-function_calling-V0-</span><span style=\"color: #569cd6;\">{</span>seed<span style=\"color: #569cd6;\">}</span><span style=\"color: #ce9178;\">\"</span> </div><div>device <span style=\"color: #d4d4d4;\">=</span> <span style=\"color: #ce9178;\">\"auto\"</span></div><div>config <span style=\"color: #d4d4d4;\">=</span> PeftConfig.from_pretrained(peft_model_id)</div><div>model <span style=\"color: #d4d4d4;\">=</span> Gemma3ForConditionalGeneration.from_pretrained(<span style=\"color: #ce9178;\">\"google/gemma-3-4b-it\"</span>,</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span style=\"color: #9cdcfe;\">device_map</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #ce9178;\">\"auto\"</span>,</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;)</div><div>tokenizer <span style=\"color: #d4d4d4;\">=</span> AutoTokenizer.from_pretrained(peft_model_id)</div><div>model.resize_token_embeddings(<span style=\"color: #dcdcaa;\">len</span>(tokenizer))</div><div>model <span style=\"color: #d4d4d4;\">=</span> PeftModel.from_pretrained(model, peft_model_id)</div><div>model.to(torch.bfloat16)</div><div>model.eval()</div></div></div></div></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\">파인튜닝이 제대로되었는 지 function call을 테스트해본다.</div><div style=\"text-align: left;\"><div style=\"background-color: #1f1f1f; color: #cccccc; font-family: Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; line-height: 16px; white-space: pre;\"><div>prompt <span style=\"color: #d4d4d4;\">=</span> <span style=\"color: #ce9178;\">\"\"\"&lt;bos&gt;&lt;start_of_turn&gt;user</span></div><div><span style=\"color: #ce9178;\">You have access to the following tools:</span></div><br /><div><span style=\"color: #ce9178;\">- numerical_derivative: Estimate the derivative of a mathematical function</span></div><br /><div><span style=\"color: #ce9178;\">User query:</span></div><div><span style=\"color: #ce9178;\">I need to estimate the derivative of the function y = sin(x) at x = π/4 and x = π. Can you help with that?&lt;end_of_turn&gt;&lt;eos&gt;</span></div><div><span style=\"color: #ce9178;\">&lt;start_of_turn&gt;assistant</span></div><div><span style=\"color: #ce9178;\">\"\"\"</span></div><br /><div>inputs <span style=\"color: #d4d4d4;\">=</span> tokenizer(prompt, <span style=\"color: #9cdcfe;\">return_tensors</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #ce9178;\">\"pt\"</span>, <span style=\"color: #9cdcfe;\">add_special_tokens</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #569cd6;\">False</span>).to(model.device)</div><br /><div>outputs <span style=\"color: #d4d4d4;\">=</span> model.generate(</div><div>&nbsp; &nbsp; <span style=\"color: #d4d4d4;\">**</span>inputs,</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">max_new_tokens</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #b5cea8;\">256</span>,</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">do_sample</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #569cd6;\">True</span>,</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">temperature</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #b5cea8;\">0.01</span>,</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">top_p</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #b5cea8;\">0.95</span>,</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">repetition_penalty</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #b5cea8;\">1.1</span>,</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">eos_token_id</span><span style=\"color: #d4d4d4;\">=</span>tokenizer.eos_token_id</div><div>)</div><br /><div>response <span style=\"color: #d4d4d4;\">=</span> tokenizer.decode(outputs[<span style=\"color: #b5cea8;\">0</span>], <span style=\"color: #9cdcfe;\">skip_special_tokens</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #569cd6;\">False</span>)</div><div><span style=\"color: #dcdcaa;\">print</span>(response)</div></div></div><div style=\"text-align: left;\"><b><br /></b></div><div style=\"text-align: left;\"><b>마무리</b></div><div style=\"text-align: left;\">파인튜닝 전과 후를 비교해 보면, 확실히 데이터셋에 있는 함수호출 방식이 제대로 생성되는 것을 확인할 수 있을 것이다.</div><div style=\"text-align: left;\"><br /></div><b>레퍼런스</b></div><ul><li><a href=\"https://medium.com/@akriti.upadhyay/enhancing-gemma-3s-capabilities-with-fine-tuning-for-function-calling-f1bc74051abe\">Enhancing Gemma 3’s Capabilities with Fine-Tuning for Function Calling | by Akriti Upadhyay | May, 2025 | Medium</a></li><li><a href=\"https://pdf.elspublishing.com/paper/journal/open/SC/earlyOnline/2025/SC-20250004.pdf\">General AI agent framework for smart buildings based on large language models and ReAct strategy</a></li><li><a href=\"https://medium.com/data-science-collective/the-open-source-stack-for-ai-agents-8ab900e33676\">Open-Source Tools for Agents | Data Science Collective</a></li><li><a href=\"https://levelup.gitconnected.com/the-era-of-high-paying-tech-jobs-is-over-572e4e577758\">The Era of High-Paying Tech Jobs is Over | by Somnath Singh | Level Up Coding</a></li><li><a href=\"https://github.com/AGI-Edgerunners/LLM-Agents-Papers\">AGI-Edgerunners/LLM-Agents-Papers: A repo lists papers related to LLM based agent</a></li><li><a href=\"https://distilabel.argilla.io/dev/sections/pipeline_samples/papers/apigen/#script-and-final-dataset\">APIGen - Distilabel Docs</a></li><li><a href=\"https://huggingface.co/datasets/AymanTarig/function-calling-v0.2-with-r1-cot\">AymanTarig/function-calling-v0.2-with-r1-cot · Datasets at Hugging Face</a></li><li><a href=\"https://blog.langchain.dev/benchmarking-agent-tool-use/\">Benchmarking Agent Tool Use</a></li></ul>",
        "contentSnippet": "이 글은 높은 성능의 AI 에이전트 구현을 위한 Gemma3 Function call 파인튜닝 방법을 설명한다.\n\n\n\nAI 에이전트에서 Function Call 개념\n\n\n준비물\n이 글은 gemma3를 이용해 function call 데이터셋을 튜닝한다. 해당 모델과 파일은 다음 링크를 참고한다.\n\ngoogle/gemma-3-4b-it · Hugging Face\n\nSalesforce/xlam-function-calling-60k · Datasets at Hugging Face\n\n\n모델을 사용하기 전에 google로부터 다음과 같이 사용 허가(grant)를 얻는다.\n\n\ngoogle/gemma-3-4b-it · Hugging Face\n\n\n터미널에서 다음처럼 패키지 설치한다.\n\npip install \"torch>=2.4.0\" tensorboard flash-attn\npip install git+https://github.com/huggingface/transformers@v4.49.0\npip install --upgrade datasets==3.3.2 accelerate==1.4.0 evaluate==0.4.3  bitsandbytes==0.45.3 trl==0.15.2 peft==0.14.0 protobuf==3.20.3  sentencepiece\n\n\n혹시 윈도우에서 다음과 같이 에러 발생하면 긴파일명 에러가 발생한 것이다.\n\n\n\nregedit 실행해 다음 레지스트리에서 오른쪽에서 LongPathsEnabled를 더블 클릭한 후 값(Data)을 1로 변경하고 확인한다.\n\nHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\FileSystem\n\n\n펑션콜 데이터셋 구조\n다음은 펑션콜 CoT 구조 데이터셋 예시이다.\n\n\nSalesforce/xlam-function-calling-60k · Datasets at Hugging Face\n\n\n\n모델 튜닝 코드 구현\n튜닝 코드를 다음과 같이 코딩한다. 우선, 라이브러리를 임포트한다.\n\nimport torch, json, gc, os\nfrom transformers import AutoTokenizer, Gemma3ForConditionalGeneration, BitsAndBytesConfig, set_seed\nfrom datasets import load_dataset\nfrom trl import SFTTrainer, SFTConfig\nfrom peft import LoraConfig, PeftModel, PeftConfig\nfrom enum import Enum\nfrom huggingface_hub import login\nfrom dotenv import load_dotenv\n\n\n\nAPI키, 모델 경로 등 기본 설정한다. 단, API키는 프로젝트에 .env 파일을 추가하고 HF_API_KEY=<허깅페이스 API KEY>가  내용에 포함되어 있어야 한다. 모델은 본인의 VRAM 크기를 고려해 설정한다. 참고로, 이 코드는 가장 작은 VRAM 을 사용하는 gemma-3-4b-it를 사용한다.\n\nload_dotenv()\nhf_token = os.getenv(\"HF_API_KEY\")\nlogin(token=hf_token)\n\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n\nseed = 42\nset_seed(seed)\n\ntorch_dtype = torch.bfloat16 if torch.cuda.get_device_capability()[0] >= 8 else torch.float16\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel_name = \"google/gemma-3-4b-it\"\ndataset_name = \"Salesforce/xlam-function-calling-60k\"\n\n\n\n모델 튜닝 파라메터를 설정한다. attn_implementation은 트랜스포머 어텐션 연산의 성능을 개선하기 위한 옵션이다. 적절히 선택하되, 환경 상 해당 알고리즘이 동작되지 않는다면 eager 옵션을 선택한다.\n\nmodel_kwargs = dict(\n    attn_implementation=\"flash_attention_2\", # \"eager\", \"sdpa\", \"flash_attention\", \"flash_attention_2\"\n    torch_dtype=torch_dtype,\n    device_map=\"auto\",\n    quantization_config=BitsAndBytesConfig(\n        load_in_4bit=True,\n        bnb_4bit_use_double_quant=True,\n        bnb_4bit_quant_type='nf4',\n        bnb_4bit_compute_dtype=torch_dtype,\n        bnb_4bit_quant_storage=torch_dtype,\n        llm_int8_enable_fp32_cpu_offload=True\n    )\n)\n\nmodel = Gemma3ForConditionalGeneration.from_pretrained(model_name, **model_kwargs)\n\n\n\n함수호출을 위한 모델 튜닝에 필요한 특수 토큰을 정의한다.\n\nclass ToolCallSpacialTokens(str, Enum):\n    tools = \"<tools>\"\n    eotools = \"</tools>\"\n    think = \"<think>\"\n    eothink = \"</think>\"\n    tool_call=\"<tool_call>\"\n    eotool_call=\"</tool_call>\"\n    tool_response=\"<tool_response>\"\n    eotool_response=\"</tool_response>\"\n    pad_token = \"<pad>\"\n    eos_token = \"<eos>\"\n\n    @classmethod\n    def list(cls):\n        return [c.value for c in cls]\n\ntokenizer = AutoTokenizer.from_pretrained(\n    model_name,\n    pad_token=ToolCallSpacialTokens.pad_token.value,\n    additional_special_tokens=ToolCallSpacialTokens.list()\n)\n\n\n\n토큰 엠베딩 차원을 리사이즈한다.\n\ntokenizer.chat_template = \"\"\"{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{{ '<start_of_turn>' + message['role'] + '\\n' + message['content'] | trim + '<end_of_turn><eos>\\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\\n'}}{% endif %}\"\"\"\n\nmodel.resize_token_embeddings(len(tokenizer))\nmodel.to(device)\n\n\n\n모델튜닝을 위해 학습데이터를 모델에 맞게 전처리한다.\n\ndef preprocess(sample):\n    try:\n        tools = json.loads(sample[\"tools\"])\n        answers = json.loads(sample[\"answers\"])\n        user_query = sample[\"query\"]\n    except Exception as e:\n        print(\"Error decoding JSON:\", sample)\n        raise e\n\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": (\n                \"You have access to the following tools:\\n\\n\"\n                + \"\\n\\n\".join(f\"- {tool['name']}: {tool['description']}\" for tool in tools)\n                + \"\\n\\nUser query:\\n\" + user_query\n            )\n        },\n        {\n            \"role\": \"assistant\",\n            \"content\": \"\\n\".join(\n                f\"<function_call>\\n{json.dumps(answer)}\\n</function_call>\"\n                for answer in answers\n            )\n        }\n    ]\n\n    return {\n        \"text\": tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)\n    }\n\ndataset = load_dataset(dataset_name)\ndataset = dataset[\"train\"].map(preprocess, remove_columns=[\"id\", \"query\", \"answers\", \"tools\"])\ndataset = dataset.train_test_split(0.1)\nprint(dataset)\n\nprint(dataset[\"train\"][19][\"text\"])\n\n\n\n파인튜닝을 위해 LoRA와 SFT 설정한다.\n\npeft_config = LoraConfig(\n    lora_alpha=16,\n    lora_dropout=0.05,\n    r=16,\n    bias=\"none\",\n    target_modules=\"all-linear\",\n    task_type=\"CAUSAL_LM\",\n    modules_to_save=[\"lm_head\", \"embed_tokens\"] # make sure to save the lm_head and embed_tokens as you train the special tokens\n)\n\ntraining_arguments = SFTConfig(\n    output_dir=\"gemma-3-4b-it-thinking-function_calling-V0\",\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=1,\n    gradient_accumulation_steps=32,\n    save_strategy=\"epoch\",\n    eval_strategy=\"epoch\",\n    logging_steps=50,\n    learning_rate=3e-4,\n    max_grad_norm=0.3,\n    weight_decay=0.1,\n    warmup_ratio=0.03,\n    lr_scheduler_type=\"constant\",\n    report_to=None,\n    bf16=True,\n    optim=\"paged_adamw_8bit\",\n    torch_compile=False,\n    push_to_hub=False,\n    num_train_epochs=3,\n    gradient_checkpointing=True,\n    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n    packing=False,\n    max_seq_length=512,\n    dataset_kwargs={\n        \"add_special_tokens\": False,\n        \"append_concat_token\": True,\n    }\n)\n\ntorch.cuda.empty_cache()\ntorch.cuda.ipc_collect()\ngc.collect()\n\n\n\n학습하고 결과를 저장한다.\n\ntrainer = SFTTrainer(\n    model=model,\n    args=training_arguments,\n    train_dataset=dataset[\"train\"],\n    eval_dataset=dataset[\"test\"],\n    # tokenizer=tokenizer,\n    peft_config=peft_config,\n)\n\ntrainer.train()\ntrainer.save_model()\n\n\n\n정상적으로 실행되면, 다음과 같이 함수 호출 데이터셋을 학습할 것이다.\n\n\n\n\nHF에 파인튜닝된 모델을 업로드한다. 그리고, 다시 다운로드하여 평가모드로 모델을 오픈한다.\n\n\ntrainer.push_to_hub(f'mac999/gemma-3-4b-it-thinking-function_calling-V0-{seed}', commit_message=\"Pushing fine-tuned model with function calling capabilities\")\n\ntokenizer.eos_token = \"<eos>\"\ntokenizer.push_to_hub(f\"mac999/\", token=True)\n\npeft_model_id = f\"mac999/gemma-3-4b-it-thinking-function_calling-V0-{seed}\" \ndevice = \"auto\"\nconfig = PeftConfig.from_pretrained(peft_model_id)\nmodel = Gemma3ForConditionalGeneration.from_pretrained(\"google/gemma-3-4b-it\",\n                                             device_map=\"auto\",\n                                             )\ntokenizer = AutoTokenizer.from_pretrained(peft_model_id)\nmodel.resize_token_embeddings(len(tokenizer))\nmodel = PeftModel.from_pretrained(model, peft_model_id)\nmodel.to(torch.bfloat16)\nmodel.eval()\n\n\n\n\n파인튜닝이 제대로되었는 지 function call을 테스트해본다.\n\nprompt = \"\"\"<bos><start_of_turn>user\nYou have access to the following tools:\n\n- numerical_derivative: Estimate the derivative of a mathematical function\n\nUser query:\nI need to estimate the derivative of the function y = sin(x) at x = π/4 and x = π. Can you help with that?<end_of_turn><eos>\n<start_of_turn>assistant\n\"\"\"\n\ninputs = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=False).to(model.device)\n\noutputs = model.generate(\n    **inputs,\n    max_new_tokens=256,\n    do_sample=True,\n    temperature=0.01,\n    top_p=0.95,\n    repetition_penalty=1.1,\n    eos_token_id=tokenizer.eos_token_id\n)\n\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=False)\nprint(response)\n\n\n\n마무리\n파인튜닝 전과 후를 비교해 보면, 확실히 데이터셋에 있는 함수호출 방식이 제대로 생성되는 것을 확인할 수 있을 것이다.\n\n레퍼런스\n\nEnhancing Gemma 3’s Capabilities with Fine-Tuning for Function Calling | by Akriti Upadhyay | May, 2025 | Medium\nGeneral AI agent framework for smart buildings based on large language models and ReAct strategy\nOpen-Source Tools for Agents | Data Science Collective\nThe Era of High-Paying Tech Jobs is Over | by Somnath Singh | Level Up Coding\nAGI-Edgerunners/LLM-Agents-Papers: A repo lists papers related to LLM based agent\nAPIGen - Distilabel Docs\nAymanTarig/function-calling-v0.2-with-r1-cot · Datasets at Hugging Face\nBenchmarking Agent Tool Use",
        "id": "tag:blogger.com,1999:blog-5201956450461596914.post-1817605231868260949",
        "isoDate": "2025-06-06T10:33:00.000Z"
      },
      {
        "title": "Gemma3 기반 Ollama 활용 AI 에이전트 개발 핵심 Function Call 구현해보기",
        "link": "http://daddynkidsmakers.blogspot.com/2025/06/gemma3-ollama-function-call.html",
        "pubDate": "2025-06-04T06:56:00.000Z",
        "author": "Daddy Maker",
        "content": "<div style=\"text-align: left;\">이 글은 AI 에이전트(Agent) 개발 시 필수적인 함수호출 방법을 오픈소스를 이용해 구현해 본다. 이를 위해, Gemma3(젬마) LLM(Large Language Model) 기반 Ollama 활용 Function Call(펑션콜) 실습 내용을 소개하고 실행 결과를 확인한다. 아울러, 이런 함수호출 방식의 한계점을 개선하기 위한 솔류션을 나눔한다. 이 실습의 결과는 다음과 같다.&nbsp;</div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgC43jML8O5ZD9gE0UBiPfEDwi1HzgyjmgHhe-L2h1Npxx1IdDAvhjEk2UBC_Ca3NUzr7WcKf9YdHx7oRfOKEQ3gxVWT8C3mbevsEMQiFif23p_BnCRz67cKLh35LPGT7Uwj5IjwUaUChbJm1Cu9dpjVGDdZqIJqQA97Xnjr-HnpwN_TdR9yTwXW0bRdO4M/s923/gemma3.gif\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"923\" data-original-width=\"766\" height=\"296\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgC43jML8O5ZD9gE0UBiPfEDwi1HzgyjmgHhe-L2h1Npxx1IdDAvhjEk2UBC_Ca3NUzr7WcKf9YdHx7oRfOKEQ3gxVWT8C3mbevsEMQiFif23p_BnCRz67cKLh35LPGT7Uwj5IjwUaUChbJm1Cu9dpjVGDdZqIJqQA97Xnjr-HnpwN_TdR9yTwXW0bRdO4M/w246-h296/gemma3.gif\" width=\"246\" /></a><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgJp5nOW2mGnTP3fmGJKyDr4mWaSxy-520mFRak2qwYX6mleo9QHErXM0ur6uI_AC4M17kU0vSEFhobzX7zhoc84vL5PTg5Zv6lkTYzMoPx23aVtlkxW9qqAKL6r0O9ykI1wTKkmA01cAvndzbQnvjfj00D_7oDd6xQ5oSvTn_2NM2NhZ1cp6-Uw2VDEGLh/s885/f1.jpg\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"885\" data-original-width=\"760\" height=\"298\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgJp5nOW2mGnTP3fmGJKyDr4mWaSxy-520mFRak2qwYX6mleo9QHErXM0ur6uI_AC4M17kU0vSEFhobzX7zhoc84vL5PTg5Zv6lkTYzMoPx23aVtlkxW9qqAKL6r0O9ykI1wTKkmA01cAvndzbQnvjfj00D_7oDd6xQ5oSvTn_2NM2NhZ1cp6-Uw2VDEGLh/w256-h298/f1.jpg\" width=\"256\" /></a><br /><br /></div><div style=\"text-align: left;\">이 글은 다음 내용을 포함한다.</div><div style=\"text-align: left;\"><ul style=\"text-align: left;\"><li>AI 에이전트 구현을 위한 함수 호출 방법</li><li>Ollama 를 통한 Gemma3 사용법</li><li>채팅 형식 프롬프트 및 메모리 사용법</li><li>Gradio 기반 웹 앱 개발</li><li>Function call 의 한계와 솔류션</li></ul><div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEgPZ4tbKonsWRUbKbnU-0gj0LzofIZaKWCY3U0ppscTZvA_bvBSvpNWfnEeVly61F4XKvMwsQFs67OstafT06qJPd6EkgV3L1CbaIDqinxztPgE5ze-dYD0fNc986bPFDXBrOm7fC15kWeAivVgRAX9P8gM0HxSLLoFaxhR7Wy1QfAqAIX2rvrokFxU4A0u\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"696\" data-original-width=\"1400\" height=\"275\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEgPZ4tbKonsWRUbKbnU-0gj0LzofIZaKWCY3U0ppscTZvA_bvBSvpNWfnEeVly61F4XKvMwsQFs67OstafT06qJPd6EkgV3L1CbaIDqinxztPgE5ze-dYD0fNc986bPFDXBrOm7fC15kWeAivVgRAX9P8gM0HxSLLoFaxhR7Wy1QfAqAIX2rvrokFxU4A0u=w553-h275\" width=\"553\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\">AI 에이전트 내부 Function call 메커니즘(Akriti, 2025)</div></div><div><br /></div><div>이 글의 구현 코드는 다음 링크에서 확인할 수 있다.</div><div><ul style=\"text-align: left;\"><li><a href=\"https://github.com/mac999/AI_agent_simple_function_call\">mac999/AI_agent_simple_function_call</a></li></ul><div><b>Gemma3 모델 특징</b></div></div><div><p>Gemma 3는 구글이 개발해&nbsp; 2025년 3월 10일에 출시한 LLM으로, 차세대 경량 오픈 멀티모달 AI 모델로, 텍스트와 이미지를 동시에 처리할 수 있는 기능을 갖추고 있다. 이 모델은 다양한 크기와 사양으로 제공되어 단일 GPU 또는 TPU 환경에서도 실행 가능하다.</p>\n<p>Gemma 3는 1B, 4B, 12B, 27B의 네 가지 모델 크기로 제공되며, 각각 10억, 40억, 120억, 270억 개의 파라미터를 갖추고 있다. 1B 모델은 텍스트 전용으로 32K 토큰의 입력 컨텍스트를 지원하고, 4B, 12B, 27B 모델은 멀티모달 기능을 지원하며 128K 토큰의 입력 컨텍스트를 처리할 수 있다. 이는 이전 Gemma 모델보다 16배 확장된 크기로, 훨씬 더 많은 양의 정보를 한 번에 처리할 수 있게 해준다.</p>\n<p>이 모델은 텍스트와 이미지 데이터를 동시에 처리하고 이해하는 멀티모달 기능을 제공한다. 이미지 해석, 객체 인식, 시각적 질의응답 등 다양한 작업을 수행할 수 있으며, 텍스트 기반 작업에 시각적 정보를 효과적으로 활용할 수 있도록 지원한다.&nbsp;</p><p></p><div class=\"separator\" style=\"clear: both; text-align: center;\"><span style=\"margin-left: 1em; margin-right: 1em;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEgpavqfnSFTPAQ5GU0lEkSPTmGgO6U223hAyKiUwyHt8Ey37f2eMpnH8BIGqhhuSp-41iUf_Pjeb4direJ1szDwKnTQNCFH8VnN1_wlybckGiWosHfATHL-B9k9Sl_N66pv6X40GIehgODBXU6NQ7W1RstzULPXpgGEeLJUxnO_p3BHJc5v9JdtW4tVpn-9\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"896\" data-original-width=\"672\" height=\"240\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEgpavqfnSFTPAQ5GU0lEkSPTmGgO6U223hAyKiUwyHt8Ey37f2eMpnH8BIGqhhuSp-41iUf_Pjeb4direJ1szDwKnTQNCFH8VnN1_wlybckGiWosHfATHL-B9k9Sl_N66pv6X40GIehgODBXU6NQ7W1RstzULPXpgGEeLJUxnO_p3BHJc5v9JdtW4tVpn-9\" width=\"180\" /></a></span><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEiT6X0A64dHwKjG6_9nAlQiLFc6v6bJ_qEXToGgyJP4_bGd2GO93MYRBxe3ZzeVZWjQZ9voGWU62WaWQSXGMdwwXomb89qdqgeTmNdNluzqmz-9P1aOP8Uu5zJsxaOvEv4Fm1UryGmLr2LB8JmMivxecSAhoxenPn5fhI6-o-QPt8-ebGBId-fe-cc0JkDM\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"4032\" data-original-width=\"3024\" height=\"240\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEiT6X0A64dHwKjG6_9nAlQiLFc6v6bJ_qEXToGgyJP4_bGd2GO93MYRBxe3ZzeVZWjQZ9voGWU62WaWQSXGMdwwXomb89qdqgeTmNdNluzqmz-9P1aOP8Uu5zJsxaOvEv4Fm1UryGmLr2LB8JmMivxecSAhoxenPn5fhI6-o-QPt8-ebGBId-fe-cc0JkDM\" width=\"180\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\">&nbsp;&nbsp;<a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEjLkalqmbDqdomwyJQf8uI9A318iI9i26mzGQoJ_K5pAeOUyYIfzvZzD5DF8VDwDO5dwdgtzthgr7bGGGi02qIEk06vnKlOve0Hmq-wZPar_r7-O6U12tQciCOi0raSH6YyiwVZBJ-7KHDBnKmXg-o05dRyWF4yV2nFQ-FgMYvmAV68wE_qpuZpq7F9CyPz\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"69\" data-original-width=\"478\" height=\"52\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEjLkalqmbDqdomwyJQf8uI9A318iI9i26mzGQoJ_K5pAeOUyYIfzvZzD5DF8VDwDO5dwdgtzthgr7bGGGi02qIEk06vnKlOve0Hmq-wZPar_r7-O6U12tQciCOi0raSH6YyiwVZBJ-7KHDBnKmXg-o05dRyWF4yV2nFQ-FgMYvmAV68wE_qpuZpq7F9CyPz=w366-h52\" width=\"366\" /></a></div></div><a href=\"https://huggingface.co/blog/gemma3\">Welcome Gemma 3: Google's all new multimodal, multilingual, long context open LLM</a><br /><p></p>\n<p>Gemma 3는 140개 이상의 언어를 지원하여 전 세계 다양한 언어 사용자를 대상으로 하는 AI 애플리케이션 개발에 매우 유리하다. 사용자는 자신의 모국어로 Gemma 3와 상호작용할 수 있으며, 다국어 기반의 텍스트 분석 및 생성 작업도 효율적으로 수행할 수 있다.</p>\n<p>이 모델은 다양한 작업 수행 능력을 갖추고 있다. 질문 답변, 텍스트 요약, 논리적 추론, 창의적인 텍스트 형식 생성(시, 스크립트, 코드, 마케팅 문구, 이메일 초안 등), 이미지 데이터 분석 및 추출 등 광범위한 자연어 처리 및 컴퓨터 비전 관련 작업을 수행할 수 있다. 또한, 함수 호출 및 구조화된 출력을 지원하여 개발자들이 특정 작업을 자동화하고 에이전트 기반의 경험을 구축하는 데 도움을 준다.</p>\n<p>Gemma 3는 다양한 도구 및 프레임워크와 원활하게 통합된다. Hugging Face Transformers, Ollama, JAX, Keras, PyTorch, Google AI Edge, UnSloth, vLLM, Gemma.cpp 등 다양한 개발 도구 및 프레임워크와 호환되어 개발자들이 자신이 익숙한 환경에서 Gemma 3를 쉽게 활용하고 실험할 수 있다.</p>\n<p>이 모델은 다양한 벤치마크 테스트에서 동급 모델 대비 최첨단 성능을 입증했다. 특히, Chatbot Arena Elo Score에서 1338점을 기록하며, 여러 오픈 소스 및 상용 모델보다 높은 성능을 보였다.&nbsp;</p>\n<p>Gemma 3는 오픈 모델로, 개방형 가중치를 제공하여 사용자가 자유롭게 조정하고 배포할 수 있다. Kaggle과 Hugging Face에서 다운로드 가능하며, Creative Commons 및 Apache 2.0 라이선스를 따름으로써, 개발자와 연구자에게 VLM 기술에 대한 접근성을 높여준다.</p></div></div><div style=\"text-align: left;\"><b>개발 환경</b></div><div style=\"text-align: left;\">개발 환경은 다음과 같다. 미리 설치, 가입한다.</div><div style=\"text-align: left;\"><ul style=\"text-align: left;\"><li>ollama:&nbsp;&nbsp;<a href=\"https://ollama.com/download/windows\">https://ollama.com/download/windows</a></li><li>gemma3:&nbsp;<a href=\"https://ollama.com/search\">https://ollama.com/search</a></li><li>serper 서비스: 가입.&nbsp;<a href=\"https://serper.dev/dashboard\">https://serper.dev/dashboard</a>&nbsp;</li></ul><div>설치되어 있다면, 다음 명령을 터미널에서 실행한다.</div><div>ollama pull gemma3:4b</div><div><div class=\"separator\" style=\"clear: both; text-align: center;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEjJWYeEDOBMGd2ouDsvdKZbcIk9QLtE1JSQkxw3HrENY7bnIlryDZF9qzmydQGPnSdrwkidraUDWQgVHChYg_JpjTamA5nwb5GBkN-PL-HHM4SEAHOUuCdLvFjwvsNdGEXC3GCmgbRjaOqa35TKcJR96vIQXndCqxH1Sl82v2tEBl7MZE37pN1LzX3IeLzl\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"492\" data-original-width=\"1033\" height=\"202\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEjJWYeEDOBMGd2ouDsvdKZbcIk9QLtE1JSQkxw3HrENY7bnIlryDZF9qzmydQGPnSdrwkidraUDWQgVHChYg_JpjTamA5nwb5GBkN-PL-HHM4SEAHOUuCdLvFjwvsNdGEXC3GCmgbRjaOqa35TKcJR96vIQXndCqxH1Sl82v2tEBl7MZE37pN1LzX3IeLzl=w426-h202\" width=\"426\" /></a></div></div></div><div class=\"separator\" style=\"clear: both; text-align: center;\">gemma3:4b GPU VRAM 소모량</div><div class=\"separator\" style=\"clear: both; text-align: center;\"><br /></div><div>이제 다음과 같이 모델을 실행해 볼 수 있다.&nbsp;</div><div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEg6oGTJTrEQBonIcLw6f6ZTXaeXWwkChJQS5GETDQnknW2wjm4nNd7UmQd-sVUeFWWv3wEtWmf4xRJ8GiqsTjh1f3CpUBnMQASKMTH8tXSg7IBO3hA5Ae4COdAcFwNDphahO6XYRMliU5PX-HwPJX6oVv013KUtEhd63OuLyO5vQ73ofikeSIYvLQpeM3u0\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"283\" data-original-width=\"985\" height=\"144\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEg6oGTJTrEQBonIcLw6f6ZTXaeXWwkChJQS5GETDQnknW2wjm4nNd7UmQd-sVUeFWWv3wEtWmf4xRJ8GiqsTjh1f3CpUBnMQASKMTH8tXSg7IBO3hA5Ae4COdAcFwNDphahO6XYRMliU5PX-HwPJX6oVv013KUtEhd63OuLyO5vQ73ofikeSIYvLQpeM3u0=w502-h144\" width=\"502\" /></a></div><br /></div></div><div style=\"text-align: left;\">참고로, GPU VRAM 등을 고려해 더 성능이 좋은 파라메터수 많은 대형 모델을 사용할 수도 있다.</div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEhk2dkbUiDZaUpH_6UhADSOesbuit96fmH_k5aERSusYLvXFmMh2yzGhGqsl7myn6hP-0ImfrIHyyJ5uecoxN-5jlD0sm56__QQ6QBjouR_xyzeqBihDN36HAECepK0jkhcZFCisBG9UK7_VdzjlymXUOtzm42PmwcXcFOM1FXw45Cj0xyJZaQaRPFeesvd\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"639\" data-original-width=\"921\" height=\"222\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEhk2dkbUiDZaUpH_6UhADSOesbuit96fmH_k5aERSusYLvXFmMh2yzGhGqsl7myn6hP-0ImfrIHyyJ5uecoxN-5jlD0sm56__QQ6QBjouR_xyzeqBihDN36HAECepK0jkhcZFCisBG9UK7_VdzjlymXUOtzm42PmwcXcFOM1FXw45Cj0xyJZaQaRPFeesvd\" width=\"320\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\">gemma3 지원 모델들</div><br /></div><div style=\"text-align: left;\"><b>처리 프로세스</b></div><div style=\"text-align: left;\">이 실습 프로그램의 프로세스는 다음과 같다.</div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\"><div>Gradio 앱이 시작되면, 사용자의 입력이 발생하고 이 입력은 process_message 함수에 전달된다. 이 함수는 사용자의 메시지를 chat_history에 추가하여 대화 기록을 저장한다. 이후 모델에게 전달할 대화 문맥을 구성하기 위해 messages 리스트가 생성된다.</div><div><br /></div><div>그 다음 단계에서는 ollama.chat 함수를 통해 언어 모델에게 응답을 요청하게 되며, 이 응답 내에 함수 호출이 포함되어 있는지를 확인한다. 만약 응답에 함수 호출이 포함되어 있다면, 이를 parse_function_call 함수를 통해 파싱한다.</div><div><br /></div><div>파싱된 함수가 google_search라면, 모델이 검색을 원한다고 판단하여 검색 쿼리를 추출하고 검색 수행 예정임을 사용자에게 안내하는 메시지를 추가한다. 이후 실제로 google_search 함수를 실행하여 외부 검색을 수행한다.</div><div><br /></div><div>검색 결과는 다시 chat_history에 저장되며, 이 결과를 바탕으로 언어 모델에게 재질문을 하여 더 정확하고 완성된 응답을 유도한다. 모델이 생성한 최종 응답은 chat_history에 마지막으로 추가되고, 이 전체 대화 기록이 사용자에게 반환된다.</div><div><br /></div><div>이 구조는 사용자의 질의에 따라 외부 정보까지 능동적으로 검색하고 반영할 수 있는 LLM 기반 AI 에이전트의 대표적인 흐름을 보여준다.</div><div><br /></div><div>다음은 이 순서도를 보여준다.</div></div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEjw1M9HD8VrRqiAjyw8oBYJqP3MmQ4fO1BCVhj2VSNV4ZTdPrTxGxzSEga0DIfJlOPGI88Uqyt-DFIg5509brIjXLFLgfGGeYGxoOo4vpUaQsspTm1E8BgdE3t7l5oMtQ6-b2hhqQSYy1ql4qyp7JtgT_12EEM-1sF-PcD1lPOCLs3d3x0r_8O3_K0gFRjW\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"862\" data-original-width=\"310\" height=\"640\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEjw1M9HD8VrRqiAjyw8oBYJqP3MmQ4fO1BCVhj2VSNV4ZTdPrTxGxzSEga0DIfJlOPGI88Uqyt-DFIg5509brIjXLFLgfGGeYGxoOo4vpUaQsspTm1E8BgdE3t7l5oMtQ6-b2hhqQSYy1ql4qyp7JtgT_12EEM-1sF-PcD1lPOCLs3d3x0r_8O3_K0gFRjW=w229-h640\" width=\"229\" /></a></div><br /></div><div style=\"text-align: left;\"><b>구현하기</b></div><div style=\"text-align: left;\">터미널에서 다음 라이브러리를 설치한다.</div><div style=\"text-align: left;\">pip install langchain-core langchain-openai gradio ollama requests python-dotenv pydantic</div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\">새로운 파이썬 파일(<a href=\"https://github.com/mac999/AI_agent_simple_function_call/blob/main/ai_agent_func_call_gemma3.py\">코드 참고</a>)을 생성한 후, 우선, 필요한 라이브러리를 임포트한다.&nbsp;</div><div style=\"text-align: left;\"><div style=\"background-color: #1f1f1f; color: #cccccc; font-family: Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; line-height: 16px; white-space: pre;\"><div><span style=\"color: #c586c0;\">import</span> gradio <span style=\"color: #c586c0;\">as</span> gr</div><div><span style=\"color: #c586c0;\">import</span> ollama</div><div><span style=\"color: #c586c0;\">import</span> requests, json, os</div><div><span style=\"color: #c586c0;\">from</span> dotenv <span style=\"color: #c586c0;\">import</span> load_dotenv</div><div><span style=\"color: #c586c0;\">from</span> pydantic <span style=\"color: #c586c0;\">import</span> BaseModel, Field</div><div><span style=\"color: #c586c0;\">from</span> typing <span style=\"color: #c586c0;\">import</span> Optional, Dict, Any, List</div><br /><div>load_dotenv()</div><div>SERPER_API_KEY <span style=\"color: #d4d4d4;\">=</span> os.getenv(<span style=\"color: #ce9178;\">'SERPER_API_KEY'</span>)</div></div></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\">그리고, 사용하는 API 키를 가져온다. 이를 위해, 미리 .env 파일을 다음과 같이 만들어 놓고, 해당 API를 입력해 놓야야 한다.</div><div style=\"text-align: left;\"><div style=\"background-color: #1f1f1f; color: #cccccc; font-family: Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; line-height: 16px; white-space: pre;\"><div><span style=\"color: #6a9955;\"># .env</span></div><div><span style=\"color: #569cd6;\">SERPER_API_KEY</span>=&lt;YOUR API KEY&gt;</div><br /></div></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\">파라메터에서 검색 질의문, 함수호출명과 파라메터를 정의한다. 아울러, 질의 결과를 명확히 데이터항목으로 추출하기 위해서 검색 결과가 될 데이타항목(타이틀, 링크, 스닙펫) 형식을 pydantic의 basemodel을 이용해 명확히 정의한다. 그리고, LLM 호출 결과를 펑션콜이 가능한 형식으로 변환하기 위한 파싱 함수인 parse_function_call 을 정의한다.</div><div style=\"text-align: left;\"><div style=\"background-color: #1f1f1f; color: #cccccc; font-family: Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; line-height: 16px; white-space: pre;\"><div><span style=\"color: #569cd6;\">class</span> <span style=\"color: #4ec9b0;\">SearchParameters</span>(<span style=\"color: #4ec9b0;\">BaseModel</span>):</div><div>&nbsp; &nbsp; query: <span style=\"color: #4ec9b0;\">str</span> <span style=\"color: #d4d4d4;\">=</span> Field(..., <span style=\"color: #9cdcfe;\">description</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #ce9178;\">\"Search term to look up\"</span>)</div><br /><div><span style=\"color: #569cd6;\">class</span> <span style=\"color: #4ec9b0;\">FunctionCall</span>(<span style=\"color: #4ec9b0;\">BaseModel</span>):</div><div>&nbsp; &nbsp; name: <span style=\"color: #4ec9b0;\">str</span></div><div>&nbsp; &nbsp; parameters: Dict[<span style=\"color: #4ec9b0;\">str</span>, Any]</div><br /><div><span style=\"color: #569cd6;\">class</span> <span style=\"color: #4ec9b0;\">SearchResult</span>(<span style=\"color: #4ec9b0;\">BaseModel</span>):</div><div>&nbsp; &nbsp; title: <span style=\"color: #4ec9b0;\">str</span></div><div>&nbsp; &nbsp; link: <span style=\"color: #4ec9b0;\">str</span></div><div>&nbsp; &nbsp; snippet: <span style=\"color: #4ec9b0;\">str</span></div><br /><div>&nbsp; &nbsp; <span style=\"color: #569cd6;\">def</span> <span style=\"color: #dcdcaa;\">to_string</span>(<span style=\"color: #9cdcfe;\">self</span>) -&gt; <span style=\"color: #4ec9b0;\">str</span>:</div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #c586c0;\">return</span> <span style=\"color: #569cd6;\">f</span><span style=\"color: #ce9178;\">\"Title: </span><span style=\"color: #569cd6;\">{self</span>.title<span style=\"color: #569cd6;\">}</span><span style=\"color: #d7ba7d;\">\\n</span><span style=\"color: #ce9178;\">Link: </span><span style=\"color: #569cd6;\">{self</span>.link<span style=\"color: #569cd6;\">}</span><span style=\"color: #d7ba7d;\">\\n</span><span style=\"color: #ce9178;\">Snippet: </span><span style=\"color: #569cd6;\">{self</span>.snippet<span style=\"color: #569cd6;\">}</span><span style=\"color: #ce9178;\">\"</span></div><br /><div><span style=\"color: #569cd6;\">def</span> <span style=\"color: #dcdcaa;\">google_search</span>(<span style=\"color: #9cdcfe;\">query</span>: <span style=\"color: #4ec9b0;\">str</span>) -&gt; SearchResult:</div><div>&nbsp; &nbsp; <span style=\"color: #ce9178;\">\"\"\"Perform a Google search using Serper.dev API\"\"\"</span></div><div>&nbsp; &nbsp; <span style=\"color: #c586c0;\">try</span>:</div><div>&nbsp; &nbsp; &nbsp; &nbsp; url <span style=\"color: #d4d4d4;\">=</span> <span style=\"color: #ce9178;\">\"https://google.serper.dev/search\"</span></div><div>&nbsp; &nbsp; &nbsp; &nbsp; payload <span style=\"color: #d4d4d4;\">=</span> json.dumps({<span style=\"color: #ce9178;\">\"q\"</span>: query})</div><div>&nbsp; &nbsp; &nbsp; &nbsp; headers <span style=\"color: #d4d4d4;\">=</span> {</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #ce9178;\">'X-API-KEY'</span>: SERPER_API_KEY,</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #ce9178;\">'Content-Type'</span>: <span style=\"color: #ce9178;\">'application/json'</span></div><div>&nbsp; &nbsp; &nbsp; &nbsp; }</div><div>&nbsp; &nbsp; &nbsp; &nbsp; </div><div>&nbsp; &nbsp; &nbsp; &nbsp; response <span style=\"color: #d4d4d4;\">=</span> requests.post(url, <span style=\"color: #9cdcfe;\">headers</span><span style=\"color: #d4d4d4;\">=</span>headers, <span style=\"color: #9cdcfe;\">data</span><span style=\"color: #d4d4d4;\">=</span>payload)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; response.raise_for_status() &nbsp;<span style=\"color: #6a9955;\"># 잘못된 상태 코드에 대해 예외 발생</span></div><div>&nbsp; &nbsp; &nbsp; &nbsp; </div><div>&nbsp; &nbsp; &nbsp; &nbsp; results <span style=\"color: #d4d4d4;\">=</span> response.json()</div><div>&nbsp; &nbsp; &nbsp; &nbsp; </div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #c586c0;\">if</span> <span style=\"color: #569cd6;\">not</span> results.get(<span style=\"color: #ce9178;\">'organic'</span>):</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #c586c0;\">raise</span> <span style=\"color: #4ec9b0;\">ValueError</span>(<span style=\"color: #ce9178;\">\"No search results found.\"</span>)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </div><div>&nbsp; &nbsp; &nbsp; &nbsp; first_result <span style=\"color: #d4d4d4;\">=</span> results[<span style=\"color: #ce9178;\">'organic'</span>][<span style=\"color: #b5cea8;\">0</span>]</div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #c586c0;\">return</span> SearchResult(</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #9cdcfe;\">title</span><span style=\"color: #d4d4d4;\">=</span>first_result.get(<span style=\"color: #ce9178;\">'title'</span>, <span style=\"color: #ce9178;\">'No title'</span>),</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #9cdcfe;\">link</span><span style=\"color: #d4d4d4;\">=</span>first_result.get(<span style=\"color: #ce9178;\">'link'</span>, <span style=\"color: #ce9178;\">'No link'</span>),</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #9cdcfe;\">snippet</span><span style=\"color: #d4d4d4;\">=</span>first_result.get(<span style=\"color: #ce9178;\">'snippet'</span>, <span style=\"color: #ce9178;\">'No snippet available.'</span>)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; )</div><div>&nbsp; &nbsp; <span style=\"color: #c586c0;\">except</span> <span style=\"color: #4ec9b0;\">Exception</span> <span style=\"color: #c586c0;\">as</span> e:</div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #dcdcaa;\">print</span>(<span style=\"color: #569cd6;\">f</span><span style=\"color: #ce9178;\">\"Search error: </span><span style=\"color: #569cd6;\">{</span><span style=\"color: #4ec9b0;\">str</span>(e)<span style=\"color: #569cd6;\">}</span><span style=\"color: #ce9178;\">\"</span>)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #c586c0;\">raise</span></div><br /><div><span style=\"color: #569cd6;\">def</span> <span style=\"color: #dcdcaa;\">parse_function_call</span>(<span style=\"color: #9cdcfe;\">response</span>: <span style=\"color: #4ec9b0;\">str</span>) -&gt; Optional[FunctionCall]:</div><div>&nbsp; &nbsp; <span style=\"color: #ce9178;\">\"\"\"Parse the model's response to extract function calls\"\"\"</span></div><div>&nbsp; &nbsp; <span style=\"color: #c586c0;\">try</span>:</div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #6a9955;\"># Clean the response and find JSON structure</span></div><div>&nbsp; &nbsp; &nbsp; &nbsp; response <span style=\"color: #d4d4d4;\">=</span> response.strip()</div><div>&nbsp; &nbsp; &nbsp; &nbsp; start_idx <span style=\"color: #d4d4d4;\">=</span> response.find(<span style=\"color: #ce9178;\">'{'</span>)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; end_idx <span style=\"color: #d4d4d4;\">=</span> response.rfind(<span style=\"color: #ce9178;\">'}'</span>) <span style=\"color: #d4d4d4;\">+</span> <span style=\"color: #b5cea8;\">1</span></div><div>&nbsp; &nbsp; &nbsp; &nbsp; </div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #c586c0;\">if</span> start_idx <span style=\"color: #d4d4d4;\">==</span> <span style=\"color: #d4d4d4;\">-</span><span style=\"color: #b5cea8;\">1</span> <span style=\"color: #569cd6;\">or</span> end_idx <span style=\"color: #d4d4d4;\">==</span> <span style=\"color: #b5cea8;\">0</span>:</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #c586c0;\">return</span> <span style=\"color: #569cd6;\">None</span></div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </div><div>&nbsp; &nbsp; &nbsp; &nbsp; json_str <span style=\"color: #d4d4d4;\">=</span> response[start_idx:end_idx]</div><div>&nbsp; &nbsp; &nbsp; &nbsp; data <span style=\"color: #d4d4d4;\">=</span> json.loads(json_str)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #c586c0;\">return</span> FunctionCall(<span style=\"color: #d4d4d4;\">**</span>data)</div><div>&nbsp; &nbsp; <span style=\"color: #c586c0;\">except</span> <span style=\"color: #4ec9b0;\">Exception</span> <span style=\"color: #c586c0;\">as</span> e:</div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #dcdcaa;\">print</span>(<span style=\"color: #569cd6;\">f</span><span style=\"color: #ce9178;\">\"Error parsing function call: </span><span style=\"color: #569cd6;\">{</span><span style=\"color: #4ec9b0;\">str</span>(e)<span style=\"color: #569cd6;\">}</span><span style=\"color: #ce9178;\">\"</span>)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #c586c0;\">return</span> <span style=\"color: #569cd6;\">None</span></div><br /></div></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\">gemma에 지시할 시스템 프롬프트 명령을 정의한다. prompt_system_message는 이 챗봇이 어떻게 동작해야 하는지, 그리고 어떤 기준으로 답변을 해야 하는지에 대한 지침을 제공하는 역할을 한다. 이 메시지는 챗봇이 2024년까지의 정보를 학습한 AI 어시스턴트임을 명확히 하고, 사용자의 질문에 대해 가능한 경우에는 바로 답변을 하되, 최신 정보나 불확실한 내용, 시의성이 있는 질문에 대해서는 반드시 펑션콜을 통해 검색 기능을 활용해야 함을 명시한다. 이전 대화 내용이 함께 입력으로 주어지기 때문에, 챗봇은 이 대화 맥락을 참고하여 일관성 있고 상황에 맞는 답변을 해야 한다고 안내한다. 참고로, 준수해야 할 gemma3의 function call 형식은 다음과 같다.&nbsp;</div><div style=\"text-align: left;\"><ul style=\"text-align: left;\"><li><a href=\"https://github.com/philschmid/gemini-samples/blob/main/examples/gemma-function-calling.ipynb\">gemini-samples/examples/gemma-function-calling.ipynb at main · philschmid/gemini-samples</a></li></ul></div><div>검색이 필요한 상황과 그렇지 않은 상황을 구체적으로 구분하여, 챗봇이 임의로 정보를 추정하거나 추가하지 않고, 검색 결과에 기반한 사실만을 간결하게 전달하도록 유도한다. 검색이 필요한 경우에는 정해진 JSON 형식으로만 응답하도록 하여, 시스템이 함수 호출 방식으로 검색을 처리할 수 있게 한다.</div><div><div style=\"background-color: #1f1f1f; color: #cccccc; font-family: Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; line-height: 16px; white-space: pre;\"><div><span style=\"color: #6a9955;\"># 프롬프트 시스템 메세지 정의</span></div><div>prompt_system_message <span style=\"color: #d4d4d4;\">=</span> <span style=\"color: #ce9178;\">\"\"\"You are an AI assistant with training data up to 2024. Answer questions directly when possible, and use search when necessary.</span></div><br /><div><span style=\"color: #ce9178;\">You will receive previous conversation messages as part of the input. Use these prior messages to maintain context and provide coherent, context-aware answers.</span></div><br /><div><span style=\"color: #ce9178;\">DECISION PROCESS:</span></div><div><span style=\"color: #ce9178;\">1. For historical events before 2024:</span></div><div><span style=\"color: #ce9178;\">&nbsp; &nbsp;- Answer directly from your training data.</span></div><div><span style=\"color: #ce9178;\">2. For events in 2024:</span></div><div><span style=\"color: #ce9178;\">&nbsp; &nbsp;- If you are certain, answer directly.</span></div><div><span style=\"color: #ce9178;\">&nbsp; &nbsp;- If you are unsure, use search.</span></div><div><span style=\"color: #ce9178;\">3. For events after 2024 or current/recent information:</span></div><div><span style=\"color: #ce9178;\">&nbsp; &nbsp;- Always use search.</span></div><div><span style=\"color: #ce9178;\">4. For timeless information (scientific facts, concepts, etc.):</span></div><div><span style=\"color: #ce9178;\">&nbsp; &nbsp;- Answer directly from your training data.</span></div><br /><div><span style=\"color: #ce9178;\">ALWAYS USE SEARCH if the question:</span></div><div><span style=\"color: #ce9178;\">- Contains words like \"current\", \"latest\", \"now\", \"present\", \"today\", \"recent\"</span></div><div><span style=\"color: #ce9178;\">- Asks about someone in a changing position (champion, president, CEO, etc.)</span></div><div><span style=\"color: #ce9178;\">- Requests information that might have changed since 2024</span></div><div><span style=\"color: #ce9178;\">- Is time-sensitive and does not specify a time period</span></div><br /><div><span style=\"color: #ce9178;\">FUNCTION CALL FORMAT:</span></div><div><span style=\"color: #ce9178;\">When you need to search, respond WITH ONLY THE JSON OBJECT, no other text, no backticks:</span></div><div><span style=\"color: #ce9178;\">{</span></div><div><span style=\"color: #ce9178;\">&nbsp; &nbsp; \"name\": \"google_search\",</span></div><div><span style=\"color: #ce9178;\">&nbsp; &nbsp; \"parameters\": {</span></div><div><span style=\"color: #ce9178;\">&nbsp; &nbsp; &nbsp; &nbsp; \"query\": \"your search query\"</span></div><div><span style=\"color: #ce9178;\">&nbsp; &nbsp; }</span></div><div><span style=\"color: #ce9178;\">}</span></div><br /><div><span style=\"color: #ce9178;\">SEARCH FUNCTION:</span></div><div><span style=\"color: #ce9178;\">{</span></div><div><span style=\"color: #ce9178;\">&nbsp; &nbsp; \"name\": \"google_search\",</span></div><div><span style=\"color: #ce9178;\">&nbsp; &nbsp; \"description\": \"Search for real-time information\",</span></div><div><span style=\"color: #ce9178;\">&nbsp; &nbsp; \"parameters\": {</span></div><div><span style=\"color: #ce9178;\">&nbsp; &nbsp; &nbsp; &nbsp; \"type\": \"object\",</span></div><div><span style=\"color: #ce9178;\">&nbsp; &nbsp; &nbsp; &nbsp; \"properties\": {</span></div><div><span style=\"color: #ce9178;\">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \"query\": {</span></div><div><span style=\"color: #ce9178;\">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \"type\": \"string\",</span></div><div><span style=\"color: #ce9178;\">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \"description\": \"Search term\"</span></div><div><span style=\"color: #ce9178;\">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }</span></div><div><span style=\"color: #ce9178;\">&nbsp; &nbsp; &nbsp; &nbsp; },</span></div><div><span style=\"color: #ce9178;\">&nbsp; &nbsp; &nbsp; &nbsp; \"required\": [\"query\"]</span></div><div><span style=\"color: #ce9178;\">&nbsp; &nbsp; }</span></div><div><span style=\"color: #ce9178;\">}</span></div><br /><div><span style=\"color: #ce9178;\">WHEN ANSWERING BASED ON SEARCH RESULTS:</span></div><div><span style=\"color: #ce9178;\">- Use ONLY facts found in the search results below.</span></div><div><span style=\"color: #ce9178;\">- Do NOT add any dates or information not present in the search results.</span></div><div><span style=\"color: #ce9178;\">- Do NOT make assumptions about timing or events.</span></div><div><span style=\"color: #ce9178;\">- Quote dates exactly as they appear in the results.</span></div><div><span style=\"color: #ce9178;\">- Keep your answer concise and factual.</span></div><div><span style=\"color: #ce9178;\">\"\"\"</span></div><br /></div></div><div><br /></div><div>gemma에 전달할 메시지는 프롬프트 지시문, 사용자 질문을 포함한 이전 채팅 이력 메시지 등을 모두 포함한다. 이를 ollama LLM 에 전달할 수 있는 형식으로 변환하는 함수를 다음과 같이 준비한다.&nbsp;</div><div><div style=\"background-color: #1f1f1f; color: #cccccc; font-family: Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; line-height: 16px; white-space: pre;\"><div><span style=\"color: #6a9955;\"># 메시지 리스트를 생성하는 함수</span></div><div><span style=\"color: #569cd6;\">def</span> <span style=\"color: #dcdcaa;\">filter_memory</span>(<span style=\"color: #9cdcfe;\">memory</span>):</div><div>&nbsp; &nbsp; <span style=\"color: #ce9178;\">\"\"\"assistant의 검색 안내 메시지를 memory에서 제외\"\"\"</span></div><div>&nbsp; &nbsp; <span style=\"color: #c586c0;\">return</span> [</div><div>&nbsp; &nbsp; &nbsp; &nbsp; msg <span style=\"color: #c586c0;\">for</span> msg <span style=\"color: #c586c0;\">in</span> memory</div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #c586c0;\">if</span> <span style=\"color: #569cd6;\">not</span> (</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; msg[<span style=\"color: #ce9178;\">\"role\"</span>] <span style=\"color: #d4d4d4;\">==</span> <span style=\"color: #ce9178;\">\"assistant\"</span> <span style=\"color: #569cd6;\">and</span> (</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; msg[<span style=\"color: #ce9178;\">\"content\"</span>].startswith(<span style=\"color: #ce9178;\">\"Searching for:\"</span>) <span style=\"color: #569cd6;\">or</span></div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; msg[<span style=\"color: #ce9178;\">\"content\"</span>].startswith(<span style=\"color: #ce9178;\">\"Searched for:\"</span>)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; )</div><div>&nbsp; &nbsp; &nbsp; &nbsp; )</div><div>&nbsp; &nbsp; ]</div><br /><div><span style=\"color: #569cd6;\">def</span> <span style=\"color: #dcdcaa;\">build_messages</span>(<span style=\"color: #9cdcfe;\">chat_history</span>, <span style=\"color: #9cdcfe;\">user_input</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #569cd6;\">None</span>, <span style=\"color: #9cdcfe;\">prompt_system_message</span><span style=\"color: #d4d4d4;\">=</span>prompt_system_message, <span style=\"color: #9cdcfe;\">N</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #b5cea8;\">6</span>, <span style=\"color: #9cdcfe;\">search_result</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #569cd6;\">None</span>):</div><div>&nbsp; &nbsp; <span style=\"color: #ce9178;\">\"\"\"</span></div><div><span style=\"color: #ce9178;\">&nbsp; &nbsp; 최근 N개 메시지와 system 메시지를 합쳐 messages 리스트를 만듭니다.</span></div><div><span style=\"color: #ce9178;\">&nbsp; &nbsp; search_result가 있으면, user_input 대신 검색 결과 기반 프롬프트를 추가합니다.</span></div><div><span style=\"color: #ce9178;\">&nbsp; &nbsp; \"\"\"</span></div><div>&nbsp; &nbsp; memory <span style=\"color: #d4d4d4;\">=</span> chat_history[<span style=\"color: #d4d4d4;\">-</span>N:] <span style=\"color: #c586c0;\">if</span> <span style=\"color: #dcdcaa;\">len</span>(chat_history) <span style=\"color: #d4d4d4;\">&gt;</span> N <span style=\"color: #c586c0;\">else</span> chat_history[:<span style=\"color: #d4d4d4;\">-</span><span style=\"color: #b5cea8;\">1</span>]</div><div>&nbsp; &nbsp; filtered_memory <span style=\"color: #d4d4d4;\">=</span> filter_memory(memory)</div><div>&nbsp; &nbsp; messages <span style=\"color: #d4d4d4;\">=</span> [{<span style=\"color: #ce9178;\">\"role\"</span>: <span style=\"color: #ce9178;\">\"system\"</span>, <span style=\"color: #ce9178;\">\"content\"</span>: prompt_system_message}] <span style=\"color: #d4d4d4;\">+</span> filtered_memory</div><div>&nbsp; &nbsp; <span style=\"color: #c586c0;\">if</span> search_result <span style=\"color: #569cd6;\">is</span> <span style=\"color: #569cd6;\">not</span> <span style=\"color: #569cd6;\">None</span>:</div><div>&nbsp; &nbsp; &nbsp; &nbsp; messages.append({</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #ce9178;\">\"role\"</span>: <span style=\"color: #ce9178;\">\"user\"</span>,</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #ce9178;\">\"content\"</span>: (</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #ce9178;\">\"Refer to the following search result and provide a concise, factual answer based only on this information:</span><span style=\"color: #d7ba7d;\">\\n</span><span style=\"color: #ce9178;\">\"</span></div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #569cd6;\">f</span><span style=\"color: #ce9178;\">\"</span><span style=\"color: #569cd6;\">{</span>search_result.to_string()<span style=\"color: #569cd6;\">}</span><span style=\"color: #ce9178;\">\"</span></div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; )</div><div>&nbsp; &nbsp; &nbsp; &nbsp; })</div><div>&nbsp; &nbsp; <span style=\"color: #c586c0;\">elif</span> user_input <span style=\"color: #569cd6;\">is</span> <span style=\"color: #569cd6;\">not</span> <span style=\"color: #569cd6;\">None</span>:</div><div>&nbsp; &nbsp; &nbsp; &nbsp; messages.append({<span style=\"color: #ce9178;\">\"role\"</span>: <span style=\"color: #ce9178;\">\"user\"</span>, <span style=\"color: #ce9178;\">\"content\"</span>: user_input})</div><div>&nbsp; &nbsp; <span style=\"color: #c586c0;\">return</span> messages</div><br /></div></div><div><br /></div><div style=\"text-align: left;\"><div>이제 process_message 함수를 구현한다. 이 함수는 사용자의 입력과 기존 채팅 기록을 받아 AI 모델과의 대화 흐름을 관리하는 역할을 한다.</div><div><br /></div><div>먼저 사용자의 메시지를 채팅 기록에 추가하고, 이전 대화 내용(메모리)을 추출하여 시스템 메시지와 함께 모델에 전달할 메시지 목록을 구성한다. 이 메시지 목록을 Ollama 모델에 전달하여 응답을 받는다. 모델의 응답이 함수 호출(JSON) 형태라면, 그 내용을 파싱하여 검색이 필요한 경우 검색 쿼리를 추출한다.</div><div><br /></div><div>검색이 필요하다고 판단되면, 검색 중임을 알리는 메시지를 채팅 기록에 추가하고, 실제로 검색을 수행한다. 검색 결과를 다시 채팅 기록에 반영한 뒤, 이 결과를 포함한 새로운 메시지 목록을 만들어 모델에 전달하여 최종 답변을 받는다. 최종적으로 받은 답변 역시 채팅 기록에 추가한다.</div><div><br /></div><div>검색이 필요하지 않은 경우에는 모델의 응답을 바로 채팅 기록에 추가한다. 이 과정에서 각 단계별로 최신 채팅 기록을 반환하여, 사용자 인터페이스가 실시간으로 대화 상태를 갱신할 수 있도록 한다.</div><div>함수 실행 중 오류가 발생하면, 오류 메시지를 채팅 기록에 추가하여 사용자에게 알린다.</div><div><div style=\"background-color: #1f1f1f; color: #cccccc; font-family: Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; line-height: 16px; white-space: pre;\"><div><span style=\"color: #6a9955;\"># Model name</span></div><div>MODEL_NAME <span style=\"color: #d4d4d4;\">=</span> <span style=\"color: #ce9178;\">\"gemma3\"</span></div><br /><div><span style=\"color: #569cd6;\">def</span> <span style=\"color: #dcdcaa;\">process_message</span>(<span style=\"color: #9cdcfe;\">user_input</span>, <span style=\"color: #9cdcfe;\">chat_history</span>):</div><div>&nbsp; &nbsp; <span style=\"color: #ce9178;\">\"\"\"Process user message and update chat history\"\"\"</span></div><div>&nbsp; &nbsp; <span style=\"color: #c586c0;\">try</span>:</div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #6a9955;\"># 사용자 메시지를 기록에 추가</span></div><div>&nbsp; &nbsp; &nbsp; &nbsp; chat_history.append({<span style=\"color: #ce9178;\">\"role\"</span>: <span style=\"color: #ce9178;\">\"user\"</span>, <span style=\"color: #ce9178;\">\"content\"</span>: user_input})</div><div>&nbsp; &nbsp; &nbsp; &nbsp; search_info <span style=\"color: #d4d4d4;\">=</span> <span style=\"color: #569cd6;\">None</span></div><br /><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #6a9955;\"># 최근 N개 메시지만 memory에 포함 (예: 최근 6개)</span></div><div>&nbsp; &nbsp; &nbsp; &nbsp; N <span style=\"color: #d4d4d4;\">=</span> <span style=\"color: #b5cea8;\">6</span></div><div>&nbsp; &nbsp; &nbsp; &nbsp; messages <span style=\"color: #d4d4d4;\">=</span> build_messages(chat_history, <span style=\"color: #9cdcfe;\">user_input</span><span style=\"color: #d4d4d4;\">=</span>user_input, <span style=\"color: #9cdcfe;\">N</span><span style=\"color: #d4d4d4;\">=</span>N)</div><br /><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #6a9955;\"># 모델로부터 응답 받기</span></div><div>&nbsp; &nbsp; &nbsp; &nbsp; response <span style=\"color: #d4d4d4;\">=</span> ollama.chat(</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #9cdcfe;\">model</span><span style=\"color: #d4d4d4;\">=</span>MODEL_NAME,</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #9cdcfe;\">messages</span><span style=\"color: #d4d4d4;\">=</span>messages &nbsp; &nbsp; &nbsp; </div><div>&nbsp; &nbsp; &nbsp; &nbsp; )</div><div>&nbsp; &nbsp; &nbsp; &nbsp; </div><div>&nbsp; &nbsp; &nbsp; &nbsp; model_response <span style=\"color: #d4d4d4;\">=</span> response[<span style=\"color: #ce9178;\">'message'</span>][<span style=\"color: #ce9178;\">'content'</span>]</div><div>&nbsp; &nbsp; &nbsp; &nbsp; </div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #6a9955;\"># 함수 호출로 응답을 파싱 시도</span></div><div>&nbsp; &nbsp; &nbsp; &nbsp; function_call <span style=\"color: #d4d4d4;\">=</span> parse_function_call(model_response)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; </div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #c586c0;\">if</span> function_call <span style=\"color: #569cd6;\">and</span> function_call.name <span style=\"color: #d4d4d4;\">==</span> <span style=\"color: #ce9178;\">\"google_search\"</span>:</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #6a9955;\"># 검색 파라미터 검증</span></div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; search_params <span style=\"color: #d4d4d4;\">=</span> SearchParameters(<span style=\"color: #d4d4d4;\">**</span>function_call.parameters)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; search_query <span style=\"color: #d4d4d4;\">=</span> search_params.query</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #6a9955;\"># 검색 정보 기록에 추가</span></div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; search_info <span style=\"color: #d4d4d4;\">=</span> <span style=\"color: #569cd6;\">f</span><span style=\"color: #ce9178;\">\"Searching for: </span><span style=\"color: #569cd6;\">{</span>search_query<span style=\"color: #569cd6;\">}</span><span style=\"color: #ce9178;\">\"</span></div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; chat_history.append({<span style=\"color: #ce9178;\">\"role\"</span>: <span style=\"color: #ce9178;\">\"assistant\"</span>, <span style=\"color: #ce9178;\">\"content\"</span>: search_info})</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #c586c0;\">yield</span> chat_history</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #6a9955;\"># 검색 실행</span></div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; search_result <span style=\"color: #d4d4d4;\">=</span> google_search(search_query)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #6a9955;\"># 검색 결과로 정보 업데이트</span></div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; search_info <span style=\"color: #d4d4d4;\">=</span> <span style=\"color: #569cd6;\">f</span><span style=\"color: #ce9178;\">\"Searched for: </span><span style=\"color: #569cd6;\">{</span>search_query<span style=\"color: #569cd6;\">}</span><span style=\"color: #d7ba7d;\">\\n\\n</span><span style=\"color: #ce9178;\">Result:</span><span style=\"color: #d7ba7d;\">\\n</span><span style=\"color: #569cd6;\">{</span>search_result.to_string()<span style=\"color: #569cd6;\">}</span><span style=\"color: #ce9178;\">\"</span></div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; chat_history[<span style=\"color: #d4d4d4;\">-</span><span style=\"color: #b5cea8;\">1</span>] <span style=\"color: #d4d4d4;\">=</span> {<span style=\"color: #ce9178;\">\"role\"</span>: <span style=\"color: #ce9178;\">\"assistant\"</span>, <span style=\"color: #ce9178;\">\"content\"</span>: search_info}</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #c586c0;\">yield</span> chat_history</div><br /><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #6a9955;\"># 검색 결과 기반 메시지 생성</span></div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; messages <span style=\"color: #d4d4d4;\">=</span> build_messages(chat_history, <span style=\"color: #9cdcfe;\">N</span><span style=\"color: #d4d4d4;\">=</span>N, <span style=\"color: #9cdcfe;\">search_result</span><span style=\"color: #d4d4d4;\">=</span>search_result)</div><div>&nbsp; &nbsp; &nbsp; </div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #6a9955;\"># 검색 결과를 포함해 모델로부터 최종 응답 받기</span></div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; final_response <span style=\"color: #d4d4d4;\">=</span> ollama.chat(</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #9cdcfe;\">model</span><span style=\"color: #d4d4d4;\">=</span>MODEL_NAME,</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #9cdcfe;\">messages</span><span style=\"color: #d4d4d4;\">=</span>messages</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; )</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; assistant_response <span style=\"color: #d4d4d4;\">=</span> final_response[<span style=\"color: #ce9178;\">'message'</span>][<span style=\"color: #ce9178;\">'content'</span>]</div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #c586c0;\">else</span>:</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #6a9955;\"># 함수 호출이 없으면 직접 응답 반환</span></div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; assistant_response <span style=\"color: #d4d4d4;\">=</span> model_response</div><div>&nbsp; &nbsp; &nbsp; &nbsp; </div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #6a9955;\"># 최종 응답을 기록에 업데이트</span></div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #c586c0;\">if</span> search_info:</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; chat_history.append({<span style=\"color: #ce9178;\">\"role\"</span>: <span style=\"color: #ce9178;\">\"assistant\"</span>, <span style=\"color: #ce9178;\">\"content\"</span>: <span style=\"color: #569cd6;\">f</span><span style=\"color: #ce9178;\">\" Response:</span><span style=\"color: #d7ba7d;\">\\n</span><span style=\"color: #569cd6;\">{</span>assistant_response<span style=\"color: #569cd6;\">}</span><span style=\"color: #ce9178;\">\"</span>})</div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #c586c0;\">else</span>:</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; chat_history.append({<span style=\"color: #ce9178;\">\"role\"</span>: <span style=\"color: #ce9178;\">\"assistant\"</span>, <span style=\"color: #ce9178;\">\"content\"</span>: assistant_response})</div><div>&nbsp; &nbsp; &nbsp; &nbsp; </div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #c586c0;\">yield</span> chat_history</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </div><div>&nbsp; &nbsp; <span style=\"color: #c586c0;\">except</span> <span style=\"color: #4ec9b0;\">Exception</span> <span style=\"color: #c586c0;\">as</span> e:</div><div>&nbsp; &nbsp; &nbsp; &nbsp; error_msg <span style=\"color: #d4d4d4;\">=</span> <span style=\"color: #569cd6;\">f</span><span style=\"color: #ce9178;\">\"An error occurred: </span><span style=\"color: #569cd6;\">{</span><span style=\"color: #4ec9b0;\">str</span>(e)<span style=\"color: #569cd6;\">}</span><span style=\"color: #ce9178;\">\"</span></div><div>&nbsp; &nbsp; &nbsp; &nbsp; chat_history.append({<span style=\"color: #ce9178;\">\"role\"</span>: <span style=\"color: #ce9178;\">\"assistant\"</span>, <span style=\"color: #ce9178;\">\"content\"</span>: error_msg})</div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #c586c0;\">yield</span> chat_history</div><br /></div></div><div><br /></div></div><div style=\"text-align: left;\">이제 Gradio UI 를 정의하고, 메인 엔트리에서 이 앱을 실행한다.</div><div style=\"text-align: left;\"><div style=\"background-color: #1f1f1f; color: #cccccc; font-family: Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; line-height: 16px; white-space: pre;\"><br /><div><span style=\"color: #6a9955;\"># Gradio 인터페이스 생성</span></div><div><span style=\"color: #c586c0;\">with</span> gr.Blocks(<span style=\"color: #9cdcfe;\">css</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #ce9178;\">\"footer </span><span style=\"color: #569cd6;\">{visibility: hidden}</span><span style=\"color: #ce9178;\">\"</span>) <span style=\"color: #c586c0;\">as</span> demo:</div><div>&nbsp; &nbsp; gr.Markdown(<span style=\"color: #ce9178;\">\"\"\"</span></div><div><span style=\"color: #ce9178;\">&nbsp; &nbsp; # Agent based on Gemma3 using Function Call</span></div><div><span style=\"color: #ce9178;\">&nbsp; &nbsp; </span></div><br /><div><span style=\"color: #ce9178;\">&nbsp; &nbsp; \"\"\"</span>)</div><div>&nbsp; &nbsp; </div><div>&nbsp; &nbsp; chatbot <span style=\"color: #d4d4d4;\">=</span> gr.Chatbot(</div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #9cdcfe;\">height</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #b5cea8;\">500</span>,</div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #9cdcfe;\">show_label</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #569cd6;\">False</span>,</div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #9cdcfe;\">avatar_images</span><span style=\"color: #d4d4d4;\">=</span>(<span style=\"color: #569cd6;\">None</span>, <span style=\"color: #ce9178;\">\"https://api.dicebear.com/9.x/identicon/svg?seed=Mason\"</span>),</div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #9cdcfe;\">type</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #ce9178;\">\"messages\"</span></div><div>&nbsp; &nbsp; )</div><div>&nbsp; &nbsp; </div><div>&nbsp; &nbsp; <span style=\"color: #c586c0;\">with</span> gr.Row():</div><div>&nbsp; &nbsp; &nbsp; &nbsp; msg <span style=\"color: #d4d4d4;\">=</span> gr.Textbox(</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #9cdcfe;\">scale</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #b5cea8;\">5</span>,</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #9cdcfe;\">show_label</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #569cd6;\">False</span>,</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #9cdcfe;\">placeholder</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #ce9178;\">\"Ask me anything...\"</span>,</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #9cdcfe;\">container</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #569cd6;\">False</span></div><div>&nbsp; &nbsp; &nbsp; &nbsp; )</div><div>&nbsp; &nbsp; &nbsp; &nbsp; submit_btn <span style=\"color: #d4d4d4;\">=</span> gr.Button(<span style=\"color: #ce9178;\">\"Send\"</span>, <span style=\"color: #9cdcfe;\">scale</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #b5cea8;\">1</span>)</div><div>&nbsp; &nbsp; </div><div>&nbsp; &nbsp; <span style=\"color: #c586c0;\">with</span> gr.Row():</div><div>&nbsp; &nbsp; &nbsp; &nbsp; clear_btn <span style=\"color: #d4d4d4;\">=</span> gr.Button(<span style=\"color: #ce9178;\">\"Clear Chat\"</span>)</div><div>&nbsp; &nbsp; </div><br /><div>&nbsp; &nbsp; <span style=\"color: #6a9955;\"># 이벤트 핸들러 설정</span></div><div>&nbsp; &nbsp; msg.submit(</div><div>&nbsp; &nbsp; &nbsp; &nbsp; process_message,</div><div>&nbsp; &nbsp; &nbsp; &nbsp; [msg, chatbot],</div><div>&nbsp; &nbsp; &nbsp; &nbsp; [chatbot],</div><div>&nbsp; &nbsp; )</div><div>&nbsp; &nbsp; </div><div>&nbsp; &nbsp; submit_btn.click(</div><div>&nbsp; &nbsp; &nbsp; &nbsp; process_message,</div><div>&nbsp; &nbsp; &nbsp; &nbsp; [msg, chatbot],</div><div>&nbsp; &nbsp; &nbsp; &nbsp; [chatbot],</div><div>&nbsp; &nbsp; )</div><div>&nbsp; &nbsp; </div><div>&nbsp; &nbsp; clear_btn.click(</div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #569cd6;\">lambda</span>: [],</div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #569cd6;\">None</span>,</div><div>&nbsp; &nbsp; &nbsp; &nbsp; chatbot,</div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #9cdcfe;\">queue</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #569cd6;\">False</span></div><div>&nbsp; &nbsp; )</div><div>&nbsp; &nbsp; </div><div>&nbsp; &nbsp; <span style=\"color: #6a9955;\"># 메시지 전송 후 텍스트박스 비우기</span></div><div>&nbsp; &nbsp; msg.submit(<span style=\"color: #569cd6;\">lambda</span>: <span style=\"color: #ce9178;\">\"\"</span>, <span style=\"color: #569cd6;\">None</span>, msg)</div><div>&nbsp; &nbsp; submit_btn.click(<span style=\"color: #569cd6;\">lambda</span>: <span style=\"color: #ce9178;\">\"\"</span>, <span style=\"color: #569cd6;\">None</span>, msg)</div><br /><div><span style=\"color: #c586c0;\">if</span> <span style=\"color: #9cdcfe;\">__name__</span> <span style=\"color: #d4d4d4;\">==</span> <span style=\"color: #ce9178;\">\"__main__\"</span>:</div><div>&nbsp; &nbsp; demo.launch(<span style=\"color: #9cdcfe;\">inbrowser</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #569cd6;\">True</span>, <span style=\"color: #9cdcfe;\">share</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #569cd6;\">True</span>) </div></div></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\"><b>실행</b></div><div style=\"text-align: left;\">앞에 구현된 앱을 실행한다. 그리고, 적절한 질문을 입력해 본다. 다음과 같이 실행되면 성공한 것이다.</div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEjl3Y9-wumZOUm7Fpqpq8Rc7Czbh8NcdLfNnPMyhiOUJbCbLw8QWfElpEUt0DnXxE7KIhZJIEGBxg_illf2ucCPZ6gNgPrgKmFkPtGe_huVjpzrgB0qPBlWMfPOdVXmd2aptxlyiytwLaUZB8K9Ga9HNwqRlMg41qbri996i46SBOO557jgAroyRWR0XqCp\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"730\" data-original-width=\"787\" height=\"371\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEjl3Y9-wumZOUm7Fpqpq8Rc7Czbh8NcdLfNnPMyhiOUJbCbLw8QWfElpEUt0DnXxE7KIhZJIEGBxg_illf2ucCPZ6gNgPrgKmFkPtGe_huVjpzrgB0qPBlWMfPOdVXmd2aptxlyiytwLaUZB8K9Ga9HNwqRlMg41qbri996i46SBOO557jgAroyRWR0XqCp=w400-h371\" width=\"400\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEhIw5Zcuqc-XrrCmMX6wjT7Blh1PRVQPkqlHy9dQ-dXrraDJBk2lHa7pSgEVQeg1H-RPWRWf1oPj2g2rCBBneteGxnZuQo8Do7NSjYlgjOicdcNqf-jqyleVY8068fyJLyT52Xfl_AxrZwrnMFjYXvXYhunmeWMIMHX51RuPVx5jMh2VffbReXaIir5TSCL\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"379\" data-original-width=\"745\" height=\"204\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEhIw5Zcuqc-XrrCmMX6wjT7Blh1PRVQPkqlHy9dQ-dXrraDJBk2lHa7pSgEVQeg1H-RPWRWf1oPj2g2rCBBneteGxnZuQo8Do7NSjYlgjOicdcNqf-jqyleVY8068fyJLyT52Xfl_AxrZwrnMFjYXvXYhunmeWMIMHX51RuPVx5jMh2VffbReXaIir5TSCL=w400-h204\" width=\"400\" /></a></div><br /></div><div style=\"text-align: left;\"><b>펑션콜 문제 개선 방법</b></div><div style=\"text-align: left;\">실제로 질의해보면 불명확한 프롬프트 입력 등에서 부적절한 함수 호출이 수행되는 것을 알 수 있다. 이를 개선하기 위해 다음 사항을 고려한다.</div><ul style=\"text-align: left;\"><li>프롬프트 설계의 명확성</li></ul><blockquote style=\"border: none; margin: 0px 0px 0px 40px; padding: 0px; text-align: left;\">함수 호출이 필요한 상황, 호출 방식(JSON 포맷 등), 호출 예시를 SYSTEM_MESSAGE에 명확하게 안내해야 한다. 함수 호출이 아닌 일반 답변을 하면 안 된다는 점을 반복적으로 강조한다.<br />예시 프롬프트:<br />\"질문에 답변하기 위해 함수 호출이 필요하다고 판단되면 반드시 아래 JSON 형식으로만 응답하라. 다른 텍스트나 설명은 절대 포함하지 마라.\"</blockquote><ul style=\"text-align: left;\"><li>함수 정의의 구체성</li></ul><blockquote style=\"border: none; margin: 0px 0px 0px 40px; padding: 0px; text-align: left;\">함수의 목적, 파라미터, 반환값, 사용 예시를 상세하게 기술한다. 각 파라미터의 타입, 필수 여부, 설명을 명확히 한다. 함수가 처리할 수 없는 입력(예: 빈 문자열, 잘못된 타입 등)에 대한 예외 상황도 명시한다.</blockquote><ul style=\"text-align: left;\"><li>예시 기반 Few-shot Prompting</li></ul><blockquote style=\"border: none; margin: 0px 0px 0px 40px; padding: 0px; text-align: left;\">SYSTEM_MESSAGE 또는 user message에 함수 호출이 필요한 질문과 그에 대한 올바른 함수 호출 예시를 여러 개 포함시킨다. 예시가 많을수록 모델이 패턴을 더 잘 학습한다.</blockquote><ul style=\"text-align: left;\"><li>함수 호출 실패 시 재시도 로직</li></ul><blockquote style=\"border: none; margin: 0px 0px 0px 40px; padding: 0px; text-align: left;\">모델이 함수 호출을 하지 않거나 잘못된 형식으로 응답하면, 내부적으로 \"함수 호출이 필요합니다. 반드시 JSON 형식으로만 응답하세요.\"와 같은 추가 프롬프트로 재요청한다.</blockquote><ul style=\"text-align: left;\"><li>출력&nbsp;파싱의 견고성</li></ul><blockquote style=\"border: none; margin: 0px 0px 0px 40px; padding: 0px; text-align: left;\">모델이 JSON 외의 텍스트를 섞어서 반환할 수 있으므로, 파싱 로직에서 JSON 부분만 추출하거나, 불완전한 JSON도 최대한 보완해서 파싱하도록 한다.</blockquote><ul style=\"text-align: left;\"><li>함수 호출 의도&nbsp;강화 프롬프트</li></ul><blockquote style=\"border: none; margin: 0px 0px 0px 40px; padding: 0px; text-align: left;\">SYSTEM_MESSAGE에 \"함수 호출이 필요한 상황에서는 반드시 함수 호출을 우선적으로 고려하라\"는 문구를 추가한다. \"만약 함수 호출이 필요하지 않다고 판단되면, 그 이유를 설명하지 말고 바로 답변만 하라.\" 등 불필요한 설명을 억제한다.</blockquote><ul style=\"text-align: left;\"><li>모델 버전 및 파라미터 최적화</li></ul><blockquote style=\"border: none; margin: 0px 0px 0px 40px; padding: 0px; text-align: left;\">최신 GPT-4 Turbo 등 함수 호출에 최적화된 모델을 사용한다. temperature, top_p 등 파라미터를 낮춰 일관된 응답을 유도한다.&nbsp;</blockquote><div><ul style=\"text-align: left;\"><li>함수 호출 실패 케이스 수집 및 개선&nbsp;</li></ul></div><blockquote style=\"border: none; margin: 0px 0px 0px 40px; padding: 0px;\"><div><div style=\"text-align: left;\">실제 사용자 입력 중 함수 호출이 누락된 사례를 수집하여, SYSTEM_MESSAGE나 예시 프롬프트를 지속적으로 개선한다.</div></div></blockquote><p>이외에 잘 활용되는 함수에 대한 파인튜닝을 수행해 본다.&nbsp;</p><div><div style=\"text-align: left;\"><b>마무리</b></div><div style=\"text-align: left;\">본 글은 ollama 를 이용한 gemma3 모델을 로딩해 Agent 개발 시 핵심이 되는 function call을 구현해 보았다. 실행해 보면 알겠지만, 펑션콜은 프롬프트 입력에 따라 민감하게 동작한다는 것을 알 수 있다. 그러므로, 함수 호출 방식은 적절히&nbsp;LLM 오케스트레이션 및 튜닝되어야 한다는 것을 알 수 있다.&nbsp;</div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\"><b>레퍼런스</b></div><div style=\"text-align: left;\"><ul style=\"text-align: left;\"><li><a href=\"https://huggingface.co/blog/gemma3\">Welcome Gemma 3: Google's all new multimodal, multilingual, long context open LLM</a></li><li><a href=\"https://github.com/philschmid/gemini-samples/blob/main/examples/gemma-function-calling.ipynb\">gemini-samples/examples/gemma-function-calling.ipynb at main · philschmid/gemini-samples</a></li><li><a href=\"https://medium.com/google-cloud/function-calling-with-gemma3-using-ollama-120194577fa6\">Function calling with Gemma3 using Ollama | by Arjun Prabhulal | Google Cloud - Community | Mar, 2025 | Medium | Google Cloud - Community</a></li><li><a href=\"https://medium.com/@akriti.upadhyay/enhancing-gemma-3s-capabilities-with-fine-tuning-for-function-calling-f1bc74051abe\">Enhancing Gemma 3’s Capabilities with Fine-Tuning for Function Calling | by Akriti Upadhyay | May, 2025 | Medium</a></li><li><a href=\"https://pdf.elspublishing.com/paper/journal/open/SC/earlyOnline/2025/SC-20250004.pdf\">General AI agent framework for smart buildings based on  large language models and ReAct strategy</a></li><li><a href=\"https://medium.com/data-science-collective/the-open-source-stack-for-ai-agents-8ab900e33676\">Open-Source Tools for Agents | Data Science Collective</a></li><li><a href=\"https://levelup.gitconnected.com/the-era-of-high-paying-tech-jobs-is-over-572e4e577758\">The Era of High-Paying Tech Jobs is Over | by Somnath Singh | Level Up Coding</a></li><li><a href=\"https://github.com/AGI-Edgerunners/LLM-Agents-Papers\">AGI-Edgerunners/LLM-Agents-Papers: A repo lists papers related to LLM based agent</a></li><li><a href=\"https://medium.com/crayon-ai/llm-for-optimisation-in-3-d-space-a-comparison-with-deterministic-optimisation-methods-04fd93c35263\">LLM for Optimisation in 3-D Space: A comparison with Deterministic optimisation methods | by Peter Eze | Crayon Data &amp; AI | Medium</a></li><li><a href=\"https://medium.com/google-cloud/demystifying-generative-ai-agents-cf5ad36322bd\">Demystifying Generative AI Agents | by Dr Sokratis Kartakis | Google Cloud - Community | Medium</a></li><li><a href=\"https://github.com/google-gemini/cookbook/blob/main/quickstarts/Function_calling.ipynb\">cookbook/quickstarts/Function_calling.ipynb at main · google-gemini/cookbook</a></li></ul></div></div>",
        "contentSnippet": "이 글은 AI 에이전트(Agent) 개발 시 필수적인 함수호출 방법을 오픈소스를 이용해 구현해 본다. 이를 위해, Gemma3(젬마) LLM(Large Language Model) 기반 Ollama 활용 Function Call(펑션콜) 실습 내용을 소개하고 실행 결과를 확인한다. 아울러, 이런 함수호출 방식의 한계점을 개선하기 위한 솔류션을 나눔한다. 이 실습의 결과는 다음과 같다. \n\n\n이 글은 다음 내용을 포함한다.\n\nAI 에이전트 구현을 위한 함수 호출 방법\nOllama 를 통한 Gemma3 사용법\n채팅 형식 프롬프트 및 메모리 사용법\nGradio 기반 웹 앱 개발\nFunction call 의 한계와 솔류션\n\n\nAI 에이전트 내부 Function call 메커니즘(Akriti, 2025)\n\n\n이 글의 구현 코드는 다음 링크에서 확인할 수 있다.\n\nmac999/AI_agent_simple_function_call\n\nGemma3 모델 특징\n\nGemma 3는 구글이 개발해  2025년 3월 10일에 출시한 LLM으로, 차세대 경량 오픈 멀티모달 AI 모델로, 텍스트와 이미지를 동시에 처리할 수 있는 기능을 갖추고 있다. 이 모델은 다양한 크기와 사양으로 제공되어 단일 GPU 또는 TPU 환경에서도 실행 가능하다.\nGemma 3는 1B, 4B, 12B, 27B의 네 가지 모델 크기로 제공되며, 각각 10억, 40억, 120억, 270억 개의 파라미터를 갖추고 있다. 1B 모델은 텍스트 전용으로 32K 토큰의 입력 컨텍스트를 지원하고, 4B, 12B, 27B 모델은 멀티모달 기능을 지원하며 128K 토큰의 입력 컨텍스트를 처리할 수 있다. 이는 이전 Gemma 모델보다 16배 확장된 크기로, 훨씬 더 많은 양의 정보를 한 번에 처리할 수 있게 해준다.\n이 모델은 텍스트와 이미지 데이터를 동시에 처리하고 이해하는 멀티모달 기능을 제공한다. 이미지 해석, 객체 인식, 시각적 질의응답 등 다양한 작업을 수행할 수 있으며, 텍스트 기반 작업에 시각적 정보를 효과적으로 활용할 수 있도록 지원한다. \n\n\n\n\n  \nWelcome Gemma 3: Google's all new multimodal, multilingual, long context open LLM\n\nGemma 3는 140개 이상의 언어를 지원하여 전 세계 다양한 언어 사용자를 대상으로 하는 AI 애플리케이션 개발에 매우 유리하다. 사용자는 자신의 모국어로 Gemma 3와 상호작용할 수 있으며, 다국어 기반의 텍스트 분석 및 생성 작업도 효율적으로 수행할 수 있다.\n이 모델은 다양한 작업 수행 능력을 갖추고 있다. 질문 답변, 텍스트 요약, 논리적 추론, 창의적인 텍스트 형식 생성(시, 스크립트, 코드, 마케팅 문구, 이메일 초안 등), 이미지 데이터 분석 및 추출 등 광범위한 자연어 처리 및 컴퓨터 비전 관련 작업을 수행할 수 있다. 또한, 함수 호출 및 구조화된 출력을 지원하여 개발자들이 특정 작업을 자동화하고 에이전트 기반의 경험을 구축하는 데 도움을 준다.\nGemma 3는 다양한 도구 및 프레임워크와 원활하게 통합된다. Hugging Face Transformers, Ollama, JAX, Keras, PyTorch, Google AI Edge, UnSloth, vLLM, Gemma.cpp 등 다양한 개발 도구 및 프레임워크와 호환되어 개발자들이 자신이 익숙한 환경에서 Gemma 3를 쉽게 활용하고 실험할 수 있다.\n이 모델은 다양한 벤치마크 테스트에서 동급 모델 대비 최첨단 성능을 입증했다. 특히, Chatbot Arena Elo Score에서 1338점을 기록하며, 여러 오픈 소스 및 상용 모델보다 높은 성능을 보였다. \nGemma 3는 오픈 모델로, 개방형 가중치를 제공하여 사용자가 자유롭게 조정하고 배포할 수 있다. Kaggle과 Hugging Face에서 다운로드 가능하며, Creative Commons 및 Apache 2.0 라이선스를 따름으로써, 개발자와 연구자에게 VLM 기술에 대한 접근성을 높여준다.\n\n개발 환경\n개발 환경은 다음과 같다. 미리 설치, 가입한다.\n\nollama:  https://ollama.com/download/windows\ngemma3: https://ollama.com/search\nserper 서비스: 가입. https://serper.dev/dashboard \n\n설치되어 있다면, 다음 명령을 터미널에서 실행한다.\nollama pull gemma3:4b\n\n\n\ngemma3:4b GPU VRAM 소모량\n\n\n이제 다음과 같이 모델을 실행해 볼 수 있다. \n\n\n\n\n참고로, GPU VRAM 등을 고려해 더 성능이 좋은 파라메터수 많은 대형 모델을 사용할 수도 있다.\n\n\ngemma3 지원 모델들\n\n처리 프로세스\n이 실습 프로그램의 프로세스는 다음과 같다.\n\n\nGradio 앱이 시작되면, 사용자의 입력이 발생하고 이 입력은 process_message 함수에 전달된다. 이 함수는 사용자의 메시지를 chat_history에 추가하여 대화 기록을 저장한다. 이후 모델에게 전달할 대화 문맥을 구성하기 위해 messages 리스트가 생성된다.\n\n\n그 다음 단계에서는 ollama.chat 함수를 통해 언어 모델에게 응답을 요청하게 되며, 이 응답 내에 함수 호출이 포함되어 있는지를 확인한다. 만약 응답에 함수 호출이 포함되어 있다면, 이를 parse_function_call 함수를 통해 파싱한다.\n\n\n파싱된 함수가 google_search라면, 모델이 검색을 원한다고 판단하여 검색 쿼리를 추출하고 검색 수행 예정임을 사용자에게 안내하는 메시지를 추가한다. 이후 실제로 google_search 함수를 실행하여 외부 검색을 수행한다.\n\n\n검색 결과는 다시 chat_history에 저장되며, 이 결과를 바탕으로 언어 모델에게 재질문을 하여 더 정확하고 완성된 응답을 유도한다. 모델이 생성한 최종 응답은 chat_history에 마지막으로 추가되고, 이 전체 대화 기록이 사용자에게 반환된다.\n\n\n이 구조는 사용자의 질의에 따라 외부 정보까지 능동적으로 검색하고 반영할 수 있는 LLM 기반 AI 에이전트의 대표적인 흐름을 보여준다.\n\n\n다음은 이 순서도를 보여준다.\n\n\n\n구현하기\n터미널에서 다음 라이브러리를 설치한다.\npip install langchain-core langchain-openai gradio ollama requests python-dotenv pydantic\n\n\n새로운 파이썬 파일(코드 참고)을 생성한 후, 우선, 필요한 라이브러리를 임포트한다. \n\nimport gradio as gr\nimport ollama\nimport requests, json, os\nfrom dotenv import load_dotenv\nfrom pydantic import BaseModel, Field\nfrom typing import Optional, Dict, Any, List\n\nload_dotenv()\nSERPER_API_KEY = os.getenv('SERPER_API_KEY')\n\n\n\n그리고, 사용하는 API 키를 가져온다. 이를 위해, 미리 .env 파일을 다음과 같이 만들어 놓고, 해당 API를 입력해 놓야야 한다.\n\n# .env\nSERPER_API_KEY=<YOUR API KEY>\n\n\n\n파라메터에서 검색 질의문, 함수호출명과 파라메터를 정의한다. 아울러, 질의 결과를 명확히 데이터항목으로 추출하기 위해서 검색 결과가 될 데이타항목(타이틀, 링크, 스닙펫) 형식을 pydantic의 basemodel을 이용해 명확히 정의한다. 그리고, LLM 호출 결과를 펑션콜이 가능한 형식으로 변환하기 위한 파싱 함수인 parse_function_call 을 정의한다.\n\nclass SearchParameters(BaseModel):\n    query: str = Field(..., description=\"Search term to look up\")\n\nclass FunctionCall(BaseModel):\n    name: str\n    parameters: Dict[str, Any]\n\nclass SearchResult(BaseModel):\n    title: str\n    link: str\n    snippet: str\n\n    def to_string(self) -> str:\n        return f\"Title: {self.title}\\nLink: {self.link}\\nSnippet: {self.snippet}\"\n\ndef google_search(query: str) -> SearchResult:\n    \"\"\"Perform a Google search using Serper.dev API\"\"\"\n    try:\n        url = \"https://google.serper.dev/search\"\n        payload = json.dumps({\"q\": query})\n        headers = {\n            'X-API-KEY': SERPER_API_KEY,\n            'Content-Type': 'application/json'\n        }\n        \n        response = requests.post(url, headers=headers, data=payload)\n        response.raise_for_status()  # 잘못된 상태 코드에 대해 예외 발생\n        \n        results = response.json()\n        \n        if not results.get('organic'):\n            raise ValueError(\"No search results found.\")\n            \n        first_result = results['organic'][0]\n        return SearchResult(\n            title=first_result.get('title', 'No title'),\n            link=first_result.get('link', 'No link'),\n            snippet=first_result.get('snippet', 'No snippet available.')\n        )\n    except Exception as e:\n        print(f\"Search error: {str(e)}\")\n        raise\n\ndef parse_function_call(response: str) -> Optional[FunctionCall]:\n    \"\"\"Parse the model's response to extract function calls\"\"\"\n    try:\n        # Clean the response and find JSON structure\n        response = response.strip()\n        start_idx = response.find('{')\n        end_idx = response.rfind('}') + 1\n        \n        if start_idx == -1 or end_idx == 0:\n            return None\n            \n        json_str = response[start_idx:end_idx]\n        data = json.loads(json_str)\n        return FunctionCall(**data)\n    except Exception as e:\n        print(f\"Error parsing function call: {str(e)}\")\n        return None\n\n\n\ngemma에 지시할 시스템 프롬프트 명령을 정의한다. prompt_system_message는 이 챗봇이 어떻게 동작해야 하는지, 그리고 어떤 기준으로 답변을 해야 하는지에 대한 지침을 제공하는 역할을 한다. 이 메시지는 챗봇이 2024년까지의 정보를 학습한 AI 어시스턴트임을 명확히 하고, 사용자의 질문에 대해 가능한 경우에는 바로 답변을 하되, 최신 정보나 불확실한 내용, 시의성이 있는 질문에 대해서는 반드시 펑션콜을 통해 검색 기능을 활용해야 함을 명시한다. 이전 대화 내용이 함께 입력으로 주어지기 때문에, 챗봇은 이 대화 맥락을 참고하여 일관성 있고 상황에 맞는 답변을 해야 한다고 안내한다. 참고로, 준수해야 할 gemma3의 function call 형식은 다음과 같다. \n\ngemini-samples/examples/gemma-function-calling.ipynb at main · philschmid/gemini-samples\n\n검색이 필요한 상황과 그렇지 않은 상황을 구체적으로 구분하여, 챗봇이 임의로 정보를 추정하거나 추가하지 않고, 검색 결과에 기반한 사실만을 간결하게 전달하도록 유도한다. 검색이 필요한 경우에는 정해진 JSON 형식으로만 응답하도록 하여, 시스템이 함수 호출 방식으로 검색을 처리할 수 있게 한다.\n\n# 프롬프트 시스템 메세지 정의\nprompt_system_message = \"\"\"You are an AI assistant with training data up to 2024. Answer questions directly when possible, and use search when necessary.\n\nYou will receive previous conversation messages as part of the input. Use these prior messages to maintain context and provide coherent, context-aware answers.\n\nDECISION PROCESS:\n1. For historical events before 2024:\n   - Answer directly from your training data.\n2. For events in 2024:\n   - If you are certain, answer directly.\n   - If you are unsure, use search.\n3. For events after 2024 or current/recent information:\n   - Always use search.\n4. For timeless information (scientific facts, concepts, etc.):\n   - Answer directly from your training data.\n\nALWAYS USE SEARCH if the question:\n- Contains words like \"current\", \"latest\", \"now\", \"present\", \"today\", \"recent\"\n- Asks about someone in a changing position (champion, president, CEO, etc.)\n- Requests information that might have changed since 2024\n- Is time-sensitive and does not specify a time period\n\nFUNCTION CALL FORMAT:\nWhen you need to search, respond WITH ONLY THE JSON OBJECT, no other text, no backticks:\n{\n    \"name\": \"google_search\",\n    \"parameters\": {\n        \"query\": \"your search query\"\n    }\n}\n\nSEARCH FUNCTION:\n{\n    \"name\": \"google_search\",\n    \"description\": \"Search for real-time information\",\n    \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"Search term\"\n            }\n        },\n        \"required\": [\"query\"]\n    }\n}\n\nWHEN ANSWERING BASED ON SEARCH RESULTS:\n- Use ONLY facts found in the search results below.\n- Do NOT add any dates or information not present in the search results.\n- Do NOT make assumptions about timing or events.\n- Quote dates exactly as they appear in the results.\n- Keep your answer concise and factual.\n\"\"\"\n\n\n\ngemma에 전달할 메시지는 프롬프트 지시문, 사용자 질문을 포함한 이전 채팅 이력 메시지 등을 모두 포함한다. 이를 ollama LLM 에 전달할 수 있는 형식으로 변환하는 함수를 다음과 같이 준비한다. \n\n# 메시지 리스트를 생성하는 함수\ndef filter_memory(memory):\n    \"\"\"assistant의 검색 안내 메시지를 memory에서 제외\"\"\"\n    return [\n        msg for msg in memory\n        if not (\n            msg[\"role\"] == \"assistant\" and (\n                msg[\"content\"].startswith(\"Searching for:\") or\n                msg[\"content\"].startswith(\"Searched for:\")\n            )\n        )\n    ]\n\ndef build_messages(chat_history, user_input=None, prompt_system_message=prompt_system_message, N=6, search_result=None):\n    \"\"\"\n    최근 N개 메시지와 system 메시지를 합쳐 messages 리스트를 만듭니다.\n    search_result가 있으면, user_input 대신 검색 결과 기반 프롬프트를 추가합니다.\n    \"\"\"\n    memory = chat_history[-N:] if len(chat_history) > N else chat_history[:-1]\n    filtered_memory = filter_memory(memory)\n    messages = [{\"role\": \"system\", \"content\": prompt_system_message}] + filtered_memory\n    if search_result is not None:\n        messages.append({\n            \"role\": \"user\",\n            \"content\": (\n                \"Refer to the following search result and provide a concise, factual answer based only on this information:\\n\"\n                f\"{search_result.to_string()}\"\n            )\n        })\n    elif user_input is not None:\n        messages.append({\"role\": \"user\", \"content\": user_input})\n    return messages\n\n\n\n\n이제 process_message 함수를 구현한다. 이 함수는 사용자의 입력과 기존 채팅 기록을 받아 AI 모델과의 대화 흐름을 관리하는 역할을 한다.\n\n\n먼저 사용자의 메시지를 채팅 기록에 추가하고, 이전 대화 내용(메모리)을 추출하여 시스템 메시지와 함께 모델에 전달할 메시지 목록을 구성한다. 이 메시지 목록을 Ollama 모델에 전달하여 응답을 받는다. 모델의 응답이 함수 호출(JSON) 형태라면, 그 내용을 파싱하여 검색이 필요한 경우 검색 쿼리를 추출한다.\n\n\n검색이 필요하다고 판단되면, 검색 중임을 알리는 메시지를 채팅 기록에 추가하고, 실제로 검색을 수행한다. 검색 결과를 다시 채팅 기록에 반영한 뒤, 이 결과를 포함한 새로운 메시지 목록을 만들어 모델에 전달하여 최종 답변을 받는다. 최종적으로 받은 답변 역시 채팅 기록에 추가한다.\n\n\n검색이 필요하지 않은 경우에는 모델의 응답을 바로 채팅 기록에 추가한다. 이 과정에서 각 단계별로 최신 채팅 기록을 반환하여, 사용자 인터페이스가 실시간으로 대화 상태를 갱신할 수 있도록 한다.\n함수 실행 중 오류가 발생하면, 오류 메시지를 채팅 기록에 추가하여 사용자에게 알린다.\n\n# Model name\nMODEL_NAME = \"gemma3\"\n\ndef process_message(user_input, chat_history):\n    \"\"\"Process user message and update chat history\"\"\"\n    try:\n        # 사용자 메시지를 기록에 추가\n        chat_history.append({\"role\": \"user\", \"content\": user_input})\n        search_info = None\n\n        # 최근 N개 메시지만 memory에 포함 (예: 최근 6개)\n        N = 6\n        messages = build_messages(chat_history, user_input=user_input, N=N)\n\n        # 모델로부터 응답 받기\n        response = ollama.chat(\n            model=MODEL_NAME,\n            messages=messages       \n        )\n        \n        model_response = response['message']['content']\n        \n        # 함수 호출로 응답을 파싱 시도\n        function_call = parse_function_call(model_response)\n        \n        if function_call and function_call.name == \"google_search\":\n            # 검색 파라미터 검증\n            search_params = SearchParameters(**function_call.parameters)\n            search_query = search_params.query\n            \n            # 검색 정보 기록에 추가\n            search_info = f\"Searching for: {search_query}\"\n            chat_history.append({\"role\": \"assistant\", \"content\": search_info})\n            yield chat_history\n            \n            # 검색 실행\n            search_result = google_search(search_query)\n            \n            # 검색 결과로 정보 업데이트\n            search_info = f\"Searched for: {search_query}\\n\\nResult:\\n{search_result.to_string()}\"\n            chat_history[-1] = {\"role\": \"assistant\", \"content\": search_info}\n            yield chat_history\n\n            # 검색 결과 기반 메시지 생성\n            messages = build_messages(chat_history, N=N, search_result=search_result)\n      \n            # 검색 결과를 포함해 모델로부터 최종 응답 받기\n            final_response = ollama.chat(\n                model=MODEL_NAME,\n                messages=messages\n            )\n            \n            assistant_response = final_response['message']['content']\n        else:\n            # 함수 호출이 없으면 직접 응답 반환\n            assistant_response = model_response\n        \n        # 최종 응답을 기록에 업데이트\n        if search_info:\n            chat_history.append({\"role\": \"assistant\", \"content\": f\" Response:\\n{assistant_response}\"})\n        else:\n            chat_history.append({\"role\": \"assistant\", \"content\": assistant_response})\n        \n        yield chat_history\n            \n    except Exception as e:\n        error_msg = f\"An error occurred: {str(e)}\"\n        chat_history.append({\"role\": \"assistant\", \"content\": error_msg})\n        yield chat_history\n\n\n\n\n이제 Gradio UI 를 정의하고, 메인 엔트리에서 이 앱을 실행한다.\n\n\n# Gradio 인터페이스 생성\nwith gr.Blocks(css=\"footer {visibility: hidden}\") as demo:\n    gr.Markdown(\"\"\"\n    # Agent based on Gemma3 using Function Call\n    \n\n    \"\"\")\n    \n    chatbot = gr.Chatbot(\n        height=500,\n        show_label=False,\n        avatar_images=(None, \"https://api.dicebear.com/9.x/identicon/svg?seed=Mason\"),\n        type=\"messages\"\n    )\n    \n    with gr.Row():\n        msg = gr.Textbox(\n            scale=5,\n            show_label=False,\n            placeholder=\"Ask me anything...\",\n            container=False\n        )\n        submit_btn = gr.Button(\"Send\", scale=1)\n    \n    with gr.Row():\n        clear_btn = gr.Button(\"Clear Chat\")\n    \n\n    # 이벤트 핸들러 설정\n    msg.submit(\n        process_message,\n        [msg, chatbot],\n        [chatbot],\n    )\n    \n    submit_btn.click(\n        process_message,\n        [msg, chatbot],\n        [chatbot],\n    )\n    \n    clear_btn.click(\n        lambda: [],\n        None,\n        chatbot,\n        queue=False\n    )\n    \n    # 메시지 전송 후 텍스트박스 비우기\n    msg.submit(lambda: \"\", None, msg)\n    submit_btn.click(lambda: \"\", None, msg)\n\nif __name__ == \"__main__\":\n    demo.launch(inbrowser=True, share=True) \n\n\n\n실행\n앞에 구현된 앱을 실행한다. 그리고, 적절한 질문을 입력해 본다. 다음과 같이 실행되면 성공한 것이다.\n\n\n\n\n펑션콜 문제 개선 방법\n실제로 질의해보면 불명확한 프롬프트 입력 등에서 부적절한 함수 호출이 수행되는 것을 알 수 있다. 이를 개선하기 위해 다음 사항을 고려한다.\n\n프롬프트 설계의 명확성\n\n함수 호출이 필요한 상황, 호출 방식(JSON 포맷 등), 호출 예시를 SYSTEM_MESSAGE에 명확하게 안내해야 한다. 함수 호출이 아닌 일반 답변을 하면 안 된다는 점을 반복적으로 강조한다.\n예시 프롬프트:\n\"질문에 답변하기 위해 함수 호출이 필요하다고 판단되면 반드시 아래 JSON 형식으로만 응답하라. 다른 텍스트나 설명은 절대 포함하지 마라.\"\n\n함수 정의의 구체성\n\n함수의 목적, 파라미터, 반환값, 사용 예시를 상세하게 기술한다. 각 파라미터의 타입, 필수 여부, 설명을 명확히 한다. 함수가 처리할 수 없는 입력(예: 빈 문자열, 잘못된 타입 등)에 대한 예외 상황도 명시한다.\n\n예시 기반 Few-shot Prompting\n\nSYSTEM_MESSAGE 또는 user message에 함수 호출이 필요한 질문과 그에 대한 올바른 함수 호출 예시를 여러 개 포함시킨다. 예시가 많을수록 모델이 패턴을 더 잘 학습한다.\n\n함수 호출 실패 시 재시도 로직\n\n모델이 함수 호출을 하지 않거나 잘못된 형식으로 응답하면, 내부적으로 \"함수 호출이 필요합니다. 반드시 JSON 형식으로만 응답하세요.\"와 같은 추가 프롬프트로 재요청한다.\n\n출력 파싱의 견고성\n\n모델이 JSON 외의 텍스트를 섞어서 반환할 수 있으므로, 파싱 로직에서 JSON 부분만 추출하거나, 불완전한 JSON도 최대한 보완해서 파싱하도록 한다.\n\n함수 호출 의도 강화 프롬프트\n\nSYSTEM_MESSAGE에 \"함수 호출이 필요한 상황에서는 반드시 함수 호출을 우선적으로 고려하라\"는 문구를 추가한다. \"만약 함수 호출이 필요하지 않다고 판단되면, 그 이유를 설명하지 말고 바로 답변만 하라.\" 등 불필요한 설명을 억제한다.\n\n모델 버전 및 파라미터 최적화\n\n최신 GPT-4 Turbo 등 함수 호출에 최적화된 모델을 사용한다. temperature, top_p 등 파라미터를 낮춰 일관된 응답을 유도한다. \n\n함수 호출 실패 케이스 수집 및 개선 \n\n\n실제 사용자 입력 중 함수 호출이 누락된 사례를 수집하여, SYSTEM_MESSAGE나 예시 프롬프트를 지속적으로 개선한다.\n\n이외에 잘 활용되는 함수에 대한 파인튜닝을 수행해 본다. \n\n마무리\n본 글은 ollama 를 이용한 gemma3 모델을 로딩해 Agent 개발 시 핵심이 되는 function call을 구현해 보았다. 실행해 보면 알겠지만, 펑션콜은 프롬프트 입력에 따라 민감하게 동작한다는 것을 알 수 있다. 그러므로, 함수 호출 방식은 적절히 LLM 오케스트레이션 및 튜닝되어야 한다는 것을 알 수 있다. \n\n\n레퍼런스\n\nWelcome Gemma 3: Google's all new multimodal, multilingual, long context open LLM\ngemini-samples/examples/gemma-function-calling.ipynb at main · philschmid/gemini-samples\nFunction calling with Gemma3 using Ollama | by Arjun Prabhulal | Google Cloud - Community | Mar, 2025 | Medium | Google Cloud - Community\nEnhancing Gemma 3’s Capabilities with Fine-Tuning for Function Calling | by Akriti Upadhyay | May, 2025 | Medium\nGeneral AI agent framework for smart buildings based on  large language models and ReAct strategy\nOpen-Source Tools for Agents | Data Science Collective\nThe Era of High-Paying Tech Jobs is Over | by Somnath Singh | Level Up Coding\nAGI-Edgerunners/LLM-Agents-Papers: A repo lists papers related to LLM based agent\nLLM for Optimisation in 3-D Space: A comparison with Deterministic optimisation methods | by Peter Eze | Crayon Data & AI | Medium\nDemystifying Generative AI Agents | by Dr Sokratis Kartakis | Google Cloud - Community | Medium\ncookbook/quickstarts/Function_calling.ipynb at main · google-gemini/cookbook",
        "id": "tag:blogger.com,1999:blog-5201956450461596914.post-18075867409642887",
        "isoDate": "2025-06-04T06:56:00.000Z"
      }
    ]
  },
  {
    "name": "권용진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김승호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for boyism Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성준의 린스타트업과 디자인씽킹",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강동혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고종범",
    "category": "개인",
    "posts": []
  },
  {
    "name": "cheese10yun",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구자철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "FSS",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권동준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김용일",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도균",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김동우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권윤학",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김만수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "엘키",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김슬기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김광현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김영우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강명훈",
    "category": "개인",
    "posts": [
      {
        "title": "데이터 노가다 실수담 - 11th",
        "link": "https://kangmyounghun.blogspot.com/2025/06/11th.html",
        "pubDate": "2025-06-08T05:22:00.002Z",
        "author": "강명훈",
        "content": "<div>3개의 필드로 이루어진 테이블. a가 있으면 c가 없고, c가 있으면 a가 없는 구조.&nbsp;</div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEglTRqxRKnWtJ-nKPMgA45R3GK9Bg5Xr7RqruYmDlVvz_PrrrS-o_svtf1yPgHsE42PmV8OihxBvT6im71x5Gx9FXZgPZivA0ejBT0u52T73HmdTnuxDxSNp47oPcW4GXR03H31U7aPIHPFFyZ2MxV1OpVrz1cOBq_tsSfwuy-ObiHQ8hrgjVe2-aroht3K/s1246/table.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"720\" data-original-width=\"1246\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEglTRqxRKnWtJ-nKPMgA45R3GK9Bg5Xr7RqruYmDlVvz_PrrrS-o_svtf1yPgHsE42PmV8OihxBvT6im71x5Gx9FXZgPZivA0ejBT0u52T73HmdTnuxDxSNp47oPcW4GXR03H31U7aPIHPFFyZ2MxV1OpVrz1cOBq_tsSfwuy-ObiHQ8hrgjVe2-aroht3K/s16000/table.png\" /></a></div><div><br /></div><div><span><a name='more'></a></span>이때 a, c는 b와 연결해야 정확한 의미를 갖는다.</div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh7w1VvCJky1n8r2OOYC7ErAtrCNutJJU_0kXlZXALOIVBki6tw3vbeNcCxSWCon7bTY9HfxLkUDoczD12_YwvYQlne5fUxDPnzmjzB90S3JzWnHHyEeXt33XL23x1q-j2NildLwEFjlq5tBBlfVUM0AxrzbrkRpyUe8n4Skk_cm-UZiXGl_CqkX1XCELxj/s1914/table2.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"1125\" data-original-width=\"1914\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh7w1VvCJky1n8r2OOYC7ErAtrCNutJJU_0kXlZXALOIVBki6tw3vbeNcCxSWCon7bTY9HfxLkUDoczD12_YwvYQlne5fUxDPnzmjzB90S3JzWnHHyEeXt33XL23x1q-j2NildLwEFjlq5tBBlfVUM0AxrzbrkRpyUe8n4Skk_cm-UZiXGl_CqkX1XCELxj/s16000/table2.png\" /></a></div><div><br /></div><div>case 조건문으로 바꾸면 이런 식.</div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhIPog9VDxccxwtbkuD8wj41LOcDs4PToJgrhpw6DHH4TeQxsvTyAWlIEXUjeYhfCYG3bDNFcigs1qKXCcUdw-dVdNWZgzuHkf_A-c3jSLEFNlgrGL3rtUKkJpFfLuuywMdH45P62sJFtcbrKzfito0EHCoLT97_jOevoBzZ8EtgB9RVKImbX1k1uVmk-7w/s1694/table3.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"1125\" data-original-width=\"1694\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhIPog9VDxccxwtbkuD8wj41LOcDs4PToJgrhpw6DHH4TeQxsvTyAWlIEXUjeYhfCYG3bDNFcigs1qKXCcUdw-dVdNWZgzuHkf_A-c3jSLEFNlgrGL3rtUKkJpFfLuuywMdH45P62sJFtcbrKzfito0EHCoLT97_jOevoBzZ8EtgB9RVKImbX1k1uVmk-7w/s16000/table3.png\" /></a></div><br /><div><b><span style=\"font-size: x-large;\">b만 존재하는 상태</span></b><b><span style=\"font-size: x-large;\">도 추가하려면?&nbsp;</span></b></div><div><br /></div><div>다음 조건 로직은 동작하지 않는다. 원하는 마지막 조건은 a, c 모두 없는 상태인데, 선행 조건을 제외하면 남는 조건은 a, c 모두 존재하는 상태뿐이기 때문.&nbsp;</div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgztZ_se-G3ivpGoM2dujOfN1OSh860H3e2MjQ87EVqzQZnWqDqRsNDfiC-2GOgSvsp58Z4hVqv866tuyisZDq8X57DQ-MWDwzz14Qi6LkshrGVnHX9PQhnob5O9pxk2asWB5csEngRqnAEd34kRmyQ7i7hbsB6z67EXCciE8bfnsf5CFREPWFyAbjMcqYG/s1634/table4.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"1125\" data-original-width=\"1634\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgztZ_se-G3ivpGoM2dujOfN1OSh860H3e2MjQ87EVqzQZnWqDqRsNDfiC-2GOgSvsp58Z4hVqv866tuyisZDq8X57DQ-MWDwzz14Qi6LkshrGVnHX9PQhnob5O9pxk2asWB5csEngRqnAEd34kRmyQ7i7hbsB6z67EXCciE8bfnsf5CFREPWFyAbjMcqYG/s16000/table4.png\" /></a></div><br /><div>a, c 모두 없는 상태를 추가하려면 a, c가 존재하는 상태를 먼저 검사하거나</div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiWDkyy_xIHBpOlfm2Uh3SX1wZSvdGqc-89GeVgNUjePubq6p6gstsEmnhXwuh5A-qVcE7tGJlIqevqJgls9TiEy8vuNDexl6yn-1D33pbcxQpkKsUgBGsHFM5fPedGwwt8s2bPnk4GhHYxnzfl3i4AAshoB25jbqb3nfYIPRwBUIfJG8WiZbVVkBapZF_p/s1548/table5.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"1125\" data-original-width=\"1548\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiWDkyy_xIHBpOlfm2Uh3SX1wZSvdGqc-89GeVgNUjePubq6p6gstsEmnhXwuh5A-qVcE7tGJlIqevqJgls9TiEy8vuNDexl6yn-1D33pbcxQpkKsUgBGsHFM5fPedGwwt8s2bPnk4GhHYxnzfl3i4AAshoB25jbqb3nfYIPRwBUIfJG8WiZbVVkBapZF_p/s16000/table5.png\" /></a></div><div><br /></div><div>a, c 모두 없는 상태를 먼저 검사해야 한다. 별로 복잡한 로직도 아닌데 이걸 헤맸네. 이제 isnull과 isnotnull 안 헷갈릴 듯<span style=\"font-size: x-small;\">(..)</span></div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj5Jo9FrHisIOWhXoaWM0ifAjFo1jj7PZNZrOVVFUbSC3yV7oBoSGRSr886OGX0kEIiXznBEM_G8X144JvuJ3q9SxE173jOXtiFFuD0vRXKAnltZxTLOGUb-rql-TkID7-tq5SyId-6RFp6QXu1Nmfb5bWb7CXlJVUVxlxuRKZ1i6JD99N2RBEC-A1w6zC8/s1548/table6.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"1125\" data-original-width=\"1548\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj5Jo9FrHisIOWhXoaWM0ifAjFo1jj7PZNZrOVVFUbSC3yV7oBoSGRSr886OGX0kEIiXznBEM_G8X144JvuJ3q9SxE173jOXtiFFuD0vRXKAnltZxTLOGUb-rql-TkID7-tq5SyId-6RFp6QXu1Nmfb5bWb7CXlJVUVxlxuRKZ1i6JD99N2RBEC-A1w6zC8/s16000/table6.png\" /></a></div><div><br /></div><div>규환님 커피 보내드립니다^^</div><div><br /></div><div><b>관련 글</b></div><div><ul style=\"text-align: left;\"><li><a href=\"https://kangmyounghun.blogspot.com/2025/04/10th.html\">데이터 노가다 실수담 - 10th</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2019/01/blog-post_90.html\" target=\"\">데이터 노가다 실수담</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2023/06/blog-post.html\">평균의 함정</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2020/09/blog-post_27.html\" target=\"\">데이터 분석이 쉬워지는 비법</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2021/12/blog-post.html\" target=\"\">데이터 분석에 필요한 자질은 뭘까?</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2024/02/splunk_25.html\" target=\"\">Splunk의 조건문</a></li></ul></div>",
        "contentSnippet": "3개의 필드로 이루어진 테이블. a가 있으면 c가 없고, c가 있으면 a가 없는 구조. \n\n\n\n\n\n이때 a, c는 b와 연결해야 정확한 의미를 갖는다.\n\n\n\n\n\ncase 조건문으로 바꾸면 이런 식.\n\n\n\n\nb만 존재하는 상태도 추가하려면? \n\n\n다음 조건 로직은 동작하지 않는다. 원하는 마지막 조건은 a, c 모두 없는 상태인데, 선행 조건을 제외하면 남는 조건은 a, c 모두 존재하는 상태뿐이기 때문. \n\n\n\n\na, c 모두 없는 상태를 추가하려면 a, c가 존재하는 상태를 먼저 검사하거나\n\n\n\n\n\na, c 모두 없는 상태를 먼저 검사해야 한다. 별로 복잡한 로직도 아닌데 이걸 헤맸네. 이제 isnull과 isnotnull 안 헷갈릴 듯(..)\n\n\n\n\n\n규환님 커피 보내드립니다^^\n\n\n관련 글\n\n데이터 노가다 실수담 - 10th\n데이터 노가다 실수담\n평균의 함정\n데이터 분석이 쉬워지는 비법\n데이터 분석에 필요한 자질은 뭘까?\nSplunk의 조건문",
        "id": "tag:blogger.com,1999:blog-2597780270996323853.post-2136228877451541718",
        "isoDate": "2025-06-08T05:22:00.002Z"
      }
    ]
  },
  {
    "name": "김민장",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성중",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구교준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고명환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강병수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김봉현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강형석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수로",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강미경",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강진우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권민재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태관",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도곤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "칡토스의 게임 개발",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Lael's World",
    "category": "개인",
    "posts": []
  },
  {
    "name": "프리웨어 이야기",
    "category": "개인",
    "posts": [
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "AI 챗봇 vs 웹사이트, 어떤 정보원을 더 신뢰해야 할까?",
        "link": "http://muzbox.tistory.com/483605",
        "pubDate": "Wed, 11 Jun 2025 09:45:41 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483605#entry483605comment",
        "content": "<p data-ke-size=\"size8\">&nbsp;</p>\n<div style=\"background-color: #e0f7fa; padding: 15px; border-radius: 8px; font-style: italic; margin-bottom: 25px; font-size: 15px; border: 1px solid #b2ebf2;\"><b>AI 챗봇 vs. 웹사이트, 어떤 정보원을 믿어야 할까요?</b> 온라인 정보의 홍수 속에서 AI 챗봇과 웹사이트 중 어떤 정보원을 더 신뢰해야 할지 고민해 본 적 있으신가요? 이 글을 통해 두 정보원의 장단점을 비교하고, 현명하게 정보를 얻는 방법을 알려드릴게요.</div>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1280\" data-origin-height=\"853\"><span data-url=\"https://blog.kakaocdn.net/dn/TOFLj/btsOw4MdKzB/RK5EsG1rQgP6Pa21ybP0Kk/img.webp\" data-phocus=\"https://blog.kakaocdn.net/dn/TOFLj/btsOw4MdKzB/RK5EsG1rQgP6Pa21ybP0Kk/img.webp\"><img src=\"https://blog.kakaocdn.net/dn/TOFLj/btsOw4MdKzB/RK5EsG1rQgP6Pa21ybP0Kk/img.webp\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FTOFLj%2FbtsOw4MdKzB%2FRK5EsG1rQgP6Pa21ybP0Kk%2Fimg.webp\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"AI 챗봇 vs 웹사이트, 어떤 정보원을 더 신뢰해야 할까?\" loading=\"lazy\" width=\"1280\" height=\"853\" data-origin-width=\"1280\" data-origin-height=\"853\"/></span></figure>\n</p>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">&nbsp;요즘 저는 자료 조사를 할 때마다 AI 챗봇의 편리함에 감탄하고 있어요. 궁금한 점을 질문하면 순식간에 답을 해주니 정말 신기하죠? 그런데 문득 이런 생각이 들었어요. '과연 이 정보들을 어디까지 믿을 수 있을까?' 여러분도 저와 같은 고민을 해보셨을 것 같아요.</p>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">인터넷이 발달하면서 정보의 양은 폭발적으로 늘었지만, 그만큼 어떤 정보가 진짜인지, 어떤 정보를 믿고 따라야 할지 혼란스러울 때가 많아요. 특히 AI 챗봇이 등장하면서 이 고민은 더 깊어진 것 같은데요. 웹사이트를 직접 찾아다니며 얻는 정보와, AI가 요약해주는 정보, 과연 어떤 쪽이 더 신뢰할 수 있을까요? 오늘 이 글에서는 AI 챗봇과 웹사이트의 장단점을 파헤쳐 보고, 여러분이 현명한 정보 탐색자가 될 수 있도록 저의 경험과 생각을 나눠볼까 합니다!  </p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"font-size: 24px; color: white; background: linear-gradient(to right, #00796b, #004d40); margin: 35px 0 15px; padding-bottom: 8px; border-bottom: 2px solid #b2ebf2; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>AI 챗봇, 빠르고 편리하지만...  </b></h2>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">AI 챗봇은 정말 편리해요. 제가 예전에 어떤 주제에 대해 찾아야 할 때, 여러 웹사이트를 일일이 방문하고 필요한 정보를 취합하느라 시간이 오래 걸렸거든요. 그런데 챗봇은 딱! 제가 원하는 질문에 대한 핵심 정보만 쏙쏙 뽑아주더라고요. 이게 바로 AI 챗봇의 가장 큰 장점 같아요. <span style=\"background-color: #fff9c4; padding: 2px 4px; border-radius: 3px;\">정보 접근성이 뛰어나고, 답변 속도가 엄청 빠르다는 점</span>이죠. 복잡한 내용을 간결하게 요약해주니 바쁜 현대인에게는 더할 나위 없이 좋고요.</p>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">하지만 편리함 뒤에는 늘 그림자가 있는 법! AI 챗봇은 아직 완벽하지 않아요. 때로는 잘못된 정보를 알려주거나, 맥락에 맞지 않는 답변을 하기도 해요. 제가 경험한 바로는, 특정 주제에 대한 깊이 있는 정보를 찾을 때는 한계가 있더라고요. 예를 들어, 전문적인 의학 정보나 법률 자문 같은 민감한 분야에서는 챗봇의 답변을 맹신하기 어렵죠.</p>\n<div style=\"background-color: #e0f2f7; border-left: 4px solid #4dd0e1; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\"><b>  알아두세요!</b><br />AI 챗봇은 방대한 데이터를 학습하지만, 그 데이터가 항상 최신이거나 100% 정확하다고 보장할 수는 없어요. 특히 논쟁의 여지가 있거나 빠르게 변화하는 정보는 꼭 교차 검증이 필요하답니다.</div>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"font-size: 24px; color: white; background: linear-gradient(to right, #00796b, #004d40); margin: 35px 0 15px; padding-bottom: 8px; border-bottom: 2px solid #b2ebf2; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>전문 웹사이트, 깊이 있고 신뢰할 수 있지만...  </b></h2>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">그럼 전통적인 방식인 웹사이트는 어떨까요? 저는 예전부터 특정 분야의 정보를 찾을 때는 늘 <span style=\"background-color: #fff9c4; padding: 2px 4px; border-radius: 3px;\">권위 있는 기관이나 전문가가 운영하는 웹사이트</span>를 선호했어요. 왜냐하면 그런 곳들은 정보의 출처가 명확하고, 내용에 대한 책임감을 가지고 작성하기 때문이죠. 예를 들어, 질병에 대한 정보를 찾을 때는 대한의사협회나 건강보험심사평가원 같은 공식 웹사이트를 찾아보는 것이 가장 확실하잖아요.</p>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">웹사이트는 단순히 정보를 제공하는 것을 넘어, 때로는 특정 주제에 대한 <span style=\"background-color: #fff9c4; padding: 2px 4px; border-radius: 3px;\">깊이 있는 통찰력이나 다양한 관점</span>을 제시하기도 해요. 저도 블로그를 운영하면서 제 경험과 생각을 담아 글을 쓰는데, 이런 글들이 다른 사람들에게 도움이 될 때 큰 보람을 느끼거든요. 잘 알려진 웹사이트는 특정 주제에 대한 전문가의 섬세한 의견을 제공할 수 있다는 점이 정말 매력적이에요.</p>\n<h3 style=\"font-size: 20px; color: #00796b; margin: 25px 0 12px;\" data-ke-size=\"size23\"><b>AI 챗봇 vs. 전문 웹사이트 비교</b></h3>\n<table style=\"width: 100%; border-collapse: collapse; margin: 20px 0;\" data-ke-align=\"alignLeft\">\n<thead>\n<tr>\n<th style=\"padding: 14px; text-align: left; border: 1px solid #e0e0e0; background-color: #e0f7fa; font-weight: bold;\">구분</th>\n<th style=\"padding: 14px; text-align: left; border: 1px solid #e0e0e0; background-color: #e0f7fa; font-weight: bold;\">AI 챗봇</th>\n<th style=\"padding: 14px; text-align: left; border: 1px solid #e0e0e0; background-color: #e0f7fa; font-weight: bold;\">전문 웹사이트</th>\n<th style=\"padding: 14px; text-align: left; border: 1px solid #e0e0e0; background-color: #e0f7fa; font-weight: bold;\">기타 정보</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"padding: 14px; text-align: left; border: 1px solid #e0e0e0;\">정보 취득 속도</td>\n<td style=\"padding: 14px; text-align: left; border: 1px solid #e0e0e0;\">매우 빠름 (즉각적인 답변)</td>\n<td style=\"padding: 14px; text-align: left; border: 1px solid #e0e0e0;\">상대적으로 느림 (탐색 필요)</td>\n<td style=\"padding: 14px; text-align: left; border: 1px solid #e0e0e0;\">빠른 검색이 필요한 경우</td>\n</tr>\n<tr style=\"background-color: #f5f5f5;\">\n<td style=\"padding: 14px; text-align: left; border: 1px solid #e0e0e0;\">정보 신뢰도</td>\n<td style=\"padding: 14px; text-align: left; border: 1px solid #e0e0e0;\">주의 필요 (환각 현상 가능)</td>\n<td style=\"padding: 14px; text-align: left; border: 1px solid #e0e0e0;\">높음 (전문가 검토, 출처 명시)</td>\n<td style=\"padding: 14px; text-align: left; border: 1px solid #e0e0e0;\">중요 정보일수록 웹사이트 추천</td>\n</tr>\n<tr>\n<td style=\"padding: 14px; text-align: left; border: 1px solid #e0e0e0;\">정보의 깊이</td>\n<td style=\"padding: 14px; text-align: left; border: 1px solid #e0e0e0;\">요약 위주 (피상적일 수 있음)</td>\n<td style=\"padding: 14px; text-align: left; border: 1px solid #e0e0e0;\">깊이 있는 정보, 다양한 관점</td>\n<td style=\"padding: 14px; text-align: left; border: 1px solid #e0e0e0;\">전문 지식이 필요한 경우</td>\n</tr>\n<tr style=\"background-color: #f5f5f5;\">\n<td style=\"padding: 14px; text-align: left; border: 1px solid #e0e0e0;\">활용 분야</td>\n<td style=\"padding: 14px; text-align: left; border: 1px solid #e0e0e0;\">빠른 질문, 아이디어 얻기</td>\n<td style=\"padding: 14px; text-align: left; border: 1px solid #e0e0e0;\">심층 학습, 검증된 정보 획득</td>\n<td style=\"padding: 14px; text-align: left; border: 1px solid #e0e0e0;\">용도에 맞게 선택</td>\n</tr>\n</tbody>\n</table>\n<div style=\"background-color: #fffde7; border-left: 4px solid #fbc02d; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\"><b>⚠️ 주의하세요!</b><br />웹사이트도 모든 정보가 100% 정확한 것은 아니에요. 특히 개인 블로그나 커뮤니티 게시글은 사실과 다른 정보가 있을 수 있으니, 항상 비판적인 시각으로 정보를 받아들이고 필요하다면 여러 출처를 확인하는 습관을 들이는 것이 중요해요.</div>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"font-size: 24px; color: white; background: linear-gradient(to right, #00796b, #004d40); margin: 35px 0 15px; padding-bottom: 8px; border-bottom: 2px solid #b2ebf2; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>그렇다면, 현명한 정보 탐색법은?  </b></h2>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">결론적으로, AI 챗봇과 웹사이트는 서로를 완벽하게 대체할 수 없어요. 각자의 장단점이 명확하기 때문에, 상황에 맞게 적절히 활용하는 지혜가 필요하다고 생각해요. 제가 주로 쓰는 방법은 이렇습니다!</p>\n<div style=\"background-color: #e0f7fa; padding: 18px; border-radius: 8px; margin: 20px 0; border: 1px solid #b2ebf2;\">\n<h3 style=\"font-size: 20px; color: #333; margin: 0 0 12px;\" data-ke-size=\"size23\"><b>  질문 유형별 정보원 선택 가이드</b></h3>\n<p style=\"margin-bottom: 0;\" data-ke-size=\"size16\"><b>정보 탐색 효율을 높이는 공식 = AI 챗봇(빠른 정보) + 웹사이트(심층 검증)</b></p>\n</div>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">제가 직접 시도해보며 얻은 정보 탐색 팁을 알려드릴게요:</p>\n<div style=\"background-color: #e0f7fa; padding: 18px; border-radius: 8px; margin: 20px 0; border: 1px solid #b2ebf2;\">\n<h3 style=\"font-size: 20px; color: #333; margin: 0 0 12px;\" data-ke-size=\"size23\"><b>정보 유형별 솔루션</b></h3>\n<ul style=\"margin: 0 0 15px 20px; padding: 0;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 8px;\"><b>기본 지식/정의 (Basic Knowledge/Definition):</b>\n<ul style=\"margin: 5px 0 0 15px; padding: 0;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 5px;\"><b>활용 도구:</b> AI 챗봇 (1차), 웹사이트 (2차)</li>\n<li style=\"margin-bottom: 5px;\"><b>활용 방법:</b> AI 챗봇에게 먼저 물어 기본적인 개념과 핵심 키워드를 빠르게 파악하세요. 이후, 검색된 키워드를 활용하여 위키백과, 지식백과 또는 관련 전문 기관의 웹사이트에서 상세 정의와 배경 정보를 확인하고 이해를 심화하세요.</li>\n</ul>\n</li>\n<li style=\"margin-bottom: 8px;\"><b>최신 뉴스/이슈 (Current News/Issues):</b>\n<ul style=\"margin: 5px 0 0 15px; padding: 0;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 5px;\"><b>활용 도구:</b> 주요 언론사 웹사이트, 뉴스 포털 (1차), AI 챗봇 (2차)</li>\n<li style=\"margin-bottom: 5px;\"><b>활용 방법:</b> 실시간성이 중요한 정보이므로, 신뢰할 수 있는 언론사의 공식 웹사이트나 주요 뉴스 포털을 직접 방문하여 사실 관계를 파악하는 것이 우선입니다. AI 챗봇은 해당 이슈의 간략한 요약이나 관련 질문을 던지는 데 활용할 수 있습니다.</li>\n</ul>\n</li>\n<li style=\"margin-bottom: 8px;\"><b>건강/의료 정보 (Health/Medical Information):</b>\n<ul style=\"margin: 5px 0 0 15px; padding: 0;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 5px;\"><b>활용 도구:</b> 공식 의료기관 웹사이트, 전문의 웹사이트 (필수)</li>\n<li style=\"margin-bottom: 5px;\"><b>활용 방법:</b> 생명과 직결될 수 있는 정보이므로, <span style=\"background-color: #fff9c4; padding: 2px 4px; border-radius: 3px;\">반드시 대학병원, 대한의사협회, 질병관리청 등 공신력 있는 기관의 웹사이트</span>를 통해 정보를 얻어야 합니다. AI 챗봇의 답변은 참고용으로만 사용하고, 의심되는 내용은 반드시 전문가와 상담하세요.</li>\n</ul>\n</li>\n<li style=\"margin-bottom: 8px;\"><b>법률/재무 자문 (Legal/Financial Advice):</b>\n<ul style=\"margin: 5px 0 0 15px; padding: 0;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 5px;\"><b>활용 도구:</b> 법무법인 웹사이트, 정부 법률/재무 정보 웹사이트 (필수)</li>\n<li style=\"margin-bottom: 5px;\"><b>활용 방법:</b> 전문성과 책임이 요구되는 분야이므로, <span style=\"background-color: #fff9c4; padding: 2px 4px; border-radius: 3px;\">정부 법률정보센터, 금융감독원, 전문 법무법인/회계법인의 공식 웹사이트</span>를 통해 정확한 정보를 확인해야 합니다. AI 챗봇은 관련 법률 용어의 정의나 기본적인 절차를 이해하는 데 보조적으로 활용할 수 있습니다.</li>\n</ul>\n</li>\n<li style=\"margin-bottom: 0;\"><b>개인 의견/경험 (Personal Opinion/Experience):</b>\n<ul style=\"margin: 5px 0 0 15px; padding: 0;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 5px;\"><b>활용 도구:</b> 개인 블로그, 커뮤니티, AI 챗봇</li>\n<li style=\"margin-bottom: 5px;\"><b>활용 방법:</b> 다양한 관점이나 실제 사용자 경험을 파악할 때 유용합니다. 하지만 <span style=\"background-color: #fff9c4; padding: 2px 4px; border-radius: 3px;\">주관적인 내용이 많으므로, 사실 여부는 반드시 다른 신뢰할 수 있는 출처를 통해 교차 검증</span>해야 합니다. AI 챗봇은 여러 사람의 의견을 종합하거나 유사한 사례를 찾아보는 데 도움을 줄 수 있습니다.</li>\n</ul>\n</li>\n</ul>\n</div>\n<h2 style=\"font-size: 24px; color: white; background: linear-gradient(to right, #00796b, #004d40); margin: 35px 0 15px; padding-bottom: 8px; border-bottom: 2px solid #b2ebf2; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>AI 시대의 현명한 정보 활용 전략  &zwj; &zwj; </b></h2>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">지금까지 AI 챗봇과 웹사이트의 특징을 살펴봤는데요, 결국 중요한 건 <span style=\"background-color: #fff9c4; padding: 2px 4px; border-radius: 3px;\">어떤 도구를 어떻게 활용하느냐</span>인 것 같아요. 저는 개인적으로 이렇게 정보 활용 전략을 세웠어요.</p>\n<div style=\"background-color: #e0f2f7; border-left: 4px solid #4dd0e1; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\"><b>  알아두세요!</b><br />AI 챗봇이 제공하는 정보는 1차적인 참고 자료로 활용하고, 최종적인 판단이나 중요한 결정은 반드시 공신력 있는 웹사이트나 전문가의 도움을 받는 것이 안전해요.</div>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"font-size: 24px; color: white; background: linear-gradient(to right, #00796b, #004d40); margin: 35px 0 15px; padding-bottom: 8px; border-bottom: 2px solid #b2ebf2; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>실전 예시: 논문 자료 찾기  </b></h2>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">제가 최근에 블로그 글을 쓰면서 '데이터 시각화 트렌드'에 대한 논문 자료가 필요했던 적이 있어요. 이때 제가 어떻게 정보를 찾아봤는지 예시를 들어볼게요.</p>\n<div style=\"background-color: #e0f7fa; padding: 18px; border-radius: 8px; margin: 20px 0; border: 1px solid #b2ebf2;\">\n<h3 style=\"font-size: 20px; color: #333; margin: 0 0 12px;\" data-ke-size=\"size23\"><b>사례: 논문 자료 탐색 과정</b></h3>\n<ul style=\"margin: 0 0 15px 20px; padding: 0;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 6px;\">1단계: <span style=\"background-color: #fffde7; padding: 2px 4px; border-radius: 3px;\">AI 챗봇에게 질문</span> - \"데이터 시각화 최신 트렌드 논문 검색 키워드 알려줘\"</li>\n<li style=\"margin-bottom: 0;\">2단계: <span style=\"background-color: #fffde7; padding: 2px 4px; border-radius: 3px;\">키워드 조합 후 학술 검색 사이트 이동</span> - 챗봇이 추천해준 키워드를 바탕으로 Google Scholar, RISS 같은 학술 검색 사이트에 접속</li>\n</ul>\n<h3 style=\"font-size: 20px; color: #333; margin: 18px 0 12px;\" data-ke-size=\"size23\"><b>계산 과정</b></h3>\n<p style=\"margin-bottom: 8px;\" data-ke-size=\"size16\">1) 첫 번째 단계: 검색 결과에서 <span style=\"background-color: #fffde7; padding: 2px 4px; border-radius: 3px;\">제목과 초록을 읽고 관련성 높은 논문 선별</span></p>\n<p style=\"margin-bottom: 8px;\" data-ke-size=\"size16\">2) 두 번째 단계: 선별된 논문의 <span style=\"background-color: #fffde7; padding: 2px 4px; border-radius: 3px;\">본문 전체를 읽고 필요한 데이터와 주장 추출</span></p>\n<h3 style=\"font-size: 20px; color: #333; margin: 18px 0 12px;\" data-ke-size=\"size23\"><b>최종 결과</b></h3>\n<p style=\"margin-bottom: 8px;\" data-ke-size=\"size16\">- 결과 항목 1: AI 챗봇 덕분에 <span style=\"background-color: #fffde7; padding: 2px 4px; border-radius: 3px;\">초기 검색 시간 절약</span> (방향성 제시)</p>\n<p style=\"margin-bottom: 0;\" data-ke-size=\"size16\">- 결과 항목 2: 전문 웹사이트를 통해 <span style=\"background-color: #fffde7; padding: 2px 4px; border-radius: 3px;\">신뢰할 수 있는 심층 정보 확보</span> (정확성 보장)</p>\n</div>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">이처럼 AI 챗봇은 정보 탐색의 시작점을 제공하고, 전문 웹사이트는 그 정보를 심화하고 검증하는 역할을 해준다고 생각해요. 두 가지를 함께 활용하면 훨씬 효율적이고 정확하게 정보를 얻을 수 있답니다!</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"font-size: 24px; color: white; background: linear-gradient(to right, #00796b, #004d40); margin: 35px 0 15px; padding-bottom: 8px; border-bottom: 2px solid #b2ebf2; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>마무리: 핵심 내용 요약  </b></h2>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">오늘 우리는 AI 챗봇과 웹사이트 중 어떤 정보원을 더 신뢰해야 할지에 대해 이야기해 봤어요. 두 가지 모두 중요한 정보원이지만, 각자의 역할과 장단점을 이해하고 현명하게 활용하는 것이 가장 중요해요.</p>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">궁금한 점이 있다면 언제든지 댓글로 물어봐주세요! 여러분의 현명한 정보 생활을 응원합니다~  </p>\n<div style=\"border-top: 1px dashed #e0e0e0; margin: 30px 0;\">&nbsp;</div>\n<div>\n<style>\n    .single-summary-card-container {\n        display: flex;\n        justify-content: center;\n        align-items: center;\n        padding: 20px 10px;\n        background-color: #e0f7fa; /* Light Teal for container background */\n        margin: 20px 0;\n    }\n    .single-summary-card {\n        width: 100%;\n        max-width: 700px;\n        /* aspect-ratio: 16 / 9; */ /* 모바일 반응형을 위해 제거 */\n        background-color: #ffffff;\n        border-radius: 12px;\n        box-shadow: 0 6px 18px rgba(0,0,0,0.12);\n        padding: 25px;\n        display: flex;\n        flex-direction: column;\n        overflow: hidden;\n        border: 1px solid #b2ebf2; /* Teal border for card */\n        box-sizing: border-box; /* 패딩과 테두리가 요소의 전체 너비와 높이에 포함되도록 보장 */\n        height: auto; /* 기본 높이를 자동으로 설정하여 콘텐츠에 따라 유연하게 조절 */\n        min-height: unset; /* aspect-ratio로 인한 최소 높이 제한 해제 */\n    }\n    .single-summary-card .card-header {\n        display: flex;\n        align-items: center;\n        border-bottom: 2px solid #00796b; /* Dark Teal border for header */\n        padding-bottom: 12px;\n        margin-bottom: 12px;\n    }\n    .single-summary-card .card-header-icon {\n        font-size: 34px;\n        color: #00796b; /* Dark Teal icon */\n        margin-right: 14px;\n    }\n    .single-summary-card .card-header h3 {\n        font-size: 26px;\n        color: #00796b; /* Dark Teal header text */\n        margin: 0;\n        line-height: 1.3;\n        font-weight: 700;\n    }\n    .single-summary-card .card-content {\n        flex-grow: 1;\n        display: flex;\n        flex-direction: column;\n        justify-content: space-around;\n        font-size: 17px;\n        line-height: 1.65;\n        color: #333; /* Main text color */\n    }\n    .single-summary-card .card-content .section {\n        margin-bottom: 10px;\n    }\n    .single-summary-card .card-content strong {\n        color: #004d40; /* Darker Teal for strong text */\n        font-weight: 600;\n    }\n    .single-summary-card .card-content .highlight {\n        background-color: #fff9c4; /* Yellow highlight as per original theme */\n        padding: 2px 6px;\n        border-radius: 3px;\n        font-weight: bold;\n    }\n    .single-summary-card .card-content .formula {\n        background-color: #e0f7fa; /* Light Teal formula background */\n        padding: 6px 10px;\n        border-radius: 4px;\n        font-size: 0.9em;\n        text-align: center;\n        margin-top: 5px;\n        color: #004d40; /* Darkest Teal for formula text */\n    }\n    .single-summary-card .card-footer {\n        font-size: 14px;\n        color: #777;\n        text-align: center;\n        padding-top: 12px;\n        border-top: 1px dashed #b2ebf2; /* Light Teal dashed border for footer */\n        margin-top: auto;\n    }\n\n    /* 모바일 맞춤 조정: 768px 이하 */\n    @media (max-width: 768px) {\n        .single-summary-card {\n            padding: 18px;\n            height: auto;\n            min-height: unset;\n        }\n        .single-summary-card .card-header-icon {\n            font-size: 28px;\n            margin-right: 10px;\n        }\n        .single-summary-card .card-header h3 {\n            font-size: 20px;\n        }\n        .single-summary-card .card-content {\n            font-size: 15px;\n            line-height: 1.5;\n        }\n        .single-summary-card .card-content .section {\n            margin-bottom: 8px;\n        }\n        .single-summary-card .card-content .formula {\n            padding: 5px 8px;\n            font-size: 0.85em;\n        }\n        .single-summary-card .card-footer {\n            font-size: 13px;\n            padding-top: 10px;\n        }\n    }\n\n    /* 모바일 맞춤 조정: 480px 이하 */\n    @media (max-width: 480px) {\n        .single-summary-card {\n            padding: 15px;\n        }\n        .single-summary-card .card-header-icon {\n            font-size: 26px;\n        }\n        .single-summary-card .card-header h3 {\n            font-size: 18px;\n        }\n        .single-summary-card .card-content {\n            font-size: 14px;\n            line-height: 1.4;\n        }\n        .single-summary-card .card-content .section {\n            margin-bottom: 6px;\n        }\n        .single-summary-card .card-content .formula {\n            padding: 4px 6px;\n            font-size: 0.8em;\n        }\n        .single-summary-card .card-footer {\n            font-size: 12px;\n            padding-top: 8px;\n        }\n    }\n</style>\n</div>\n<div class=\"single-summary-card-container\">\n<div class=\"single-summary-card\">\n<div class=\"card-header\"><span class=\"card-header-icon\"> </span>\n<h3 data-ke-size=\"size23\">AI 챗봇 vs. 웹사이트: 현명한 정보 활용 가이드</h3>\n</div>\n<div class=\"card-content\">\n<div class=\"section\"><b>✨ AI 챗봇 활용법:</b> <span class=\"highlight\">빠른 정보 탐색, 아이디어 얻기</span>에 최적화! 질문에 대한 핵심 답변을 즉시 얻을 수 있어요.</div>\n<div class=\"section\"><b>  웹사이트 활용법:</b> <span class=\"highlight\">심층 학습, 검증된 정보 획득</span>에 필수! 특히 전문적인 지식이나 신뢰도가 중요한 정보는 웹사이트를 이용하는 것이 좋아요.</div>\n<div class=\"section\"><b>  현명한 정보 탐색 공식:</b>\n<div class=\"formula\">AI 챗봇 (빠른 정보) + 웹사이트 (심층 검증) = 정확하고 효율적인 정보 습득!</div>\n</div>\n<div class=\"section\"><b> &zwj;  기억할 점:</b> <span class=\"highlight\">교차 검증은 필수</span>! AI 챗봇의 정보는 참고용, 중요한 내용은 항상 공신력 있는 출처에서 확인하세요.</div>\n</div>\n<div class=\"card-footer\">이 가이드를 통해 온라인 정보의 바다에서 길을 잃지 않고 현명하게 항해하시길 바랍니다!</div>\n</div>\n</div>\n<h2 style=\"font-size: 24px; color: #00796b; margin: 35px 0 15px; padding-bottom: 8px; border-bottom: 2px solid #b2ebf2;\" data-ke-size=\"size26\"><b>자주 묻는 질문 ❓</b></h2>\n<div style=\"margin: 30px 0;\">\n<div style=\"margin-bottom: 20px; padding: 12px; background-color: #f9f9f9; border-radius: 6px; border: 1px solid #eeeeee;\">\n<div style=\"font-weight: bold; margin-bottom: 5px; color: #00796b;\">Q: AI 챗봇이 주는 정보는 믿을 수 없나요?</div>\n<div style=\"padding-left: 15px; color: #555;\">A: 아니요, 믿을 수 없는 것은 아니지만, <span style=\"background-color: #fff9c4; padding: 2px 4px; border-radius: 3px;\">항상 100% 정확하다고 볼 수는 없습니다.</span> 특히 사실 확인이 필요한 정보나 중요한 결정과 관련된 정보는 반드시 웹사이트를 통해 교차 검증하는 것이 좋습니다.</div>\n</div>\n<div style=\"margin-bottom: 20px; padding: 12px; background-color: #f9f9f9; border-radius: 6px; border: 1px solid #eeeeee;\">\n<div style=\"font-weight: bold; margin-bottom: 5px; color: #00796b;\">Q: 특정 분야의 전문 정보는 어디서 찾는 게 좋을까요?</div>\n<div style=\"padding-left: 15px; color: #555;\">A: <span style=\"background-color: #fff9c4; padding: 2px 4px; border-radius: 3px;\">해당 분야의 공신력 있는 기관, 학술 단체, 전문 연구소 등에서 운영하는 공식 웹사이트</span>를 이용하는 것이 가장 좋습니다. 이런 곳들은 정보의 정확성과 신뢰성이 높습니다.</div>\n</div>\n<div style=\"margin-bottom: 20px; padding: 12px; background-color: #f9f9f9; border-radius: 6px; border: 1px solid #eeeeee;\">\n<div style=\"font-weight: bold; margin-bottom: 5px; color: #00796b;\">Q: AI 챗봇과 웹사이트를 함께 활용하는 팁이 있나요?</div>\n<div style=\"padding-left: 15px; color: #555;\">A: 네! 챗봇에게는 <span style=\"background-color: #fff9c4; padding: 2px 4px; border-radius: 3px;\">간단한 질문이나 아이디어 얻기</span>를 요청하고, 챗봇이 제공한 키워드나 개념을 바탕으로 <span style=\"background-color: #fff9c4; padding: 2px 4px; border-radius: 3px;\">전문 웹사이트에서 심층 정보를 탐색하고 검증</span>하는 방식이 효율적입니다.</div>\n</div>\n<div style=\"margin-bottom: 20px; padding: 12px; background-color: #f9f9f9; border-radius: 6px; border: 1px solid #eeeeee;\">\n<div style=\"font-weight: bold; margin-bottom: 5px; color: #00796b;\">Q: 개인 블로그나 커뮤니티 정보는 어떻게 걸러내야 할까요?</div>\n<div style=\"padding-left: 15px; color: #555;\">A: 개인적인 의견이나 경험은 참고할 수 있지만, <span style=\"background-color: #fff9c4; padding: 2px 4px; border-radius: 3px;\">객관적인 사실 여부를 항상 의심하고 여러 출처를 통해 교차 검증</span>해야 합니다. 특히 중요한 정보일수록 더욱 신중해야 해요.</div>\n</div>\n<div style=\"margin-bottom: 20px; padding: 12px; background-color: #f9f9f9; border-radius: 6px; border: 1px solid #eeeeee;\">\n<div style=\"font-weight: bold; margin-bottom: 5px; color: #00796b;\">Q: 미래에는 AI 챗봇이 웹사이트를 완전히 대체할까요?</div>\n<div style=\"padding-left: 15px; color: #555;\">A: 가까운 미래에는 <span style=\"background-color: #fff9c4; padding: 2px 4px; border-radius: 3px;\">완전히 대체하기는 어려울 것으로 보입니다.</span> AI 챗봇은 빠른 정보 요약에 강점이 있지만, 웹사이트는 깊이 있는 전문성과 인간적인 통찰력을 제공하는 데 강점이 있어 서로 보완하는 형태로 발전할 가능성이 높습니다.</div>\n</div>\n</div>\n<script type=\"application/ld+json\">\n{\n    \"@context\": \"https://schema.org\",\n    \"@type\": \"FAQPage\",\n    \"mainEntity\": [\n        {\n            \"@type\": \"Question\",\n            \"name\": \"AI 챗봇이 주는 정보는 믿을 수 없나요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"  아니요, 믿을 수 없는 것은 아니지만, 항상 100% 정확하다고 볼 수는 없습니다. 특히 사실 확인이 필요한 정보나 중요한 결정과 관련된 정보는 반드시 웹사이트를 통해 교차 검증하는 것이 좋습니다.\"\n            }\n        },\n        {\n            \"@type\": \"Question\",\n            \"name\": \"특정 분야의 전문 정보는 어디서 찾는 게 좋을까요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"  해당 분야의 공신력 있는 기관, 학술 단체, 전문 연구소 등에서 운영하는 공식 웹사이트를 이용하는 것이 가장 좋습니다. 이런 곳들은 정보의 정확성과 신뢰성이 높습니다.\"\n            }\n        },\n        {\n            \"@type\": \"Question\",\n            \"name\": \"AI 챗봇과 웹사이트를 함께 활용하는 팁이 있나요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"  네! 챗봇에게는 간단한 질문이나 아이디어 얻기를 요청하고, 챗봇이 제공한 키워드나 개념을 바탕으로 전문 웹사이트에서 심층 정보를 탐색하고 검증하는 방식이 효율적입니다.\"\n            }\n        },\n        {\n            \"@type\": \"Question\",\n            \"name\": \"개인 블로그나 커뮤니티 정보는 어떻게 걸러내야 할까요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"  개인적인 의견이나 경험은 참고할 수 있지만, 객관적인 사실 여부를 항상 의심하고 여러 출처를 통해 교차 검증해야 합니다. 특히 중요한 정보일수록 더욱 신중해야 해요.\"\n            }\n        },\n        {\n            \"@type\": \"Question\",\n            \"name\": \"미래에는 AI 챗봇이 웹사이트를 완전히 대체할까요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"  가까운 미래에는 완전히 대체하기는 어려울 것으로 보입니다. AI 챗봇은 빠른 정보 요약에 강점이 있지만, 웹사이트는 깊이 있는 전문성과 인간적인 통찰력을 제공하는 데 강점이 있어 서로 보완하는 형태로 발전할 가능성이 높습니다.\"\n            }\n        }\n    ]\n}\n    </script>",
        "contentSnippet": "AI 챗봇 vs. 웹사이트, 어떤 정보원을 믿어야 할까요? 온라인 정보의 홍수 속에서 AI 챗봇과 웹사이트 중 어떤 정보원을 더 신뢰해야 할지 고민해 본 적 있으신가요? 이 글을 통해 두 정보원의 장단점을 비교하고, 현명하게 정보를 얻는 방법을 알려드릴게요.\n\n\n \n 요즘 저는 자료 조사를 할 때마다 AI 챗봇의 편리함에 감탄하고 있어요. 궁금한 점을 질문하면 순식간에 답을 해주니 정말 신기하죠? 그런데 문득 이런 생각이 들었어요. '과연 이 정보들을 어디까지 믿을 수 있을까?' 여러분도 저와 같은 고민을 해보셨을 것 같아요.\n \n인터넷이 발달하면서 정보의 양은 폭발적으로 늘었지만, 그만큼 어떤 정보가 진짜인지, 어떤 정보를 믿고 따라야 할지 혼란스러울 때가 많아요. 특히 AI 챗봇이 등장하면서 이 고민은 더 깊어진 것 같은데요. 웹사이트를 직접 찾아다니며 얻는 정보와, AI가 요약해주는 정보, 과연 어떤 쪽이 더 신뢰할 수 있을까요? 오늘 이 글에서는 AI 챗봇과 웹사이트의 장단점을 파헤쳐 보고, 여러분이 현명한 정보 탐색자가 될 수 있도록 저의 경험과 생각을 나눠볼까 합니다!  \n \nAI 챗봇, 빠르고 편리하지만...  \nAI 챗봇은 정말 편리해요. 제가 예전에 어떤 주제에 대해 찾아야 할 때, 여러 웹사이트를 일일이 방문하고 필요한 정보를 취합하느라 시간이 오래 걸렸거든요. 그런데 챗봇은 딱! 제가 원하는 질문에 대한 핵심 정보만 쏙쏙 뽑아주더라고요. 이게 바로 AI 챗봇의 가장 큰 장점 같아요. 정보 접근성이 뛰어나고, 답변 속도가 엄청 빠르다는 점이죠. 복잡한 내용을 간결하게 요약해주니 바쁜 현대인에게는 더할 나위 없이 좋고요.\n \n하지만 편리함 뒤에는 늘 그림자가 있는 법! AI 챗봇은 아직 완벽하지 않아요. 때로는 잘못된 정보를 알려주거나, 맥락에 맞지 않는 답변을 하기도 해요. 제가 경험한 바로는, 특정 주제에 대한 깊이 있는 정보를 찾을 때는 한계가 있더라고요. 예를 들어, 전문적인 의학 정보나 법률 자문 같은 민감한 분야에서는 챗봇의 답변을 맹신하기 어렵죠.\n  알아두세요!\nAI 챗봇은 방대한 데이터를 학습하지만, 그 데이터가 항상 최신이거나 100% 정확하다고 보장할 수는 없어요. 특히 논쟁의 여지가 있거나 빠르게 변화하는 정보는 꼭 교차 검증이 필요하답니다.\n \n전문 웹사이트, 깊이 있고 신뢰할 수 있지만...  \n그럼 전통적인 방식인 웹사이트는 어떨까요? 저는 예전부터 특정 분야의 정보를 찾을 때는 늘 권위 있는 기관이나 전문가가 운영하는 웹사이트를 선호했어요. 왜냐하면 그런 곳들은 정보의 출처가 명확하고, 내용에 대한 책임감을 가지고 작성하기 때문이죠. 예를 들어, 질병에 대한 정보를 찾을 때는 대한의사협회나 건강보험심사평가원 같은 공식 웹사이트를 찾아보는 것이 가장 확실하잖아요.\n \n웹사이트는 단순히 정보를 제공하는 것을 넘어, 때로는 특정 주제에 대한 깊이 있는 통찰력이나 다양한 관점을 제시하기도 해요. 저도 블로그를 운영하면서 제 경험과 생각을 담아 글을 쓰는데, 이런 글들이 다른 사람들에게 도움이 될 때 큰 보람을 느끼거든요. 잘 알려진 웹사이트는 특정 주제에 대한 전문가의 섬세한 의견을 제공할 수 있다는 점이 정말 매력적이에요.\nAI 챗봇 vs. 전문 웹사이트 비교\n구분\nAI 챗봇\n전문 웹사이트\n기타 정보\n\n\n\n\n정보 취득 속도\n매우 빠름 (즉각적인 답변)\n상대적으로 느림 (탐색 필요)\n빠른 검색이 필요한 경우\n\n\n정보 신뢰도\n주의 필요 (환각 현상 가능)\n높음 (전문가 검토, 출처 명시)\n중요 정보일수록 웹사이트 추천\n\n\n정보의 깊이\n요약 위주 (피상적일 수 있음)\n깊이 있는 정보, 다양한 관점\n전문 지식이 필요한 경우\n\n\n활용 분야\n빠른 질문, 아이디어 얻기\n심층 학습, 검증된 정보 획득\n용도에 맞게 선택\n\n\n\n⚠️ 주의하세요!\n웹사이트도 모든 정보가 100% 정확한 것은 아니에요. 특히 개인 블로그나 커뮤니티 게시글은 사실과 다른 정보가 있을 수 있으니, 항상 비판적인 시각으로 정보를 받아들이고 필요하다면 여러 출처를 확인하는 습관을 들이는 것이 중요해요.\n \n그렇다면, 현명한 정보 탐색법은?  \n결론적으로, AI 챗봇과 웹사이트는 서로를 완벽하게 대체할 수 없어요. 각자의 장단점이 명확하기 때문에, 상황에 맞게 적절히 활용하는 지혜가 필요하다고 생각해요. 제가 주로 쓰는 방법은 이렇습니다!\n  질문 유형별 정보원 선택 가이드\n정보 탐색 효율을 높이는 공식 = AI 챗봇(빠른 정보) + 웹사이트(심층 검증)\n제가 직접 시도해보며 얻은 정보 탐색 팁을 알려드릴게요:\n정보 유형별 솔루션\n기본 지식/정의 (Basic Knowledge/Definition):\n\n활용 도구: AI 챗봇 (1차), 웹사이트 (2차)\n활용 방법: AI 챗봇에게 먼저 물어 기본적인 개념과 핵심 키워드를 빠르게 파악하세요. 이후, 검색된 키워드를 활용하여 위키백과, 지식백과 또는 관련 전문 기관의 웹사이트에서 상세 정의와 배경 정보를 확인하고 이해를 심화하세요.\n최신 뉴스/이슈 (Current News/Issues):\n\n활용 도구: 주요 언론사 웹사이트, 뉴스 포털 (1차), AI 챗봇 (2차)\n활용 방법: 실시간성이 중요한 정보이므로, 신뢰할 수 있는 언론사의 공식 웹사이트나 주요 뉴스 포털을 직접 방문하여 사실 관계를 파악하는 것이 우선입니다. AI 챗봇은 해당 이슈의 간략한 요약이나 관련 질문을 던지는 데 활용할 수 있습니다.\n건강/의료 정보 (Health/Medical Information):\n\n활용 도구: 공식 의료기관 웹사이트, 전문의 웹사이트 (필수)\n활용 방법: 생명과 직결될 수 있는 정보이므로, 반드시 대학병원, 대한의사협회, 질병관리청 등 공신력 있는 기관의 웹사이트를 통해 정보를 얻어야 합니다. AI 챗봇의 답변은 참고용으로만 사용하고, 의심되는 내용은 반드시 전문가와 상담하세요.\n법률/재무 자문 (Legal/Financial Advice):\n\n활용 도구: 법무법인 웹사이트, 정부 법률/재무 정보 웹사이트 (필수)\n활용 방법: 전문성과 책임이 요구되는 분야이므로, 정부 법률정보센터, 금융감독원, 전문 법무법인/회계법인의 공식 웹사이트를 통해 정확한 정보를 확인해야 합니다. AI 챗봇은 관련 법률 용어의 정의나 기본적인 절차를 이해하는 데 보조적으로 활용할 수 있습니다.\n개인 의견/경험 (Personal Opinion/Experience):\n\n활용 도구: 개인 블로그, 커뮤니티, AI 챗봇\n활용 방법: 다양한 관점이나 실제 사용자 경험을 파악할 때 유용합니다. 하지만 주관적인 내용이 많으므로, 사실 여부는 반드시 다른 신뢰할 수 있는 출처를 통해 교차 검증해야 합니다. AI 챗봇은 여러 사람의 의견을 종합하거나 유사한 사례를 찾아보는 데 도움을 줄 수 있습니다.\nAI 시대의 현명한 정보 활용 전략  ‍ ‍ \n지금까지 AI 챗봇과 웹사이트의 특징을 살펴봤는데요, 결국 중요한 건 어떤 도구를 어떻게 활용하느냐인 것 같아요. 저는 개인적으로 이렇게 정보 활용 전략을 세웠어요.\n  알아두세요!\nAI 챗봇이 제공하는 정보는 1차적인 참고 자료로 활용하고, 최종적인 판단이나 중요한 결정은 반드시 공신력 있는 웹사이트나 전문가의 도움을 받는 것이 안전해요.\n \n실전 예시: 논문 자료 찾기  \n제가 최근에 블로그 글을 쓰면서 '데이터 시각화 트렌드'에 대한 논문 자료가 필요했던 적이 있어요. 이때 제가 어떻게 정보를 찾아봤는지 예시를 들어볼게요.\n사례: 논문 자료 탐색 과정\n1단계: AI 챗봇에게 질문 - \"데이터 시각화 최신 트렌드 논문 검색 키워드 알려줘\"\n2단계: 키워드 조합 후 학술 검색 사이트 이동 - 챗봇이 추천해준 키워드를 바탕으로 Google Scholar, RISS 같은 학술 검색 사이트에 접속\n계산 과정\n1) 첫 번째 단계: 검색 결과에서 제목과 초록을 읽고 관련성 높은 논문 선별\n2) 두 번째 단계: 선별된 논문의 본문 전체를 읽고 필요한 데이터와 주장 추출\n최종 결과\n- 결과 항목 1: AI 챗봇 덕분에 초기 검색 시간 절약 (방향성 제시)\n- 결과 항목 2: 전문 웹사이트를 통해 신뢰할 수 있는 심층 정보 확보 (정확성 보장)\n이처럼 AI 챗봇은 정보 탐색의 시작점을 제공하고, 전문 웹사이트는 그 정보를 심화하고 검증하는 역할을 해준다고 생각해요. 두 가지를 함께 활용하면 훨씬 효율적이고 정확하게 정보를 얻을 수 있답니다!\n \n마무리: 핵심 내용 요약  \n오늘 우리는 AI 챗봇과 웹사이트 중 어떤 정보원을 더 신뢰해야 할지에 대해 이야기해 봤어요. 두 가지 모두 중요한 정보원이지만, 각자의 역할과 장단점을 이해하고 현명하게 활용하는 것이 가장 중요해요.\n궁금한 점이 있다면 언제든지 댓글로 물어봐주세요! 여러분의 현명한 정보 생활을 응원합니다~  \n \n \nAI 챗봇 vs. 웹사이트: 현명한 정보 활용 가이드\n✨ AI 챗봇 활용법: 빠른 정보 탐색, 아이디어 얻기에 최적화! 질문에 대한 핵심 답변을 즉시 얻을 수 있어요.\n  웹사이트 활용법: 심층 학습, 검증된 정보 획득에 필수! 특히 전문적인 지식이나 신뢰도가 중요한 정보는 웹사이트를 이용하는 것이 좋아요.\n  현명한 정보 탐색 공식:\nAI 챗봇 (빠른 정보) + 웹사이트 (심층 검증) = 정확하고 효율적인 정보 습득!\n ‍  기억할 점: 교차 검증은 필수! AI 챗봇의 정보는 참고용, 중요한 내용은 항상 공신력 있는 출처에서 확인하세요.\n이 가이드를 통해 온라인 정보의 바다에서 길을 잃지 않고 현명하게 항해하시길 바랍니다!\n자주 묻는 질문 ❓\nQ: AI 챗봇이 주는 정보는 믿을 수 없나요?\nA: 아니요, 믿을 수 없는 것은 아니지만, 항상 100% 정확하다고 볼 수는 없습니다. 특히 사실 확인이 필요한 정보나 중요한 결정과 관련된 정보는 반드시 웹사이트를 통해 교차 검증하는 것이 좋습니다.\nQ: 특정 분야의 전문 정보는 어디서 찾는 게 좋을까요?\nA: 해당 분야의 공신력 있는 기관, 학술 단체, 전문 연구소 등에서 운영하는 공식 웹사이트를 이용하는 것이 가장 좋습니다. 이런 곳들은 정보의 정확성과 신뢰성이 높습니다.\nQ: AI 챗봇과 웹사이트를 함께 활용하는 팁이 있나요?\nA: 네! 챗봇에게는 간단한 질문이나 아이디어 얻기를 요청하고, 챗봇이 제공한 키워드나 개념을 바탕으로 전문 웹사이트에서 심층 정보를 탐색하고 검증하는 방식이 효율적입니다.\nQ: 개인 블로그나 커뮤니티 정보는 어떻게 걸러내야 할까요?\nA: 개인적인 의견이나 경험은 참고할 수 있지만, 객관적인 사실 여부를 항상 의심하고 여러 출처를 통해 교차 검증해야 합니다. 특히 중요한 정보일수록 더욱 신중해야 해요.\nQ: 미래에는 AI 챗봇이 웹사이트를 완전히 대체할까요?\nA: 가까운 미래에는 완전히 대체하기는 어려울 것으로 보입니다. AI 챗봇은 빠른 정보 요약에 강점이 있지만, 웹사이트는 깊이 있는 전문성과 인간적인 통찰력을 제공하는 데 강점이 있어 서로 보완하는 형태로 발전할 가능성이 높습니다.\n\n\n\n{\n    \"@context\": \"https://schema.org\",\n    \"@type\": \"FAQPage\",\n    \"mainEntity\": [\n        {\n            \"@type\": \"Question\",\n            \"name\": \"AI 챗봇이 주는 정보는 믿을 수 없나요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"  아니요, 믿을 수 없는 것은 아니지만, 항상 100% 정확하다고 볼 수는 없습니다. 특히 사실 확인이 필요한 정보나 중요한 결정과 관련된 정보는 반드시 웹사이트를 통해 교차 검증하는 것이 좋습니다.\"\n            }\n        },\n        {\n            \"@type\": \"Question\",\n            \"name\": \"특정 분야의 전문 정보는 어디서 찾는 게 좋을까요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"  해당 분야의 공신력 있는 기관, 학술 단체, 전문 연구소 등에서 운영하는 공식 웹사이트를 이용하는 것이 가장 좋습니다. 이런 곳들은 정보의 정확성과 신뢰성이 높습니다.\"\n            }\n        },\n        {\n            \"@type\": \"Question\",\n            \"name\": \"AI 챗봇과 웹사이트를 함께 활용하는 팁이 있나요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"  네! 챗봇에게는 간단한 질문이나 아이디어 얻기를 요청하고, 챗봇이 제공한 키워드나 개념을 바탕으로 전문 웹사이트에서 심층 정보를 탐색하고 검증하는 방식이 효율적입니다.\"\n            }\n        },\n        {\n            \"@type\": \"Question\",\n            \"name\": \"개인 블로그나 커뮤니티 정보는 어떻게 걸러내야 할까요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"  개인적인 의견이나 경험은 참고할 수 있지만, 객관적인 사실 여부를 항상 의심하고 여러 출처를 통해 교차 검증해야 합니다. 특히 중요한 정보일수록 더욱 신중해야 해요.\"\n            }\n        },\n        {\n            \"@type\": \"Question\",\n            \"name\": \"미래에는 AI 챗봇이 웹사이트를 완전히 대체할까요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"  가까운 미래에는 완전히 대체하기는 어려울 것으로 보입니다. AI 챗봇은 빠른 정보 요약에 강점이 있지만, 웹사이트는 깊이 있는 전문성과 인간적인 통찰력을 제공하는 데 강점이 있어 서로 보완하는 형태로 발전할 가능성이 높습니다.\"\n            }\n        }\n    ]\n}",
        "guid": "http://muzbox.tistory.com/483605",
        "categories": [
          "AI, 미래기술/AI 인사이트",
          "AI 시대",
          "AI 챗봇",
          "데이터 검증",
          "온라인 정보",
          "웹사이트",
          "전문가 의견",
          "정보 신뢰도",
          "정보 탐색",
          "정보 활용 전략",
          "정보의 질"
        ],
        "isoDate": "2025-06-11T00:45:41.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "제미나이 멀티모달로 고품질 맛집 블로그 콘텐츠 초고속 제작 방법, 무료 지침 공개",
        "link": "http://muzbox.tistory.com/483604",
        "pubDate": "Sun, 8 Jun 2025 14:28:03 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483604#entry483604comment",
        "content": "<p data-ke-size=\"size8\">&nbsp;</p>\n<div style=\"background-color: #e0f7fa; padding: 15px; border-radius: 8px; font-style: italic; margin-bottom: 25px; font-size: 15px; border: 1px solid #b2ebf2;\"><b>스마트폰 속 음식 사진, 블로그 수익으로 바꾸는 비법!</b> 용량 부족 걱정 없이 애드센스 수익까지 얻는 맛집 블로그, AI가 알아서 만들어줘요!</div>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1280\" data-origin-height=\"853\"><span data-url=\"https://blog.kakaocdn.net/dn/ccLAE3/btsOsO4nPt9/TZfczh3sQKgseiXJq3DeSK/img.webp\" data-phocus=\"https://blog.kakaocdn.net/dn/ccLAE3/btsOsO4nPt9/TZfczh3sQKgseiXJq3DeSK/img.webp\"><img src=\"https://blog.kakaocdn.net/dn/ccLAE3/btsOsO4nPt9/TZfczh3sQKgseiXJq3DeSK/img.webp\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FccLAE3%2FbtsOsO4nPt9%2FTZfczh3sQKgseiXJq3DeSK%2Fimg.webp\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"고품질 맛집 블로그 콘텐츠 초고속 제작 방법\" loading=\"lazy\" width=\"1280\" height=\"853\" data-origin-width=\"1280\" data-origin-height=\"853\"/></span></figure>\n</p>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">&nbsp;스마트폰에 쌓여만 가는 수많은 음식 사진들, 용량 부족 경고가 뜨면 결국 아깝지만 지워야 하죠?   그런데 이 사진들을 전문적인 맛집 블로그로 올리고, 여기에 애드센스 수익까지 얻는다면 금상첨화 아닐까요? 지금 보고 계신 이 블로그 포스팅처럼 말이죠!</p>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">놀라지 마세요. 이 모든 걸 이번에도 <span style=\"background-color: #fff9c4; padding: 2px 4px; border-radius: 3px;\">제미나이</span>로 가능합니다! 제가 지난번에 제미나이를 활용한 초고속 블로그 글쓰기 영상을 올렸는데요, 정말 많은 분들이 \"실제로 그 지침을 어떻게 만드는지\" 알고 싶다고 하셔서 이번에는 그 비하인드를 공개하는 심화 강의를 준비했습니다.  </p>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">우리가 AI와 효과적으로 대화하기 위해서는 그저 \"맛집 글 써줘\"라고 하는 것보다 훨씬 더 체계적인 접근이 필요해요. 정확한 지시와 명확한 가이드라인이 있어야 원하는 결과를 얻을 수 있죠. 그래서 오늘은 이 특별한 '젬 지침'을 만드는 과정까지 여러분께 낱낱이 공개하려고 합니다! 그리고 이번 지침의 핵심에는 단순 글쓰기가 아닌 제미나이의 <span style=\"background-color: #fff9c4; padding: 2px 4px; border-radius: 3px;\">멀티모달 기능</span>이 있습니다. 이 기능이 왜 혁명적인지, 어떻게 하면 이를 최대한 활용할 수 있는지 함께 알아보겠습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"font-size: 24px; color: white; background: linear-gradient(to right, #00796b, #004d40); margin: 35px 0 15px; padding-bottom: 8px; border-bottom: 2px solid #b2ebf2; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>AI 멀티모달 기능의 이해와 활용  </b></h2>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">여러분, 예전 AI는 텍스트만 읽을 수 있었어요. 하지만 최근에는 많은 LLM 모델들이 사진도 보고, 영상도 이해하는 <span style=\"background-color: #fff9c4; padding: 2px 4px; border-radius: 3px;\">'멀티모달'</span> 능력을 갖추게 되었습니다. 마치 우리가 식당에서 메뉴를 선택할 때 사진과 설명을 함께 보는 것처럼요! 멀티모달이란 쉽게 말해서 다양한 형태의 정보를 동시에 이해하고 처리할 수 있는 인공지능 기술을 의미하는데요. 예를 들어 맛집 사진을 AI에게 보여주면, 예전의 AI는 \"이것은 사진입니다\"라고만 인식했지만, 멀티모달 기능이 있으면 \"이 사진은 식당 내부이고, 테이블 위에는 해물칼국수가 있으며, 옆에는 김치가 놓여있고, 사람들이 즐겁게 식사하고 있네요\"라고 더 자세하고 종합적으로 이해할 수 있게 된 거죠.</p>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">여기서 재미있는 점은 AI가 이제 <span style=\"background-color: #fff9c4; padding: 2px 4px; border-radius: 3px;\">'맥락'을 읽을 수 있다는 거예요.</span> 식당 내부 사진, 음식 사진, 메뉴판을 보고 \"아, 이건 맛집 리뷰를 위한 사진들이구나\"라고 파악합니다. 그래서 여러분이 찍은 맛집 사진을 몇 장만 넣어줘도 전문 블로거가 쓴 것 같은 리뷰를 뚝딱 만들어내는 것이 가능해진 겁니다.</p>\n<div style=\"background-color: #e0f2f7; border-left: 4px solid #4dd0e1; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\"><b>  알아두세요!</b><br />AI가 아무리 똑똑해도 여러분의 머릿속 생각을 알아서 척척 맞춰주진 않아요. 구체적인 지시가 없으면, 기대한 결과가 나오기 어렵습니다.</div>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"font-size: 24px; color: white; background: linear-gradient(to right, #00796b, #004d40); margin: 35px 0 15px; padding-bottom: 8px; border-bottom: 2px solid #b2ebf2; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>프롬프트 엔지니어링의 중요성 (기본적인 시도와 한계)  </b></h2>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">자, 이제 기본적인 방법으로 한번 시도해보겠습니다. 제가 천안에 사는데, 최근에 방문한 회사 근처 <span style=\"background-color: #fff9c4; padding: 2px 4px; border-radius: 3px;\">\"성거산 시골 막국수\"</span>라는 곳의 사진 일곱 장을 준비했습니다. 이 사진들을 제미나이에 업로드하고 간단하게 \"이 사진들로 맛집 블로그 포스팅을 작성해줘\"라고 요청해보겠습니다. 천안 오시면 꼭 한 번 방문해 보세요. 맛있어요!!</p>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">음... 나쁘지 않지만 뭔가 아쉬워요. '성거산 막국수: 막국수와 찰떡궁합 보쌈 맛집!'이라는 제목으로 기본적인 정보는 잘 담았지만, 뭔가 차별화된 느낌이 부족합니다. '식당은 넓은 주차 공간을 갖추고 있어, 차량으로 방문하기에 정말 편리했어요' '내부로 들어서니 생각보다 훨씬 넓고 쾌적한 공간이 펼쳐졌습니다'처럼 정보는 있지만 독자의 감성을 자극하는 생생한 묘사가 부족하죠.</p>\n<table style=\"width: 100%; border-collapse: collapse; margin: 20px 0;\" data-ke-align=\"alignLeft\">\n<thead>\n<tr>\n<th style=\"padding: 14px; text-align: left; border: 1px solid #e0e0e0; background-color: #e0f7fa; font-weight: bold;\">구분</th>\n<th style=\"padding: 14px; text-align: left; border: 1px solid #e0e0e0; background-color: #e0f7fa; font-weight: bold;\">설명</th>\n<th style=\"padding: 14px; text-align: left; border: 1px solid #e0e0e0; background-color: #e0f7fa; font-weight: bold;\">기대 효과</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"padding: 14px; text-align: left; border: 1px solid #e0e0e0;\">명확한 역할 부여</td>\n<td style=\"padding: 14px; text-align: left; border: 1px solid #e0e0e0;\">\"너는 지금부터 맛집 블로거야!\"</td>\n<td style=\"padding: 14px; text-align: left; border: 1px solid #e0e0e0;\">글의 톤앤매너와 방향 설정</td>\n</tr>\n<tr style=\"background-color: #f5f5f5;\">\n<td style=\"padding: 14px; text-align: left; border: 1px solid #e0e0e0;\">구체적인 목표 제시</td>\n<td style=\"padding: 14px; text-align: left; border: 1px solid #e0e0e0;\">\"사진 분석해서 생생한 맛집 리뷰 써줘.\"</td>\n<td style=\"padding: 14px; text-align: left; border: 1px solid #e0e0e0;\">AI가 나아가야 할 명확한 길 제시</td>\n</tr>\n<tr>\n<td style=\"padding: 14px; text-align: left; border: 1px solid #e0e0e0;\">결과 형식 지정</td>\n<td style=\"padding: 14px; text-align: left; border: 1px solid #e0e0e0;\">\"HTML 코드로, 특정 스타일 적용해서.\"</td>\n<td style=\"padding: 14px; text-align: left; border: 1px solid #e0e0e0;\">일관성 있고 사용 가능한 결과물 도출</td>\n</tr>\n</tbody>\n</table>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">이럴 때 <span style=\"background-color: #fff9c4; padding: 2px 4px; border-radius: 3px;\">프롬프트 엔지니어링</span>이 효과적인 것이죠. 프롬프트 엔지니어링은 AI에게 어떤 요청을 할 때, 원하는 결과물을 얻기 위해 질문이나 요청을 효과적으로 설계하는 기술입니다. 간단히 말해 AI와 잘 소통하는 방법을 찾는 거죠. 프롬프트 엔지니어링의 핵심은 AI에게 명확한 역할, 목표, 형식을 제공하는 것입니다. 이 프롬프트 엔지니어링을 기반으로 젬 지침을 만드는 것이죠.</p>\n<div style=\"background-color: #fffde7; border-left: 4px solid #fbc02d; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\"><b>⚠️ 주의하세요!</b><br />AI가 아무리 똑똑해도 여러분의 머릿속 생각을 알아서 척척 맞춰주지 않습니다. 구체적인 지시가 없으면, 기대한 결과가 나오기 어렵다는 점을 꼭 기억하세요!</div>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"font-size: 24px; color: white; background: linear-gradient(to right, #00796b, #004d40); margin: 35px 0 15px; padding-bottom: 8px; border-bottom: 2px solid #b2ebf2; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>Google AI Studio 활용 (젬 지침 제작 환경)  </b></h2>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">오늘 저는 이 젬 지침을 제미나이 2.5 모델을 이용해 만들려고 합니다. 하지만 제미나이 사이트가 아닌 <span style=\"background-color: #fff9c4; padding: 2px 4px; border-radius: 3px;\">AI Studio</span>라는 곳에서 지침을 만들게요.</p>\n<div style=\"background-color: #e0f7fa; padding: 18px; border-radius: 8px; margin: 20px 0; border: 1px solid #b2ebf2;\">\n<h3 style=\"font-size: 20px; color: #333; margin: 0 0 12px;\" data-ke-size=\"size23\"><b>  AI Studio는?</b></h3>\n<p style=\"margin-bottom: 0;\" data-ke-size=\"size16\"><b>Google AI Studio</b>는 구글에서 제공하는 개발자 친화적인 플랫폼으로, AI 모델을 더 세밀하게 제어하고 실험할 수 있는 공간입니다. 개발자, 학생, 연구자들이 프롬프트를 테스트하고 최적화하며, API 통합까지 준비할 수 있는 전문적인 환경이죠. AI Studio도 무료로 사용할 수 있습니다.</p>\n</div>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">특히 구글의 다양한 최신 AI 모델들을 가장 빨리 만날 수 있으니, 영상 설명란의 링크로 접속하셔서, 다양한 경험을 해 보세요. 흥미로운 사실은, 제가 이번에는 파라미터 조정 없이 기본값으로 진행했는데도 일반 제미나이와 결과가 달랐다는 점입니다. 왜 그럴까요?</p>\n<div style=\"background-color: #e0f7fa; padding: 18px; border-radius: 8px; margin: 20px 0; border: 1px solid #b2ebf2;\">\n<h3 style=\"font-size: 20px; color: #333; margin: 0 0 12px;\" data-ke-size=\"size23\"><b>AI Studio vs. 일반 제미나이 차이점</b></h3>\n<p style=\"margin-bottom: 8px;\" data-ke-size=\"size16\">1) 첫 번째 단계: AI Studio는 기본 Temperature(창의성) 값이 1.0으로 설정되어 있어 더 다양하고 창의적인 결과물 생성</p>\n<p style=\"margin-bottom: 8px;\" data-ke-size=\"size16\">2) 두 번째 단계: 일반 제미나이는 일관된 답변을 위해 이 값을 더 낮게 설정 가능</p>\n<p style=\"margin-bottom: 0;\" data-ke-size=\"size16\">&rarr; AI Studio는 모델의 '날 것 그대로'의 동작을 확인하고 제어하는 데 중점을 둡니다. 따라서, 전문적인 콘텐츠 제작이나 복잡한 지침을 만들 때는 AI Studio에서 작업하는 것을 추천합니다.</p>\n</div>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"font-size: 24px; color: white; background: linear-gradient(to right, #00796b, #004d40); margin: 35px 0 15px; padding-bottom: 8px; border-bottom: 2px solid #b2ebf2; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>맛집 블로그 프롬프트 제작 과정 (1차 및 2차 수정)  &zwj; &zwj; </b></h2>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">자, 이제 본격적으로 맛집 블로그용 지침을 만들어 보겠습니다! AI STUDIO에 방문하신 후 우측에서 최신 AI 모델을 선택합니다. 아까 얘기한 것처럼 하단에 파라메터는 그대로 두고 첫 번째 프롬프트를 입력할게요. \"사용자 입력 정보와 사진을 기반으로 멀티모달 기능을 최대한 활용하여 구글 상위노출에 최적화된 맛집탐방 블로그 기사를 생성하고 그 결과물을 HTML 코드로 생성하는 젬 지침을 만들어\" 라고 요청하면 바로 맛집 블로거를 위한 지침을 생성합니다.</p>\n<div style=\"background-color: #e0f2f7; border-left: 4px solid #4dd0e1; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\"><b>  알아두세요!</b><br />1차 요청에서는 사용자에게 너무 많은 정보를 요구했습니다. 식당명, 주소, 키워드, 한 줄 평 등. 편리하게 쓰려고 AI를 활용하는데, 정보 입력에 시간을 다 쓰면 본말이 전도됩니다.</div>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">그래서 두 번째 요청에서는 복잡한 질문만 단순화했습니다. \"사용자에게 묻는 질문이 너무 많아. 처음에 식당명/지역, 주문음식/추가음식, 주변음식/반찬, 후식, 방문배경, 사진을 요청하면서 시작하고, 사용자가 입력을 하면 나머지 정보는 사진을 분석해서 대신 작성하게 지침을 수정해\" 이런 식으로 사용자가 5가지 질문과 사진 업로드만으로 맛집 블로그를 작성할 수 있도록 만들었어요. 중요한 점은, 제미나이의 멀티모달 기능을 활용해 사진을 직접 분석하여 블로그 내용에 반영하도록 한 것이죠.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"font-size: 24px; color: white; background: linear-gradient(to right, #00796b, #004d40); margin: 35px 0 15px; padding-bottom: 8px; border-bottom: 2px solid #b2ebf2; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>젬 지침 등록 및 테스트  </b></h2>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">자, 이렇게 해서 나온 2차 결과물을, 제미나이로 돌아가서 젬 지침에 등록을 하고, 결과를 확인해볼게요. 젬 관리자의 샘 젬 만들기에서 예를 들어 제목을 \"맛집 블로그 전문가\"라고 입력을 합니다.</p>\n<div style=\"background-color: #e0f7fa; padding: 18px; border-radius: 8px; margin: 20px 0; border: 1px solid #b2ebf2;\">\n<h3 style=\"font-size: 20px; color: #333; margin: 0 0 12px;\" data-ke-size=\"size23\"><b>사례 주인공의 상황: '성거산 시골 막국수' 테스트</b></h3>\n<ul style=\"margin: 0 0 15px 20px; padding: 0;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 6px;\">1. 식당명/지역: 천안 성거, 성거산 시골 막국수</li>\n<li style=\"margin-bottom: 0;\">2. 주문음식/추가음식: 비빔 막국수와 수육</li>\n</ul>\n<h3 style=\"font-size: 20px; color: #333; margin: 18px 0 12px;\" data-ke-size=\"size23\"><b>계산 과정: 간편한 입력으로 결과 확인</b></h3>\n<p style=\"margin-bottom: 8px;\" data-ke-size=\"size16\">1) 3. 주변 음식/반찬: 주변 음식 코너가 따로 있고 셀프임</p>\n<p style=\"margin-bottom: 8px;\" data-ke-size=\"size16\">2) 4. 후식: 후식 없음</p>\n<h3 style=\"font-size: 20px; color: #333; margin: 18px 0 12px;\" data-ke-size=\"size23\"><b>최종 결과: 블로그 글 자동 생성!</b></h3>\n<p style=\"margin-bottom: 8px;\" data-ke-size=\"size16\">- 5. 방문배경: 5월 중순 26도의 이른 더위 점심시간. 팀원들과 점심 식사</p>\n<p style=\"margin-bottom: 0;\" data-ke-size=\"size16\">- 사진 업로드 &rarr; AI가 알아서 블로그 글 생성</p>\n</div>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">이런 식으로 결과를 확인하고 수정할 부분을 계속해서 AI와 대화를 해 나가면서 완성형으로 만들어 가는 것입니다. 완벽한 결과물은 처음부터 나오지 않습니다. AI와 지속적인 대화를 통해 결과를 확인하고 수정해나가는 <span style=\"background-color: #fff9c4; padding: 2px 4px; border-radius: 3px;\">'반복 최적화'</span> 과정이 핵심입니다. 제가 이전 영상에서 공유해드린 지침들도 수십 번의 시행착오와 세밀한 조정을 거쳐 완성된 것들이랍니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"font-size: 24px; color: white; background: linear-gradient(to right, #00796b, #004d40); margin: 35px 0 15px; padding-bottom: 8px; border-bottom: 2px solid #b2ebf2; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>결과물 개선 (HTML 구조 및 디자인 문제점 해결)  </b></h2>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">자, 지금 우리가 받은 결과물을 살펴보면 세 가지 중요한 문제점이 보입니다. 이런 세부 사항들이 블로그 포스팅의 품질을 좌우하게 됩니다.</p>\n<ol style=\"margin: 0 0 15px 20px; padding: 0;\" data-ke-list-type=\"decimal\">\n<li style=\"margin-bottom: 8px;\"><b>HTML 코드 생성 문제:</b> HTML 코드가 코드 블록 안에 제대로 생성되지 않았습니다.</li>\n<li style=\"margin-bottom: 8px;\"><b>불완전한 HTML 구조:</b> HTML이 완전한 형태의 웹페이지 구조(HTML, HEAD, BODY 태그 포함)로 표시되고 있습니다. 이는 블로그에 붙여넣을 때 구조적 충돌을 일으킵니다. 블로그 플랫폼은 이미 이 태그들을 가지고 있기 때문이죠.</li>\n<li style=\"margin-bottom: 8px;\"><b>H1 태그 중복 문제:</b> 블로그 플랫폼에서는 제목을 별도로 입력하는 필드가 있기 때문에, 본문 내에 H1 태그가 있으면 중복 제목이 생겨 SEO에 좋지 않고 디자인도 깨질 수 있습니다.</li>\n</ol>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">이런 경우, AI에게 '<span style=\"background-color: #fff9c4; padding: 2px 4px; border-radius: 3px;\">블로그 본문에 추가해야 하므로 헤드, 바디 태그와 에이치원 태그가 없는 인라인 스타일로 변경해주세요. 제목은 별도로 입력할 것입니다.</span>'라고 요청하세요. 그러면 블로그 플랫폼에 바로 붙여넣을 수 있는 최적화된 HTML 코드를 받을 수 있습니다. 위의 2가지 문제 개선을 위해, 1. 이 지침의 출력물 중 HTML 코드로 생성되는 결과물은 \"코드 블록\"으로 출력해, 2. 블로그 본문에 추가해야 하므로 헤드, 바디 태그와 에이치원 태그가 없는 인라인 스타일로 변경해. 라고 다시 지침 수정을 요청합니다.</p>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">자, 수정된 지침으로 생성된 결과물을 보면 인라인 스타일의 에이치티엠엘 코드가 코드블록에서 생성되는 것을 확인할 수 있습니다. 그런데 이번엔 디자인이 별로입니다. 이럴 때는 \"좀 더 시각화된 결과물이 나올 수 있게 디자인을 개선해줘\" 또는 구체적인 디자인 지침을 주거나 이전 영상에서 소개한 디자인 템플릿을 업로드하고 \"첨부 디자인 스타일로 반영되게 수정해\"라고 요청하셔도 될 거 같습니다. 아, 그리고 디자인만 보시려면, 젬을 수정할 필요 없이, AI STUDIO의 수정된 지침의 코드만 복사해서 <span style=\"background-color: #fff9c4; padding: 2px 4px; border-radius: 3px;\">코드펜</span>으로 가서 확인하면 됩니다.</p>\n<div style=\"border-top: 1px dashed #e0e0e0; margin: 30px 0;\">&nbsp;</div>\n<div>\n<style>\n        .single-summary-card-container {\n            display: flex;\n            justify-content: center;\n            align-items: center;\n            padding: 20px 10px;\n            background-color: #e0f7fa; /* Light Teal for container background */\n            margin: 20px 0;\n        }\n        .single-summary-card {\n            width: 100%;\n            max-width: 700px;\n            /* aspect-ratio: 16 / 9; */ /* 모바일 반응형을 위해 제거 */\n            background-color: #ffffff;\n            border-radius: 12px;\n            box-shadow: 0 6px 18px rgba(0,0,0,0.12);\n            padding: 25px;\n            display: flex;\n            flex-direction: column;\n            overflow: hidden;\n            border: 1px solid #b2ebf2; /* Teal border for card */\n            box-sizing: border-box; /* 패딩과 테두리가 요소의 전체 너비와 높이에 포함되도록 보장 */\n            height: auto; /* 기본 높이를 자동으로 설정하여 콘텐츠에 따라 유연하게 조절 */\n            min-height: unset; /* aspect-ratio로 인한 최소 높이 제한 해제 */\n        }\n        .single-summary-card .card-header {\n            display: flex;\n            align-items: center;\n            border-bottom: 2px solid #00796b; /* Dark Teal border for header */\n            padding-bottom: 12px;\n            margin-bottom: 12px;\n        }\n        .single-summary-card .card-header-icon {\n            font-size: 34px;\n            color: #00796b; /* Dark Teal icon */\n            margin-right: 14px;\n        }\n        .single-summary-card .card-header h3 {\n            font-size: 26px;\n            color: #00796b; /* Dark Teal header text */\n            margin: 0;\n            line-height: 1.3;\n            font-weight: 700;\n        }\n        .single-summary-card .card-content {\n            flex-grow: 1;\n            display: flex;\n            flex-direction: column;\n            justify-content: space-around;\n            font-size: 17px;\n            line-height: 1.65;\n            color: #333; /* Main text color */\n        }\n        .single-summary-card .card-content .section {\n            margin-bottom: 10px;\n        }\n        .single-summary-card .card-content strong {\n            color: #004d40; /* Darker Teal for strong text */\n            font-weight: 600;\n        }\n        .single-summary-card .card-content .highlight {\n            background-color: #fff9c4; /* Yellow highlight as per original theme */\n            padding: 2px 6px;\n            border-radius: 3px;\n            font-weight: bold;\n        }\n        .single-summary-card .card-content .formula {\n            background-color: #e0f7fa; /* Light Teal formula background */\n            padding: 6px 10px;\n            border-radius: 4px;\n            font-size: 0.9em;\n            text-align: center;\n            margin-top: 5px;\n            color: #004d40; /* Darkest Teal for formula text */\n        }\n        .single-summary-card .card-footer {\n            font-size: 14px;\n            color: #777;\n            text-align: center;\n            padding-top: 12px;\n            border-top: 1px dashed #b2ebf2; /* Light Teal dashed border for footer */\n            margin-top: auto;\n        }\n\n        /* 모바일 맞춤 조정 */\n        @media (max-width: 768px) {\n            .single-summary-card {\n                padding: 18px; /* 작은 화면을 위해 패딩을 약간 줄임 */\n                height: auto; /* 콘텐츠에 맞춰 높이 자동 조절 */\n                min-height: unset; /* aspect-ratio로 인한 최소 높이 제한 해제 */\n            }\n            .single-summary-card .card-header-icon {\n                font-size: 28px; /* 모바일에서 아이콘 크기 조정 */\n                margin-right: 10px;\n            }\n            .single-summary-card .card-header h3 {\n                font-size: 20px; /* 모바일에서 헤더 제목 글꼴 크기 조정 */\n            }\n            .single-summary-card .card-content {\n                font-size: 15px; /* 모바일에서 내용 글꼴 크기 조정 */\n                line-height: 1.5;\n            }\n            .single-summary-card .card-content .section {\n                margin-bottom: 8px; /* 모바일에서 섹션 간 간격 조정 */\n            }\n            .single-summary-card .card-content .formula {\n                padding: 5px 8px; /* 수식 글꼴 크기 조정 */\n                font-size: 0.85em;\n            }\n            .single-summary-card .card-footer {\n                font-size: 13px; /* 모바일에서 푸터 글꼴 크기 조정 */\n                padding-top: 10px;\n            }\n        }\n\n        @media (max-width: 480px) {\n            .single-summary-card {\n                padding: 15px; /* 매우 작은 화면을 위해 패딩 더 줄임 */\n            }\n            .single-summary-card .card-header-icon {\n                font-size: 26px;\n            }\n            .single-summary-card .card-header h3 {\n                font-size: 18px;\n            }\n            .single-summary-card .card-content {\n                font-size: 14px;\n                line-height: 1.4;\n            }\n            .single-summary-card .card-content .section {\n                margin-bottom: 6px;\n            }\n            .single-summary-card .card-content .formula {\n                padding: 4px 6px;\n                font-size: 0.8em;\n            }\n            .single-summary-card .card-footer {\n                font-size: 12px;\n                padding-top: 8px;\n            }\n        }\n    </style>\n</div>\n<div class=\"single-summary-card-container\">\n<div class=\"single-summary-card\">\n<div class=\"card-header\"><span class=\"card-header-icon\"> </span>\n<h3 data-ke-size=\"size23\">맛집 블로그 생성 지침 핵심 요약!</h3>\n</div>\n<div class=\"card-content\">\n<div class=\"section\"><b>✨ 프롬프트 엔지니어링:</b> <span class=\"highlight\">AI와 잘 소통하는 기술.</span> 명확한 역할, 목표, 형식을 제공하여 원하는 결과물을 얻는 것이 핵심이죠.</div>\n<div class=\"section\"><b>  멀티모달 기능 활용:</b> <span class=\"highlight\">사진을 직접 분석해서 생생한 리뷰를 작성</span>하도록 지시! 단순히 텍스트를 생성하는 것을 넘어, 시각 정보까지 통합하여 블로그 글의 퀄리티를 높입니다.</div>\n<div class=\"section\"><b>  HTML 구조 및 디자인 최적화:</b>\n<div class=\"formula\">HTML = (SEO 최적화) + (인라인 스타일) + (H1 태그 제외)</div>\n</div>\n<div class=\"section\"><b> &zwj;  반복 최적화의 중요성:</b> <span class=\"highlight\">완벽한 결과물은 한 번에 나오지 않아요!</span> AI와 지속적으로 대화하고, 결과를 수정하며 더 나은 지침을 만들어가는 과정이 필요합니다.</div>\n</div>\n<div class=\"card-footer\">이 지침으로 여러분도 전문 맛집 블로거로 거듭나세요!  </div>\n</div>\n</div>\n<h2 style=\"font-size: 24px; color: #00796b; margin: 35px 0 15px; padding-bottom: 8px; border-bottom: 2px solid #b2ebf2;\" data-ke-size=\"size26\"><b>자주 묻는 질문 ❓</b></h2>\n<div style=\"margin: 30px 0;\">\n<div style=\"margin-bottom: 20px; padding: 12px; background-color: #f9f9f9; border-radius: 6px; border: 1px solid #eeeeee;\">\n<div style=\"font-weight: bold; margin-bottom: 5px; color: #00796b;\">Q: 제미나이 멀티모달 기능은 어떤 점에서 혁신적인가요?</div>\n<div style=\"padding-left: 15px; color: #555;\">A:   예전 AI는 텍스트만 이해했지만, 멀티모달 기능은 사진, 영상 등 다양한 형태의 정보를 동시에 이해하고 처리할 수 있어, AI가 맥락을 파악하고 더 풍부하고 정확한 콘텐츠를 생성할 수 있게 합니다.</div>\n</div>\n<div style=\"margin-bottom: 20px; padding: 12px; background-color: #f9f9f9; border-radius: 6px; border: 1px solid #eeeeee;\">\n<div style=\"font-weight: bold; margin-bottom: 5px; color: #00796b;\">Q: AI Studio를 사용하는 이유가 무엇인가요?</div>\n<div style=\"padding-left: 15px; color: #555;\">A:   AI Studio는 구글의 최신 AI 모델을 가장 먼저 접하고, Temperature(창의성) 값 등을 세밀하게 조정하며 프롬프트를 테스트하고 최적화할 수 있는 개발자 친화적인 환경을 제공합니다.</div>\n</div>\n<div style=\"margin-bottom: 20px; padding: 12px; background-color: #f9f9f9; border-radius: 6px; border: 1px solid #eeeeee;\">\n<div style=\"font-weight: bold; margin-bottom: 5px; color: #00796b;\">Q: 블로그 포스팅용 HTML 코드를 생성할 때 주의할 점은?</div>\n<div style=\"padding-left: 15px; color: #555;\">A:   블로그 플랫폼의 구조와 충돌하지 않도록 HEAD, BODY 태그와 H1 태그를 제외한 인라인 스타일로 코드를 생성해야 합니다.</div>\n</div>\n<div style=\"margin-bottom: 20px; padding: 12px; background-color: #f9f9f9; border-radius: 6px; border: 1px solid #eeeeee;\">\n<div style=\"font-weight: bold; margin-bottom: 5px; color: #00796b;\">Q: 맛집 블로그를 위한 '젬 지침'은 어떻게 만드나요?</div>\n<div style=\"padding-left: 15px; color: #555;\">A:   AI Studio에서 프롬프트 엔지니어링을 활용하여 AI에게 명확한 역할, 목표, 형식을 부여하고, 사용자가 최소한의 정보만 입력해도 되는 방식으로 반복 최적화 과정을 거쳐 만듭니다.</div>\n</div>\n<div style=\"margin-bottom: 20px; padding: 12px; background-color: #f9f9f9; border-radius: 6px; border: 1px solid #eeeeee;\">\n<div style=\"font-weight: bold; margin-bottom: 5px; color: #00796b;\">Q: 완성된 블로그 콘텐츠를 어떻게 활용할 수 있나요?</div>\n<div style=\"padding-left: 15px; color: #555;\">A:   생성된 고품질의 블로그 포스팅을 꾸준히 업로드하여 블로그 방문자를 늘리고, 애드센스 수익을 창출하며, 스마트폰 용량 확보와 맛집 기록까지 일석삼조의 효과를 누릴 수 있습니다.</div>\n</div>\n</div>\n<h2 style=\"font-size: 24px; color: white; background: linear-gradient(to right, #00796b, #004d40); margin: 35px 0 15px; padding-bottom: 8px; border-bottom: 2px solid #b2ebf2; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>GEM 무료 지침 다운 로드</b></h2>\n<div class=\"revenue_unit_wrap\">\n  <div class=\"revenue_unit_item adsense responsive\">\n    <div class=\"revenue_unit_info\">반응형</div>\n    <script src=\"//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js\" async=\"async\"></script>\n    <ins class=\"adsbygoogle\" style=\"display: block;\" data-ad-host=\"ca-host-pub-9691043933427338\" data-ad-client=\"ca-pub-8195497734535830\" data-ad-format=\"auto\"></ins>\n    <script>(adsbygoogle = window.adsbygoogle || []).push({});</script>\n  </div>\n</div>\n<p><figure class=\"fileblock\" data-ke-align=\"alignCenter\"><a href=\"https://blog.kakaocdn.net/dn/brYzeD/btsOtePfYzh/3LPJL5s7XQcrLhat3Co8EK/%EB%A7%9B%EC%A7%91%20%EB%B8%94%EB%A1%9C%EA%B7%B8%20%EC%83%9D%EC%84%B1%20GEM%20%EC%A7%80%EC%B9%A8.zip?attach=1&amp;knm=tfile.zip\" class=\"\">\n    <div class=\"image\"></div>\n    <div class=\"desc\"><div class=\"filename\"><span class=\"name\">맛집 블로그 생성 GEM 지침.zip</span></div>\n<div class=\"size\">0.01MB</div>\n</div>\n  </a></figure>\n</p>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">&nbsp;</p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=wNdWROd050s\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/d2bLlO/hyY47yGEuV/SueTLLMQwMk5lb5AUtRuL0/img.jpg?width=1280&amp;height=720&amp;face=310_124_480_310,https://scrap.kakaocdn.net/dn/TJxgn/hyY449N6D3/B6yu46Ua7qc5mAS2K1oMdk/img.jpg?width=1280&amp;height=720&amp;face=310_124_480_310\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"사진만 있으면 5분 만에 맛집 블로그 생성!! | GEMINI 활용법 4편\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/wNdWROd050s\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<script type=\"application/ld+json\">\n    {\n        \"@context\": \"https://schema.org\",\n        \"@type\": \"FAQPage\",\n        \"mainEntity\": [\n            {\n                \"@type\": \"Question\",\n                \"name\": \"제미나이 멀티모달 기능은 어떤 점에서 혁신적인가요?\",\n                \"acceptedAnswer\": {\n                    \"@type\": \"Answer\",\n                    \"text\": \"  예전 AI는 텍스트만 이해했지만, 멀티모달 기능은 사진, 영상 등 다양한 형태의 정보를 동시에 이해하고 처리할 수 있어, AI가 맥락을 파악하고 더 풍부하고 정확한 콘텐츠를 생성할 수 있게 합니다.\"\n                }\n            },\n            {\n                \"@type\": \"Question\",\n                \"name\": \"AI Studio를 사용하는 이유가 무엇인가요?\",\n                \"acceptedAnswer\": {\n                    \"@type\": \"Answer\",\n                    \"text\": \"  AI Studio는 구글의 최신 AI 모델을 가장 먼저 접하고, Temperature(창의성) 값 등을 세밀하게 조정하며 프롬프트를 테스트하고 최적화할 수 있는 개발자 친화적인 환경을 제공합니다.\"\n                }\n            },\n            {\n                \"@type\": \"Question\",\n                \"name\": \"블로그 포스팅용 HTML 코드를 생성할 때 주의할 점은?\",\n                \"acceptedAnswer\": {\n                    \"@type\": \"Answer\",\n                    \"text\": \"  블로그 플랫폼의 구조와 충돌하지 않도록 HEAD, BODY 태그와 H1 태그를 제외한 인라인 스타일로 코드를 생성해야 합니다.\"\n                }\n            },\n            {\n                \"@type\": \"Question\",\n                \"name\": \"맛집 블로그를 위한 '젬 지침'은 어떻게 만드나요?\",\n                \"acceptedAnswer\": {\n                    \"@type\": \"Answer\",\n                    \"text\": \"  AI Studio에서 프롬프트 엔지니어링을 활용하여 AI에게 명확한 역할, 목표, 형식을 부여하고, 사용자가 최소한의 정보만 입력해도 되는 방식으로 반복 최적화 과정을 거쳐 만듭니다.\"\n                }\n            },\n            {\n                \"@type\": \"Question\",\n                \"name\": \"완성된 블로그 콘텐츠를 어떻게 활용할 수 있나요?\",\n                \"acceptedAnswer\": {\n                    \"@type\": \"Answer\",\n                    \"text\": \"  생성된 고품질의 블로그 포스팅을 꾸준히 업로드하여 블로그 방문자를 늘리고, 애드센스 수익을 창출하며, 스마트폰 용량 확보와 맛집 기록까지 일석삼조의 효과를 누릴 수 있습니다.\"\n                }\n            }\n        ]\n    }\n    </script>\n<div id=\"gtx-trans\" style=\"position: absolute; left: -67px; top: 6247.39px;\">\n<div class=\"gtx-trans-icon\">&nbsp;</div>\n</div>",
        "contentSnippet": "스마트폰 속 음식 사진, 블로그 수익으로 바꾸는 비법! 용량 부족 걱정 없이 애드센스 수익까지 얻는 맛집 블로그, AI가 알아서 만들어줘요!\n\n\n \n 스마트폰에 쌓여만 가는 수많은 음식 사진들, 용량 부족 경고가 뜨면 결국 아깝지만 지워야 하죠?   그런데 이 사진들을 전문적인 맛집 블로그로 올리고, 여기에 애드센스 수익까지 얻는다면 금상첨화 아닐까요? 지금 보고 계신 이 블로그 포스팅처럼 말이죠!\n놀라지 마세요. 이 모든 걸 이번에도 제미나이로 가능합니다! 제가 지난번에 제미나이를 활용한 초고속 블로그 글쓰기 영상을 올렸는데요, 정말 많은 분들이 \"실제로 그 지침을 어떻게 만드는지\" 알고 싶다고 하셔서 이번에는 그 비하인드를 공개하는 심화 강의를 준비했습니다.  \n \n우리가 AI와 효과적으로 대화하기 위해서는 그저 \"맛집 글 써줘\"라고 하는 것보다 훨씬 더 체계적인 접근이 필요해요. 정확한 지시와 명확한 가이드라인이 있어야 원하는 결과를 얻을 수 있죠. 그래서 오늘은 이 특별한 '젬 지침'을 만드는 과정까지 여러분께 낱낱이 공개하려고 합니다! 그리고 이번 지침의 핵심에는 단순 글쓰기가 아닌 제미나이의 멀티모달 기능이 있습니다. 이 기능이 왜 혁명적인지, 어떻게 하면 이를 최대한 활용할 수 있는지 함께 알아보겠습니다.\n \nAI 멀티모달 기능의 이해와 활용  \n여러분, 예전 AI는 텍스트만 읽을 수 있었어요. 하지만 최근에는 많은 LLM 모델들이 사진도 보고, 영상도 이해하는 '멀티모달' 능력을 갖추게 되었습니다. 마치 우리가 식당에서 메뉴를 선택할 때 사진과 설명을 함께 보는 것처럼요! 멀티모달이란 쉽게 말해서 다양한 형태의 정보를 동시에 이해하고 처리할 수 있는 인공지능 기술을 의미하는데요. 예를 들어 맛집 사진을 AI에게 보여주면, 예전의 AI는 \"이것은 사진입니다\"라고만 인식했지만, 멀티모달 기능이 있으면 \"이 사진은 식당 내부이고, 테이블 위에는 해물칼국수가 있으며, 옆에는 김치가 놓여있고, 사람들이 즐겁게 식사하고 있네요\"라고 더 자세하고 종합적으로 이해할 수 있게 된 거죠.\n \n여기서 재미있는 점은 AI가 이제 '맥락'을 읽을 수 있다는 거예요. 식당 내부 사진, 음식 사진, 메뉴판을 보고 \"아, 이건 맛집 리뷰를 위한 사진들이구나\"라고 파악합니다. 그래서 여러분이 찍은 맛집 사진을 몇 장만 넣어줘도 전문 블로거가 쓴 것 같은 리뷰를 뚝딱 만들어내는 것이 가능해진 겁니다.\n  알아두세요!\nAI가 아무리 똑똑해도 여러분의 머릿속 생각을 알아서 척척 맞춰주진 않아요. 구체적인 지시가 없으면, 기대한 결과가 나오기 어렵습니다.\n \n프롬프트 엔지니어링의 중요성 (기본적인 시도와 한계)  \n자, 이제 기본적인 방법으로 한번 시도해보겠습니다. 제가 천안에 사는데, 최근에 방문한 회사 근처 \"성거산 시골 막국수\"라는 곳의 사진 일곱 장을 준비했습니다. 이 사진들을 제미나이에 업로드하고 간단하게 \"이 사진들로 맛집 블로그 포스팅을 작성해줘\"라고 요청해보겠습니다. 천안 오시면 꼭 한 번 방문해 보세요. 맛있어요!!\n음... 나쁘지 않지만 뭔가 아쉬워요. '성거산 막국수: 막국수와 찰떡궁합 보쌈 맛집!'이라는 제목으로 기본적인 정보는 잘 담았지만, 뭔가 차별화된 느낌이 부족합니다. '식당은 넓은 주차 공간을 갖추고 있어, 차량으로 방문하기에 정말 편리했어요' '내부로 들어서니 생각보다 훨씬 넓고 쾌적한 공간이 펼쳐졌습니다'처럼 정보는 있지만 독자의 감성을 자극하는 생생한 묘사가 부족하죠.\n구분\n설명\n기대 효과\n\n\n\n\n명확한 역할 부여\n\"너는 지금부터 맛집 블로거야!\"\n글의 톤앤매너와 방향 설정\n\n\n구체적인 목표 제시\n\"사진 분석해서 생생한 맛집 리뷰 써줘.\"\nAI가 나아가야 할 명확한 길 제시\n\n\n결과 형식 지정\n\"HTML 코드로, 특정 스타일 적용해서.\"\n일관성 있고 사용 가능한 결과물 도출\n\n\n\n이럴 때 프롬프트 엔지니어링이 효과적인 것이죠. 프롬프트 엔지니어링은 AI에게 어떤 요청을 할 때, 원하는 결과물을 얻기 위해 질문이나 요청을 효과적으로 설계하는 기술입니다. 간단히 말해 AI와 잘 소통하는 방법을 찾는 거죠. 프롬프트 엔지니어링의 핵심은 AI에게 명확한 역할, 목표, 형식을 제공하는 것입니다. 이 프롬프트 엔지니어링을 기반으로 젬 지침을 만드는 것이죠.\n⚠️ 주의하세요!\nAI가 아무리 똑똑해도 여러분의 머릿속 생각을 알아서 척척 맞춰주지 않습니다. 구체적인 지시가 없으면, 기대한 결과가 나오기 어렵다는 점을 꼭 기억하세요!\n \nGoogle AI Studio 활용 (젬 지침 제작 환경)  \n오늘 저는 이 젬 지침을 제미나이 2.5 모델을 이용해 만들려고 합니다. 하지만 제미나이 사이트가 아닌 AI Studio라는 곳에서 지침을 만들게요.\n  AI Studio는?\nGoogle AI Studio는 구글에서 제공하는 개발자 친화적인 플랫폼으로, AI 모델을 더 세밀하게 제어하고 실험할 수 있는 공간입니다. 개발자, 학생, 연구자들이 프롬프트를 테스트하고 최적화하며, API 통합까지 준비할 수 있는 전문적인 환경이죠. AI Studio도 무료로 사용할 수 있습니다.\n특히 구글의 다양한 최신 AI 모델들을 가장 빨리 만날 수 있으니, 영상 설명란의 링크로 접속하셔서, 다양한 경험을 해 보세요. 흥미로운 사실은, 제가 이번에는 파라미터 조정 없이 기본값으로 진행했는데도 일반 제미나이와 결과가 달랐다는 점입니다. 왜 그럴까요?\nAI Studio vs. 일반 제미나이 차이점\n1) 첫 번째 단계: AI Studio는 기본 Temperature(창의성) 값이 1.0으로 설정되어 있어 더 다양하고 창의적인 결과물 생성\n2) 두 번째 단계: 일반 제미나이는 일관된 답변을 위해 이 값을 더 낮게 설정 가능\n→ AI Studio는 모델의 '날 것 그대로'의 동작을 확인하고 제어하는 데 중점을 둡니다. 따라서, 전문적인 콘텐츠 제작이나 복잡한 지침을 만들 때는 AI Studio에서 작업하는 것을 추천합니다.\n \n맛집 블로그 프롬프트 제작 과정 (1차 및 2차 수정)  ‍ ‍ \n자, 이제 본격적으로 맛집 블로그용 지침을 만들어 보겠습니다! AI STUDIO에 방문하신 후 우측에서 최신 AI 모델을 선택합니다. 아까 얘기한 것처럼 하단에 파라메터는 그대로 두고 첫 번째 프롬프트를 입력할게요. \"사용자 입력 정보와 사진을 기반으로 멀티모달 기능을 최대한 활용하여 구글 상위노출에 최적화된 맛집탐방 블로그 기사를 생성하고 그 결과물을 HTML 코드로 생성하는 젬 지침을 만들어\" 라고 요청하면 바로 맛집 블로거를 위한 지침을 생성합니다.\n  알아두세요!\n1차 요청에서는 사용자에게 너무 많은 정보를 요구했습니다. 식당명, 주소, 키워드, 한 줄 평 등. 편리하게 쓰려고 AI를 활용하는데, 정보 입력에 시간을 다 쓰면 본말이 전도됩니다.\n그래서 두 번째 요청에서는 복잡한 질문만 단순화했습니다. \"사용자에게 묻는 질문이 너무 많아. 처음에 식당명/지역, 주문음식/추가음식, 주변음식/반찬, 후식, 방문배경, 사진을 요청하면서 시작하고, 사용자가 입력을 하면 나머지 정보는 사진을 분석해서 대신 작성하게 지침을 수정해\" 이런 식으로 사용자가 5가지 질문과 사진 업로드만으로 맛집 블로그를 작성할 수 있도록 만들었어요. 중요한 점은, 제미나이의 멀티모달 기능을 활용해 사진을 직접 분석하여 블로그 내용에 반영하도록 한 것이죠.\n \n젬 지침 등록 및 테스트  \n자, 이렇게 해서 나온 2차 결과물을, 제미나이로 돌아가서 젬 지침에 등록을 하고, 결과를 확인해볼게요. 젬 관리자의 샘 젬 만들기에서 예를 들어 제목을 \"맛집 블로그 전문가\"라고 입력을 합니다.\n사례 주인공의 상황: '성거산 시골 막국수' 테스트\n1. 식당명/지역: 천안 성거, 성거산 시골 막국수\n2. 주문음식/추가음식: 비빔 막국수와 수육\n계산 과정: 간편한 입력으로 결과 확인\n1) 3. 주변 음식/반찬: 주변 음식 코너가 따로 있고 셀프임\n2) 4. 후식: 후식 없음\n최종 결과: 블로그 글 자동 생성!\n- 5. 방문배경: 5월 중순 26도의 이른 더위 점심시간. 팀원들과 점심 식사\n- 사진 업로드 → AI가 알아서 블로그 글 생성\n이런 식으로 결과를 확인하고 수정할 부분을 계속해서 AI와 대화를 해 나가면서 완성형으로 만들어 가는 것입니다. 완벽한 결과물은 처음부터 나오지 않습니다. AI와 지속적인 대화를 통해 결과를 확인하고 수정해나가는 '반복 최적화' 과정이 핵심입니다. 제가 이전 영상에서 공유해드린 지침들도 수십 번의 시행착오와 세밀한 조정을 거쳐 완성된 것들이랍니다.\n \n결과물 개선 (HTML 구조 및 디자인 문제점 해결)  \n자, 지금 우리가 받은 결과물을 살펴보면 세 가지 중요한 문제점이 보입니다. 이런 세부 사항들이 블로그 포스팅의 품질을 좌우하게 됩니다.\nHTML 코드 생성 문제: HTML 코드가 코드 블록 안에 제대로 생성되지 않았습니다.\n불완전한 HTML 구조: HTML이 완전한 형태의 웹페이지 구조(HTML, HEAD, BODY 태그 포함)로 표시되고 있습니다. 이는 블로그에 붙여넣을 때 구조적 충돌을 일으킵니다. 블로그 플랫폼은 이미 이 태그들을 가지고 있기 때문이죠.\nH1 태그 중복 문제: 블로그 플랫폼에서는 제목을 별도로 입력하는 필드가 있기 때문에, 본문 내에 H1 태그가 있으면 중복 제목이 생겨 SEO에 좋지 않고 디자인도 깨질 수 있습니다.\n이런 경우, AI에게 '블로그 본문에 추가해야 하므로 헤드, 바디 태그와 에이치원 태그가 없는 인라인 스타일로 변경해주세요. 제목은 별도로 입력할 것입니다.'라고 요청하세요. 그러면 블로그 플랫폼에 바로 붙여넣을 수 있는 최적화된 HTML 코드를 받을 수 있습니다. 위의 2가지 문제 개선을 위해, 1. 이 지침의 출력물 중 HTML 코드로 생성되는 결과물은 \"코드 블록\"으로 출력해, 2. 블로그 본문에 추가해야 하므로 헤드, 바디 태그와 에이치원 태그가 없는 인라인 스타일로 변경해. 라고 다시 지침 수정을 요청합니다.\n \n자, 수정된 지침으로 생성된 결과물을 보면 인라인 스타일의 에이치티엠엘 코드가 코드블록에서 생성되는 것을 확인할 수 있습니다. 그런데 이번엔 디자인이 별로입니다. 이럴 때는 \"좀 더 시각화된 결과물이 나올 수 있게 디자인을 개선해줘\" 또는 구체적인 디자인 지침을 주거나 이전 영상에서 소개한 디자인 템플릿을 업로드하고 \"첨부 디자인 스타일로 반영되게 수정해\"라고 요청하셔도 될 거 같습니다. 아, 그리고 디자인만 보시려면, 젬을 수정할 필요 없이, AI STUDIO의 수정된 지침의 코드만 복사해서 코드펜으로 가서 확인하면 됩니다.\n \n \n맛집 블로그 생성 지침 핵심 요약!\n✨ 프롬프트 엔지니어링: AI와 잘 소통하는 기술. 명확한 역할, 목표, 형식을 제공하여 원하는 결과물을 얻는 것이 핵심이죠.\n  멀티모달 기능 활용: 사진을 직접 분석해서 생생한 리뷰를 작성하도록 지시! 단순히 텍스트를 생성하는 것을 넘어, 시각 정보까지 통합하여 블로그 글의 퀄리티를 높입니다.\n  HTML 구조 및 디자인 최적화:\nHTML = (SEO 최적화) + (인라인 스타일) + (H1 태그 제외)\n ‍  반복 최적화의 중요성: 완벽한 결과물은 한 번에 나오지 않아요! AI와 지속적으로 대화하고, 결과를 수정하며 더 나은 지침을 만들어가는 과정이 필요합니다.\n이 지침으로 여러분도 전문 맛집 블로거로 거듭나세요!  \n자주 묻는 질문 ❓\nQ: 제미나이 멀티모달 기능은 어떤 점에서 혁신적인가요?\nA:   예전 AI는 텍스트만 이해했지만, 멀티모달 기능은 사진, 영상 등 다양한 형태의 정보를 동시에 이해하고 처리할 수 있어, AI가 맥락을 파악하고 더 풍부하고 정확한 콘텐츠를 생성할 수 있게 합니다.\nQ: AI Studio를 사용하는 이유가 무엇인가요?\nA:   AI Studio는 구글의 최신 AI 모델을 가장 먼저 접하고, Temperature(창의성) 값 등을 세밀하게 조정하며 프롬프트를 테스트하고 최적화할 수 있는 개발자 친화적인 환경을 제공합니다.\nQ: 블로그 포스팅용 HTML 코드를 생성할 때 주의할 점은?\nA:   블로그 플랫폼의 구조와 충돌하지 않도록 HEAD, BODY 태그와 H1 태그를 제외한 인라인 스타일로 코드를 생성해야 합니다.\nQ: 맛집 블로그를 위한 '젬 지침'은 어떻게 만드나요?\nA:   AI Studio에서 프롬프트 엔지니어링을 활용하여 AI에게 명확한 역할, 목표, 형식을 부여하고, 사용자가 최소한의 정보만 입력해도 되는 방식으로 반복 최적화 과정을 거쳐 만듭니다.\nQ: 완성된 블로그 콘텐츠를 어떻게 활용할 수 있나요?\nA:   생성된 고품질의 블로그 포스팅을 꾸준히 업로드하여 블로그 방문자를 늘리고, 애드센스 수익을 창출하며, 스마트폰 용량 확보와 맛집 기록까지 일석삼조의 효과를 누릴 수 있습니다.\nGEM 무료 지침 다운 로드\n반응형\n\n    \n    (adsbygoogle = window.adsbygoogle || []).push({});\n  \n\n    \n\n    \n맛집 블로그 생성 GEM 지침.zip\n0.01MB",
        "guid": "http://muzbox.tistory.com/483604",
        "categories": [
          "AI, 미래기술/AI 챗봇 및 지침 무료 배포",
          "ai 멀티모달",
          "google ai studio",
          "html 블로그",
          "SEO 최적화",
          "맛집 블로그",
          "블로그 수익",
          "제미나이",
          "지침 생성",
          "콘텐츠 제작",
          "프롬프트 엔지니어링"
        ],
        "isoDate": "2025-06-08T05:28:03.000Z"
      }
    ]
  },
  {
    "name": "동우리의 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "하테나",
    "category": "개인",
    "posts": []
  },
  {
    "name": "늑돌이네 라지온",
    "category": "개인",
    "posts": []
  },
  {
    "name": "루리웹 - 루리웹 리뷰 게시판",
    "category": "게임",
    "posts": [
      {
        "creator": "｜RULIWEB｜",
        "title": "[NS2] 닌텐도 스위치 2 - 확실한 성능 체감, 아쉬운 출시 전략",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2318",
        "pubDate": "Mon, 09 Jun 2025 19:13:12 +0900",
        "author": "｜RULIWEB｜",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i1.ruliweb.com/thumb/25/06/09/197526bf77351ad6b.jpg\">",
        "contentSnippet": "",
        "categories": [
          "리뷰"
        ],
        "isoDate": "2025-06-09T10:13:12.000Z"
      },
      {
        "creator": "(RULIWEB`Д')/",
        "title": "[MULTI] 즐거움 가득한 드퀘의 전설의 숲, 판타지 라이프 i",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2317",
        "pubDate": "Thu, 05 Jun 2025 18:25:23 +0900",
        "author": "(RULIWEB`Д')/",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i1.ruliweb.com/thumb/25/06/05/1973f68592d4c329e.jpg\">",
        "contentSnippet": "",
        "categories": [
          "리뷰"
        ],
        "isoDate": "2025-06-05T09:25:23.000Z"
      },
      {
        "creator": "［RULIWEB］",
        "title": "[MOBILE] 그래 퍼드는 원래 재미있는 게임이었지, 퍼즐앤드래곤 제로",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2316",
        "pubDate": "Thu, 05 Jun 2025 14:19:53 +0900",
        "author": "［RULIWEB］",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i2.ruliweb.com/thumb/25/06/05/1973e8792c65104c1.jpg\">",
        "contentSnippet": "",
        "categories": [
          "리뷰"
        ],
        "isoDate": "2025-06-05T05:19:53.000Z"
      },
      {
        "creator": "｜RULIWEB｜",
        "title": "악역영애 4컷 만화 - 5화, 등교 시작인데스와~★",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2315",
        "pubDate": "Wed, 04 Jun 2025 19:09:01 +0900",
        "author": "｜RULIWEB｜",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i2.ruliweb.com/thumb/25/06/04/1973a6b125f51ad6b.jpg\">",
        "contentSnippet": "",
        "categories": [
          "웹툰"
        ],
        "isoDate": "2025-06-04T10:09:01.000Z"
      },
      {
        "creator": "「RULIWEB」",
        "title": "[MULTI] 절반만 성공한 실험, 엘든 링: 밤의 통치자",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2314",
        "pubDate": "Wed, 04 Jun 2025 16:12:50 +0900",
        "author": "「RULIWEB」",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i3.ruliweb.com/thumb/25/06/04/19739c82fc44cacdc.jpg\">",
        "contentSnippet": "",
        "categories": [
          "리뷰"
        ],
        "isoDate": "2025-06-04T07:12:50.000Z"
      }
    ]
  },
  {
    "name": "Reasontobe",
    "category": "개인",
    "posts": [
      {
        "creator": "Reasontobe",
        "title": "영어 레벨의 함정 - 영포자 일병 구출작전 by 다독",
        "link": "https://brunch.co.kr/@@34qN/44",
        "pubDate": "Mon, 09 Jun 2025 07:25:19 GMT",
        "author": "Reasontobe",
        "content": "&quot;한 배에서 아롱이 다롱이 난다.&quot; 라는 이야기 처럼, 우리 둘째는 첫째와 아주 많이 다릅니다. 성격, 외모 뿐 아니라, 좋아하는 것도, 잘하는 것도 아주 다릅니다. 그 중, 요즘 제가 신경을 많이 쓰는 부분은 언어에 대한 감각입니다.  어려서 부터, 영어를 좋아하고 쉽게 깨우친 오빠와 달리, 둘째는 오빠 보다 더 빨리 시작했고, 많은 시간을 썼음에도 불구<img src= \"https://img1.daumcdn.net/thumb/R1280x0/?fname=http%3A%2F%2Ft1.daumcdn.net%2Fbrunch%2Fservice%2Fuser%2F34qN%2Fimage%2FCFSIaekoXrFFlJWQhL0tvKwiQj4.jpg\" width=\"500\" />",
        "contentSnippet": "\"한 배에서 아롱이 다롱이 난다.\" 라는 이야기 처럼, 우리 둘째는 첫째와 아주 많이 다릅니다. 성격, 외모 뿐 아니라, 좋아하는 것도, 잘하는 것도 아주 다릅니다. 그 중, 요즘 제가 신경을 많이 쓰는 부분은 언어에 대한 감각입니다.  어려서 부터, 영어를 좋아하고 쉽게 깨우친 오빠와 달리, 둘째는 오빠 보다 더 빨리 시작했고, 많은 시간을 썼음에도 불구",
        "guid": "https://brunch.co.kr/@@34qN/44",
        "isoDate": "2025-06-09T07:25:19.000Z"
      }
    ]
  },
  {
    "name": "자유로운 생활",
    "category": "개인",
    "posts": []
  },
  {
    "name": "에스티마의 인터넷이야기 EstimaStory.com",
    "category": "개인",
    "posts": []
  },
  {
    "name": "나긋한 개발 - 데비안 리눅스와 프로그램 언어",
    "category": "개인",
    "posts": []
  },
  {
    "name": "일상을 여행처럼...",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Just hack'em",
    "category": "개인",
    "posts": []
  },
  {
    "name": "C++ Truths",
    "category": "개인",
    "posts": []
  },
  {
    "name": "jacking75",
    "category": "개인",
    "posts": [
      {
        "title": "Visual Studio Code 1.98의 AI 기능",
        "link": "https://jacking75.github.io/ai-github_copilot_20250607/",
        "pubDate": "Sat, 07 Jun 2025 00:00:00 +0900",
        "content": "<iframe width=\"1024\" height=\"1024\" src=\"https://docs.google.com/document/d/e/2PACX-1vT_uMzIak_O5zMLJ7gdTbzpo8DRx5tg2bxXUkzN9LnmQ1aW61S2BU5zjoQ3JLMCxpA6Q3Js_24xh_8h/pub?embedded=true\"></iframe>\n\n",
        "contentSnippet": "",
        "guid": "https://jacking75.github.io/ai-github_copilot_20250607/",
        "isoDate": "2025-06-06T15:00:00.000Z"
      }
    ]
  },
  {
    "name": "Joel on Software",
    "category": "개인",
    "posts": []
  },
  {
    "name": "벤자민로그",
    "category": "개인",
    "posts": [
      {
        "title": "깔끔한 이메일 주소",
        "link": "https://jeho.page/essay/2025/06/09/neat-email-address.html",
        "pubDate": "2025-06-09T09:48:00.000Z",
        "author": "김재호",
        "content": "<p>이메일 주소가 깔끔한 사람을 보면 좋은 느낌이 듭니다.<br />\n자기 이름을 영어로 혹은 짧고 읽기 쉬운 닉네임으로 만든 이메일들.</p>\n\n<p>그렇지 않고 한글 이름을 영어로 rlawogh(김재호) 한다거나,<br />\n숫자가 들어간 이메일을(rlawogh777) 보면 좋은 느낌이 들지 않습니다.</p>\n\n<p>가장 인상적이었던 이메일은 r@google.com 였습니다.<br />\nUTF-8과 Go 언어를 만든 <a href=\"https://en.wikipedia.org/wiki/Rob_Pike\">롭 파이크</a>.<br />\n그가 구글에 들어갈 때 선택한 이메일.<br />\n한 글자 이메일 주소라니. 센스 터지는 군.</p>\n\n<p>깔끔한 이메일을 보면 이 사람은 신중하고 좋은 결정을 하는 사람이라는 생각이 듭니다.  <br />\n이런 생각은 편견일 수 있다는 걸 알면서도… 이 편견에서 빠져나오기가 힘드네요.</p>\n\n<p>P.S 저는 wlsdudtm 라는 이메일을 쓰는 동생에게 메일 주소 좀 바꾸라고 잔소리를 하곤 합니다.<br />\n이제 좀 바꾸자 지녕쓰.😆</p>\n\n<p><br />\n<em>함께 읽으면 좋은 글:</em></p>\n<ul>\n  <li><a href=\"/essay/2023/04/21/most-delightful-emails.html\">가장 기쁜 이메일</a></li>\n</ul>",
        "contentSnippet": "이메일 주소가 깔끔한 사람을 보면 좋은 느낌이 듭니다.\n그렇지 않고 한글 이름을 영어로 rlawogh(김재호) 한다거나,\n가장 인상적이었던 이메일은 r@google.com 였습니다.\n롭 파이크.\n깔끔한 이메일을 보면 이 사람은 신중하고 좋은 결정을 하는 사람이라는 생각이 듭니다.  \nP.S 저는 wlsdudtm 라는 이메일을 쓰는 동생에게 메일 주소 좀 바꾸라고 잔소리를 하곤 합니다.\n\n함께 읽으면 좋은 글:\n가장 기쁜 이메일",
        "summary": "이메일 주소가 깔끔한 사람을 보면 좋은 느낌이 듭니다. 자기 이름을 영어로 혹은 짧고 읽기 쉬운 닉네임으로 만든 이메일들.",
        "id": "https://jeho.page/essay/2025/06/09/neat-email-address",
        "isoDate": "2025-06-09T09:48:00.000Z"
      },
      {
        "title": "최고의 사무실은 바로 우리집 방구석",
        "link": "https://jeho.page/essay/2025/06/09/my-office-is-my-room.html",
        "pubDate": "2025-06-09T02:44:00.000Z",
        "author": "김재호",
        "content": "<p>집에서는 도저히 일이 안 된다는 사람들을 많이 봤습니다.<br />\n사무실에 가서 하지 않으면 절대 집중이 안 된다고. 커피숍이라도 가야한다고.</p>\n\n<p>저도 그 기분을 압니다.<br />\n커피숍에서 코딩을 해보기도 했는데 변수가 많았습니다.<br />\n어느 날은 잘 되다가도 어느 날은 공치고 돌아오고.<br />\n이렇게 일 하는 건 안정적으로 오래할 수 없다는 걸 깨달았습니다.</p>\n\n<p>다행히 저는 집에서도 집중을 잘 하는 편입니다.<br />\n커피한잔 작업의 90%이상은 집에 있는 제 책상에서 이루어졌습니다.</p>\n\n<p>커다란 모니터도 2개나 있고, 책상과 의자의 높이, 키보드, 온도/습도. 소음.<br />\n출근 시간도 없지, 모든 면에서 집이 훨씬 편하니까.</p>\n\n<p>집에서 일을 잘하는 건 타고난 게 아닙니다. 하다보면 습관이 되어 편해지는 것.<br />\n집에서 일할 수 있는 습관을 들여놓으면 1인 개발에 다른 사람보다 한 발 유리해진 겁니다.<br />\n돈도 안 들지, 시간도 아낄 수 있지, 무엇보다 안정적으로 코딩할 수 있게 되니까.</p>\n\n<p>강력 추천하는 사무실은 바로 자기집 방구석입니다.</p>\n\n<p><br />\n<em>함께 읽으면 좋은 글:</em></p>\n<ul>\n  <li><a href=\"/essay/2023/03/30/silence-in-the-office.html\">사무실의 고요함이 너무 좋아</a></li>\n  <li><a href=\"/essay/2022/09/14/successful-developer.html\">1인 개발자 전성시대</a></li>\n</ul>",
        "contentSnippet": "집에서는 도저히 일이 안 된다는 사람들을 많이 봤습니다.\n저도 그 기분을 압니다.\n다행히 저는 집에서도 집중을 잘 하는 편입니다.\n커다란 모니터도 2개나 있고, 책상과 의자의 높이, 키보드, 온도/습도. 소음.\n집에서 일을 잘하는 건 타고난 게 아닙니다. 하다보면 습관이 되어 편해지는 것.\n강력 추천하는 사무실은 바로 자기집 방구석입니다.\n\n함께 읽으면 좋은 글:\n사무실의 고요함이 너무 좋아\n1인 개발자 전성시대",
        "summary": "집에서는 도저히 일이 안 된다는 사람들을 많이 봤습니다. 사무실에 가서 하지 않으면 절대 집중이 안 된다고. 커피숍이라도 가야한다고.",
        "id": "https://jeho.page/essay/2025/06/09/my-office-is-my-room",
        "isoDate": "2025-06-09T02:44:00.000Z"
      },
      {
        "title": "앱 개발 개척시대",
        "link": "https://jeho.page/essay/2025/06/05/at-the-app-development-race.html",
        "pubDate": "2025-06-05T02:44:00.000Z",
        "author": "김재호",
        "content": "<p>AI 시대에는 개발자가 유리한가?<br />\n디자이너에게 좋은건가? 기획자는? 마케터는?</p>\n\n<p>다 똑같다고 생각합니다. 모두가 같은 출발선.</p>\n\n<p>제가 공부한 모든 컴퓨터 공학 지식의 가치를 0으로 설정했습니다.<br />\n맘이 좀 아프지만 이렇게 생각하니 차라리 편하기도 합니다. (다른 직군도 마찬가지일 겁니다)</p>\n\n<p>서부 개척시대에서 요이땅 하고 땅따먹기를 하러 가는 느낌입니다.<br />\n누구든 먼저 땅에다 깃발을 꼽으면 그 땅을 주었던 시대.<br />\n말 한 마리만으로 달려가던 사람도 있었고 전차를 만들어서 가기도 하고 연합을 하기도 했습니다.<br />\n마냥 좋지만은 않았을 겁니다. 옆에 달려가는 사람들을 죽이기도 하고, 미리 가서 기다리고 있다가 깃발을 꼽는 등 얍삽이가 수두룩했습니다. 그래도 기회의 시대였던 것은 분명합니다.</p>\n\n<p>어쩌면 이게 제 개발자 경력의 마지막은 아닐까?<br />\n나이도 들었고 함께할 연합도 없지만 제가 가진 장점들이 분명히 있을 겁니다.<br />\n이 레이스를 즐겨보려 합니다.😁</p>\n\n<p><img src=\"/assets/img/far_and_away.png\" alt=\"파앤드어웨이\" /></p>\n\n<p><br />\n<em>함께 읽으면 좋은 글:</em></p>\n<ul>\n  <li><a href=\"/essay/2022/09/14/successful-developer.html\">1인 개발자 전성시대</a></li>\n  <li><a href=\"/essay/2024/03/18/surviving-alone.html\">1인 개발이란 전쟁터에서 혼자 살아남는 것</a></li>\n</ul>",
        "contentSnippet": "AI 시대에는 개발자가 유리한가?\n다 똑같다고 생각합니다. 모두가 같은 출발선.\n제가 공부한 모든 컴퓨터 공학 지식의 가치를 0으로 설정했습니다.\n서부 개척시대에서 요이땅 하고 땅따먹기를 하러 가는 느낌입니다.\n어쩌면 이게 제 개발자 경력의 마지막은 아닐까?\n\n\n함께 읽으면 좋은 글:\n1인 개발자 전성시대\n1인 개발이란 전쟁터에서 혼자 살아남는 것",
        "summary": "AI 시대에는 개발자가 유리한가? 디자이너에게 좋은건가? 기획자는? 마케터는?",
        "id": "https://jeho.page/essay/2025/06/05/at-the-app-development-race",
        "isoDate": "2025-06-05T02:44:00.000Z"
      }
    ]
  },
  {
    "name": "악보쓰는 프로그래머",
    "category": "개인",
    "posts": []
  },
  {
    "name": "쭌안아빠",
    "category": "개인",
    "posts": []
  },
  {
    "name": "A Gangster World",
    "category": "개인",
    "posts": []
  },
  {
    "name": "요우의 내맘대로 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자스럽다",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Against All Odds.",
    "category": "개인",
    "posts": []
  },
  {
    "name": "움직이는 게임서버",
    "category": "개인",
    "posts": []
  },
  {
    "name": "이상욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "임철재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "어쩐지 오늘은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "oddpoet’s étude",
    "category": "개인",
    "posts": []
  },
  {
    "name": "0x00 - NULL",
    "category": "개인",
    "posts": []
  },
  {
    "name": "퇴근 후 서버다운",
    "category": "개인",
    "posts": []
  },
  {
    "name": "coolspeed",
    "category": "개인",
    "posts": []
  },
  {
    "name": "오늘도 끄적끄적",
    "category": "개인",
    "posts": []
  },
  {
    "name": "dx11 Vanica's Lifelog - 夢が夢で終わらないように",
    "category": "개인",
    "posts": []
  },
  {
    "name": "초코사랑",
    "category": "개인",
    "posts": []
  },
  {
    "name": "ZeroCho Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "imays게임엔진개발자",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for hurinmon Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "기억보단 기록을",
    "category": "개인",
    "posts": [
      {
        "creator": "향로 (기억보단 기록을)",
        "title": "학습 플랫폼과 AI",
        "link": "https://jojoldu.tistory.com/831",
        "pubDate": "Sun, 8 Jun 2025 10:17:54 +0900",
        "author": "향로 (기억보단 기록을)",
        "comments": "https://jojoldu.tistory.com/831#entry831comment",
        "content": "<blockquote data-ke-style=\"style1\"><p data-ke-size=\"size16\"><span style=\"font-family: 'Noto Serif KR';\"><p>아래는 저희 제품팀 전체에게 공유한 내용 중 일부를 정리해서 공유합니다.</p>\n</span></p></blockquote><p>최근에 팀원과 함께 AI 요약 노트를 어떻게 제공할지에 대해 논의 논의하는 시간을 가졌다.  </p>\n<p>여러 아이디어가 나왔는데, <strong>퀴즈를 풀기 전에 요약 내용을 꼭 숙지</strong> 하도록 장치를 두는 것은 놓치지 말았으면 한다는 것을 조건으로 두었다.<br>다만, 그걸 덜 불편하게, 자연스럽게 전달할 수 있도록 고민을 더 할 필요는 있다고도 덧붙였다.  </p>\n<p>퀴즈를 풀려면 요약 노트를 꼭 봐야하는 것이 불편할 수 있다.<br>바로 퀴즈 풀고 싶은데, 요약 노트가 한번 등장하면 퀴즈까지 가는 퍼널이 증가하는 것이고, 고객은 최소 1번 이상은 클릭을 더 해야하니 퀴즈 자체가 목적인 분들께는 좀 더 귀찮은 요소가 될 수 있다.<br>그렇다 해도 잘 정리된 요약 노트를 보게 하는 것은 꼭 필수 과정으로 들어가야한다고 이야기드렸다.<br>고객이 불편해하는 것들은 모두 다 편한 것으로 개선하는 것도 중요하다고 생각한다.<br>그런 면에서는 넷플릭스, 에이비앤비, 유튜브에서 배울 점이 많다.<br>다만, 그것보다 더 양보할 수 없는 중요한 점이 있는데, 그건 바로 우리 플랫폼의 근본 목적인 <code>고객의 학습</code> 이다.    </p>\n<p><strong>아무리 편하더라도 그게 수강생분들의 학습, 성장에 전혀 도움이 안된다면 그건 우리의 목표에 방해</strong>되는 기능이다.  </p>\n<p>설령 조금 불편하더라도 훨씬 더 고객이 원하는 교육, 성장, 학습의 목표를 잘 달성할 수 있게하는 장치라면 그걸 지향해야하고 그로 인해 발생하는 불편한 점을 최대한 상쇄시키는 것이 저희 같은 제품가들이 해야하는 고민이라는 것이다.  </p>\n<hr>\n<p>(틀릴 수도 있지만) 요즘 AI 제품들에 대한 내 생각도 여기에서의 연장선에 있다.  </p>\n<p>요즘 여러 오픈카톡방과 커뮤니티에서 &quot;모든 서비스가 채팅 UI만 남고 다른 UI/UX는 모두 사라질 것이다&quot; 라는 이야기를 공공연하게 꺼내곤 한다.    </p>\n<p>그런 면에서 우리 학습 강의실 내에도 AI 채팅을 넣는 것고 고려해볼 수 있다.  </p>\n<p>다만, 이 부분에 대해서는 가능하면 최대한 유보하는 입장이다.<br>제품가로서 제품에 대한 고민이 너무 날카롭지 않고 무딘 감각으로 느껴지기 때문이다.  </p>\n<p>좋은 학습 플랫폼이라면 <strong>개개인이 갖고 있는 백그라운드에 따라 학습 성과가 천차만별이 되는 것을 최대한 지양</strong>해야하고, 백그라운드가 부족하더라도 최대한 많은 것을 가져갈 수 있는 방향으로 제품을 만들어야 한다고 생각한다.  </p>\n<p>물론 자질이 훌륭한 분들의 상방선을 열어두고 극대화 하는 것도 중요하지만 <strong>그런 분들은 학습 플랫폼의 도움 없이도 혼자서도 잘 할 수 있는 분들</strong>이기에 오히려 우리 같은 플랫폼의 도움이 필요로 하지 않는다.<br>진짜 우리의 도움이 필요한 분들은 <strong>부족한 백그라운드로 인해서 배우는데 어려움이 있거나 효율이 떨어지는 분들</strong>이다.<br>그들에게 학습에 대한 레버리지를 줄 수 있는 것을 지향해야한다고 보는 것이다.  </p>\n<p>그런 면에서 <strong>AI 채팅으로 모르는 것을 물어보세요</strong> 라는 것은 이 관점에서는 불합격인 제품이라고 본다.<br>왜냐면 <strong>프롬프트 역량에 따라 학습 효율이 천차만별</strong>로 나뉘기 때문이다.  </p>\n<p>지금도 대다수의 많은 사람들은 AI 채팅을 통해 제대로 학습하는 사람은 극 소수이다.<br>희노애락으로 AI를 쓰시는 분들은 많지만, 여전히 많은 분들이 학습하기 위해 AI를 쓰는 경우는 전체 인구에 비하면 소수이다.<br>AI는 틀린 답을 낸다고 생각해서 적당히 질문하다가 원하는 답이 안나와서 &quot;에잇&quot; 하고 다시 기존의 검색 서비스를 이용하시거나 AI가 틀린 답을 낸 건지도 모르고 사용 하시는 분들도 많다.<br>혹은 여전히 AI를 쓰지 않는 분들도 많다.  </p>\n<p>이런 관점에서는 <strong>개인의 프롬프트 역량에 따라 정확한 답변을 받을 수 있을 확률이 달라지는</strong> AI 채팅이란 기능이 진짜 백그라운드가 부족한, 독학이 어려운 분들에게 도움이 되는 제품인가?   </p>\n<p>&quot;AA&quot; 라는 주제를 공부하려고 강의를 결제했는데, <strong>그 주제를 잘 공부하기 위해서는 AI 프롬프트를 자세히 공부해야한다</strong> 라는 것이 과연 학습 플랫폼이 고객에게 전달해야할 가치인가? 라는 근본적인 의문인 것이다.  </p>\n<p>이는 얼핏보면 <strong>AI 이전 시대의 &#39;영어&#39; 와 비슷한 것 같단 생각</strong>도 든다.  </p>\n<p>영어를 잘 한다면 전세계의 모든 지식을 쉽게 배울 수 있다.<br>강의에서 전달하고자 하는 내용을 모두 영어로 설명한다면 관련된 내용을 추가적으로 찾아볼때도 훨씬 더 편하게 찾아 볼 수 있다.<br>모든 용어가 다 원래의 용어 그대로를 사용할테니 더 정확한 설명이 될 것이고, 영어로 배운 사람은 이후에도 그 주제에 대해서는 훨씬 더 정확히, 훨씬 더 확장성 있게 학습을 한 상태가 된다.  </p>\n<p>근데 그 서비스가 과연 <strong>학습 성장을 평등하게 제공한 것</strong>인가?<br>그 서비스는 영어를 잘 아는 사람들만을 위한 서비스이다.  </p>\n<p>학습 성장 평등을 지향하는 우리 같은 학습 플랫폼은 <strong>영어, 프롬프트 역량이 부족해도 잘 배울 수 있는 환경</strong>을 만드는 것에 집중해야 한다는 생각이 요즘 더 강하게 들었다.    </p>\n<p><strong>AI는 사업과 제품에 있어서 큰 곱하기 효과를 주는 것은 맞는데, 이것 자체가 제품이나 사업이 되어서는 안된다</strong>.  </p>\n<p>특히나 그 기능이 정말로 우리가 깊은 고민 없이 그냥 남들이 하니깐 하는 정도 수준에서의 기능이라면 더더욱 그 방향은 위험하다고 본다.  </p>\n<p>그건 뭘 위한 것인지 목표 없이 단순히 AI를 붙이고 &#39;해줘&#39;에 가까운 것인데, 그런건 좋은 제품의 기준에는 전혀 합당하다고 보진 않는다.  </p>\n<p>발전 방향도 어색하다고 본다.<br>AI 채팅의 답변이 좋으려면 그만큼 더 좋은 모델을 사용해야한다.<br>근데 좋은 모델을 사용할수록 대부분 BEP를 맞추기 힘들다.<br>그 많은 AI 토큰 비용을 다 플랫폼이 부담해야하고, 그러다 보면 플랫폼 수수료는 더욱 더 높아진다.  </p>\n<p>그렇다면 저렴한 모델을 고객에게 제공하고 <strong>별로인 AI 모델인데 쓸려면 써라</strong> 정도의 스탠스를 가지고 가는 것도 너무 웃긴다.<br>어차피 만족할만한 답변은 나오지 않는데 고객은 그걸 왜 써야하나.</p>\n<p>반면 이런 기능들은 좋다.  </p>\n<ul>\n<li>&quot;이 내용을 어디선가 봤는데, 그게 어느 강의의 어느 영상이였는지 모르겠다&quot; 라면 그걸 쉽게 찾을 수 있는 검색</li>\n<li>방금 전에 강사님이 &quot;이 내용은 다른 강의에서 자세히 이야기 하고 있으니 그 강의를 수강해보세요&quot; 라고 하는데 그게 어느 강의의 어느 영상 몇분째 인지 알려주는 학습 도우미</li>\n<li>&quot;남들을 가르치는 것이 가장 좋은 학습 방법&quot; 이라는 기준으로 방금 배운 내용을 토대로 누군갈 가르쳐보는 경험을 줄 수 있는 환경</li>\n</ul>\n<p>이런 기능들은 목표가 뚜렷하고 프롬프트 등의 백그라운드 지식과 관계없이 학습을 더 잘할 수 있도록 나름의 고민과 여러 학습 효과에 대한 자료를 기반으로 했기 때문에 좋다.<br>고객이 학습을 하는데 있어 방해되는 요소가 자연스레 해소 되는 것이기도 한다.  </p>\n<p>물론 이런 예시들을 전부 &quot;AI 채팅으로 물어보도록 하면 되지 않냐&quot; 고 할 수도 있다.<br>그건 세상에서 가장 똑똑한 과외 선생님을 붙여도 서울대를 못가는 수많은 학생들과 같다.  </p>\n<p>&quot;내가 뭘 모르는지도 모르고, 뭘 물어봐야하는지도 모르는&quot; 대다수의 학생들에겐 적합하지 않다.  </p>\n<p>고객에게 &quot;이런 것도 질문하세요&quot;, &quot;저런 것도 질문하세요&quot; 라고 하기 보다는 <strong>고객 스스로도 몰랐던 학습의 방해 요소들이 제품 안에서 자연스럽게 해결되고, 성장을 가속할 수 있는 장치가 자연스럽게 적용 되어있는 것</strong> 이 가장 좋다.  </p>\n<p>종국에는 &quot;인프런 써보기 전에는 몰랐는데 인프런 써보고 나니깐 다른 서비스는 못쓰겠다&quot; 라는 이야기가 나올 수 있다고 믿고 있다.  </p>\n<p>우리가 해야할 것은, <strong>AI를 어떻게하면 잘 사용할 수 있을지는 우리의 고민으로 가져오고, 고객들은 AI를 얼마나 잘 사용하는지에 관계없이 원했던 것 이상으로 성장시켜드리는 것</strong>이다.  </p>\n<p>그래서 직접 학습자가 되어보는 것이 중요하다.  </p>\n<ul>\n<li>나는 어떤 환경에서 학습이 잘 되었나,  </li>\n<li>나는 아예 처음 접하는 것을 배울때 어떻게 배우나,  </li>\n<li>내가 가장 만족스러웠던 학습 경험은 어떤 것이었나 등등  </li>\n</ul>\n<p>스스로가 고객이 되어서 &quot;있으면 좋은 것&quot; 이 아니라, &quot;이게 진짜 공부하는데 있어서 큰 도움이 되었다&quot; 라는 것을 계속해서 고민하고 시도해보는 것이 인프랩의 제품 팀으로서 중요하다.  </p>\n<p>그래서 이 부분에 대해 꼭 명심하고 어떤 제품을 만들던 좀 더 날카롭게 고민해야하는 시기인 것 같다.</p>",
        "contentSnippet": "아래는 저희 제품팀 전체에게 공유한 내용 중 일부를 정리해서 공유합니다.\n\n최근에 팀원과 함께 AI 요약 노트를 어떻게 제공할지에 대해 논의 논의하는 시간을 가졌다.  \n여러 아이디어가 나왔는데, 퀴즈를 풀기 전에 요약 내용을 꼭 숙지 하도록 장치를 두는 것은 놓치지 말았으면 한다는 것을 조건으로 두었다.\n다만, 그걸 덜 불편하게, 자연스럽게 전달할 수 있도록 고민을 더 할 필요는 있다고도 덧붙였다.  \n퀴즈를 풀려면 요약 노트를 꼭 봐야하는 것이 불편할 수 있다.\n바로 퀴즈 풀고 싶은데, 요약 노트가 한번 등장하면 퀴즈까지 가는 퍼널이 증가하는 것이고, 고객은 최소 1번 이상은 클릭을 더 해야하니 퀴즈 자체가 목적인 분들께는 좀 더 귀찮은 요소가 될 수 있다.\n그렇다 해도 잘 정리된 요약 노트를 보게 하는 것은 꼭 필수 과정으로 들어가야한다고 이야기드렸다.\n고객이 불편해하는 것들은 모두 다 편한 것으로 개선하는 것도 중요하다고 생각한다.\n그런 면에서는 넷플릭스, 에이비앤비, 유튜브에서 배울 점이 많다.\n다만, 그것보다 더 양보할 수 없는 중요한 점이 있는데, 그건 바로 우리 플랫폼의 근본 목적인 고객의 학습 이다.    \n아무리 편하더라도 그게 수강생분들의 학습, 성장에 전혀 도움이 안된다면 그건 우리의 목표에 방해되는 기능이다.  \n설령 조금 불편하더라도 훨씬 더 고객이 원하는 교육, 성장, 학습의 목표를 잘 달성할 수 있게하는 장치라면 그걸 지향해야하고 그로 인해 발생하는 불편한 점을 최대한 상쇄시키는 것이 저희 같은 제품가들이 해야하는 고민이라는 것이다.  \n(틀릴 수도 있지만) 요즘 AI 제품들에 대한 내 생각도 여기에서의 연장선에 있다.  \n요즘 여러 오픈카톡방과 커뮤니티에서 \"모든 서비스가 채팅 UI만 남고 다른 UI/UX는 모두 사라질 것이다\" 라는 이야기를 공공연하게 꺼내곤 한다.    \n그런 면에서 우리 학습 강의실 내에도 AI 채팅을 넣는 것고 고려해볼 수 있다.  \n다만, 이 부분에 대해서는 가능하면 최대한 유보하는 입장이다.\n제품가로서 제품에 대한 고민이 너무 날카롭지 않고 무딘 감각으로 느껴지기 때문이다.  \n좋은 학습 플랫폼이라면 개개인이 갖고 있는 백그라운드에 따라 학습 성과가 천차만별이 되는 것을 최대한 지양해야하고, 백그라운드가 부족하더라도 최대한 많은 것을 가져갈 수 있는 방향으로 제품을 만들어야 한다고 생각한다.  \n물론 자질이 훌륭한 분들의 상방선을 열어두고 극대화 하는 것도 중요하지만 그런 분들은 학습 플랫폼의 도움 없이도 혼자서도 잘 할 수 있는 분들이기에 오히려 우리 같은 플랫폼의 도움이 필요로 하지 않는다.\n진짜 우리의 도움이 필요한 분들은 부족한 백그라운드로 인해서 배우는데 어려움이 있거나 효율이 떨어지는 분들이다.\n그들에게 학습에 대한 레버리지를 줄 수 있는 것을 지향해야한다고 보는 것이다.  \n그런 면에서 AI 채팅으로 모르는 것을 물어보세요 라는 것은 이 관점에서는 불합격인 제품이라고 본다.\n왜냐면 프롬프트 역량에 따라 학습 효율이 천차만별로 나뉘기 때문이다.  \n지금도 대다수의 많은 사람들은 AI 채팅을 통해 제대로 학습하는 사람은 극 소수이다.\n희노애락으로 AI를 쓰시는 분들은 많지만, 여전히 많은 분들이 학습하기 위해 AI를 쓰는 경우는 전체 인구에 비하면 소수이다.\nAI는 틀린 답을 낸다고 생각해서 적당히 질문하다가 원하는 답이 안나와서 \"에잇\" 하고 다시 기존의 검색 서비스를 이용하시거나 AI가 틀린 답을 낸 건지도 모르고 사용 하시는 분들도 많다.\n혹은 여전히 AI를 쓰지 않는 분들도 많다.  \n이런 관점에서는 개인의 프롬프트 역량에 따라 정확한 답변을 받을 수 있을 확률이 달라지는 AI 채팅이란 기능이 진짜 백그라운드가 부족한, 독학이 어려운 분들에게 도움이 되는 제품인가?   \n\"AA\" 라는 주제를 공부하려고 강의를 결제했는데, 그 주제를 잘 공부하기 위해서는 AI 프롬프트를 자세히 공부해야한다 라는 것이 과연 학습 플랫폼이 고객에게 전달해야할 가치인가? 라는 근본적인 의문인 것이다.  \n이는 얼핏보면 AI 이전 시대의 '영어' 와 비슷한 것 같단 생각도 든다.  \n영어를 잘 한다면 전세계의 모든 지식을 쉽게 배울 수 있다.\n강의에서 전달하고자 하는 내용을 모두 영어로 설명한다면 관련된 내용을 추가적으로 찾아볼때도 훨씬 더 편하게 찾아 볼 수 있다.\n모든 용어가 다 원래의 용어 그대로를 사용할테니 더 정확한 설명이 될 것이고, 영어로 배운 사람은 이후에도 그 주제에 대해서는 훨씬 더 정확히, 훨씬 더 확장성 있게 학습을 한 상태가 된다.  \n근데 그 서비스가 과연 학습 성장을 평등하게 제공한 것인가?\n그 서비스는 영어를 잘 아는 사람들만을 위한 서비스이다.  \n학습 성장 평등을 지향하는 우리 같은 학습 플랫폼은 영어, 프롬프트 역량이 부족해도 잘 배울 수 있는 환경을 만드는 것에 집중해야 한다는 생각이 요즘 더 강하게 들었다.    \nAI는 사업과 제품에 있어서 큰 곱하기 효과를 주는 것은 맞는데, 이것 자체가 제품이나 사업이 되어서는 안된다.  \n특히나 그 기능이 정말로 우리가 깊은 고민 없이 그냥 남들이 하니깐 하는 정도 수준에서의 기능이라면 더더욱 그 방향은 위험하다고 본다.  \n그건 뭘 위한 것인지 목표 없이 단순히 AI를 붙이고 '해줘'에 가까운 것인데, 그런건 좋은 제품의 기준에는 전혀 합당하다고 보진 않는다.  \n발전 방향도 어색하다고 본다.\nAI 채팅의 답변이 좋으려면 그만큼 더 좋은 모델을 사용해야한다.\n근데 좋은 모델을 사용할수록 대부분 BEP를 맞추기 힘들다.\n그 많은 AI 토큰 비용을 다 플랫폼이 부담해야하고, 그러다 보면 플랫폼 수수료는 더욱 더 높아진다.  \n그렇다면 저렴한 모델을 고객에게 제공하고 별로인 AI 모델인데 쓸려면 써라 정도의 스탠스를 가지고 가는 것도 너무 웃긴다.\n어차피 만족할만한 답변은 나오지 않는데 고객은 그걸 왜 써야하나.\n반면 이런 기능들은 좋다.  \n\"이 내용을 어디선가 봤는데, 그게 어느 강의의 어느 영상이였는지 모르겠다\" 라면 그걸 쉽게 찾을 수 있는 검색\n방금 전에 강사님이 \"이 내용은 다른 강의에서 자세히 이야기 하고 있으니 그 강의를 수강해보세요\" 라고 하는데 그게 어느 강의의 어느 영상 몇분째 인지 알려주는 학습 도우미\n\"남들을 가르치는 것이 가장 좋은 학습 방법\" 이라는 기준으로 방금 배운 내용을 토대로 누군갈 가르쳐보는 경험을 줄 수 있는 환경\n이런 기능들은 목표가 뚜렷하고 프롬프트 등의 백그라운드 지식과 관계없이 학습을 더 잘할 수 있도록 나름의 고민과 여러 학습 효과에 대한 자료를 기반으로 했기 때문에 좋다.\n고객이 학습을 하는데 있어 방해되는 요소가 자연스레 해소 되는 것이기도 한다.  \n물론 이런 예시들을 전부 \"AI 채팅으로 물어보도록 하면 되지 않냐\" 고 할 수도 있다.\n그건 세상에서 가장 똑똑한 과외 선생님을 붙여도 서울대를 못가는 수많은 학생들과 같다.  \n\"내가 뭘 모르는지도 모르고, 뭘 물어봐야하는지도 모르는\" 대다수의 학생들에겐 적합하지 않다.  \n고객에게 \"이런 것도 질문하세요\", \"저런 것도 질문하세요\" 라고 하기 보다는 고객 스스로도 몰랐던 학습의 방해 요소들이 제품 안에서 자연스럽게 해결되고, 성장을 가속할 수 있는 장치가 자연스럽게 적용 되어있는 것 이 가장 좋다.  \n종국에는 \"인프런 써보기 전에는 몰랐는데 인프런 써보고 나니깐 다른 서비스는 못쓰겠다\" 라는 이야기가 나올 수 있다고 믿고 있다.  \n우리가 해야할 것은, AI를 어떻게하면 잘 사용할 수 있을지는 우리의 고민으로 가져오고, 고객들은 AI를 얼마나 잘 사용하는지에 관계없이 원했던 것 이상으로 성장시켜드리는 것이다.  \n그래서 직접 학습자가 되어보는 것이 중요하다.  \n나는 어떤 환경에서 학습이 잘 되었나,  \n나는 아예 처음 접하는 것을 배울때 어떻게 배우나,  \n내가 가장 만족스러웠던 학습 경험은 어떤 것이었나 등등  \n스스로가 고객이 되어서 \"있으면 좋은 것\" 이 아니라, \"이게 진짜 공부하는데 있어서 큰 도움이 되었다\" 라는 것을 계속해서 고민하고 시도해보는 것이 인프랩의 제품 팀으로서 중요하다.  \n그래서 이 부분에 대해 꼭 명심하고 어떤 제품을 만들던 좀 더 날카롭게 고민해야하는 시기인 것 같다.",
        "guid": "https://jojoldu.tistory.com/831",
        "categories": [
          "생각정리",
          "AI",
          "ai 채팅",
          "GPT",
          "교육 플랫폼",
          "인프런",
          "학습"
        ],
        "isoDate": "2025-06-08T01:17:54.000Z"
      }
    ]
  },
  {
    "name": "WestwoodForever's Dev Log",
    "category": "개인",
    "posts": []
  },
  {
    "name": "허니몬(Honeymon)의 자바guru",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Wolf Loves Fox :: 일상",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Game Programmer Life",
    "category": "개인",
    "posts": []
  },
  {
    "name": "IT 프리랜서 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "yuchi's dev",
    "category": "개인",
    "posts": []
  },
  {
    "name": "만화로 나누는 자유/오픈소스 소프트웨어 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "신현석(Hyeonseok Shin)",
    "category": "개인",
    "posts": []
  },
  {
    "name": "한상곤 - Sigmadream",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자 울이 노트",
    "category": "개인",
    "posts": []
  },
  {
    "name": "즐거운 개발자 :: 네이버  블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황제펭귄의 게임개발이야기 [여기는 한국]",
    "category": "개인",
    "posts": []
  },
  {
    "name": "LINE ENGINEERING",
    "category": "기업",
    "posts": [
      {
        "title": "LINE 앱 영상 통화를 가장 많이 사용하는 나라, 태국에서 LINE 앱의 영상 통화 품질을 점검했습니다",
        "link": "https://techblog.lycorp.co.jp/ko/thailand-call-quality-report",
        "pubDate": "Mon, 09 Jun 2025 08:00:00 GMT",
        "content": "들어가며안녕하세요. LINE 메신저 앱의 통화 모듈을 개발하고 있는 곽정남입니다. 제가 속한 Platform Product Engineering 2 팀은 지난 2024년 11월 태...",
        "contentSnippet": "들어가며안녕하세요. LINE 메신저 앱의 통화 모듈을 개발하고 있는 곽정남입니다. 제가 속한 Platform Product Engineering 2 팀은 지난 2024년 11월 태...",
        "guid": "https://techblog.lycorp.co.jp/ko/thailand-call-quality-report",
        "isoDate": "2025-06-09T08:00:00.000Z"
      },
      {
        "title": "코드 품질 개선 기법 14편: 책임을 부여하는 오직 하나의 책임",
        "link": "https://techblog.lycorp.co.jp/ko/techniques-for-improving-code-quality-14",
        "pubDate": "Wed, 04 Jun 2025 02:00:00 GMT",
        "content": "이 글은 2024년 2월 22일에 일본어로 먼저 발행된 기사를 번역한 글입니다.안녕하세요. 커뮤니케이션 앱 LINE의 모바일 클라이언트를 개발하고 있는 Ishikawa입니다.저희 ...",
        "contentSnippet": "이 글은 2024년 2월 22일에 일본어로 먼저 발행된 기사를 번역한 글입니다.안녕하세요. 커뮤니케이션 앱 LINE의 모바일 클라이언트를 개발하고 있는 Ishikawa입니다.저희 ...",
        "guid": "https://techblog.lycorp.co.jp/ko/techniques-for-improving-code-quality-14",
        "isoDate": "2025-06-04T02:00:00.000Z"
      }
    ]
  },
  {
    "name": "뱅크샐러드 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "우아한형제들 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "TOAST Meetup",
    "category": "기업",
    "posts": []
  },
  {
    "name": "ZUM 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "SK Planet",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Spoqa tech blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "팀 왈도 번역팀",
    "category": "게임",
    "posts": []
  },
  {
    "name": "근원님",
    "category": "개인",
    "posts": []
  },
  {
    "name": "호돌맨",
    "category": "개인",
    "posts": []
  },
  {
    "name": "박우빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "문다영",
    "category": "개인",
    "posts": [
      {
        "title": "Cursor 에서 유용한 Setting",
        "link": "https://velog.io/@mdy0102/Cursor-%EC%97%90%EC%84%9C-%EC%9C%A0%EC%9A%A9%ED%95%9C-Setting",
        "pubDate": "Sun, 08 Jun 2025 09:16:16 GMT",
        "content": "<h2 id=\"개요\">개요</h2>\n<p>많은 개발자들이 바이브 코딩의 툴로서 Cursor를 선택하고 있습니다. 특히 VSCode에 익숙한 개발자라면 동일한 인터페이스로 더 높은 생산성을 얻을 수 있기 때문에 Cursor를 선택합니다.\n오늘은 Cursor 사용시 설정하면 좋을 Setting에 대해 알아보겠습니다.</p>\n<h2 id=\"docs\">@Docs</h2>\n<p>Cursor에서 채팅하거나 코드 생성시 참고할만한 공식 문서를 지정할 수 있습니다. 채팅 시 @&lt;문서명&gt; 을 치고 질문을 하면 해당 문서를 참고해서 답변을 생성합니다.</p>\n<p><img src=\"https://velog.velcdn.com/images/mdy0102/post/d5a784b0-a4e4-4a9b-b3e4-59b22faab641/image.png\" alt=\"apply_docs\"></p>\n<p>만약 Cursor가 제공하는 문서에 내가 원하는 문서가 없다면, @doc 을 하면 맨 하단에 Add new doc이 나옵니다.\n<img src=\"https://velog.velcdn.com/images/mdy0102/post/1ff73d7c-3ed0-4677-87eb-25ebb230dd23/image.png\" alt=\"add_new_doc\">\n그 다음 원하는 공식문서를 추가하면 앞으로 채팅에서 공식문서를 참고할 수 있습니다.\n<img src=\"https://velog.velcdn.com/images/mdy0102/post/c0555572-8a98-4a5f-b786-684f47e67c90/image.png\" alt=\"add_langgraph\">\n<img src=\"https://velog.velcdn.com/images/mdy0102/post/df91ea22-5bab-467f-9cc2-7acf6bfa40b8/image.png\" alt=\"add_langgraph_meta\">\n<img src=\"https://velog.velcdn.com/images/mdy0102/post/08e498cb-f8a2-4059-a21e-a70af03018df/image.png\" alt=\"use_langgraph\"></p>\n<h2 id=\"cursor-rules\">Cursor Rules</h2>\n<p>Cursor에서 답변이나 코드를 생성할 때 참고해야할 나만의 룰이 있다면 프로젝트 폴더에 <code>.cursorrules</code> 파일을 만들어 프롬프트를 입력해보세요. 그럼 커서가 해당 프롬프트를 참고해서 코드를 생성합니다.</p>\n<p>저는 Cursor Rule에 다음과 같은 내용을 작성합니다.</p>\n<ul>\n<li>Coding Conventions</li>\n<li>Import 문 구조</li>\n<li>자주 사용하는 패키지 (langchain, langgraph 등)</li>\n<li>UI/ Styling (Shadcn, Tailwind 등을 사용해)</li>\n</ul>\n<h2 id=\"privacy-mode\">Privacy Mode</h2>\n<p>내 코드가 모델 학습에 활용되지 않도록 설정을 원한다면 프라이버시 모드를 활성화해야합니다.\nCursor Setting &gt; Privacy에 가면 Privacy Mode를 설정할 수 있습니다.<img src=\"https://velog.velcdn.com/images/mdy0102/post/8d38910c-3831-4d98-93a4-f990f1e45267/image.png\" alt=\"privacy_mode\"></p>\n<ol>\n<li>프라이버시 모드\n설정에서 &quot;Privacy Mode&quot; 활성화 시 데이터 저장이 전혀 되지 않음\n코드는 저장되거나 학습되지 않음</li>\n<li>일반 모드 (Privacy Mode OFF)\n원격 측정, 사용 데이터, 코드베이스 데이터 수집\n프롬프트, 에디터 작업, 코드 스니펫, 저장소 파일, 코드 편집 내용 포함\n자동완성 사용 시 Fireworks(추론 제공업체)가 추론 속도 개선을 위해 프롬프트 수집 가능</li>\n</ol>\n<h2 id=\"마무리\">마무리</h2>\n<p>이처럼 몇가지 설정을 한다면 Cursor는 내가 원하는 정보와 Rule에 맞춰서 코드 생성 및 채팅 답변을 생성해줍니다. 다음 시간에는 Cursor에서 사용하기 좋은 MCP Tool과 Extension을 소개해보도록 하겠습니다.</p>\n",
        "contentSnippet": "개요\n많은 개발자들이 바이브 코딩의 툴로서 Cursor를 선택하고 있습니다. 특히 VSCode에 익숙한 개발자라면 동일한 인터페이스로 더 높은 생산성을 얻을 수 있기 때문에 Cursor를 선택합니다.\n오늘은 Cursor 사용시 설정하면 좋을 Setting에 대해 알아보겠습니다.\n@Docs\nCursor에서 채팅하거나 코드 생성시 참고할만한 공식 문서를 지정할 수 있습니다. 채팅 시 @<문서명> 을 치고 질문을 하면 해당 문서를 참고해서 답변을 생성합니다.\n\n만약 Cursor가 제공하는 문서에 내가 원하는 문서가 없다면, @doc 을 하면 맨 하단에 Add new doc이 나옵니다.\n\n그 다음 원하는 공식문서를 추가하면 앞으로 채팅에서 공식문서를 참고할 수 있습니다.\n\n\n\nCursor Rules\nCursor에서 답변이나 코드를 생성할 때 참고해야할 나만의 룰이 있다면 프로젝트 폴더에 .cursorrules 파일을 만들어 프롬프트를 입력해보세요. 그럼 커서가 해당 프롬프트를 참고해서 코드를 생성합니다.\n저는 Cursor Rule에 다음과 같은 내용을 작성합니다.\nCoding Conventions\nImport 문 구조\n자주 사용하는 패키지 (langchain, langgraph 등)\nUI/ Styling (Shadcn, Tailwind 등을 사용해)\nPrivacy Mode\n내 코드가 모델 학습에 활용되지 않도록 설정을 원한다면 프라이버시 모드를 활성화해야합니다.\nCursor Setting > Privacy에 가면 Privacy Mode를 설정할 수 있습니다.\n프라이버시 모드\n설정에서 \"Privacy Mode\" 활성화 시 데이터 저장이 전혀 되지 않음\n코드는 저장되거나 학습되지 않음\n일반 모드 (Privacy Mode OFF)\n원격 측정, 사용 데이터, 코드베이스 데이터 수집\n프롬프트, 에디터 작업, 코드 스니펫, 저장소 파일, 코드 편집 내용 포함\n자동완성 사용 시 Fireworks(추론 제공업체)가 추론 속도 개선을 위해 프롬프트 수집 가능\n마무리\n이처럼 몇가지 설정을 한다면 Cursor는 내가 원하는 정보와 Rule에 맞춰서 코드 생성 및 채팅 답변을 생성해줍니다. 다음 시간에는 Cursor에서 사용하기 좋은 MCP Tool과 Extension을 소개해보도록 하겠습니다.",
        "guid": "https://velog.io/@mdy0102/Cursor-%EC%97%90%EC%84%9C-%EC%9C%A0%EC%9A%A9%ED%95%9C-Setting",
        "isoDate": "2025-06-08T09:16:16.000Z"
      }
    ]
  },
  {
    "name": "유수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "안건주",
    "category": "개인",
    "posts": []
  },
  {
    "name": "손현호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "STARTUP BIBLE",
    "category": "개인",
    "posts": [
      {
        "creator": "Kihong Bae",
        "title": "잠수보단 거절",
        "link": "https://www.thestartupbible.com/2025/06/just-say-no-and-never-go-mia.html",
        "pubDate": "Sun, 08 Jun 2025 21:19:00 +0000",
        "content:encodedSnippet": "한국과 미국을 1대1로 비교하는 건 큰 의미가 없다. 문화가 다르고, 사람들이 다르고, 교육 내용과 환경이 다르므로 살아가는 방식과 일하는 방식이 너무 다르다. 그래서 무조건 미국은 좋고, 한국은 나쁘다고 하는 건 정말 구닥다리 사고방식이다. 오히려 나는 요새 무조건 한국은 좋고, 미국은 나쁘다는 말을 많이 하는데, 물론, 이 또한 유연하지 못한 사고와 발언이다.\n그래도 비즈니스 문화에서 한국이 미국보다 훨씬 못하다고 생각하는 게 바로 거절하는 문화다. 상대방이 나에게 뭔가를 간절하게 원하는데, 내가 못 하거나, 아니면 단순히 하기 싫다면, 그냥 거절하면 되는데, 이게 꽤 많은 한국 분에겐 참 어려운가 보다.\n내가 못 하는 거면, 그냥 솔직히 내 능력이 안 되거나, 시간이 안 되거나, 뭐 여러 가지 합당한 이유를 – 상대방이 합당하다고 생각해서 나한테 서운하게 생각하지 않는 – 대면서 그냥 못 한다고 하면 된다. 한국에서 태어나서, 한국에서 정규 교육을 받고, 한국의 기업에서 일을 해 본 많은 분들이 실은 이것도 힘들어한다.\n더 어려운 거절은 내가 할 수 있지만, 그냥 하기 싫을 때이다. 나도 이런 경우가 상당히 많다. 엄청 바쁘거나, 상대방의 부탁을 그냥 들어주기 싫거나, 아니면 그냥 굳이 내가 시간과 에너지를 쓰기 싫을 때가 있다. 상대방의 부탁을 그냥 들어주기 싫은 경우는, 그분이 미워서라기보단 그냥 잘 모르는 분이 불쑥 연락이 와서 뭔가를 해달라고 할 때다. 나한테 큰 도움이 되지도 않은데 굳이 내가 잘 모르는 분을 위해서 시간을 투자할 필요가 없고, 그냥 여기에 시간을 쓸 바에야 집에서 책을 읽거나 잠을 자는 게 더 좋을 때가 있다.\n나는 거절을 꽤 잘 한다고 생각한다. 실은 과거엔 나도 남들이 부탁하면 웬만하면 다 들어줬다. 한때는 모든 사람들에게 친절해야만 한다고 생각했고, 내가 거절했을 때 상대방이 나에 대해서 나쁘게 생각하는 걸 좀 두려워할 때가 있었다. 그런데, 이렇게 해보니, 내가 원하는 삶을 살기보단 어느 순간 남이 나에게 원하는 삶을 살고 있다는 느낌을 받아서 그 이후론 의식적으로 모든 걸 거절하기 시작했다. 못 하는 건 그냥 못 하므로 못 한다고 하고, 하기 싫은 건 그냥 하기 싫어서 안 한다고 한다. 이렇게 너무 직설적으로 이야기하면 꽤 많은 분들이 내가 인성이 나쁘고, 싸가지가 없다고 생각하는데, 뭐, 그렇게 신경 쓰지 않기 때문에 상관없다. 심지어 전엔 어떤 분이 뭔가를 부탁했는데, 내가 잘할 수 있는 일이었지만, 그냥 못 한다고 했다. 그러자 이분은 일정이 안 맞는 줄 알고, 다른 여러 날짜를 제시했는데, 그냥 전부 다 못 한다고 하면서, 시간은 가능한데 내가 하기 싫다고 했다. 그 이후로 이분은 나를 사람 취급하지 않았는데, 뭐, 나는 크게 신경 쓰지 않는다.\n내 경험상, 오히려 이렇게 대차게 거절하는 게 상대방이나 나를 위해서 가장 좋은 관계 유지 방법이다. 거절하는 사람으로서도 처음엔 불편하고, 거절당하는 사람으로서도 기분이 상할 수도 있지만 – 솔직히 나도 거절을 정말 많이 당하는데, 거절당하는 사람의 입장에서 기분이 상할 이유는 전혀 없다 – 결국엔 서로 깔끔하게 교통정리가 되고, 각자의 인생을 살 수 있고, 각자 그냥 move on 할 수 있다. 이런 분들은 오히려 평생 친구가 될 수도 있다.\n그런데 이 거절하는 걸 너무 힘들게 생각해서, 아예 상대방의 연락을 피하고 잠수 타는 분들이 의외로 많다. 내가 세상에서 가장 싫어하는 부류의 사람들이고, 인간관계에 있어서 잠수타기는 최악의 한 수이다. 이런 분들은 본인은 ‘원래’ 상대방에게 싫은 소리를 못 한다고 하는데, 이건 개소리다. 그냥 본인들이 상대방에게 싫은 소리를 하고 싶지 않기 때문이다. 싫은 소리 하거나, 거절하면 상대방이 본인을 안 좋게 생각하는 게 걱정되는 이런 분들의 또 다른 특성은 남이 그들에 대해서 어떻게 생각하는지에 지대한 관심이 많다는 점이다.\n나도 가끔 이런 분들을 만난다. 잘 이야기하다가 갑자기 연락이 끊기는데, 내 성격상 이렇게 연락이 안 되면 나는 계속 연락한다. 끝까지 잠수 타는 분들도 있지만 – 참고로, 나는 이런 사람들은 인간 취급 안 한다 – 대부분 몇 달 뒤에 다시 연락된다. 그리고 왜 갑자기 잠수 탔냐고 물어보면 돌아오는 답변은 “바빴어요” , “원래 내가 싫은 소리 못 하잖아요” 또는 “내가요?” 정도이다.\n하기 싫으면 그냥 하기 싫다고 해라. 못 하겠으면 그냥 못 한다고 해라. 그리고 만약 거절하는 게 내가 미안해야 할 일이라면, 아주 솔직하게 미안하다고 해라. 특히 나 같은 사람한텐 그냥 대차게 거절해야 한다. 안 그러면 나는 희망을 갖고 계속 귀찮게 하고, 계속 연락할 것이다. 어쨌든 절대로 잠수는 타지 마라. \n잠수 타면서 오랫동안 마음이 불안한 것보단, 그냥 거절하고 그때 한순간만 살짝 미안함을 느끼는 게 스트레스 관리에도 훨씬 좋다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2025/06/just-say-no-and-never-go-mia.html#respond",
        "content": "한국과 미국을 1대1로 비교하는 건 큰 의미가 없다. 문화가 다르고, 사람들이 다르고, 교육 내용과 환경이 다르므로 살아가는 방식과 일하는 방식이 너무 다르다. 그래서 무조건 미국은 좋고, 한국은 나쁘다고 하는 건 정말 구닥다리 사고방식이다. 오히려 나는 요새 무조건 한국은 좋고, 미국은 나쁘다는 말을 많이 하는데, 물론, 이 또한 유연하지 못한 사고와 발언이다. 그래도 비즈니스 문화에서 한국이(...)",
        "contentSnippet": "한국과 미국을 1대1로 비교하는 건 큰 의미가 없다. 문화가 다르고, 사람들이 다르고, 교육 내용과 환경이 다르므로 살아가는 방식과 일하는 방식이 너무 다르다. 그래서 무조건 미국은 좋고, 한국은 나쁘다고 하는 건 정말 구닥다리 사고방식이다. 오히려 나는 요새 무조건 한국은 좋고, 미국은 나쁘다는 말을 많이 하는데, 물론, 이 또한 유연하지 못한 사고와 발언이다. 그래도 비즈니스 문화에서 한국이(...)",
        "guid": "https://www.thestartupbible.com/?p=9463",
        "categories": [
          "Uncategorized",
          "general",
          "people"
        ],
        "isoDate": "2025-06-08T21:19:00.000Z"
      },
      {
        "creator": "Kihong Bae",
        "title": "세상에서 가장 외로운 싸움",
        "link": "https://www.thestartupbible.com/2025/06/fighting-the-loneliest-fight.html",
        "pubDate": "Wed, 04 Jun 2025 21:27:00 +0000",
        "content:encodedSnippet": "세상에서 가장 외로운 직업은 무엇일까? 내가 전 세계의 모든 직업을 알진 못하지만, 내가 아는 한, 세상에서 가장 외로운 직업은 창업가이고, 이들은 세상에서 가장 외로운 전투싸움을 하고 있다. 전투라고 썼다가 지운 이유는, 그래도 같이 싸워주는 부대가 있어서 어느 정도는 쪽수가 맞아야지 전투라고 할 텐데, 대부분의 창업가들은 온 세상을 상대로 혼자 외롭게 싸우기 때문에 이건 싸움이라고 해야 할 것 같다.\n안쓰럽지만, 대부분의 창업가 주변 지인들은 이들을 믿지 않고, 이들이 하는 것도 믿지 않는다. 실은, 이 글을 읽고 있는 분 중 대단하게 큰 스타트업을 만든 분들이 아니라면 – 즉, 이 글을 읽는 대다수 – 당신들이 하는 일을 당신들 친구도 믿지 않고, 심지어는 가족들도 믿지 않을 것이다. 세상에서 이렇게 외로운 직업이 어디 있을까? 그리고 매일 온 세상을 상대로 외롭게 싸워야 하는 이런 직업이 어디 있을까?\n얼마 전에 이런 외로운 싸움을 5년째 하고 있는 창업가를 만났다. 그리고 며칠 후에 10년 넘게 큰 성장 없이 사업을 하는 분을 만났다. 이분들과 조금 더 깊게 이야기해 보니, 내가 생각했던 것보다 훨씬 더 힘든 것 같다. 처음 시작할 땐, 자신을 불신하고 무시했던 사람들을 엿먹이고 싶었고, 그들이 틀렸다는 걸 증명해 주고 싶었다고 한다. 세월이 흘렀고, 5년, 10년이라는 시간이 지나면서 어느 순간 스스로에게도 의구심이 생기기 시작하면서, 세상 그 누구도 안 믿어도 굳게 자신을 믿었던 본인에 대한 불신이 생기기 시작했다. 그러면서 나와 세상과의 외로운 싸움이, 어느 순간 나와 나와의 싸움이 되기도 했다고 한다. 그나마 계속 이 힘든 일을 할 수 있던 몇 가지 계기가 있었는데, 그건 가끔, 아주 가끔 본인을 믿어주는 사람들을 만났고 – 직원과 투자자 – 이들과 같이 외로운 싸움을 하고 있기 때문이라고 한다.\n이런 말 하면 좀 그렇지만, 솔직히 좀 안쓰럽고 짠하고, 미련하다는 생각이 들었지만, 결국 이들을 존경하고 응원하지 않을 수가 없다. 이 세상에는 하는 사람과 안 하는 사람, 이렇게 두 부류의 사람이 있는데, 이들은 하는 사람들이고, 이들을 비난하는 모든 사람들은 안 하는 사람들이다. 안 하는 사람이 하는 사람을 어떻게 비난할 수 있겠는가. \n오늘도 세상에서 가장 외로운 싸움을 하고 있는 창업가들 파이팅. 결과가 어떨진 모르겠지만, 그래도 당신들은 본인의 믿음으로 삶을 살아가는 인생의 승자들이다.(하지만, 사업에서 승자가 될진 잘 모르겠다.)",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2025/06/fighting-the-loneliest-fight.html#comments",
        "content": "세상에서 가장 외로운 직업은 무엇일까? 내가 전 세계의 모든 직업을 알진 못하지만, 내가 아는 한, 세상에서 가장 외로운 직업은 창업가이고, 이들은 세상에서 가장 외로운 전투싸움을 하고 있다. 전투라고 썼다가 지운 이유는, 그래도 같이 싸워주는 부대가 있어서 어느 정도는 쪽수가 맞아야지 전투라고 할 텐데, 대부분의 창업가들은 온 세상을 상대로 혼자 외롭게 싸우기 때문에 이건 싸움이라고 해야(...)",
        "contentSnippet": "세상에서 가장 외로운 직업은 무엇일까? 내가 전 세계의 모든 직업을 알진 못하지만, 내가 아는 한, 세상에서 가장 외로운 직업은 창업가이고, 이들은 세상에서 가장 외로운 전투싸움을 하고 있다. 전투라고 썼다가 지운 이유는, 그래도 같이 싸워주는 부대가 있어서 어느 정도는 쪽수가 맞아야지 전투라고 할 텐데, 대부분의 창업가들은 온 세상을 상대로 혼자 외롭게 싸우기 때문에 이건 싸움이라고 해야(...)",
        "guid": "https://www.thestartupbible.com/?p=9460",
        "categories": [
          "Uncategorized",
          "failure",
          "FoundersAtWork",
          "hustle",
          "inspiring"
        ],
        "isoDate": "2025-06-04T21:27:00.000Z"
      }
    ]
  },
  {
    "name": "매거진 입맛",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "요즘 IT",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "지마켓 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Kimchi hill",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Hudi.blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "토스",
    "category": "기업",
    "posts": [
      {
        "title": "토스, 페이스페이 가맹점 확대…서울 전역 2만 개 점포 시범 운영",
        "link": "https://toss.im/tossfeed/article/facepayseoul",
        "pubDate": "Tue, 10 Jun 2025 08:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}페이스페이 사전 가입자 대상 서울 전 자치구에서 시범 서비스 전개\n카페, 음식점, 미용실 등 생활 밀착형 가맹점으로 이용 가능 업종도 다변화\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n\n토스(운영사 비바리퍼블리카, 대표 이승건)가 ‘페이스페이’ 가맹점을 확대한다고 10일 밝혔다. 서울 시내 2만 개 가맹점에서 페이스페이 시범 운영에 나선다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n토스 페이스페이는 얼굴 인식만으로 간편하게 결제할 수 있는 서비스다. 높은 정확도와 빠른 속도가 강점으로 토스 앱에서 본인 확인 절차를 거쳐 얼굴을 최초 1회 등록하면 신용카드, 체크카드, 계좌 중 원하는 수단으로 편리하게 결제할 수 있다.\n지난 2월 편의점에서 페이스페이를 처음 선보인 데 이어 서울 전 자치구 2만 개 점포에서 시범 운영에 나선다. 페이스페이를 사전 가입한 이용자 중 일부에게 먼저 서비스를 오픈하고, 결제 가능 대상은 점차 늘려갈 계획이다.\n페이스페이는 토스 결제 단말기 및 포스(POS) 솔루션 공급 자회사인 토스플레이스 단말기가 비치된 가맹점에서 이용할 수 있다. 가맹점 수 확대와 더불어 이용할 수 있는 업종도 다양해졌다. 카페, 음식점, 미용실, 학원, 헬스장 등 생활 밀착형 가맹점에서 페이스페이 이용이 가능하다.\n안전하고 편리한 페이스페이를 위한 노력도 기울이고 있다. 24시간 이상거래탐지시스템(FDS)을 가동해 부정 거래를 실시간으로 감지하고 바로 조치한다. ‘안심보상제’도 운영한다. 페이스페이 이용 중 부정 거래가 발생할 경우, 피해 금액을 토스가 선제적으로 보상한다.\n서비스 출시 전, 개인정보보호위원회 사전적정성 검토도 받았다. 사전적정성 검토는 신기술이나 신규 서비스를 출시하려는 기업이 개인정보보호위원회와 개인정보보호 원칙의 합리적인 적용 방안을 찾도록 한 제도다. 이 제도를 거쳐 안면식별정보, 고유식별정보 등을 개인정보보호법상 안전하게 처리할 방안을 마련했다.\n토스 관계자는 “페이스페이가 일상생활에 빠르게 자리 잡을 수 있도록 시범 운영을 통해 사용성과 안정성을 고도화해 나갈 계획”이라며 “안전하고 편리한 서비스를 기반으로 혁신적인 결제 경험을 제공하기 위해 노력하겠다”고 말했다.",
        "content": "페이스페이 사전 가입자 대상 서울 전 자치구에서 시범 서비스 전개",
        "contentSnippet": "페이스페이 사전 가입자 대상 서울 전 자치구에서 시범 서비스 전개",
        "guid": "https://toss.im/tossfeed/article/facepayseoul",
        "isoDate": "2025-06-10T08:00:00.000Z"
      },
      {
        "title": "헬스장 회원권은 신용카드 할부로 결제하면 좋은 이유",
        "link": "https://toss.im/tossfeed/article/installment_payments",
        "pubDate": "Tue, 10 Jun 2025 06:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}헬스장이나 에스테틱처럼 장기 이용권이나 다회권을 구매할 땐 신용카드 할부 결제를 활용하는 게 유리해요. 결제한 곳이 갑자기 폐업하는 등 문제가 생겨도 소비자가 보호 받을 수 있기 때문이에요.\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}할부 결제를 하면 2가지 소비자 권리가 생겨요\n바로 할부철회권과 할부항변권이에요. .css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}거래금액이 20만원 이상이면서 할부 기간이 3개월 이상이면, 이 2가지 권리를 행사할 수 있어요.\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n할부철회권 : 7일(방문 판매 14일) 이내에 계약을 철회할 수 있는 권리\n할부항변권 : 서비스 제공이 불가능하거나 계약이 해지될 경우, 할부금 납입을 거절할 수 있는 권리\n\n카드사에 할부항병권을 행사하겠다고 알리면, 카드사가 나머지 대금을 사업자에게 법적으로 청구할 수 있어요.\n예를 들어, 헬스장에서 12개월 회원권을 구입했는데 2달 뒤 헬스장이 폐업하는 경우 일시불로 구입했다면 이미 지급을 완료했기 때문에 방법이 없어요. 하지만 12개월 할부로 구입했다면 남은 10달 치 할부금에 대해 할부항병권을 행사할 수 있어요. 즉, 남은 할부금을 더이상 내지 않아도 되는 거예요. \n이런 경우엔 권리를 쓸 수 없어요\n아래 해당하는 제품은 제외예요. \n\n농수축산물처럼 제조되지 않은 자연산물 \n세탁기, 냉장고 등 설치 인력이 필요한 가전제품\n자동차, CD, 소프트웨어 등 단 한 번이라도 사용하면 가치가 떨어지는 제품\n의약품, 보험, 부동산 등\n\n또한 할부금을 이미 완납한 거래나 상거래(광고), 투자 목적 등의 거래에 대해서도 행사할 수 없어요. 일시불 결제 후 할부 분납 서비스로 전환한 경우도 제외되니, 처음부터 할부로 결제하는 것이 중요해요.",
        "content": "폐업해도 남은 금액 지킬 수 있는 법적 권리가 생겨요",
        "contentSnippet": "폐업해도 남은 금액 지킬 수 있는 법적 권리가 생겨요",
        "guid": "https://toss.im/tossfeed/article/installment_payments",
        "isoDate": "2025-06-10T06:00:00.000Z"
      },
      {
        "title": "토스페이먼츠, 이커머스 사업자 성장 위한 무료 웨비나 시리즈 개최",
        "link": "https://toss.im/tossfeed/article/tosspayments",
        "pubDate": "Mon, 09 Jun 2025 09:17:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}K-뷰티 브랜드 ‘VT코스메틱’, 대표 제품 ‘리들샷’ 글로벌 판매 전략 소개\n토스페이먼츠, “가맹점 사업 성장 돕는 실질적 파트너로 역할 확대”\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n\n비바리퍼블리카(토스)의 전자지급결제대행(PG) 계열사 토스페이먼츠(대표 임한욱)가 이커머스 사업자의 성장을 돕기 위한 무료 웨비나 시리즈를 개최하고 있다고 9일 밝혔다. 이번 웨비나 시리즈는 단순한 결제 솔루션을 소개를 넘어 고객사들의 사업 성공 사례를 통해 실질적인 비즈니스 성장 전략을 제시하는 데 중점을 뒀다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n이달 25일에는 K-뷰티 브랜드 ‘VT코스메틱’의 글로벌 진출 성공 전략을 주제로 두 번째 웨비나를 연다. VT코스메틱 최철호 부사장이 연사로 나서 ‘리들샷’을 성공으로 이끈 비결을 소개한다. 인디 뷰티 브랜드로서 한국, 일본, 미국 등 시장에서 성과를 거둔 판매 전략과 성장 로드맵도 공개한다. 이어 토스페이먼츠 글로벌세일즈팀 황규호 리더가 국가별 현지 고객이 선호하는 결제 시스템 도입법을 소개한다.\n지난달 열린 첫 웨비나에서는 프리미엄 과일 브랜드 ‘온브릭스’가 자사몰 중심의 성장 전략을 소개했다. 온브릭스 허재성 대표는 자사몰 회원 수를 5천명에서 20만명으로 확대하고 외부 투자 없이 연매출 860억원을 달성한 과정을 공유했다. 당시 웨비나는 700여명이 참석했다.\n웨비나는 토스페이먼츠 공식 블로그를 통해 누구나 신청할 수 있다. 신청 후 별도 발송되는 이메일 내 ‘줌(Zoom)’ 링크를 통해 웨비나에 접속할 수 있다. 참가비는 무료다.\n토스페이먼츠 관계자는 “가맹점의 사업 성장을 돕는 실질적 파트너가 되기 위해 다양한 지원을 이어가고 있다”며 “앞으로도 고객사의 성장 사례를 바탕으로 성공 인사이트를 지속 공유할 계획”이라고 말했다.",
        "content": "가맹점 사업 성장 돕는 실질적 파트너로 역할 확대",
        "contentSnippet": "가맹점 사업 성장 돕는 실질적 파트너로 역할 확대",
        "guid": "https://toss.im/tossfeed/article/tosspayments",
        "isoDate": "2025-06-09T09:17:00.000Z"
      },
      {
        "title": "토스, 근로복지공단과 상생형 직장어린이집 업무 협약",
        "link": "https://toss.im/tossfeed/article/Preschool",
        "pubDate": "Mon, 09 Jun 2025 09:04:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}오는 12월까지 직장어린이집 설립… 인근 중소기업 자녀에게도 개방\n육아 전 단계 포용하는 실질적이고 지속가능한 복지 인프라 완성 노력\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n\n토스(운영사 비바리퍼블리카, 대표 이승건)가 근로복지공단(이사장 박종길, 이하 공단)과 상생형 직장어린이집 확충을 위한 업무 협약을 체결했다고 9일 밝혔다. 협약식은 서울 강남구 소재 토스 본사에서 열렸으며, 토스 정희연 최고인사책임자와 근로복지공단 형희환 복지사업국장 등 주요 관계자들이 참석했다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n이번 협약을 통해 토스와 근로복지공단은 강남구 인근 근로자의 육아 부담을 덜 수 있도록 협력할 계획이다. 토스는 오는 12월 중 아동 49명을 수용할 수 있는 직장어린이집을 새로 설립하고, 이를 제휴한 중소기업 근로자에게도 개방해 지역 공동체와의 상생을 실현할 예정이다. 근로복지공단은 해당 어린이집의 설치와 운영을 위한 재정적·제도적 지원을 맡는다.\n토스는 이미 지난해 6월, 원아의 거주지 인근 어린이집과 제휴하는 거점형 ‘우리동네 토스 어린이집’ 제도를 도입해 팀원들의 육아 접근성 및 편의성을 높인 바 있다. 이번 추가 설립을 통해 단순한 의무 이행을 넘어 지역 기반 공동 양육 문화를 조성하고, 인근 중소기업에게 비상 돌봄 서비스를 포함한 육아 지원 혜택을 나누는 모델로 확대하게 된다.\n아울러 토스는 자녀 계획부터 출산, 육아까지 전 단계를 아우르는 포괄적 복지 인프라를 갖추고 있다. 난임 진단비 지원, 맘스 커뮤니티 운영, 베이비시터 고용 지원, 육아 휴직자와 복직자 대상 맞춤 제도, 출산 예정 팀원을 위한 맘스 키트와 출산 선물 등 다양한 제도가 마련돼 있다.\n정희연 토스 최고인사책임자는 “토스는 개인의 행복이 업무에 몰입을 가져온다는 조직 문화를 바탕으로, 모든 구성원이 육아와 업무를 균형 있게 병행할 수 있도록 실질적이고 진정성 있는 복지 제도를 설계해왔다”며 “이번 협약은 지역 사회와 돌봄 자원을 나누는 상생의 시작이자, 육아의 전 과정을 포용하는 토스의 복지 철학을 구체화하는 계기가 될 것”라고 밝혔다.",
        "content": "오는 12월까지 직장어린이집 설립… 인근 중소기업 자녀에게도 개방",
        "contentSnippet": "오는 12월까지 직장어린이집 설립… 인근 중소기업 자녀에게도 개방",
        "guid": "https://toss.im/tossfeed/article/Preschool",
        "isoDate": "2025-06-09T09:04:00.000Z"
      },
      {
        "title": "토스, 글로벌 채용 네트워킹 행사 ‘토스 USA 밋업’ 개최",
        "link": "https://toss.im/tossfeed/article/tossusameetup",
        "pubDate": "Sun, 08 Jun 2025 06:50:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}실리콘밸리 현역 엔지니어 초청… 사업 비전 및 개발 친화적 조직 문화 공유\n세계적 수준의 인재 집중 채용… AI 기반 서비스 고도화 시동\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n\n토스(운영사 비바리퍼블리카, 대표 이승건)가 지난 6일(현지 시간) 미국 캘리포니아주 로스앨터스에서 첫 글로벌 채용 네트워킹 행사인 ‘토스 USA 밋업(Toss USA Meetup)’을 개최했다고 8일 밝혔다. 이번 행사는 실리콘밸리에서 활동 중인 엔지니어들을 초청해 진행했다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n이날 이승건 대표는 토스의 사업 비전과 엔지니어에게 최적화된 업무 환경을 소개했다. 현재 토스는 전사적으로 머신러닝(ML)과 인공지능(AI) 역량을 강화하고 있으며, 광고 및 커머스(Commerce) 분야를 시작으로 전사 서비스의 AI 기반 고도화를 추진하고 있다. 이 과정에서 엔지니어는 자율적인 실험 문화, 우수한 배포 시스템, 2,480만 월간 활성 사용자 수(MAU, 2024년 12월 기준) 기반의 방대한 데이터를 활용해 AI 전문가로 성장할 수 있다.\n행사가 열린 ‘토스 USA(Toss USA)’는 국내외 우수 인재 확보를 위해 올해 실리콘밸리에 설립한 토스의 글로벌 오피스다. 이곳에서 전 세계 엔지니어들과 교류의 장을 마련하고, 토스의 테크 역량을 소개하는 활동을 이어갈 예정이다. 이를 위해 대한무역투자진흥공사(KOTRA) 실리콘밸리 무역관, 창발(Changbal), 한인정보과학기술자협회(KOCSEA) 등 현지 단체와의 협력도 검토 중이다.\n토스는 올해 AI·데이터 직군에서 세 자릿수의 핵심 인력을 채용할 계획이다. 이를 위해 지난달 ‘데이터·AI 채용팀(Data & AI Recruiting Team)’을 신설했으며, 해당 팀은 토스의 데이터 기반 의사 결정과 약 100개가 넘는 제품 중심의 인프라를 책임지는 다양한 역할의 인재 영입에 집중하고 있다.\n이승건 토스 대표는 “토스는 뛰어난 엔지니어 확보를 최우선 과제로 삼고 있으며, 그에 걸맞은 최고 수준의 처우를 제공할 준비가 돼 있다”라며 “훌륭한 팀원들과 함께 AI 분야에서도 인정받는 기업으로 도약하겠다”고 밝혔다.",
        "content": "AI 인재 확보 본격화",
        "contentSnippet": "AI 인재 확보 본격화",
        "guid": "https://toss.im/tossfeed/article/tossusameetup",
        "isoDate": "2025-06-08T06:50:00.000Z"
      },
      {
        "title": "대환대출로 신용대출 이자 줄일 수 있어요",
        "link": "https://toss.im/tossfeed/article/tossmoment-11",
        "pubDate": "Thu, 05 Jun 2025 06:31:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}월급은 들어오자마자 썰물처럼 빠져나가는 것 같아요. ‘텅장’이라는 신조어가 괜히 생긴 건 아니겠죠. 월세, 공과금, 식비… 그리고 이자까지. .css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}다행인 건, 이자 부담만큼은 대환대출을 통해 줄일 수도 있다는 거예요.\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}대환대출이 뭔가요?\n대환대출, 이름부터 낯설고 어렵습니다. 한자로 ‘대(代)’는 대신한다는 뜻이고, ‘환(換)’은 바꾼다는 뜻이에요. 즉, 지금 이미 가지고 있던 대출을 대신해서 새로운 대출로 바꾸는 것이에요. 쉽게 말해 대출 갈아타기죠. 이름 때문에 생겼던 괜한 벽이 조금은 허물어지죠?\n사실, 예전에는 이런 대출 갈아타기가 쉽진 않았어요. 어디가 더 저렴한지 알아보려면 은행 여러 군데를 직접 돌아다녀야 했고, 서류도 잔뜩 챙겨 다녀야 했기 때문이죠. 대환대출이 복잡하다는 인식은 이때 생겼을지도 몰라요.\n하지만 2023년 5월부터는 완전히 달라졌습니다. 정부가 금리 상승으로 높아지는 금융소비자의 이자 부담을 줄이기 위해 '온라인‧원스톱 대환대출 인프라'를 만들면서, 여러 금융사의 대출 조건을 한 번에 비교할 수 있게 되었거든요. 지금은 앱 하나로 내 대출 정보 불러와 가장 좋은 조건의 대출을 고르고, 원한다면 바로 갈아탈 수 있어요. 여러 은행 지점을 돌아다닐 일도, 복잡한 서류를 준비하는 것도 이제는 필요 없습니다.\n신용대출 갈아타면\n뭐가 좋아질까요?\n대환대출의 가장 좋은 점은 지금보다 낮은 금리로 대출을 받을 수 있다는 것이에요. 예를 들어 2천만 원을 연 10% 이자로 빌렸다면, 1년 동안 내는 이자가 200만 원이에요. 그런데 6%로 갈아타면 이자가 120만 원으로 줄어, 1년에 80만 원을 아낄 수 있어요. 대출금이 크거나 기간이 길수록 그 차이는 더 커져요.\n상환 기간을 조정하는 데에도 유용해요. 상환 기간이 짧아 매달 부담이 큰 분들은, 대환대출로 상환 기간을 늘려서 월 납입액을 줄일 수 있죠. 이렇게 하면 생활비에 숨통이 트이고, 혹시 모를 연체 위험도 낮아져요.\n이런 부분들이 차곡차곡 쌓이면 신용점수에도 긍정적인 영향을 줘요. 연체 이력이 사라지고, 상환 능력이 높아졌다고 평가받아 나중에 또 다른 금융상품을 찾을 때 유리해질 수 있죠. 신용대출을 갈아타는 건 단순히 대출 하나 바꾸는 일이 아니라, 나의 신용을 지키는 일이라고 할 수 있어요.\n신용대출 갈아타기 전,\n꼼꼼하게 확인해야 할 것들\n① 중도상환수수료: 약속된 대출 기간보다 빨리 갚으면 ‘중도상환수수료’를 내야 할 때가 있어요. 대출을 갈아탈 때도 이 수수료가 얼마나 드는지 꼭 확인해야 해요. 그래도 새로 받는 대출 이자가 충분히 낮다면, 수수료를 내고도 갈아타는 게 더 유리할 수 있어요.\n② 인지세: 대출을 받으면 ‘인지세’라는 세금을 국가에 내야 해요. 인지세는 법적으로 효력이 있는 증서를 작성할 때 발생하는 세금이죠. 보통은 은행과 내가 반반씩 나눠서 내는데요. 5천만 원 이하는 세금이 없지만, 1억 원 이하일 땐 7만 원, 10억 원 이하는 15만 원, 10억 원을 넘으면 35만 원이 들어가요. 그래서 대출을 갈아탈 때 본인의 대출 규모에 따라 이 비용까지 계산해봐야 해요.\n③ 금리: 현재 금리 수준도 꼭 확인해야 해요. 예전보다 지금 금리가 낮으면 대환대출로 이자 부담을 줄일 수 있어요. 하지만 금리가 오히려 올랐다면, 대환대출이 도움이 될지 꼼꼼히 따져봐야 해요.\n④ 대출 기간: 새로 받는 대출의 상환 기간도 체크해야 해요. 대출을 갈아타면서 상환 기간이 늘어난다면, 이자가 줄어들어도 결국 내야 할 총이자액은 커질 수 있어요. 짧은 기간에 갚는 게 가능한지, 아니면 기간이 길어도 매달 부담을 줄이는 게 나은지 내 상황에 맞게 정해야 해요.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n토스에서\n가장 쉽고 빠르게\n토스에서는 내가 가진 대출 정보를 정확하게 불러와서, 토스와 제휴된 금융사들이 제안하는 대출 조건을 한눈에 보여줘요. 이자율, 상환 기간, 월 납입액까지 비교해보고, 원하는 조건이 있다면 앱에서 대출을 갈아탈 수 있어요. 중도상환수수료까지 포함해서 실제로 내는 이자 부담액도 알려드려요.\n갈아타기를 미루는 사이에도 이자는 계속 쌓여요. 남은 대출 기간이 길다면 나에게 더 좋은 조건의 대출로 빠르게 바꿀수록 유리해요. 신용대출 갈아타기를 여러 번 조회해도 신용점수에는 전혀 영향이 없으니, 조회하는 것을 주저할 이유는 없습니다. 아래 버튼을 눌러 내가 갈아탈 수 있는 신용대출 상품이 있는지 확인해보세요. 지금보다 더 나은 조건이 기다리고 있을지도 몰라요.\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 윤동해 Graphic 조수희 이제현\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}✽준법감시인 심의완료(2025-284호)",
        "content": "이자 부담 줄일 수 있는 신용대출 갈아타기",
        "contentSnippet": "이자 부담 줄일 수 있는 신용대출 갈아타기",
        "guid": "https://toss.im/tossfeed/article/tossmoment-11",
        "isoDate": "2025-06-05T06:31:00.000Z"
      },
      {
        "title": "농구를 넘어 글로벌 콘텐츠 플랫폼이 된 NBA",
        "link": "https://toss.im/tossfeed/article/moneyball-3",
        "pubDate": "Thu, 05 Jun 2025 06:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}NBA 포스트시즌*이 한창입니다. 이번 시즌에는 창단 이후 처음으로 우승을 노리는 오클라호마시티 썬더의 활약으로 팬들의 관심이 더욱 뜨겁습니다. NBA가 요즘 이렇게 주목받는 건 이제 농구 리그를 넘어, 전 세계를 무대로 하는 콘텐츠 플랫폼으로 자리 잡았기 때문이에요.\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}* 포스트시즌: 정규 시즌이 끝난 뒤 열리는 모든 경기\nNBA에서 최근 눈에 띄는 건 미국 국적이 아닌 선수들의 활약이 눈부시다는 점입니다. 2018-19 시즌부터 올 시즌까지 7시즌 연속으로 유럽, 아프리카, 캐나다 출신 선수들이 정규리그 MVP를 차지했거든요. 이런 모습은 NBA가 글로벌 콘텐츠로 성장하고 있다는 걸 잘 보여줍니다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n20-21, 21-22, 23-24 시즌 MVP를 차지한 세르비아 출신 니콜라 요키치 / 사진: 로이터\n산업적으로도 NBA는 발 빠르게 시대를 읽고 있어요. 한때는 전통적인 방식에 얽매인 리그라는 평가를 받았지만, 이제는 OTT와 소셜 미디어를 가장 잘 활용하는 스포츠 리그로 평가받고 있죠. 어떻게 NBA는 이런 변화를 이끌어냈을까요?\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}실리콘밸리와 월스트리트 출신\n구단주들이 만든 변화\nNBA는 2010년대 이후 완전히 새로운 시대를 맞았어요. 과거에는 지역 기업가들이 농구팀의 구단주가 된다는 건 연고지의 명예를 드러내는 상징으로 여겨졌어요. 그런데 .css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}최근에는 실리콘밸리와 월스트리트 출신의 기술·금융 전문가들이 구단을 사들이고 있어요. LA 클리퍼스의 구단주 스티브 발머처럼 기술과 데이터, 그리고 콘텐츠 비즈니스에 강점을 가진 이들이 NBA를 이끌고 있죠.\n\n실리콘밸리나 월스트리트 출신 구단주들이 NBA에 집중적으로 나타난 이유는 이들이 젊은 시절 마이클 조던을 중심으로 한 NBA 황금시대를 경험했기 때문입니다. 기본적으로, 농구에 대한 애정이 깊은 것이죠.\n물론 그렇다고 단순히 농구만 좋아해서 NBA팀의 구단주가 된 것은 아닙니다. MLB나 NFL은 경기에 뛰는 선수의 수가 많아서 승리를 위한 변수가 상대적으로 NBA보다 더 많습니다. 하지만 농구는 5명이 뛰기 때문에 한두 명의 스타급 선수들이 가지는 영향력이 매우 크죠. 기술·금융 전문가들에게 NBA는 데이터를 활용한 경기 전략과 적절한 선수 트레이드를 통한 빠른 전력 극대화에 안성맞춤이었던 리그였던 셈입니다.\n그리고 농구는 축구 다음으로 글로벌 확장성이 큰 스포츠라는 점도 중요했어요. 야구나 미식축구처럼 특정 지역에서만 사랑받는 종목과는 달리, 북미, 유럽, 아시아 어디서나 큰 관심을 받으니까요. 이런 점에서 NBA는 글로벌 시장을 중시하는 실리콘밸리와 월스트리트 사람들에게 매력적인 투자처였어요.\n\n구단주의 배경이 바뀌면서 NBA의 매출 변화도 확실히 드러나요. 2009-10 시즌에 5조 2,500억 원이었던 매출이 최근 시즌에는 15조 6,000억 원을 넘었습니다. 데이터 기반의 전략과 빠른 실험으로 이런 성장을 만들어냈죠. 유니폼 광고, 트레이드 활성화, 3점슛 중심 전술 혁신 같은 것들이 대표적이에요.\nNBA의 혁신에는 유대계 구단주들의 역할도 눈에 띕니다. 실제로 최근 10년 동안 무려 8번이나 유대인 구단주가 투자한 팀이 우승을 차지했을 정도입니다. 여기에 현 NBA 총재인 아담 실버도 유대인입니다. 그래서 유대인이 NBA의 혁신을 주도했다는 얘기가 나오고 있죠.\n유대인들은 전통적으로 교육과 상업, 금융 분야에서 강한 경쟁력을 키워왔어요. 미국 전체 인구의 2.4%에 불과하지만, 미국 억만장자의 40%가 유대계라는 통계가 있을 정도로 경제적 영향력이 큽니다. 데이터를 중시하고 네트워크를 활용하는 이들의 경영 방식은 NBA를 단순한 ‘경기장을 보유한 스포츠팀’이 아니라 글로벌 IP와 데이터, 콘텐츠 비즈니스로 확장할 수 있는 플랫폼으로 이끌었습니다.\n\n혁신을 이끌고 있는 NBA 총재 아담 실버 / 사진: 로이터\n팬들이 원한다면\n규칙도 바꾸는 유연함\nNBA는 팬들이 더 재미있게 경기를 볼 수 있다면 규칙도 기꺼이 바꿔왔어요. 경기가 즐거워야 팬이 늘고, 팬이 많아진다면 수익은 덩달아 따라오기 때문이죠.\n그래서 핸드체킹 금지(2004-05 시즌)로 외곽 공격수를 자유롭게 풀어주고, 수비 3초 규칙(2001-02 시즌)으로 골밑 수비를 약화해 코트를 넓혔습니다. 공격 리바운드 후 샷 클락은 14초로 단축(2018-19 시즌)해 경기 속도를 높였고, 3점슛 시도가 폭발적으로 늘었습니다. 그 결과, 2010년대 초반만 해도 팀당 경기당 3점슛 시도는 18회 수준이었지만 지금은 37회를 넘었어요.\n\nNBA 3점슛 전술의 아이콘, 스테판 커리 / 사진: 로이터\n2021년에는 7~10위 팀들이 플레이오프*를 놓고 토너먼트를 벌이는 ‘플레이 인 토너먼트’도 생겼어요. 정규 시즌 마지막까지 긴장감을 유지할 수 있도록 한 거죠. 2023-24 시즌부터는 정규 시즌 중간에 ‘인시즌 토너먼트’까지 열어 유럽 축구처럼 또 다른 트로피 경쟁을 만들었어요. NBA는 경기 규칙을 단순한 룰이 아니라, 팬들이 더 몰입할 수 있도록 하는 콘텐츠 설계의 일부로 보고 있어요.\n* 플레이오프: 포스트 시즌 중, 정규 시즌 상위 팀들이 우승을 놓고 겨루는 토너먼트 경기\n넷플릭스, 디즈니 버금가는\n콘텐츠 왕국을 꿈꾸는 NBA\nNBA는 경기 중계뿐만 아니라 경기장 안팎에서 일어나는 모든 순간을 콘텐츠로 만듭니다. 감독의 작전회의, 벤치에서의 리액션, 선수들끼리의 대화까지도 NBA 리그패스*에서 그대로 볼 수 있죠. ESPN과 TNT 같은 중계 파트너사도 이런 영상들을 공유받아서 프리·포스트쇼나 SNS 숏폼 영상으로 가공해 더 많은 팬을 붙잡고 있어요.\n* NBA 리그패스: NBA에서 직접 운영하는 OTT 서비스\n라커룸 비하인드 영상, 팬 인터뷰, 팀별 다큐멘터리 시리즈까지도 만들어내요. 마이클 조던이 시카고 불스에서 활약하던 이야기를 다룬 넷플릭스 다큐멘터리 <The Last Dance>처럼 농구 경기 너머의 이야기를 ‘팔리는 IP’로 키워가는 거죠. 요즘 팬들은 단순히 누가 이겼는지만이 아니라, 누가 어떤 말을 했고 어떤 표정을 지었는지까지도 궁금해합니다. NBA는 이 모든 순간을 이야기로 가공해서 2차 콘텐츠로 풀어냅니다.\n\n선수들의 하이라이트 영상을 NFT 형태로 거래하며 보유할 수 있는 NBA Top Shot\n최근에는 VR과 NFT 같은 새로운 기술도 적극적으로 도입하고 있어요. 리그패스에 VR 중계 기술을 도입해 마치 경기장에 직접 있는 것처럼 몰입감을 높이고, NBA Top Shot 같은 NFT 플랫폼을 통해 명장면을 디지털 소유권으로 만들어 팔고 있죠. 팬들은 이걸 사고팔며, NBA와의 관계를 데이터와 디지털 자산 차원에서 더 깊게 쌓아가고 있어요. 특히 NBA Top Shot의 누적 거래액은 1조 4,000억 원을 돌파할 정도로 규모가 커졌습니다.\n이제 NBA는 단순히 농구 경기만이 아니라, 이야기와 데이터, 디지털 소유권까지 아우르는 거대한 비즈니스로 성장하고 있습니다.\nSNS 영향력\n1위 스포츠 리그, NBA\nNBA는 소셜 미디어에서도 압도적인 영향력을 자랑합니다. 디지털 미디어 분석업체 퀄트릭스가 발표한 자료에 따르면, 4대 소셜 미디어에서 NBA의 팔로워는 2억 600만 명을 넘습니다. 이는 NASA와 넷플릭스보다 많은 수치이며, UFC와 NFL 같은 다른 스포츠 리그들과 비교해도 큰 격차를 보입니다.\n\n이런 영향력은 NBA가 팬들이 자유롭게 콘텐츠를 만들어내도록 허용했기 때문에 가능했습니다. 아담 실버 NBA 총재는 “팬들이 만드는 하이라이트는 스낵이에요. 스낵을 먹으면 결국 정식 식사(정규 중계)를 찾게 됩니다.”라고 말한 바 있죠. 실제로 NBA는 인플루언서나 팬 크리에이터들을 주요 이벤트에 초대해, 그들이 자신만의 방식으로 NBA를 해석하고 전파하게끔 도와주고 있어요.\n다른 프로 스포츠 리그들은 팬들이 올린 경기 영상을 저작권 침해로 규제하는 경우가 많아요. 하지만 NBA는 오히려 팬 콘텐츠를 새로운 성장 동력으로 보고 있죠. 구단들도 소셜미디어 전담팀을 두고 선수들의 훈련 영상이나 개인적인 순간을 SNS에 공유하고 있어요.\n보스턴 셀틱스는 동영상 하이라이트를 제공하면서 선수들의 움직임을 농구 작전 판처럼 볼 수 있는 컨텐츠도 만들고, 경기 후에 스타 선수가 어떻게 컨디션을 회복하는지에 대한 개인적인 영상도 포스팅하며 큰 인기를 누리고 있습니다. 이 덕분에 셀틱스의 인스타그램 팔로워는 이미 700만 명을 넘었습니다. 팬들이 소비하는 콘텐츠를 통해 나오는 광고 수입은 보스턴 셀틱스 구단의 또 다른 비즈니스 모델이 되고 있죠.\nNBA가 오랜 인연을 뒤로 하고\n아마존과 새로 손 잡은 이유\nNBA의 급격한 매출 성장에는 중계권 계약도 중요한 역할을 했습니다. 2002-2003 시즌을 앞두고 NBA는 6시즌 동안 5조 5000억 원에 달하는 중계권료 계약을 체결했었는데, 2016-17 시즌부터 올 시즌까지 9시즌 동안은 33조 원이 넘는 중계권료를 받았습니다. 이를 한 시즌 평균으로 환산하면 3조 6000억 원이 넘는 거액입니다. 다음 시즌부터는 한 시즌에만 9조 5,000억 원이 넘는 중계권 수익을 올릴 전망입니다. 직전 중계권 계약에 비해 금액이 3배 가까이 늘어난 규모죠.\n흥미로운 건, NBA가 35년 동안 중계권을 보유했던 TNT 스포츠 대신 아마존을 새로운 중계 파트너로 선택했다는 사실입니다. TNT 스포츠가 제시한 금액은 아마존과 동일했음에도 불구하고, NBA는 아마존의 손을 들어주었습니다. 왜 NBA는 아마존을 새로운 중계 파트너로 선정했을까요?\n\nNBA는 이제 케이블 TV 중심의 중계가 시대에 뒤처진 방식이라는 점을 잘 알고 있었습니다. 미국 내 케이블 TV 가입 가구는 계속 줄어들고 있으며, OTT가 대세가 되고 있기 때문이죠. 게다가 OTT 서비스는 글로벌 확장력이 뛰어납니다. NBA는 이미 자체 스트리밍 서비스인 리그패스를 운영하고 있지만, 아마존 같은 글로벌 OTT 파트너를 통해 리그의 해외 팬을 더 효과적으로 확보할 수 있다고 판단했습니다.\n무엇보다 가장 중요한 이유는 바로 고객 데이터에 있습니다. 기존 방송사는 단순히 시청자 수만 알려줬지만, 아마존은 “뉴욕에 사는 21세 남성이 스테픈 커리 경기를 23분 시청했고, 나이키 구매율이 평균보다 25% 높다” 같은 데이터를 NBA에 전달할 수 있습니다. NBA는 이런 데이터를 스폰서나 파트너사에 다시 팔아 새로운 수익을 만들어내고 있어요.\n이제 NBA는 단순히 농구 경기만 보여주는 무대가 아닙니다. 경기장에서 펼쳐지는 모든 순간을 이야기로 만들고, 그 이야기를 데이터로 바꿔 새로운 수익을 창출하는 글로벌 콘텐츠 플랫폼이죠. NBA가 만드는 이 흐름은 모든 스포츠 팬과 산업계에 새로운 영감을 주고 있습니다.\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 윤동해 Graphic 이은호 윤자영",
        "content": "데이터와 콘텐츠로 진화하는 스포츠 리그",
        "contentSnippet": "데이터와 콘텐츠로 진화하는 스포츠 리그",
        "guid": "https://toss.im/tossfeed/article/moneyball-3",
        "isoDate": "2025-06-05T06:00:00.000Z"
      },
      {
        "title": "토스페이 혜택, 사용법 총정리 2025년 6월",
        "link": "https://toss.im/tossfeed/article/tosspay-2025-02",
        "pubDate": "Wed, 04 Jun 2025 07:05:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-nv7vyi{margin:24px 0 8px;padding:16px 40px 32px;border-radius:16px;background-color:var(--adaptiveGrey100);}.css-123co55{font-size:19px;letter-spacing:0em;line-height:1.6;margin:24px 0 0;font-weight:400;color:var(--adaptiveGrey900);background-color:transparent;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}3분만 시간 내면 \n✔️ 토스페이에 카드나 계좌를 등록하고 결제하는 방법을 알 수 있어요. \n✔️  무신사, LG전자, 오늘의집, 신세계면세점, 알리익스프레스 등 6월 할인·적립 혜택을 알 수 있어요. \n.css-1c1qox8{font-size:30px;letter-spacing:0em;line-height:1.55;font-weight:bold;color:var(--adaptiveGrey900);margin:40px 0 4px;}\n.css-p4abj2{display:contents;line-height:1.55;}토스로도 간편결제 하세요\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}복잡한 인증 절차나 정보 입력 없이 빠르고 간편하게 결제할 수 있는 간편결제, 토스로도 할 수 있는 것 알고 계셨나요? 미리 등록한 카드나 계좌를 선택해 몇 번의 클릭만으로 편리한 결제를 경험해보세요. \n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n토스페이 사용법 \n한 번만 카드나 계좌를 등록해두면, 결제 시 선택하여 바로 사용할 수 있습니다. 또한, 토스페이 결제 시 포인트 적립 및 다양한 혜택도 받을 수 있어요. 예를 들어, 토스페이로 간편결제 하면 다양한 금융사의 카드/계좌에서 돈이 출금되었더라도, 모든 결제에 대해 토스페이 포인트가 쌓이는 장점이 있어요.\n토스페이에 카드, 계좌 등록하기 \n(1) 토스 홈에서 [결제]를 클릭해주세요. ‘결제수단’을 클릭하고, ‘추가하기’로 이동하면 추가할 결제수단(카드나 계좌)을 선택할 수 있어요. \n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n(2) 카드는 카드앱을 통해 몇 번의 클릭만으로 연결할 수 있고, 직접 번호를 입력하거나 스캔할 수도 있어요.\n(3) 계좌는 계좌번호와 은행명만 입력하면 5초 만에 연결할 수 있어요.\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}Tip. 신용카드도 등록 가능해요\n자주 쓰는 신용카드로도 토스페이 결제가 가능해요! 카드 실적, 카드 할부 모두 다 동일한 혜택을 받을 수 있어요.\n토스페이로 결제하기 \n토스페이는 온라인과 오프라인 결제가 모두 가능해요. \n📌 온라인 결제\n(1) 쇼핑몰 결제창에서 결제수단으로 토스페이를 선택하고 결제를 진행해주세요. \n(2) 결제 진행 시, 토스앱으로 곧장 연결되어 간편하게 결제를 진행할 수 있어요. 등록해둔 수단 중 출금될 수단을 선택해 결제하면 돼요.  \n\n📌 오프라인 결제\n(1) 토스 홈에서 [결제]를 클릭해주세요.\n(2) QR코드를 클릭하면 출금될 카드·계좌를 선택할 수 있어요. \n(3) 바코드 리더기에 QR코드를 스캔하면 결제가 완료돼요.\n토스페이 6월 혜택 모아보기\n어느덧 6월, 여름이 성큼 다가왔어요. 옷장도, 장바구니도 계절에 맞게 바뀔 시기죠. 6월에도 조금 더 알뜰한 소비를 위해 실속 있는 토스페이 결제 혜택만 모아 정리했어요.\n.css-2sk6rv{font-size:19px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);white-space:pre-wrap;margin:24px 0;padding-left:20px;position:relative;}.css-2sk6rv::before{content:'';display:block;position:absolute;top:4px;left:0;width:2px;height:calc(100% - 4px * 2);padding:4px 0;background-color:var(--adaptiveGrey800);}\n.css-mlvj3o{white-space:pre-wrap;color:#4593fc;font-weight:bold;}토스페이로 결제하고 자동 할인받기 \n아래 혜택들은 결제 시 토스페이만 선택하면 자동으로 할인이 적용돼요. .css-7mseny>*{margin-left:0;margin-right:0;}.css-7mseny>:last-child{margin-bottom:0;}blockquote>.css-7mseny:first-child>:first-child{margin-top:0;}\n👗 패션\n무신사 6월 ‘무진장’ 캠페인으로 파격 할인받고, 토스페이 결제할인까지 더하면 가장 저렴하게 쇼핑할 수 있어요.\n\n✅ 무신사 (무진장 캠페인 기간)\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n10만원 이상 결제 시 1만원 즉시 할인\n이벤트 기간: 25.06.15~25.06.25\n\n.css-1lvcgm8{padding:22px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;border-radius:20px;}\n.css-13ko30i{width:375px;}무신사 바로 가기\n🍽️ 인테리어\n여름맞이 집 꾸미기, 다가오는 계절에 맞춰 시원한 분위기로 바꿔보세요.\n\n✅ 오늘의집\n\n10만원 이상 토스페이머니·계좌 결제 시 1,000원 즉시 할인\n이벤트 기간: 25.06.01~25.06.30\n\n\n오늘의집 바로 가기\n🛍️ 면세점·해외 직구\n면세 쇼핑부터 해외 직구까지, 토스페이로 결제하면 더 알뜰하게 소비할 수 있어요.\n\n✅ 신세계면세점 \n\n20만원 이상 결제 시 2.4만원 즉시 할인\n100만원 이상 결제 시 12만원 즉시 할인\n이벤트 기간: 25.06.11~25.06.30\n\n✅ 알리익스프레스 \n\n$100 이상 결제 시 $11 즉시 할인 \n이벤트 기간: 25.06.16~25.06.25\n\n\n신세계면세점 바로 가기\n알리익스프레스 바로 가기\n\n할인 쿠폰 발급받기\n아래 혜택들은 토스 앱에서 쿠폰을 발급받고 토스페이로 결제하면 자동으로 적용돼요.\n👗 패션\n옷 쇼핑할 때 지그재그, SSFSHOP도 토스페이 결제 혜택을 받을 수 있어요.\n\n✅ 지그재그\n\n2.5% 적립 쿠폰 \n기간: 25.06.16~25.06.30\n\n✅ SSFSHOP\n\n7% 할인 쿠폰\n기간: 25.06.01~25.06.25\n\n\n🍽️ 식품\n날씨가 더울 때는 입맛 돋우는 시원한 음료를 저렴하게 쟁여보세요.\n\n✅ 코크플레이(코카콜라)\n\n20% 할인 쿠폰\n기간: 25.06.01~25.06.30\n\n\n🛍️ 종합몰\n장바구니에 담아만 놓았던 물건들, 이번 기회에 부담 없이 챙겨보세요.\n\n✅ 11번가\n\n5% 적립 쿠폰\n기간: 25.06.01~25.06.30\n\n\nLG전자, 6월에는 더블 혜택이 찾아와요\n토스페이 할인 쿠폰에 더해 결제창에서도 추가로 할인받을 수 있어요. \nLG전자 제품을 가장 알뜰하게 살 수 있는 타이밍입니다. \n\n이벤트 기간: 25.06.01~25.06.30\n\nStep 1. 쿠폰으로 할인받기\n\n모든 고객 2.5% 적립 (~08.31)\n신규 고객 7.2% 할인 \n신규 고객이라면 2.5% + 7.2% = 최대 9.7% 혜택을 받을 수 있어요.\n\nStep 2. 결제하면서 한 번 더 할인받기 \n\n10만원 이상 결제 시 7% 즉시 할인\n\n\nLG전자 쿠폰 받기\n혹시 여행 계획 있으신가요?\n특히 일본으로 떠나는 분이라면, 이 소식은 꼭 알아두세요. 일본 Paypay MPM 가맹점에서 토스페이로 결제하면 랜덤으로 최대 JPY18,888까지 할인받을 수 있습니다.\n\n기간: 25.06.03~25.08.31\n\n기간 내 1인당 5회 참여 가능해요.\n사전 쿠폰 발급 없이, 결제 즉시 자동 할인 받아요.\n하루 약 200명에게 혜택이 제공되니 놓치지 마세요! \n\n\n무더운 날씨가 다가오지만 토스페이 할인 혜택과 함께 조금은 마음 가벼운 날들 보내시기를 바랍니다. 7월에는 더 풍성하고 시원한 혜택들과 함께 찾아올게요.",
        "content": " 무신사, LG전자, 오늘의집, 신세계면세점 등 할인·적립 쿠폰 확인하기",
        "contentSnippet": "무신사, LG전자, 오늘의집, 신세계면세점 등 할인·적립 쿠폰 확인하기",
        "guid": "https://toss.im/tossfeed/article/tosspay-2025-02",
        "isoDate": "2025-06-04T07:05:00.000Z"
      }
    ]
  },
  {
    "name": "모나미",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김진홍",
    "category": "개인",
    "posts": []
  }
]