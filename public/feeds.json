[
  {
    "name": "ㅍㅍㅅㅅ",
    "category": "큐레이팅",
    "posts": []
  },
  {
    "name": "C++ Team Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Mryam Girmay",
        "title": "Prevent Critical Bugs with MSVC Code Analysis",
        "link": "https://devblogs.microsoft.com/cppblog/prevent-critical-bugs-with-msvc-code-analysis/",
        "pubDate": "Thu, 22 Aug 2024 18:12:24 +0000",
        "content:encodedSnippet": "Imagine this: You’re deep into a complex C++ project, and everything seems to be running smoothly. But then, out of nowhere, a critical bug surfaces— one that requires a bit more foresight. We’ve all been there, right? This is where code analysis steps in as your silent guardian. \nCode analysis is a great tool for catching those elusive bugs and ensuring your code adheres to the best programming practices. It identifies defects that are difficult to discover through testing by searching for specific code patterns known to cause problems.  \n The analysis results are displayed in the Visual Studio Error List window and as squiggles in the editor. This feature checks for problematic code patterns, such as buffer overruns caused by converting an element count into a byte count and null pointer dereferences, even if the code  looks correct. In this blog, we will focus on MSVC Code Analysis, which is one of the different types of code analysis available in Visual Studio for C++. \nWhere MSVC Code Analysis Shines \nIn 2014, the tech world was shaken by the discovery of the Heartbleed bug in OpenSSL. This critical vulnerability, caused by a missing bounds check, allowed attackers to exploit the TLS heartbeat extension and read sensitive data from server memory, including private keys, usernames, and passwords. The fallout was massive, affecting millions of users and causing widespread panic. \nNow, picture yourself as a C++ developer working on a high-stakes project. You know that even a small mistake can lead to significant security vulnerabilities, just like Heartbleed. This is where MSVC Code Analysis becomes your best ally. \nMSVC Code Analysis is a static analysis tool that checks your code for errors, potential improvements, and adherence to coding best practices when using the Microsoft Visual C++ (MSVC) compiler. For example, failing to initialize a pointer (e.g., int* uninitializedPtr;) in your project can result in unpredictable behavior, crashes, and security vulnerabilities. Consider the following scenario: You declare a pointer and initialize it to nullptr (int* imageData = nullptr;). Later, you attempt to allocate memory for the pointer based on uninitialized width and height variables (imageData = new int[width * height];). This can lead to undefined behavior because width and height are not initialized before use. If the pointer is used before being properly assigned, it can lead to accessing uninitialized memory, which Rule C6001 identifies, helping you catch these issues before they become critical problems. The following sample generates ‘Using uninitialized memory’ warning: \n#include <iostream> \r\n\r\n#include <stdexcept> \r\n\r\n class ImageProcessor { \r\n\r\npublic: \r\n\r\n    void processImage() { \r\n\r\n        int width, height; \r\n\r\n        int* imageData = nullptr; \r\n\r\n        try { \r\n\r\n            // Attempt to allocate memory based on width and height \r\n\r\n            imageData = new int[width * height]; // Uninitialized width and height \r\n\r\n            // Process the image data (this will cause undefined behavior) \r\n\r\n            for (int i = 0; i < width * height; ++i) { \r\n\r\n                imageData[i] = i; // Potentially accessing uninitialized memory \r\n\r\n            } \r\n\r\n            // Simulate further processing \r\n\r\n            std::cout << \"Image processed successfully.\" << std::endl; \r\n\r\n        } \r\n\r\n        catch (const std::bad_alloc& e) { \r\n\r\n            std::cerr << \"Memory allocation failed: \" << e.what() << std::endl; \r\n\r\n        } \r\n\r\n        // Clean up allocated memory \r\n\r\n        delete[] imageData; \r\n\r\n    } \r\n\r\n}; \nNow, let’s use this example to understand the different ways to invoke code analysis in Visual Studio.\nBackground Code Analysis  \nThis integral feature of Visual Studio functions as a real-time code analysis tool. This tool is particularly beneficial for you because it: \nProvides immediate feedback on potential issues, aiding in early problem resolution. \nFocuses on the files that are currently open in the editor, streamlining analysis during active development.  \nBackground code analysis will automatically run after you open or save the file. The warning for uninitialized memory will be enabled by default, displaying a green squiggle in the editor and appearing in the error list, as demonstrated in the example below. \n\nThis feature is enabled by default; however, you can double check the setting by navigating to Tools > Options > Text Editor > C/C++ > Advanced > Code Analysis > Disable Background Code Analysis: False.\nManually Running Code Analysis \nIn addition to background code analysis, you can also manually run code analysis as needed. You can start by clearing all warnings in the current file you’re working on, then invoke Code Analysis for the current project. Periodically, run Code Analysis for the entire solution to maintain overall code quality. You can also manually run code analysis for individual files. There are several ways to manually run a code analysis. Following any of these steps will display the ‘Using uninitialized memory’ warning in the error list window for our example. \n1. Menu-bar: \nOpen the project.\nFrom the menu-bar, select Build -> Run Code Analysis on [Solution | Project Name | File] \nFrom the menu-bar, select Analyze -> Run Code Analysis -> [On Solution | Run Code Analysis on ‘project name’ | Run Code Analysis on File]\n\n2. Keyboard Shortcut: \nFor a single file: Ctrl + Shift + Alt + F7 \nLearn more about the different ways to run code analysis manually in Run code analysis. \nEnable Code Analysis on Build \nThis setup ensures that code analysis runs automatically every time you build your project or compile a single file. Think of code analysis as an inspector who checks your project. While this inspector might take more time to examine everything, catching potential issues early provides peace of mind. This additional time you invest   is necessary to ensure your code is secure. To enable it: \n Open Project Properties in Visual Studio.\nNavigate to Configuration Properties > Code Analysis > General. \nSelect the Yes option for Enable Code Analysis on Build. Note that this option is disabled by default, whereas Microsoft Code Analysis is enabled by default.\n\nTo view all default selected rules, including the rule for detecting uninitialized memory, navigate to Configuration Properties > Code Analysis > Microsoft, and then click Configure.   \n\nAfter enabling code analysis on build, building the example code will cause Visual Studio to generate a warning for the lines imageData = new int[width * height];, indicating that width and height are uninitialized. Background code analysis focuses on the files you’re actively working on, while build-time analysis ensures all project files are checked, catching any missed issues that aren’t in the current file. This warning will appear in the Error List window. \n\nKey Events in Microsoft C++ Code Analysis help you quickly identify and fix defects by providing detailed information in selected warnings from the Error List. They trace code flow to pinpoint root causes, making it easier to understand issues like variable initialization or branching. For example, double-clicking the C6001 ‘Using uninitialized memory: width’ warning in the Error List opens a new window showing the Key Events. For further insights, please refer to the Microsoft C++ Code Analysis Warnings with Key Events blog. \n\nCode Analysis Rules and Rulesets  \nRulesets in Visual Studio for C++ are collections of code analysis rules that ensure code quality and adherence to standards. For example, enabling the MSVC rule C26440, ‘Function can be declared ‘noexcept’,’ suggests marking functions with ‘noexcept’ if they do not throw exceptions. This can improve both performance and reliability. \nTo create a new custom rule set with the “Function can be declared ‘noexcept’” rule added, follow these steps: \nOpen Project Properties in Visual Studio \nNavigate to Configuration Properties > Code Analysis > Microsoft. \nIn the Active rules section, click “Configure”  \nSelect the check box for the rule that you want to include in the ruleset. The Action will automatically change from ‘None’ to ‘Warning’. You can change the severity of this rule based on your needs, with options like Error, Info, Hidden, None, or <Inherit>.  \nSave the rule set with a new file name. The custom rule set is now automatically assigned to the project. \n\nTo learn more about using rule sets in depth, refer to the Use Rule Sets to Specify the C++ Rules to Run article.  \nAdditional Tools and Techniques\nVisual Studio offers several features that can enhance code quality and prevent issues like the Heartbleed bug. Here are some tools you might find useful: \nClang-Tidy Code Analysis \nClang-Tidy, a tool used with the LLVM/clang-cl compiler, is designed to modernize your code, ensure adherence to standards, perform static analysis, and automatically format your code. When using an MSVC toolset, you can configure Clang-Tidy to complement or replace the conventional Code Analysis process. This helps catch different types of issues and improves overall code quality. You can find more details in Using Clang-Tidy in Visual Studio article. \nSuppress Specific Warnings \nSuppressing specific warnings in C++ involves configuring your project settings to ignore certain compiler warnings for a single line, section of code, file, or entire project. This can be done at the project level or for individual files using Visual Studio’s project properties or ‘#pragma warning’ directives. By suppressing less relevant warnings, you can focus on the most critical issues, making the build output cleaner and easier to read, which simplifies identifying and addressing significant problems. To dive deeper into this topic, check out the Suppress compiler warnings article. \nIt’s important to note that Code Analysis tools may occasionally generate false positives. If you encounter a false positive, please report it through the Visual Studio Developer Community channel with detailed repro code and information. This helps us to improve the accuracy of Code Analysis tools and ensures a smoother development experience. \nLearn More \nTo learn more about securing your C++ programs, visit the Build Reliable and Secure C++ programs blog. For the latest updates to the MSVC backend, check out the MSVC Backend Updates in Visual Studio 2022 version 17.10 blog.  \nYour feedback is invaluable in helping us enhance the MSVC Code Analysis experience. Please share your suggestions in the comments below or through the Developer Community. You can also reach us via email at visualcpp@microsoft.com or via X at @VisualC. \nThe post Prevent Critical Bugs with MSVC Code Analysis appeared first on C++ Team Blog.",
        "dc:creator": "Mryam Girmay",
        "comments": "https://devblogs.microsoft.com/cppblog/prevent-critical-bugs-with-msvc-code-analysis/#comments",
        "content": "<p>Imagine this: You’re deep into a complex C++ project, and everything seems to be running smoothly. But then, out of nowhere, a critical bug surfaces— one that requires a bit more foresight. We’ve all been there, right? This is where code analysis steps in as your silent guardian. </p>\n<p>The post <a href=\"https://devblogs.microsoft.com/cppblog/prevent-critical-bugs-with-msvc-code-analysis/\">Prevent Critical Bugs with MSVC Code Analysis</a> appeared first on <a href=\"https://devblogs.microsoft.com/cppblog\">C++ Team Blog</a>.</p>\n",
        "contentSnippet": "Imagine this: You’re deep into a complex C++ project, and everything seems to be running smoothly. But then, out of nowhere, a critical bug surfaces— one that requires a bit more foresight. We’ve all been there, right? This is where code analysis steps in as your silent guardian. \nThe post Prevent Critical Bugs with MSVC Code Analysis appeared first on C++ Team Blog.",
        "guid": "https://devblogs.microsoft.com/cppblog/?p=34525",
        "categories": [
          "C++"
        ],
        "isoDate": "2024-08-22T18:12:24.000Z"
      }
    ]
  },
  {
    "name": "Facebook Engineering",
    "category": "기업",
    "posts": [
      {
        "creator": "",
        "title": "RETINAS: Real-Time Infrastructure Accounting for Sustainability",
        "link": "https://engineering.fb.com/2024/08/26/data-infrastructure/retinas-real-time-infrastructure-accounting-for-sustainability/",
        "pubDate": "Mon, 26 Aug 2024 16:00:40 +0000",
        "content:encodedSnippet": "We are introducing a new metric— real-time server fleet utilization effectiveness —as part of the RETINAS initiative to help reduce emissions and achieve net zero emissions across our value chain in 2030.\nThis new metric allows us to measure server resource usage (e.g., compute, storage) and efficiency in our large-scale data center server fleet in near real-time.\nWe are sharing our learnings in adopting depreciation methods for accumulated carbon assets for internal fleet measurements, and encourage further industry improvement and development on these concepts. This is not intended to replace global emissions accounting standards for purposes of external reporting.\nSince 2020, Meta has maintained net zero emissions in our operations and matched 100% of our electricity use with renewable energy. However, we know our work doesn’t stop there, and we recognize our responsibility to decarbonize our footprint beyond our data centers and offices, including emissions from the server components our suppliers manufacture to our employees’ commutes. To align with the Paris Agreement, we have set a goal to reach net zero emissions across our value chain in 2030.\nMeta’s Net Zero Program has three foundational pillars: understanding our emissions, reducing our emissions, and removing remaining emissions. To understand our emissions, improving the granularity, accuracy, and near real-time measurement of our greenhouse gas data goes beyond carbon accounting. The right data will help us apply actionable metrics to advance decarbonization across our business operations and with our suppliers.\nWith this in mind, we have created the Real Time Infrastructure Accounting for Sustainability (RETINAS) initiative, which seeks to study and understand the impact of server reliability, performance, and operational optimization on Meta’s Scope 3 emissions.\nThis initiative has led to the development of a new internal metric— real-time server fleet utilization effectiveness —that enables us to take action to reduce the emissions associated with the embodied carbon of our data center servers and components.  Embodied carbon contributes to Meta’s upstream Scope 3 emissions, and includes the emissions associated with the full lifecycle of the manufacturing, assembly, and transportation of servers and materials in our physical infrastructure.\nOptimizing the utilization of our server fleet is important to reducing these emissions. Real-time server fleet utilization effectiveness provides a framework toward effective measurement and integration of embodied carbon into ubiquitous infrastructure metrics to drive informed decisions to manage our server fleet resource usage (e.g., compute and storage) and their impacts on Meta’s Scope 3 emissions. \nHow we measure greenhouse gas emissions at Meta\nSince 2011, Meta has reported our Scope 1 and 2 emissions. In 2017, we began reporting select Scope 3 emissions categories. Since 2019 we have reported annually on all relevant emissions defined by the Greenhouse Gas Protocol. We obtain limited assurance conducted by a third party for select environmental metrics. In our accounting, data center servers and their components are a significant driver of our Scope 3 emissions footprint, and we have taken numerous steps to deepen our understanding of those emissions in order to surface reduction opportunities. \nAn important reduction strategy we are focused on is the circularity of our servers and components. The more effectively and efficiently servers are utilized, the more sustainable the server fleet. We can extend the lifespans of servers, components, and network infrastructure with improvements to server reliability, efforts to reuse components based on their reliability expectations, and various performance optimizations and operational improvements (e.g., firmware/server upgrades and repairs).\nWhile implementing these circularity strategies, we observed limitations in current carbon accounting practices to understand and weigh Scope 3 emissions trade-offs in our server fleet against traditional power, performance, and total cost of ownership (TCO) metrics, such as performance per dollar, performance per watt, and performance per dollar per watt, in real-time. \nCurrent carbon accounting and reporting practices for Scope 3 emissions are static. For data center servers and components, in particular, this means that the entirety of the embodied emissions from the upstream supply chain, manufacturing, and logistics is attributed in the year of purchase. Benefits from circularity are not realized in our Scope 3 footprint until future purchases of new servers or components are deferred. This does not provide actionable information to our operational teams in real-time on how varying the usage or the expected life of the acquired servers can impact Meta’s Scope 3 emissions. \nWe see a need to develop internal metrics to monitor and incentivize greater efficiency, utilization, and extension of the expected life of servers, which will influence current and future server fleet management. \nIntroducing real-time server fleet utilization effectiveness\nThe RETINAS initiative, launched by Meta’s Infrastructure Engineering team, seeks to study and understand how server reliability, performance, and operational optimization impact Meta’s Scope 3 emissions. To understand this holistically, we introduced a standardized, fleet-wide metric for any given resource (e.g., a server or rack) that measures the utilization of embodied carbon:\n\n \nWhere: \n\n \n\n \nThis metric borrows depreciation concepts from finance and accounting practices and applies them to aspects of server reliability, efficiency, and useful life. The concept of depreciation is used to showcase the expected useful life of acquired assets. This concept also allows for tracking of acquisition and disposition of server resources at fleet scale and is reported on an ongoing basis. \nUtilization metrics like power usage effectiveness (PUE) and hardware usage effectiveness (HUE) measure the effective IT usage from a power perspective at the data center and server level, respectively.  Combining depreciated Scope 3 emissions with these utilization metrics allows us to standardize these measurements along with other fleet health measurements for a defined period of time. \nWe illustrate the usage of this metric with a set of servers and various circularity strategies. \nExample (current static state) \nLet’s consider an example set of servers purchased in 2023 which have associated embodied emissions attributed to the buyer with 1000 tons of CO2e. Here is how this would be represented using current, static carbon accounting methods: \n\nThere is no representation for the useful life of the example set of servers. If we change the server set’s useful life (UL) from four years to five years, the metric doesn’t move. \nExample (with proposed dynamic accounting)\nFor the same example of servers purchased in 2023 with 1000 units of CO2e Scope 3 emissions, we use the concept of depreciation over a period of useful life of four years (example time horizon):\nDepreciation in action:\n\nIf the server set’s useful life is modified from four years to five years, this would be visible as part of the depreciation metric and showcase the longevity of resource usage. \nEffective change in depreciation with extension (from 4y UL to 5y UL): \n\nWithin large-scale infrastructure, there are different layers of availability within the hardware and software stack, such as hardware, firmware, the kernel, the operating system, and the application.  At each layer, there are metrics associated with efficiency based on available capacity, resources, and their effective use. To represent the use of a depreciation-based metric, we examine the efficiency of a service at the application stack. The representative graph below showcases an example set of variations in the utilization effectiveness stemming from application improvements over a larger time scale.\n\nUtilization effectiveness is defined as:  Total resource available / Resource utilized \n\nCombining the depreciation of embodied emissions resources per unit time to the utilization effectiveness for a given unit of time (say, every year), we can arrive at a more real-time measurement of server fleet utilization effectiveness of embodied carbon. (Note: The measurements for utilization effectiveness in the chart are representative values).\nOur goal is to consistently minimize the real-time server fleet utilization effectiveness. Utilization effectiveness ideally is decreasing asymptotically towards 1, when resources available are 100% utilized.  Depreciation of Scope 3 emissions over a longer period of time due to a longer useful life will also minimize this metric. Combined, this metric allows for ranking of different efforts one must pursue within the server fleet and compare and contrast efficiency improvements, reliability efforts like extensions or initial component selection, and associated embodied carbon impacts. \nBelow is the comparison of real-time server fleet utilization effectiveness and the way the metric behaves under server life extension and efficiency improvements with the above considered scenarios.\n\nCharacteristics of the metric:\nThe metric above can enable relative comparison of circularity strategies on the server fleet. It can be sliced horizontally into any given timescale (from seconds to years) for understanding a resource’s (e.g., servers or racks) embodied emissions attribution giving fine-grained real-time insights for the server fleet. The metric can also be vertically sliced to obtain utilization effectiveness at different layers of the stack, from entire servers, to containers, to production workloads, to app residencies for short durations – combining that with the associated resource available for the chosen abstraction. \nTo illustrate how this metric can be used, using the same set example as above: \nIncreasing server useful life from five years to seven years lowers the ​metric by 28% due to slower depreciation. \nEnabling reuse of a component, pursuing an application efficiency improvement, or choosing server parts that have lower emissions will contribute towards the metric and enable cross-stack tradeoff.\nTo close, we can observe in this example that this single metric ties together different fleet operations towards a single goal of reducing embodied emissions, delivering  insights for decision making at any given time horizon. By integrating depreciation and utilization effectiveness to embodied carbon, our operational and server fleet management teams can leverage this metric to make data-driven decisions that address an important portion of Meta’s Scope 3 footprint.  \nThe post RETINAS: Real-Time Infrastructure Accounting for Sustainability appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>We are introducing a new metric— real-time server fleet utilization effectiveness —as part of the RETINAS initiative to help reduce emissions and achieve net zero emissions across our value chain in 2030. This new metric allows us to measure server resource usage (e.g., compute, storage) and efficiency in our large-scale data center server fleet in [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2024/08/26/data-infrastructure/retinas-real-time-infrastructure-accounting-for-sustainability/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2024/08/26/data-infrastructure/retinas-real-time-infrastructure-accounting-for-sustainability/\">RETINAS: Real-Time Infrastructure Accounting for Sustainability</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "We are introducing a new metric— real-time server fleet utilization effectiveness —as part of the RETINAS initiative to help reduce emissions and achieve net zero emissions across our value chain in 2030. This new metric allows us to measure server resource usage (e.g., compute, storage) and efficiency in our large-scale data center server fleet in [...]\nRead More...\nThe post RETINAS: Real-Time Infrastructure Accounting for Sustainability appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=21592",
        "categories": [
          "Data Center Engineering",
          "Data Infrastructure"
        ],
        "isoDate": "2024-08-26T16:00:40.000Z"
      },
      {
        "creator": "",
        "title": "How PyTorch powers AI training and inference",
        "link": "https://engineering.fb.com/2024/08/23/ml-applications/pytorch-ai-training-inference/",
        "pubDate": "Fri, 23 Aug 2024 16:00:54 +0000",
        "content:encodedSnippet": "Learn about new PyTorch advancements for LLMs and how PyTorch is enhancing every aspect of the LLM lifecycle.\nIn this talk from AI Infra @ Scale 2024, software engineers Wanchao Liang and Evan Smothers are joined by Meta research scientist Kimish Patel to discuss our newest features and tools that enable large-scale training, memory efficient fine-tuning, and on-device LLM capabilities.\nFirst, they cover the importance of memory-efficient fine-tuning and a few common architectural and algorithmic techniques to enable fine-tuning on consumer-grade hardware. Then they discuss the challenges of deploying large models for on-device deployment and how techniques such as quantization make these deployments possible.\n\nThe post How PyTorch powers AI training and inference appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>Learn about new PyTorch advancements for LLMs and how PyTorch is enhancing every aspect of the LLM lifecycle. In this talk from AI Infra @ Scale 2024, software engineers Wanchao Liang and Evan Smothers are joined by Meta research scientist Kimish Patel to discuss our newest features and tools that enable large-scale training, memory efficient [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2024/08/23/ml-applications/pytorch-ai-training-inference/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2024/08/23/ml-applications/pytorch-ai-training-inference/\">How PyTorch powers AI training and inference</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "Learn about new PyTorch advancements for LLMs and how PyTorch is enhancing every aspect of the LLM lifecycle. In this talk from AI Infra @ Scale 2024, software engineers Wanchao Liang and Evan Smothers are joined by Meta research scientist Kimish Patel to discuss our newest features and tools that enable large-scale training, memory efficient [...]\nRead More...\nThe post How PyTorch powers AI training and inference appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=21568",
        "categories": [
          "AI Research",
          "ML Applications",
          "Open Source",
          "AI Infra @ Scale"
        ],
        "isoDate": "2024-08-23T16:00:54.000Z"
      },
      {
        "creator": "",
        "title": "Inside the hardware and co-design of MTIA",
        "link": "https://engineering.fb.com/2024/08/22/ml-applications/meta-mtia-hardware-co-design/",
        "pubDate": "Thu, 22 Aug 2024 16:00:34 +0000",
        "content:encodedSnippet": "In this talk from AI Infra @ Scale 2024, Joel Colburn, a software engineer at Meta, technical lead Junqiang Lan, and software engineer Jack Montgomery discuss the second generation of MTIA, Meta’s in-house training and inference accelerator.\nThey cover the co-design process behind building the second generation of Meta’s first-ever custom silicon for AI workloads, including the PyTorch software ecosystem, and the model architectures for Meta’s key applications. They demonstrate how MTIA achieves the performance, efficiency, and developer experience to successfully launch models into production. They also highlight several co-design examples where special silicon features are utilized to accelerate Meta’s models.\n\nThe post Inside the hardware and co-design of MTIA appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>In this talk from AI Infra @ Scale 2024, Joel Colburn, a software engineer at Meta, technical lead Junqiang Lan, and software engineer Jack Montgomery discuss the second generation of MTIA, Meta’s in-house training and inference accelerator. They cover the co-design process behind building the second generation of Meta’s first-ever custom silicon for AI workloads, [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2024/08/22/ml-applications/meta-mtia-hardware-co-design/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2024/08/22/ml-applications/meta-mtia-hardware-co-design/\">Inside the hardware and co-design of MTIA</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "In this talk from AI Infra @ Scale 2024, Joel Colburn, a software engineer at Meta, technical lead Junqiang Lan, and software engineer Jack Montgomery discuss the second generation of MTIA, Meta’s in-house training and inference accelerator. They cover the co-design process behind building the second generation of Meta’s first-ever custom silicon for AI workloads, [...]\nRead More...\nThe post Inside the hardware and co-design of MTIA appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=21571",
        "categories": [
          "AI Research",
          "ML Applications",
          "AI Infra @ Scale"
        ],
        "isoDate": "2024-08-22T16:00:34.000Z"
      },
      {
        "creator": "",
        "title": "Bringing Llama 3 to life",
        "link": "https://engineering.fb.com/2024/08/21/production-engineering/bringing-llama-3-to-life/",
        "pubDate": "Wed, 21 Aug 2024 16:00:49 +0000",
        "content:encodedSnippet": "Llama 3 is Meta’s most capable openly-available LLM to date and the recently-released Llama 3.1 will enable new workflows, such as synthetic data generation and model distillation with unmatched flexibility, control, and state-of-the-art capabilities that rival the best closed source models. \nAt AI Infra @ Scale 2024, Meta engineers discussed every step of how we built and brought Llama 3 to life, from data and training to inference. \nJoe Spisak, Product Director and Head of Generative AI Open Source at Meta, talks about the history of Llama and Meta’s overarching vision for open source AI.\nHe’s joined by Delia David, a software engineer at Meta, to discuss all things data-related for GenAI. David covers the diversity, volume, and freshness of data needed for GenAI and how different data types should be extracted and prepared.\nKaushik Veeraraghavan, a software engineer at Meta, discusses how Meta trains Llama at scale and delves into the data center, networking, and software investments that have enabled the development of Meta’s Llama 3 models.\nFinally, Ye (Charlotte) Qi, a production engineer at Meta, discusses how Meta handles inference for Llama. Optimizing and scaling LLM inference is important for enabling large-scale product applications. Qi introduces key parallelism techniques that help scale model sizes and context windows, which in turn influence inference system designs. She also discusses practical challenges associated with deploying these complex serving paradigms throughout Meta’s internal cloud to our data center of heterogeneous hardware.\n\nThe post Bringing Llama 3 to life appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>Llama 3 is Meta’s most capable openly-available LLM to date and the recently-released Llama 3.1 will enable new workflows, such as synthetic data generation and model distillation with unmatched flexibility, control, and state-of-the-art capabilities that rival the best closed source models.  At AI Infra @ Scale 2024, Meta engineers discussed every step of how we [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2024/08/21/production-engineering/bringing-llama-3-to-life/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2024/08/21/production-engineering/bringing-llama-3-to-life/\">Bringing Llama 3 to life</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "Llama 3 is Meta’s most capable openly-available LLM to date and the recently-released Llama 3.1 will enable new workflows, such as synthetic data generation and model distillation with unmatched flexibility, control, and state-of-the-art capabilities that rival the best closed source models.  At AI Infra @ Scale 2024, Meta engineers discussed every step of how we [...]\nRead More...\nThe post Bringing Llama 3 to life appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=21564",
        "categories": [
          "AI Research",
          "Culture",
          "ML Applications",
          "Open Source",
          "Production Engineering",
          "AI Infra @ Scale"
        ],
        "isoDate": "2024-08-21T16:00:49.000Z"
      },
      {
        "creator": "",
        "title": "Aparna Ramani discusses the future of AI infrastructure",
        "link": "https://engineering.fb.com/2024/08/20/data-infrastructure/aparna-ramani-future-of-ai-infrastructure-meta/",
        "pubDate": "Tue, 20 Aug 2024 16:00:26 +0000",
        "content:encodedSnippet": "Delivering new AI technologies at scale also means rethinking every layer of our infrastructure – from silicon and software systems and even our data center designs.\nFor the second year in a row, Meta’s engineering and infrastructure teams returned for the AI Infra @ Scale conference, where they discussed the challenges of scaling up an infrastructure for AI as well as work being done on our large-scale GPU clusters, open hardware designs for next-generation data center hardware, and how Meta is building custom silicon like the Meta Training and Inference Accelerator (MTIA) to handle some of our AI training workloads.\nAparna Ramani, VP of Engineering at Meta, responsible for AI infrastructure, data infrastructure and developer infrastructure, delivered the opening keynote at AI Infra @Scale 2024 and discussed the AI landscape up to today, the technical challenges, and how solutions like open models and hardware can push AI to new frontiers.\nWatch the full keynote presentation below:\n\nThe post Aparna Ramani discusses the future of AI infrastructure appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>Delivering new AI technologies at scale also means rethinking every layer of our infrastructure – from silicon and software systems and even our data center designs. For the second year in a row, Meta’s engineering and infrastructure teams returned for the AI Infra @ Scale conference, where they discussed the challenges of scaling up an [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2024/08/20/data-infrastructure/aparna-ramani-future-of-ai-infrastructure-meta/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2024/08/20/data-infrastructure/aparna-ramani-future-of-ai-infrastructure-meta/\">Aparna Ramani discusses the future of AI infrastructure</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "Delivering new AI technologies at scale also means rethinking every layer of our infrastructure – from silicon and software systems and even our data center designs. For the second year in a row, Meta’s engineering and infrastructure teams returned for the AI Infra @ Scale conference, where they discussed the challenges of scaling up an [...]\nRead More...\nThe post Aparna Ramani discusses the future of AI infrastructure appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=21559",
        "categories": [
          "AI Research",
          "Data Center Engineering",
          "Data Infrastructure",
          "ML Applications",
          "AI Infra @ Scale"
        ],
        "isoDate": "2024-08-20T16:00:26.000Z"
      }
    ]
  },
  {
    "name": "eBay Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Twitter Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Netflix TechBlog",
    "category": "기업",
    "posts": [
      {
        "creator": "Netflix Technology Blog",
        "title": "Improve Your Next Experiment by Learning Better Proxy Metrics From Past Experiments",
        "link": "https://netflixtechblog.com/improve-your-next-experiment-by-learning-better-proxy-metrics-from-past-experiments-64c786c2a3ac?source=rss----2615bd06b42e---4",
        "pubDate": "Mon, 26 Aug 2024 15:46:24 GMT",
        "content:encodedSnippet": "By Aurélien Bibaut, Winston Chou, Simon Ejdemyr, and Nathan Kallus\n\nWe are excited to share our work on how to learn good proxy metrics from historical experiments at KDD 2024. This work addresses a fundamental question for technology companies and academic researchers alike: how do we establish that a treatment that improves short-term (statistically sensitive) outcomes also improves long-term (statistically insensitive) outcomes? Or, faced with multiple short-term outcomes, how do we optimally trade them off for long-term benefit?\nFor example, in an A/B test, you may observe that a product change improves the click-through rate. However, the test does not provide enough signal to measure a change in long-term retention, leaving you in the dark as to whether this treatment makes users more satisfied with your service. The click-through rate is a proxy metric (S, for surrogate, in our paper) while retention is a downstream business outcome or north star metric (Y). We may even have several proxy metrics, such as other types of clicks or the length of engagement after click. Taken together, these form a vector of proxy metrics.\nThe goal of our work is to understand the true relationship between the proxy metric(s) and the north star metric — so that we can assess a proxy’s ability to stand in for the north star metric, learn how to combine multiple metrics into a single best one, and better explore and compare different proxies.\nSeveral intuitive approaches to understanding this relationship have surprising pitfalls:\n\nLooking only at user-level correlations between the proxy S and north star Y. Continuing the example from above, you may find that users with a higher click-through rate also tend to have a higher retention. But this does not mean that a product change that improves the click-through rate will also improve retention (in fact, promoting clickbait may have the opposite effect). This is because, as any introductory causal inference class will tell you, there are many confounders between S and Y — many of which you can never reliably observe and control for.\nLooking naively at treatment effect correlations between S and Y. Suppose you are lucky enough to have many historical A/B tests. Further imagine the ordinary least squares (OLS) regression line through a scatter plot of Y on S in which each point represents the (S,Y)-treatment effect from a previous test. Even if you find that this line has a positive slope, you unfortunately cannot conclude that product changes that improve S will also improve Y. The reason for this is correlated measurement error — if S and Y are positively correlated in the population, then treatment arms that happen to have more users with high S will also have more users with high Y.\n\nBetween these naive approaches, we find that the second one is the easier trap to fall into. This is because the dangers of the first approach are well-known, whereas covariances between estimated treatment effects can appear misleadingly causal. In reality, these covariances can be severely biased compared to what we actually care about: covariances between true treatment effects. In the extreme — such as when the negative effects of clickbait are substantial but clickiness and retention are highly correlated at the user level — the true relationship between S and Y can be negative even if the OLS slope is positive. Only more data per experiment could diminish this bias — using more experiments as data points will only yield more precise estimates of the badly biased slope. At first glance, this would appear to imperil any hope of using existing experiments to detect the relationship.\nThis figure shows a hypothetical treatment effect covariance matrix between S and Y (white line; negative correlation), a unit-level sampling covariance matrix creating correlated measurement errors between these metrics (black line; positive correlation), and the covariance matrix of estimated treatment effects which is a weighted combination of the first two (orange line; no correlation).\nTo overcome this bias, we propose better ways to leverage historical experiments, inspired by techniques from the literature on weak instrumental variables. More specifically, we show that three estimators are consistent for the true proxy/north-star relationship under different constraints (the paper provides more details and should be helpful for practitioners interested in choosing the best estimator for their setting):\n\nA Total Covariance (TC) estimator allows us to estimate the OLS slope from a scatter plot of true treatment effects by subtracting the scaled measurement error covariance from the covariance of estimated treatment effects. Under the assumption that the correlated measurement error is the same across experiments (homogeneous covariances), the bias of this estimator is inversely proportional to the total number of units across all experiments, as opposed to the number of members per experiment.\nJackknife Instrumental Variables Estimation (JIVE) converges to the same OLS slope as the TC estimator but does not require the assumption of homogeneous covariances. JIVE eliminates correlated measurement error by removing each observation’s data from the computation of its instrumented surrogate values.\nA Limited Information Maximum Likelihood (LIML) estimator is statistically efficient as long as there are no direct effects between the treatment and Y (that is, S fully mediates all treatment effects on Y). We find that LIML is highly sensitive to this assumption and recommend TC or JIVE for most applications.\n\nOur methods yield linear structural models of treatment effects that are easy to interpret. As such, they are well-suited to the decentralized and rapidly-evolving practice of experimentation at Netflix, which runs thousands of experiments per year on many diverse parts of the business. Each area of experimentation is staffed by independent Data Science and Engineering teams. While every team ultimately cares about the same north star metrics (e.g., long-term revenue), it is highly impractical for most teams to measure these in short-term A/B tests. Therefore, each has also developed proxies that are more sensitive and directly relevant to their work (e.g., user engagement or latency). To complicate matters more, teams are constantly innovating on these secondary metrics to find the right balance of sensitivity and long-term impact.\nIn this decentralized environment, linear models of treatment effects are a highly useful tool for coordinating efforts around proxy metrics and aligning them towards the north star:\n\nManaging metric tradeoffs. Because experiments in one area can affect metrics in another area, there is a need to measure all secondary metrics in all tests, but also to understand the relative impact of these metrics on the north star. This is so we can inform decision-making when one metric trades off against another metric.\nInforming metrics innovation. To minimize wasted effort on metric development, it is also important to understand how metrics correlate with the north star “net of” existing metrics.\nEnabling teams to work independently. Lastly, teams need simple tools in order to iterate on their own metrics. Teams may come up with dozens of variations of secondary metrics, and slow, complicated tools for evaluating these variations are unlikely to be adopted. Conversely, our models are easy and fast to fit, and are actively used to develop proxy metrics at Netflix.\n\nWe are thrilled about the research and implementation of these methods at Netflix — while also continuing to strive for great and always better, per our culture. For example, we still have some way to go to develop a more flexible data architecture to streamline the application of these methods within Netflix. Interested in helping us? See our open job postings!\nFor feedback on this blog post and for supporting and making this work better, we thank Apoorva Lal, Martin Tingley, Patric Glynn, Richard McDowell, Travis Brooks, and Ayal Chen-Zion.\n\nImprove Your Next Experiment by Learning Better Proxy Metrics From Past Experiments was originally published in Netflix TechBlog on Medium, where people are continuing the conversation by highlighting and responding to this story.",
        "dc:creator": "Netflix Technology Blog",
        "guid": "https://medium.com/p/64c786c2a3ac",
        "categories": [
          "data-science",
          "experimentation",
          "machine-learning",
          "a-b-testing",
          "statistics"
        ],
        "isoDate": "2024-08-26T15:46:24.000Z"
      }
    ]
  },
  {
    "name": "JetBrains: Developer Tools for Professionals and Teams – Company Blog | JetBrains",
    "category": "기업",
    "posts": [
      {
        "creator": "Aleksandra Aganezova",
        "title": "JetBrains JavaScript Day 2024 Registration Is Now Open",
        "link": "https://blog.jetbrains.com/webstorm/2024/08/jetbrains-javascript-day-2024-registration-is-now-open/",
        "pubDate": "Mon, 26 Aug 2024 15:47:01 +0000",
        "content:encodedSnippet": "Hey everyone! JetBrains JavaScript Day is back for year four, and this edition promises to be our best one yet!\n\n\n\n\n\nLet’s face it, keeping up with the rapid changes in the JavaScript ecosystem is no easy task – it can be hard for us, too. That’s exactly why we created JetBrains JavaScript Day! This year, as always, we brought together top experts to share their insights and discuss the latest trends of modern JavaScript and TypeScript development. Make sure to join us live to ask your questions and be a part of the conversation as it happens.\nWhen: October 24 at 9:00 am EDT (check your timezone)\nWhere: Online\nCost: Free\nRegister!\n                                                    \nHere is this year’s lineup of inspiring speakers and talks: \nVite and the Future of JavaScript Tooling, by Evan You\nTypeScript Generics: Practical Fun!, by Josh Goldberg\nThe Silent Open Source Crisis: When Maintainers Walk Away, by Bekah Hawrot Weigel\nYou Don’t Need JavaScript for That, by Kevin Powell \nEverything You Need to Know About React 19, by Shruti Kapoor\nDriving Your JavaScript Library Ecosystem With Nx, by Chau Tran\nEvolving Angular for the Long Run, by Jeremy Elbourn\nTypeScript and Your Codebase: They Deserve Each Other!, by Danny Thompson\nWe’ve also added an Ask Me Anything (AMA) session with the WebStorm team to our agenda for all of you who want to meet the people behind the JavaScript support for JetBrains IDEs.\nGrab your tickets today, and we’ll see you there!\nYour JetBrains team",
        "dc:creator": "Aleksandra Aganezova",
        "content": "Hey everyone! JetBrains JavaScript Day is back for year four, and this edition promises to be our best one yet! Let’s face it, keeping up with the rapid changes in the JavaScript ecosystem is no easy task – it can be hard for us, too. That’s exactly why we created JetBrains JavaScript Day! This year, [&#8230;]",
        "contentSnippet": "Hey everyone! JetBrains JavaScript Day is back for year four, and this edition promises to be our best one yet! Let’s face it, keeping up with the rapid changes in the JavaScript ecosystem is no easy task – it can be hard for us, too. That’s exactly why we created JetBrains JavaScript Day! This year, […]",
        "guid": "https://blog.jetbrains.com/?post_type=webstorm&p=505594",
        "categories": [
          "news",
          "javascript-day"
        ],
        "isoDate": "2024-08-26T15:47:01.000Z"
      },
      {
        "creator": "Andrei Kislitsyn",
        "title": "Track and Analyze GitHub Star Growth With  Kandy and Kotlin DataFrame",
        "link": "https://blog.jetbrains.com/kotlin/2024/08/track-and-analyze-github-star-growth-with-kandy-and-kotlin-dataframe/",
        "pubDate": "Mon, 26 Aug 2024 14:37:54 +0000",
        "content:encodedSnippet": "Kotlin DataFrame and Kandy are two powerful tools for data analysis in Kotlin. Kotlin DataFrame simplifies data manipulation and processing, while Kandy allows you to create visualizations directly within your Kotlin projects.\nIn this post, we’ll show you how these tools can be used together within Kotlin Notebook to analyze the star history of GitHub repositories. This isn’t just a simple exercise for demonstration purposes – it’s a tutorial that can help you learn how to analyze your own repositories, understand their popularity trends, and visualize your data effectively. All examples from this post are available as a Kotlin Notebook on GitHub or a Notebook on Datalore, a data science platform by JetBrains.\nAnalyze your GitHub star history\nUnderstanding the star history of a GitHub repository can provide insights into its popularity and growth over time. By analyzing this data, you can see how different events and activities impact the interest in your project. Our goal is to equip you with the knowledge and tools to perform this analysis on your own repositories.\nObtain repository stargazers data from GitHub\nFirst, we need to gather data about the users who have starred a given repository. To achieve this, we’ll use the GitHub GraphQL API, which requires a GitHub access token. Here’s a simple function to request data about repo stars, including the starring time and user login:\nimport io.ktor.client.request.*\nimport io.ktor.http.*\n\n/**\n*  We need to specify the repository owner and name, as well as the access token.\n* There can be up to 100 results on one response page.\n* For this example, we'll take only the first 3 results.\n* `endCursor` points to the end of the previous page (`null` for the first one). \n*/\nfun fetchStarHistoryPage(owner: String, name: String, token: String, first: Int = 100, endCursor: String? = null): NotebookHttpResponse {\n   // GraphQL query\n   val query = \"\"\"\n       query {\n         repository(owner: \"$owner\", name: \"$name\") {\n           stargazers(first: $first, after: $endCursor) {\n             edges {\n               starredAt\n               node {\n                 login\n               }\n             }\n             pageInfo {\n               endCursor\n               hasNextPage\n             }\n           }\n         }\n       }\n   \"\"\".trimIndent()\n   // `http` is the default Ktor `HttpClient` for Notebook;\n   // it has the same methods but without `suspend` modifiers, \n   // allowing you to make HTTP requests quickly and easily. \n   // Make a \"post\" request to the API with this query\n   return http.post(\"https://api.github.com/graphql\") {\n       // Set authorization header with token\n       bearerAuth(token)\n       // Set content type header\n       contentType(ContentType.Application.Json)\n       // Set query as body\n       setBody(buildJsonObject { put(\"query\", query) })\n   }\n}\nA convenient and easy way to set an environment variable is through the Kotlin Notebook settings:\n\n\n\n\nNext, specify the repository owner and name, and ensure your GitHub token is securely stored:\nval ownerKotlin = \"Kotlin\"\nval repoKandy = \"kandy\"\n// Keep your token safe as an environment variable or a system property!\n// For example, you can place it in environment variables in Kotlin Notebook settings.\nval token = System.getenv(\"GITHUB_TOKEN\")\nTo start, let’s query a single page with a few users to examine the data. \nval rawResponse = fetchStarHistoryPage(ownerKotlin, repoKandy, token, first = 3)\nrawResponse\n\n\n\n\nThe response from the API looks like this:\nHttpResponse[https://api.github.com/graphql, 200 OK]\nNext, we’ll deserialize the JSON response to a Kotlin data class using the .deserializeJson() extension provided by our Kotlin Notebook Ktor integration. This makes it easier to work with the response body data in Kotlin.\nval starHistorySimplePage = rawResponse.deserializeJson()\n// Take the JSON string for further work with DataFrame\nval responseAsJson = starHistorySimplePage.jsonString\nstarHistorySimplePage\nThe result is a structured object representing the data, which looks like this:\n{\n \"data\": {\n   \"repository\": {\n     \"stargazers\": {\n       \"edges\": [\n         {\n           \"starredAt\": \"2022-07-13T22:46:16Z\",\n           \"node\": {\n             \"login\": \"manojselvam\"\n           }\n  ...\n}\nAfter executing the cell above, starHistorySimplePage is converted to a data class, allowing us to easily access those of its properties that correspond to JSON fields. This seamless integration with IntelliJ IDEA autocompletion makes working with the response straightforward.\n\n\n\n\nFor example, we can extract all the starring times from the page:\nstarHistorySimplePage.data.repository.stargazers.edges.map { it.starredAt }\nOutput:\n[2022-07-13T22:46:16Z, 2022-11-05T14:21:10Z, 2022-11-05T18:42:37Z]\nNext, let’s parse the page data into a DataFrame. \nval starHistoryPageDF = DataFrame.readJsonStr(responseAsJson)\nstarHistoryPageDF\n\n\n\n\nWe need two columns: one showing the user logins and the other their starring times. We can retrieve these columns as follows:\nstarHistoryPageDF.data.repository.stargazers.edges\n   .single() // the `edges` column contains a single DataFrame with current page stargazers\n   .flatten() // `login` is a subcolumn of `node`, after `flatten()` it is a simple column\n\n\n\n\nAdditionally, we need page meta-information, including whether there is a next page and the current page end cursor.\nwith(starHistoryPageDF.data.repository.stargazers.pageInfo) {\n   // Both are columns with a single value\n   println(\"end cursor: ${endCursor.single()}\")\n   println(\"has next page: ${hasNextPage.single()}\")\n}\nThis code outputs the following:\nend cursor: Y3Vyc29yOnYyOpIAzhXiSlk=\nhas next page: true\nNow, let’s create a function that iteratively processes all pages with stargazers and returns a DataFrame with complete information:\n// Casts DataFrame to the type of a given DataFrame so we can use\n// extension columns that have already been generated.\n// Temporary workaround, will be available in future DataFrame releases\n// (https://github.com/Kotlin/dataframe/pull/747)\ninline fun <reified T> AnyFrame.castTo(df: DataFrame<T>): DataFrame<T> {\n   return cast<T>(verify = true)\n}\nimport io.ktor.client.statement.*\n\n// Provide repo owner, name, and access token\nfun fetchStarHistory(owner: String, name: String, token: String): AnyFrame {\n   var hasNextPage: Boolean = true\n   var endCursor: String? = null\n   var buffer: DataFrame<*> = DataFrame.Empty\n   while (hasNextPage) {\n       val response = fetchStarHistoryPage(owner, name, token, 100, endCursor)\n       // Cast type of DataFrame to the type of `starHistoryPageDF`,\n       // so we can use its already-generated extensions\n       val responseDF = DataFrame.readJsonStr(response.bodyAsText()).castTo(starHistoryPageDF)\n       val stargazers = responseDF.data.repository.stargazers\n       buffer = buffer.concat(stargazers.edges.first().flatten())\n       val pageInfo = stargazers.pageInfo\n       endCursor = \"\\\"${pageInfo.endCursor.single()}\\\"\"\n       hasNextPage = pageInfo.hasNextPage.single()\n   }\n   return buffer\n}\nUsing this function, we can now retrieve all the Kandy stargazers:\nval kandyStargazers = fetchStarHistory(ownerKotlin, repoKandy, token)\nkandyStargazers\n\n\n\n\nLook at the DataFrame summary using the .describe() method, which shows meta-information and accumulated statistics about DataFrame columns:\nkandyStargazers.describe()\n\n\n\n\nAll login values are unique, indicating that the dataset is correct. Additionally, there are no null values, so no further processing is needed.\nCreate a DataFrame for cumulative star count analysis\nWe now have two key pieces of information: user logins and the times they award stars. Our next step is to perform an initial analysis.\nWe’ll create a visualization showing the cumulative number of stars received over time, illustrating how user interest in our library grows and changes.\nThis approach will help us understand the dynamics of user engagement and the popularity of our library.\nHere’s how to transform this data:\nConvert the starredAt column to LocalDateTime.\nSort the DataFrame by  starredAt, in ascending order.\nAdd a starsCount column to track the total number of stars over time.\nPut the processing code into a function so that it can be reused later on.\nfun AnyFrame.processStargazers(): AnyFrame {\n   return castTo(kandyStargazers)\n       // Convert `starredAt` column to `LocalDateTime`\n       .convert { starredAt }.toLocalDateTime()\n       // Sort rows by `starredAt`\n       .sortBy { starredAt }\n       // Add `starsCount` column with total stars count at each row.\n       // The star count is simply the row index increased by 1\n       .add(\"starsCount\") { index() + 1 }\n}\nval kandyStarHistory = kandyStargazers.processStargazers()\nkandyStarHistory\n\n\n\n\nVisualize star history: plot with Kandy\nWith the data processed, we can now visualize the star history using Kandy. Here’s a simple line plot to show how the number of stars has changed over time. \nkandyStarHistory.plot {\n   line {\n       // The starring time corresponds to the `x` axis\n       x(starredAt) {\n           axis {\n               // Set the name for the `x` axis\n               name = \"date\"\n               // Set the format for axis breaks\n               breaks(format = \"%b, %Y\")\n           }\n       }\n       // The stars count corresponds to the `y` axis\n       y(starsCount) {\n           // Set the name for the `y` axis\n           axis.name = \"GitHub stars\"\n       }\n   }\n    layout {\n       title = \"Kandy GitHub star history\"\n       size = 800 to 500\n   }\n}\n\n\n\n\nThe plot displays the cumulative growth of stars, reflecting how interest in the Kandy library has evolved. Key points of significant increase can often be associated with major announcements or events related to the library.\nTo better understand how user interest in our library evolves over time, we’ll animate this chart using the Kotlin Jupyter API. This dynamic visualization will help us see how engagement patterns shift and grow, providing deeper insights than a static chart could offer.\nWe’ll start by creating a function that builds a star history chart for the first n star(s). \nfun kandyStarHistoryPlot(n: Int) = kandyStarHistory.plot {\n   line {\n       x(starredAt.take(n)) {\n           axis {\n               name = \"date\"\n               breaks(format = \"%b, %Y\")\n           }\n       }\n       y(starsCount.take(n)) {\n           axis.name = \"GitHub stars\"\n       }\n   }\n   layout {\n       title = \"Kandy GitHub star history\"\n       size = 800 to 500\n   }\n}\nThen, we’ll use the ANIMATE() function to update the cell output for a given set of frames. Each frame will be a star history plot, starting with one star and incrementing by one star each frame until we reach the maximum number of stars.\nANIMATE(50.milliseconds, kandyStarHistory.rowsCount()) { frameID ->\n   // frame with `frameID` contsins plot with `frameID + 1` stars\n   kandyStarHistoryPlot(frameID + 1)\n}\n\n\n\n\nAnalyze key events\nWe’ll look at how different events influenced the growth of stars. We’ll add mark lines with the most important events related to Kandy, such as the Kotlin Notebook video, the Kandy introductory post, the Plotting Financial Data in Kotlin with Kandy post, and KotlinConf 2024. Such analysis helps to identify what drives interest and engagement with the project.\nWe’ll look at events starting from October 2023, which was when we initiated our marketing activities:\nval starHistoryFiltered = kandyStarHistory.filter { starredAt >= LocalDateTime(2023, 10, 1, 0, 0, 0, 0) }\nThen we’ll add mark lines with the events:\nval ktnbYTVideodate = LocalDate(2023, 10, 25)\nval kandyIntroductoryPostDate = LocalDate(2023, 12, 14)\nval kandyFinancialPostDate = LocalDate(2024, 4, 9)\nval kotlinConf24Date = LocalDate(2024, 5, 22)\n\nval kandyEvents = listOf(\n   \"Kotlin Notebook\\nYouTube video\",\n   \"Kandy Introduction\\nKotlin Blog post\",\n   \"Financial Plotting\\nMedium post\",\n   \"KotlinConf 2024\"\n)\nval kandyEventsDates = listOf(ktnbYTVideodate, kandyIntroductoryPostDate, kandyFinancialPostDate, kotlinConf24Date)\n\n\n\n\nTo make the plot more visually engaging, we’ll create a custom color palette for these event markers.\nval eventColors = listOf(\n   Color.hex(\"#1f77b4\"),\n   Color.hex(\"#ff7f0e\"),\n   Color.hex(\"#d62728\"),\n   Color.hex(\"#2ca02c\"),\n)\nFinally, we’ll generate the plot with vertical lines representing these events, allowing us to see how each significant event influenced the star history.\nstarHistoryFiltered.plot {\n   // add vertical marklines with event dates\n   vLine {\n       color(kandyEvents, \"event\") { scale = categorical(eventColors, kandyEvents) }\n       xIntercept(kandyEventsDates)\n       width = 1.5\n       alpha = 0.9\n   }\n   line {\n       x(starredAt) {axis.name = \"date\" }\n       y(starsCount) { axis.name = \"GitHub stars\" }\n   }\n   layout {\n       title = \"Kandy GitHub star history & key events\"\n       size = 800 to 500\n       style {\n           legend.position = LegendPosition.Bottom\n       }\n   }\n}\n\n\n\n\nThis plot shows the number of stars Kandy received each month, with different colors representing key events that influenced these numbers. For example, the introductory post and other significant updates coincide with noticeable increases in stars, highlighting the influence of these activities on community engagement.\nAnalyze monthly star growth\nTo analyze the monthly growth of stars, we will create a bar chart to visually display the changes in the number of stars received each month. This visualization will help us identify key growth periods and evaluate the effectiveness of our marketing strategies.\nFirst, let’s define simple extension functions to convert the LocalDate/LocalDateTime to a month and four-figure year format.\nfun LocalDate.toMonthOfYear(): String = \"$month, $year\"\nfun LocalDateTime.toMonthOfYear(): String = \"$month, $year\"\nNow, we’ll add the “month” column to our DataFrame:\nval starHistoryWithMonth = starHistoryFiltered.add(\"month\") {\n   starredAt.toMonthOfYear()\n}\nstarHistoryWithMonth\n\n\n\n\nNext, we’ll group the DataFrame by the “month” column and count the number of stars in each group.\nval starsCountMonthly = starHistoryWithMonth.groupBy { month }.count()\nstarsCountMonthly\n\n\n\n\nNext, we’ll add information about key events to the DataFrame. We’ll include the events in the corresponding months and set the value to null if there were no events.\nFirst, create a DataFrame with events and their corresponding months:\nval eventsDF = dataFrameOf(\"event\" to kandyEvents, \"month\" to kandyEventsDates.map {\n   it.toMonthOfYear()\n})\nThen, perform a left join with our main DataFrame at the month column:\nval starsMonthlyWithEvent = starsCountMonthly.leftJoin(eventsDF) { month }\nstarsMonthlyWithEvent\n\n\n\n\nNow, we can create a bar plot to visualize the distribution of new stars by month, along with the key events.\nstarsMonthlyWithEvent.plot {\n   bars {\n       x(month)\n       y(count)\n       alpha = 0.8\n       fillColor(event) { scale = categorical(eventColors, kandyEvents) }\n   }\n   // add horizontal markline with median of monthly count\n   hLine {\n       val medianMonthly = count.median()\n       yIntercept.constant(medianMonthly)\n       type = LineType.DASHED\n       color = Color.hex(\"#4b0082\")\n       width = 2.0\n   }\n   layout {\n       title = \"Kandy GitHub star history (monthly count)\"\n       size = 800 to 500\n       style {\n           legend.position = LegendPosition.Bottom\n           xAxis.text { angle = 30.0 }\n       }\n   }\n}\n\n\n\n\nThis plot shows the monthly distribution of stars, with bars representing the number of stars each month. The colors of the bars indicate key events, providing a clear visualization of how these events impacted the star counts. The dashed horizontal line represents the median star count per month.\nUnlike the overall star history chart, which shows cumulative growth, the monthly statistics plot helps you pinpoint the exact timing and impact of key events. By creating similar plots for your own projects, you can better understand the effectiveness of your promotional efforts, identify seasonal patterns, and plan future activities more effectively.\nUnderstand your audience\nUnderstanding the top programming languages of your stargazers can provide insights into your audience. With this in mind, we’ll use the GitHub REST API to find out the most popular languages among Kandy stargazers and visualize this data as a pie chart.\nLet’s write a function that requests user repositories:\nimport io.ktor.http.*\n\nfun getUserRepos(login: String): AnyFrame {\n   return DataFrame.readJsonStr(http.get(\"https://api.github.com/users/$login/repos\") {\n       // Set authorization header with token\n       bearerAuth(token)\n       // Add GitHub API custom \"accept\" header\n       header(HttpHeaders.Accept, \"application/vnd.github.v3+json\")\n   }.deserializeJson().jsonString)\n}\nNext, we’ll test this function on our sample repositories:\nval myRepos = getUserRepos(\"Kotlin\")\nmyRepos\n\n\n\n\nEach column in this DataFrame corresponds to a repository and contains different information about that repository. We are interested in the language column. We can count the most frequent language using the .valueCounts() method, where the first entry represents the most popular language:\nval myLanguagesCounts = myRepos.language.valueCounts(dropNA = false) // Don't drop nulls\nmyLanguagesCounts\n\n\n\n\nBecause the rows are sorted by count by default, identifying the most popular language is straightforward – it’s the first one.\nmyLanguagesCounts.language.first()\nKotlin\nTo generalize this process, we’ll write an extension function for a DataFrame obtained from the user’s repositories. This extension function will retrieve the most popular language (returning null if the account is private, has no repositories, or lacks sufficient information).\nfun AnyFrame.getTopLanguage(): String? {\n   //  Handle non-default response bodies (private account, no repositories, etc.)\n   if (!containsColumn(\"language\")) return null\n   return castTo(myRepos).language\n       .valueCounts(dropNA = false)\n       .castTo(myLanguagesCounts)\n       .language.let { languages ->\n           val first = languages.firstOrNull()\n           //  Try to pick the second value if the first one is null\n           if (first == null && languages.size() >= 2) {\n               languages[1]\n           } else first\n       }\n}\nNow, let’s retrieve the most popular languages for all stargazers. Note that this process might take some time to execute:\nval stargazersLanguages = kandyStarHistory.select {\n   login and login.map { login -> getUserRepos(login).getTopLanguage() }.named(\"language\")\n}\nstargazersLanguages\n\n\n\n\nNext, we’ll count the occurrences of each language:\nval languageCounts = stargazersLanguages.language.valueCounts() // Drops null by default\nlanguageCounts\n\n\n\n\nFinally, let’s plot these counts as a pie chart. We’ll take the seven most popular languages and group the remaining ones into an “other” category:\nlanguageCounts.let {\n   val takeFirst = 7\n   it.take(takeFirst).concat(\n       dataFrameOf(\"language\" to listOf(\"other\"), \"count\" to listOf(it.drop(takeFirst).sum {count}))\n   )\n}.plot {\n   pie {\n       slice(\"count\")\n       fillColor(\"language\")\n       size = 25.0\n       hole = 0.3\n   }\n   layout {\n       title = \"Kandy stargazers' most popular languages\"\n       style(Style.Void)\n   }\n}\n\n\n\n\nThe pie chart shows that Kotlin is the most popular language among Kandy stargazers, confirming our primary audience as Kotlin developers. The presence of Java suggests potential for further engagement with related ecosystems. The inclusion of less-common languages highlights the diversity of our user base, which is important for understanding different use cases and potential feature requests.\nThese insights can help tailor your project’s documentation, tutorials, and marketing efforts to better serve and expand your audience.\nCompare star growth: Kandy vs. Kotlin DataFrame\nComparing star data across different projects can provide valuable insights into their popularity and user engagement. Here, we’ll look at the growth of stars for Kandy alongside Kotlin DataFrame. These two projects, launched within a year of each other, target the same audience of Kotlin developers.\nTo ensure a fair comparison, we’ll use the introduction post date as the starting point for both libraries and examine the six months that followed. This way, we can see how each project grew over the same timeframe, giving us a clearer picture of their growth patterns.\nval repoDataframe = \"dataframe\"\n// Use the already written methods to get star history for DataFrame\nval dataFrameStarHistory = fetchStarHistory(ownerKotlin, repoDataframe, token).processStargazers()\n\n\n\n\nDefining the introductory post date for DataFrame:\nval dataFrameIntroductoryPostDate = LocalDate(2022, 6, 30)\nNext, we’ll define a function to process the star history for the six months following the introduction post:\n// Function that will slightly transform the dataframe with star history for a given library: \n// 1) Take a period of six months after the introduction post date; \n// 2) Add a column \"daysAfterPost\" with the number of days after the post date; \n// 3) Take the maximum number of stars for the day; \n// 4) Add a column \"library\" corresponding to the name of the library.\nfun AnyFrame.proccessAfterPostPeriod(introductionPostDate: LocalDate, library: String): AnyFrame {\n   // Six-month period after `introductionPostDate`\n   val period = (introductionPostDate - DatePeriod(days = 1))..(introductionPostDate + DatePeriod(months = 6))\n   return castTo(kandyStarHistory)\n       // Only take stars placed during that period\n       .filter { starredAt.date in period }\n       // Add daysAfterPost column with number of days after post\n       .add(\"daysAfterPost\") {\n           introductionPostDate.daysUntil(starredAt.date)\n       }\n       // Group by number of days and take the max value of `starsCount` for each group\n       .groupBy(\"daysAfterPost\").max { starsCount }\n       // Add a column with library name\n       .add(\"library\") { library }\n}\nFinally, we’ll combine the star histories for Kandy and DataFrame into a single DataFrame for comparison:\n// Count six-month history for both libraries and concatenate them into one DataFrame\nval kandyAndDataFrameStarHistory = kandyStarHistory\n   .proccessAfterPostPeriod(kandyIntroductoryPostDate, \"Kandy\")\n   .concat(\n       dataFrameStarHistory.proccessAfterPostPeriod(dataFrameIntroductoryPostDate, \"DataFrame\")\n   )\nkandyAndDataFrameStarHistory\n\n\n\n\nNext, we’ll visualize the comparison:\nkandyAndDataFrameStarHistory.plot {\n   line {\n       x(daysAfterPost) {\n           axis {\n               name = \"days after post\"\n           }\n       }\n       y(starsCount) {\n           axis.name = \"GitHub stars\"\n       }\n       color(library)\n   }\n   layout {\n       title = \"Kandy vs. DataFrame GitHub stars history\\nwithin 6 months after the introductory post\"\n       size = 800 to 500\n   }\n}\n\n\n\n\nFrom the initial observation, we can see that before the introduction post, both Kandy and Kotlin DataFrame had similar star counts. However, immediately after the post, Kandy showed a significantly higher growth rate, achieving nearly twice as many stars as DataFrame within the first six months.\nThis difference suggests several things. Firstly, it shows the growing interest in Kotlin for data projects. The period of time that elapsed from the initial DataFrame post and the Kandy post was about a year and a half. While DataFrame helped establish a community of Kotlin data enthusiasts, Kandy attracted a new audience interested in visualization.\nAdditionally, Kandy had more intense promotional activities within the six months following its first post, which likely contributed to its rapid growth.\nShared stargazers\nIt’s also interesting to see how many users have starred both Kandy and DataFrame. We hypothesize that there will be a significant overlap, since both libraries serve the same community of Kotlin developers. Here’s how we can analyze this and get the relevant data:\n// inner join star history dataframes of repositories by login,\n// getting a dataframe with all common stargazers, taking its size to get a number of them\nval commonStargazers = kandyStarHistory.innerJoin(dataFrameStarHistory) { login }.rowsCount()\nval kandyTotalStargazers = kandyStarHistory.rowsCount()\nval kandyOnlyStargazers = kandyTotalStargazers - commonStargazers\nval dataFrameTotalStargazers = dataFrameStarHistory.rowsCount()\nval dataFrameOnlyStargazers = dataFrameTotalStargazers - commonStargazers\nPlot this data as a pie chart:\nplot {\n   pie {\n       slice(listOf(commonStargazers, kandyOnlyStargazers, dataFrameOnlyStargazers))\n       fillColor(listOf(\"Common\", \"Kandy only\", \"DataFrame only\")) {\n           scale = categorical(\n               \"Common\" to Color.hex(\"#4A90E2\"),\n               \"Kandy only\" to Color.hex(\"#F5A623\"),\n               \"DataFrame only\" to Color.hex(\"#7ED321\"),\n           )\n           legend.name = \"\"\n       }\n       size = 25.0\n   }\n   layout {\n       title = \"Kandy & DataFrame stargazers ratio\"\n       style(Style.Void)\n   }\n}\n\n\n\n\nThe analysis shows that the majority of stargazers are unique to DataFrame, with fewer users starring both DataFrame and Kandy. Specifically, the share of DataFrame stargazers who also starred Kandy is quite small. This is probably because many users use DataFrame for data tasks that don’t involve visualization, making Kandy less relevant to them.\nInterestingly, only about a quarter of Kandy stargazers have also starred DataFrame. This suggests that Kandy has attracted a new audience mainly interested in plotting, rather than data processing. This reveals a great opportunity to promote how both libraries can work together.\nUsing Kandy for visualization and DataFrame for data processing allows users to benefit from the strengths of both libraries. This combination, as we’ve shown in this post, can help create powerful and comprehensive data analysis solutions. By highlighting this synergy, we can encourage more users to explore how these tools can complement each other and enhance their data projects.\nConclusion\nIn this post, we explored how to use Kotlin DataFrame and Kandy to dive into the star history of GitHub repositories. But it wasn’t just about looking at the numbers – it was about uncovering the stories those numbers tell.\nOne big takeaway is how quickly Kandy gained traction after its launch, highlighting a growing interest in visualization tools within the Kotlin community. Yet, we also found that many Kandy users haven’t tried DataFrame, and vice versa. This shows there’s an opportunity to help developers see how these tools can complement each other.\nWe also noticed that certain events, like blog posts and conferences, had a noticeable impact on star counts. This kind of insight can help you time your own announcements to get the most attention.\nWhat’s next?\nNow it’s your turn! Apply these techniques to your own repositories, analyze their star history, and create your own visualizations within Kotlin Notebook. All examples from this post are available as a Kotlin Notebook on GitHub or a Notebook on Datalore.\nWe’d love to see your results and hear your feedback. Join us in the #datascience channel on Kotlin Slack, or reach out via GitHub issues for Kandy or Kotlin DataFrame.\nIf you find our repositories useful, we’d really appreciate it if you starred them. Your support helps us improve and develop these tools further.\nWhat else to read and watch\nFor more information, check out the following resources:\nKotlin for Data Analysis Overview\nGet started with Kotlin Notebook\nA Step-by-Step Guide to Performing Data Analysis With Kotlin DataFrame\nData Analytics With Kotlin Notebooks, DataFrame, and Kandy",
        "dc:creator": "Andrei Kislitsyn",
        "content": "Kotlin DataFrame and Kandy are two powerful tools for data analysis in Kotlin. Kotlin DataFrame simplifies data manipulation and processing, while Kandy allows you to create visualizations directly within your Kotlin projects. In this post, we’ll show you how these tools can be used together within Kotlin Notebook to analyze the star history of GitHub [&#8230;]",
        "contentSnippet": "Kotlin DataFrame and Kandy are two powerful tools for data analysis in Kotlin. Kotlin DataFrame simplifies data manipulation and processing, while Kandy allows you to create visualizations directly within your Kotlin projects. In this post, we’ll show you how these tools can be used together within Kotlin Notebook to analyze the star history of GitHub […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=504121",
        "categories": [
          "ecosystem",
          "data-analysis",
          "dataframe",
          "kandy",
          "notebooks"
        ],
        "isoDate": "2024-08-26T14:37:54.000Z"
      },
      {
        "creator": "Alena Guzharina",
        "title": "A Complete Guide to Credit Risk Analysis With Python and Datalore AI",
        "link": "https://blog.jetbrains.com/datalore/2024/08/26/a-complete-guide-to-credit-risk-analysis-with-python-and-datalore-ai/",
        "pubDate": "Mon, 26 Aug 2024 14:34:49 +0000",
        "content:encodedSnippet": "This is a guest blog post by Ryan O’Connell, CFA, FRM.\nUnderstanding the relationships between various economic indicators is crucial for navigating the financial landscape. These relationships significantly impact the overall state of the economy, affecting businesses, investors, and individuals alike. \n“In this tutorial, we’ll focus on the complex interplay between federal funds rates, 10-year Treasury yields, and corporate bond yields – key indicators that shape investment strategies, economic forecasts, and policy decisions.”\n\n            \nRyan O’Connell\n                                                                CFA, FRM\n                                    \nWe’ll analyze data spanning over two decades of financial history, leveraging the power of Python, the Federal Reserve Economic Data (FRED) API, and Datalore’s AI-assisted coding capabilities. Python is particularly well-suited for this analysis due to its ability to efficiently pull and process large amounts of financial data through APIs. This approach allows for easy automation and replication of the analysis, offering a significant advantage over traditional spreadsheet methods.\nOur goal is to uncover patterns, anomalies, and insights that illuminate the predictive power of yield curve changes on credit spreads. By using Python, we can create a workflow that’s not only powerful but also easily updatable for future analyses in just a few clicks.\n\n\n\n\nIn this tutorial, you’ll learn how to:\nSet up your Python environment in Datalore for financial data analysis.\nUse Datalore’s AI Assistant to generate code for data retrieval and preprocessing.\nCreate visualizations to analyze yield curve dynamics and credit spreads.\nImplement statistical analyses to explore the relationship between yield curves and credit risk.\nLeverage AI to help interpret results and generate insights.\nWhether you’re a credit risk analyst looking to leverage more of Python within your stack or a curious newcomer to the world of credit risk, this tutorial will provide you with the tools and techniques to conduct your own in-depth analysis using Python and Datalore AI assistance.\nLet’s dive in and start coding!\n      \n      Open Datalore Code\n\n\n\n\n\nDisclaimer: This article is for informational and educational purposes only and is not intended to serve as personal financial advice.\nThe Yield Curve: A Financial Crystal Ball?\nBefore we dive into the data, let’s establish some context. The yield curve, particularly the spread between long-term and short-term interest rates, has long been considered a powerful predictive tool in finance. But why?\nEconomic expectations: The yield curve reflects market expectations about future economic conditions. A normal, upward-sloping curve suggests optimism, while an inverted curve often signals pessimism.\nMonetary policy: It provides insights into the market’s view of future monetary policy decisions by central banks.\nCredit risk: The shape of the yield curve can influence lending behaviors and, consequently, credit risk in the economy.\n\n\n\n\nOur analysis focuses on three key components:\nThe federal funds rate: the short-term interest rate at which banks lend to each other overnight.\nThe 10-year Treasury yield: a benchmark for long-term interest rates in the US.\nCorporate bond yields: representing the cost of borrowing for corporations.\n\n\n\n\nBy examining the relationships between these factors, we aim to uncover insights that could help predict changes in credit spreads and, by extension, credit risk in the market.\nSetting up your environment and retrieving data\nBefore we dive into the analysis, you have two options to get started:\nStart a new Datalore notebook to follow along with this tutorial from scratch.\nIf you have a Datalore account, you can click Edit copy on this Datalore report. This option allows you to see the full analysis and modify it as you go.\nWhichever option you choose, we’ll need to set up our Python environment in Datalore and retrieve the necessary data. We’ll be using the Federal Reserve Economic Data (FRED) API to fetch historical data on federal funds rates, 10-year Treasury yields, and corporate bond yields.\nSetting up your FRED API key\nTo use the FRED API, you’ll need to obtain an API key. Here’s how to set it up in Datalore:\nGo to the FRED API Key documentation and click on Request API Key.\nRegister for an account or log in if you already have one.\nOnce you have your API key, go to Environment in your Datalore workspace.\nClick on Environment Variables.\nSelect + New Variable.\nSet up the variable as follows:\n\nVariable title: FRED_API_KEY\nKey: FRED_API_KEY\nValue: Your actual FRED API key\n\n\n\n\nInstalling required packages\nIn Datalore, you can easily install required packages. For this tutorial, we’ll need the fredapi package. To install it:\nGo to the Environment tab in Datalore.\nClick on Package Management.\nSearch for ”fredapi” and click Install.\n\n\n\n\nDatalore’s Environment Manager\n\n\n\nRetrieving fed funds rate data with AI assistance\nNow, let’s use Datalore’s AI assistance to help us write code to retrieve and plot 20 years of federal funds rate data. \nDatalore AI\n\n\n\nHere’s how you can prompt the AI:\n\nAI Prompt\nWrite Python code to retrieve the last 20 years of federal funds rate data using the FRED API. Please include the following steps:\n1. Import necessary libraries (fredapi and pandas)\n2. Set up the FRED API connection using the FRED_API_KEY environment variable\n3. Retrieve the federal funds rate data (series ID: FEDFUNDS) for the last 20 years\n4. Convert the data to a pandas DataFrame\n5. Display the first few rows of the DataFrame\n6. Plot the federal funds rate over time using matplotlib\nNote: Include comments explaining each step of the process.\n\n\n\n\n\nHere’s the code the AI might generate:\n# Import necessary libraries\nimport pandas as pd\nfrom fredapi import Fred\nimport matplotlib.pyplot as plt\nfrom datetime import datetime, timedelta\nimport os\n\n# Set up the FRED API connection using the environment variable\nfred = Fred(api_key=os.environ['FRED_API_KEY'])\n\n# Calculate the date 20 years ago from today\nend_date = datetime.now()\nstart_date = end_date - timedelta(days=20*365)\n\n# Retrieve the federal funds rate data (series ID: FEDFUNDS) for the last 20 years\nfed_funds_data = fred.get_series('FEDFUNDS', start_date, end_date)\n\n# Convert the data to a pandas DataFrame\nfed_funds_df = pd.DataFrame(fed_funds_data, columns=['Rate'])\nfed_funds_df.index.name = 'Date'\n\n# Display the first few rows of the DataFrame\nprint(fed_funds_df.head())\n\n# Plot the federal funds rate over time\nplt.figure(figsize=(12, 6))\nplt.plot(fed_funds_df.index, fed_funds_df['Rate'])\nplt.title('Federal Funds Rate (Last 20 Years)')\nplt.xlabel('Date')\nplt.ylabel('Rate (%)')\nplt.grid(True)\nplt.show()\n      \n      Open Datalore Code\n\n\n\n\n\nThe graph that this code plots can be seen below.\nFederal funds rate: navigating two decades of monetary policy\nNow that we’ve retrieved and plotted the data, let’s analyze the key trends and events visible in our graph:\n\n\n\n\nKey observations from our initial data exploration of the federal funds rate:\nCyclical nature: The federal funds rate exhibits clear cyclical patterns over the 20-year period, reflecting the economic cycles and the Federal Reserve’s monetary policy responses.\nPre-2008 financial crisis: From 2004 to 2006, we observe a steady increase in the rate, peaking at around 5.25% in 2006–2007. This period of rising rates was likely in response to a growing economy and inflationary pressures.\n2008 financial crisis: The rate drops dramatically starting in 2007 and accelerates in 2008, coinciding with the Global Financial Crisis. The Fed rapidly cut rates to near zero in an attempt to stimulate the economy.\nExtended low-rate environment: From 2009 to 2015, we see an unprecedented period of near-zero interest rates, often referred to as the “zero lower bound” era. This reflects the Fed’s aggressive monetary policy to support economic recovery post-crisis.\nGradual normalization: Starting in late 2015, there’s a gradual increase in rates as the Fed began to normalize monetary policy in response to improving economic conditions.\nCOVID-19 pandemic impact: In early 2020, we observe another sharp drop to near-zero rates, mirroring the Fed’s emergency response to the economic shock of the COVID-19 pandemic.\nRecent rapid increase: From 2022 to 2023, we see a steep and rapid increase in rates, reaching levels not seen since before the 2008 crisis. This reflects the Fed’s aggressive tightening to combat high inflation.\n\n\n\n\nThese observations set the stage for our deeper analysis of how federal funds rate changes interact with other key indicators and influence credit risk. Next, we’ll retrieve Treasury yields and corporate bond rates.\nRetrieving 10-year Treasury rate data with AI assistance\nIn this section, we’ll focus on retrieving historical data for 10-year US Treasury yields, a key indicator in financial markets. The 10-year Treasury yield is often used as a benchmark for other interest rates and is crucial for understanding broader economic trends.\nWe’ll use the FRED API to fetch 20 years of daily data, giving us a comprehensive view of long-term interest rate movements.\nLet’s start by prompting the AI to write our data retrieval and visualization code. Here’s the prompt we’ll use:\n\nAI Prompt\nWrite Python code to retrieve the last 20 years of 10-year Treasury yields data using the FRED API. Please include the following steps:\n1. Import necessary libraries (if not already imported)\n2. Use the existing FRED API connection (assuming it’s already set up)\n3. Retrieve the 10-year Treasury yields data (series ID: DGS10) for the last 20 years\n4. Convert the data to a pandas DataFrame\n5. Display the first few rows of the DataFrame\n6. Plot the 10-year Treasury yields over time using matplotlib\nNote: Include comments explaining each step of the process.\n\n\n\n\n\nHere’s the code the AI might generate:\n# Import necessary libraries (if not already imported)\nimport pandas as pd\nfrom fredapi import Fred\nimport matplotlib.pyplot as plt\nfrom datetime import datetime, timedelta\nimport os\n\n# Use the existing FRED API connection\nfred = Fred(api_key=os.environ['FRED_API_KEY'])\n\n# Calculate the date 20 years ago from today\nend_date = datetime.now()\nstart_date = end_date - timedelta(days=20*365)\n\n# Retrieve the 10-year Treasury yields data (series ID: DGS10) for the last 20 years\ntreasury_10y_data = fred.get_series('DGS10', start_date, end_date)\n\n# Convert the data to a pandas DataFrame\ntreasury_10y_df = pd.DataFrame(treasury_10y_data, columns=['Yield'])\ntreasury_10y_df.index.name = 'Date'\n\n# Display the first few rows of the DataFrame\nprint(treasury_10y_df.head())\n\n# Plot the 10-year Treasury yields over time\nplt.figure(figsize=(12, 6))\nplt.plot(treasury_10y_df.index, treasury_10y_df['Yield'])\nplt.title('10-Year Treasury Yields (Last 20 Years)')\nplt.xlabel('Date')\nplt.ylabel('Yield (%)')\nplt.grid(True)\nplt.show()\n      \n      Open Datalore Code\n\n\n\n\n\nNow, let’s take a look at the plot of 20 years of long-term Treasury data.\n10-year Treasury yields: two decades of fluctuations\n\n\n\n\nNow that we’ve retrieved and plotted the data, let’s analyze the key trends and events visible in our graph:\n2008 financial crisis impact: There’s a sharp decline in yields starting in late 2007 and accelerating through 2008, mirroring the flight to safety during the financial crisis, though less dramatic than the federal funds rate drop.\nPost-crisis volatility and recovery: After the initial drop, yields showed significant volatility between 2009 and 2012, followed by a gradual increase until 2018, reflecting the uncertain economic recovery and the effects of changing monetary policies.\nCOVID-19 pandemic shock: In early 2020, we observe a dramatic plunge in yields to historic lows below 1%, coinciding with the economic shock of the COVID-19 pandemic and aggressive Fed intervention.\nRecent rapid increase: From 2021 onwards, there’s a sharp upward trend in yields, reaching levels not seen since before the 2008 crisis, aligning with rising inflation concerns and the Fed’s tightening monetary policy.\n\n\n\n\nThese observations provide crucial context for understanding how both short-term and longer-term interest rates have behaved in response to economic conditions and policy changes over the past two decades. As we proceed, we’ll explore how these rate movements interact to shape the overall yield curve and influence credit risk in the market.\nRetrieving corporate bond yields with AI assistance\nHaving examined the 10-year Treasury yields, we now turn to corporate bond yields, which provide insights into borrowing costs for corporations and serve as a key component in our credit risk analysis. We’ll use the ICE BofA US Corporate Index Effective Yield as our benchmark, offering a broad measure of US dollar-denominated investment-grade corporate debt performance.\nLet’s use Datalore’s AI assistance to generate code that retrieves and visualizes 20 years of daily data from the FRED API. Here’s the prompt:\n\nAI Prompt\nWrite Python code to retrieve the last 20 years of corporate bond yield data using the FRED API. Please include the following steps:\n1. Use the existing FRED API connection\n2. Retrieve the ICE BofA US Corporate Index Effective Yield data (series ID: BAMLC0A0CMEY) for the last 20 years\n3. Convert the data to a pandas DataFrame\n4. Handle any missing values appropriately\n5. Display the first few rows of the DataFrame\n6. Plot the corporate bond yields over time using matplotlib\nNote: Include comments explaining each step of the process.\n\n\n\n\n\nMy Datalore AI Assistant produced this code:\n# Use the existing FRED API connection\n# Assuming fred is already defined and the API key is set up as an environment variable\n\n# Calculate the date 20 years ago from today\nend_date = datetime.now()\nstart_date = end_date - timedelta(days=20*365)\n\n# Retrieve the ICE BofA US Corporate Index Effective Yield data (series ID: BAMLC0A0CMEY) for the last 20 years\ncorporate_yield_data = fred.get_series('BAMLC0A0CMEY', start_date, end_date)\n\n# Convert the data to a pandas DataFrame\ncorporate_yield_df = pd.DataFrame(corporate_yield_data, columns=['Yield'])\ncorporate_yield_df.index.name = 'Date'\n\n# Handle missing values by forward filling (using the last known value)\ncorporate_yield_df = corporate_yield_df.fillna(method='ffill')\n\n# Display the first few rows of the DataFrame\nprint(corporate_yield_df.head())\n\n# Plot the corporate bond yields over time\nplt.figure(figsize=(12, 6))\nplt.plot(corporate_yield_df.index, corporate_yield_df['Yield'])\nplt.title('ICE BofA US Corporate Index Effective Yield (Last 20 Years)')\nplt.xlabel('Date')\nplt.ylabel('Yield (%)')\nplt.grid(True)\nplt.show()\n      \n      Open Datalore Code\n\n\n\n\n\nIn the next section, we will analyze the results of this code block.\nCorporate bond yields: two decades of risk and reward\n\n\n\n\nNow that we’ve retrieved and plotted the data, let’s analyze the key trends and events in corporate bond yields over the past 20 years:\n2008 financial crisis spike: The most dramatic feature of the graph is the sharp spike in yields during the 2008 financial crisis, reaching a peak of over 9%. This reflects the extreme risk aversion and liquidity concerns in the corporate bond market during this period.\nPre-crisis build-up: Leading up to the 2008 crisis, we observe a gradual increase in yields from 2004 to 2007, possibly indicating growing concerns about credit risk in the years preceding the financial crisis.\nPost-crisis decline and stabilization: Following the 2008 peak, yields declined rapidly and then stabilized, fluctuating between 3% and 4% for much of the period from 2010 to 2019. This reflects the impact of the Fed’s accommodative monetary policy and a general improvement in economic conditions.\nCOVID-19 pandemic impact: In early 2020, we see another significant, though less extreme, spike in yields coinciding with the onset of the COVID-19 pandemic. This spike was quickly reversed, likely due to swift central bank intervention.\nRecent upward trend: From 2021 onwards, we observe an upward trend in yields, reaching levels not seen since before the 2008 crisis. This aligns with rising inflation concerns and tightening monetary policy, reflecting increased borrowing costs for corporations.\n\n\n\n\nThese observations provide valuable insights into how corporate borrowing costs and perceived credit risk have evolved over the past two decades. In the next section, we’ll explore how these corporate bond yields interact with the federal funds rate and Treasury yields to shape the overall credit risk landscape.\nFed Funds Rate vs. 10-year Treasury yield and spread analysis\nAfter examining the federal funds rate and 10-year Treasury yields individually, we now turn our attention to the relationship between these two crucial indicators. The spread between these rates, often referred to as the yield curve slope, provides valuable insights into economic expectations and potential credit risk.\nThe yield curve spread is calculated as follows:\nYield Curve Spread = 10-Year Treasury Yield - Federal Funds Rate\nA positive spread indicates a “normal” yield curve, generally associated with economic growth expectations. Conversely, a negative spread signals an inverted yield curve, which is often seen as a predictor of economic downturns.\nLet’s use AI assistance to create a comprehensive line chart visualization that tracks these key elements. Here’s the prompt for the AI:\n\nAI Prompt\nPlot monthly Fed Funds Rate, Corporate Bond Yields, and their spread:\n1. Use ‘fed_funds_data’ for Fed Funds Rate\n2. Retrieve Corporate Bond Yield data (BAMLC0A0CMEY) from FRED\n3. Resample both to monthly frequency and align to common date range\n4. Calculate spread (Corporate Bond Yield minus Fed Funds Rate)\n5. Remove NaN values\n6. Plot all three lines with different colors\n7. Include legend, title, axis labels, and red dashed line at y=0\n8. Show summary statistics\n\n\n\n\n\nYour AI assistant should produce code that looks something like this:\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Resample both series to monthly frequency and align them\nfed_funds_monthly = fed_funds_data.resample('M').last()\ntreasury_10y_monthly = treasury_10y_data.resample('M').last()\n\n# Create a DataFrame with both series, using the common date range\nstart_date = max(fed_funds_monthly.index.min(), treasury_10y_monthly.index.min())\nend_date = min(fed_funds_monthly.index.max(), treasury_10y_monthly.index.max())\n\ndf = pd.DataFrame({\n    'Fed Funds Rate': fed_funds_monthly[start_date:end_date],\n    '10-Year Treasury Yield': treasury_10y_monthly[start_date:end_date]\n})\n\n# Calculate the spread\ndf['Spread'] = df['10-Year Treasury Yield'] - df['Fed Funds Rate']\n\n# Remove any rows with NaN values\ndf = df.dropna()\n\n# Plot the data\nplt.figure(figsize=(12, 6))\nplt.plot(df.index, df['Fed Funds Rate'], label='Fed Funds Rate', color='blue')\nplt.plot(df.index, df['10-Year Treasury Yield'], label='10-Year Treasury Yield', color='orange')\nplt.plot(df.index, df['Spread'], label='Spread', color='green')\n\nplt.title('Fed Funds Rate vs 10-Year Treasury Yield and Spread')\nplt.xlabel('Date')\nplt.ylabel('Rate (%)')\nplt.legend()\nplt.grid(True)\n\n# Add horizontal line at y=0\nplt.axhline(y=0, color='r', linestyle='--')\n\nplt.show()\n\n# Print some summary statistics\nprint(\"\\nSummary Statistics:\")\nprint(df.describe())\n      \n      Open Datalore Code\n\n\n\n\n\nIn the next section, we will dive into the plotted results of this code to draw some conclusions about the economy over time.\nInterpreting yield curve dynamics\n\n\n\n\nNow that we’ve visualized the data, let’s analyze the key trends and events in yield curve dynamics:\nPre-2008 inversion: Leading up to the 2008 financial crisis, we observe a period of yield curve inversion (negative spread), with the fed funds rate exceeding the 10-year Treasury yield. This inversion is often seen as a predictor of economic recessions. In this particular case, the yield curve inversion was an accurate leading indicator.\nPost-crisis widening: Following the 2008 crisis, we see a significant widening of the spread as the Fed Funds Rate dropped dramatically while the 10-year Treasury Yield declined more gradually. This wide spread reflects the Fed’s aggressive monetary easing and attempts to stimulate long-term borrowing and investment.\nExtended period of positive spread: From 2009 to 2019, the spread remained consistently positive, with long-term rates higher than short-term rates. This “normal” yield curve is generally associated with expectations of economic growth.\nRecent inversions: We observe two notable periods of inversion in recent years – a brief inversion in 2019 and a more pronounced one starting in 2022. These inversions coincide with economic uncertainties, including trade tensions and inflation concerns.\nPandemic impact and recovery: The spread widened sharply at the onset of the COVID-19 pandemic in 2020 as the Fed cut rates to near zero. Subsequently, we see a rapid narrowing and eventual inversion as the Fed aggressively raised rates to combat inflation. As of our analysis in 2024, we are currently experiencing an inverted yield curve, with short-term rates higher than long-term rates. Historically, such inversions have often preceded economic recessions, suggesting the possibility of an economic downturn in the coming years. However, it’s important to note that while yield curve inversions have been reliable predictors in the past, economic conditions can vary, and past performance doesn’t guarantee future outcomes.\n\n\n\n\nThese yield curve dynamics provide crucial context for understanding market expectations and potential economic turning points. The current inversion underscores the importance of monitoring these indicators closely in the coming months and years.\n10-year Treasury yield vs. corporate bond yields analysis\nIn this section, we’ll explore a crucial relationship in fixed-income markets: the comparison between 10-year Treasury yields and corporate bond yields. This analysis is fundamental to understanding credit risk in the economy.\nThe spread between these yields, known as the credit spread, is calculated as:\nCredit Spread = Corporate Bond Yield - 10-Year Treasury Yield\nThis spread represents the additional return investors demand for taking on the risk of lending to corporations rather than the US government. A widening spread typically indicates increased perceived risk, while a narrowing spread suggests improving conditions or increased risk appetite.\nLet’s use AI assistance to create a visualization that includes:\nThe 10-year Treasury yield.\nThe corporate bond yield (using the ICE BofA US Corporate Index Effective Yield as a proxy).\nThe spread between these rates.\n\n\n\n\nHere’s the prompt for the AI:\n\nAI Prompt\nPlot monthly 10-Year Treasury Yield, Corporate Bond Yields, and their spread:\n1. Use ‘treasury_10y_data’ for 10-Year Treasury Yield\n2. Retrieve Corporate Bond Yield data (BAMLC0A0CMEY) from FRED\n3. Resample both to monthly frequency and align to common date range\n4. Calculate spread (Corporate Bond Yield minus 10-Year Treasury Yield)\n5. Remove NaN values\n6. Plot all three lines with different colors\n7. Include legend, title, axis labels, and red dashed line at y=0\n8. Show summary statistics\n\n\n\n\n\nThe code output should look like this:\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom fredapi import Fred\nimport os\nfrom datetime import datetime, timedelta\n\n# Use the existing FRED API connection\nfred = Fred(api_key=os.environ['FRED_API_KEY'])\n\n# Calculate the date range\nend_date = datetime.now()\nstart_date = end_date - timedelta(days=20*365)\n\n# Retrieve the corporate bond yield data\ncorporate_yield_data = fred.get_series('BAMLC0A0CMEY', start_date, end_date)\n\n# Resample both series to monthly frequency\ntreasury_10y_monthly = treasury_10y_data.resample('M').last()\ncorporate_yield_monthly = corporate_yield_data.resample('M').last()\n\n# Create a DataFrame with both series, using the common date range\nstart_date = max(treasury_10y_monthly.index.min(), corporate_yield_monthly.index.min())\nend_date = min(treasury_10y_monthly.index.max(), corporate_yield_monthly.index.max())\n\ndf = pd.DataFrame({\n    '10-Year Treasury Yield': treasury_10y_monthly[start_date:end_date],\n    'Corporate Bond Yield': corporate_yield_monthly[start_date:end_date]\n})\n\n# Calculate the spread\ndf['Spread'] = df['Corporate Bond Yield'] - df['10-Year Treasury Yield']\n\n# Remove any rows with NaN values\ndf = df.dropna()\n\n# Plot the data\nplt.figure(figsize=(12, 6))\nplt.plot(df.index, df['10-Year Treasury Yield'], label='10-Year Treasury Yield', color='blue')\nplt.plot(df.index, df['Corporate Bond Yield'], label='Corporate Bond Yield', color='orange')\nplt.plot(df.index, df['Spread'], label='Spread', color='green')\n\nplt.title('10-Year Treasury Yield vs Corporate Bond Yield and Spread')\nplt.xlabel('Date')\nplt.ylabel('Rate (%)')\nplt.legend()\nplt.grid(True)\n\n# Add horizontal line at y=0\nplt.axhline(y=0, color='r', linestyle='--')\n\nplt.show()\n\n# Print some summary statistics\nprint(\"\\nSummary Statistics:\")\nprint(df.describe())\n      \n      Open Datalore Code\n\n\n\n\n\nNow, let’s dive into the results of this analysis in the next section.\nInterpreting credit spread dynamics\n\n\n\n\nNow that we’ve visualized the data, let’s analyze the key trends in credit spread dynamics:\n2008 financial crisis impact: The most striking feature of the graph is the dramatic widening of the spread during the 2008 financial crisis. This spike reflects a severe increase in perceived credit risk as investors fled to the safety of government bonds, demanding much higher yields for corporate debt.\nPre-crisis build-up: In the years leading up to the 2008 crisis, we observe a gradual narrowing of the spread, suggesting increasing investor comfort with corporate credit risk. This trend reversed sharply with the onset of the crisis.\nPost-crisis normalization: Following the crisis, the spread gradually narrowed but largely remained elevated compared to pre-crisis levels for several years, indicating a more cautious approach to credit risk in the aftermath of the financial turmoil.\nCOVID-19 pandemic spike: In early 2020, we see another significant, though less extreme, widening of the spread coinciding with the onset of the COVID-19 pandemic. This reflects the sudden increase in perceived corporate credit risk due to economic uncertainties.\nRecent trends: Since the pandemic spike, the spread has narrowed but remains above pre-pandemic levels, suggesting that while credit risk perceptions have improved, investors still maintain a degree of caution in the current economic environment.\n\n\n\n\nThese credit spread dynamics provide crucial insights for investors and policymakers. A widening spread often signals increasing economic stress and may precede broader market downturns. Conversely, a narrowing spread typically indicates improving conditions and increased confidence in corporate debt.\nHowever, it’s important to consider credit spreads alongside other economic indicators for a comprehensive view of market conditions and credit risk. In the next section, we’ll explore how these insights can be applied to predictive analysis and risk management strategies.\nCongratulations! You’ve made it this far into our tutorial. Want more? Read on to explore the relationship between yield curve changes and credit spreads.\n[Advanced] Yield curve changes and credit spreads\nIn this section, we’ll explore the predictive relationship between yield curve changes and credit spreads. This analysis is crucial for understanding how changes in interest rates might signal future shifts in credit risk.\nWe’ll focus on two key questions:\nDo changes in the yield curve precede changes in credit spreads?\nHave yield curve inversions historically led to widening credit spreads?\n\n\n\n\nLet’s use AI assistance to create a comprehensive Python script that analyzes these relationships:\n\nAI Prompt\nCreate a Python script to analyze yield curve slopes and credit spread changes:\n1. Use FRED API for 40 years of:\n– Federal funds rate\n– 10-year Treasury yield\n– Corporate bond yield\n2. Calculate:\n– Yield curve slope\n– Credit spread\n– Identify inversions\n3. Analyze periods: 1, 7, 14, 30, 60, 90, 180, 270, 365, 547, 730, 1095 days\nFor each:\n– Compute forward credit spread changes\n– Calculate correlations and mean changes (normal/inverted periods)\n– Perform t-tests (normal vs inverted)\n4. Store results in DataFrame\n5. Plot:\n– Correlation vs forward period\n– Mean changes vs forward period\n6. Print results\n\n\n\n\n\nTo check the resulting code, go to Datalore:\n      \n      Open Datalore Code\n\n\n\n\n\nLet’s delve deeper into the relationship between yield curve slopes and future changes in credit spreads. Our goal is to understand how yield curve inversions might predict future spikes in credit risk and, by extension, potential economic downturns.\nMethodology:\nWe analyzed the correlation between the yield curve slope (10-year Treasury yield minus fed funds rate) and forward changes in credit spreads (corporate bond yield minus 10-year Treasury yield) for various future time periods, ranging from 1 day to 3 years (1,095 days).\nAnalysis of correlation between yield curve slope and forward credit spread change\nKey observations:\nShort-term correlations (1–90 days): We observe weak negative correlations, suggesting limited predictive power in the immediate future.\nMedium-term correlations (180–547 days): There’s a stronger negative relationship, with the peak negative correlation occurring around the 547-day mark. This indicates that yield curve inversions tend to precede credit spread widening most reliably in this time frame.\nLong-term correlation (1,095 days): Interestingly, the correlation turns positive, suggesting a potential reversal or cyclical nature of the relationship over very long periods.\n\n\n\n\nImplications:\nThe strongest predictive power of yield curve inversions for credit spread widening appears to be in the 1–2 year range.\nThis aligns with the common observation that recessions often follow yield curve inversions by 12–24 months.\nThe positive correlation at 1,095 days warrants further investigation and could relate to long-term economic cycles.\n\n\n\n\nAnalysis of mean forward credit spread change\n\n\n\n\nThis graph illustrates the average change in credit spreads over various future time periods, comparing normal yield curve periods (blue line) to inverted yield curve periods (orange line).\nKey observations:\nNormal yield curve periods (blue line):\n\nThe line remains relatively flat and close to zero across all time periods.\nThere’s a slight dip into negative territory for medium-term periods (180–547 days), suggesting a tendency for mild credit improvement during normal economic conditions.\nLong-term periods (730–1,095 days) show a small positive change, indicating a slight widening of credit spreads over extended time frames.\nInverted yield curve periods (orange line):\n\nShort-term periods (1–90 days) show small positive changes, indicating slight immediate credit deterioration following inversions.\nMedium-term periods (180–547 days) exhibit large positive changes, peaking around the 547-day mark. This suggests significant credit spread widening in the 1–2 year period following yield curve inversions.\nLong-term periods (730–1,095 days) show a dramatic reversal, with the 1,095-day point dropping into negative territory. This indicates a potential improvement in credit conditions or a cyclical effect over very long time frames.\nComparison between normal and inverted periods:\n\nThe divergence between the two lines is most pronounced in the medium-term range (180–547 days), highlighting the predictive power of yield curve inversions for credit spread changes in this timeframe.\nThe convergence and eventual crossover of the lines in the long term (1,095 days) is particularly interesting, suggesting a potential “mean reversion” effect over extended periods.\n\n\n\n\nImplications:\nTiming of credit risk: The peak in the inverted line around 547 days suggests that the greatest credit risk following a yield curve inversion typically manifests between 1.5 to 2 years after the inversion occurs.\nMagnitude of impact: The large gap between normal and inverted lines in the medium term indicates that yield curve inversions precede significantly larger credit spread widenings compared to normal periods.\nRisk management strategies: Financial institutions and investors might consider implementing more conservative credit policies or increasing hedges against credit risk in the 1–2 year period following yield curve inversions.\nEconomic cycle insights: The reversal seen at 1,095 days could indicate the typical length of a credit cycle or the delayed effects of policy interventions following economic stress periods.\nPredictive power: This graph reinforces the idea that yield curve inversions can serve as early warning indicators for increased credit risk, with a lead time of approximately 1–2 years.\n\n\n\n\nWhile these patterns offer guidance, they should not be treated as infallible predictors. Economic conditions can vary, and past patterns may not always repeat in the same way. Nonetheless, this analysis offers a framework for understanding the relationship between yield curve dynamics and future credit risk, providing a valuable tool for economic forecasting and risk management.\n[Advanced] Credit spread analysis with economic events: a 90-day forward look\nIn this final section, we’ll explore the dynamic relationship between credit spreads and major economic events, focusing on a 90-day forward-looking perspective. This analysis provides crucial insights into how credit risk perceptions evolve over relatively short periods, offering a window into market sentiment and economic conditions.\nWe’ll use AI assistance to create a comprehensive Python script that combines data manipulation, statistical analysis, and advanced visualization techniques. Our analysis will:\nCalculate 90-day forward changes in credit spreads.\nIdentify and visualize outliers in credit spread changes.\nMap these changes to significant economic events from 2001 to 2020.\nCompare credit spread behavior during normal and inverted yield curve periods.\nConduct statistical tests to validate our observations.\n\n\n\n\nLet’s prompt the AI to help us create this analysis:\n\nAI Prompt\nCreate a Python script to analyze and visualize 90-day forward credit spread changes in relation to major economic events:\n1. Use existing DataFrame ‘df’ with credit spread data\n2. Calculate 90-day forward change in credit spreads: diff(periods=90).shift(-90)\n3. Identify outliers using IQR method\n4. Create a time series plot:\n– X-axis: Date (show every 5 years)\n– Y-axis: 90-day forward change in credit spread\n– Plot main line for spread changes\n– Highlight outliers as red scatter points\n5. Add vertical lines for economic events (2001-2020):\n– Enron Bankruptcy, WorldCom Bankruptcy, Lehman Brothers Bankruptcy\n– European Debt Crisis, 2019 Repo Spike, COVID-19 Pandemic Declaration\n6. Customize plot: large fonts, clear labels, grid, legend\n7. Print summary statistics:\n– Number and percentage of outliers\n– Top 10 positive and negative outliers\n– Mean spread change for normal and inverted yield curve periods\n8. Perform t-test comparing normal and inverted periods\nUse pandas for data manipulation, matplotlib for plotting, seaborn for styling, and scipy.stats for the t-test. Ensure the script is well-commented and follows Python best practices.\n\n\n\n\n\nTo check the generated code, go to Datalore:\n      \n      Open Datalore Code\n\n\n\n\n\nLet’s dive into the results of this code and get a unique look at the history of the United States through the lens of credit spread changes.\n\n\n\n\nNow that we’ve visualized the data and generated our statistics, let’s analyze the key trends and events:\nVolatility clusters: The graph reveals distinct periods of high volatility in credit spread changes, particularly around major economic events. This clustering of volatility suggests that credit risk perceptions can change rapidly and dramatically during times of economic uncertainty.\nAsymmetric outliers: We observe that the most extreme outliers (red dots) tend to be on the positive side, indicating sudden, large increases in credit spreads. This asymmetry suggests that credit risk can spike more sharply than it tends to decrease, reflecting the market’s sensitivity to negative news.\nMajor economic events:\n\nDot-com bubble (2000–2002): We see increased volatility and some outliers, reflecting the tech market crash and subsequent economic uncertainty.\n2008 financial crisis: The most dramatic spike in our dataset occurs around the Lehman Brothers bankruptcy, with extreme positive outliers indicating a severe credit crunch.\nEuropean debt crisis (2011): Another cluster of outliers is visible, showing how international events can impact US credit markets.\nCOVID-19 pandemic (2020): A sharp spike in credit spread changes, rivaling the 2008 crisis in magnitude, demonstrates the immediate and severe impact of the pandemic on credit risk perceptions.\nRecovery patterns: Following each major spike, we observe periods of negative changes in credit spreads, indicating a gradual return to lower credit risk perceptions. However, the recovery patterns vary in duration and stability.\nRecent trends: In the years leading up to 2020, we see relatively stable credit spread changes with fewer outliers, possibly reflecting the prolonged period of low interest rates and economic growth. The COVID-19 pandemic disrupts this stability dramatically.\nFrequency of outliers: Outliers appear to be more frequent and extreme during recognized periods of economic stress, serving as a visual indicator of market turmoil.\n\n\n\n\nLimitations:\nWhile this 90-day forward view provides valuable insights, it doesn’t capture longer-term trends or very short-term fluctuations. The causes behind these changes can be complex and multifaceted, often requiring additional context to fully interpret.\nThis analysis offers a nuanced view of credit risk dynamics over the past two decades. It highlights the market’s sensitivity to major economic events and provides a valuable tool for anticipating potential shifts in credit risk perceptions.\nConclusion: applying your new credit risk analysis skills\nCongratulations on completing this comprehensive tutorial on credit risk analysis using Python and AI-assisted coding in Datalore! Let’s recap what you’ve learned and how you can apply these skills in your own financial analyses:\nKey skills acquired\nData retrieval and preprocessing: You’ve learned how to use the FRED API to fetch economic data and prepare it for analysis using pandas.\nVisualization techniques: You’ve created various plots to visualize federal funds rates, Treasury yields, and corporate bond yields, enhancing your data presentation skills.\nYield curve analysis: You’ve explored how to calculate and interpret yield curve slopes and inversions, crucial indicators for economic forecasting.\nCredit spread calculation: You’ve computed and analyzed credit spreads, gaining insights into market risk perception.\nPredictive analysis: You’ve conducted forward-looking analyses to understand the relationship between yield curve changes and future credit spread movements.\nEvent impact assessment: You’ve examined how major economic events affect credit spreads, developing skills in contextual data interpretation.\nAI-assisted coding: Throughout the tutorial, you’ve leveraged AI to generate code, demonstrating how to use this powerful tool to streamline your workflow.\n\n\n\n\nApplying your skills\nCustom analyses: Use the code templates provided to analyze different time periods or other economic indicators that interest you.\nRisk management: Apply the yield curve inversion and credit spread analysis techniques to assess potential risks in your investment portfolio.\nEconomic forecasting: Utilize the predictive analysis methods to create your own forecasts for credit risk and economic conditions.\nData-driven decision making: Incorporate these data analysis techniques into your financial decision-making processes, whether for personal investments or professional applications.\nContinuous learning: As you’ve seen, economic conditions evolve. Use the skills you’ve learned to stay updated on market trends and continually refine your analysis techniques.\n\n\n\n\nNext steps\nExpand your dataset: Try incorporating additional economic indicators or international data to broaden your analysis.\nEnhance your models: Experiment with more advanced statistical methods or machine learning techniques to improve predictive power.\nAutomate your analyses: Create scripts that automatically update your analyses as new data becomes available with Datalore’s Scheduled runs feature.\nCollaborate and share: Use Datalore’s collaboration features to work with others and share your insights.\n\n\n\n\nWhile these tools and techniques are powerful, they should be used in conjunction with a nuanced understanding of economic principles and current market conditions. Stay curious, keep practicing, and continue to refine your credit risk analysis skills!\nIf you’d like to edit the full code of this tutorial in Datalore, including interactive elements and additional resources, click the button below:\n      \n      Open Datalore Code",
        "dc:creator": "Alena Guzharina",
        "content": "This is a guest blog post by Ryan O’Connell, CFA, FRM. Understanding the relationships between various economic indicators is crucial for navigating the financial landscape. These relationships significantly impact the overall state of the economy, affecting businesses, investors, and individuals alike. We&#8217;ll analyze data spanning over two decades of financial history, leveraging the power of [&#8230;]",
        "contentSnippet": "This is a guest blog post by Ryan O’Connell, CFA, FRM. Understanding the relationships between various economic indicators is crucial for navigating the financial landscape. These relationships significantly impact the overall state of the economy, affecting businesses, investors, and individuals alike. We’ll analyze data spanning over two decades of financial history, leveraging the power of […]",
        "guid": "https://blog.jetbrains.com/?post_type=datalore&p=505317",
        "categories": [
          "datalore-ai",
          "python-for-finance"
        ],
        "isoDate": "2024-08-26T14:34:49.000Z"
      },
      {
        "creator": "Andrey Belyaev",
        "title": "Workspaces in IntelliJ IDEA",
        "link": "https://blog.jetbrains.com/idea/2024/08/workspaces-in-intellij-idea/",
        "pubDate": "Mon, 26 Aug 2024 09:01:26 +0000",
        "content:encodedSnippet": "Better late than never! This idiom is probably the best way to describe the functionality we’ll introduce in this article, specifically, support for workspaces in IntelliJ IDEA.\nIntro\nIn a nutshell, a workspace is a meta-project that allows you to manage multiple projects simultaneously. This feature is useful for various reasons, from coordinating complex development environments to having a couple of unrelated projects on your hands\nNote for the impatient: There will be some theory and history included below, so if you’re eager to get workspaces into your IDE, just go to the How to use workspaces chapter and crack on! Also, join the upcoming webinar for more details. Please note that this feature is currently in preview, so you may encounter some bugs and limitations. \nThere’s been a ticket for workspace support on our issue tracker since 2011. However, the rise of microservices and monorepositories in the mid-2010s seemed to make workspaces obsolete. The monorepo model was totally aligned with IntelliJ IDEA’s focus on the “one project – multiple modules” approach. Yet, demand for workspaces continued to grow, something confirmed by the increasing number of likes and supportive comments from users on YouTrack. In the next section, we’ll explore why workspaces are still relevant in 2024.\nWhy monorepos didn’t put an end to the workspace approach \nMonorepos indeed have plenty of advantages over other approaches to code arrangement, namely multi-repos, namely:\nBetter collaboration. All developers are able to see what’s going on in other parts of the project they’re working on. Every change becomes visible as soon as the code is committed. While implementing a service that communicates with another service written by another team, developers can see the other services’ code to get an understanding of how it works.\nEasier dependency management. In most cases, all projects in a monorepo use the same package management and build tool, making it easier to track dependencies and versions. Also, all application components in a monorepo are usually released together, meaning there is no risk of problems arising with inter-project dependencies. \nCross-project refactoring. Having access to the entire codebase allows the IDE to index code references, meaning it can detect changes and easily perform refactorings correctly.\nImproved code discoverability. New team members can easily navigate the entire codebase and understand the dependencies between different projects and components.\n\n\n\n\n\nIf you check out a monorepo and open it with IntelliJ IDEA, you’ll see that the monorepo structure fits into the “project-modules” paradigm perfectly. The root folder becomes a “project”, and all subfolders become “modules”. So, on this basis, it looked like the model worked fine, and the implementation of the workspaces feature could be postponed.\nHowever, monorepos have some disadvantages:\nMonorepos tend to grow quickly. Loading a massive codebase and gathering metadata about the code can be time-consuming. The vast number of commits to all projects within the monorepo can lead to branching, merging, and rebasing operations taking longer than expected. \nRestricting access to subfolders might become a challenge. For example, with Git, you can do this by using submodules or provider-specific features like GitHub’s Codeowners.\nCI/CD integration can be challenging if different projects within a monorepo have different release cycles.\nIn addition to the purely technical challenges of using monorepos, we can add a behavioral dimension. Usually, developers don’t work on the entire monorepo code. Instead, they tend to focus on an isolated service or a few of them. \nSo, despite offering many advantages, usage of the monorepo approach started to wane due to the following:\nPerformance problems: Cloning, pulling, and merging code became challenging as soon as the codebase began to grow.\nLimited autonomy: In a monorepo, it’s harder to develop and release a selected project independently from other parts of the whole system compared to the multi-repository approach. In addition to this, access control remained a challenge.\nUnknown boundaries: Projects are treated as a single monolith, so code and abstractions can “leak” into other projects, creating tight coupling. Another consequence is a “broken master”. If just one project within the monorepo is broken, the whole monorepo is treated as broken.\nDistracted developer’s focus: While developers usually work on a single small project, with monorepos, they have to deal with a codebase of dozens of projects.\nThe above has contributed to increasing votes on issue IDEA-65293, making it evident that we had to include workspaces as a new feature in our IDEs. \nAs a confirmation, surveys show that microservice developers use multiple repositories for development, and this is a growing trend.\n\n\n\n\nWorkspaces improve developers’ experience when they work with multiple projects and repositories. Please note that workspaces can also be useful for developers who prefer monorepos. Having the ability to check out particular projects from a big monorepo and work on those only is a great benefit.\nIf you’d like to dive deeper into this topic, there are some handy articles like “The issue with monorepos” and “Monorepo is a bad idea” that explain things in greater detail.\nWhat is a workspace?\nIn one of the discussions on the JetBrains support forum, someone posted the following:\n\nProject: This is essentially a description of your final software product.\nWorkspace doesn’t have anything to do with actual projects and/or software products! It is (ideally) your IntelliJ IDEA’s desktop, merely a container for projects you’re currently working with. This is your current view of your developer’s environment. It does not produce results, but controls how results are produced.\n\n\n\n\nThis is the best explanation for the “workspace” concept introduced in this plugin. You can treat a workspace as a collection of the projects that you work on. Every project can use its own technology stack and a build tool and can be run independently.\nUser scenarios for workspaces\nWhen we made the plugin, we thought about a “typical” setup for an application, comprising:\nA set of backend services.\nAn API gateway.\nClient applications, such as a React web app or a mobile app.\nA collection of custom libraries (for example, Spring Boot starters) used across services.\nThe code for these components might be organized in a single monorepo or across multiple repositories. Developers might also need to create small “satellite” applications for testing and debugging components like libraries, without the need to commit these auxiliary apps to the main codebase.\nIt’s important to note that this architectural setup can vary. For instance, in a monolithic application, the backend might be consolidated into a single service, and the API gateway could become optional. In another scenario, if an application lacks a client interface, the focus would be solely on the backend services and the API gateway.\nBased on this, we’ve come up with the following major use cases and corresponding workspace configurations for the plugin:\n1. Fullstack developer\nIn many cases, we need to update both front-end and back-end components, which could be stored in different repositories. The workspaces plugin allows us to check out projects from repositories independently, add them to the same workspace, and work with their code as if they were in one project.\n\n\n\n\n2. Microservices developer\nLet’s assume that we have dozens of microservices in a monorepo, and we need to update only some of them. There’s no longer any need to import the entire repository into IntelliJ IDEA. We can create a workspace and add only the required services to it. Moreover, we can also use different build tools for different projects. If you build one service with Maven and another with Gradle – no problem!\n\n\n\n\n3. Library developer\nThis scenario can be used when we need a simple “Hello, World!” application to test a solution. The perfect example of this is the development of a Spring Boot starter. The test application won’t be committed to the code repository, but we may need it to simplify development. In this case, we can create a simple project right in the workspace in addition to the starter project, run the app, debug the starter, and then just discard the app or reuse it in another workspace.\n\n\n\n\nCurrent implementation\nA workspace is a separate folder that stores references to projects from other folders. Additionally, we can create a project inside a workspace folder if needed. A workspace should not be invasive in terms of project settings. IntelliJ IDEA stores project settings, such as code style, SDK, etc., in a separate file in a project-specific folder (.idea). When we add a project to a workspace, IntelliJ IDEA copies its settings to the workspace folder, and then we can change them locally. This means that one project can be included in several workspaces with different settings. The picture below shows how this works. \n\n\n\n\nSince the functionality of workspaces is still a work in progress, we’ve implemented it as a separate non-bundled plugin to be able to release it faster as we continue to improve it based on the feedback we get from users. We hope that, sooner or later, this feature will become a part of the core IDE functionality.\nHow to use workspaces\nInstall the plugin from JetBrains Marketplace.\nCreate a workspace as a new project type.\n\n\n\n\n\nGive your workspaces folder a name and add all required projects to it.\n\n\n\n\nYou can run projects separately using well-known run configurations in IDEA or Maven/Gradle commands. To run several projects at once, for example, microservices, you’ll probably need a special shell script or Docker compose file. We tried to make the user experience as familiar as possible.\nCurrent version limitations\nLet us share some limitations we are aware of. This isn’t a comprehensive list, but it includes key issues that might seem crucial to you and could prevent you from trying the workspaces today. \nWe do not copy run configurations from the included projects to the workspace. For the time being, you will need to create run configurations manually after project import.\nThere is no constant settings synchronization. For example, if you used JDK 17 in the project and then included it in the workspace – the workspace will use JDK 17. If we upgrade JDK to a newer version in the “main” project settings, the workspace won’t “see” this change.\nProject renaming is not supported.\nResolving dependencies across independent projects is a work in progress.\nYou can find the full list of issues linked to the YouTrack ticket IDEA-65293. \nFurther plans\nWe are currently working on the implementation of a number of tasks to make workspaces support even better, notably:\nProject settings synchronization.\nAbility to store and share workspace in VCS.\nMore build tools to support.\nMaking workspace a first-class citizen in all IDEs.\nSimplify run configuration for running multiple projects at once.\nSmooth debugging across projects.\nFeedback welcome! \n\n\n\n\nThe workspaces feature is far from finished. We’ve only just begun our work as we edge another step toward our goal of creating the ideal IDE. We welcome all feedback you might have, it will help us in our efforts! Try out the new workspaces feature, and let us know your thoughts. Your feedback will help us make IntelliJ IDEA even better. You can rate our efforts on the plugin page or add your thoughts and report issues in YouTrack.\n5-star us if you like the initiative!",
        "dc:creator": "Andrey Belyaev",
        "content": "Better late than never! This idiom is probably the best way to describe the functionality we’ll introduce in this article, specifically, support for workspaces in IntelliJ IDEA. Intro In a nutshell, a workspace is a meta-project that allows you to manage multiple projects simultaneously. This feature is useful for various reasons, from coordinating complex development [&#8230;]",
        "contentSnippet": "Better late than never! This idiom is probably the best way to describe the functionality we’ll introduce in this article, specifically, support for workspaces in IntelliJ IDEA. Intro In a nutshell, a workspace is a meta-project that allows you to manage multiple projects simultaneously. This feature is useful for various reasons, from coordinating complex development […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=505111",
        "categories": [
          "features",
          "tutorials",
          "intellijidea-2",
          "monorepos",
          "monorepositories",
          "workspaces"
        ],
        "isoDate": "2024-08-26T09:01:26.000Z"
      },
      {
        "creator": "Olga Bedrina",
        "title": "The Fail-Fast Strategy: What Is It and How Does TeamCity Support It?",
        "link": "https://blog.jetbrains.com/teamcity/2024/08/fail-fast-strategy-teamcity/",
        "pubDate": "Fri, 23 Aug 2024 09:57:01 +0000",
        "content:encodedSnippet": "This is a guest post from Cameron Pavey, draft.dev.\nSoftware development teams are always looking for ways to move faster and deliver more value in less time. However, one common pitfall for many teams is spending far too much time and effort building something, only to encounter major issues late in the project’s lifecycle.\nThe fail-fast strategy addresses this problem by “shifting left” on potential points of failure and embracing them as part of a virtuous feedback loop. Whether in project management or software development, a failure is often just a signal that something needs to change. The earlier you can detect this signal, the sooner you can adjust for it, thus mitigating the risk of wasted work.\nTo properly implement a fail-fast strategy, you need a tool that supports this way of working. TeamCity is a CI/CD solution that complements the fail-fast strategy and has several features to help you implement it.\nIn this guide, you’ll learn more about the fail fast strategy and how you can leverage TeamCity to adopt this strategy for yourself.\nWhat is the fail-fast strategy?\nIn software development, the fail-fast strategy emphasizes iterative discovery over strict planning. Key principles include:\nRapid feedback loops: Short cycles allow for frequent releases and early feedback, helping teams move quickly and efficiently.\n\n\n\n\nProactive risk management: Early identification of risks allows for timely mitigation or pivoting, reducing wasted effort.\n\n\n\n\nIterative experimentation: Frequent experimentation helps quickly identify dead ends and promising solutions, optimizing the use of resources.\n\n\n\n\nTransparency: Promotes a culture of continuous improvement, where teams share and learn openly.\nThis strategy operates on multiple levels:\nProject management: Focuses on direction, ideation, and finding product-market fit.\nSoftware development: Applies the same principles to concrete practices like continuous integration (CI).\nPairing the fail-fast mentality with a CI service like TeamCity helps shorten feedback cycles and improve outcomes by rapidly identifying and addressing issues.\nMajor advantages of the fail-fast strategy\nCompared to traditional methods like the waterfall strategy, the fail-fast strategy offers significant benefits:\nShorter feedback loop: Submit small, incremental changes for automated checks, catching faults early and fixing them quickly.\nIdentifying pitfalls early on: Incremental builds help identify technical issues early, allowing for timely adjustments and de-risking your approach upfront.\nPotential drawbacks of the fail-fast strategy\nWhile the fail-fast strategy offers many benefits, there are potential drawbacks:\nMindset shift: Teams used to traditional methods may resist the concept of “failure”, impacting morale and causing frustration.\nEmbracing failure: Understanding that failure, discovery, and pivoting are key elements is crucial for the strategy’s success.\nTooling requirements: Effective implementation requires robust tools, particularly a CI/CD tool like TeamCity.\nHow does TeamCity support the fail-fast strategy?\nAs the central goal of the fail-fast strategy is shorter feedback cycles, you need a tool that provides this feedback for you in a timely manner. Continuous integration tools, such as TeamCity, are designed for this purpose. They can run builds, tests, and other scripted workflows in response to code changes.\nReal-time reporting\nLarge software projects can have long, slow-running builds. This makes it especially frustrating when you wait a long time for a build to run, only to discover that it failed. Whether it’s a blocking build issue that stops subsequent steps or an early test failure that makes the rest of the run redundant – the sooner you discover these issues, the better.\nTeamCity mitigates this issue for you by providing real-time reporting. You can view in-progress builds, inspect their current state, and build logs to identify problems as they occur rather than waiting until the end of a CI run.\nBy seeing the live status of running builds, developers can identify and fix problems without waiting for the build to finish. When the build fails, you can see what went wrong, fix it, and run another build. Compared to other CI systems where you need to wait for the build to complete, this workflow offers a shorter feedback cycle that works well with the fail-fast strategy.\n\n\n\n\nThis approach is particularly effective if quick-running build steps provide high-value feedback, like static analysis and other code quality checks. You can view the progress of these live to determine if you need to make any alterations to your code, and once these pass, you can leave the rest of the build to run.\nBuild configurations\nYour build process will likely be nontrivial when dealing with complex software systems. You’ll need to do any number of steps, including:\nBuilding Docker images\nCompiling source code\nDownloading dependencies\nRunning various kinds of tests (with varying degrees of cost)\nAs your build grows over time, it could become too large to reasonably manage. At this point, you may want to find a way to split the build into smaller steps.\nTeamCity solves this through build configurations. Build configurations allow you to split your build into discrete steps. When you do this, each step has a clearly defined responsibility, limiting the potential for complexity to leak between steps as your system grows.\nBuild chains\nAnother helpful feature of TeamCity that can be used to implement the fail-fast strategy is build chains. This feature allows you to declare build configurations as dependent on one another. In practice, this means you can run all your quality gates before the deployment step, allowing you to skip the deployment if there are quality issues that prevent it from being a release candidate.\nExample of a build chain in TeamCity\n\n\n\nFailures in the earlier steps in the chain will stop subsequent build configurations from running. This can save time and resources and help shorten the feedback loop even more by avoiding the effort spent on faulty builds.\nTest reports\nFailing tests are a fact of life for software developers. The key factor that separates frustrating failures from helpful failures is how much information you have when trying to fix them. Ideally, you want to know:\n– What failed: Was it a unit test, an integration test, etc.?\n– When it failed: Is it a new failure? Is this the first time it has happened? Is it a recurring flaky test?\n– Why it failed: Is it a legitimate functional failure or a flaky test?\nThis information helps you narrow down the cause and promptly fix the issue. You could run the test on your development machine and see it fail for yourself, but you’ll likely miss out on a lot of context (for example, information about in which commit this failure first arose). \nTeamCity test reports solve this problem. Every time your CI workflow runs, test data is captured for a wide range of testing frameworks. This data is then presented to you in relation to the CI runs that have experienced test failures, as well as a few other views like Current Problems and Flaky Tests.\nExample of a test report in TeamCity\n\n\n\nThese reports provide immediate insights into what problems your build is facing and the nature of the problems, such as flaky tests, newly introduced issues, or long-standing failures. \nHigh-quality test reports are a must for projects that require heavy use of automated testing at any level, but they’re especially helpful if you have broad coverage from unit tests and integration tests.\nThis way, at a glance, you have a comprehensive snapshot of the state of your code base each time CI runs.\nNotifications\nFail fast is only good if you know about the failure, and detailed build information is only helpful if people know it’s there. Developers would typically prefer to work on things themselves rather than sit and watch something being built by CI.\nThanks to highly configurable notifications, there’s no need to babysit builds. In TeamCity, you can configure rules to determine what you would like to be notified about and where you’d like those notifications to go. From email and browser notifications to Slack and even in-IDE notifications, there are several channels to choose from.\nNotification options in TeamCity\n\n\n\nNotifications are a key requirement in a system that’s intended to help you work more proactively, and the more configuration options you have at your disposal, the more use cases you will be able to satisfy.\nFor a fail-fast workflow, you might want to configure notifications for any failed build to which you’ve contributed. Then, relying on the VCS integration, you can get rapid feedback on your changes directly in your IDE as you make small, atomic changes.\nTeamCity notifications can be configured to only notify you of Builds containing my changes or when The first build error occurs. These settings are great for fine-tuning the notifications you see. Rather than seeing every failing build, you might only want to see failures on builds that include your changes or when the first error happens for a build.\nIf you set up continuous development through TeamCity, you can also enable notifications to inform you whenever a deployment or infrastructure change (through infrastructure as code tools like Terraform or Kubernetes deployments) occurs. In this case, you’d likely want to be notified in case of success as well as failure.\nArtifacts\nIssues often arise in CI that you cannot replicate locally. This can lead to a lot of misdirected time as you try to determine which is different between the CI run and your local application. Using artifacts can help address this problem.\nIn TeamCity, artifacts are typically anything produced by your build, such as binaries, logs, recordings, screenshots, etc. You can treat pretty much anything as an artifact, which gives you great flexibility in how you use this feature. Artifacts are then captured by TeamCity and are available for download through the UI after the build.\nThis can greatly streamline the analysis and debugging process that you go through when trying to rectify a failing build. For example, if you have end-to-end (E2E) tests that only seem to fail in your CI runs, there’s a good chance that your E2E tool has the ability to produce screenshots and screen recordings when failures occur. Being able to capture these as artifacts gives you a trove of data to help with debugging.\nArtifacts can also be used for any other use case where you want to capture the output of a build. Perhaps your project produces binary executables. In that case, you could capture the built binary for each CI run, allowing you to test any build for any commit that runs through your CI workflow.\nWrapping up\nThis guide introduced the fail-fast strategy, including its benefits, such as proactive risk management, transparency, and adaptability. TeamCity supports fail-fast through various powerful features, including real-time reporting, flexible notifications, and detailed test reports.\nWhen utilized properly, the fail-fast strategy can be a powerful tool. It can help you move faster and deliver value without the constraints of slower, more traditional ways of working. However, the process needs to be supported by suitably powerful and flexible tools. If you’re looking for a CI/CD server that fits the bill, consider taking TeamCity for a spin today.",
        "dc:creator": "Olga Bedrina",
        "content": "This is a guest post from Cameron Pavey, draft.dev. Software development teams are always looking for ways to move faster and deliver more value in less time. However, one common pitfall for many teams is spending far too much time and effort building something, only to encounter major issues late in the project&#8217;s lifecycle. The [&#8230;]",
        "contentSnippet": "This is a guest post from Cameron Pavey, draft.dev. Software development teams are always looking for ways to move faster and deliver more value in less time. However, one common pitfall for many teams is spending far too much time and effort building something, only to encounter major issues late in the project’s lifecycle. The […]",
        "guid": "https://blog.jetbrains.com/?post_type=teamcity&p=505010",
        "categories": [
          "news"
        ],
        "isoDate": "2024-08-23T09:57:01.000Z"
      },
      {
        "creator": "Sarah Haggarty",
        "title": "Kotlin 2.0.20 Released",
        "link": "https://blog.jetbrains.com/kotlin/2024/08/kotlin-2-0-20-released/",
        "pubDate": "Thu, 22 Aug 2024 14:51:13 +0000",
        "content:encodedSnippet": "The Kotlin 2.0.20 release is out! This version includes performance improvements and bug fixes for Kotlin 2.0.0, where we announced the Kotlin K2 compiler as Stable. Here are some additional highlights from this release:\nThe data class copy function will have the same visibility as the constructor\nStatic accessors for source sets from the default target hierarchy are now available in multiplatform projects\nConcurrent marking for Kotlin/Native has been made possible in the garbage collector\nThe @ExperimentalWasmDsl annotation in Kotlin/Wasm has a new location\nSupport has been added for Gradle versions 8.6–8.8\nA new option allows sharing JVM artifacts between Gradle projects as class files\nThe Compose compiler has been updated\nSupport for UUIDs has been added to the common Kotlin standard library\n\n\n\n\nFor the complete list of changes, refer to What’s new in Kotlin 2.0.20 or the release notes on GitHub.\nHow to install Kotlin 2.0.20\nStarting from IntelliJ IDEA 2023.3 and Android Studio Iguana (2023.2.1) Canary 15, the Kotlin plugin is distributed as a bundled plugin included in your IDE. This means that you can’t install the plugin from JetBrains Marketplace anymore.\nTo update to the new Kotlin version, change the Kotlin version to 2.0.20 in your build scripts.\nIf you need the command-line compiler, download it from the GitHub release page.\nIf you run into any problems\nFind help on Slack (get an invite).\nReport issues to our issue tracker, YouTrack.\n\n\n\n\n\nStay up to date with the latest Kotlin features! Subscribe to receive Kotlin updates by filling out the form at the bottom of this post. ⬇️\nSpecial thanks to our EAP Champions 🥇👏\nZac Sweers\nRick Clephas\nFlorian Schreiber\nSechaba Mofokeng\nYang\nŁukasz Wasylkowski\nDavid Lopez\nBernd Prünster\nAlexander Nozik\nBenoit ‘BoD’ Lubek\nSterling Albury\nKacper Wojciechowski\nMohamed Rejeb\nJake Wharton\nJohannes Svensson\nArtyom Shendrik\n\n\n\n\nWhat else to read and watch\nWhat’s new in Kotlin 2.0.20 documentation\nK2 compiler migration guide\nK2 Compiler Performance Benchmarks and How to Measure Them on Your Projects\nMeet Renovated Kotlin Support – K2 Mode: What You Need to Know\nJetpack Compose compiler moving to the Kotlin repository\nKotlin EAP Champions",
        "dc:creator": "Sarah Haggarty",
        "content": "The Kotlin 2.0.20 release is out! This version includes performance improvements and bug fixes for Kotlin 2.0.0, where we announced the Kotlin K2 compiler as Stable. Here are some additional highlights from this release: For the complete list of changes, refer to What&#8217;s new in Kotlin 2.0.20 or the release notes on GitHub. How to [&#8230;]",
        "contentSnippet": "The Kotlin 2.0.20 release is out! This version includes performance improvements and bug fixes for Kotlin 2.0.0, where we announced the Kotlin K2 compiler as Stable. Here are some additional highlights from this release: For the complete list of changes, refer to What’s new in Kotlin 2.0.20 or the release notes on GitHub. How to […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=503938",
        "categories": [
          "releases"
        ],
        "isoDate": "2024-08-22T14:51:13.000Z"
      },
      {
        "creator": "Alena Guzharina",
        "title": "What’s New in Datalore 2024.4: Limit 500 Toggle, Easier Folder Import, Polars DataFrames Support, and More",
        "link": "https://blog.jetbrains.com/datalore/2024/08/22/what-s-new-in-datalore-2024-4-limit-500-toggle-easier-folder-import-polars-dataframes-support-and-more/",
        "pubDate": "Thu, 22 Aug 2024 10:07:56 +0000",
        "content:encodedSnippet": "Datalore 2024.4 introduces quality-of-life improvements for SQL cells, a revamped folder import workflow, support for Polars DataFrames, and more. Datalore Cloud customers have already received the new update automatically, and Datalore On-Premises customers can upgrade by following these instructions.\nLimit 500 toggle for SQL cells\nTo help you prototype SQL queries faster, we’ve introduced a new Limit 500 feature inside SQL cells in Datalore notebooks. There is now a toggle visible in the SQL cell next to the Browse schema action. This setting will persist after a kernel restart, ensuring a seamless workflow.\n\n\n\n\nRevamped import folder workflow\nIt is now easier to import your previous work into Datalore. We’ve enhanced the folder import experience with a new, streamlined dialog that appears when you click Import | Upload folder. You can now easily select which notebooks and files to import, with the option to import notebooks as files. Hidden files and folders are fully supported and can be imported if selected. \n\n\n\n\nUpdates to the notebook UI\nWe’ve made several updates to the notebook UI to enhance your editing experience. Unfocused code cells now have borders, improving cell visibility and making it easier to target the insert cell buttons. Interactive controls and metric cells now have their options merged with the cell toolbar, no longer occupying the full width of the notebook. Additionally, cell type-specific actions, such as selecting a datasource or target variable, are now positioned to the right of the execution time for easier access. Cells now also feature a Run button, which can be gray or blue depending on whether the cell was changed after execution – offering a clearer indication of a cell’s status.\n\n\n\n\nDrop-down cell improvements\nFor large lists, you can now use a search string within the drop-down to quickly find your desired option. Additionally, multiselect drop-downs now include Select all and Clear all options.\n\n\n\n\nQuick notebook access from the editor\nYou can now quickly search for and open notebooks in a separate tab directly from the Notebooks view. Enjoy easier navigation without extra context switching.\n\n\n\n\nSupport for Polars DataFrames\nDatalore now supports rich table outputs for Polars DataFrames. To get an interactive table output, specify the DataFrame name at the end of the cell without a print statement.\n\n\n\n\nOther updates and bug fixes\nDuplicate file names are no longer permitted inside Datalore’s file system, with existing duplicates renamed with (#N) prefixes to make files easier to find and minimize naming confusion. \nPython `input()` commands are now supported for interactive reports. \nGit repositories with submodules are now cloned correctly. \nTables are no longer cropped when printing to PDF. \nWe’ve resolved the issue where pages would not load when Datalore was set up with an HTTP proxy on a non-standard port. \nWe’ve fixed the issue where refreshing the schema in the Edit database connection dialog would not work for users logged in via OAuth.\nIt is now possible to copy data from the cell outputs to the clipboard via the output’s context menut. This feature is supported for most cell output types. \nThe workspace owner is now indicated in the left-hand sidebar of the home page.\nDatalore Cloud customers have already received these updates automatically. \nFor Datalore On-Premises customers, it is highly important to ensure the database that stores all the Datalore content is backed up before upgrading to the 2024.4 version.\n      \n      Upgrade to 2024.4\n    \n\n\n\n\nKind regards,\nThe Datalore team",
        "dc:creator": "Alena Guzharina",
        "content": "Datalore 2024.4 introduces quality-of-life improvements for SQL cells, a revamped folder import workflow, support for Polars DataFrames, and more. Datalore Cloud customers have already received the new update automatically, and Datalore On-Premises customers can upgrade by following these instructions. Limit 500 toggle for SQL cells To help you prototype SQL queries faster, we&#8217;ve introduced a [&#8230;]",
        "contentSnippet": "Datalore 2024.4 introduces quality-of-life improvements for SQL cells, a revamped folder import workflow, support for Polars DataFrames, and more. Datalore Cloud customers have already received the new update automatically, and Datalore On-Premises customers can upgrade by following these instructions. Limit 500 toggle for SQL cells To help you prototype SQL queries faster, we’ve introduced a […]",
        "guid": "https://blog.jetbrains.com/?post_type=datalore&p=504871",
        "categories": [
          "releases"
        ],
        "isoDate": "2024-08-22T10:07:56.000Z"
      },
      {
        "creator": "Khalid Abuhakmeh",
        "title": "ReSharper Tips & Tricks with Matt Ellis – Livestream",
        "link": "https://blog.jetbrains.com/dotnet/2024/08/21/resharper-tips-tricks-with-matt-ellis-livestream/",
        "pubDate": "Wed, 21 Aug 2024 13:58:37 +0000",
        "content:encodedSnippet": "Join us on September 12, 2024, at 2:00 PM UTC for another JetBrains livestream event. You can register for the event using the link below or subscribe to our YouTube channel, JetBrainsTV, to get a notification closer to the event.\nRegister\n                                \nfor the livestream\n\n\n\n\nWith over 20 years of ReSharper setting the standard for the .NET development experience, it’s time for .NET developers, new and accomplished, to see what the #1 productivity extension for Visual Studio has to offer. In this livestream, we’ll be joined by JetBrains Developer Advocate Matt Ellis, who will highlight some of his best tips and tricks to get the most productivity gains in your .NET workflows. Discover what you’ve been missing with ReSharper.\nMatt Ellis – Developer Advocate Game Development, JetBrains\nMatt Ellis is a developer advocate at JetBrains, working with lots of different IDEs and technologies such as the Unity and Unreal Engine game development tools in Rider, Code With Me for collaborative editing and remote development with JetBrains Gateway. He has spent (well) over 20 years shipping software in various industries, and thoroughly enjoys working with IDEs and development tools, having fun with syntax trees and source code analysis. He also helps build the Unity support in Rider, and contributes to the popular IdeaVim plugin.",
        "dc:creator": "Khalid Abuhakmeh",
        "content": "Join us on September 12, 2024, at 2:00 PM UTC for another JetBrains livestream event. You can register for the event using the link below or subscribe to our YouTube channel, JetBrainsTV, to get a notification closer to the event. With over 20 years of ReSharper setting the standard for the .NET development experience, it&#8217;s [&#8230;]",
        "contentSnippet": "Join us on September 12, 2024, at 2:00 PM UTC for another JetBrains livestream event. You can register for the event using the link below or subscribe to our YouTube channel, JetBrainsTV, to get a notification closer to the event. With over 20 years of ReSharper setting the standard for the .NET development experience, it’s […]",
        "guid": "https://blog.jetbrains.com/?post_type=dotnet&p=503092",
        "categories": [
          "net-tools",
          "c",
          "resharper",
          "visual-studio"
        ],
        "isoDate": "2024-08-21T13:58:37.000Z"
      },
      {
        "creator": "Evgenia Verbina",
        "title": "How to Build Chatbots With LangChain",
        "link": "https://blog.jetbrains.com/pycharm/2024/08/how-to-build-chatbots-with-langchain/",
        "pubDate": "Wed, 21 Aug 2024 10:06:08 +0000",
        "content:encodedSnippet": "This is a guest post from Dido Grigorov, a deep learning engineer and Python programmer with 17 years of experience in the field.\n\n\n\n\nChatbots have evolved far beyond simple question-and-answer tools. With the power of large language models (LLMs), they can understand the context of conversations and generate human-like responses, making them invaluable for customer support applications and other types of virtual assistance. \nLangChain, an open-source framework, streamlines the process of building these conversational chatbots by providing tools for seamless model integration, context management, and prompt engineering.\nIn this blog post, we’ll explore how LangChain works and how chatbots interact with LLMs. We’ll also guide you step by step through building a context-aware chatbot that delivers accurate, relevant responses using LangChain and GPT-3.\n\n\n\n\nWhat are the chatbots in the realm of LLMs?\nChatbots in the field of LLMs are cutting-edge software that simulate human-like conversations with users through text or voice interfaces. These chatbots exploit the advanced capabilities of LLMs, which are neural networks trained on huge amounts of text data which allows them to produce human-like responses to a wide range of input prompts.\nOne among all other matters is that LLM-based chatbots can take a conversation’s context into account when generating a response. This means they can keep coherence across several exchanges and can process complex queries to produce outputs that are in line with the users’ intentions. Additionally, these chatbots assess the emotional tone of a user’s input and adjust their responses to match the user’s sentiments.\nChatbots are highly adaptable and personalized. They learn from how users interact with them thus improving on their responses by adjusting them according to individual preferences and needs. \nWhat is LangChain?\nLangChain is a framework that’s open-source developed for creating apps that use large language models (LLMs). It comes with tools and abstractions to better personalize the information produced from these models while maintaining accuracy and relevance. \nOne common term you can see when you read about LLMs is “prompt chains”. A prompt chain refers to a sequence of prompts or instructions used in the context of artificial intelligence and machine learning, with the purpose to guide the AI model through a multi-step process to generate more accurate, detailed, or refined outputs. This method can be employed for various tasks, such as writing, problem-solving, or generating code. \nDevelopers can create new prompt chains using LangChain, which is one of the strongest sides of the framework. They can even modify existing prompt templates without needing to train the model again when using new datasets.\nHow does LangChain work?\nLangChain is a framework designed to simplify the development of applications that utilize language models. It offers a suite of tools that help developers efficiently build and manage applications that involve natural language processing (NLP) and Large Language Models. By defining the steps needed to achieve the desired outcome (this might be a chatbot, task automation, virtual assistant, customer support, and even more), developers can adapt language models flexibly to specific business contexts using LangChain. \nHere’s a high-level overview of how LangChain works.\nModel integration\nLangChain supports various Language models including those from OpenAI, Hugging Face, Cohere, Anyscale, Azure Models, Databricks, Ollama, Llama, GPT4All, Spacy, Pinecone, AWS Bedrock, MistralAI, among others. Developers can easily switch between different models or use multiple models in one application. They can build custom-developed model integration solutions, which allow developers to take advantage of specific capabilities tailored to their specific applications.\nChains\nThe core concept of LangChain is chains, which bring together different AI components for context-aware responses. A chain represents a set of automated actions between a user prompt and the final model output. There are two types of chains provided by LangChain:\nSequential chains: These chains enable the output of a model or function to be used as an input for another one. This is particularly helpful in making multi-step processes that depend on each other.\nParallel chains: It allows for simultaneous running of multiple tasks, with their outputs merged at the end. This makes it perfect for doing tasks that can be divided into subtasks that are completely independent.\nMemory\nLangChain facilitates the storage and retrieval of information across various interactions. This is essential where there is need for persistence of context such as with chat-bots or interactive agents. There are also two types of memory provided:\nShort-term memory – Helps keep track of recent sessions.\nLong-term memory – Allows retention of information from previous sessions enhancing system recall capability on past chats and user preferences.\nTools and utilities\nLangChain provides many tools, but the most used ones are Prompt Engineering, Data Loaders and Evaluators.  When it comes to Prompt Engineering, LangChain contains utilities to develop good prompts, which are very important in getting the best responses from language models.\nIf you want to load up files like csv, pdf or other format, Data Loaders are here to help you to load and pre-process different types of data hence making them usable in model interactions.\nEvaluation is an essential part of working with machine learning models and large language models. That’s why LangChain provides Evaluators – tools used for testing language models and chains so that generated results meet the required criteria, which might include:\nDatasets criteria:\nManually curated examples: Start with high-quality, diverse inputs.\nHistorical logs: Use real user data and feedback.\nSynthetic data: Generate examples based on initial data.\nTypes of evaluations:\nHuman: Manual scoring and feedback.\nHeuristic: Rule-based functions, both reference-free and reference-based.\nLLM-as-judge: LLMs score outputs based on encoded criteria.\nPairwise: Compare two outputs to pick the better one.\nApplication evaluations:\nUnit tests: Quick, heuristic-based checks.\nRegression testing: Measure performance changes over time.\nBack-testing: Re-run production data on new versions.\nOnline evaluation: Evaluate in real-time, often for guardrails and classifications.\nAgents\nLangChain agents are essentially autonomous entities that leverage LLMs to interact with users, perform tasks, and make decisions based on natural language inputs.\nAction-driven agents use language models to decide on optimal actions for predefined tasks. On the other side interactive agents or interactive applications such as chatbots make use of these agents, which also take into account user input and stored memory when responding to queries.\nHow do chatbots work with LLMs?\nLLMs underlying chatbots use Natural Language Understanding (NLU) and Natural Language Generation (NLG), which are made possible through pre-training of models on vast textual data.\nNatural Language Understanding (NLU)\nContext awareness: LLMs can understand the subtlety and allusions in a conversation, and they can keep track of the conversation from one turn to the next. This makes it possible for the chatbots to generate logical and contextually appropriate responses to the clients.\nIntent recognition: These models should be capable of understanding the user’s intent from their queries, whether the language is very specific or quite general. They can discern what the user wants to achieve and determine the best way to help them reach that goal.\nSentiment analysis: Chatbots can determine the emotion of the user through the tone of language used and adapt to the user’s emotional state, which increases the engagement of the user.\nNatural Language Generation (NLG)\nResponse generation: When LLMs are asked questions, the responses they provide are correct both in terms of grammar and the context. This is because the responses that are produced by these models mimic human communication, due to the training of the models on vast amounts of natural language textual data.\nCreativity and flexibility: Apart from simple answers, LLM-based chatbots can tell a story, create a poem, or provide a detailed description of a specific technical issue and, therefore, can be considered to be very flexible in terms of the provided material.\nPersonalization and adaptability\nLearning from interactions: Chatbots make the interaction personalized because they have the ability to learn from the users’ behavior, as well as from their choices. It can be said that it is constantly learning, thereby making the chatbot more effective and precise in answering questions.\nAdaptation to different domains: The LLMs can be tuned to particular areas or specialties that allow the chatbots to perform as subject matter experts in customer relations, technical support, or the healthcare domain.\nLLMs are capable of understanding and generating text in multiple languages, making them suitable for applications in diverse linguistic contexts.\nBuilding your own chatbot with LangChain in five steps\nThis project aims to build a chatbot that leverages GPT-3 to search for answers within documents. First, we scrape content from online articles, split them into small chunks, compute their embeddings, and store them in Deep Lake. Then, we use a user query to retrieve the most relevant chunks from Deep Lake, which are incorporated into a prompt for generating the final answer with the LLM.\nIt’s important to note that using LLMs carries a risk of generating hallucinations or false information. While this may be unacceptable for many customer support scenarios, the chatbot can still be valuable for assisting operators in drafting answers that they can verify before sending to users.\nNext, we’ll explore how to manage conversations with GPT-3 and provide examples to demonstrate the effectiveness of this workflow\nStep 1: Project creation, prerequisites, and required library installation\nFirst create your PyCharm project for the chatbot. Open up Pycharm and click on “new project”. Then give a name of your project.\n\n\n\n\nOnce ready with the project set up, generate your `OPENAI_API_KEY` on the OpenAI API Platform Website, once you are logged in (or sign up on the OpenAI website for that purpose). To do that go to the “API Keys” section on the left navigation menu and then click on the button “+Create new secret key”. Don’t forget to copy your key.\nAfter that get your `ACTIVELOOP_TOKEN` by signing up on the Activeloop website. Once logged in, just click on the button “Create API Token” and you’ll be navigated to the token creation page. Copy this token as well.\nOnce you have both the token and the key, open your configuration settings in PyCharm, by clicking on the 3 dots button next to the run and debug buttons, and choose “Edit”. You should see the following window:\n\n\n\n\nNow locate the field “Environment variables” and find the icon on the right side of the field. Then click there – you’ll see the following window:\n\n\n\n\nAnd now by clicking the + button start adding your environmental variables and be careful with their names. They should be the same as mentioned above: `OPENAI_API_KEY` and `ACTIVELOOP_TOKEN`. When ready just click OK on the first window and then “Apply” and “OK” on the second one.\nThat’s a very big advantage of PyCharm and I very much love it, because it handles the environment variables for us automatically without the requirement for additional calls to them, allowing us to think more about the creative part of the code.\nNote: ActiveLoop is a technology company that focuses on developing data infrastructure and tools for machine learning and artificial intelligence. The company aims to streamline the process of managing, storing, and processing large-scale datasets, particularly for deep learning and other AI applications.\nDeepLake is an ActiveLoop’s flagship product. It provides efficient data storage, management, and access capabilities, optimized for large-scale datasets often used in AI.\nInstall the required libraries\nWe’ll use the `SeleniumURLLoader` class from LangChain, which relies on the `unstructured` and `selenium` Python libraries. Install these using pip.  It is recommended to install the latest version, although the code has been specifically tested with version 0.7.7. \nTo do that use the following command in your PyCharm terminal:\npip install unstructured selenium\n\n\n\n\nNow we need to install langchain, deeplake and openai. To do that just use this command in your terminal (same window you used for Selenium) and wait a bit until everything is successfully installed:\npip install langchain==0.0.208 deeplake openai==0.27.8 psutil tiktoken\nTo make sure all libraries are properly installed, just add the following lines needed for our chatbot app and click on the Run button:\nfrom langchain.embeddings.openai import OpenAIEmbeddings\n\nfrom langchain.vectorstores import DeepLake\n\nfrom langchain.text_splitter import CharacterTextSplitter\n\nfrom langchain import OpenAI\n\nfrom langchain.document_loaders import SeleniumURLLoader\n\nfrom langchain import PromptTemplate\nAnother way to install your libraries is through the settings of PyCharm. Open them and go to the section Project -> Project Interpreter. Then locate the + button, search for your package and hit the button “Install Package”. Once ready, close it, and on the next window click “Apply” and then “OK”.\n\n\n\n\nStep 2: Splitting content into chunks and computing their embeddings\nAs previously mentioned, our chatbot will “communicate” with content coming out of online articles, that’s why I picked Digitaltrends.com as my source of data and selected 8 articles to start. All of them are organized into a Python list and assigned to a variable called “articles”.\narticles = ['https://www.digitaltrends.com/computing/claude-sonnet-vs-gpt-4o-comparison/',\n           'https://www.digitaltrends.com/computing/apple-intelligence-proves-that-macbooks-need-something-more/',\n           'https://www.digitaltrends.com/computing/how-to-use-openai-chatgpt-text-generation-chatbot/',\n           'https://www.digitaltrends.com/computing/character-ai-how-to-use/',\n           'https://www.digitaltrends.com/computing/how-to-upload-pdf-to-chatgpt/']\nWe load the documents from the provided URLs and split them into chunks using the `CharacterTextSplitter` with a chunk size of 1000 and no overlap:\n# Use the selenium to load the documents\nloader = SeleniumURLLoader(urls=articles)\ndocs_not_splitted = loader.load()\n\n# Split the documents into smaller chunks\ntext_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\ndocs = text_splitter.split_documents(docs_not_splitted)\nIf you run the code till now you should receive the following output, if everything works well:\n[Document(page_content=\"techcrunch\\n\\ntechcrunch\\n\\nWe, TechCrunch, are part of the Yahoo family of brandsThe sites and apps that we own and operate, including Yahoo and AOL, and our digital advertising service, Yahoo Advertising.Yahoo family of brands.\\n\\n    When you use our sites and apps, we use \\n\\nCookiesCookies (including similar technologies such as web storage) allow the operators of websites and apps to store and read information from your device. Learn more in our cookie policy.cookies to:\\n\\nprovide our sites and apps to you\\n\\nauthenticate users, apply security measures, and prevent spam and abuse, and\\n\\nmeasure your use of our sites and apps\\n\\n    If you click '\", metadata={'source': ……………]\nNext, we generate the embeddings using OpenAIEmbeddings and save them in a DeepLake vector store hosted in the cloud. Ideally, in a production environment, we could upload an entire website or course lesson to a DeepLake dataset, enabling searches across thousands or even millions of documents. \nBy leveraging a serverless Deep Lake dataset in the cloud, applications from various locations can seamlessly access a centralized dataset without the necessity of setting up a vector store on a dedicated machine.\nWhy do we need embeddings and documents in chunks?\nWhen building chatbots with Langchain, embeddings and chunking documents are essential for several reasons that relate to the efficiency, accuracy, and performance of the chatbot.\nEmbeddings are vector representations of text (words, sentences, paragraphs, or documents) that capture semantic meaning. They encapsulate the context and meaning of words in a numerical form. This allows the chatbot to understand and generate responses that are contextually appropriate by capturing nuances, synonyms, and relationships between words.\nThanks to the embeddings, the chatbot can also quickly identify and retrieve the most relevant responses or information from a knowledge base, because they allow matching user queries with the most semantically relevant chunks of information, even if the wording differs.\nChunking, on the other side, involves dividing large documents into smaller, manageable pieces or chunks. Smaller chunks are faster to process and analyze compared to large, monolithic documents. This results in quicker response times from the chatbot.\nDocument chunking helps also with the relevancy of the output, because when a user asks a question, it is often only in a specific part of a document. Chunking allows the system to pinpoint and retrieve just the relevant sections and the chatbot can provide more precise and accurate answers.\nNow let’s get back to our application and let’s update the following code by including your Activeloop organization ID. Keep in mind that, by default, your organization ID is the same as your username.\n# TODO: use your organization id here. (by default, org id is your username)\nmy_activeloop_org_id = \"didogrigorov\"\nmy_activeloop_dataset_name = \"jetbrains_article_dataset\"\ndataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\ndb = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)\n\n\n# add documents to our Deep Lake dataset\ndb.add_documents(docs)\nAnother great feature of PyCharm I love is the option TODO notes to be added directly in Python comments. Once you type TODO with capital letters, all notes go to a section of PyCharm where you can see them all:\n# TODO: use your organization id here. (by default, org id is your username)\nYou can click on them and PyCharm directly shows you where they are in your code. I find it very convenient for developers and use it all the time:\n\n\n\n\nIf you execute the code till now you should see the following output, if everything works normal:\n\n\n\n\nTo find the most similar chunks to a given query, we can utilize the similarity_search method provided by the Deep Lake vector store:\n# Check the top relevant documents to a specific query\nquery = \"how to check disk usage in linux?\"\ndocs = db.similarity_search(query)\nprint(docs[0].page_content)\nStep 3: Let’s build the prompt for GPT-3\nWe will design a prompt template that integrates role-prompting, pertinent Knowledge Base data, and the user’s inquiry. This template establishes the chatbot’s persona as an outstanding customer support agent. It accepts two input variables: chunks_formatted, containing the pre-formatted excerpts from articles, and query, representing the customer’s question. The goal is to produce a precise response solely based on the given chunks, avoiding any fabricated or incorrect information.\nStep 4: Building the chatbot functionality\nTo generate a response, we begin by retrieving the top-k (e.g., top-3) chunks that are most similar to the user’s query. These chunks are then formatted into a prompt, which is sent to the GPT-3 model with a temperature setting of 0.\n# user question\nquery = \"How to check disk usage in linux?\"\n\n# retrieve relevant chunks\ndocs = db.similarity_search(query)\nretrieved_chunks = [doc.page_content for doc in docs]\n\n# format the prompt\nchunks_formatted = \"\\n\\n\".join(retrieved_chunks)\nprompt_formatted = prompt.format(chunks_formatted=chunks_formatted, query=query)\n\n# generate answer\nllm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0)\nanswer = llm(prompt_formatted)\nprint(answer)\nIf everything works fine, your output should be:\nTo upload a PDF to ChatGPT, first log into the website and click the paperclip icon next to the text input field. Then, select the PDF from your local hard drive, Google Drive, or Microsoft OneDrive. Once attached, type your query or question into the prompt field and click the upload button. Give the system time to analyze the PDF and provide you with a response.\nStep 5: Build conversational history\n# Create conversational memory\nmemory = ConversationBufferMemory(memory_key=\"chat_history\", input_key=\"input\")\n\n# Define a prompt template that includes memory\ntemplate = \"\"\"You are an exceptional customer support chatbot that gently answers questions.\n\n{chat_history}\n\nYou know the following context information.\n\n{chunks_formatted}\n\nAnswer the following question from a customer. Use only information from the previous context information. Do not invent stuff.\n\nQuestion: {input}\n\nAnswer:\"\"\"\n\nprompt = PromptTemplate(\n    input_variables=[\"chat_history\", \"chunks_formatted\", \"input\"],\n    template=template,\n)\n\n# Initialize the OpenAI model\nllm = OpenAI(openai_api_key=\"YOUR API KEY\", model=\"gpt-3.5-turbo-instruct\", temperature=0)\n\n# Create the LLMChain with memory\nchain = LLMChain(\n    llm=llm,\n    prompt=prompt,\n    memory=memory\n)\n\n# User query\nquery = \"What was the 5th point about on the question how to remove spotify account?\"\n\n# Retrieve relevant chunks\ndocs = db.similarity_search(query)\nretrieved_chunks = [doc.page_content for doc in docs]\n\n# Format the chunks for the prompt\nchunks_formatted = \"\\n\\n\".join(retrieved_chunks)\n\n# Prepare the input for the chain\ninput_data = {\n    \"input\": query,\n    \"chunks_formatted\": chunks_formatted,\n    \"chat_history\": memory.buffer\n}\n\n# Simulate a conversation\nresponse = chain.predict(**input_data)\n\nprint(response)\nLet’s walk through the code in a more conversational manner.\nTo start with, we set up a conversational memory using `ConversationBufferMemory`. This allows our chatbot to remember the ongoing chat history, using `input_key=”input”` to manage the incoming user inputs.\nNext, we design a prompt template. This template is like a script for the chatbot, including sections for chat history, the chunks of information we’ve gathered, and the current user question (input). This structure helps the chatbot know exactly what context it has and what question it needs to answer.\nThen, we move on to initializing our language model chain, or `LLMChain`. Think of this as assembling the components: we take our prompt template, the language model, and the memory we set up earlier, and combine them into a single workflow.\nWhen it’s time to handle a user query, we prepare the input. This involves creating a dictionary that includes the user’s question (`input`) and the relevant information chunks (`chunks_formatted`). This setup ensures that the chatbot has all the details it needs to craft a well-informed response.\nFinally, we generate a response. We call the `chain.predict` method, passing in our prepared input data. The method processes this input through the workflow we’ve built, and out comes the chatbot’s answer, which we then display.\nThis approach allows our chatbot to maintain a smooth, informed conversation, remembering past interactions and providing relevant answers based on the context.\nAnother favorite trick with PyCharm that helped me a lot to build this functionality was the opportunity to put my cursor over a method, to hit the key “CTRL” and click on it.\nIn conclusion\nGPT-3 excels at creating conversational chatbots capable of answering specific questions based on contextual information provided in the prompt. However, ensuring the model generates answers solely based on this context can be challenging, as it often tends to hallucinate (i.e., generate new, potentially false information). The impact of such false information varies depending on the use case.\nIn summary, we developed a context-aware question-answering system using LangChain, following the provided code and strategies. The process included splitting documents into chunks, computing their embeddings, implementing a retriever to find similar chunks, crafting a prompt for GPT-3, and using the GPT-3 model for text generation. This approach showcases the potential of leveraging GPT-3 to create powerful and contextually accurate chatbots while also emphasizing the importance of being vigilant about the risk of generating false information.\nAbout the author\nDido Grigorov\nDido is a seasoned Deep Learning Engineer and Python programmer with an impressive 17 years of experience in the field. He is currently pursuing advanced studies at the prestigious Stanford University, where he is enrolled in a cutting-edge AI program, led by renowned experts such as Andrew Ng, Christopher Manning, Fei-Fei Li and Chelsea Finn, providing Dido with unparalleled insights and mentorship.\nDido’s passion for Artificial Intelligence is evident in his dedication to both work and experimentation. Over the years, he has developed a deep expertise in designing, implementing, and optimizing machine learning models. His proficiency in Python has enabled him to tackle complex problems and contribute to innovative AI solutions across various domains.",
        "dc:creator": "Evgenia Verbina",
        "content": "This is a guest post from Dido Grigorov, a deep learning engineer and Python programmer with 17 years of experience in the field. Chatbots have evolved far beyond simple question-and-answer tools. With the power of large language models (LLMs), they can understand the context of conversations and generate human-like responses, making them invaluable for customer [&#8230;]",
        "contentSnippet": "This is a guest post from Dido Grigorov, a deep learning engineer and Python programmer with 17 years of experience in the field. Chatbots have evolved far beyond simple question-and-answer tools. With the power of large language models (LLMs), they can understand the context of conversations and generate human-like responses, making them invaluable for customer […]",
        "guid": "https://blog.jetbrains.com/?post_type=pycharm&p=503887",
        "categories": [
          "data-science",
          "how-tos",
          "chatbots",
          "langchain",
          "llms"
        ],
        "isoDate": "2024-08-21T10:06:08.000Z"
      },
      {
        "creator": "Daniela Bentrup",
        "title": "Fleet 1.39 Is Out With Smart Mode for Single Files, the Ability to Compare Files, the Structure Tool Window, Automatic Language Detection for Untitled Files, and Other Enhancements",
        "link": "https://blog.jetbrains.com/fleet/2024/08/fleet-1-39-is-out-with-smart-mode-for-single-files-the-ability-to-compare-files-the-structure-tool-window-automatic-language-detection-for-untitled-files-and-other-enhancements/",
        "pubDate": "Tue, 20 Aug 2024 14:59:18 +0000",
        "content:encodedSnippet": "Fleet 1.39 is now available! Explore our latest release, which introduces many new features designed to improve your development experience. You can update to this version using the Toolbox App.\nLet’s take a closer look at the highlights.\nDownload Fleet 1.39\nNew features\nYou can now open a file and use Smart Mode without having to open a folder. This feature is currently supported for most languages that use the IntelliJ backend, including but not limited to Java, Kotlin, TypeScript, JavaScript, PHP, Python, and Go. It is also available for C+⁠⁠⁠+.\nIn version 1.39, we’ve implemented a file comparison feature. Go to Git | Current File and select Compare with Branch or Compare with Commit to review differences between files and directories.\nThe new Structure tool window offers a dedicated interface for viewing and navigating the structure of a file, which can be more convenient than using the Structure popup when working with large files. To open it, go to View | Symbols or use the Actions shortcut (⇧⌘K / Ctrl+Shift+K) and select Jump to Symbols Tool.\n\n\n\n\n\nWe’ve added an inlay hint for generating documentation. Just type /** and press Enter to bring up the Generate Documentation option, and then press ⌥↵ / Alt+Enter to show the tooltip. Inlay hints are currently supported for Java, Kotlin, and JavaScript. This feature will also be made available for PHP, Groovy, and Swift in later versions.\n\n\n\n\n\nFleet 1.39 offers automatic language detection for untitled files. Just add your code to a scratch file, and Fleet will detect the language you are coding in. Untitled files won’t be saved automatically.\n\n\n\n\n\nWe’ve added highlighting to the gray-text code completion. This feature can be enabled or disabled by going to Settings | Code and clicking the Enable AI code completion and Enable syntax highlighting in AI code completion checkboxes.\n\n\n\n\n\nFleet 1.39 offers faster, more accurate code completion suggestions for Kotlin, Python, and Java.\nYou can now pipe standard output (stdout) into Fleet by using the | fleet - syntax, for example: \ndir | fleet - \n./test_script.sh | fleet - \nGet-Process | Select-Object -First 5 | fleet -  \nFleet will then open a new scratch file with an automatically generated file name.\nA highly requested feature in Fleet 1.39 enhances its usability as a quick and effective ad hoc editor. In the terminal, you can now use Fleet by calling fleet --wait, which keeps the command line active until the edited file is closed. It also returns a non-zero exit code if file opening or editing fails. This feature brings Fleet one step closer to supporting the EDITOR environment variable in the terminal, expanding its versatility and functionality in various workflows, including as a Git commit editor.\n\n\n\n\n\n\nWe’ve added two ways of specifying a file with environment variables. Each config in run.json can now specify the environmentFile. Furthermore, on each settings level, it’s possible to specify the run.environmentFile. If such a file is given, the variables are loaded from it and passed to the run config(s).\nBeginning with version 1.38.89, Fleet supports custom theme plugins. Now you can control the appearance of built-in UI elements and publish your own theme plugins to JetBrains Marketplace. The customization options include the ability to change the colors of UI controls and provide custom editor schemes. Learn more about how to create your own themes in this tutorial.\nImprovements\nWith Fleet 1.39, config files and themes are no longer stored in the home directory.\nThe plugin documentation has received a major update, including a detailed tutorial about building a theme plugin in Fleet.\nYou can now open files directly in other applications. Just right-click on the file and click on Open In.\n\n\n\nBug fixes\nWe’ve also fixed several bugs:\nImages are now shown in their original size in the editor [FL-11201].\nClicking Configure Docker now navigates you to the Docker section in the settings when a workspace settings tab is open [FL-19807].\nThe value of the counter in the Search tab no longer changes after you click on a file [FL-25443].\nSee the full release notes for more details about Fleet 1.39\nPlease report any problems you encounter to our issue tracker, and stay tuned for further exciting announcements.\nSupport for plugins and plugin APIs is a work in progress, but the list of bundled plugins is now available and visible to everyone. To view it, select Plugins from the Actions menu. \nJoin the JetBrains Tech Insights Lab to participate in surveys, interviews, and UX studies, and help us make JetBrains Fleet better!",
        "dc:creator": "Daniela Bentrup",
        "content": "Fleet 1.39 is now available! Explore our latest release, which introduces many new features designed to improve your development experience. You can update to this version using the Toolbox App. Let’s take a closer look at the highlights. Download Fleet 1.39 New features Improvements Bug fixes We&#8217;ve also fixed several bugs: See the full release [&#8230;]",
        "contentSnippet": "Fleet 1.39 is now available! Explore our latest release, which introduces many new features designed to improve your development experience. You can update to this version using the Toolbox App. Let’s take a closer look at the highlights. Download Fleet 1.39 New features Improvements Bug fixes We’ve also fixed several bugs: See the full release […]",
        "guid": "https://blog.jetbrains.com/?post_type=fleet&p=503559",
        "categories": [
          "news",
          "releases"
        ],
        "isoDate": "2024-08-20T14:59:18.000Z"
      },
      {
        "creator": "Alena Guzharina",
        "title": "New Datalore Cloud Plans – What You Need to Know",
        "link": "https://blog.jetbrains.com/datalore/2024/08/20/new-datalore-cloud-plans-what-you-need-to-know/",
        "pubDate": "Tue, 20 Aug 2024 13:10:45 +0000",
        "content:encodedSnippet": "As Datalore has evolved over the years, we’ve added more and more pricing tiers to cater to different users in the cloud. The variety of tiers sometimes made choosing a plan complicated. Now, we’ve decided to revamp our subscription plans to simplify the process of finding the option that best fits your needs. You no longer have to worry about juggling between Team, Professional, and Community plans; we now present a unified and powerful solution for all cloud users: Datalore Cloud.\nRead on to learn more, and check out the new pricing plan comparison table below. \n      \n      Explore the new plans\n    \n\n\n\n\nDatalore Cloud: One plan for all\nWhether you’re an individual data scientist, a small startup, or a large corporation, Datalore Cloud is designed to cater to your needs. This comprehensive plan includes robust team management functionalities, ensuring seamless collaboration and efficiency. If you need a limited set of features, you can still enjoy Datalore on the Cloud Free tier. \n\n\n\n\nNew features for Datalore Cloud users\nIn line with many requests from our customers, Datalore Cloud offers a powerful CPU L machine, featuring 4 virtual CPUs (vCPUs) and 16 GB RAM. This machine is optimized to handle most of your daily tasks with ease and is included in your subscription.\nMoreover, we’ve updated our computation options to include the latest and most powerful machines. You can explore detailed specifications and pricing in our documentation.\nTransition details for existing users\nFor Team plan users:\nYour team will now enjoy the upgraded CPU L machines, and you’ll receive six Datalore credits per month for each member.\nThe transition to the Cloud plan has happened automatically, so no action is needed from your side. Rest assured, the price remains the same!\n\n\n\n\nFor Professional plan users:\nYou can continue with your existing plan under the same terms and conditions.\nHowever, you have the option to upgrade to the new Cloud plan, which includes the powerful CPU L machines and team-management features.\n\n\n\n\nPlease note that the Professional plan has been archived and is no longer available for new users.\nFor Community plan users:\nUpon your next login, your Community plan will be upgraded to a 14-day Cloud trial at no additional cost.\nAfter the trial, if you choose not to subscribe to the Cloud plan, you will transition to Cloud Free, our new free plan offering similar functionality to the old Community plan.\n\n\n\n\nFor Enterprise plan users:\nDatalore Enterprise has been renamed to Datalore On-Premises. Other changes outlined above do not affect you.\n\n\n\n\nIf you have any questions or require assistance, please don’t hesitate to contact Datalore Support.\nBest regards,\nThe Datalore team",
        "dc:creator": "Alena Guzharina",
        "content": "As Datalore has evolved over the years, we’ve added more and more pricing tiers to cater to different users in the cloud. The variety of tiers sometimes made choosing a plan complicated. Now, we&#8217;ve decided to revamp our subscription plans to simplify the process of finding the option that best fits your needs. You no [&#8230;]",
        "contentSnippet": "As Datalore has evolved over the years, we’ve added more and more pricing tiers to cater to different users in the cloud. The variety of tiers sometimes made choosing a plan complicated. Now, we’ve decided to revamp our subscription plans to simplify the process of finding the option that best fits your needs. You no […]",
        "guid": "https://blog.jetbrains.com/?post_type=datalore&p=504334",
        "categories": [
          "news"
        ],
        "isoDate": "2024-08-20T13:10:45.000Z"
      },
      {
        "creator": "Olga Bedrina",
        "title": "What We Learned From the Perforce 2024 State of Game Technology Report",
        "link": "https://blog.jetbrains.com/teamcity/2024/08/perforce-2024-game-tech-report/",
        "pubDate": "Tue, 20 Aug 2024 11:44:43 +0000",
        "content:encodedSnippet": "The gaming industry has long been a hotbed of innovation, with developers consistently pushing the boundaries of what’s possible. But as we progress into 2024, it’s clear that game technology’s sphere of influence is expanding far beyond the realm of gaming. \nTechnological advancements coming out of the game industry are quickly adopted by various other industries, from automotive to healthcare to education, as identified by Perforce’s 2024 State of Game Technology.\nIn this blog post, we’ll take a closer look at the report’s key findings and the trends that are shaping the future of game technology. We’ll also highlight some of the findings we found the most interesting. \nYou can download the full report via the link below to get more information on the challenges the game industry is facing, the latest AI trends, the current state of the job market, and predictions for the future of the industry.\nDownload your report copy here\nKey findings and trends\nWidespread adoption across industries sphere\nThe most striking trend in this year’s report is the widespread adoption of game technology across multiple sectors. Traditionally confined to gaming, tools like game engines are now being embraced by industries including media, automotive, and healthcare. \nThe report reveals that 50% of respondents are now using game engines outside of gaming, marking a significant shift in how these tools are perceived and utilized.\nThe main reason behind this trend is the growing complexity of projects. Projects are becoming more complex as the demand for high-quality, immersive experiences grows.\nEconomic uncertainty has added to this challenge, forcing teams to handle changing consumer demands, higher costs, and the pressure to deliver realistic visuals. The report highlights just how difficult it is to manage such large projects, especially with limited resources and teams distributed across different locations.\nCollaboration challenges\nDespite promising technological advancements in technology, collaboration remains a significant hurdle. The report identifies moving large files as the main barrier to effective teamwork, a challenge exacerbated by the growing size of digital assets.\nSource: Perforce 2024 State of Game Technology Report\n\n\n\nWhile issues surrounding remote work have become more manageable, other collaboration issues, such as inefficient communication and feedback loops, continue to impede progress.\nUnsurprisingly, smaller studios and AAA studios face different challenges. Large and AAA studios primarily struggle with collaboration issues and finding time dedicated to innovation. On the other hand, small studios find funding to be their biggest hurdle, far outweighing other concerns.\nSource: Perforce 2024 State of Game Technology Report\nConsolidation of toolsets\nEfficiency is becoming more critical as organizations look to streamline their processes. Instead of adopting a wide array of tools, teams are focusing on consolidating their technology stacks. Game engines are particularly valued for their versatility, with applications ranging from digital twins in manufacturing to immersive educational tools.\nCross-industry trends in game development\nThe cross-industry trends regarding game technology, as highlighted in the report, include several key insights.\nAdoption of game engines \nUnreal Engine is by far the most utilized game engine industry-wide, with 63% of respondents using it. The engine is especially favored in media and entertainment due to its robust tools for creating 3D worlds and its flexibility in various production roles​.\nJust as AAA and indie studios face different challenges, they also prefer using different game engines. Thus, AAA developers often use proprietary game engines but predominantly rely on Unreal Engine, which is nearly twice as popular as Unity. \nIn contrast, indie studios use Unreal Engine and Unity at more similar rates, with Godot gaining popularity as an alternative.\nSource: Perforce 2024 State of Game Technology Report\nUsage of Perforce Helix Core\nThe report revealed that a significant majority of respondents (54%) incorporate Git-based version control tools like GitHub, GitLab, BitBucket, or Azure DevOps into their workflows. Similarly, over half of the respondents reported using Perforce Helix Core as part of their version control processes.\nOther tools used widely in the industry\nIn addition to game engines and version control systems, game developers continue to rely on other technologies and tools to help them create top-notch experiences for their users.\nIDEs\nAs revealed by the report, the majority of respondents use Microsoft Visual Studio within their development process. However, more than a third of respondents (34% among AAA studios and 46% among indie studios) also reported using JetBrains Rider as their IDE of choice. This could be attributed to Rider’s seamless integration with game engines (Unreal Engine, Unity, and Godot).\nCI/CD tools\nThe report revealed a great variety of CI/CD tools used by AAA studios and indie studios alike. Among AAA studios, Jenkins (41%) and TeamCity (23%) stand out as the most widely used CI/CD tools.\nSource: Perforce 2024 State of Game Technology Report\nTeamCity is a powerful CI/CD tool that seamlessly integrates with Unreal Engine, Unity, and Perforce and is widely used by AAA and indie game studios. If you’d like to learn more about TeamCity, feel free to schedule a call with our solutions engineer.\nConclusion\nThe 2024 State of Game Technology Report paints a vivid picture of an industry at a crossroads. As game technology continues to break into new sectors, the challenges of complexity, collaboration, and innovation must be addressed to fully realize its potential. \nThe key for organizations across all industries will be to harness the right tools and strategies to stay competitive in an increasingly dynamic landscape.",
        "dc:creator": "Olga Bedrina",
        "content": "The gaming industry has long been a hotbed of innovation, with developers consistently pushing the boundaries of what’s possible. But as we progress into 2024, it’s clear that game technology’s sphere of influence is expanding far beyond the realm of gaming.&#160; Technological advancements coming out of the game industry are quickly adopted by various other [&#8230;]",
        "contentSnippet": "The gaming industry has long been a hotbed of innovation, with developers consistently pushing the boundaries of what’s possible. But as we progress into 2024, it’s clear that game technology’s sphere of influence is expanding far beyond the realm of gaming.  Technological advancements coming out of the game industry are quickly adopted by various other […]",
        "guid": "https://blog.jetbrains.com/?post_type=teamcity&p=504369",
        "categories": [
          "news"
        ],
        "isoDate": "2024-08-20T11:44:43.000Z"
      }
    ]
  },
  {
    "name": "Airbnb Engineering & Data Science",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Instagram Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "PayPal Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "article New updates to Planner comment notifications and settings in Planner Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Visual Studio Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Mads Kristensen",
        "title": "New IDE features in Visual Studio v17.11",
        "link": "https://devblogs.microsoft.com/visualstudio/new-ide-features-in-visual-studio-v17-11/",
        "pubDate": "Mon, 26 Aug 2024 15:53:30 +0000",
        "content:encodedSnippet": "In Visual Studio 2022 v17.11, you’ll discover several new features that address specific issues developers have reported. These updates don’t belong to a distinct category, but we’re dedicated to sharing them with you in this blog post. You can download the update and view the comprehensive release notes for full details.\nFind the code you’re looking for\nDo you ever feel like you’re seeing too many results in code search? Narrow down your focus with the newly added scoping options in Code Search.\n\nFor the default code search experience and each filter, you can now set the scope to Entire solution, Current project, or Current document and toggle inclusion of external files.\nYou can set different scopes for different filters. For example, the default experience can be set to look through Entire solution and members can be set to look through only current document. Your selections will be preserved past the current session.\nFamiliar keyboard shortcuts\nWhen moving between different IDEs and editors, it can be frustrating to have to relearn keyboard shortcuts. We’ve made some changes to some default keyboard shortcuts to make them more familiar and to preserve your muscle memory.\nToggle line comments\nYou’ve been able to toggle line comments in Visual Studio for a long time, but the default keyboard shortcut was Ctrl+K, Ctrl+/. We’ve now added Ctrl+/ as an alternative shortcut, which is the default in many other IDEs and editors.\n\nOpen Command Palette\nOr Feature Search as it’s called in Visual Studio. The default keyboard shortcut for this feature is now Ctrl+Shift+P, which should be familiar to VS Code users for opening the Command Palette.\n\nNever miss installing a component\nMany teams use *.vsconfig files to standardize their teams’ Visual Studio installations. The *.vsconfig files can be placed in a repo or a project’s solution directory, and Visual Studio will automatically detect if components specified in the *.vsconfig file are missing.\n\nIf any are missing, then a notification such as the one pictured below will appear.\n\nWe’ve made two improvements to this experience in Visual Studio 2022 version 17.11 Preview 1.\nFirst, Visual Studio can now detect if any local or network hosted extensions are missing from the installation, and if so, it’ll prompt you to install them. Previously, with respect to extensions, Visual Studio was only able to recognize if marketplace extensions were missing.\nSecondly, Visual Studio will now re-prompt the notification in certain situations, such as if the *.vsconfig file has changed because new components or extensions get added to it. Previously, the notification would only pop until you acted upon it, at which point it would be suppressed forever.\nImproved user authentication\nVisual Studio now uses the Web Account Manager (WAM) as its main authentication mechanism. This integration not only streamlines the authentication experience for Visual Studio, but it also enhances the security of your credentials.\nHere’s how the new WAM experience looks like:\n\nHow does this impact your experience?\nUsing WAM as the default authentication experience has many benefits, including:\nWindows integration: In addition to reducing the overall number of authentication prompts, you can now select existing Windows accounts instead of repeatedly entering credentials.\nBetter token protection: Refresh tokens are better secured as they are now device bound.\nSupport for the latest security features:\n\nLeverage rich OS capabilities such as Windows Hello & FIDO keys.\nAccess the latest and greatest Microsoft Entra ID capabilities and conditional access policies.\nNew Teams Toolkit templates\nTeams Toolkit now offers an empty Teams template for you to connect with your existing projects or use it as a starting point for new Teams apps.\nStart with this empty template to create a Teams app.\nIf you want to add Teams capability to your existing project, add Empty Teams App to your project and then connect two projects by making simple edits follow https://aka.ms/Config-Teams-app.\n\nTeams Toolkit supports authentication for Search Results from API Message Extensions app.\n\nWe hope you enjoy this update to Visual Studio, and we look forward to hearing what you think. You can share feedback with us via Developer Community, by reporting issues via report a problem and share your suggestions for new features or improvements to existing ones.\nStay connected with the Visual Studio team by following us on Twitter, YouTube, LinkedIn, and on Microsoft Learn.\nThank you for using Visual Studio and happy coding!\nDownload Visual Studio 17.11\n\n \nThe post New IDE features in Visual Studio v17.11 appeared first on Visual Studio Blog.",
        "dc:creator": "Mads Kristensen",
        "content": "<p>In Visual Studio 2022 v17.11, you&#8217;ll discover several new features that address specific issues developers have reported. These updates don&#8217;t belong to a distinct category, but we&#8217;re dedicated to sharing them with you in this blog post. You can download the update and view the comprehensive release notes for full details.</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/new-ide-features-in-visual-studio-v17-11/\">New IDE features in Visual Studio v17.11</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "In Visual Studio 2022 v17.11, you’ll discover several new features that address specific issues developers have reported. These updates don’t belong to a distinct category, but we’re dedicated to sharing them with you in this blog post. You can download the update and view the comprehensive release notes for full details.\nThe post New IDE features in Visual Studio v17.11 appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=250326",
        "categories": [
          "Productivity",
          "Team and Development",
          "Visual Studio",
          "code search",
          "Keyboard Shortcuts",
          "vsconfig"
        ],
        "isoDate": "2024-08-26T15:53:30.000Z"
      },
      {
        "creator": "Rhea Patel",
        "title": "Enhancing Code Comprehension: GitHub Copilot’s Features in Visual Studio 2022 17.11",
        "link": "https://devblogs.microsoft.com/visualstudio/enhancing-code-comprehension-github-copilots-features-in-visual-studio-2022-17-11/",
        "pubDate": "Thu, 22 Aug 2024 10:00:28 +0000",
        "content:encodedSnippet": "GitHub Copilot in Visual Studio 2022 17.11 now offers an improved experience you to refer to their methods, classes, functions, and entire solution directly within the chat. By using the # symbol followed by the name of a method, class, or function, or by referring to your solution with @workspace, you can provide specific context that helps GitHub Copilot better understand their code and the problem at hand.\nRefer to your solution\nGitHub Copilot Chat now allows you to refer to your entire solution. This feature helps provide an even deeper understanding of your solution to get the best results. To refer to your solution, simply use the @workspace and Copilot will answer high level questions about your solution, files and how they work together.\n\nTry asking GitHub Copilot Chat questions like:\n@workspace What project can I run in my solution?\n@workspace In my workspace, where is #methodname referenced?\n@workspace Where does serialization occur in my solution?\n \nReference your methods, classes, functions\nGitHub Copilot Chat now allows you to refer to your methods, classes, and functions inline. By referring to methods, classes, and functions directly within the chat, you can provide specific context that helps GitHub Copilot better comprehend your code and the problem at hand. This feature empowers you to provide richer context to GitHub Copilot, enabling it to deliver more precise responses by gaining a deeper understanding of your codebase.\n\nTry asking GitHub Copilot Chat questions like:\nI have a test method named #methodName. How can I ensure that it’s being executed correctly?\nWhat are some optimizations that could be applied to #methodName?\nHow does #methodName1 use #methodName2 and what issues should I look out for?\n/explain #methodName\n \nSearch the web in Copilot Chat\nGitHub Copilot now includes context from your entire repository & can search the web.\nGitHub Copilot Enterprise subscribers in Visual Studio can now use GitHub Copilot Chat to get answers enriched with context from their entire repository and Bing search results.\n\nGet answers from across your entire codebase\nGitHub Copilot Chat can now answer questions with understanding of your full repository, not just the tabs you have open. Index your repository on GitHub.com, and then ask a question mentioning @github. You can ask questions like @github where is rate limiting implemented?\nSearch with the context of the web\nGitHub Copilot chat can also search Bing to find information outside of its general knowledge or your codebase. When you mention @github, GitHub Copilot will intelligently decide when to use Bing. You can ask questions like @github what is the latest LTS version of .NET?\nBing search is only available if enabled by an administrator – for more details, see Enabling GitHub Copilot Enterprise features or read the docs.\nTry it out today!\nWe hope you enjoy this new feature in GitHub Copilot for Visual Studio! Your feedback is important to us, so please share your thoughts using the thumbs up or down in the Chat, or by visiting the Developer Community. We look forward to hearing from you!\n\nHappy coding!\nWe appreciate the time you’ve spent reporting issues/suggestions and hope you continue to give us feedback when using GitHub Copilot in Visual Studio on what you like and what we can improve. Your feedback is critical to help us make GitHub Copilot  the best tool it can be! You can share feedback with us via Developer Community: report any bugs or issues via report a problem and share your suggestions for new features or improvements to existing ones.\nStay connected with the Visual Studio team by following us on YouTube, Twitter, LinkedIn, Twitch and on Microsoft Learn.\n\nThe post Enhancing Code Comprehension: GitHub Copilot’s Features in Visual Studio 2022 17.11 appeared first on Visual Studio Blog.",
        "dc:creator": "Rhea Patel",
        "content": "<p>GitHub Copilot in Visual Studio 2022 17.11 now offers an improved experience you to refer to their methods, classes, functions, and entire solution directly within the chat. By using the # symbol followed by the name of a method, class, or function,</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/enhancing-code-comprehension-github-copilots-features-in-visual-studio-2022-17-11/\">Enhancing Code Comprehension: GitHub Copilot’s Features in Visual Studio 2022 17.11</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "GitHub Copilot in Visual Studio 2022 17.11 now offers an improved experience you to refer to their methods, classes, functions, and entire solution directly within the chat. By using the # symbol followed by the name of a method, class, or function,\nThe post Enhancing Code Comprehension: GitHub Copilot’s Features in Visual Studio 2022 17.11 appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=249711",
        "categories": [
          "Copilot",
          "Visual Studio",
          "Context",
          "GitHub Copilot"
        ],
        "isoDate": "2024-08-22T10:00:28.000Z"
      },
      {
        "creator": "Sy Brand",
        "title": "New C++ features in Visual Studio v17.11",
        "link": "https://devblogs.microsoft.com/visualstudio/new-c-features-in-visual-studio-v17-11/",
        "pubDate": "Wed, 21 Aug 2024 10:00:31 +0000",
        "content:encodedSnippet": "Visual Studio 2022 version 17.11 is here and comes with a host of new features for C++ developers. We’ve made improvements across our toolchain, Unreal Engine support, Build Insights, CMake debugger, and more. This post gives a quick overview of what’s available; for all the details, see What’s New for C++ Developers in Visual Studio 2022 17.11 on the C++ blog.\nStandard Library\nThe three main areas of improvement in this release are in formatted output, vectorization, and diagnostics. For formatted output, we’ve implemented parts of Formatting Ranges and all of Printing Blank Lines with println. Our vectorization improvements hit over a dozen of the standard algorithms, and we’ve improved the diagnostics of common misuses of std::ranges::to and std::get(std::tuple). See the STL changelog for all the details.\nCMake Debugger\nWe have added support for the CMake debugger in CMake projects targeting Linux via WSL or SSH. The CMake debugger allows you to debug your CMake scripts and CMakeLists.txt files through the Visual Studio debugger.\nTo start a CMake debugging session, set a breakpoint in your CMakeLists.txt file and then navigate to Project > Configure Cache with CMake Debugging.\n\nUnreal Engine Support\nWe’ve added several new features for Unreal Engine developers:\nAn Unreal Engine toolbar that provides quick access to Unreal Engine actions such as attaching to UE processes and accessing the UE log\nAn Add Class dialog for adding common UE class templates to your project\nAn Add Module dialog for adding UE modules to your project\n\nBuild Insights\nIn this update, we added quality of life changes to C++ Build Insights integration. You can now filter your Build Insights trace results by project. For results in each row, you will now see the relative path and file name instead of the full path. We have also improved the grouping of results in the Included Files view.\n\nBreakpoint Performance\nWe have significantly enhanced the performance of conditional breakpoints in C++ through a reworked implementation.\nBeginning with version 17.11, our initial assessment finds that execution time is almost four times as fast, reducing execution time from 80 seconds to 21 seconds over 80,000 iterations.\nSummary\nWe hope this has given you a taste of what’s new. For all the details, see What’s New for C++ Developers in Visual Studio 2022 17.11 on the C++ blog.\nWe are very much interested in your feedback. The comments below are open. Feedback can also be shared through Visual Studio Developer Community. You can also reach us on Twitter (@VisualC), or via email at visualcpp@microsoft.com.\nThe post New C++ features in Visual Studio v17.11 appeared first on Visual Studio Blog.",
        "dc:creator": "Sy Brand",
        "content": "<p>Visual Studio 2022 version 17.11 is here and comes with a host of new features for C++ developers. We’ve made improvements across our toolchain, Unreal Engine support, Build Insights, CMake debugger, and more. This post gives a quick overview of what’s available;</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/new-c-features-in-visual-studio-v17-11/\">New C++ features in Visual Studio v17.11</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "Visual Studio 2022 version 17.11 is here and comes with a host of new features for C++ developers. We’ve made improvements across our toolchain, Unreal Engine support, Build Insights, CMake debugger, and more. This post gives a quick overview of what’s available;\nThe post New C++ features in Visual Studio v17.11 appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=250237",
        "categories": [
          "Cross-Platform",
          "Gaming",
          "Visual Studio",
          "C++",
          "Visual Studio 2022"
        ],
        "isoDate": "2024-08-21T10:00:31.000Z"
      },
      {
        "creator": "Harshada Hole",
        "title": "New debugging and diagnostic features",
        "link": "https://devblogs.microsoft.com/visualstudio/new-debugging-and-diagnostic-features/",
        "pubDate": "Tue, 20 Aug 2024 10:00:11 +0000",
        "content:encodedSnippet": "Debugging and diagnostics are vital skills for any developer, but they can also be difficult and time-consuming to get proficient . That’s why we’ve added some fantastic new features and enhancements to Visual Studio 2022 v17.11 that will help you find and resolve bugs faster and easier than ever before. Here are some of the highlights. Download this update and see the release notes for all the details.\n\nDebugging\nBreak on async method exceptions\nDebugging asynchronous code, especially in frameworks like ASP.NET, can be tricky due to the potential for exceptions to be thrown across asynchronous boundaries.\nNow, with Visual Studio Debugger it automatically breaks when an async Task method throws an exception back to framework code.\nAI-generated breakpoint expressions\nAI-generated expressions for conditional breakpoints and tracepoints are now supported in C++. GitHub Copilot analyzes your code and offers insightful breakpoint expressions, streamlining your debugging process.\nDebug AnyCPU applications manifested to run as arm64\nVisual Studio natively supports building and debugging Arm64 apps on Arm-based processors. Unfortunately, applications built with the AnyCPU setting running on an Arm64 machine will default to using x64 emulation. While the capabilities of the x64 emulator have expanded, the most efficient Arm CPU scenarios are supported when applications are running natively.\nTo better support the intended native behavior the Windows 24H2 update introduces a new <supportedArchitectures> setting for your App manifest files. .NET developers can include a list of supported architectures (amd64 or arm64), explicitly signaling that an application built with the AnyCPU setting should run natively using the Arm64 CLR on Arm64 devices.\nBlazor WebAssembly debugging\nThis release features a preview of the improved debugging experience for Blazor WebAssembly apps targeting .NET 9 or later.\nOrganize your breakpoints with default breakpoint groups\nBreakpoint groups allow you to customize and toggle breakpoints for faster and more effective debugging.\nYou can now mark the selected breakpoint group as the default, ensuring all newly added breakpoints are automatically included in that group.\nEdit and visualize LINQ expressions in the IEnumerable visualizer\nThe Visual Studio debugger now offers an editable expression feature in the IEnumerable visualizer, a powerful enhancement for developers working with collections.\nImproved performance of conditional breakpoints in C++\nWe have significantly enhanced the performance of conditional breakpoints in C++ through a reworked implementation.\nOur initial assessment shows a performance improvement of at least 35% in version 17.10 and 70% in version 17.11, reducing execution time from 80 seconds to 21 seconds over 80,000 iterations.\nProfiling\nKeep your target selection in the instrumentation tool between runs\nThe instrumentation tool now persists the target selection between runs offering a significant benefit by enhancing the continuity of profiling sessions.\nWith this improvement, you can maintain your specified target across multiple instrumentation runs, removing the need for repetitive selection tasks.\nDecompile .NET assemblies\nVisual Studio profiler now offers auto-decompilation for .NET libraries in scenarios where source code is unavailable. By automatically decompiling code during source lookup, even without loaded symbols or exact file locations, you can gain insights into the code’s structure and performance issues.\nWith this new feature, while visualizing a collection or dataset, you can directly edit the expressions textbox on the top of the dialog with your desired LINQ expressions. The visualizer updates in real-time, reflecting the data change resulting from your query.\nWe hope you enjoy this update to Visual Studio, and we look forward to hearing what you think. You can share feedback with us via Developer Community, by reporting issues via report a problem and share your suggestions for new features or improvements to existing ones.\nStay connected with the Visual Studio team by following us on Twitter @VS_Debugger, Twitter @VisualStudio, YouTube, and LinkedIn and on Microsoft Learn.\nThank you for using Visual Studio and happy coding!\nThe post New debugging and diagnostic features appeared first on Visual Studio Blog.",
        "dc:creator": "Harshada Hole",
        "content": "<p>Debugging and diagnostics are vital skills for any developer, but they can also be difficult and time-consuming to get proficient . That&#8217;s why we&#8217;ve added some fantastic new features and enhancements to Visual Studio 2022 v17.11 that will help you find and resolve bugs faster and easier than ever before.</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/new-debugging-and-diagnostic-features/\">New debugging and diagnostic features</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "Debugging and diagnostics are vital skills for any developer, but they can also be difficult and time-consuming to get proficient . That’s why we’ve added some fantastic new features and enhancements to Visual Studio 2022 v17.11 that will help you find and resolve bugs faster and easier than ever before.\nThe post New debugging and diagnostic features appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=250236",
        "categories": [
          "Debug",
          "Visual Studio",
          "Debugger",
          "Debugging",
          "Debugging and Diagnostics",
          "Visual Studio 2022"
        ],
        "isoDate": "2024-08-20T10:00:11.000Z"
      }
    ]
  },
  {
    "name": "Instagram Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Dropbox Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Joshua",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권재명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김석기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선영",
    "category": "개인",
    "posts": [
      {
        "creator": "sunyzero",
        "title": "개발자용 고정폭 글꼴(mono font) 추천 - nerd font",
        "link": "https://sunyzero.tistory.com/301",
        "pubDate": "Tue, 20 Aug 2024 22:04:40 +0900",
        "author": "sunyzero",
        "comments": "https://sunyzero.tistory.com/301#entry301comment",
        "content": "<p data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">개발자라면 필수로 <span style=\"background-color: #f6e199;\">고정폭 글꼴</span>(fixed width font, mono font)을 사용한다. 여기서 mono font란 monospace font를 의미한다. 개발자가 고정폭을 좋아하는 이유는 코드를 볼때 간격이 일정해서 가독성이 좋기 때문이다. 반대로 가변폭 글꼴을 사용하면 탭이나 기호가 들어간 코드를 볼때 매우 불편해진다.</span></p>\n<p data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">글꼴은 취향의 영역이라서 어느 것이 최고라고 말할 수는 없다. 다만 여기서는 많이 사용되는 <span style=\"background-color: #f3c000;\">Nerd font</span>를 기준으로 하겠다. 너드 폰트는 다운로드를 자동화하는 스크립트도 있지만, 시스템 전역으로 쓸때는 그냥 수동으로 /usr/share/fonts/ 밑에 디렉터리를 만들고 설치하는게 좋다.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">0. 글꼴 선택 기준</span></h2>\n<p data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">본인은 글꼴을 선택할 때 우선적으로 2가지를 살펴본다. </span></p>\n<p data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">첫번째로 숫자 0 (zero)의 안쪽이 빗금인지 점인지를 확인한다. 개인적으로 빗금 스타일을 더 선호한다. 아래 그림을 보면 좌측은 빗금 스타일 0(slashed zero number)을 사용하고, 우측은 점을 찍은 것이다. 어느 스타일을 선호하는지 본인이 여기서 보고 정하면 된다.</span></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"font-zero_slash_vs_dot.jpg\" data-origin-width=\"1249\" data-origin-height=\"151\"><span data-url=\"https://blog.kakaocdn.net/dn/chsZDQ/btsJaCHs6Fr/A253tuHn1OhG76Q7K2MKu0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/chsZDQ/btsJaCHs6Fr/A253tuHn1OhG76Q7K2MKu0/img.jpg\" data-alt=\"Mono font - Slashed zero vs Doted zero\"><img src=\"https://blog.kakaocdn.net/dn/chsZDQ/btsJaCHs6Fr/A253tuHn1OhG76Q7K2MKu0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FchsZDQ%2FbtsJaCHs6Fr%2FA253tuHn1OhG76Q7K2MKu0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"font-zero_slash_vs_dot.jpg\" data-origin-width=\"1249\" data-origin-height=\"151\"/></span><figcaption>Mono font - Slashed zero vs Doted zero</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">두번째로는 폭을 본다. 글꼴의 폭이 넓으면 눈이 덜 피로하지만 한 화면에 많이 표시하지 못한다. 대표적으로 폭이 넓은 형태로는 Roboto가 있고, 좁은 형태로는 Iosevka가 있다. 둘을 비교하기 위해 아래 그림을 보면 된다. 위가 Roboto이고 아래가 Iosevka이다.</span></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"font-narrow-Roboto_vs_Iosevka.png\" data-origin-width=\"590\" data-origin-height=\"270\"><span data-url=\"https://blog.kakaocdn.net/dn/WdxYi/btsI9eOMy9l/hJr9xAf16xDlGb8bqLiBCk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/WdxYi/btsI9eOMy9l/hJr9xAf16xDlGb8bqLiBCk/img.png\" data-alt=\"Roboto (top) vs Iosevka (bottom)\"><img src=\"https://blog.kakaocdn.net/dn/WdxYi/btsI9eOMy9l/hJr9xAf16xDlGb8bqLiBCk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FWdxYi%2FbtsI9eOMy9l%2FhJr9xAf16xDlGb8bqLiBCk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"font-narrow-Roboto_vs_Iosevka.png\" data-origin-width=\"590\" data-origin-height=\"270\"/></span><figcaption>Roboto (top) vs Iosevka (bottom)</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">폭이 좁으면 화면에 많은 글을 표시할 수 있어서 log를 보거나 code를 분석할 때는 용이한 측면이 있다. 다만 문서 자료를 작성할 때는 정신이 사나울 수도 있다.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">1. Nerd font란?</span></h2>\n<p data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">Nerd font는 개발자들이 주로 사용하는 폰트에 각종 기호(git이나 vim 에디터에서 사용하는 기호)를 추가한 버전이다. 기존 폰트에 기호 이미지를 추가하는 패치된 폰트이므로 어떤 폰트든지 패치해서 만들 수 있다. 다만 패치 스크립트를 직접 사용하면 작업 시간이 좀 오래 걸리는 편이라서 미리 패치된 글꼴을 제공한다. 아래에서 볼 수 있다.</span></p>\n<p data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">Nerd Font Downloads -&nbsp;<b><span style=\"color: #1155cc;\"></span><a href=\"https://www.nerdfonts.com/font-downloads\">https://www.nerdfonts.com/font-downloads</a></b></span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">2. 추천하는 폰트</span></h2>\n<p data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">개인적으로 추천하는 Nerd font는 다음과 같다.&nbsp;</span></p>\n<table style=\"border-collapse: collapse; width: 100%;\" border=\"1\" data-ke-align=\"alignLeft\">\n<tbody>\n<tr>\n<td style=\"width: 50%;\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif; background-color: #f6e199;\">CodeNewRoman</span></td>\n<td style=\"width: 50%;\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">넓은 폭을 가진 글꼴이다.</span><br /><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">가독성이 좋아서 터미널용으로 많이 사용된다.</span></td>\n</tr>\n<tr>\n<td style=\"width: 50%;\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif; background-color: #9feec3;\">D2coding</span></td>\n<td style=\"width: 50%;\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">네이버에서 제작한 글꼴이다.&nbsp;</span><br /><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">폭이 좁은 편이라 한 화면에 많은 글자를 표시할 수 있다.</span></td>\n</tr>\n<tr>\n<td style=\"width: 50%;\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">EnvyCodeR</span></td>\n<td style=\"width: 50%;\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">좁은 폭과 귀엽게 둥근 글꼴이다.</span></td>\n</tr>\n<tr>\n<td style=\"width: 50%;\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">Iosevka</span></td>\n<td style=\"width: 50%;\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">좁은 폭을 가진 글꼴이다.</span><br /><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">자매품으로 Zed가 있다.</span></td>\n</tr>\n<tr>\n<td style=\"width: 50%;\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif; background-color: #f6e199;\">Mononoki</span></td>\n<td style=\"width: 50%;\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">중간 폭을 가진 글꼴이다.<br />동글동글해서 귀여운 글꼴이다.</span></td>\n</tr>\n<tr>\n<td style=\"width: 50%;\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">Roboto Mono</span></td>\n<td style=\"width: 50%;\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">넓은 폭을 가진 글꼴이다.</span></td>\n</tr>\n<tr>\n<td style=\"width: 50%;\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif; background-color: #99cefa;\">ZedMono</span></td>\n<td style=\"width: 50%;\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">좁은 폭을 가진 글꼴이다.</span><br /><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">Iosevka를 약간 둥글게 수정한 글꼴이다. 개인적으로 추천.</span></td>\n</tr>\n</tbody>\n</table>\n<p data-ke-size=\"size16\"><span>위 글꼴 외에 FiraCode, IBM Plex나 Noto Nerd, Source code pro 도 많이 쓰이므로 한번 위의 Nerd Font 링크에서 확인해보기 바란다.</span></p>\n<p data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif; color: #333333; text-align: start;\">그러면 위에서 언급한 글꼴을 순서대로 그림으로 살펴보면 다음과 같다. 참고로 Gnome builder의 설정 화면에서 캡쳐했다.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">2.1. CodeNewRoman Nerd Font</span></h3>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"font-CodeNewRoman-nerdfont.png\" data-origin-width=\"780\" data-origin-height=\"773\"><span data-url=\"https://blog.kakaocdn.net/dn/oH2kn/btsJaCAHLxB/aZM24SYmooDsSJz8RKKQ2K/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/oH2kn/btsJaCAHLxB/aZM24SYmooDsSJz8RKKQ2K/img.png\" data-alt=\"CodeNewRoman\"><img src=\"https://blog.kakaocdn.net/dn/oH2kn/btsJaCAHLxB/aZM24SYmooDsSJz8RKKQ2K/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FoH2kn%2FbtsJaCAHLxB%2FaZM24SYmooDsSJz8RKKQ2K%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"font-CodeNewRoman-nerdfont.png\" data-origin-width=\"780\" data-origin-height=\"773\"/></span><figcaption>CodeNewRoman</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">CodeNewRoman은 터미널인 gnome-terminal에서 설정해도 좋은 글꼴이다. 아래 그림은 gnome-terminal에 설정한 모습이다.</span></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"font-codenewroman_gnome-terminal.png\" data-origin-width=\"952\" data-origin-height=\"651\"><span data-url=\"https://blog.kakaocdn.net/dn/1wkJs/btsJaIHHepO/0gBiK8Uysu9iA3BnGnEg5k/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/1wkJs/btsJaIHHepO/0gBiK8Uysu9iA3BnGnEg5k/img.png\" data-alt=\"gnome-terminal profile\"><img src=\"https://blog.kakaocdn.net/dn/1wkJs/btsJaIHHepO/0gBiK8Uysu9iA3BnGnEg5k/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F1wkJs%2FbtsJaIHHepO%2F0gBiK8Uysu9iA3BnGnEg5k%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"font-codenewroman_gnome-terminal.png\" data-origin-width=\"952\" data-origin-height=\"651\"/></span><figcaption>gnome-terminal profile</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">2.2. D2coding Nerd Font</span></h3>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"font-D2coding-nerdfont.png\" data-origin-width=\"789\" data-origin-height=\"774\"><span data-url=\"https://blog.kakaocdn.net/dn/cgnKSX/btsI9xAAvPv/lN54ebkfXTxrxv8mA2XZM0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cgnKSX/btsI9xAAvPv/lN54ebkfXTxrxv8mA2XZM0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/cgnKSX/btsI9xAAvPv/lN54ebkfXTxrxv8mA2XZM0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcgnKSX%2FbtsI9xAAvPv%2FlN54ebkfXTxrxv8mA2XZM0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"font-D2coding-nerdfont.png\" data-origin-width=\"789\" data-origin-height=\"774\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">D2coding은 터미널 용으로 써도 좋은 편이다. 그리고 한글이 지원된다는 강점이 있다. 본인은 D2coding 공식 사이트에서 받은 TTC 파일 1개로 버전을 nerdfont 패치 프로그램으로 직접 패치해서 사용하는데, d2coding은 재배포가 가능하므로 나중에 파일 링크를 올리도록 하겠다.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">2.3. EnvyCodeR Nerd Font Mono</span></h3>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"font-EnvyCodeR-nerdfont-mono.png\" data-origin-width=\"788\" data-origin-height=\"766\"><span data-url=\"https://blog.kakaocdn.net/dn/nGYJw/btsI9EM4WZi/KwJVF3IwSYriRdbfqRorm0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/nGYJw/btsI9EM4WZi/KwJVF3IwSYriRdbfqRorm0/img.png\" data-alt=\"EnvyCodeR\"><img src=\"https://blog.kakaocdn.net/dn/nGYJw/btsI9EM4WZi/KwJVF3IwSYriRdbfqRorm0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FnGYJw%2FbtsI9EM4WZi%2FKwJVF3IwSYriRdbfqRorm0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"font-EnvyCodeR-nerdfont-mono.png\" data-origin-width=\"788\" data-origin-height=\"766\"/></span><figcaption>EnvyCodeR</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">EnvyCodeR도 좁은 편에 둥글둥글한 스타일인데, 문서 읽을때 오히려 더 좋은 것 같다는 생각이 든다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">2.4. Iosevka Nerd Font Medium</span></h3>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"font-Iosevka-nerdfont-medium.png\" data-origin-width=\"785\" data-origin-height=\"772\"><span data-url=\"https://blog.kakaocdn.net/dn/vntCe/btsI9EGjS3Y/yirQyBMt7LALKbvFQi7G31/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/vntCe/btsI9EGjS3Y/yirQyBMt7LALKbvFQi7G31/img.png\" data-alt=\"Iosevka\"><img src=\"https://blog.kakaocdn.net/dn/vntCe/btsI9EGjS3Y/yirQyBMt7LALKbvFQi7G31/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FvntCe%2FbtsI9EGjS3Y%2FyirQyBMt7LALKbvFQi7G31%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"font-Iosevka-nerdfont-medium.png\" data-origin-width=\"785\" data-origin-height=\"772\"/></span><figcaption>Iosevka</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">Iosevka는 기본적으로 가늘어서 가독성을 높이려면 Medium 정도의 레벨을 사용하는 것을 추천한다.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\">2.5. Mononoki Nerd Font Propo</h3>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"font-Mononoki-nerdfont-propo.png\" data-origin-width=\"785\" data-origin-height=\"776\"><span data-url=\"https://blog.kakaocdn.net/dn/bem4WE/btsJapn51Sl/a3ZvWAHH8v9pH0Fxhcfw61/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bem4WE/btsJapn51Sl/a3ZvWAHH8v9pH0Fxhcfw61/img.png\" data-alt=\"Mononoki Nerd Font propo\"><img src=\"https://blog.kakaocdn.net/dn/bem4WE/btsJapn51Sl/a3ZvWAHH8v9pH0Fxhcfw61/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbem4WE%2FbtsJapn51Sl%2Fa3ZvWAHH8v9pH0Fxhcfw61%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"font-Mononoki-nerdfont-propo.png\" data-origin-width=\"785\" data-origin-height=\"776\"/></span><figcaption>Mononoki Nerd Font propo</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">동글동글해서 보기 좋은 글꼴이다. 터미널용으로도 괜찮은 글꼴이다. 개인적으로 추천하는 글꼴 중에 하나이다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">2.6. Roboto Nerd Font</span></h3>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"font-Roboto-mono-nerdfont.png\" data-origin-width=\"781\" data-origin-height=\"772\"><span data-url=\"https://blog.kakaocdn.net/dn/rn1Jd/btsI94xWXNr/hmLwxkWc7iih3warCPUnx0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/rn1Jd/btsI94xWXNr/hmLwxkWc7iih3warCPUnx0/img.png\" data-alt=\"Roboto Nerd Font\"><img src=\"https://blog.kakaocdn.net/dn/rn1Jd/btsI94xWXNr/hmLwxkWc7iih3warCPUnx0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Frn1Jd%2FbtsI94xWXNr%2FhmLwxkWc7iih3warCPUnx0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"font-Roboto-mono-nerdfont.png\" data-origin-width=\"781\" data-origin-height=\"772\"/></span><figcaption>Roboto Nerd Font</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">2.7. ZedMono Nerd Font Mono Medium</span></h3>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"font-ZedMono-nerdfont-mono-medium.png\" data-origin-width=\"789\" data-origin-height=\"771\"><span data-url=\"https://blog.kakaocdn.net/dn/lbUEi/btsI93Mxh6C/NcYshFilh72ectosyik1Ek/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/lbUEi/btsI93Mxh6C/NcYshFilh72ectosyik1Ek/img.png\" data-alt=\"ZedMono Nerd Font Mono Medium\"><img src=\"https://blog.kakaocdn.net/dn/lbUEi/btsI93Mxh6C/NcYshFilh72ectosyik1Ek/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FlbUEi%2FbtsI93Mxh6C%2FNcYshFilh72ectosyik1Ek%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"font-ZedMono-nerdfont-mono-medium.png\" data-origin-width=\"789\" data-origin-height=\"771\"/></span><figcaption>ZedMono Nerd Font Mono Medium</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">ZedMono는 Iosevka를 다음은 글꼴이다.&nbsp;</span><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">개인적으로 좁은 폰트 중에 제일 좋아하는 폰트이다. 특히 Medium 레벨의 굵기로 표시하면 가독성도 좋다.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">3. 폰트 설치 방법</span></h2>\n<p data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">리눅스에서는 개인 홈디렉터리에 폰트를 설치하는 방법과 시스템에 설치하는 방법이 있는데, 되도록이면 시스템에 설치하는 것을 추천한다. 시스템에 폰트를 설치하는 방법은 매우 간단하다. Nerd Font 사이트에서 받은 폰트는 zip 파일로 되어있는데, 이를 풀면 디렉터리가 나온다. 그리고 해당 디렉터리를 통째로 /usr/share/fonts/ 로 복사하면 된다. (복사는 당연히 root 권한으로 작업해야만 한다)</span></p>\n<p data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">만일 폰트 파일만 있는 경우, 예를 들어 ttc 파일 1개라면 /usr/share/fonts/ 밑에 적당한 이름의 디렉터리를 만들고 그 안에 넣어주면 된다. 예를 들어 mynerdfont.ttc 파일이라면 /usr/share/fonts/mynerdfont 라고 디렉터리를 만들고 그 안에 파일을 넣어주면 된다. ttf같이 여러개의 파일이 있는 경우라도 방법은 같다.</span></p>\n<p data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">보통 글꼴을 /usr/share/fonts 밑에 복사하면 아무 작업을 안해도 자동으로 인식된다. 그렇지만 간혹 인식이 안된 경우도 생길 수 있는데, 그럴 경우에는 font cache를 재설정하기 위해 fc-cache -f 명령을 내리면 된다. 그래도 안된다면 재부팅하도록 하자.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">히스토리</span></h3>\n<p data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">2024-08-20 초고</span></p>",
        "contentSnippet": "개발자라면 필수로 고정폭 글꼴(fixed width font, mono font)을 사용한다. 여기서 mono font란 monospace font를 의미한다. 개발자가 고정폭을 좋아하는 이유는 코드를 볼때 간격이 일정해서 가독성이 좋기 때문이다. 반대로 가변폭 글꼴을 사용하면 탭이나 기호가 들어간 코드를 볼때 매우 불편해진다.\n글꼴은 취향의 영역이라서 어느 것이 최고라고 말할 수는 없다. 다만 여기서는 많이 사용되는 Nerd font를 기준으로 하겠다. 너드 폰트는 다운로드를 자동화하는 스크립트도 있지만, 시스템 전역으로 쓸때는 그냥 수동으로 /usr/share/fonts/ 밑에 디렉터리를 만들고 설치하는게 좋다.\n \n0. 글꼴 선택 기준\n본인은 글꼴을 선택할 때 우선적으로 2가지를 살펴본다. \n첫번째로 숫자 0 (zero)의 안쪽이 빗금인지 점인지를 확인한다. 개인적으로 빗금 스타일을 더 선호한다. 아래 그림을 보면 좌측은 빗금 스타일 0(slashed zero number)을 사용하고, 우측은 점을 찍은 것이다. 어느 스타일을 선호하는지 본인이 여기서 보고 정하면 된다.\nMono font - Slashed zero vs Doted zero\n\n\n두번째로는 폭을 본다. 글꼴의 폭이 넓으면 눈이 덜 피로하지만 한 화면에 많이 표시하지 못한다. 대표적으로 폭이 넓은 형태로는 Roboto가 있고, 좁은 형태로는 Iosevka가 있다. 둘을 비교하기 위해 아래 그림을 보면 된다. 위가 Roboto이고 아래가 Iosevka이다.\nRoboto (top) vs Iosevka (bottom)\n\n\n폭이 좁으면 화면에 많은 글을 표시할 수 있어서 log를 보거나 code를 분석할 때는 용이한 측면이 있다. 다만 문서 자료를 작성할 때는 정신이 사나울 수도 있다.\n \n \n1. Nerd font란?\nNerd font는 개발자들이 주로 사용하는 폰트에 각종 기호(git이나 vim 에디터에서 사용하는 기호)를 추가한 버전이다. 기존 폰트에 기호 이미지를 추가하는 패치된 폰트이므로 어떤 폰트든지 패치해서 만들 수 있다. 다만 패치 스크립트를 직접 사용하면 작업 시간이 좀 오래 걸리는 편이라서 미리 패치된 글꼴을 제공한다. 아래에서 볼 수 있다.\nNerd Font Downloads - https://www.nerdfonts.com/font-downloads\n \n2. 추천하는 폰트\n개인적으로 추천하는 Nerd font는 다음과 같다. \nCodeNewRoman\n넓은 폭을 가진 글꼴이다.\n가독성이 좋아서 터미널용으로 많이 사용된다.\n\n\nD2coding\n네이버에서 제작한 글꼴이다. \n폭이 좁은 편이라 한 화면에 많은 글자를 표시할 수 있다.\n\n\nEnvyCodeR\n좁은 폭과 귀엽게 둥근 글꼴이다.\n\n\nIosevka\n좁은 폭을 가진 글꼴이다.\n자매품으로 Zed가 있다.\n\n\nMononoki\n중간 폭을 가진 글꼴이다.\n동글동글해서 귀여운 글꼴이다.\n\n\nRoboto Mono\n넓은 폭을 가진 글꼴이다.\n\n\nZedMono\n좁은 폭을 가진 글꼴이다.\nIosevka를 약간 둥글게 수정한 글꼴이다. 개인적으로 추천.\n\n\n\n위 글꼴 외에 FiraCode, IBM Plex나 Noto Nerd, Source code pro 도 많이 쓰이므로 한번 위의 Nerd Font 링크에서 확인해보기 바란다.\n그러면 위에서 언급한 글꼴을 순서대로 그림으로 살펴보면 다음과 같다. 참고로 Gnome builder의 설정 화면에서 캡쳐했다.\n \n2.1. CodeNewRoman Nerd Font\nCodeNewRoman\n\n\nCodeNewRoman은 터미널인 gnome-terminal에서 설정해도 좋은 글꼴이다. 아래 그림은 gnome-terminal에 설정한 모습이다.\ngnome-terminal profile\n\n\n \n2.2. D2coding Nerd Font\n\n\nD2coding은 터미널 용으로 써도 좋은 편이다. 그리고 한글이 지원된다는 강점이 있다. 본인은 D2coding 공식 사이트에서 받은 TTC 파일 1개로 버전을 nerdfont 패치 프로그램으로 직접 패치해서 사용하는데, d2coding은 재배포가 가능하므로 나중에 파일 링크를 올리도록 하겠다.\n \n2.3. EnvyCodeR Nerd Font Mono\nEnvyCodeR\n\n\nEnvyCodeR도 좁은 편에 둥글둥글한 스타일인데, 문서 읽을때 오히려 더 좋은 것 같다는 생각이 든다.\n \n2.4. Iosevka Nerd Font Medium\nIosevka\n\n\nIosevka는 기본적으로 가늘어서 가독성을 높이려면 Medium 정도의 레벨을 사용하는 것을 추천한다.\n \n2.5. Mononoki Nerd Font Propo\nMononoki Nerd Font propo\n\n\n동글동글해서 보기 좋은 글꼴이다. 터미널용으로도 괜찮은 글꼴이다. 개인적으로 추천하는 글꼴 중에 하나이다.\n \n2.6. Roboto Nerd Font\nRoboto Nerd Font\n\n\n \n \n2.7. ZedMono Nerd Font Mono Medium\nZedMono Nerd Font Mono Medium\n\n\nZedMono는 Iosevka를 다음은 글꼴이다. 개인적으로 좁은 폰트 중에 제일 좋아하는 폰트이다. 특히 Medium 레벨의 굵기로 표시하면 가독성도 좋다.\n \n \n3. 폰트 설치 방법\n리눅스에서는 개인 홈디렉터리에 폰트를 설치하는 방법과 시스템에 설치하는 방법이 있는데, 되도록이면 시스템에 설치하는 것을 추천한다. 시스템에 폰트를 설치하는 방법은 매우 간단하다. Nerd Font 사이트에서 받은 폰트는 zip 파일로 되어있는데, 이를 풀면 디렉터리가 나온다. 그리고 해당 디렉터리를 통째로 /usr/share/fonts/ 로 복사하면 된다. (복사는 당연히 root 권한으로 작업해야만 한다)\n만일 폰트 파일만 있는 경우, 예를 들어 ttc 파일 1개라면 /usr/share/fonts/ 밑에 적당한 이름의 디렉터리를 만들고 그 안에 넣어주면 된다. 예를 들어 mynerdfont.ttc 파일이라면 /usr/share/fonts/mynerdfont 라고 디렉터리를 만들고 그 안에 파일을 넣어주면 된다. ttf같이 여러개의 파일이 있는 경우라도 방법은 같다.\n보통 글꼴을 /usr/share/fonts 밑에 복사하면 아무 작업을 안해도 자동으로 인식된다. 그렇지만 간혹 인식이 안된 경우도 생길 수 있는데, 그럴 경우에는 font cache를 재설정하기 위해 fc-cache -f 명령을 내리면 된다. 그래도 안된다면 재부팅하도록 하자.\n \n히스토리\n2024-08-20 초고",
        "guid": "https://sunyzero.tistory.com/301",
        "categories": [
          "컴퓨터 관련",
          "codenewroman",
          "D2Coding",
          "envycoder",
          "fc-cache",
          "ibm plex",
          "iosevka",
          "mono font",
          "nerdfont",
          "고정폭글꼴",
          "리눅스 글꼴"
        ],
        "isoDate": "2024-08-20T13:04:40.000Z"
      }
    ]
  },
  {
    "name": "권진호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강대명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권정혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "줌구",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수보",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김시은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "곽민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김범진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민서",
    "category": "개인",
    "posts": []
  },
  {
    "name": "I am not Okay",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권창현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권기호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강태욱",
    "category": "개인",
    "posts": [
      {
        "title": "인공지능 딥러닝 모델 성능 지표",
        "link": "http://daddynkidsmakers.blogspot.com/2024/08/blog-post.html",
        "pubDate": "2024-08-25T09:46:00.000Z",
        "author": "Daddy Maker",
        "content": "<div style=\"text-align: left;\">이 글은&nbsp;인공지능 딥러닝 모델 성능 지표를 간략히 정리한 것이다. 개발 목적에 따라 다양한 딥러닝 모델을 사용하고, 그에 따라 적절한 성능 지표를 모니터링해 튜닝 등 품질을 개선하는 것이 좋다. 필요할 때 찾아보기 귀찮으니 정리해 놓기로 한다. 이와 관련된 다양한 성능지표를 확인해 본다.</div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEid4gFMYYST6FBuhnZnTi_81U3sox36neNlc6Zl88lIXUyUXN5H8A9jDHJOYBqf0FIxS5oiOWpHUT4Cemd_IIhROVJhMvsmzVh7Mw6puJ__pXHubj9tmQuZDmDjBKGSAxKrqmkvxxZ3yo7ChuqqRYh3GFcDYWzKn_1yhcQLOl2KBeROGvVvhd_8tNnN9lm1\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"480\" data-original-width=\"720\" height=\"213\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEid4gFMYYST6FBuhnZnTi_81U3sox36neNlc6Zl88lIXUyUXN5H8A9jDHJOYBqf0FIxS5oiOWpHUT4Cemd_IIhROVJhMvsmzVh7Mw6puJ__pXHubj9tmQuZDmDjBKGSAxKrqmkvxxZ3yo7ChuqqRYh3GFcDYWzKn_1yhcQLOl2KBeROGvVvhd_8tNnN9lm1\" width=\"320\" /></a></div></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\"><b>개요</b></div><div style=\"text-align: left;\">많은 딥러닝 모델 개발의 경우, 성능 지표를 미리 고민하지 않고, 개발을 하였다가 뒤늦게 관련 기능을 추가하느라 고생하는 경우가 있다. 이런 경우를 대비해, 미리 어떤 지표가 있는 지 확인해 본다.</div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\"><b>본론</b></div><div style=\"text-align: left;\">가장 단순한 성능 지표부터 시작해, LLM에서 많이 사용되는 지표도 확인해 보자.&nbsp;</div><div style=\"text-align: left;\">여기서 수식은 n개의 데이터 셋을 가진 입력 변수 x에 대한 참 값 y가 있다고 가정한다. ŷ 은 입력 x 에 대한 f(x)의 결과로 가정한다. f(x)의 참 값은 y이다.&nbsp;</div><div style=\"text-align: left;\"><ul style=\"text-align: left;\"><li>MSE (Mean Squared Error) : 편차의 제곱을 n으로 나눈 편차 평균</li></ul></div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEh69EAXcrN8uA6Nmo9DcVlTgn4EJJ2f4Aqa9iWQenvcLJ2N9UL8l5_pHkB80SsIa5yno-r18Xi6uNeo7U5gm7FXtVpAKxU7_4-2dUSv1akMEiPhnZGDYS8NMa8d0zuimOwLjr0Lt8yILzR55oPyMWdfS7j8xqDmuLxT1N-RoW8V9tRtOCwYu0qM_JK-KUsd\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"85\" data-original-width=\"262\" height=\"64\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEh69EAXcrN8uA6Nmo9DcVlTgn4EJJ2f4Aqa9iWQenvcLJ2N9UL8l5_pHkB80SsIa5yno-r18Xi6uNeo7U5gm7FXtVpAKxU7_4-2dUSv1akMEiPhnZGDYS8NMa8d0zuimOwLjr0Lt8yILzR55oPyMWdfS7j8xqDmuLxT1N-RoW8V9tRtOCwYu0qM_JK-KUsd=w196-h64\" width=\"196\" /></a></div><ul style=\"text-align: left;\"><li>RMSE (Root Mean Squared Error): 예측값과 실제값의 편차 평균의 제곱근 값</li></ul><div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEgSQHJRltZB-1O4lzoVcSBAiL7NAhs3t6TEtxHNenraOIthWZl2H3e3GArY0nSY5NwAok0zx3p88tTwullR-i-AAuZZNGx2R1U0lDH3V5nArvaIfs6oJnIiKRiAnwh619tTqbOU2ocPS1vwPWdxaNPL2mWs0Y3AMeEd40nEITq2VEcwSdBXbpOCbwgheGkm\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"85\" data-original-width=\"307\" height=\"60\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEgSQHJRltZB-1O4lzoVcSBAiL7NAhs3t6TEtxHNenraOIthWZl2H3e3GArY0nSY5NwAok0zx3p88tTwullR-i-AAuZZNGx2R1U0lDH3V5nArvaIfs6oJnIiKRiAnwh619tTqbOU2ocPS1vwPWdxaNPL2mWs0Y3AMeEd40nEITq2VEcwSdBXbpOCbwgheGkm=w217-h60\" width=\"217\" /></a></div></div><ul style=\"text-align: left;\"><li>CvRMSE (Coefficent of Variation of RMSE): RMSE를 표준화하여 데이터 변동성을 알려주는 지표. RMSE의 백분율임. 데이터 평균에 대한 RMSE의 백분류로 계산</li></ul><div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEj2s3ScOnAhYLIEBw9NSKf3QWd2rGMoya9pPEHMm-VGGA5UV1aNQXo2iVcH9UlnrubLLV486LdFWuvbJezRn-7fF8uWqVhqFmuaWOsG4dwFnfYb6LbwlhdQV95S-8-BsHZEVDl-2CGFAQJMBjCELAsVyauUCJALAGEWFFxdKa3NYE9RxXcQcoQDfKGCKR7I\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"69\" data-original-width=\"303\" height=\"49\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEj2s3ScOnAhYLIEBw9NSKf3QWd2rGMoya9pPEHMm-VGGA5UV1aNQXo2iVcH9UlnrubLLV486LdFWuvbJezRn-7fF8uWqVhqFmuaWOsG4dwFnfYb6LbwlhdQV95S-8-BsHZEVDl-2CGFAQJMBjCELAsVyauUCJALAGEWFFxdKa3NYE9RxXcQcoQDfKGCKR7I=w218-h49\" width=\"218\" /></a></div></div><ul style=\"text-align: left;\"><li>MAE (Mean Absolute Error) : 편차값에 가까운 절대 차이 평균값</li></ul><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEjSaWNJ11wjB8baPUkxN5k1Ib2u0TnJnfsdpSXVkTm-I8CioNRokhfI72BBcV8b7LUCX9o3M7HOkarrql7SL_dTlSgPg4bnSZN_X2-OaT_Ap79OKeeBsbJ82NbZULsArpVaoIXny-A45IwbG1J2LQBUZNIyVZDYdgoLM4aII8ovy3JpVUsxskldFJOgB_UV\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"85\" data-original-width=\"265\" height=\"61\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEjSaWNJ11wjB8baPUkxN5k1Ib2u0TnJnfsdpSXVkTm-I8CioNRokhfI72BBcV8b7LUCX9o3M7HOkarrql7SL_dTlSgPg4bnSZN_X2-OaT_Ap79OKeeBsbJ82NbZULsArpVaoIXny-A45IwbG1J2LQBUZNIyVZDYdgoLM4aII8ovy3JpVUsxskldFJOgB_UV=w189-h61\" width=\"189\" /></a></div><ul style=\"text-align: left;\"><li>Accuray : 모델이 정확히 값을 예측했는 지 지표. 분류 모델 등 사용. 여기서 1은 조건 부합 시 참(1), 거짓(0)을 반환하는 indicator function 임</li></ul><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEjO1y7n-M_EW3a3wnrFQKqTNdyvMOYfKVgYxf1yTAgt1wFEhJBVYd0C4ayetZuIgXoz-M2WZ5gvTVlrceOvtJPmaqZurwNOBSmwWKNIOUfe6YnVMAYG8FkPX3AmXOPcL2oTRErhideW_bzB_uFhnB-FbUZ8SjEReolSj-DHuScBruZmzTBZgXodRb5ydHO0\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"89\" data-original-width=\"315\" height=\"62\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEjO1y7n-M_EW3a3wnrFQKqTNdyvMOYfKVgYxf1yTAgt1wFEhJBVYd0C4ayetZuIgXoz-M2WZ5gvTVlrceOvtJPmaqZurwNOBSmwWKNIOUfe6YnVMAYG8FkPX3AmXOPcL2oTRErhideW_bzB_uFhnB-FbUZ8SjEReolSj-DHuScBruZmzTBZgXodRb5ydHO0=w219-h62\" width=\"219\" /></a></div><ul style=\"text-align: left;\"><li>MAPE (Mean Abslute Percentage Error): 회귀분석 모델 예측에 주로 사용되는 지표.&nbsp;</li></ul></div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEhVLddPwwpb5fzh78A7OuFqjQcjW74tEgVtZZ5XWi---S8xLB9sFC-89hapWA2252PssVLYN9bNpg4CMdDra7JtHTbRoGiM5atC4m7XHna4odMw1EDDmXNSpOij2dFKtFY6k4jG78wUJVE8dvQqhSrZTxGFc83fWEd5pdaMMUGUq2l2UmEPIWOIK-OXcsKf\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"83\" data-original-width=\"336\" height=\"54\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEhVLddPwwpb5fzh78A7OuFqjQcjW74tEgVtZZ5XWi---S8xLB9sFC-89hapWA2252PssVLYN9bNpg4CMdDra7JtHTbRoGiM5atC4m7XHna4odMw1EDDmXNSpOij2dFKtFY6k4jG78wUJVE8dvQqhSrZTxGFc83fWEd5pdaMMUGUq2l2UmEPIWOIK-OXcsKf=w217-h54\" width=\"217\" /></a></div></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\">이외에, LLM에 주로 사용되는 ROGUE, BLEU, 컴퓨터 비전에 주로 사용되는 mAP, IoU, F1, call, recall 등 지표가 있다.&nbsp;</div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\"><br /></div>",
        "contentSnippet": "이 글은 인공지능 딥러닝 모델 성능 지표를 간략히 정리한 것이다. 개발 목적에 따라 다양한 딥러닝 모델을 사용하고, 그에 따라 적절한 성능 지표를 모니터링해 튜닝 등 품질을 개선하는 것이 좋다. 필요할 때 찾아보기 귀찮으니 정리해 놓기로 한다. 이와 관련된 다양한 성능지표를 확인해 본다.\n\n\n\n\n개요\n많은 딥러닝 모델 개발의 경우, 성능 지표를 미리 고민하지 않고, 개발을 하였다가 뒤늦게 관련 기능을 추가하느라 고생하는 경우가 있다. 이런 경우를 대비해, 미리 어떤 지표가 있는 지 확인해 본다.\n\n\n본론\n가장 단순한 성능 지표부터 시작해, LLM에서 많이 사용되는 지표도 확인해 보자. \n여기서 수식은 n개의 데이터 셋을 가진 입력 변수 x에 대한 참 값 y가 있다고 가정한다. ŷ 은 입력 x 에 대한 f(x)의 결과로 가정한다. f(x)의 참 값은 y이다. \n\nMSE (Mean Squared Error) : 편차의 제곱을 n으로 나눈 편차 평균\n\n\n\n\nRMSE (Root Mean Squared Error): 예측값과 실제값의 편차 평균의 제곱근 값\n\n\n\nCvRMSE (Coefficent of Variation of RMSE): RMSE를 표준화하여 데이터 변동성을 알려주는 지표. RMSE의 백분율임. 데이터 평균에 대한 RMSE의 백분류로 계산\n\n\n\nMAE (Mean Absolute Error) : 편차값에 가까운 절대 차이 평균값\n\n\n\nAccuray : 모델이 정확히 값을 예측했는 지 지표. 분류 모델 등 사용. 여기서 1은 조건 부합 시 참(1), 거짓(0)을 반환하는 indicator function 임\n\n\n\nMAPE (Mean Abslute Percentage Error): 회귀분석 모델 예측에 주로 사용되는 지표. \n\n\n\n\n\n이외에, LLM에 주로 사용되는 ROGUE, BLEU, 컴퓨터 비전에 주로 사용되는 mAP, IoU, F1, call, recall 등 지표가 있다.",
        "id": "tag:blogger.com,1999:blog-5201956450461596914.post-5149285106406844516",
        "isoDate": "2024-08-25T09:46:00.000Z"
      }
    ]
  },
  {
    "name": "권용진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권영재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김승호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김병환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for boyism Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성준의 린스타트업과 디자인씽킹",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권혁우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김준형",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강동혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고종범",
    "category": "개인",
    "posts": [
      {
        "creator": "고종범",
        "title": "가을이 되는 느낌? 독서",
        "link": "https://brunch.co.kr/@@24SO/45",
        "pubDate": "Mon, 26 Aug 2024 00:54:06 GMT",
        "author": "고종범",
        "content": "여유가 주는 바쁨 진행하던 프로젝트가 너무 잘 진행되어 여유가 생겼다. 1차 고개를 넘은 터라 한 달 정도 여유 있을 거라 생각했는데 2달은 여유가 있을 듯싶다. 그래서 그 여유를 즐기기 위해 그동안 정리 못하고 있던 것들을 정리하기 시작했다. 잔뜩 쌓였던 나의 주제 단지를 열어보니 생각보다 많은 주제가 있었다. 게다가 끝난 줄 알았던 주제에 꼬리가 붙어서",
        "contentSnippet": "여유가 주는 바쁨 진행하던 프로젝트가 너무 잘 진행되어 여유가 생겼다. 1차 고개를 넘은 터라 한 달 정도 여유 있을 거라 생각했는데 2달은 여유가 있을 듯싶다. 그래서 그 여유를 즐기기 위해 그동안 정리 못하고 있던 것들을 정리하기 시작했다. 잔뜩 쌓였던 나의 주제 단지를 열어보니 생각보다 많은 주제가 있었다. 게다가 끝난 줄 알았던 주제에 꼬리가 붙어서",
        "guid": "https://brunch.co.kr/@@24SO/45",
        "isoDate": "2024-08-26T00:54:06.000Z"
      }
    ]
  },
  {
    "name": "cheese10yun",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구자철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "FSS",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권동준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김용일",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도균",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김상훈",
    "category": "개인",
    "posts": [
      {
        "creator": "김상훈",
        "title": "Threads on week 33",
        "link": "https://interpiler.com/2024/08/20/threads-on-week-33/",
        "pubDate": "Tue, 20 Aug 2024 03:17:25 +0000",
        "content:encodedSnippet": "sanghoon_k08/17/2024\n“지난해 환경미화원 사상자는 ‘6439명’이다. 전국 환경미화원은 약 4만 명으로 집계되는데 연간 6명 중 1명이 산재를 당하는 셈이다.”\n“이웃인 우리의 반성도 필요하다. 종량제 봉투를 넘치게 채워 무겁게 만들고, 깨진 접시 같은 날카로운 물건을 아무렇게나 봉투에 담는 등 사소한 습관이 환경미화원을 크게 다치게 만든다고 한다. 환경미화원 연간 사상자 ‘6439명’. 이 숫자야말로 우리 사회의 진짜 안전 성적표란 생각이 든다.”\n[횡설수설/우경임]환경미화원 死傷 연 6000명\n\n\n\n\nsanghoon_k08/16/2024\n와이어드에서 조사한 팔로어 숫자에 따른 인플루언서 그래프. 빨간색은 공화당 쪽, 파란색은 민주당 쪽.팔로어 수로만 보면 약 2억 명에 가까운 팔로어를 확보한 일론 머스크가 모두를 과다대표하는 탓에 공화당이 인터넷을 지배하는 것처럼 보임. 실제로 머스크가 X를 이용해 사업과 정치를 넘나드는 모습을 보면 영향력이 대단한 것은 알 수 있지만, 플랫폼 문제도 있음.공화당 쪽 상위 인플루언서들은 X 또는 유튜브에서 활동, 하지만 민주당 쪽 상위 유튜버는 대부분 틱톡이 메인 플랫폼. 어찌보면 인터넷을 지배하는 것 같은 카말라 해리스 쪽 민주당 진영이 10대-20대 파티장인 틱톡만의 태풍 같기도 하고, 그냥 보수주의자들의 막말 대잔치 플랫폼 같은 X의 영향력이 실제 이상으로 대표되는 것 같기도 함. 복잡한 미디어 지형.\n\n\n\n\n\nsanghoon_k4d4 d08/16/2024\n세계 최고령 혹등고래 올드타이머(Old Timer) 이야기….가 아니고, 실제로는 세계 최고령 혹등고래의 나이를 추정하게 된 방법에 대한 기사.혹등고래는 꼬리 지느러미 사진으로 개체를 구분. 사람의 지문이나 얼굴처럼 개체별로 생김새가 다르기 때문. 과거에는 특정 혹등고래를 찾아내기 위해 연구자들이 직접 고래를 촬영하고 눈으로 비교했음.인터넷과 AI의 시대인 21세기에는 모든 게 달라짐. Happywhale이라는 사이트는 일반인으로부터 고래 사진을 제출받아 AI로 분석. 이렇게 사진을 올려준 사람들에겐 자신이 올린 사진과 동일 개체의 사진이 올라오면 그 내용을 계속 업데이트 해 줌. 고래가 언제 나타나 어디를 돌아다니며 어떻게 살아가는지 이해할 방법이 늘어난 것.꼬리지느러미를 분석하는데 쓰이는 알고리듬은 한국 개발자 박진모 님이 개발. 전 세계의 고래연구자들이 널리 쓰는 기술.\nHow the World’s Oldest Humpback Whale Has Survived Is a Mystery\n박진모님 인터뷰 blog.estsoft.co.kr/727, 해피웨일 사이트 happywhale.com\n혹등고래 등밖에 못 봤는데 꼬리지느러미라도 보는 게 쉬운 일이 아니었던 듯. 해피웨일 사이트에선 고래에게 위협을 가하지 않도록 적절한 단계를 지키는 여행사를 찾도록 권장. 세계고래연맹(WCA) 회원사를 추천한다고. 한국 인근에서는 오키나와의 혹등고래 관광이 유명한데, 불행히도 오키나와에는 WCA 회원사가 없는 듯.\n\nsanghoon_k6d6 days ago\n튜비(Tubi)라는 무료 스트리밍 서비스가 미국에서 폭발적인 인기. 넷플릭스가 지배하는 이 업계에서 처음엔 “내 컴퓨터에 바이러스가 깔리는 것 아닌가?”, “정말 무료 맞아?” 같은 의심을 들었지만 지금은 당당히 메이저 서비스가 됐음.- 유튜브, 넷플릭스, 아마존, 훌루 다음의 5위 서비스. 디즈니플러스, 애플티비 같은 서비스들이 모두 튜비보다 시청시간이 적음. – 수익성은 아직 물음표. 수익모델은 당연히 광고. – 낮은 비용이 핵심. 저예산 독립영화, 흘러간 옛 영화, 유명배우가 없는 영화 등이 주요 콘텐츠. – 오리지널 콘텐츠도 제작하는데 철저히 소수의 마니아층을 노리는 콘텐츠.점점 스트리밍 서비스들의 값이 올라가면서 조만간 데드크로스(스트리밍 신규가입자보다 해지가입자가 더 많은 상황)가 생길 가능성도 얘기되는 중. 튜비의 성장은 어찌 보면 당연. 생각해보면 왓챠도 10년째 버티며 아니메, 독립영화 등으로 틈새를 잡은 회사. 한국의 튜비가 될 수 있을까 궁금.\nThe Little Streamer That Could\n\nsanghoon_k08/13/2024\n인공지능이 길가메시 서사시의 번역을 돕기 시작. 수천개의 석판에 새겨진 설형문자가 해석되지 않은 상태로 남겨져 있었는데, 이 석판들을 디지털화한 다음 인공지능에게 번역하도록 시켜서 디테일을 빠르게 보강하는 중. 뿐만 아니라 비슷한 지역과 시기의 유물이 새로 발굴됐을 때 빠르게 해당 유물의 내용을 판단하고 다른 작품들과의 연관성을 파악하는데도 도움을 주고 있음.문과생들도 인공지능 정도는 다룰 줄 알아야 문학 공부를 제대로 해볼 수 있는 세상.\nPiecing Together an Ancient Epic Was Slow Work. Until A.I. Got Involved.\n\nsanghoon_k08/12/2024\n뉴욕타임즈가 메달 수 분석을 여러가지로 했는데, 읽다가 재미있는 부분이 있어서 거기만 발췌. 무기를 사용한 시합에서 한국의 성적을 보세요. 양궁과 사격, 펜싱 덕분. 이렇게 쪼개놓고 봐도 미국이 대부분 1등이지만 2020 도쿄올림픽 대비로 봐도 한국이 3위. 1위야 개최국 효과가 있는 프랑스고, 2위는 미국인데, 한국도 전 올림픽 대비 금메달 7개가 많고 전체 매달수도 12개가 많은 나라. 개인적으로도 가깝고 시차도 없었던 도쿄올림픽보다도 중계를 더 많이 봤던 듯.",
        "dc:creator": "김상훈",
        "comments": "https://interpiler.com/2024/08/20/threads-on-week-33/#respond",
        "content": "sanghoon_k08/17/2024 “지난해 환경미화원 사상자는 ‘6439명’이다. 전국 환경미화원은 약 4만 명으로 집계되는데 연간 6명 중 1명이 산재를 당하는 셈이다.” “이웃인 우리의 반성도 필요하다. 종량제 봉투를 넘치게 채워 무겁게 만들고, 깨진 접시 같은 날카로운 물건을 아무렇게나 봉투에 담는 등 사소한 습관이 환경미화원을 크게 다치게 만든다고 한다. 환경미화원 연간 사상자 ‘6439명’. 이 숫자야말로 우리 사회의 진짜 안전 성적표란 &#8230; <a href=\"https://interpiler.com/2024/08/20/threads-on-week-33/\" class=\"more-link\">계속 읽기 <span class=\"screen-reader-text\">Threads on week&#160;33</span> <span class=\"meta-nav\">\t</span></a>",
        "contentSnippet": "sanghoon_k08/17/2024 “지난해 환경미화원 사상자는 ‘6439명’이다. 전국 환경미화원은 약 4만 명으로 집계되는데 연간 6명 중 1명이 산재를 당하는 셈이다.” “이웃인 우리의 반성도 필요하다. 종량제 봉투를 넘치게 채워 무겁게 만들고, 깨진 접시 같은 날카로운 물건을 아무렇게나 봉투에 담는 등 사소한 습관이 환경미화원을 크게 다치게 만든다고 한다. 환경미화원 연간 사상자 ‘6439명’. 이 숫자야말로 우리 사회의 진짜 안전 성적표란 … 계속 읽기 Threads on week 33",
        "guid": "http://interpiler.com/?p=1504",
        "categories": [
          "That's IT"
        ],
        "isoDate": "2024-08-20T03:17:25.000Z"
      }
    ]
  },
  {
    "name": "김민석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김동우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권윤학",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김만수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "엘키",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김슬기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김광현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김영우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강명훈",
    "category": "개인",
    "posts": [
      {
        "title": "비율 계산",
        "link": "https://kangmyounghun.blogspot.com/2024/08/blog-post_22.html",
        "pubDate": "2024-08-22T08:58:00.001Z",
        "author": "강명훈",
        "content": "<div>프로세스 단위별 합산 구하고,</div><div><br /></div>\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgOhXs36W9US2RiekjU5y8DAa8GsEORl5sxBBmgaw5HWBInPzfuQetcjYRWg7SV6rpPWzMjOqxAxGT0xFogcUkWYGgc4HD5Oibw80V1Huyo7K3Vc4aGbWBCaV9WJy65dPmsqWoAgaNgTWkkGTcOHHAaFN7amC7fywBDesHcp5u1StPRUtUAP128JSkh0feq/s1240/percent.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"720\" data-original-width=\"1240\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgOhXs36W9US2RiekjU5y8DAa8GsEORl5sxBBmgaw5HWBInPzfuQetcjYRWg7SV6rpPWzMjOqxAxGT0xFogcUkWYGgc4HD5Oibw80V1Huyo7K3Vc4aGbWBCaV9WJy65dPmsqWoAgaNgTWkkGTcOHHAaFN7amC7fywBDesHcp5u1StPRUtUAP128JSkh0feq/s520/percent.png\" width=\"520\" /></a></div><div><br /></div><div><span><a name='more'></a></span>총합 <a href=\"https://docs.splunk.com/Documentation/Splunk/9.3.0/SearchReference/Appendcols\" target=\"_blank\">필드 추가</a> 후,</div><br />\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEimln5NpC3Fdsuv5daWi5vziXQDbwY46Nvz3Zh_kgNQyg6o_Q4jLmahA_DvVO6YdsXWjCjOPk3Qf1h3YUuH-3N3Z7iPCNIG8QlNAD0HZhXpJnAzkSCY03YXRMLs1EmZAjfGSqa2XIojFMjuyZ1s9p_Mpdmc6d7zc1Q2iBTWVLKcncpPbhZzJDEKmCNpXXzv/s1240/percent2.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"720\" data-original-width=\"1240\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEimln5NpC3Fdsuv5daWi5vziXQDbwY46Nvz3Zh_kgNQyg6o_Q4jLmahA_DvVO6YdsXWjCjOPk3Qf1h3YUuH-3N3Z7iPCNIG8QlNAD0HZhXpJnAzkSCY03YXRMLs1EmZAjfGSqa2XIojFMjuyZ1s9p_Mpdmc6d7zc1Q2iBTWVLKcncpPbhZzJDEKmCNpXXzv/s520/percent2.png\" width=\"520\" /></a></div><br />\n<div>비율 계산.</div><div><br /></div><div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh4dpHdY-hZJxGnhlSoMHPWA6c0CK6WBgxavdAbIBWIiUFaA_vaFZuvXT6VDNr8WFILy6PByRHI6wSC1s-YI6Bo7PbulvuXoMwEDS4MqrwBB1jSF-nwmm2jl3JktWxINodvUqtb1fLocQwMjp6bBzpIiueU0QKCnScM7pdNuO5whFicWfCxcS1sHCH4XJsw/s1240/percent3.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"720\" data-original-width=\"1240\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh4dpHdY-hZJxGnhlSoMHPWA6c0CK6WBgxavdAbIBWIiUFaA_vaFZuvXT6VDNr8WFILy6PByRHI6wSC1s-YI6Bo7PbulvuXoMwEDS4MqrwBB1jSF-nwmm2jl3JktWxINodvUqtb1fLocQwMjp6bBzpIiueU0QKCnScM7pdNuO5whFicWfCxcS1sHCH4XJsw/s520/percent3.png\" width=\"520\" /></a></div><div><br /></div><div>아니면 이벤트 단위로 총합, 단위별 합산 추가 후 계산.</div></div><div><br /></div><div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjkrY1Cl8fh7lL04rj0SgMxiiaV8xXoTDk6VhMoI0lv27mzptIPny21eod4yLhZnrQHzEZfeKKdWzw_dXPoVUmaIJ5WtT_nCYndvk6ecNisXTtRXY9mVM7Yx3eTRden5ejxJVHEw2PERBKQ10LmbVTKfliPgnzNvUlHLaSwiVLkjQnijIscvdmHHxYdkxWJ/s1280/percent4.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"666\" data-original-width=\"1280\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjkrY1Cl8fh7lL04rj0SgMxiiaV8xXoTDk6VhMoI0lv27mzptIPny21eod4yLhZnrQHzEZfeKKdWzw_dXPoVUmaIJ5WtT_nCYndvk6ecNisXTtRXY9mVM7Yx3eTRden5ejxJVHEw2PERBKQ10LmbVTKfliPgnzNvUlHLaSwiVLkjQnijIscvdmHHxYdkxWJ/s520/percent4.png\" width=\"520\" /></a></div><div><br /></div><div>그냥 <a href=\"https://docs.splunk.com/Documentation/Splunk/9.3.0/SearchReference/Top\" target=\"_blank\">top</a> 쓰자.</div><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgN-n-UihLnfQ5CN9jamjwW55gQsHGen9R34TVjvnRmApkAp-FoKQPybxnUTfCRAph0GwlCC2Wx-Q_uwJ6mYVSDf211B6_FX0_7vt4_oawkkIHsL_ea9iXkKVuNVGOrLSsrr_mowxmwCU4e4nwdCHq4WwssJTWOahGXe0y4Fi8VEZ-q0MNJkzRoo9Q_6_I-/s1280/percent5.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"554\" data-original-width=\"1280\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgN-n-UihLnfQ5CN9jamjwW55gQsHGen9R34TVjvnRmApkAp-FoKQPybxnUTfCRAph0GwlCC2Wx-Q_uwJ6mYVSDf211B6_FX0_7vt4_oawkkIHsL_ea9iXkKVuNVGOrLSsrr_mowxmwCU4e4nwdCHq4WwssJTWOahGXe0y4Fi8VEZ-q0MNJkzRoo9Q_6_I-/s520/percent5.png\" width=\"520\" /></a></div><div><br /></div></div><div><div><b>관련 글</b></div><div><ul><li><a href=\"https://kangmyounghun.blogspot.com/2021/08/splunk-eval-rex.html\">Splunk의 eval과 rex</a></li></ul></div></div>",
        "contentSnippet": "프로세스 단위별 합산 구하고,\n\n\n\n\n\n총합 필드 추가 후,\n\n\n\n비율 계산.\n\n\n\n\n\n아니면 이벤트 단위로 총합, 단위별 합산 추가 후 계산.\n\n\n\n\n\n\n그냥 top 쓰자.\n\n\n\n\n\n관련 글\n\nSplunk의 eval과 rex",
        "id": "tag:blogger.com,1999:blog-2597780270996323853.post-2918153940603938022",
        "isoDate": "2024-08-22T08:58:00.001Z"
      }
    ]
  },
  {
    "name": "김민장",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕홍",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성중",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구교준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고명환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성희",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강병수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김봉현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강형석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수로",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강미경",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강진우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권민재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태관",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도곤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "칡토스의 게임 개발",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김놀부",
    "category": "개인",
    "posts": []
  },
  {
    "name": "프리웨어 이야기",
    "category": "개인",
    "posts": [
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "윈도우용 추천 프리웨어 (2024.8.26) 모니터밝기조절, 파일관리, Linux에뮬레이션, CAD뷰어, 데이터시각화, 프로젝트관리",
        "link": "http://muzbox.tistory.com/483462",
        "pubDate": "Mon, 26 Aug 2024 08:37:38 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483462#entry483462comment",
        "content": "<p style=\"text-align: left;\" data-ke-size=\"size18\"><span style=\"background-color: #ffffff; color: #0d0d0d; text-align: start;\">&nbsp;네이버 소프트웨어와 같은 프로그램 소개 사이트가 종료된 후, 윈도우 운영체제를 사용하는 이용자들을 위해 공개 프리웨어 및 오픈소스 프로그램을 소개합니다. 유용한 무료 소프트웨어를 찾고자 하는 사용자들에게 정기적으로 알찬 정보를 제공합니다.</span></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"freeware.png\" data-origin-width=\"500\" data-origin-height=\"500\"><span data-url=\"https://blog.kakaocdn.net/dn/l9JVa/btsJe7uOawY/WatS3qwKv992v68b9uBeE0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/l9JVa/btsJe7uOawY/WatS3qwKv992v68b9uBeE0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/l9JVa/btsJe7uOawY/WatS3qwKv992v68b9uBeE0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fl9JVa%2FbtsJe7uOawY%2FWatS3qwKv992v68b9uBeE0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"윈도우용 추천 프리웨어 (2024.8.26)\" data-filename=\"freeware.png\" data-origin-width=\"500\" data-origin-height=\"500\"/></span></figure>\n</p>\n<p style=\"text-align: left;\" data-ke-size=\"size18\">&nbsp;</p>\n<p style=\"text-align: left;\" data-ke-size=\"size18\"><span style=\"color: #333333; text-align: left;\">&nbsp;윈도우용 응용프로그램 (Application)은 수없이 많은 종류가 많은 개발자들에 의해 하루에도 수백,수천개가 새로 출시되고 그보다 더 많은 수의 프로그램들이 업데이트 됩니다. 이들 응용프로그램 (Application)은 비율을 지불해야하는<span>&nbsp;</span></span><b><span style=\"color: #009a87;\">상용프로그램</span></b><span style=\"color: #333333; text-align: left;\">과 정품 구매를 확대하기 위해 공급하는 일종의 샘플 개념의<span>&nbsp;</span></span><span style=\"color: #ee2323;\"><b>쉐어웨어</b></span><span style=\"color: #333333; text-align: left;\">, 무료로 사용할 수 있는<span>&nbsp;</span></span><b><span style=\"color: #ef6f53;\">프리웨어</span></b>등으로 크게 3가지로 나뉘게 되는데요.</p>\n<p style=\"text-align: left;\" data-ke-size=\"size18\"><br />&nbsp;물론 프리웨어에도 개인만 사용할 있다던가, 기업이나 관공서에서도 사용이 가능하다던가, 소스까지 같이 공개하여 맘대로 수정과 배포가 가능한 완전 무료등의 추가 분류가 필요합니다. 하지만, 개발자가 공개하는 무료배포의 의미가 정확하지 않는 프로그램도 많고, 저작권의 정의도 각양각색이라 본 블로그에서 소개하는 프리웨어도 <span style=\"color: #006dd7;\"><b>최대한 확인이 가능한 범위에서 개인 또는 기업에서 사용가능한지를 구분하여 소개</b></span>하고 있습니다.</p>\n<p style=\"text-align: left;\" data-ke-size=\"size18\">&nbsp;</p>\n<p style=\"text-align: left;\" data-ke-size=\"size18\">&nbsp;</p>\n<p style=\"text-align: center;\" data-ke-size=\"size18\">'어떤오후의 프리웨어 이야기'에서 추천하는<br /><span style=\"color: #409d00;\">&nbsp;<b>2024년 8월 26일자 공개자료실 윈도우용 추천 프리웨어</b></span>입니다.</p>\n<p id=\"no_1\" data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><i><b>1. Bright Master (트레이 아이콘에서 휠 회전으로 모니터 밝기 조정)<br /></b></i></span></h2>\n<p data-ke-size=\"size18\">&nbsp; 설치가&nbsp;필요&nbsp;없는&nbsp;모니터&nbsp;밝기&nbsp;조절&nbsp;도구입니다. <br />DDC/CI를&nbsp;지원하는&nbsp;외부&nbsp;모니터와&nbsp;WMI&nbsp;서비스가&nbsp;비활성화되지&nbsp;않은&nbsp;노트북,&nbsp;올인원&nbsp;PC,&nbsp;윈도우&nbsp;태블릿의&nbsp;내장&nbsp;디스플레이에서&nbsp;작동합니다. <br />주요&nbsp;기능으로는&nbsp;모든&nbsp;기기의&nbsp;동기화된&nbsp;밝기&nbsp;변경,&nbsp;제3자&nbsp;소프트웨어에&nbsp;의한&nbsp;밝기&nbsp;변경&nbsp;추적,&nbsp;디지털&nbsp;밝기&nbsp;표시,&nbsp;자동&nbsp;시작,&nbsp;마우스&nbsp;휠을&nbsp;이용한&nbsp;밝기&nbsp;조절,&nbsp;밝기&nbsp;조절&nbsp;단계&nbsp;선택,&nbsp;한&nbsp;번의&nbsp;클릭으로&nbsp;최소&nbsp;밝기&nbsp;설정&nbsp;등이&nbsp;있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Bright Master.png\" data-origin-width=\"504\" data-origin-height=\"304\"><span data-url=\"https://blog.kakaocdn.net/dn/CCuKC/btsJfiXcAQ5/hkfwcbBPBrbsN3fro1pF70/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/CCuKC/btsJfiXcAQ5/hkfwcbBPBrbsN3fro1pF70/img.png\"><img src=\"https://blog.kakaocdn.net/dn/CCuKC/btsJfiXcAQ5/hkfwcbBPBrbsN3fro1pF70/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FCCuKC%2FbtsJfiXcAQ5%2FhkfwcbBPBrbsN3fro1pF70%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"Bright Master.png\" data-origin-width=\"504\" data-origin-height=\"304\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">▶프리웨어 - 개인</p>\n<p data-ke-size=\"size18\">▶ Windows 10/11</p>\n<p data-ke-size=\"size18\">▶무료 다운로드◀</p>\n<figure id=\"og_1724628763665\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"Bright Master / Screen dimmer\" data-og-description=\"Ru Bright Master Simple screen dimmer The program is designed to adjust the brightness of monitors, laptop displays and other equipment. Runs on Windows 7+ and does not require installation. Works with all external monitors that have DDC/CI support, as wel\" data-og-host=\"brightmaster.ru\" data-og-source-url=\"https://brightmaster.ru/en\" data-og-url=\"https://brightmaster.ru/en\" data-og-image=\"\"><a href=\"https://brightmaster.ru/en\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://brightmaster.ru/en\">\n<div class=\"og-image\" style=\"background-image: url();\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">Bright Master / Screen dimmer</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">Ru Bright Master Simple screen dimmer The program is designed to adjust the brightness of monitors, laptop displays and other equipment. Runs on Windows 7+ and does not require installation. Works with all external monitors that have DDC/CI support, as wel</p>\n<p class=\"og-host\" data-ke-size=\"size16\">brightmaster.ru</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"no_2\" data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><i><b>2. Cygwin (Linux 기능을 사용할 수 있는 유연한 에뮬레이션 도구)</b></i></span></h2>\n<p data-ke-size=\"size18\">&nbsp; Windows&nbsp;사용자가&nbsp;Linux의&nbsp;기능을&nbsp;경험할&nbsp;수&nbsp;있게&nbsp;해주는&nbsp;에뮬레이션&nbsp;레이어입니다. <br />사용자는&nbsp;원하는&nbsp;Linux&nbsp;기능을&nbsp;선택하여&nbsp;설치할&nbsp;수&nbsp;있으며,&nbsp;프로그램은&nbsp;사용자&nbsp;친화적이고&nbsp;잘&nbsp;조직된&nbsp;구조를&nbsp;가지고&nbsp;있습니다.&nbsp;오디오&nbsp;드라이버,&nbsp;그래픽&nbsp;소프트웨어,&nbsp;LXDE,&nbsp;GNOME,&nbsp;KDE&nbsp;등&nbsp;다양한&nbsp;Linux&nbsp;기능을&nbsp;제공합니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Cygwin.png\" data-origin-width=\"1083\" data-origin-height=\"668\"><span data-url=\"https://blog.kakaocdn.net/dn/b2AN3z/btsJfGXIURN/NeV5FdKmPcffTyNmWppCfk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/b2AN3z/btsJfGXIURN/NeV5FdKmPcffTyNmWppCfk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/b2AN3z/btsJfGXIURN/NeV5FdKmPcffTyNmWppCfk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb2AN3z%2FbtsJfGXIURN%2FNeV5FdKmPcffTyNmWppCfk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"Cygwin.png\" data-origin-width=\"1083\" data-origin-height=\"668\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">▶프리웨어 - 개인/기업(오픈소스)</p>\n<p data-ke-size=\"size18\">▶Windows 10/11</p>\n<p data-ke-size=\"size18\">▶무료 다운로드 ◀</p>\n<figure id=\"og_1724628796923\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"Cygwin\" data-og-description=\"Cygwin Get that Linux feeling - on Windows This is the home of the Cygwin project What... ...is it? Cygwin is: a large collection of GNU and Open Source tools which provide functionality similar to a Linux distribution on Windows. a DLL (cygwin1.dll) which\" data-og-host=\"www.cygwin.com\" data-og-source-url=\"https://www.cygwin.com/\" data-og-url=\"https://www.cygwin.com/\" data-og-image=\"\"><a href=\"https://www.cygwin.com/\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://www.cygwin.com/\">\n<div class=\"og-image\" style=\"background-image: url();\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">Cygwin</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">Cygwin Get that Linux feeling - on Windows This is the home of the Cygwin project What... ...is it? Cygwin is: a large collection of GNU and Open Source tools which provide functionality similar to a Linux distribution on Windows. a DLL (cygwin1.dll) which</p>\n<p class=\"og-host\" data-ke-size=\"size16\">www.cygwin.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"no_3\" data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><i><b>3. Rename Master (다기능적인&nbsp;파일&nbsp;이름&nbsp;변경&nbsp;솔루션)</b></i></span></h2>\n<p data-ke-size=\"size18\">&nbsp;사용자가&nbsp;다양한&nbsp;도구를&nbsp;통해&nbsp;파일&nbsp;이름을&nbsp;효율적이고&nbsp;접근하기&nbsp;쉽게&nbsp;변경할&nbsp;수&nbsp;있게&nbsp;해주는&nbsp;프로그램입니다.&nbsp;주요&nbsp;기능은&nbsp;'Renaming&nbsp;Script'&nbsp;탭에서&nbsp;찾을&nbsp;수&nbsp;있으며,&nbsp;단어/숫자&nbsp;제거,&nbsp;표현&nbsp;변경,&nbsp;기존&nbsp;이름&nbsp;교체,&nbsp;카운터&nbsp;추가&nbsp;등&nbsp;다양한&nbsp;옵션을&nbsp;제공합니다. <br />프로그램은&nbsp;일반&nbsp;사용자를&nbsp;위한&nbsp;기본&nbsp;기능뿐만&nbsp;아니라&nbsp;고급&nbsp;사용자를&nbsp;위한&nbsp;'Textfile&nbsp;Wizard'&nbsp;같은&nbsp;기능도&nbsp;제공합니다.&nbsp;전반적으로&nbsp;Rename&nbsp;Master는&nbsp;사용하기&nbsp;쉬우면서도&nbsp;고급&nbsp;사용자를&nbsp;위한&nbsp;충분한&nbsp;구성&nbsp;옵션을&nbsp;제공하는&nbsp;신뢰할&nbsp;수&nbsp;있는&nbsp;종합&nbsp;솔루션입니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Rename Master.png\" data-origin-width=\"1030\" data-origin-height=\"647\"><span data-url=\"https://blog.kakaocdn.net/dn/vUqbY/btsJfElmKdd/sEbM4woMxpjLG6fgE8TpTk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/vUqbY/btsJfElmKdd/sEbM4woMxpjLG6fgE8TpTk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/vUqbY/btsJfElmKdd/sEbM4woMxpjLG6fgE8TpTk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FvUqbY%2FbtsJfElmKdd%2FsEbM4woMxpjLG6fgE8TpTk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"Rename Master.png\" data-origin-width=\"1030\" data-origin-height=\"647\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">▶프리웨어 - 개인</p>\n<p data-ke-size=\"size18\">▶Windows 10/11&nbsp;</p>\n<p data-ke-size=\"size18\">▶무료 다운로드 ◀</p>\n<figure id=\"og_1724628842166\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"JoeJoe's freeware utilities - [Rename Master]\" data-og-description=\"Rename Master is a freeware utility designed to rename multiple files with a just few clicks. Anyone that has worked with websites, file archives, or collections of music, videos, or pictures has probably spent way too much time renaming hundreds of files.\" data-og-host=\"www.joejoesoft.com\" data-og-source-url=\"https://www.joejoesoft.com/vcms/108/\" data-og-url=\"https://www.joejoesoft.com/vcms/108/\" data-og-image=\"\"><a href=\"https://www.joejoesoft.com/vcms/108/\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://www.joejoesoft.com/vcms/108/\">\n<div class=\"og-image\" style=\"background-image: url();\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">JoeJoe's freeware utilities - [Rename Master]</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">Rename Master is a freeware utility designed to rename multiple files with a just few clicks. Anyone that has worked with websites, file archives, or collections of music, videos, or pictures has probably spent way too much time renaming hundreds of files.</p>\n<p class=\"og-host\" data-ke-size=\"size16\">www.joejoesoft.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"no_4\" data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><i><b>4. VariCAD Viewer (다기능&nbsp;CAD&nbsp;파일&nbsp;뷰어)<br /></b></i></span></h2>\n<p data-ke-size=\"size18\">&nbsp;단순히&nbsp;CAD&nbsp;도면을&nbsp;보는&nbsp;것&nbsp;이상의&nbsp;기능을&nbsp;제공합니다.&nbsp;2D&nbsp;DWG,&nbsp;3D&nbsp;STEP,&nbsp;2D/3D&nbsp;VariCAD&nbsp;등&nbsp;다양한&nbsp;형식의&nbsp;파일을&nbsp;지원하며,&nbsp;간단한&nbsp;조정과&nbsp;인쇄&nbsp;기능도&nbsp;갖추고&nbsp;있습니다.&nbsp;이&nbsp;프로그램은&nbsp;3D&nbsp;모델링에&nbsp;대해&nbsp;잘&nbsp;아는&nbsp;전문가들을&nbsp;위해&nbsp;설계되었습니다.</p>\n<p data-ke-size=\"size18\">&nbsp;인터페이스는 현대적이지만 다양한 기능으로 인해 다소 복잡해 보일 수 있습니다. 그러나 CAD 경험이 있는 사용자라면 직관적으로 사용할 수 있을 것입니다. 도구 모음의 배치를 사용자가 원하는 대로 조정할 수 있는 것도 장점입니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"VariCAD Viewer.png\" data-origin-width=\"1360\" data-origin-height=\"757\"><span data-url=\"https://blog.kakaocdn.net/dn/Zxvkp/btsJeQ7R4Ia/5zkpqgQItCCEUbKkidGFhk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/Zxvkp/btsJeQ7R4Ia/5zkpqgQItCCEUbKkidGFhk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/Zxvkp/btsJeQ7R4Ia/5zkpqgQItCCEUbKkidGFhk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FZxvkp%2FbtsJeQ7R4Ia%2F5zkpqgQItCCEUbKkidGFhk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"VariCAD Viewer.png\" data-origin-width=\"1360\" data-origin-height=\"757\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">▶프리웨어 - 개인</p>\n<p data-ke-size=\"size18\">▶Windows 10/11</p>\n<p data-ke-size=\"size18\">▶무료 다운로드 ◀</p>\n<figure id=\"og_1724628874152\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"Products | VariCAD - 3D/2D CAD system\" data-og-description=\"Products VariCAD - 3D / 2D mechanical CAD software We have a simple strategy - to sell VariCAD, with all its features, for one very affordable price. VariCAD is the best value you will find anywhere for this type of modeling and designing software. VariCAD\" data-og-host=\"www.varicad.com\" data-og-source-url=\"https://www.varicad.com/en/home/products/products/\" data-og-url=\"https://www.varicad.com/en/home/products/products/\" data-og-image=\"\"><a href=\"https://www.varicad.com/en/home/products/products/\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://www.varicad.com/en/home/products/products/\">\n<div class=\"og-image\" style=\"background-image: url();\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">Products | VariCAD - 3D/2D CAD system</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">Products VariCAD - 3D / 2D mechanical CAD software We have a simple strategy - to sell VariCAD, with all its features, for one very affordable price. VariCAD is the best value you will find anywhere for this type of modeling and designing software. VariCAD</p>\n<p class=\"og-host\" data-ke-size=\"size16\">www.varicad.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"no_5\" data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><i><b>5. TreeSheets (다목적 데이터 조직화 및 시각화 도구)</b></i></span></h2>\n<p data-ke-size=\"size18\">&nbsp; 스프레드시트,&nbsp;마인드맵,&nbsp;노트&nbsp;애플리케이션의&nbsp;기능을&nbsp;하나의&nbsp;사용하기&nbsp;쉬운&nbsp;인터페이스로&nbsp;결합한&nbsp;프로그램입니다.&nbsp;복잡한&nbsp;데이터&nbsp;구조를&nbsp;쉽게&nbsp;다룰&nbsp;수&nbsp;있는&nbsp;것이&nbsp;주요&nbsp;특징입니다.</p>\n<p data-ke-size=\"size18\"><br />이&nbsp;프로그램은&nbsp;프로젝트&nbsp;관리,&nbsp;일정&nbsp;계획,&nbsp;브레인스토밍,&nbsp;할&nbsp;일&nbsp;목록&nbsp;작성&nbsp;등&nbsp;다양한&nbsp;용도로&nbsp;사용할&nbsp;수&nbsp;있습니다.&nbsp;사용자는&nbsp;데이터를&nbsp;계층적&nbsp;트리,&nbsp;스프레드시트&nbsp;그리드,&nbsp;마인드맵&nbsp;등&nbsp;다양한&nbsp;형태로&nbsp;시각화할&nbsp;수&nbsp;있습니다. <br />또한&nbsp;색상과&nbsp;테두리&nbsp;등을&nbsp;사용자&nbsp;지정하여&nbsp;시트의&nbsp;외관을&nbsp;개선할&nbsp;수&nbsp;있으며,&nbsp;작업을&nbsp;우선순위화하고&nbsp;마감일을&nbsp;설정하는&nbsp;등의&nbsp;기능을&nbsp;통해&nbsp;생산성을&nbsp;높일&nbsp;수&nbsp;있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"TreeSheets.png\" data-origin-width=\"1149\" data-origin-height=\"761\"><span data-url=\"https://blog.kakaocdn.net/dn/bareS8/btsJelm7E7B/nMJiF5wlkyZskOHMQ57w20/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bareS8/btsJelm7E7B/nMJiF5wlkyZskOHMQ57w20/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bareS8/btsJelm7E7B/nMJiF5wlkyZskOHMQ57w20/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbareS8%2FbtsJelm7E7B%2FnMJiF5wlkyZskOHMQ57w20%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"TreeSheets.png\" data-origin-width=\"1149\" data-origin-height=\"761\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">▶프리웨어 - 개인/기업 (오픈소스)</p>\n<p data-ke-size=\"size18\">▶Windows 10/11</p>\n<p data-ke-size=\"size18\">▶무료 다운로드 ◀</p>\n<figure id=\"og_1724628900387\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"TreeSheets\" data-og-description=\"Open Source Free Form Data Organizer (Hierarchical Spreadsheet) D O W N L O A D : Download LATEST from github releases: Windows / OS X / Linux Click HERE, pick your platform from the latest release. &nbsp; A &quot;hierarchical spreadsheet&quot; that is a great replaceme\" data-og-host=\"strlen.com\" data-og-source-url=\"https://strlen.com/treesheets/\" data-og-url=\"https://strlen.com/treesheets/\" data-og-image=\"https://scrap.kakaocdn.net/dn/bndYPd/hyWSfzKILl/YLEhMi5yuQXXxgdNMPthdk/img.png?width=607&amp;height=498&amp;face=0_0_607_498\"><a href=\"https://strlen.com/treesheets/\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://strlen.com/treesheets/\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/bndYPd/hyWSfzKILl/YLEhMi5yuQXXxgdNMPthdk/img.png?width=607&amp;height=498&amp;face=0_0_607_498');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">TreeSheets</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">Open Source Free Form Data Organizer (Hierarchical Spreadsheet) D O W N L O A D : Download LATEST from github releases: Windows / OS X / Linux Click HERE, pick your platform from the latest release. &nbsp; A \"hierarchical spreadsheet\" that is a great replaceme</p>\n<p class=\"og-host\" data-ke-size=\"size16\">strlen.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "네이버 소프트웨어와 같은 프로그램 소개 사이트가 종료된 후, 윈도우 운영체제를 사용하는 이용자들을 위해 공개 프리웨어 및 오픈소스 프로그램을 소개합니다. 유용한 무료 소프트웨어를 찾고자 하는 사용자들에게 정기적으로 알찬 정보를 제공합니다.\n\n\n \n 윈도우용 응용프로그램 (Application)은 수없이 많은 종류가 많은 개발자들에 의해 하루에도 수백,수천개가 새로 출시되고 그보다 더 많은 수의 프로그램들이 업데이트 됩니다. 이들 응용프로그램 (Application)은 비율을 지불해야하는 상용프로그램과 정품 구매를 확대하기 위해 공급하는 일종의 샘플 개념의 쉐어웨어, 무료로 사용할 수 있는 프리웨어등으로 크게 3가지로 나뉘게 되는데요.\n 물론 프리웨어에도 개인만 사용할 있다던가, 기업이나 관공서에서도 사용이 가능하다던가, 소스까지 같이 공개하여 맘대로 수정과 배포가 가능한 완전 무료등의 추가 분류가 필요합니다. 하지만, 개발자가 공개하는 무료배포의 의미가 정확하지 않는 프로그램도 많고, 저작권의 정의도 각양각색이라 본 블로그에서 소개하는 프리웨어도 최대한 확인이 가능한 범위에서 개인 또는 기업에서 사용가능한지를 구분하여 소개하고 있습니다.\n \n \n'어떤오후의 프리웨어 이야기'에서 추천하는\n 2024년 8월 26일자 공개자료실 윈도우용 추천 프리웨어입니다.\n \n \n1. Bright Master (트레이 아이콘에서 휠 회전으로 모니터 밝기 조정)\n\n  설치가 필요 없는 모니터 밝기 조절 도구입니다. \nDDC/CI를 지원하는 외부 모니터와 WMI 서비스가 비활성화되지 않은 노트북, 올인원 PC, 윈도우 태블릿의 내장 디스플레이에서 작동합니다. \n주요 기능으로는 모든 기기의 동기화된 밝기 변경, 제3자 소프트웨어에 의한 밝기 변경 추적, 디지털 밝기 표시, 자동 시작, 마우스 휠을 이용한 밝기 조절, 밝기 조절 단계 선택, 한 번의 클릭으로 최소 밝기 설정 등이 있습니다.\n\n\n▶프리웨어 - 개인\n▶ Windows 10/11\n▶무료 다운로드◀\n\n \nBright Master / Screen dimmer\nRu Bright Master Simple screen dimmer The program is designed to adjust the brightness of monitors, laptop displays and other equipment. Runs on Windows 7+ and does not require installation. Works with all external monitors that have DDC/CI support, as wel\nbrightmaster.ru\n\n \n \n \n \n \n \n2. Cygwin (Linux 기능을 사용할 수 있는 유연한 에뮬레이션 도구)\n  Windows 사용자가 Linux의 기능을 경험할 수 있게 해주는 에뮬레이션 레이어입니다. \n사용자는 원하는 Linux 기능을 선택하여 설치할 수 있으며, 프로그램은 사용자 친화적이고 잘 조직된 구조를 가지고 있습니다. 오디오 드라이버, 그래픽 소프트웨어, LXDE, GNOME, KDE 등 다양한 Linux 기능을 제공합니다.\n\n\n▶프리웨어 - 개인/기업(오픈소스)\n▶Windows 10/11\n▶무료 다운로드 ◀\n\n \nCygwin\nCygwin Get that Linux feeling - on Windows This is the home of the Cygwin project What... ...is it? Cygwin is: a large collection of GNU and Open Source tools which provide functionality similar to a Linux distribution on Windows. a DLL (cygwin1.dll) which\nwww.cygwin.com\n\n \n \n \n \n \n \n3. Rename Master (다기능적인 파일 이름 변경 솔루션)\n 사용자가 다양한 도구를 통해 파일 이름을 효율적이고 접근하기 쉽게 변경할 수 있게 해주는 프로그램입니다. 주요 기능은 'Renaming Script' 탭에서 찾을 수 있으며, 단어/숫자 제거, 표현 변경, 기존 이름 교체, 카운터 추가 등 다양한 옵션을 제공합니다. \n프로그램은 일반 사용자를 위한 기본 기능뿐만 아니라 고급 사용자를 위한 'Textfile Wizard' 같은 기능도 제공합니다. 전반적으로 Rename Master는 사용하기 쉬우면서도 고급 사용자를 위한 충분한 구성 옵션을 제공하는 신뢰할 수 있는 종합 솔루션입니다.\n\n\n▶프리웨어 - 개인\n▶Windows 10/11 \n▶무료 다운로드 ◀\n\n \nJoeJoe's freeware utilities - [Rename Master]\nRename Master is a freeware utility designed to rename multiple files with a just few clicks. Anyone that has worked with websites, file archives, or collections of music, videos, or pictures has probably spent way too much time renaming hundreds of files.\nwww.joejoesoft.com\n\n \n \n \n \n \n \n4. VariCAD Viewer (다기능 CAD 파일 뷰어)\n\n 단순히 CAD 도면을 보는 것 이상의 기능을 제공합니다. 2D DWG, 3D STEP, 2D/3D VariCAD 등 다양한 형식의 파일을 지원하며, 간단한 조정과 인쇄 기능도 갖추고 있습니다. 이 프로그램은 3D 모델링에 대해 잘 아는 전문가들을 위해 설계되었습니다.\n 인터페이스는 현대적이지만 다양한 기능으로 인해 다소 복잡해 보일 수 있습니다. 그러나 CAD 경험이 있는 사용자라면 직관적으로 사용할 수 있을 것입니다. 도구 모음의 배치를 사용자가 원하는 대로 조정할 수 있는 것도 장점입니다.\n\n\n▶프리웨어 - 개인\n▶Windows 10/11\n▶무료 다운로드 ◀\n\n \nProducts | VariCAD - 3D/2D CAD system\nProducts VariCAD - 3D / 2D mechanical CAD software We have a simple strategy - to sell VariCAD, with all its features, for one very affordable price. VariCAD is the best value you will find anywhere for this type of modeling and designing software. VariCAD\nwww.varicad.com\n\n \n \n \n \n \n \n5. TreeSheets (다목적 데이터 조직화 및 시각화 도구)\n  스프레드시트, 마인드맵, 노트 애플리케이션의 기능을 하나의 사용하기 쉬운 인터페이스로 결합한 프로그램입니다. 복잡한 데이터 구조를 쉽게 다룰 수 있는 것이 주요 특징입니다.\n이 프로그램은 프로젝트 관리, 일정 계획, 브레인스토밍, 할 일 목록 작성 등 다양한 용도로 사용할 수 있습니다. 사용자는 데이터를 계층적 트리, 스프레드시트 그리드, 마인드맵 등 다양한 형태로 시각화할 수 있습니다. \n또한 색상과 테두리 등을 사용자 지정하여 시트의 외관을 개선할 수 있으며, 작업을 우선순위화하고 마감일을 설정하는 등의 기능을 통해 생산성을 높일 수 있습니다.\n\n\n▶프리웨어 - 개인/기업 (오픈소스)\n▶Windows 10/11\n▶무료 다운로드 ◀\n\n \nTreeSheets\nOpen Source Free Form Data Organizer (Hierarchical Spreadsheet) D O W N L O A D : Download LATEST from github releases: Windows / OS X / Linux Click HERE, pick your platform from the latest release.   A \"hierarchical spreadsheet\" that is a great replaceme\nstrlen.com",
        "guid": "http://muzbox.tistory.com/483462",
        "categories": [
          "NEWS/프리웨어 뉴스",
          "cad뷰어",
          "linux에뮬레이션",
          "기업무료프로그램",
          "데이터시각화",
          "모니터밝기조절",
          "무료프로그램",
          "추천프로그램",
          "파일관리",
          "프로젝트관리",
          "프리웨어"
        ],
        "isoDate": "2024-08-25T23:37:38.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "스마트폰으로 DSLR 부럽지 않은 사진 찍는 4가지 방법",
        "link": "http://muzbox.tistory.com/483461",
        "pubDate": "Fri, 23 Aug 2024 17:50:43 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483461#entry483461comment",
        "content": "<p data-ke-size=\"size16\">스마트폰으로 DSLR 못지않은 사진을 찍고 싶으신가요? 이 글에서 소개하는 간단한 비법들을 통해, DSLR 없이도 스마트폰만으로 멋진 사진을 촬영하는 방법을 알아보세요.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"0000.png\" data-origin-width=\"1234\" data-origin-height=\"694\"><span data-url=\"https://blog.kakaocdn.net/dn/dgYX4o/btsJcJnZHOm/sHaXaT6CAXv3XpQ5iSCWG0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/dgYX4o/btsJcJnZHOm/sHaXaT6CAXv3XpQ5iSCWG0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/dgYX4o/btsJcJnZHOm/sHaXaT6CAXv3XpQ5iSCWG0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdgYX4o%2FbtsJcJnZHOm%2FsHaXaT6CAXv3XpQ5iSCWG0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"스마트폰으로 DSLR 부럽지 않은 사진 찍는 4가지 방법\" data-filename=\"0000.png\" data-origin-width=\"1234\" data-origin-height=\"694\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">스마트폰이 우리 일상에서 없어서는 안 될 필수 아이템이 된 지도 오래입니다. 특히, 최근 몇 년간 스마트폰 카메라 기술이 비약적으로 발전하면서, 이제는 DSLR 없이도 훌륭한 사진을 촬영할 수 있게 되었습니다. 하지만 좋은 장비만으로는 뛰어난 사진을 찍을 수 없다는 사실, 알고 계셨나요? 이번 글에서는 별도의 DSLR 없이도 스마트폰으로 멋진 사진을 찍을 수 있는 몇 가지 비법을 소개하고자 합니다. 이제 언제 어디서나 스마트폰을 꺼내들어 전문가처럼 사진을 찍어보세요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>1. 카메라 설정 최적화하기</b></span></h2>\n<p data-ke-size=\"size16\">스마트폰의 기본 카메라 앱은 많은 설정을 자동으로 처리해줍니다. 하지만 설정을 조금만 손봐도 사진의 퀄리티를 크게 향상시킬 수 있습니다. 예를 들어, HDR(High Dynamic Range) 기능을 활성화하면 밝고 어두운 영역이 고르게 노출되어 더 자연스럽고 선명한 사진을 얻을 수 있습니다. 또한, 촬영 전에 초점을 수동으로 맞추고, 노출을 조정하는 것 역시 중요합니다. 빛이 너무 많거나 적으면 사진이 흐릿해지거나, 디테일이 사라질 수 있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"a.png\" data-origin-width=\"1234\" data-origin-height=\"694\"><span data-url=\"https://blog.kakaocdn.net/dn/eXksWk/btsJcQHmAMR/qlHktJNK87wm2pUXyqECgk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/eXksWk/btsJcQHmAMR/qlHktJNK87wm2pUXyqECgk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/eXksWk/btsJcQHmAMR/qlHktJNK87wm2pUXyqECgk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FeXksWk%2FbtsJcQHmAMR%2FqlHktJNK87wm2pUXyqECgk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"카메라 설정 최적화하기\" data-filename=\"a.png\" data-origin-width=\"1234\" data-origin-height=\"694\"/></span></figure>\n</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>HDR 기능 사용:</b> 강한 대비가 있는 장면에서 더 디테일한 사진을 촬영할 수 있습니다.</li>\n<li><b>초점 수동 조절:</b> 사진의 주제가 명확하게 보이도록 초점을 맞추세요.</li>\n<li><b>노출 조정:</b> 밝기를 조절하여 디테일을 더 살릴 수 있습니다.</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>2. 자연광을 활용하라</b></span></h2>\n<p data-ke-size=\"size16\">빛은 사진의 품질을 좌우하는 중요한 요소입니다. 스마트폰 카메라 센서의 크기는 DSLR보다 작기 때문에, 충분한 조명이 없다면 사진이 흐릿하게 나오기 쉽습니다. 자연광을 잘 활용하면 이런 문제를 해결할 수 있습니다. 예를 들어, 창가에서 들어오는 자연광을 활용하거나, 해가 질 무렵의 부드러운 빛을 이용해 촬영해 보세요. 실내 촬영 시에는 인공 조명보다는 자연광을 최대한 활용하는 것이 좋습니다. 단, 역광을 피하고 피사체가 빛을 충분히 받도록 각도를 조절해야 합니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"b.png\" data-origin-width=\"1234\" data-origin-height=\"694\"><span data-url=\"https://blog.kakaocdn.net/dn/ba9KfT/btsJdmThLeR/r6rk4BWLkFmtlBfZVDOu60/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/ba9KfT/btsJdmThLeR/r6rk4BWLkFmtlBfZVDOu60/img.png\"><img src=\"https://blog.kakaocdn.net/dn/ba9KfT/btsJdmThLeR/r6rk4BWLkFmtlBfZVDOu60/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fba9KfT%2FbtsJdmThLeR%2Fr6rk4BWLkFmtlBfZVDOu60%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"자연광을 활용하라\" data-filename=\"b.png\" data-origin-width=\"1234\" data-origin-height=\"694\"/></span></figure>\n</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>황금 시간대 촬영:</b> 일출이나 일몰 시의 부드러운 빛을 활용해보세요.</li>\n<li><b>역광 피하기:</b> 피사체가 어두워지지 않도록 주의하세요.</li>\n<li><b>반사된 빛 활용:</b> 직사광선이 강할 때는 반사된 빛을 이용하세요.</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>3. 구도와 각도에 신경 쓰기</b></span></h2>\n<p data-ke-size=\"size16\">좋은 사진은 구도에서 시작된다고 해도 과언이 아닙니다. 촬영할 때 단순히 피사체를 중앙에 두기보다는 3분할 구도를 활용하거나, 다양한 각도에서 찍어보는 것이 좋습니다. 예를 들어, 낮은 각도에서 촬영하면 피사체가 더 돋보이게 되며, 높은 각도에서는 넓은 배경을 효과적으로 담을 수 있습니다. 또한, 수평을 맞추는 것 역시 중요합니다. 스마트폰의 그리드 라인을 활용하면 수평을 쉽게 맞출 수 있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"c.png\" data-origin-width=\"1234\" data-origin-height=\"694\"><span data-url=\"https://blog.kakaocdn.net/dn/QXn8G/btsJeAvZqmg/3DJuAfVCyf3jb2r1qEqH50/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/QXn8G/btsJeAvZqmg/3DJuAfVCyf3jb2r1qEqH50/img.png\"><img src=\"https://blog.kakaocdn.net/dn/QXn8G/btsJeAvZqmg/3DJuAfVCyf3jb2r1qEqH50/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FQXn8G%2FbtsJeAvZqmg%2F3DJuAfVCyf3jb2r1qEqH50%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"구도와 각도에 신경 쓰기\" data-filename=\"c.png\" data-origin-width=\"1234\" data-origin-height=\"694\"/></span></figure>\n</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>3분할 구도:</b> 사진의 중심을 3등분하여 구성하세요.</li>\n<li><b>다양한 각도 실험:</b> 여러 각도에서 촬영하여 가장 인상적인 장면을 찾아보세요.</li>\n<li><b>수평 맞추기:</b> 그리드 라인을 사용하여 수평을 정확히 맞추세요.</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>4. 간단한 후반 작업으로 완성도 높이기</b></span></h2>\n<p data-ke-size=\"size16\">사진을 찍고 난 후에도 스마트폰에서 바로 간단한 편집 작업을 통해 완성도를 높일 수 있습니다. 예를 들어, 밝기와 대비를 조정하거나, 색온도를 맞추는 것만으로도 사진의 분위기가 완전히 달라질 수 있습니다. 요즘 스마트폰에는 다양한 편집 앱이 있어서 전문가처럼 색상 보정, 노이즈 제거, 크롭 등을 손쉽게 할 수 있습니다. 하지만 과도한 편집은 오히려 사진의 자연스러움을 해칠 수 있으므로, 적절한 선에서 작업을 마무리하는 것이 좋습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"d.png\" data-origin-width=\"1234\" data-origin-height=\"694\"><span data-url=\"https://blog.kakaocdn.net/dn/bHSy0O/btsJekmEDnB/IqyGjmZRrUxZx8mgErOMqK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bHSy0O/btsJekmEDnB/IqyGjmZRrUxZx8mgErOMqK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bHSy0O/btsJekmEDnB/IqyGjmZRrUxZx8mgErOMqK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbHSy0O%2FbtsJekmEDnB%2FIqyGjmZRrUxZx8mgErOMqK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"d.png\" data-origin-width=\"1234\" data-origin-height=\"694\"/></span></figure>\n</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>밝기 및 대비 조절:</b> 간단한 조정만으로도 사진이 선명해질 수 있습니다.</li>\n<li><b>색온도 맞추기:</b> 사진의 분위기를 원하는 대로 조정하세요.</li>\n<li><b>과한 편집 피하기:</b> 자연스러움을 잃지 않도록 주의하세요.</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>결론</b></span></h2>\n<p data-ke-size=\"size16\">스마트폰 카메라는 이제 우리 삶의 필수품이 되었으며, DSLR에 뒤지지 않는 성능을 자랑합니다. 하지만 그만큼 사용자의 노력도 중요합니다. 이번에 소개한 간단한 팁들을 활용하면, 언제 어디서나 스마트폰으로 전문가 못지않은 사진을 촬영할 수 있을 것입니다. 중요한 것은 장비가 아닌, 그 장비를 어떻게 활용하느냐입니다. 다음번에 사진을 찍을 때는 이 비법들을 꼭 기억하고 적용해 보세요.</p>",
        "contentSnippet": "스마트폰으로 DSLR 못지않은 사진을 찍고 싶으신가요? 이 글에서 소개하는 간단한 비법들을 통해, DSLR 없이도 스마트폰만으로 멋진 사진을 촬영하는 방법을 알아보세요.\n\n\n \n스마트폰이 우리 일상에서 없어서는 안 될 필수 아이템이 된 지도 오래입니다. 특히, 최근 몇 년간 스마트폰 카메라 기술이 비약적으로 발전하면서, 이제는 DSLR 없이도 훌륭한 사진을 촬영할 수 있게 되었습니다. 하지만 좋은 장비만으로는 뛰어난 사진을 찍을 수 없다는 사실, 알고 계셨나요? 이번 글에서는 별도의 DSLR 없이도 스마트폰으로 멋진 사진을 찍을 수 있는 몇 가지 비법을 소개하고자 합니다. 이제 언제 어디서나 스마트폰을 꺼내들어 전문가처럼 사진을 찍어보세요.\n \n \n1. 카메라 설정 최적화하기\n스마트폰의 기본 카메라 앱은 많은 설정을 자동으로 처리해줍니다. 하지만 설정을 조금만 손봐도 사진의 퀄리티를 크게 향상시킬 수 있습니다. 예를 들어, HDR(High Dynamic Range) 기능을 활성화하면 밝고 어두운 영역이 고르게 노출되어 더 자연스럽고 선명한 사진을 얻을 수 있습니다. 또한, 촬영 전에 초점을 수동으로 맞추고, 노출을 조정하는 것 역시 중요합니다. 빛이 너무 많거나 적으면 사진이 흐릿해지거나, 디테일이 사라질 수 있습니다.\n\n\n\nHDR 기능 사용: 강한 대비가 있는 장면에서 더 디테일한 사진을 촬영할 수 있습니다.\n초점 수동 조절: 사진의 주제가 명확하게 보이도록 초점을 맞추세요.\n노출 조정: 밝기를 조절하여 디테일을 더 살릴 수 있습니다.\n \n \n2. 자연광을 활용하라\n빛은 사진의 품질을 좌우하는 중요한 요소입니다. 스마트폰 카메라 센서의 크기는 DSLR보다 작기 때문에, 충분한 조명이 없다면 사진이 흐릿하게 나오기 쉽습니다. 자연광을 잘 활용하면 이런 문제를 해결할 수 있습니다. 예를 들어, 창가에서 들어오는 자연광을 활용하거나, 해가 질 무렵의 부드러운 빛을 이용해 촬영해 보세요. 실내 촬영 시에는 인공 조명보다는 자연광을 최대한 활용하는 것이 좋습니다. 단, 역광을 피하고 피사체가 빛을 충분히 받도록 각도를 조절해야 합니다.\n\n\n\n황금 시간대 촬영: 일출이나 일몰 시의 부드러운 빛을 활용해보세요.\n역광 피하기: 피사체가 어두워지지 않도록 주의하세요.\n반사된 빛 활용: 직사광선이 강할 때는 반사된 빛을 이용하세요.\n \n \n3. 구도와 각도에 신경 쓰기\n좋은 사진은 구도에서 시작된다고 해도 과언이 아닙니다. 촬영할 때 단순히 피사체를 중앙에 두기보다는 3분할 구도를 활용하거나, 다양한 각도에서 찍어보는 것이 좋습니다. 예를 들어, 낮은 각도에서 촬영하면 피사체가 더 돋보이게 되며, 높은 각도에서는 넓은 배경을 효과적으로 담을 수 있습니다. 또한, 수평을 맞추는 것 역시 중요합니다. 스마트폰의 그리드 라인을 활용하면 수평을 쉽게 맞출 수 있습니다.\n\n\n\n3분할 구도: 사진의 중심을 3등분하여 구성하세요.\n다양한 각도 실험: 여러 각도에서 촬영하여 가장 인상적인 장면을 찾아보세요.\n수평 맞추기: 그리드 라인을 사용하여 수평을 정확히 맞추세요.\n \n \n4. 간단한 후반 작업으로 완성도 높이기\n사진을 찍고 난 후에도 스마트폰에서 바로 간단한 편집 작업을 통해 완성도를 높일 수 있습니다. 예를 들어, 밝기와 대비를 조정하거나, 색온도를 맞추는 것만으로도 사진의 분위기가 완전히 달라질 수 있습니다. 요즘 스마트폰에는 다양한 편집 앱이 있어서 전문가처럼 색상 보정, 노이즈 제거, 크롭 등을 손쉽게 할 수 있습니다. 하지만 과도한 편집은 오히려 사진의 자연스러움을 해칠 수 있으므로, 적절한 선에서 작업을 마무리하는 것이 좋습니다.\n\n\n\n밝기 및 대비 조절: 간단한 조정만으로도 사진이 선명해질 수 있습니다.\n색온도 맞추기: 사진의 분위기를 원하는 대로 조정하세요.\n과한 편집 피하기: 자연스러움을 잃지 않도록 주의하세요.\n \n \n결론\n스마트폰 카메라는 이제 우리 삶의 필수품이 되었으며, DSLR에 뒤지지 않는 성능을 자랑합니다. 하지만 그만큼 사용자의 노력도 중요합니다. 이번에 소개한 간단한 팁들을 활용하면, 언제 어디서나 스마트폰으로 전문가 못지않은 사진을 촬영할 수 있을 것입니다. 중요한 것은 장비가 아닌, 그 장비를 어떻게 활용하느냐입니다. 다음번에 사진을 찍을 때는 이 비법들을 꼭 기억하고 적용해 보세요.",
        "guid": "http://muzbox.tistory.com/483461",
        "categories": [
          "ANDROID &amp; 모바일/안드로이드 꿀팁",
          "dslr 없이 사진",
          "hdr 기능",
          "사진 구도",
          "사진 편집",
          "스마트폰 사진 비법",
          "스마트폰 사진 촬영",
          "스마트폰 카메라 설정",
          "자연광 활용"
        ],
        "isoDate": "2024-08-23T08:50:43.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "이미지 품질 향상 AIarty, 무료 1년 라이센스 받는 방법",
        "link": "http://muzbox.tistory.com/483460",
        "pubDate": "Thu, 22 Aug 2024 09:24:29 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483460#entry483460comment",
        "content": "<p data-ke-size=\"size16\">&nbsp;AIarty 이미지 향상 프로그램으로 사진을 놀랍도록 향상시키세요. 무료 1년 라이선스를 통해 Windows와 Mac에서 고해상도 이미지를 손쉽게 제작할 수 있습니다. 지금 한정된 시간 동안 무료로 제공되는 이 기회를 놓치지 마세요!</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1280\" data-origin-height=\"720\"><span data-url=\"https://blog.kakaocdn.net/dn/XdCYQ/btsJbtj4Hgg/ZKza8SqAkQgpbhyUvGpE10/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/XdCYQ/btsJbtj4Hgg/ZKza8SqAkQgpbhyUvGpE10/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/XdCYQ/btsJbtj4Hgg/ZKza8SqAkQgpbhyUvGpE10/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FXdCYQ%2FbtsJbtj4Hgg%2FZKza8SqAkQgpbhyUvGpE10%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"이미지 품질 향상 AIarty, 무료 1년 라이센스 받는 방법\" data-origin-width=\"1280\" data-origin-height=\"720\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;이미지의 품질은 높을수록 시각적 경험이 향상되며, 이는 개인 프로젝트든 비즈니스 마케팅이든 매우 중요한 요소로 작용합니다. 그러나 때로는 저해상도 이미지나 노이즈가 많은 사진 때문에 원하는 결과를 얻지 못할 때가 있습니다. 이런 문제를 해결하기 위해 AIarty 이미지 향상 소프트웨어가 등장했습니다. AIarty는 최신 딥러닝 기술을 활용하여 이미지를 향상시키고, 저해상도 이미지를 고해상도로 변환하며, 노이즈 제거와 블러 현상을 개선하는 강력한 기능을 제공합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><span style=\"color: #ee2323;\"><i>&nbsp;특히, 이 소프트웨어의 일반적인 1년 라이선스는 85달러이지만, 현재 무료로 제공되고 있어 누구나 손쉽게 이 강력한 도구를 활용할 수 있습니다.</i></span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>AIarty 소개</b></span></h2>\n<p data-ke-size=\"size16\">AIarty 이미지 향상 프로그램은 Mac과 Windows에서 모두 사용할 수 있는 친환경 데스크탑 프로그램으로, 혁신적인 딥러닝 기술을 사용하여 이미지의 품질을 향상시키고 업스케일링하며, 세부 정보를 생성하는 데 최적화되어 있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1092\" data-origin-height=\"724\"><span data-url=\"https://blog.kakaocdn.net/dn/cL5hCO/btsJaAxsUyE/VygUOy55ShYubfj04aIzqK/img.webp\" data-phocus=\"https://blog.kakaocdn.net/dn/cL5hCO/btsJaAxsUyE/VygUOy55ShYubfj04aIzqK/img.webp\"><img src=\"https://blog.kakaocdn.net/dn/cL5hCO/btsJaAxsUyE/VygUOy55ShYubfj04aIzqK/img.webp\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcL5hCO%2FbtsJaAxsUyE%2FVygUOy55ShYubfj04aIzqK%2Fimg.webp\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"AIarty\" data-origin-width=\"1092\" data-origin-height=\"724\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이 소프트웨어는 최대 32K(Windows) 또는 16K(Mac) 해상도로 이미지를 업스케일링할 수 있으며, 이를 통해 저해상도 이미지를 200%, 400%, 800%로 확대해도 고품질로 인쇄할 수 있습니다. 뿐만 아니라 2K, 4K, 8K의 고해상도 이미지를 제공하여 노이즈와 블러를 제거하고, 압축된 JPEG를 복원하는 기능도 포함되어 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이 소프트웨어는 이미지 품질을 크게 개선하여 잡음과 결함이 없는 선명한 이미지를 제공합니다. 특히 AIarty의 기술은 저품질, 저해상도 이미지나 AI가 생성한 이미지를 고화질의 예술 작품으로 변환하는 데 탁월한 성능을 발휘합니다. 사용자는 1K, 2K, 4K, 8K 해상도를 선택할 수 있으며, 최대 32K 이미지 품질을 제공하는 업스케일 기능도 포함되어 있어 큰 포맷의 출력물을 손쉽게 제작할 수 있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"AIarty 01.png\" data-origin-width=\"1392\" data-origin-height=\"745\"><span data-url=\"https://blog.kakaocdn.net/dn/bgYWwC/btsJbKeOf5C/Kc8ni1oTzcLj4yM6PCjda1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bgYWwC/btsJbKeOf5C/Kc8ni1oTzcLj4yM6PCjda1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bgYWwC/btsJbKeOf5C/Kc8ni1oTzcLj4yM6PCjda1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbgYWwC%2FbtsJbKeOf5C%2FKc8ni1oTzcLj4yM6PCjda1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"AIarty\" data-filename=\"AIarty 01.png\" data-origin-width=\"1392\" data-origin-height=\"745\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;또한 이 프로그램은 이미지의 모서리를 선명하게 만들어주는 디블러 기능과, 노이즈를 제거하고 이미지를 재구성하여 더욱 깨끗한 결과물을 제공하는 디노이즈 기능을 제공합니다. AIarty는 세 가지 AI 모델을 사용하여 사진을 개선합니다. 첫 번째 모델은 이미지의 세부 정보를 더욱 뚜렷하게 하고, 두 번째 모델은 사진을 부드럽게 처리하여 결함을 제거하며, 세 번째 모델은 실제와 같은 세부 정보를 추가하여 이미지를 더 생동감 있게 만듭니다.</p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=Y3QdLNFWP0I\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/eghvGt/hyWSchXMkT/NcWPFazPRFoZB0H0Pw7yBk/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"Aiarty Image Enhancer Quick Start Guide | From Pixelated to Perfect\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/Y3QdLNFWP0I\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>AIarty 무료 1년 라이선스 취득 방법</b></span></h2>\n<p data-ke-size=\"size16\">AIarty 이미지 향상 소프트웨어의 1년 무료 라이선스를 얻는 방법은 매우 간단합니다. 아래 단계를 따라 무료 라이선스를 취득해 보세요:</p>\n<ol style=\"list-style-type: decimal;\" data-ke-list-type=\"decimal\">\n<li>공식 웹사이트 방문: 먼저 <b><span style=\"color: #006dd7;\"><u>[</u> <a href=\"https://www.aiarty.com\" target=\"_blank\" rel=\"noopener\">AIarty 공식 웹사이트</a> ]</span></b>를 방문합니다. 웹사이트에서 해당 프로그램의 무료 1년 라이선스를 제공하는 페이지로 이동하세요.</li>\n<li>다운로드 및 설치: 사용 중인 운영 체제에 맞는 설치 파일을 다운로드합니다. Windows 사용자는 <span style=\"color: #006dd7;\"><b>[</b> <a href=\"https://www.aiarty.com/release/aiarty-image-enhancer.exe\" target=\"_blank\" rel=\"noopener\">여기</a> <b>]</b></span>에서, Mac 사용자는<b><u><span style=\"color: #006dd7;\">[ <a href=\"https://www.aiarty.com/release/aiarty-image-enhancer.dmg\" target=\"_blank\" rel=\"noopener\">여기</a> ]</span></u></b>에서 설치 파일을 다운로드할 수 있습니다. 다운로드가 완료되면 파일을 실행하여 프로그램을 설치합니다.</li>\n<li>라이선스 코드 입력: 프로그램 설치 및 실행 후, 이메일 주소와 함께 제공된 라이선스 코드를 입력합니다. Windows와 Mac 사용자에게 각각 다른 라이선스 코드가 제공되며, 이를 통해 프로그램을 활성화할 수 있습니다.\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>Windows 라이선스 코드:\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>FAN3I-ZJE5W-A4QRQ-JWEBH</li>\n<li>FA5OU-OQKNW-QPHTC-4VMGZ</li>\n<li>FAMU5-MJFVU-T3KAY-664VF</li>\n</ul>\n</li>\n<li>Mac 라이선스 코드:\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>FBOIZ-JJRUD-6IEFN-KGZCR</li>\n<li>FBR6N-A75VN-PVIEO-CCSSU</li>\n<li>FB2HF-24TT5-U7YEB-5562Z</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>프로그램 활성화: 라이선스 코드를 입력하고 \"Activate\" 버튼을 클릭하면 프로그램이 활성화됩니다. 이제 1년 동안 AIarty 이미지 향상 소프트웨어의 모든 기능을 무료로 이용할 수 있습니다.<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"847\" data-origin-height=\"850\"><span data-url=\"https://blog.kakaocdn.net/dn/cseRwY/btsJag7hTya/qHw4JpK2MqJAy61SyhmphK/img.webp\" data-phocus=\"https://blog.kakaocdn.net/dn/cseRwY/btsJag7hTya/qHw4JpK2MqJAy61SyhmphK/img.webp\"><img src=\"https://blog.kakaocdn.net/dn/cseRwY/btsJag7hTya/qHw4JpK2MqJAy61SyhmphK/img.webp\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcseRwY%2FbtsJag7hTya%2FqHw4JpK2MqJAy61SyhmphK%2Fimg.webp\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"AIarty\" data-origin-width=\"847\" data-origin-height=\"850\"/></span></figure>\n</li>\n</ol>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>마치며</b></span></h2>\n<p data-ke-size=\"size16\">AIarty 이미지 향상 소프트웨어는 매우 강력하면서도 사용하기 쉬운 사진 향상 도구로, 이미지 품질을 한 단계 끌어올리려는 모든 사용자에게 추천할 만한 프로그램입니다. 이 소프트웨어는 업스케일링, 노이즈 제거, 블러 개선뿐만 아니라 세부 정보를 추가하는 등 다양한 기능을 제공하여 이미지를 더욱 선명하고 생생하게 만듭니다. 지금 바로 무료 1년 라이선스를 통해 AIarty를 경험해 보세요.&nbsp;</p>",
        "contentSnippet": "AIarty 이미지 향상 프로그램으로 사진을 놀랍도록 향상시키세요. 무료 1년 라이선스를 통해 Windows와 Mac에서 고해상도 이미지를 손쉽게 제작할 수 있습니다. 지금 한정된 시간 동안 무료로 제공되는 이 기회를 놓치지 마세요!\n \n\n\n \n 이미지의 품질은 높을수록 시각적 경험이 향상되며, 이는 개인 프로젝트든 비즈니스 마케팅이든 매우 중요한 요소로 작용합니다. 그러나 때로는 저해상도 이미지나 노이즈가 많은 사진 때문에 원하는 결과를 얻지 못할 때가 있습니다. 이런 문제를 해결하기 위해 AIarty 이미지 향상 소프트웨어가 등장했습니다. AIarty는 최신 딥러닝 기술을 활용하여 이미지를 향상시키고, 저해상도 이미지를 고해상도로 변환하며, 노이즈 제거와 블러 현상을 개선하는 강력한 기능을 제공합니다.\n \n 특히, 이 소프트웨어의 일반적인 1년 라이선스는 85달러이지만, 현재 무료로 제공되고 있어 누구나 손쉽게 이 강력한 도구를 활용할 수 있습니다.\n \n \nAIarty 소개\nAIarty 이미지 향상 프로그램은 Mac과 Windows에서 모두 사용할 수 있는 친환경 데스크탑 프로그램으로, 혁신적인 딥러닝 기술을 사용하여 이미지의 품질을 향상시키고 업스케일링하며, 세부 정보를 생성하는 데 최적화되어 있습니다.\n\n\n \n이 소프트웨어는 최대 32K(Windows) 또는 16K(Mac) 해상도로 이미지를 업스케일링할 수 있으며, 이를 통해 저해상도 이미지를 200%, 400%, 800%로 확대해도 고품질로 인쇄할 수 있습니다. 뿐만 아니라 2K, 4K, 8K의 고해상도 이미지를 제공하여 노이즈와 블러를 제거하고, 압축된 JPEG를 복원하는 기능도 포함되어 있습니다.\n \n이 소프트웨어는 이미지 품질을 크게 개선하여 잡음과 결함이 없는 선명한 이미지를 제공합니다. 특히 AIarty의 기술은 저품질, 저해상도 이미지나 AI가 생성한 이미지를 고화질의 예술 작품으로 변환하는 데 탁월한 성능을 발휘합니다. 사용자는 1K, 2K, 4K, 8K 해상도를 선택할 수 있으며, 최대 32K 이미지 품질을 제공하는 업스케일 기능도 포함되어 있어 큰 포맷의 출력물을 손쉽게 제작할 수 있습니다.\n\n\n \n 또한 이 프로그램은 이미지의 모서리를 선명하게 만들어주는 디블러 기능과, 노이즈를 제거하고 이미지를 재구성하여 더욱 깨끗한 결과물을 제공하는 디노이즈 기능을 제공합니다. AIarty는 세 가지 AI 모델을 사용하여 사진을 개선합니다. 첫 번째 모델은 이미지의 세부 정보를 더욱 뚜렷하게 하고, 두 번째 모델은 사진을 부드럽게 처리하여 결함을 제거하며, 세 번째 모델은 실제와 같은 세부 정보를 추가하여 이미지를 더 생동감 있게 만듭니다.\n\n\n\n \n \n \nAIarty 무료 1년 라이선스 취득 방법\nAIarty 이미지 향상 소프트웨어의 1년 무료 라이선스를 얻는 방법은 매우 간단합니다. 아래 단계를 따라 무료 라이선스를 취득해 보세요:\n공식 웹사이트 방문: 먼저 [ AIarty 공식 웹사이트 ]를 방문합니다. 웹사이트에서 해당 프로그램의 무료 1년 라이선스를 제공하는 페이지로 이동하세요.\n다운로드 및 설치: 사용 중인 운영 체제에 맞는 설치 파일을 다운로드합니다. Windows 사용자는 [ 여기 ]에서, Mac 사용자는[ 여기 ]에서 설치 파일을 다운로드할 수 있습니다. 다운로드가 완료되면 파일을 실행하여 프로그램을 설치합니다.\n라이선스 코드 입력: 프로그램 설치 및 실행 후, 이메일 주소와 함께 제공된 라이선스 코드를 입력합니다. Windows와 Mac 사용자에게 각각 다른 라이선스 코드가 제공되며, 이를 통해 프로그램을 활성화할 수 있습니다.\n\nWindows 라이선스 코드:\n\nFAN3I-ZJE5W-A4QRQ-JWEBH\nFA5OU-OQKNW-QPHTC-4VMGZ\nFAMU5-MJFVU-T3KAY-664VF\nMac 라이선스 코드:\n\nFBOIZ-JJRUD-6IEFN-KGZCR\nFBR6N-A75VN-PVIEO-CCSSU\nFB2HF-24TT5-U7YEB-5562Z\n프로그램 활성화: 라이선스 코드를 입력하고 \"Activate\" 버튼을 클릭하면 프로그램이 활성화됩니다. 이제 1년 동안 AIarty 이미지 향상 소프트웨어의 모든 기능을 무료로 이용할 수 있습니다.\n\n\n \n \n마치며\nAIarty 이미지 향상 소프트웨어는 매우 강력하면서도 사용하기 쉬운 사진 향상 도구로, 이미지 품질을 한 단계 끌어올리려는 모든 사용자에게 추천할 만한 프로그램입니다. 이 소프트웨어는 업스케일링, 노이즈 제거, 블러 개선뿐만 아니라 세부 정보를 추가하는 등 다양한 기능을 제공하여 이미지를 더욱 선명하고 생생하게 만듭니다. 지금 바로 무료 1년 라이선스를 통해 AIarty를 경험해 보세요.",
        "guid": "http://muzbox.tistory.com/483460",
        "categories": [
          "NEWS/윈도우10 한시적 무료앱",
          "ai 이미지 향상",
          "고해상도 업스케일링",
          "노이즈 제거",
          "딥러닝 이미지",
          "무료 라이선스",
          "무료 소프트웨어",
          "블러 제거",
          "사진 품질 개선"
        ],
        "isoDate": "2024-08-22T00:24:29.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "Google 계정으로 다른 사이트 가입을 하지 말아야 하는 이유",
        "link": "http://muzbox.tistory.com/483459",
        "pubDate": "Wed, 21 Aug 2024 08:36:38 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483459#entry483459comment",
        "content": "<p data-ke-size=\"size16\">Google 또는 Facebook을 통해 온라인 계정을 만드는 것이 편리할 수 있지만, 이는 보안과 프라이버시에 심각한 위험을 초래할 수 있습니다. 이 기사에서는 이러한 방법을 피해야 하는 이유와 대안을 제시합니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"google.png\" data-origin-width=\"500\" data-origin-height=\"500\"><span data-url=\"https://blog.kakaocdn.net/dn/dhfTAd/btsI9cXQZx1/hoGlkBNLcCGD4Z8ui1g6PK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/dhfTAd/btsI9cXQZx1/hoGlkBNLcCGD4Z8ui1g6PK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/dhfTAd/btsI9cXQZx1/hoGlkBNLcCGD4Z8ui1g6PK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdhfTAd%2FbtsI9cXQZx1%2FhoGlkBNLcCGD4Z8ui1g6PK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"Google 계정으로 다른 사이트 가입을 하지 말아야 하는 이유\" data-filename=\"google.png\" data-origin-width=\"500\" data-origin-height=\"500\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;온라인 서비스를 사용할 때, Google 또는 Facebook 계정을 사용해 쉽게 로그인을 할 수 있는 옵션을 자주 보게 됩니다. 처음에는 이러한 기능이 시간을 절약하고 사용이 편리하게 느껴질 수 있지만, 그 이면에는 우리가 간과하기 쉬운 심각한 위험 요소가 숨어 있습니다. 특히, 보안과 프라이버시 측면에서 이 방법이 가지는 문제점을 이해하는 것이 중요합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><b>SSO란 무엇인가?</b></h2>\n<p data-ke-size=\"size16\">SSO(싱글 사인온)는 한 번의 로그인으로 여러 서비스에 접근할 수 있게 해주는 기술입니다. 이 기술을 사용하면 Google 또는 Facebook 계정을 통해 다른 서비스에 가입할 때마다 별도의 로그인 정보를 입력할 필요 없이 자동으로 인증이 이루어집니다. 이는 매우 편리하게 보일 수 있습니다. 하지만 이 편리함은 커다란 대가를 요구합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><b>SSO를 사용하지 말아야 하는 이유</b></h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"로그인.png\" data-origin-width=\"1080\" data-origin-height=\"1080\"><span data-url=\"https://blog.kakaocdn.net/dn/c1VUDg/btsJaUnGYWa/2G67loBvtaFriGiHH5JBtk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/c1VUDg/btsJaUnGYWa/2G67loBvtaFriGiHH5JBtk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/c1VUDg/btsJaUnGYWa/2G67loBvtaFriGiHH5JBtk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fc1VUDg%2FbtsJaUnGYWa%2F2G67loBvtaFriGiHH5JBtk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"SSO를 사용하지 말아야 하는 이유\" width=\"500\" height=\"500\" data-filename=\"로그인.png\" data-origin-width=\"1080\" data-origin-height=\"1080\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;SSO의 가장 큰 문제는 보안의 단일 실패 지점(single point of failure)을 만든다는 점입니다. 즉, 하나의 계정이 해킹당하면, 해당 계정을 통해 접속한 모든 서비스가 위험에 처할 수 있습니다. 예를 들어, Google 계정이 해킹되면 Google을 통해 로그인한 모든 계정에 대한 접근 권한이 해커에게 넘어갑니다. 이는 보안 측면에서 큰 위험 요소입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">또한, SSO를 사용하면 Google이나 Facebook 같은 거대 기술 기업에 당신의 계정 통제권을 넘기는 셈이 됩니다. 만약 Google이나 Facebook 계정이 잠기거나 문제가 발생하면, 다른 계정들에도 접근할 수 없게 되는 문제가 발생할 수 있습니다. 이는 단순한 불편을 넘어, 디지털 자산에 대한 심각한 손실을 초래할 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><b>프라이버시 측면에서의 위험성</b></h2>\n<p data-ke-size=\"size16\">&nbsp;SSO를 사용하면 개인의 인터넷 활동을 거대 기술 기업들이 추적하고 관리할 수 있는 기회를 제공하게 됩니다. Google이나 Facebook은 이미 사용자 데이터를 광고 목적으로 수집하고 있으며, SSO를 통해 그들이 접근할 수 있는 데이터 범위는 더욱 확대됩니다. 이러한 이유로, 개인정보 보호에 민감한 사용자라면 SSO 사용을 재고해볼 필요가 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><b>대안: 비밀번호 관리자 사용</b></h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1024\" data-origin-height=\"1024\"><span data-url=\"https://blog.kakaocdn.net/dn/cXVqL6/btsI8Y6FyQa/q8PIsenyNwTrSmH2Ssnqo1/img.webp\" data-phocus=\"https://blog.kakaocdn.net/dn/cXVqL6/btsI8Y6FyQa/q8PIsenyNwTrSmH2Ssnqo1/img.webp\"><img src=\"https://blog.kakaocdn.net/dn/cXVqL6/btsI8Y6FyQa/q8PIsenyNwTrSmH2Ssnqo1/img.webp\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcXVqL6%2FbtsI8Y6FyQa%2Fq8PIsenyNwTrSmH2Ssnqo1%2Fimg.webp\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"비밀번호 관리자 사용\" width=\"500\" height=\"500\" data-origin-width=\"1024\" data-origin-height=\"1024\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;SSO의 편리함을 포기하기 어려운 사용자라면, 비밀번호 관리자를 사용하는 것이 좋은 대안이 될 수 있습니다. 비밀번호 관리자는 각 서비스마다 별도의 비밀번호를 안전하게 저장하고 자동으로 입력해주는 프로그램입니다. 이를 통해 SSO의 편리함을 그대로 유지하면서도 보안과 프라이버시 문제를 해결할 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><b>결론</b></h2>\n<p data-ke-size=\"size16\">Google 또는 Facebook 계정으로 간편하게 로그인을 하는 것은 처음에는 매력적으로 보일 수 있습니다. 그러나 보안과 프라이버시의 측면에서 보면, 이는 커다란 위험을 동반합니다. 안전한 온라인 생활을 위해서는 비밀번호 관리자를 사용하는 것이 더 나은 선택일 수 있습니다.</p>",
        "contentSnippet": "Google 또는 Facebook을 통해 온라인 계정을 만드는 것이 편리할 수 있지만, 이는 보안과 프라이버시에 심각한 위험을 초래할 수 있습니다. 이 기사에서는 이러한 방법을 피해야 하는 이유와 대안을 제시합니다.\n\n\n \n 온라인 서비스를 사용할 때, Google 또는 Facebook 계정을 사용해 쉽게 로그인을 할 수 있는 옵션을 자주 보게 됩니다. 처음에는 이러한 기능이 시간을 절약하고 사용이 편리하게 느껴질 수 있지만, 그 이면에는 우리가 간과하기 쉬운 심각한 위험 요소가 숨어 있습니다. 특히, 보안과 프라이버시 측면에서 이 방법이 가지는 문제점을 이해하는 것이 중요합니다.\n \nSSO란 무엇인가?\nSSO(싱글 사인온)는 한 번의 로그인으로 여러 서비스에 접근할 수 있게 해주는 기술입니다. 이 기술을 사용하면 Google 또는 Facebook 계정을 통해 다른 서비스에 가입할 때마다 별도의 로그인 정보를 입력할 필요 없이 자동으로 인증이 이루어집니다. 이는 매우 편리하게 보일 수 있습니다. 하지만 이 편리함은 커다란 대가를 요구합니다.\n \n \nSSO를 사용하지 말아야 하는 이유\n\n\n \n SSO의 가장 큰 문제는 보안의 단일 실패 지점(single point of failure)을 만든다는 점입니다. 즉, 하나의 계정이 해킹당하면, 해당 계정을 통해 접속한 모든 서비스가 위험에 처할 수 있습니다. 예를 들어, Google 계정이 해킹되면 Google을 통해 로그인한 모든 계정에 대한 접근 권한이 해커에게 넘어갑니다. 이는 보안 측면에서 큰 위험 요소입니다.\n \n또한, SSO를 사용하면 Google이나 Facebook 같은 거대 기술 기업에 당신의 계정 통제권을 넘기는 셈이 됩니다. 만약 Google이나 Facebook 계정이 잠기거나 문제가 발생하면, 다른 계정들에도 접근할 수 없게 되는 문제가 발생할 수 있습니다. 이는 단순한 불편을 넘어, 디지털 자산에 대한 심각한 손실을 초래할 수 있습니다.\n \n \n \n프라이버시 측면에서의 위험성\n SSO를 사용하면 개인의 인터넷 활동을 거대 기술 기업들이 추적하고 관리할 수 있는 기회를 제공하게 됩니다. Google이나 Facebook은 이미 사용자 데이터를 광고 목적으로 수집하고 있으며, SSO를 통해 그들이 접근할 수 있는 데이터 범위는 더욱 확대됩니다. 이러한 이유로, 개인정보 보호에 민감한 사용자라면 SSO 사용을 재고해볼 필요가 있습니다.\n \n \n대안: 비밀번호 관리자 사용\n\n\n \n SSO의 편리함을 포기하기 어려운 사용자라면, 비밀번호 관리자를 사용하는 것이 좋은 대안이 될 수 있습니다. 비밀번호 관리자는 각 서비스마다 별도의 비밀번호를 안전하게 저장하고 자동으로 입력해주는 프로그램입니다. 이를 통해 SSO의 편리함을 그대로 유지하면서도 보안과 프라이버시 문제를 해결할 수 있습니다.\n \n \n결론\nGoogle 또는 Facebook 계정으로 간편하게 로그인을 하는 것은 처음에는 매력적으로 보일 수 있습니다. 그러나 보안과 프라이버시의 측면에서 보면, 이는 커다란 위험을 동반합니다. 안전한 온라인 생활을 위해서는 비밀번호 관리자를 사용하는 것이 더 나은 선택일 수 있습니다.",
        "guid": "http://muzbox.tistory.com/483459",
        "categories": [
          "Google 이야기/구글 뉴스",
          "facebook 로그인",
          "google 로그인",
          "SSO",
          "계정 해킹",
          "데이터 추적",
          "비밀번호 관리자",
          "온라인 보안",
          "프라이버시 보호"
        ],
        "isoDate": "2024-08-20T23:36:38.000Z"
      }
    ]
  },
  {
    "name": "동우리의 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "하테나",
    "category": "개인",
    "posts": []
  },
  {
    "name": "늑돌이네 라지온",
    "category": "개인",
    "posts": []
  },
  {
    "name": "루리웹 - 루리웹 리뷰 게시판",
    "category": "게임",
    "posts": [
      {
        "creator": "｜RULIWEB｜",
        "title": "[게임툰] 하중 계산은 어려워, 월드 오브 구 2",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2243",
        "pubDate": "Mon, 26 Aug 2024 20:04:42 +0900",
        "author": "｜RULIWEB｜",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i3.ruliweb.com/thumb/24/08/26/1918e4c2d2151ad6b.jpg\">",
        "contentSnippet": "",
        "categories": [
          "공지"
        ],
        "isoDate": "2024-08-26T11:04:42.000Z"
      },
      {
        "creator": "샤말란의눈",
        "title": "[MULTI] 게임스컴 2024, 공식 방송 및 관련 기사 종합",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2242",
        "pubDate": "Mon, 26 Aug 2024 08:12:38 +0900",
        "author": "샤말란의눈",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i3.ruliweb.com/thumb/24/08/25/191884a1ee413b2a1.jpg\">",
        "contentSnippet": "",
        "categories": [
          "특집"
        ],
        "isoDate": "2024-08-25T23:12:38.000Z"
      }
    ]
  },
  {
    "name": "Reasontobe",
    "category": "개인",
    "posts": []
  },
  {
    "name": "자유로운 생활",
    "category": "개인",
    "posts": []
  },
  {
    "name": "에스티마의 인터넷이야기 EstimaStory.com",
    "category": "개인",
    "posts": []
  },
  {
    "name": "나긋한 개발 - 데비안 리눅스와 프로그램 언어",
    "category": "개인",
    "posts": []
  },
  {
    "name": "일상을 여행처럼...",
    "category": "개인",
    "posts": []
  },
  {
    "name": "khris'log",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Just hack'em",
    "category": "개인",
    "posts": []
  },
  {
    "name": "C++ Truths",
    "category": "개인",
    "posts": []
  },
  {
    "name": "jacking75",
    "category": "개인",
    "posts": [
      {
        "title": "GitHub Copilot 통합으로 향상된 \"Visual Studio 2022 버전 17.10\"의 Git 도구 기능",
        "link": "https://jacking75.github.io/tech-ai_20240822/",
        "pubDate": "Thu, 22 Aug 2024 00:00:00 +0900",
        "content": "<iframe width=\"1024\" height=\"1024\" src=\"https://docs.google.com/document/d/e/2PACX-1vQxAH2MgY6UHmBNwjep5Q4AAf82MNhrFR_3yI-ShVy_mtsrpMMXd25YLuobBWV52JNbZopoo_wpGy76/pub?embedded=true\"></iframe>\n\n",
        "contentSnippet": "",
        "guid": "https://jacking75.github.io/tech-ai_20240822/",
        "isoDate": "2024-08-21T15:00:00.000Z"
      }
    ]
  },
  {
    "name": "Joel on Software",
    "category": "개인",
    "posts": []
  },
  {
    "name": "벤자민로그",
    "category": "개인",
    "posts": [
      {
        "title": "매일 커밋에 실패했던 날",
        "link": "https://jeho.page/essay/2024/08/26/daily-commit-failed.html",
        "pubDate": "2024-08-26T05:00:00.000Z",
        "author": "김재호",
        "content": "<p>2020년, 코로나가 시작되고 루틴이라는 게 생기기 시작했습니다.<br />\n약속도 없고 방구석에만 있다 보니 자연스레 루틴이 잡혔습니다.</p>\n\n<p>아침 9시에 일어난다.<br />\n드르륵드르륵 커피를 간다.<br />\n커피잔을 들고 방에 들어가서 컴퓨터 앞에 앉는다.<br />\n코딩을 한다.</p>\n\n<p>매일 코딩을 했습니다.<br />\nGitHub 잔디도 빽빽이 잘 쌓였습니다.</p>\n\n<p>와 이거 멋진걸.<br />\n2021년에는 진짜로 잔디를 꽉 한 번 채워봐야겠다.</p>\n\n<p><img src=\"/assets/img/daily_coding.png\" alt=\"2021년 커밋 기록\" /><br />\n<em>2021년 GitHub</em></p>\n\n<p>하… 잘나가다가 실패해버렸습니다. 6/16일.</p>\n\n<p>6/16일은 가평의 어느 호텔에 놀러 갔던 날입니다.<br />\n노느라 오늘 코딩을 못했네. 지금이라도 코딩해야지.<br />\n밤 10시쯤 집중해서 코딩하다가..<br />\n문득 시계를 보니 자정이 넘어버린 걸 깨달았습니다.</p>\n\n<blockquote>\n  <p>헉…! 망했다. 아직 커밋 안 했는데.</p>\n</blockquote>\n\n<p>이렇게 무너진 건가? 끝난거야?<br />\n어찌나 허무하던지.<br />\n미리 커밋부터 정리해둘걸..</p>\n\n<p>아쉬워 하다가 이런 생각이 들었습니다.</p>\n<blockquote>\n  <p>잠깐. 난 잘못한 거 없잖아. 억울하다고.<br />\n놀다가 놓친 것도 아니고 진짜로 코딩하고 있었는걸.<br />\n시간을 돌려서 커밋을 집어넣을까?<br />\n이건 반칙이 아닌 것 같은데?</p>\n</blockquote>\n\n<p>1분쯤 고민했습니다.<br />\nGit 명령어를 찾아보기까지 했습니다.<br />\n하지만 그러지 않기로 했습니다.</p>\n\n<p>반칙이 아니긴 뭐가 아니야. 반칙 맞잖아.<br />\n그렇게 하는 순간 의미가 없어져 버려.<br />\n못한 건 못한 거야. 이게 뭐라고.</p>\n\n<p>마음이 편해졌습니다.<br />\n노력은 하되 실패한 날은 실패한 날대로 두자.</p>\n\n<p>이후로는 그다지 신경쓰며 하지 않았는데도 잔디는 여전히 푸릇푸릇합니다.<br />\n너무 신경 쓰며 할 때보다 오히려 지금이 더 좋습니다.</p>\n\n<p><img src=\"/assets/img/commits.png\" alt=\"최근 5년간 커밋\" /></p>\n\n<p><br />\n<em>함께 읽으면 좋은 글:</em></p>\n<ul>\n  <li><a href=\"/essay/2022/01/05/daily-coding.html\">매일매일 코딩하기</a></li>\n  <li><a href=\"/essay/2024/08/01/commit-count.html\">1년에 몇 개나 커밋하세요?</a></li>\n</ul>",
        "contentSnippet": "2020년, 코로나가 시작되고 루틴이라는 게 생기기 시작했습니다.\n아침 9시에 일어난다.\n매일 코딩을 했습니다.\n와 이거 멋진걸.\n\n2021년 GitHub\n하… 잘나가다가 실패해버렸습니다. 6/16일.\n6/16일은 가평의 어느 호텔에 놀러 갔던 날입니다.\n헉…! 망했다. 아직 커밋 안 했는데.\n이렇게 무너진 건가? 끝난거야?\n아쉬워 하다가 이런 생각이 들었습니다.\n잠깐. 난 잘못한 거 없잖아. 억울하다고.\n1분쯤 고민했습니다.\n반칙이 아니긴 뭐가 아니야. 반칙 맞잖아.\n마음이 편해졌습니다.\n이후로는 그다지 신경쓰며 하지 않았는데도 잔디는 여전히 푸릇푸릇합니다.\n\n\n함께 읽으면 좋은 글:\n매일매일 코딩하기\n1년에 몇 개나 커밋하세요?",
        "summary": "2020년, 코로나가 시작되고 루틴이라는 게 생기기 시작했습니다. 약속도 없고 방구석에만 있다 보니 자연스레 루틴이 잡혔습니다.",
        "id": "https://jeho.page/essay/2024/08/26/daily-commit-failed",
        "isoDate": "2024-08-26T05:00:00.000Z"
      }
    ]
  },
  {
    "name": "악보쓰는 프로그래머",
    "category": "개인",
    "posts": []
  },
  {
    "name": "쭌안아빠",
    "category": "개인",
    "posts": []
  },
  {
    "name": "A Gangster World",
    "category": "개인",
    "posts": []
  },
  {
    "name": "요우의 내맘대로 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자스럽다",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Against All Odds.",
    "category": "개인",
    "posts": []
  },
  {
    "name": "움직이는 게임서버",
    "category": "개인",
    "posts": []
  },
  {
    "name": "이상욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "임철재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "어쩐지 오늘은",
    "category": "개인",
    "posts": [
      {
        "title": "데이터 분석가 로드맵(프로덕트 분석가)을 만들며 했던 생각들",
        "link": "https://zzsza.github.io/diary/2024/08/21/product-analyst-roadmap/",
        "pubDate": "Wed, 21 Aug 2024 00:00:00 +0000",
        "content": "<ul>\n  <li>와 올해 블로그에 쓴 글이 0개였다니.. 충격적이네요. 의식하면서 글을 써보도록 할게요</li>\n  <li>이번 글은 인프런에 프로덕트 분석가 로드맵을 작성한 내용에 대해 공유해볼게요</li>\n  <li>강의 만드는 과정의 노하우 공유는 예전에 작성한 <a href=\"https://zzsza.github.io/diary/2023/07/13/how-to-make-a-lecture/\">인프런에서 강의 만들기</a> 글에 있어요</li>\n</ul>\n\n<hr />\n\n<h1 id=\"프로덕트-분석가-로드맵-제작\">프로덕트 분석가 로드맵 제작</h1>\n<ul>\n  <li><a href=\"https://www.inflearn.com/roadmaps/4639\">인프런 로드맵</a>을 만들었어요. 제가 퇴사하고 만든 강의들을 모아둔 내용입니다</li>\n</ul>\n\n<p><img src=\"https://capture.dropbox.com/37KrIVW1YEPIkOzd?raw=1\" /></p>\n\n<h2 id=\"왜-프로덕트-분석가인가\">왜 프로덕트 분석가인가?</h2>\n<ul>\n  <li>데이터 직무로 처음 일했던 회사에서 했던 일을 돌이켜보면 앱 로그 데이터 분석을 많이 진행했어요. Firebase의 데이터를 다루면서 앱 데이터가 어떻게 생겼는지, 로그 설계는 어떻게 해야하는지 등을 경험했어요</li>\n  <li>그 당시엔 프로덕트 분석가라는 이름이 따로 있진 않았지만, 시간이 지나고 보니 이런 이름으로 불리게 되더라구요</li>\n  <li>이직한 후에도 GA, Firebase 데이터를 어떻게 다룰지에 대해 생각해보고, 앱 로그 데이터에 대한 마트를 제작하기도 했어요. 그래서 이 부분에 대해서는 많은 시행착오를 겪었어요</li>\n  <li>Amplitude, Mixpanel에 대한 것도 개인적으로 경험해보면서, 로그 데이터가 어떻게 구성되고 어떤 관점으로 바라볼지에 대해 알게 되었어요</li>\n  <li>그리고 비즈니스나 머신러닝 알고리즘 관점에서 AB Test를 해보고, 해석의 모호함이 생길 땐 어떻게 해결해야 할지, 통계적 유의성이 이슈가 있으면 어떻게 해야할지 등에 대해 경험했어요</li>\n  <li>돌이켜보면, 저는 여러 직무를 경험했지만 B2C 앱 데이터를 많이 다루곤 했어요. 그래서 프로덕트 데이터 분석가 로드맵을 만들기로 했어요(제일 많이 경험하고 시행 착오가 존재하는)</li>\n</ul>\n\n<p><br /><br /></p>\n\n<h2 id=\"나는-왜-교육을-하는가\">나는 왜 교육을 하는가?</h2>\n<ul>\n  <li>프로덕트 분석가라는 이름이 있지 않던 시절 이 분야를 공부할 때 참 어려웠어요. 회사 개발자분께서 DB를 배우는 것이 필요하다고 해서 <a href=\"https://www.yes24.com/Product/Goods/1820583\">새로쓴 대용량 데이터베이스 솔루션</a>을 공부하기도 했어요. DB를 이해하는데 도움이 되긴 했지만, 내용이 너무 어려웠던 기억이 나네요(요즘 학습하면 LLM의 도움을 받아 더 쉽게 가능하겠지만)</li>\n  <li>교육을 해야겠다고 다짐할 때, <strong>과거의 저처럼 회사에서 업무를 진행하다가 어려움을 겪는 분들이 조금이나마 더 나은 길을 가길 바랬어요</strong></li>\n  <li>어떻게 보면 <strong>과거의 저에게 보내는 강의</strong>라고 볼 수 있어요\n    <ul>\n      <li>이 내용을 미리 알았다면 참 좋았을텐데, 실제로 해보면 이런 부분을 깊게 생각하면 좋은 것 등</li>\n      <li>그래서 PM을 위한 데이터 리터러시 강의에는 “카일 스토리”라는 것이 나옵니다. 원래 강의 인트로에 연기하려고 했다가, 어설프게 하려니 이상해서 그냥 덤덤한 방식으로 전개했어요</li>\n    </ul>\n  </li>\n  <li><strong>저를 경험한 분들이 더 좋은 삶을 살길 바라고 있어요. 그냥 각자가 더 좋은 삶(사람마다 정의하기 나름이지만)을 살길 바라고 있어요</strong>\n    <ul>\n      <li>여러 관점이 있지만, 인프런에 올리는 내용은 대부분 업무를 하다가 겪는 내용들을 다루곤 해요. 어떻게 해야 일을 더 잘할 수 있고, 회사에서 인정 받을 수 있을까?를 주로 다룹니다</li>\n      <li>유튜브에는 커리어에서 생각할 수 있는 고민들을 주로 다루고, 로드맵이나 제 생각을 공유하곤 해요. 이런 내용을 통해 영감을 받길 바라고 있어요(꼭 그대로 하는 것이 아닌 자신만의 방법을 찾는 것)</li>\n    </ul>\n  </li>\n  <li>어떤 형태의 강의를 하고 싶었는지 생각해보면, 고등학생 때 들었던 신승범 선생님처럼 수업하고 싶었던 것 같네요. 강의 자체도 하지만, 인생에 대한 내용이나 어떻게 삶을 살아갈지, 동기부여 등도 같이 진행하고 싶었어요\n    <ul>\n      <li>요즘 수학은 정승제 선생님 강의를 듣던데, 이 맥락과 비슷한 것 같네요</li>\n      <li>강의에 저도 이런 동기 부여에 대한 내용도 추가하려고 생각하고 있어요</li>\n    </ul>\n  </li>\n</ul>\n\n<p><br /><br /></p>\n\n<h2 id=\"어떤-것이-중요하다고-생각했는가\">어떤 것이 중요하다고 생각했는가?</h2>\n<ul>\n  <li>강의는 총 3개로 구성되어 있고, 나머지는 유튜브 영상이에요.</li>\n  <li><a href=\"https://inf.run/jfWT\">PM을 위한 데이터 리터러시</a>\n    <ul>\n      <li>문제 정의, 구조적인 사고, 로그 설계, 실험 설계, 의사 결정, 데이터 문화 등 데이터를 다루다가 생기는 다양한 일을 모두 담았어요</li>\n      <li>제 강의 중에 처음 어떤 강의를 들을까? 생각하면 이 강의가 제일 좋다고 생각합니다. 회사에서 어떤 방식으로 일을 하는지 알아보면서 데이터 분석을 어떻게 해야할지에 대해 알 수 있어요</li>\n      <li>제가 익힌 여러 암묵지를 모두 담은 강의라, 다시 이런 종류의 강의를 만들라고 하면 어떤 내용을 더 넣어야 할지 고민될 것 같네요. 물론 더 추가할 부분이 있긴 합니다</li>\n      <li>PM 직무에 계신 분들도 보기 좋고, 디자이너, 데이터 분석가 모두 보면 좋을 내용으로 구성되어 있어요</li>\n    </ul>\n  </li>\n  <li><a href=\"https://inf.run/p121d\">초보자를 위한 BigQuery(SQL)</a>\n    <ul>\n      <li>데이터를 다루기 위해 SQL을 알아야 합니다.</li>\n      <li>회사에서 SQL을 처음 배우는 분들이 어디서 어려움을 겪는지, 어떤 것을 알면 좋을지 고민하며 만들었어요</li>\n      <li>강의에서 특히 힘을 준 부분은 <strong>“데이터 검증”</strong>, <strong>“쿼리를 작성하는 흐름”</strong>. 이 부분은 암묵지에 해당될 수 있는 내용인데, 회사에서 참 중요하다 생각했어요</li>\n      <li>지표를 잘못 뽑고, 지표를 보는 분에게 잘못 뽑았다고 말하는 경우 종종 있을 수 있는데, 데이터 검증을 어떻게 해야할지에 대해 모르거나 쿼리의 실수로 발생하곤 합니다. 간단하게 특정 user_id를 선정해서 미리 확인해보는 과정으로 해결할 수 있는데, 이런 내용에 대해 알지 못하는 경우가 있었어요</li>\n      <li>쿼리를 작성하는 흐름은 처음에 이런 큰 그림을 이해하면 더 잘 작성할 수 있다고 판단했어요</li>\n      <li>쿼리를 작성할 때 참고할 수 있는 데이터 템플릿도 공유드리고, 이걸 자동화할 수 있는 도구도 알려드렸어요. <a href=\"https://espanso.org/\">Espanso</a>라는 도구인데, 무료고 오픈소스라 많은 분들이 아시면 좋을거에요</li>\n      <li>시간 데이터를 다룰 일이 많은데, 서버의 데이터는 UTC로 저장되어 있는 경우가 많아요. 이 때 타임존에 대한 내용을 모를 수 있는데, SQL에서 이 부분을 학습하면 좋겠다고 생각했어요</li>\n    </ul>\n  </li>\n  <li><a href=\"https://inf.run/QVgPf\">BigQuery 활용편</a>\n    <ul>\n      <li>이 강의는 입문편에서 다루진 않은 부분 중 유용한 함수인 윈도우 함수를 주로 다룹니다</li>\n      <li>Firebase 데이터의 특징으로 배열 데이터를 다뤄야 하는데, 배열 데이터를 다루는 방법에 대해서도 학습합니다</li>\n      <li>단순히 문법만 배우는 것이 아니라 퍼널 분석, 리텐션 분석을 어떻게 접근하면 좋은지 공유합니다</li>\n      <li>PM을 위한 데이터 리터러시 강의랑 연결되는 부분인데, 제품에 대해 생각하고, 그 부분에서 리텐션 개선 아이디어를 생각하도록 강의를 구성했어요. 이렇게 말을 해도 실제로 데이터를 보면 데이터만 보게 되는 경우가 종종 있어서, 강의에서 계속 제품에 대해 고민할 수 있도록 생각을 공유했어요</li>\n      <li>Google Sheets로 자동화를 할 수 있는 부분이 꽤 있는데, 이 부분도 알아가시면 좋을 것 같다 싶어 이 부분도 추가했어요</li>\n    </ul>\n  </li>\n</ul>\n\n<p><br /><br /></p>\n\n<h2 id=\"데이터를-활용하고-싶은-분들이-어떻게-학습하면-좋을까\">데이터를 활용하고 싶은 분들이 어떻게 학습하면 좋을까</h2>\n<ul>\n  <li>이 부분은 최근에 <a href=\"https://www.threads.net/@data.scientist/post/C-c48E7zEM_\">쓰레드</a>에 길게 남겼는데, 블로그에도 공유해보아요. 존댓말을 쓰지 않고 자유롭게 남긴 내용입니다</li>\n  <li>하드 스킬에 대한 내용은 줄인 버전이고, 머신러닝이나 데이터 시각화 등에 대한 지식은 언제든 해도 괜찮다고 생각</li>\n  <li>보통 데이터를 활용한다라고 하면 파이썬, SQL, 통계 같은 기술적인 것부터 생각한다. 그렇기 때문에 이걸 해야 데이터를 활용할 수 있다고 생각\n    <ul>\n      <li>데이터를 활용한다는 것은 데이터 기반 의사결정을 한다는 것이고, 이것은 문제를 해결하는 과정에서 지표를 정의해서 지표에 따른 의사 결정을 하는 것</li>\n      <li>제일 중요한 것은 문제를 정의하고, 문제를 인식하는 것. 대부분 이 부분을 그냥 넘어가지만, 문제 정의를 잘 진행하는 것이 제일 중요하다. 정의가 잘 된다면 지표는 자연스럽게 나오고, 지표는 사용할 수 있는 도구(엑셀, 파이썬, SQL 등 사용 가능한 것)로 추출하면 된다</li>\n      <li>논리적 사고는 “로지컬 씽킹” 책을 추천. 맥킨지식 논리적 사고로 유명하고, MECE / So What? Why So를 매번 생각한다</li>\n      <li>사실 이 역량은 모든 직무에게 필요하다</li>\n    </ul>\n  </li>\n  <li>논리적 사고에 대해 어느정도 파악을 했다면, 그 후엔 무엇을 해야할까?\n    <ul>\n      <li>그 후엔 데이터를 어떤 관점으로 바라볼지에 대해 감을 잡으면 좋다. 신입 시절에 데이터를 어떻게 바라볼지에 대한 관점이 없이 일단 데이터를 뽑고 해석을 하려고 했는데, 데이터를 바라보는 관점이 없어서 어려웠다.</li>\n      <li>데이터를 바라보는 과정에선 1) 그래프 기반, 2) 호기심 기반, 3) 상급자 기반 등이 있는데 3가지 방법보단 “목적 기반”으로 보는 것이 핵심. 어떤 목적을 가지고 어떤 지표를 볼지, 그리고 어떤 것을 해야할까?에 대해 생각해보는 것이 필요하다. 목적이 없으면 기준이나 판단이 어렵다.</li>\n      <li>이런 관점에 대해 잘 나온 책은 “빅데이터 시대, 성과를 이끌어 내는 데이터 문해력” 이 책이 나왔을 때 처음 읽고 완전 감동받은 책. 논리적 사고랑 연결되는 부분이 있다</li>\n    </ul>\n  </li>\n  <li>(3) 논리적 사고, 데이터 목적에 대한 학습. 그 후엔?\n    <ul>\n      <li>앞선 것들을 잘 진행하기 위해, 회사의 비즈니스 모델을 잘 이해하면 좋다. 비즈니스 모델이란 것은 회사에서 매출이 언제 발생하고, 어떤 흐름으로 돈이 돌아다니는지를 의미한다. 데이터 분석을 한다는 것은 목적이 있을텐데, 회사의 서비스를 성장하기 위해 무엇을 해야할까?, 매출을 증가시키기 위해 무엇을 해야할까?, 비용을 줄이기 위해 무엇을 해야할까? 등을 생각한다. 이 때 비즈니스 모델을 이해하면 더 수월하게 생각할 수 있었다.</li>\n      <li>관련해서는 “한 장으로 끝내는 비즈니스 모델 100” 책을 추천. 도식화로 정리가 되어있어서 도움이 된다. 그러면서 사용하고 있는 앱이나 서비스의 비즈니스 모델을 분석해보는 것도 추천</li>\n      <li>강의를 들은 분들 중 면접을 잘 보고 싶다고 하는 분들에겐 “지원하는 회사의 비즈니스 모델”을 스스로 분석해보고, 도식화해서 그 내용 기반으로 무엇을 할지 생각해보라고 권한다. 이런 것을 하는 사람이 적다.</li>\n    </ul>\n  </li>\n  <li>(4) 논리적 사고, 데이터 목적, 비즈니스 모델. 그 후엔?\n    <ul>\n      <li>그 후에 간단한 통계학 공부를 하면 좋은데, 통계학을 어려워하는 사람이 있기에 처음엔 쉽게 접근하는 것을 추천한다.\n  “데이터 분석가의 숫자유감”이란 책이 있는데, 만화로 구성되어 있다. 통계를 활용하는 핵심적인 부분이 나와있어서 이 책을 보면 대략적으로 어떻게 활용해야 할지에 대해 감이 온다.</li>\n      <li>그 후에 추천하는 책은 “숫자에 약한 사람들을 위한 통계학 수업”. 이 책도 핵심적인 통계학 개념을 쭉 훑고, 실용적인 관점에서 사례가 많이 나온다. 수학을 극도로 배제해서 눈높이를 낮추어서 많은 분들이 읽을 수 있다.</li>\n      <li>그 후에 본격적인 통계를 공부하고 싶다면 “An Introduction to Statistical Learning”를 추천. 줄여서 ISLR라고도 하는데, 많은 분들이 이 책을 기본서 같이 생각한다. 한국어 번역이 있다고 들었지만, 원서를 추천. 구글에 책 제목을 검색하면 원서가 나온다(파이썬 버전도 있음)</li>\n    </ul>\n  </li>\n  <li>(5) 통계학 그 후엔 무엇을 해야할까, 이 시기엔 상황에 따라 다를듯. 우선 회사에 다니고 계신 분들 대상으로 먼저 이야기\n회사에 다니고 있다면, 어떤 문제를 해결해야 할 것. 진행하고 있는 업무가 문제와 관련되어 있을 것이다. 이 문제를 해결하기 위해 어떤 것을 해야할까? 어떤 지표를 봐야할까? 생각하기\n    <ul>\n      <li>이 과정에서 지표 정의에 대해서 알면 좋은데, 지표가 어렵다면 “문제가 해결되면 어떤 모습이 되는가? 그 모습을 숫자로 표시한다면?” 질문을 통해 정의. 요즘은 LLM이 잘 발전되어 있어서 어떤 문제를 해결하고 싶은지를 클로드 등에 물어보면 잘 추천해준다. 그러면 그 지표들을 모두 모아서 어떤 것을 사용할지 결정한다.</li>\n      <li>그리고 해당 지표를 개발자나 데이터 분석가분들에게 부탁해서 받아보고, 그것 기반으로 “Action Item”을 생각해본다. 뭘 해야 그 지표를 올릴 수 있을까? 그리고 그것을 실행하고 기능 개발 -&gt; 의사 결정. 바로 문제를 푸는 방법</li>\n    </ul>\n  </li>\n  <li>(6) 회사에 다니지 않는 취준생이라면\n    <ul>\n      <li>이런 경우 참 어렵다. 취준생 입장에서 데이터를 어떻게 구할까?라는 고민에 빠진다. 이를 해결하기 위해 캐글이란 플랫폼이 나왔지만, 캐글은 문제 정의가 된 후에 데이터를 제공한 후 모델링에 집중한다.</li>\n      <li>데이터를 활용한다는 것은 문제에서 데이터를 해석하고, 의사결정하는 것이라고 볼 수 있다. 그리고 데이터가 쌓인 후 목적에 맞으면 예측 모델링을 진행한다.\n취준생이라면 내가 데이터 분석을 집중하고 싶은지, 모델링을 하고 싶은지 고민해야 한다. 많은 교육 과정에서 모델링 위주로 교육해서 혼란스러운 경우가 있는데, 나눠서 생각해보는 것을 추천.</li>\n      <li>어떤 직무를 하던, 이 쯔음에 SQL/파이썬 등을 학습한다. 요즘은 대부분의 책이 잘 나와서 서점에서 고르는 것도 추천</li>\n    </ul>\n  </li>\n</ul>\n\n<p><br /><br /></p>\n\n<h1 id=\"데이터-분석가-로드맵에-더-추가되면-좋은-것은\">데이터 분석가 로드맵에 더 추가되면 좋은 것은?</h1>\n<ul>\n  <li>어떤 내용이 더 필요할까 생각해봤는데, 다음 내용을 추가하면 좋을 것 같다</li>\n  <li><strong>데이터 전처리에 대한 학습</strong> : 데이터를 어떻게 처리할지에 대해 방법론이 다양한데 각 방법론의 장단점과 어떻게 활용하면 좋을지에 대해 학습</li>\n  <li><strong>설득하기, 협상하기</strong> : 대화를 할 일이 참 많은 직무다. 설득하기, 협상하기는 어떤 직무여도 있으면 좋겠지만 데이터 분석가분들이 더 들어보면 좋겠다. 사내 컨설턴트가 된다는 생각도 같이 하면서</li>\n  <li>그 후엔 자신이 자신 있는 <strong>도메인 영역</strong>을 정해보면 좋겠다. 산업이여도 괜찮고, 비즈니스나 프러덕트 등으로 생각해도 좋다. 하나의 도메인에서 해결할 수 있는 문제를 거시적으로도 파악하고, 미시적으로도 파악해보면 좋겠다</li>\n  <li><strong>경영진의 사고 과정</strong> : 경영진에 계신 분들이 어떤 생각을 주로 하고, 어떻게 생각하는지 알아두면 좋다. 이런 생각을 할 수 있게 된다면, 내가 지금 어떤 일을 해야할지를 더 잘 생각할 수 있다. 상황에 따라 유연한 접근이 필요한데, 대표님이 지금 무슨 생각을 할까?라는 생각을 하면서 업무를 하곤 했다</li>\n  <li>물론 위에 말한 내용은 일반적인 데이터 분석가 로드맵에서 나오는 내용도 있지만, 아닌 내용도 있다. 회사에서 일을 잘 진행하기 위해 필요했던 내용인데 나만의 경험일 수도 있을 것 같고, 아닐수도 있다</li>\n  <li>데이터 사이언티스트가 되고 싶다면, 데이터 분석도 해보고 전략, 데이터 엔지니어링 등을 모두 경험해보는 것을 추천한다. 다만 요즘 데이터 사이언티스트도 회사마다 다르다. 주로 추천 알고리즘을 만들고 데이터 분석을 할 때 데이터 사이언티스트라고 불리는 것 같다</li>\n</ul>\n\n<p><br /><br /></p>\n\n<h1 id=\"앞으로-할-것들\">앞으로 할 것들</h1>\n<ul>\n  <li>데이터 분석 관련 강의는 잠시 쉬고, 원래 만들고 싶었던 내용을 만들려고 합니다</li>\n  <li>어떻게 해야 데이터 엔지니어링을 쉽게 할 수 있을지에 대한 내용. 그리고 데이터 분석가가 이정도는 알면 좋은 개발 지식. 이렇게 선언해두면, 언젠가 하려고 시도할거라 생각해서 선언해두어요</li>\n  <li>일단 개발자 블로그 글쓰기 강의는 빠르게 만들 수 있어서, 이것부터 하고 전체적인  강의에 대해 설계할 예정</li>\n  <li>강의 만드는 것도 시행착오가 있어서, 여러 방법으로 시도하고 있어요. 이제는 어떻게 해야 속도를 낼 수 있을지 감을 잡아서 계속 시도해볼 예정이에요.</li>\n  <li>그 후엔 다시 회사로 돌아가지 않을까 싶어요. 다만 그 사이에 최선을 다해 강의를 만들려고 해요. 회사에 들어가서 온보딩 자료로 활용할 수 있는 수준으로 강의를 만들려고 합니다. 정해진 것은 아무것도 없지만, 일단 이정도로 생각하고 있어요</li>\n  <li>최근 데이터 리터러시에 대한 니즈를 많이 느끼고 있어요. 강의 판매도 늘어나고 있고, 기업 강의도 요청받고 있어요. 많은 분들이 데이터를 더 잘 활용하고, 쉽게 접근할 수 있도록 계속 하나씩 만들어 볼게요\n    <ul>\n      <li>회사에서 데이터를 어떻게 활용해야 하는지 가이드를 주고, 더 잘 진행할 수 있도록 돕는 직무도 점점 필요해지는 것 같아요. 단순히 데이터 프러덕트를 만들고 끝이 아니고 여러 조직에 있는 사람들의 상황을 파악하고 해결할 수 있는 방법 도출</li>\n    </ul>\n  </li>\n  <li>저는 데이터 분석가분들이 점점 데이터 엔지니어링을 할 수 있어야 하고, 데이터 엔지니어도 데이터나 비즈니스에 대한 큰 그림을 이해하면 좋다고 생각해요. 회사 상황에 따라 다를 수도 있지만, 데이터 관련 큰 그림을 잘 이해할 수 있는 사람들이 더 필요한 시기라고 생각해요</li>\n  <li>대학생분들을 어떻게 도울 수 있을까 고민하고 있어요. 대학원을 가지 않은 제가 교수를 하긴 어려워서, 지금 진행하고 있는 일들을 집중하려고 해요. 부스트캠프 AI Tech와 유튜브 등. 학생분들이 도움을 구하면 가능하면 최대한 시도해보려고 하고 있어요</li>\n  <li>데이터 직무가 아닌 분들이 어떻게 데이터를 잘 활용할 수 있을까? 이 부분에 대해 활용 지침 위주로 내용을 정리해볼까 생각하고 있어요</li>\n</ul>\n\n<p><br /><br /></p>\n\n<h1 id=\"마무리\">마무리</h1>\n<ul>\n  <li>인프런에 올린 <a href=\"https://www.inflearn.com/roadmaps/4639\">로드맵</a>에 관심이 있다면 한번 봐주셔요. 유튜브 영상도 추가해두었어요\n    <ul>\n      <li>2주 동안 로드맵 화면에서 쿠폰을 발급 받을 수 있어요. 필요하시다면 활용하셔도 좋을 것 같아요.</li>\n    </ul>\n  </li>\n  <li>앞으로 제가 어떤 일을 할지, 어떤 커리어를 밟을지 잘 모르지만 지금 상황에 진심을 다해 하나씩 해볼 예정이에요. 지금의 시간이 참 소중하기에.</li>\n  <li>제게 궁금한 내용이 있다면 무엇이든 말씀해주셔요. 이 글에 대한 피드백도 좋아요. 제가 답이라는 것은 아니고, 제 생각을 공유했으니 여러 이야기를 나누며 합쳐보고 싶네요.</li>\n</ul>\n\n<p><br /><br /></p>\n\n<ul>\n  <li>글 작성하는데 걸린 시간 : 약 40분</li>\n</ul>\n\n",
        "contentSnippet": "와 올해 블로그에 쓴 글이 0개였다니.. 충격적이네요. 의식하면서 글을 써보도록 할게요\n이번 글은 인프런에 프로덕트 분석가 로드맵을 작성한 내용에 대해 공유해볼게요\n강의 만드는 과정의 노하우 공유는 예전에 작성한 인프런에서 강의 만들기 글에 있어요\n프로덕트 분석가 로드맵 제작\n인프런 로드맵을 만들었어요. 제가 퇴사하고 만든 강의들을 모아둔 내용입니다\n\n왜 프로덕트 분석가인가?\n데이터 직무로 처음 일했던 회사에서 했던 일을 돌이켜보면 앱 로그 데이터 분석을 많이 진행했어요. Firebase의 데이터를 다루면서 앱 데이터가 어떻게 생겼는지, 로그 설계는 어떻게 해야하는지 등을 경험했어요\n그 당시엔 프로덕트 분석가라는 이름이 따로 있진 않았지만, 시간이 지나고 보니 이런 이름으로 불리게 되더라구요\n이직한 후에도 GA, Firebase 데이터를 어떻게 다룰지에 대해 생각해보고, 앱 로그 데이터에 대한 마트를 제작하기도 했어요. 그래서 이 부분에 대해서는 많은 시행착오를 겪었어요\nAmplitude, Mixpanel에 대한 것도 개인적으로 경험해보면서, 로그 데이터가 어떻게 구성되고 어떤 관점으로 바라볼지에 대해 알게 되었어요\n그리고 비즈니스나 머신러닝 알고리즘 관점에서 AB Test를 해보고, 해석의 모호함이 생길 땐 어떻게 해결해야 할지, 통계적 유의성이 이슈가 있으면 어떻게 해야할지 등에 대해 경험했어요\n돌이켜보면, 저는 여러 직무를 경험했지만 B2C 앱 데이터를 많이 다루곤 했어요. 그래서 프로덕트 데이터 분석가 로드맵을 만들기로 했어요(제일 많이 경험하고 시행 착오가 존재하는)\n\n\n\n나는 왜 교육을 하는가?\n프로덕트 분석가라는 이름이 있지 않던 시절 이 분야를 공부할 때 참 어려웠어요. 회사 개발자분께서 DB를 배우는 것이 필요하다고 해서 새로쓴 대용량 데이터베이스 솔루션을 공부하기도 했어요. DB를 이해하는데 도움이 되긴 했지만, 내용이 너무 어려웠던 기억이 나네요(요즘 학습하면 LLM의 도움을 받아 더 쉽게 가능하겠지만)\n교육을 해야겠다고 다짐할 때, 과거의 저처럼 회사에서 업무를 진행하다가 어려움을 겪는 분들이 조금이나마 더 나은 길을 가길 바랬어요\n어떻게 보면 과거의 저에게 보내는 강의라고 볼 수 있어요\n    \n이 내용을 미리 알았다면 참 좋았을텐데, 실제로 해보면 이런 부분을 깊게 생각하면 좋은 것 등\n그래서 PM을 위한 데이터 리터러시 강의에는 “카일 스토리”라는 것이 나옵니다. 원래 강의 인트로에 연기하려고 했다가, 어설프게 하려니 이상해서 그냥 덤덤한 방식으로 전개했어요\n저를 경험한 분들이 더 좋은 삶을 살길 바라고 있어요. 그냥 각자가 더 좋은 삶(사람마다 정의하기 나름이지만)을 살길 바라고 있어요\n    \n여러 관점이 있지만, 인프런에 올리는 내용은 대부분 업무를 하다가 겪는 내용들을 다루곤 해요. 어떻게 해야 일을 더 잘할 수 있고, 회사에서 인정 받을 수 있을까?를 주로 다룹니다\n유튜브에는 커리어에서 생각할 수 있는 고민들을 주로 다루고, 로드맵이나 제 생각을 공유하곤 해요. 이런 내용을 통해 영감을 받길 바라고 있어요(꼭 그대로 하는 것이 아닌 자신만의 방법을 찾는 것)\n어떤 형태의 강의를 하고 싶었는지 생각해보면, 고등학생 때 들었던 신승범 선생님처럼 수업하고 싶었던 것 같네요. 강의 자체도 하지만, 인생에 대한 내용이나 어떻게 삶을 살아갈지, 동기부여 등도 같이 진행하고 싶었어요\n    \n요즘 수학은 정승제 선생님 강의를 듣던데, 이 맥락과 비슷한 것 같네요\n강의에 저도 이런 동기 부여에 대한 내용도 추가하려고 생각하고 있어요\n\n\n\n어떤 것이 중요하다고 생각했는가?\n강의는 총 3개로 구성되어 있고, 나머지는 유튜브 영상이에요.\nPM을 위한 데이터 리터러시\n    \n문제 정의, 구조적인 사고, 로그 설계, 실험 설계, 의사 결정, 데이터 문화 등 데이터를 다루다가 생기는 다양한 일을 모두 담았어요\n제 강의 중에 처음 어떤 강의를 들을까? 생각하면 이 강의가 제일 좋다고 생각합니다. 회사에서 어떤 방식으로 일을 하는지 알아보면서 데이터 분석을 어떻게 해야할지에 대해 알 수 있어요\n제가 익힌 여러 암묵지를 모두 담은 강의라, 다시 이런 종류의 강의를 만들라고 하면 어떤 내용을 더 넣어야 할지 고민될 것 같네요. 물론 더 추가할 부분이 있긴 합니다\nPM 직무에 계신 분들도 보기 좋고, 디자이너, 데이터 분석가 모두 보면 좋을 내용으로 구성되어 있어요\n초보자를 위한 BigQuery(SQL)\n    \n데이터를 다루기 위해 SQL을 알아야 합니다.\n회사에서 SQL을 처음 배우는 분들이 어디서 어려움을 겪는지, 어떤 것을 알면 좋을지 고민하며 만들었어요\n강의에서 특히 힘을 준 부분은 “데이터 검증”, “쿼리를 작성하는 흐름”. 이 부분은 암묵지에 해당될 수 있는 내용인데, 회사에서 참 중요하다 생각했어요\n지표를 잘못 뽑고, 지표를 보는 분에게 잘못 뽑았다고 말하는 경우 종종 있을 수 있는데, 데이터 검증을 어떻게 해야할지에 대해 모르거나 쿼리의 실수로 발생하곤 합니다. 간단하게 특정 user_id를 선정해서 미리 확인해보는 과정으로 해결할 수 있는데, 이런 내용에 대해 알지 못하는 경우가 있었어요\n쿼리를 작성하는 흐름은 처음에 이런 큰 그림을 이해하면 더 잘 작성할 수 있다고 판단했어요\n쿼리를 작성할 때 참고할 수 있는 데이터 템플릿도 공유드리고, 이걸 자동화할 수 있는 도구도 알려드렸어요. Espanso라는 도구인데, 무료고 오픈소스라 많은 분들이 아시면 좋을거에요\n시간 데이터를 다룰 일이 많은데, 서버의 데이터는 UTC로 저장되어 있는 경우가 많아요. 이 때 타임존에 대한 내용을 모를 수 있는데, SQL에서 이 부분을 학습하면 좋겠다고 생각했어요\nBigQuery 활용편\n    \n이 강의는 입문편에서 다루진 않은 부분 중 유용한 함수인 윈도우 함수를 주로 다룹니다\nFirebase 데이터의 특징으로 배열 데이터를 다뤄야 하는데, 배열 데이터를 다루는 방법에 대해서도 학습합니다\n단순히 문법만 배우는 것이 아니라 퍼널 분석, 리텐션 분석을 어떻게 접근하면 좋은지 공유합니다\nPM을 위한 데이터 리터러시 강의랑 연결되는 부분인데, 제품에 대해 생각하고, 그 부분에서 리텐션 개선 아이디어를 생각하도록 강의를 구성했어요. 이렇게 말을 해도 실제로 데이터를 보면 데이터만 보게 되는 경우가 종종 있어서, 강의에서 계속 제품에 대해 고민할 수 있도록 생각을 공유했어요\nGoogle Sheets로 자동화를 할 수 있는 부분이 꽤 있는데, 이 부분도 알아가시면 좋을 것 같다 싶어 이 부분도 추가했어요\n\n\n\n데이터를 활용하고 싶은 분들이 어떻게 학습하면 좋을까\n이 부분은 최근에 쓰레드에 길게 남겼는데, 블로그에도 공유해보아요. 존댓말을 쓰지 않고 자유롭게 남긴 내용입니다\n하드 스킬에 대한 내용은 줄인 버전이고, 머신러닝이나 데이터 시각화 등에 대한 지식은 언제든 해도 괜찮다고 생각\n보통 데이터를 활용한다라고 하면 파이썬, SQL, 통계 같은 기술적인 것부터 생각한다. 그렇기 때문에 이걸 해야 데이터를 활용할 수 있다고 생각\n    \n데이터를 활용한다는 것은 데이터 기반 의사결정을 한다는 것이고, 이것은 문제를 해결하는 과정에서 지표를 정의해서 지표에 따른 의사 결정을 하는 것\n제일 중요한 것은 문제를 정의하고, 문제를 인식하는 것. 대부분 이 부분을 그냥 넘어가지만, 문제 정의를 잘 진행하는 것이 제일 중요하다. 정의가 잘 된다면 지표는 자연스럽게 나오고, 지표는 사용할 수 있는 도구(엑셀, 파이썬, SQL 등 사용 가능한 것)로 추출하면 된다\n논리적 사고는 “로지컬 씽킹” 책을 추천. 맥킨지식 논리적 사고로 유명하고, MECE / So What? Why So를 매번 생각한다\n사실 이 역량은 모든 직무에게 필요하다\n논리적 사고에 대해 어느정도 파악을 했다면, 그 후엔 무엇을 해야할까?\n    \n그 후엔 데이터를 어떤 관점으로 바라볼지에 대해 감을 잡으면 좋다. 신입 시절에 데이터를 어떻게 바라볼지에 대한 관점이 없이 일단 데이터를 뽑고 해석을 하려고 했는데, 데이터를 바라보는 관점이 없어서 어려웠다.\n데이터를 바라보는 과정에선 1) 그래프 기반, 2) 호기심 기반, 3) 상급자 기반 등이 있는데 3가지 방법보단 “목적 기반”으로 보는 것이 핵심. 어떤 목적을 가지고 어떤 지표를 볼지, 그리고 어떤 것을 해야할까?에 대해 생각해보는 것이 필요하다. 목적이 없으면 기준이나 판단이 어렵다.\n이런 관점에 대해 잘 나온 책은 “빅데이터 시대, 성과를 이끌어 내는 데이터 문해력” 이 책이 나왔을 때 처음 읽고 완전 감동받은 책. 논리적 사고랑 연결되는 부분이 있다\n(3) 논리적 사고, 데이터 목적에 대한 학습. 그 후엔?\n    \n앞선 것들을 잘 진행하기 위해, 회사의 비즈니스 모델을 잘 이해하면 좋다. 비즈니스 모델이란 것은 회사에서 매출이 언제 발생하고, 어떤 흐름으로 돈이 돌아다니는지를 의미한다. 데이터 분석을 한다는 것은 목적이 있을텐데, 회사의 서비스를 성장하기 위해 무엇을 해야할까?, 매출을 증가시키기 위해 무엇을 해야할까?, 비용을 줄이기 위해 무엇을 해야할까? 등을 생각한다. 이 때 비즈니스 모델을 이해하면 더 수월하게 생각할 수 있었다.\n관련해서는 “한 장으로 끝내는 비즈니스 모델 100” 책을 추천. 도식화로 정리가 되어있어서 도움이 된다. 그러면서 사용하고 있는 앱이나 서비스의 비즈니스 모델을 분석해보는 것도 추천\n강의를 들은 분들 중 면접을 잘 보고 싶다고 하는 분들에겐 “지원하는 회사의 비즈니스 모델”을 스스로 분석해보고, 도식화해서 그 내용 기반으로 무엇을 할지 생각해보라고 권한다. 이런 것을 하는 사람이 적다.\n(4) 논리적 사고, 데이터 목적, 비즈니스 모델. 그 후엔?\n    \n그 후에 간단한 통계학 공부를 하면 좋은데, 통계학을 어려워하는 사람이 있기에 처음엔 쉽게 접근하는 것을 추천한다.\n  “데이터 분석가의 숫자유감”이란 책이 있는데, 만화로 구성되어 있다. 통계를 활용하는 핵심적인 부분이 나와있어서 이 책을 보면 대략적으로 어떻게 활용해야 할지에 대해 감이 온다.\n그 후에 추천하는 책은 “숫자에 약한 사람들을 위한 통계학 수업”. 이 책도 핵심적인 통계학 개념을 쭉 훑고, 실용적인 관점에서 사례가 많이 나온다. 수학을 극도로 배제해서 눈높이를 낮추어서 많은 분들이 읽을 수 있다.\n그 후에 본격적인 통계를 공부하고 싶다면 “An Introduction to Statistical Learning”를 추천. 줄여서 ISLR라고도 하는데, 많은 분들이 이 책을 기본서 같이 생각한다. 한국어 번역이 있다고 들었지만, 원서를 추천. 구글에 책 제목을 검색하면 원서가 나온다(파이썬 버전도 있음)\n(5) 통계학 그 후엔 무엇을 해야할까, 이 시기엔 상황에 따라 다를듯. 우선 회사에 다니고 계신 분들 대상으로 먼저 이야기\n회사에 다니고 있다면, 어떤 문제를 해결해야 할 것. 진행하고 있는 업무가 문제와 관련되어 있을 것이다. 이 문제를 해결하기 위해 어떤 것을 해야할까? 어떤 지표를 봐야할까? 생각하기\n    \n이 과정에서 지표 정의에 대해서 알면 좋은데, 지표가 어렵다면 “문제가 해결되면 어떤 모습이 되는가? 그 모습을 숫자로 표시한다면?” 질문을 통해 정의. 요즘은 LLM이 잘 발전되어 있어서 어떤 문제를 해결하고 싶은지를 클로드 등에 물어보면 잘 추천해준다. 그러면 그 지표들을 모두 모아서 어떤 것을 사용할지 결정한다.\n그리고 해당 지표를 개발자나 데이터 분석가분들에게 부탁해서 받아보고, 그것 기반으로 “Action Item”을 생각해본다. 뭘 해야 그 지표를 올릴 수 있을까? 그리고 그것을 실행하고 기능 개발 -> 의사 결정. 바로 문제를 푸는 방법\n(6) 회사에 다니지 않는 취준생이라면\n    \n이런 경우 참 어렵다. 취준생 입장에서 데이터를 어떻게 구할까?라는 고민에 빠진다. 이를 해결하기 위해 캐글이란 플랫폼이 나왔지만, 캐글은 문제 정의가 된 후에 데이터를 제공한 후 모델링에 집중한다.\n데이터를 활용한다는 것은 문제에서 데이터를 해석하고, 의사결정하는 것이라고 볼 수 있다. 그리고 데이터가 쌓인 후 목적에 맞으면 예측 모델링을 진행한다.\n취준생이라면 내가 데이터 분석을 집중하고 싶은지, 모델링을 하고 싶은지 고민해야 한다. 많은 교육 과정에서 모델링 위주로 교육해서 혼란스러운 경우가 있는데, 나눠서 생각해보는 것을 추천.\n어떤 직무를 하던, 이 쯔음에 SQL/파이썬 등을 학습한다. 요즘은 대부분의 책이 잘 나와서 서점에서 고르는 것도 추천\n\n\n\n데이터 분석가 로드맵에 더 추가되면 좋은 것은?\n어떤 내용이 더 필요할까 생각해봤는데, 다음 내용을 추가하면 좋을 것 같다\n데이터 전처리에 대한 학습 : 데이터를 어떻게 처리할지에 대해 방법론이 다양한데 각 방법론의 장단점과 어떻게 활용하면 좋을지에 대해 학습\n설득하기, 협상하기 : 대화를 할 일이 참 많은 직무다. 설득하기, 협상하기는 어떤 직무여도 있으면 좋겠지만 데이터 분석가분들이 더 들어보면 좋겠다. 사내 컨설턴트가 된다는 생각도 같이 하면서\n그 후엔 자신이 자신 있는 도메인 영역을 정해보면 좋겠다. 산업이여도 괜찮고, 비즈니스나 프러덕트 등으로 생각해도 좋다. 하나의 도메인에서 해결할 수 있는 문제를 거시적으로도 파악하고, 미시적으로도 파악해보면 좋겠다\n경영진의 사고 과정 : 경영진에 계신 분들이 어떤 생각을 주로 하고, 어떻게 생각하는지 알아두면 좋다. 이런 생각을 할 수 있게 된다면, 내가 지금 어떤 일을 해야할지를 더 잘 생각할 수 있다. 상황에 따라 유연한 접근이 필요한데, 대표님이 지금 무슨 생각을 할까?라는 생각을 하면서 업무를 하곤 했다\n물론 위에 말한 내용은 일반적인 데이터 분석가 로드맵에서 나오는 내용도 있지만, 아닌 내용도 있다. 회사에서 일을 잘 진행하기 위해 필요했던 내용인데 나만의 경험일 수도 있을 것 같고, 아닐수도 있다\n데이터 사이언티스트가 되고 싶다면, 데이터 분석도 해보고 전략, 데이터 엔지니어링 등을 모두 경험해보는 것을 추천한다. 다만 요즘 데이터 사이언티스트도 회사마다 다르다. 주로 추천 알고리즘을 만들고 데이터 분석을 할 때 데이터 사이언티스트라고 불리는 것 같다\n\n\n\n앞으로 할 것들\n데이터 분석 관련 강의는 잠시 쉬고, 원래 만들고 싶었던 내용을 만들려고 합니다\n어떻게 해야 데이터 엔지니어링을 쉽게 할 수 있을지에 대한 내용. 그리고 데이터 분석가가 이정도는 알면 좋은 개발 지식. 이렇게 선언해두면, 언젠가 하려고 시도할거라 생각해서 선언해두어요\n일단 개발자 블로그 글쓰기 강의는 빠르게 만들 수 있어서, 이것부터 하고 전체적인  강의에 대해 설계할 예정\n강의 만드는 것도 시행착오가 있어서, 여러 방법으로 시도하고 있어요. 이제는 어떻게 해야 속도를 낼 수 있을지 감을 잡아서 계속 시도해볼 예정이에요.\n그 후엔 다시 회사로 돌아가지 않을까 싶어요. 다만 그 사이에 최선을 다해 강의를 만들려고 해요. 회사에 들어가서 온보딩 자료로 활용할 수 있는 수준으로 강의를 만들려고 합니다. 정해진 것은 아무것도 없지만, 일단 이정도로 생각하고 있어요\n최근 데이터 리터러시에 대한 니즈를 많이 느끼고 있어요. 강의 판매도 늘어나고 있고, 기업 강의도 요청받고 있어요. 많은 분들이 데이터를 더 잘 활용하고, 쉽게 접근할 수 있도록 계속 하나씩 만들어 볼게요\n    \n회사에서 데이터를 어떻게 활용해야 하는지 가이드를 주고, 더 잘 진행할 수 있도록 돕는 직무도 점점 필요해지는 것 같아요. 단순히 데이터 프러덕트를 만들고 끝이 아니고 여러 조직에 있는 사람들의 상황을 파악하고 해결할 수 있는 방법 도출\n저는 데이터 분석가분들이 점점 데이터 엔지니어링을 할 수 있어야 하고, 데이터 엔지니어도 데이터나 비즈니스에 대한 큰 그림을 이해하면 좋다고 생각해요. 회사 상황에 따라 다를 수도 있지만, 데이터 관련 큰 그림을 잘 이해할 수 있는 사람들이 더 필요한 시기라고 생각해요\n대학생분들을 어떻게 도울 수 있을까 고민하고 있어요. 대학원을 가지 않은 제가 교수를 하긴 어려워서, 지금 진행하고 있는 일들을 집중하려고 해요. 부스트캠프 AI Tech와 유튜브 등. 학생분들이 도움을 구하면 가능하면 최대한 시도해보려고 하고 있어요\n데이터 직무가 아닌 분들이 어떻게 데이터를 잘 활용할 수 있을까? 이 부분에 대해 활용 지침 위주로 내용을 정리해볼까 생각하고 있어요\n\n\n\n마무리\n인프런에 올린 로드맵에 관심이 있다면 한번 봐주셔요. 유튜브 영상도 추가해두었어요\n    \n2주 동안 로드맵 화면에서 쿠폰을 발급 받을 수 있어요. 필요하시다면 활용하셔도 좋을 것 같아요.\n앞으로 제가 어떤 일을 할지, 어떤 커리어를 밟을지 잘 모르지만 지금 상황에 진심을 다해 하나씩 해볼 예정이에요. 지금의 시간이 참 소중하기에.\n제게 궁금한 내용이 있다면 무엇이든 말씀해주셔요. 이 글에 대한 피드백도 좋아요. 제가 답이라는 것은 아니고, 제 생각을 공유했으니 여러 이야기를 나누며 합쳐보고 싶네요.\n\n\n\n\n  \n글 작성하는데 걸린 시간 : 약 40분",
        "guid": "https://zzsza.github.io/diary/2024/08/21/product-analyst-roadmap/",
        "categories": [
          "diary",
          "diary"
        ],
        "isoDate": "2024-08-21T00:00:00.000Z"
      }
    ]
  },
  {
    "name": "oddpoet’s étude",
    "category": "개인",
    "posts": []
  },
  {
    "name": "0x00 - NULL",
    "category": "개인",
    "posts": []
  },
  {
    "name": "퇴근 후 서버다운",
    "category": "개인",
    "posts": [
      {
        "creator": "SIDNFT",
        "title": "Firebase 세금 - 간이결제 일반결제 - 바꾸는 ui 어딧을까?",
        "link": "http://serverdown.tistory.com/793",
        "pubDate": "Wed, 21 Aug 2024 01:44:17 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/793#entry793comment",
        "content": "<p data-ke-size=\"size16\">법인은 일반과세를 해야한다고합니다.</p>\n<p data-ke-size=\"size16\">간이는 어디 쓰는지 모르겠는데 싸보여서 했다가 고쳐야할일이 생겨서 ui 열심히 찾았습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">간이과세 일반과세 부분을 바꾸려면 간단하게는 안되고</p>\n<p data-ke-size=\"size16\">1. Firebase 에서 무료 오금제로 변경합니다.</p>\n<p data-ke-size=\"size16\">Blaze -&gt; Spark 로 바꾸라는 이야기</p>\n<p data-ke-size=\"size16\">좌측 하단에 수정 버튼이 있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"355\" data-origin-height=\"304\"><span data-url=\"https://blog.kakaocdn.net/dn/P8ZZG/btsJaS6oPcC/EqySgA5Yhuf8ubXJKnkbL0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/P8ZZG/btsJaS6oPcC/EqySgA5Yhuf8ubXJKnkbL0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/P8ZZG/btsJaS6oPcC/EqySgA5Yhuf8ubXJKnkbL0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FP8ZZG%2FbtsJaS6oPcC%2FEqySgA5Yhuf8ubXJKnkbL0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"355\" data-origin-height=\"304\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">2. 무료로 다운그레이드하시고 다시 Blaze 요금제를 선택할때 결제 프로필을 고르라고 합니다.</p>\n<p data-ke-size=\"size16\">이때 프로필 새로 만들기를 하면</p>\n<p data-ke-size=\"size16\">예전 데이터가 입력되어있으니 여기서 과세 부분만 바꿔서 다시 진행 하시면 됩니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">==== 아래는 과세 정보 보는 UI 위치에 대한 설명입니다. ===</p>\n<p data-ke-size=\"size16\">과세 유형 바꿀수 있는지 알고 적상했는데</p>\n<p data-ke-size=\"size16\">변경이 안되는군요 UI 위치 참고용으로 남겨둡니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">1. Firebase 콘솔 에서 프로젝트 고릅니다.</p>\n<p data-ke-size=\"size16\">2.&nbsp; 우측 메뉴에서 [프로젝트 개요] -&gt; [톱니바퀴] -&gt; [사용량 및 결제] 로 갑니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"476\" data-origin-height=\"255\"><span data-url=\"https://blog.kakaocdn.net/dn/dIEpre/btsI9OoBgTz/aDRD8DYB3ybQXHiKZl4t4K/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/dIEpre/btsI9OoBgTz/aDRD8DYB3ybQXHiKZl4t4K/img.png\"><img src=\"https://blog.kakaocdn.net/dn/dIEpre/btsI9OoBgTz/aDRD8DYB3ybQXHiKZl4t4K/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdIEpre%2FbtsI9OoBgTz%2FaDRD8DYB3ybQXHiKZl4t4K%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"476\" data-origin-height=\"255\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">3. [계정보기] 들어갑니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"699\" data-origin-height=\"668\"><span data-url=\"https://blog.kakaocdn.net/dn/bIucWz/btsI81CcStp/vXs6ZSn4lnk7xvm2Vk4ck0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bIucWz/btsI81CcStp/vXs6ZSn4lnk7xvm2Vk4ck0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bIucWz/btsI81CcStp/vXs6ZSn4lnk7xvm2Vk4ck0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbIucWz%2FbtsI81CcStp%2FvXs6ZSn4lnk7xvm2Vk4ck0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"699\" data-origin-height=\"668\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">4.&nbsp; Google Cloud 로 왔네요 우측 하단에 [결제 설정] 누릅니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"341\" data-origin-height=\"632\"><span data-url=\"https://blog.kakaocdn.net/dn/try4n/btsI9bEBjWb/psdk649aFE5TDmjxCWccg0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/try4n/btsI9bEBjWb/psdk649aFE5TDmjxCWccg0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/try4n/btsI9bEBjWb/psdk649aFE5TDmjxCWccg0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Ftry4n%2FbtsI9bEBjWb%2Fpsdk649aFE5TDmjxCWccg0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"341\" data-origin-height=\"632\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">5. 간이과세 골랐던 부분이 있습니다. ctrl-f 눌러서 검색하셔도 되구요 잘찾아보세요</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"307\" data-origin-height=\"126\"><span data-url=\"https://blog.kakaocdn.net/dn/bqmjko/btsI8QAYamq/V3ebNfO1gx8Va8sTdwuG0K/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bqmjko/btsI8QAYamq/V3ebNfO1gx8Va8sTdwuG0K/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bqmjko/btsI8QAYamq/V3ebNfO1gx8Va8sTdwuG0K/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbqmjko%2FbtsI8QAYamq%2FV3ebNfO1gx8Va8sTdwuG0K%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"307\" data-origin-height=\"126\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">이상입니다.</p>\n<p data-ke-size=\"size16\">변경은 실패하더군요 보는 용도로만 ..</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "법인은 일반과세를 해야한다고합니다.\n간이는 어디 쓰는지 모르겠는데 싸보여서 했다가 고쳐야할일이 생겨서 ui 열심히 찾았습니다.\n \n간이과세 일반과세 부분을 바꾸려면 간단하게는 안되고\n1. Firebase 에서 무료 오금제로 변경합니다.\nBlaze -> Spark 로 바꾸라는 이야기\n좌측 하단에 수정 버튼이 있습니다.\n\n\n \n2. 무료로 다운그레이드하시고 다시 Blaze 요금제를 선택할때 결제 프로필을 고르라고 합니다.\n이때 프로필 새로 만들기를 하면\n예전 데이터가 입력되어있으니 여기서 과세 부분만 바꿔서 다시 진행 하시면 됩니다.\n \n \n==== 아래는 과세 정보 보는 UI 위치에 대한 설명입니다. ===\n과세 유형 바꿀수 있는지 알고 적상했는데\n변경이 안되는군요 UI 위치 참고용으로 남겨둡니다.\n \n1. Firebase 콘솔 에서 프로젝트 고릅니다.\n2.  우측 메뉴에서 [프로젝트 개요] -> [톱니바퀴] -> [사용량 및 결제] 로 갑니다.\n\n\n3. [계정보기] 들어갑니다.\n\n\n4.  Google Cloud 로 왔네요 우측 하단에 [결제 설정] 누릅니다.\n\n\n5. 간이과세 골랐던 부분이 있습니다. ctrl-f 눌러서 검색하셔도 되구요 잘찾아보세요\n\n\n이상입니다.\n변경은 실패하더군요 보는 용도로만 ..",
        "guid": "http://serverdown.tistory.com/793",
        "categories": [
          "프로그래밍/개발메모",
          "Firebase"
        ],
        "isoDate": "2024-08-20T16:44:17.000Z"
      }
    ]
  },
  {
    "name": "coolspeed",
    "category": "개인",
    "posts": []
  },
  {
    "name": "오늘도 끄적끄적",
    "category": "개인",
    "posts": []
  },
  {
    "name": "dx11 Vanica's Lifelog - 夢が夢で終わらないように",
    "category": "개인",
    "posts": []
  },
  {
    "name": "초코사랑",
    "category": "개인",
    "posts": []
  },
  {
    "name": "ZeroCho Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Hybrid's Notes",
    "category": "개인",
    "posts": []
  },
  {
    "name": "imays게임엔진개발자",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for hurinmon Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "기억보단 기록을",
    "category": "개인",
    "posts": [
      {
        "creator": "향로 (기억보단 기록을)",
        "title": "1. TS를 만나고 - 디자인",
        "link": "https://jojoldu.tistory.com/801",
        "pubDate": "Mon, 26 Aug 2024 12:43:13 +0900",
        "author": "향로 (기억보단 기록을)",
        "comments": "https://jojoldu.tistory.com/801#entry801comment",
        "content": "<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">JVM 컨퍼런스가 있으면 \"Java 세상에서 살던 사람이 처음 TS 세계를 만나고 느낀 여러가지 차이점\" 을 발표하려고했는데, 시간도 너무 지났고, 발표 준비하기도 쉽지 않은 것 같아 블로그에 시리즈로 시작한다.<br />Java가 구린 언어다를 표현하기 위한 글이기 보다는 <a href=\"https://jojoldu.tistory.com/687\">전작(다른 언어로 성장하기)</a>과 마찬가지로 타 생태계를 통해 성장할 수 있음을 알리는 글이다</p>\n</blockquote>\n<p data-ke-size=\"size16\">자바를 처음 배울때 <code>getter/setter</code> 에 대한 이야기를 많이 들었다.<br />캡슐화 등의 장점을 들으면서 클래스 안에는 항상 무분별하게 <code>getter/setter</code> 를 생성했다.<br />(그때는 Lombok을 배우지 못했던 터라) IDE의 자동 생성 기능을 사용하면서 열심히 <code>getter/setter</code>를 생성했다.</p>\n<p data-ke-size=\"size16\">물론 예전부터 많은 분들은 무분별한 getter/setter를 사용하지말라는 글과 토론을 나누었다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><a href=\"https://www.yegor256.com/2014/09/16/getters-and-setters-are-evil.html\">2014.09.16 - getters-and-setters-are-evil</a></li>\n</ul>\n<p data-ke-size=\"size16\">다만, 내가 배울때 법칙?처럼 <code>getter/setter</code> 만든다로 배워서 그렇게 했다.<br />(지금이야 getter/setter를 쓰지 않고, <a href=\"https://martinfowler.com/bliki/TellDontAsk.html\">Tell, Don't Ask</a> 를 당연한 것처럼 다뤄지고 있지만 말이다.)</p>\n<p data-ke-size=\"size16\">여튼, 배우던 당시에는 무분별하게 <code>getter/setter</code>를 만들다보니 \"<b>어차피 단순한 data holders로 사용하는데 그냥 public으로 열면 안되나</b>\" 같은 생각이 들었다.</p>\n<p data-ke-size=\"size16\">이를 테면 다음과 같다.<br />매번 아래와 같이 생성하는데,</p>\n<pre class=\"cpp\"><code>public class Course {\n    private int price;\n\n    public int getPrice() {\n        return price;\n    }\n\n    public void setPrice(int price) {\n        this.price = price;\n    }\n}</code></pre>\n<p data-ke-size=\"size16\">아래와 같이 \"그냥 <code>public</code> 으로 열어두는 것과 무엇이 다르지?\" 라는 생각인 것이다.</p>\n<pre class=\"angelscript\"><code>public class Course {\n    public int price;\n}</code></pre>\n<p data-ke-size=\"size16\">어차피 값을 넣고 빼는 역할 밖에 없는데, 똑같지 않나? 라는 생각을 하곤 했다.</p>\n<p data-ke-size=\"size16\">그러다가 기능이 여러가지로 확장되는 상황을 만나니 접근자를 통해서 사용해야하는 것의 중요성을 알게 되었다.</p>\n<p data-ke-size=\"size16\">예를 들어 단순히 <code>price</code>에 값을 넣기만 하면 되는 로직에서 아래와 같이 <b>부가세 10%가 추가된 가격으로 반환해야한다</b>는 조건이 추가되니 단순히 <code>public</code> 으로 열어두는 것은 기존의 코드를 모두 바꿔야하는 문제가 생겼다.</p>\n<pre class=\"angelscript\"><code>public class Course {\n    ...\n\n    public int getPrice() {\n        return (int) (price * 1.1); // 부가세 10% 적용\n    }\n}\n\ncoursePrice = course.price; // &lt;&lt;&lt; 이렇게 호출되는 코드들이\ncoursePrice = course.getPrice(); // &lt;&lt;&lt; 이 코드로 모두 변경되어야만 했다.</code></pre>\n<p data-ke-size=\"size16\">접근자를 통해서 처음 구현해두지 않으니, 이런 경우가 발생했다.<br />그래서 \"<b>처음부터 접근자를 생성해두고, 이를 호출자들이 사용하도록 해야만 이런 문제를 겪지 않는 다</b>\" 는 것을 알게되었다.</p>\n<p data-ke-size=\"size16\">다만, 그럼 \"매번 이렇게 접근자를 생성해두고 코드를 작성해야하는 불편함과 귀찮음은 어쩔 수 없는 것인가\" 라는 생각은 계속 들었다.</p>\n<p data-ke-size=\"size16\">그러던 중, JavaScript/TypeScript 코드들을 보게 되었는데, 여기서는 <code>get/set</code> 접근자를 언어 레벨에서 지원했다.</p>\n<p data-ke-size=\"size16\">즉, <b>아래 2개 코드는 호출자 입장에서 동일한 방법으로 호출할 수 있다</b>.</p>\n<pre class=\"kotlin\"><code>// 1. 접근자 없이 public 필드\nclass Course {\n    public price: number;\n\n    constructor(price: number) {\n        this.price = price;\n    }\n}\n\n// 2. 접근자를 통한 접근\nclass Course {\n    private _price: number;\n\n    ...\n\n    get price(): number {\n        return this._price;\n    }\n}\n\nval price = course.price; // 1, 2 모두 동일한 코드로 호출</code></pre>\n<p data-ke-size=\"size16\">이건 코틀린도 동일한데, 코틀린 역시 <code>get/set</code> 접근자를 언어 레벨에서 지원한다.</p>\n<pre class=\"kotlin\"><code>// 1. 접근자 없이 public 필드\nclass Course(var price: Int)\n\n// 2. 접근자를 통한 접근\nclass Course(private var _price: Int) {\n    var price: Int\n        get() = (_price * 1.1).toInt() // 부가세 10% 적용\n}\n\nval coursePrice = course.price</code></pre>\n<p data-ke-size=\"size16\">(코틀린과 자바를 굳이 다른 생태계라고 구분하지는 않지만)<br />이런 개념이 요즘의 모던한 언어들에게는 기본적으로 내장되어있다.</p>\n<p data-ke-size=\"size16\">Java를 처음 배우는 입장에서는 \"public 필드를 사용하면 안되고, private 필드를 사용하고 이에 대한 접근자를 무조건 생성해야한다\" 를 배워야만 했다.<br />이걸 그나마 편하게 하기 위해 Lombok 라이브러리 등의 도입도 알아야만 한다.<br />만약 이 모든걸 무시하고 처음 배운 클래스에서 단순히 public 필드를 사용하면 이후에 큰 비용을 지불하게 된다.</p>\n<p data-ke-size=\"size16\">반면, <b>JS, TS, Kotlin 등의 언어를 배우는 입장에서는 이런 것이 고민 거리이자 배워야할 내용이 되지 않는다</b>.<br />public 필드를 사용하는 것과 접근자를 통한 접근이 모두 <b>동일한 인터페이스를 지원하기 때문에 내가 알게되는 지식이 늘어난다고해서 기존의 코드들이 전체 교체 될 일은 거의 없다</b>.<br />즉, 프로그래밍을 배우고 사용할때 중요한 고민거리가 하나 없어지게 되는 셈이다.</p>\n<p data-ke-size=\"size16\">이런 사례는 <b>언어 레벨에서 좋은 디자인 인터페이스를 지원한다</b> 라는 의미로 다가왔다.</p>\n<p data-ke-size=\"size16\">처음 클래스를 배울때 단순하게 public으로 모든 필드를 선언하고 코드를 작성하더라도 이후에 <b>접근자 (accessor) 개념을 배우고 클래스 코드를 변경하더라도 기존 호출자 코드에 변경이 필요하지 않는다</b>는 것을 초보 개발자들에게 알려줄 수 있는 셈이다.</p>\n<p data-ke-size=\"size16\">이걸로 변경에 유연한 디자인을 아주 쉽게 익히게 된다.<br />Lombok 같은 외부의 라이브러리를 도입해야한다거나,<br />접근자 (accessor) 에 대한 개념을 배운다던가 그런 언어 외적인 추가적인 학습없이 말이다.</p>\n<h2 data-ke-size=\"size26\">마무리</h2>\n<p data-ke-size=\"size16\">좋은 언어는 그 자체로 좋은 디자인을 배울 수 있어야 한다는 생각을 한다.<br />그런면에서 문법 설탕에 불과하다고 이야기하는 사람들도 있지만, 특정 프레임워크, 라이브러리의 도움으로 해결하는 문제들을 언어 레벨에서 직접 해결해주고 있다는 점이 참 좋았다.</p>\n<p data-ke-size=\"size16\">그리고 그런 개념들이 TS, Kotlin 등 Java가 아닌 다른 언어에서는 당연하게도 들어가 있다는 점이 섬세하게도 느껴졌다.<br />(물론 Kotlin과 Java 사이에 큰 차이가 있냐는 의견에도 동의하지만 말이다.)</p>\n<h2 data-ke-size=\"size26\">함께 보면 좋은 글</h2>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><a href=\"https://jojoldu.tistory.com/687\">다른 언어로 성장하기</a></li>\n</ul>",
        "contentSnippet": "JVM 컨퍼런스가 있으면 \"Java 세상에서 살던 사람이 처음 TS 세계를 만나고 느낀 여러가지 차이점\" 을 발표하려고했는데, 시간도 너무 지났고, 발표 준비하기도 쉽지 않은 것 같아 블로그에 시리즈로 시작한다.\nJava가 구린 언어다를 표현하기 위한 글이기 보다는 전작(다른 언어로 성장하기)과 마찬가지로 타 생태계를 통해 성장할 수 있음을 알리는 글이다\n자바를 처음 배울때 getter/setter 에 대한 이야기를 많이 들었다.\n캡슐화 등의 장점을 들으면서 클래스 안에는 항상 무분별하게 getter/setter 를 생성했다.\n(그때는 Lombok을 배우지 못했던 터라) IDE의 자동 생성 기능을 사용하면서 열심히 getter/setter를 생성했다.\n물론 예전부터 많은 분들은 무분별한 getter/setter를 사용하지말라는 글과 토론을 나누었다.\n2014.09.16 - getters-and-setters-are-evil\n다만, 내가 배울때 법칙?처럼 getter/setter 만든다로 배워서 그렇게 했다.\n(지금이야 getter/setter를 쓰지 않고, Tell, Don't Ask 를 당연한 것처럼 다뤄지고 있지만 말이다.)\n여튼, 배우던 당시에는 무분별하게 getter/setter를 만들다보니 \"어차피 단순한 data holders로 사용하는데 그냥 public으로 열면 안되나\" 같은 생각이 들었다.\n이를 테면 다음과 같다.\n매번 아래와 같이 생성하는데,\npublic class Course {\n    private int price;\n\n    public int getPrice() {\n        return price;\n    }\n\n    public void setPrice(int price) {\n        this.price = price;\n    }\n}\n아래와 같이 \"그냥 public 으로 열어두는 것과 무엇이 다르지?\" 라는 생각인 것이다.\npublic class Course {\n    public int price;\n}\n어차피 값을 넣고 빼는 역할 밖에 없는데, 똑같지 않나? 라는 생각을 하곤 했다.\n그러다가 기능이 여러가지로 확장되는 상황을 만나니 접근자를 통해서 사용해야하는 것의 중요성을 알게 되었다.\n예를 들어 단순히 price에 값을 넣기만 하면 되는 로직에서 아래와 같이 부가세 10%가 추가된 가격으로 반환해야한다는 조건이 추가되니 단순히 public 으로 열어두는 것은 기존의 코드를 모두 바꿔야하는 문제가 생겼다.\npublic class Course {\n    ...\n\n    public int getPrice() {\n        return (int) (price * 1.1); // 부가세 10% 적용\n    }\n}\n\ncoursePrice = course.price; // <<< 이렇게 호출되는 코드들이\ncoursePrice = course.getPrice(); // <<< 이 코드로 모두 변경되어야만 했다.\n접근자를 통해서 처음 구현해두지 않으니, 이런 경우가 발생했다.\n그래서 \"처음부터 접근자를 생성해두고, 이를 호출자들이 사용하도록 해야만 이런 문제를 겪지 않는 다\" 는 것을 알게되었다.\n다만, 그럼 \"매번 이렇게 접근자를 생성해두고 코드를 작성해야하는 불편함과 귀찮음은 어쩔 수 없는 것인가\" 라는 생각은 계속 들었다.\n그러던 중, JavaScript/TypeScript 코드들을 보게 되었는데, 여기서는 get/set 접근자를 언어 레벨에서 지원했다.\n즉, 아래 2개 코드는 호출자 입장에서 동일한 방법으로 호출할 수 있다.\n// 1. 접근자 없이 public 필드\nclass Course {\n    public price: number;\n\n    constructor(price: number) {\n        this.price = price;\n    }\n}\n\n// 2. 접근자를 통한 접근\nclass Course {\n    private _price: number;\n\n    ...\n\n    get price(): number {\n        return this._price;\n    }\n}\n\nval price = course.price; // 1, 2 모두 동일한 코드로 호출\n이건 코틀린도 동일한데, 코틀린 역시 get/set 접근자를 언어 레벨에서 지원한다.\n// 1. 접근자 없이 public 필드\nclass Course(var price: Int)\n\n// 2. 접근자를 통한 접근\nclass Course(private var _price: Int) {\n    var price: Int\n        get() = (_price * 1.1).toInt() // 부가세 10% 적용\n}\n\nval coursePrice = course.price\n(코틀린과 자바를 굳이 다른 생태계라고 구분하지는 않지만)\n이런 개념이 요즘의 모던한 언어들에게는 기본적으로 내장되어있다.\nJava를 처음 배우는 입장에서는 \"public 필드를 사용하면 안되고, private 필드를 사용하고 이에 대한 접근자를 무조건 생성해야한다\" 를 배워야만 했다.\n이걸 그나마 편하게 하기 위해 Lombok 라이브러리 등의 도입도 알아야만 한다.\n만약 이 모든걸 무시하고 처음 배운 클래스에서 단순히 public 필드를 사용하면 이후에 큰 비용을 지불하게 된다.\n반면, JS, TS, Kotlin 등의 언어를 배우는 입장에서는 이런 것이 고민 거리이자 배워야할 내용이 되지 않는다.\npublic 필드를 사용하는 것과 접근자를 통한 접근이 모두 동일한 인터페이스를 지원하기 때문에 내가 알게되는 지식이 늘어난다고해서 기존의 코드들이 전체 교체 될 일은 거의 없다.\n즉, 프로그래밍을 배우고 사용할때 중요한 고민거리가 하나 없어지게 되는 셈이다.\n이런 사례는 언어 레벨에서 좋은 디자인 인터페이스를 지원한다 라는 의미로 다가왔다.\n처음 클래스를 배울때 단순하게 public으로 모든 필드를 선언하고 코드를 작성하더라도 이후에 접근자 (accessor) 개념을 배우고 클래스 코드를 변경하더라도 기존 호출자 코드에 변경이 필요하지 않는다는 것을 초보 개발자들에게 알려줄 수 있는 셈이다.\n이걸로 변경에 유연한 디자인을 아주 쉽게 익히게 된다.\nLombok 같은 외부의 라이브러리를 도입해야한다거나,\n접근자 (accessor) 에 대한 개념을 배운다던가 그런 언어 외적인 추가적인 학습없이 말이다.\n마무리\n좋은 언어는 그 자체로 좋은 디자인을 배울 수 있어야 한다는 생각을 한다.\n그런면에서 문법 설탕에 불과하다고 이야기하는 사람들도 있지만, 특정 프레임워크, 라이브러리의 도움으로 해결하는 문제들을 언어 레벨에서 직접 해결해주고 있다는 점이 참 좋았다.\n그리고 그런 개념들이 TS, Kotlin 등 Java가 아닌 다른 언어에서는 당연하게도 들어가 있다는 점이 섬세하게도 느껴졌다.\n(물론 Kotlin과 Java 사이에 큰 차이가 있냐는 의견에도 동의하지만 말이다.)\n함께 보면 좋은 글\n다른 언어로 성장하기",
        "guid": "https://jojoldu.tistory.com/801",
        "categories": [
          "Architecture",
          "Java",
          "kotlin",
          "node.js",
          "typescript",
          "인터페이스",
          "자바",
          "코틀린",
          "타입스크립트"
        ],
        "isoDate": "2024-08-26T03:43:13.000Z"
      }
    ]
  },
  {
    "name": "WestwoodForever's Dev Log",
    "category": "개인",
    "posts": []
  },
  {
    "name": "허니몬(Honeymon)의 자바guru",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Wolf Loves Fox :: 일상",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Game Programmer Life",
    "category": "개인",
    "posts": []
  },
  {
    "name": "IT 프리랜서 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "yuchi's dev",
    "category": "개인",
    "posts": [
      {
        "creator": "megayuchi",
        "title": "LightMap 구현전략",
        "link": "https://megayuchi.com/2024/08/22/lightmap-%ea%b5%ac%ed%98%84%ec%a0%84%eb%9e%b5/",
        "pubDate": "Thu, 22 Aug 2024 14:10:10 +0000",
        "content:encodedSnippet": "2024년 8월 22일 방송분입니다.",
        "dc:creator": "megayuchi",
        "comments": "https://megayuchi.com/2024/08/22/lightmap-%ea%b5%ac%ed%98%84%ec%a0%84%eb%9e%b5/#respond",
        "content": "2024년 8월 22일 방송분입니다.",
        "contentSnippet": "2024년 8월 22일 방송분입니다.",
        "guid": "http://megayuchi.com/?p=7047",
        "categories": [
          "Development",
          "Game Engine Development",
          "GPU"
        ],
        "isoDate": "2024-08-22T14:10:10.000Z"
      }
    ]
  },
  {
    "name": "만화로 나누는 자유/오픈소스 소프트웨어 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "신현석(Hyeonseok Shin)",
    "category": "개인",
    "posts": [
      {
        "title": "Puppeteer로 웹페이지 열고 조작하기",
        "link": "https://hyeonseok.com/blog/916",
        "pubDate": "Sun, 25 Aug 2024 17:26:34 GMT",
        "content": "<p>화면 없이 웹 브라우징을 할 수 있는 제품으로 기억나는 최초는 <a href=\"https://phantomjs.org/\">팬텀(PhantomJS)</a>이다. 화면도 없이 브라우저를 열고 스크린 샷도 찍고 탐색하는 것이 엄청 신기했다. 지금은 개발이 중단되었다. 팬텀의 불편함을 극복해보고자 <a href=\"https://github.com/casperjs/casperjs\">캐스퍼(CasperJS)</a>도 나왔었는데 이것 역시 지금은 개발이 중단되었다. 아마도 <a href=\"https://pptr.dev/\">퍼피티어(Puppeteer)</a>와 <a href=\"https://playwright.dev/\">플레이라이트(Playwright)</a>같은 대안 프로젝트들이 구글과 마이크로소프트 같은 큰 회사에서 나와서 그렇게 된 것 같다.</p>\r\n\r\n<p>플레이라이트가 퍼피티어를 포크해서 나왔다고 하는데 두 프로젝트는 지향하는 바가 다르다. 퍼피티어가 헤드리스 크롬이나 <a href=\"https://hacks.mozilla.org/2024/08/puppeteer-support-for-firefox/\">파이어폭스</a>를 편하게 활용할 수 있게 고안되었다면 플레이라이트는 테스트를 위한 스위트에 가깝다. 나는 테스트를 돌리기 보다는 브라우저에서의 작업이 필요해서 퍼피티어를 선택했다.</p>\r\n\r\n<p>API는 상당히 직관적이어서 <a href=\"https://pptr.dev/#example\">예제</a>를 보면 바로 브라우저를 실행해서 테스트 해 볼 수 있다. 브라우저 열고 페이지 열고 등 코드만 봐도 바로 이해가 간다. 나는 처리해야 하는 작업이 많아서 별도 스크립트를 <a href=\"https://pptr.dev/api/puppeteer.page.__eval/\"><code>page.$$eval</code></a>을 사용해서 실행했다.</p>\r\n\r\n<pre><code>const imageCount = await page.$$eval(\"img\", (imgs) => imgs.length)</code></pre>\r\n\r\n<p>서로 다른 컨텍스트를 직관적으로 연결해줘서 아주 사용하기 편하다. 예전과 비교하면 정말 좋아졌다.</p>\r\n\r\n<p>페이지를 열려면 <code>const browser = await puppeteer.launch()</code>로 브라우저를 실행하고 <code>const page = await browser.newPage()</code>로 페이지를 열어서 사용하게 된다. 처음에는 매번 브라우저를 여는 시간도 아깝고 보통 브라우저 사용하듯이 하나 실행해 놓고 페이지만 열고 닫으며 사용해봤다. 이렇게 하니 평소에 브라우저가 메모리 많이 사용하고 있다고 욕하던 상황이 서버에서 벌어져서 서버가 죽었다. 프로세스가 열리는 것을 보니 페이지 하나만 열어도 크롬 관련 프로세스가 열개가 넘게 뜨고 <code>await page.close()</code>로 페이지를 닫아줘도 일부 프로세스들이 계속 남아 있었다. 결국 계속 쓸수록 메모리 점유가 늘어났다. <code>await browser.close()</code>로 실행된 브라우저를 닫아줘야 프로세스가 모두 정리가 된다.</p>\r\n\r\n<p><a href=\"https://accessibility.kr/\">accessibility.kr</a>에서 지금까지는 자바스크립트로 생성되는 페이지를 검사할 수 없었는데 이제 검사할 수 있는 사이트가 많이 늘어났다. 리다이렉션 처리도 많이 개선되었다.</p>",
        "contentSnippet": "화면 없이 웹 브라우징을 할 수 있는 제품으로 기억나는 최초는 팬텀(PhantomJS)이다. 화면도 없이 브라우저를 열고 스크린 샷도 찍고 탐색하는 것이 엄청 신기했다. 지금은 개발이 중단되었다. 팬텀의 불편함을 극복해보고자 캐스퍼(CasperJS)도 나왔었는데 이것 역시 지금은 개발이 중단되었다. 아마도 퍼피티어(Puppeteer)와 플레이라이트(Playwright)같은 대안 프로젝트들이 구글과 마이크로소프트 같은 큰 회사에서 나와서 그렇게 된 것 같다.\n\r\n\r\n플레이라이트가 퍼피티어를 포크해서 나왔다고 하는데 두 프로젝트는 지향하는 바가 다르다. 퍼피티어가 헤드리스 크롬이나 파이어폭스를 편하게 활용할 수 있게 고안되었다면 플레이라이트는 테스트를 위한 스위트에 가깝다. 나는 테스트를 돌리기 보다는 브라우저에서의 작업이 필요해서 퍼피티어를 선택했다.\n\r\n\r\nAPI는 상당히 직관적이어서 예제를 보면 바로 브라우저를 실행해서 테스트 해 볼 수 있다. 브라우저 열고 페이지 열고 등 코드만 봐도 바로 이해가 간다. 나는 처리해야 하는 작업이 많아서 별도 스크립트를 page.$$eval을 사용해서 실행했다.\n\r\n\r\nconst imageCount = await page.$$eval(\"img\", (imgs) => imgs.length)\n\r\n\r\n서로 다른 컨텍스트를 직관적으로 연결해줘서 아주 사용하기 편하다. 예전과 비교하면 정말 좋아졌다.\n\r\n\r\n페이지를 열려면 const browser = await puppeteer.launch()로 브라우저를 실행하고 const page = await browser.newPage()로 페이지를 열어서 사용하게 된다. 처음에는 매번 브라우저를 여는 시간도 아깝고 보통 브라우저 사용하듯이 하나 실행해 놓고 페이지만 열고 닫으며 사용해봤다. 이렇게 하니 평소에 브라우저가 메모리 많이 사용하고 있다고 욕하던 상황이 서버에서 벌어져서 서버가 죽었다. 프로세스가 열리는 것을 보니 페이지 하나만 열어도 크롬 관련 프로세스가 열개가 넘게 뜨고 await page.close()로 페이지를 닫아줘도 일부 프로세스들이 계속 남아 있었다. 결국 계속 쓸수록 메모리 점유가 늘어났다. await browser.close()로 실행된 브라우저를 닫아줘야 프로세스가 모두 정리가 된다.\n\r\n\r\naccessibility.kr에서 지금까지는 자바스크립트로 생성되는 페이지를 검사할 수 없었는데 이제 검사할 수 있는 사이트가 많이 늘어났다. 리다이렉션 처리도 많이 개선되었다.",
        "guid": "https://hyeonseok.com/blog/916",
        "isoDate": "2024-08-25T17:26:34.000Z"
      }
    ]
  },
  {
    "name": "한상곤 - Sigmadream",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자 울이 노트",
    "category": "개인",
    "posts": []
  },
  {
    "name": "즐거운 개발자 :: 네이버  블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황제펭귄의 게임개발이야기 [여기는 한국]",
    "category": "개인",
    "posts": []
  },
  {
    "name": "LINE ENGINEERING",
    "category": "기업",
    "posts": [
      {
        "title": "Kafka와 ETL을 활용해 대용량 데이터 마이그레이션하기",
        "link": "https://techblog.lycorp.co.jp/ko/migrating-large-data-with-kafka-and-etl",
        "pubDate": "Mon, 26 Aug 2024 02:00:00 GMT",
        "content": "들어가며\n안녕하세요. LINE Plus에서 Global E-Commerce Platform 개발을 맡고 있는 장효택입니다. \nLINE Brand Catalog와 통합 커머스 검색 ...",
        "contentSnippet": "들어가며\n안녕하세요. LINE Plus에서 Global E-Commerce Platform 개발을 맡고 있는 장효택입니다. \nLINE Brand Catalog와 통합 커머스 검색 ...",
        "guid": "https://techblog.lycorp.co.jp/ko/migrating-large-data-with-kafka-and-etl",
        "isoDate": "2024-08-26T02:00:00.000Z"
      }
    ]
  },
  {
    "name": "뱅크샐러드 블로그",
    "category": "기업",
    "posts": [
      {
        "title": "이걸 진짜 만든다고요? 세상에 없던 게임, 샐러드게임 | 1편. BX",
        "link": "https://blog.banksalad.com/tech/banksalad-saladgame-1/",
        "pubDate": "Fri, 23 Aug 2024 00:00:00 GMT",
        "content": "“이걸 진짜 만든다고요? 🤯 ” 샐러드게임 탄생 배경 202…",
        "contentSnippet": "“이걸 진짜 만든다고요? 🤯 ” 샐러드게임 탄생 배경 202…",
        "guid": "https://blog.banksalad.com/tech/banksalad-saladgame-1/",
        "isoDate": "2024-08-23T00:00:00.000Z"
      },
      {
        "title": "이걸 진짜 만든다고요? 세상에 없던 게임, 샐러드게임 | 2편. UX",
        "link": "https://blog.banksalad.com/tech/banksalad-saladgame-2/",
        "pubDate": "Fri, 23 Aug 2024 00:00:00 GMT",
        "content": "…",
        "contentSnippet": "…",
        "guid": "https://blog.banksalad.com/tech/banksalad-saladgame-2/",
        "isoDate": "2024-08-23T00:00:00.000Z"
      }
    ]
  },
  {
    "name": "우아한형제들 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "TOAST Meetup",
    "category": "기업",
    "posts": [
      {
        "title": "NHN Cloud의 보안 가이드를 소개합니다",
        "link": "https://meetup.nhncloud.com/posts/384",
        "pubDate": "Sun, 25 Aug 2024 23:38:45 GMT",
        "content": "![NHN Cloud_meetup banner_security guides_202408_900.png](https://image.toast.com/aaaadh/real/2024/techblog/NHN%20Cloudmeetup%20bannersecurity%20guides202408900.png)\r\r\n\r\r\n## 들어가며\r\r\n\r\r\n다양한 산업 분야에서 클라우드 컴퓨팅의 확장성, 유연성, 데이터 분석 및 협업 기능을 활용하여 경쟁력을 강화하고, 서비스 운영 효율성을 높이고 있습니다. 이제 클라우드 전환은 선택이 아닌 필수가 된 것처럼 보입니다. 하지만 가상화 기술, 자원의 공유 및 인터넷을 통한 접속이라는 클라우드의 특성으로 인해 취약점 공격이나 악성 코드, DDoS와 같이 온프레미스 환경에서도 나타났던 보안 위협뿐만 아니라 기존에 없던 유형의 보안 위협도 다양하게 발생할 수 있다는 점에서 클라우드 보안에 대한 우려는 남아 있는 상태입니다.\r\r\n\r\r\n클라우드를 안전하게 이용하기 위해서는 온프레미스 인프라와 대비되는 클라우드의 구조와 보안 관리 방안을 정확히 이해하고, 클라우드 서비스 공급자와 이용자가 협력하여 각자의 책임 영역에서 적극적인 정보보호 활동을 수행할 수 있어야 합니다. 이를 [보안 책임 공유 모델(shared security responsibility, SSRM)](https://www.nhncloud.com/kr/security-center/ssrm)이라고 하는데요. 이 모델에서는 안전한 클라우드 서비스를 위해 클라우드 서비스 공급자와 이용자의 책임과 역할을 분류하고, 각자가 통제하는 요소를 보호하여 클라우드 전반의 안전하고 신뢰성 있는 보안을 확립합니다.\r\r\n\r\r\n보안 책임 공유 모델에서 클라우드 서비스 이용자는 가상 리소스와 데이터 보안을 위해 클라우드 및 보안 서비스를 활용해 보안을 고려한 서비스를 구성하고 관리할 책임을 갖습니다. 이를 위해서는 온프레미스 환경과 대비되는 클라우드 컴퓨팅 환경의 특성과 보안 전반에 대한 이해가 선행되어야 합니다. NHN Cloud는 보안을 위한 다양한 서비스와 기능을 제공할 뿐만 아니라, 다양한 보안 가이드를 제공하여 이용자가 데이터, 애플리케이션, 운영체제 단에서 직접 수행해야 하는 작업이나 반드시 숙지해야 할 사항 등을 안내합니다. 이를 통해 클라우드 서비스 이용자 책임 영역의 보안을 강화하고, 클라우드에 대한 위협과 대응 방안, 클라우드 영역별 보안, 정보보호 등에 대한 이해를 돕기 위한 노력을 지속하고 있습니다.\r\r\n\r\r\n이 글에서는 [NHN Cloud 보안 센터](https://www.nhncloud.com/kr/security-center)에서 제공하는 다양한 보안 가이드의 종류를 알아보고, 상황과 필요에 따라 적합한 문서를 활용하실 수 있도록 각 가이드에 대해 소개하고자 합니다.\r\r\n\r\r\n## NHN Cloud 보안 가이드의 종류와 소개\r\r\n\r\r\n![02_보안가이드메인.png](https://image.toast.com/aaaadh/real/2024/techblog/02uBCF4uC548uAC00uC774uB4DCuBA54uC778.png)\r\r\n\r\r\n### **NHN Cloud 보안 백서**\r\r\n\r\r\n고객이 클라우드 환경의 보안을 쉽게 이해할 수 있도록 돕고, NHN Cloud가 제공하는 보안 체계와 기술을 안내하기 위해 제작된 「NHN Cloud 보안 백서」는 NHN Cloud의 이름으로 발행된 첫 번째 백서입니다. 온프레미스 인프라와 대비되는 클라우드 컴퓨팅 환경의 특성과 그 특성에 기인한 보안 위협, 클라우드 보안 전반에 대해 안내하고, NHN Cloud가 고객의 클라우드 인프라와 서비스, 이용자의 개인정보와 데이터를 보호하기 위해 제공하는 다양한 보안 서비스와 기능을 소개합니다. 클라우드 서비스 이용 시 적절한 기술적 보안 대책을 마련하는 데 참고하거나 취약점 관리, 위협 탐지 및 대응, 인증, 컴플라이언스, 접근 통제, 데이터 보호 및 암호화 서비스를 이용한 안전한 서비스 인프라를 구성하는 데도 활용할 수 있을 것으로 기대합니다.\r\r\n\r\r\n [NHN Cloud 보안 백서 다운로드 신청 페이지 바로 가기](https://info.nhncloud.com/security-whitepaper.html?utm_source=nhncloud&utm_medium=home&utm_campaign=whitepapers&utm_content=security01&utm_term=cta)\r\r\n<br>\r\r\n### **NHN Cloud 개인정보보호 준수 가이드**\r\r\n\r\r\n개인정보는 살아 있는 개인에 대한 정보로 이름, 주민등록번호, 영상 등을 통해 개인을 식별할 수 있는 정보를 의미합니다. 하나의 정보만으로 개인을 식별할 수 없더라도, 다른 정보와 결합하여 개인을 특정할 수 있다면 개인정보로 간주합니다. 인터넷 기술이 발전하고, 소셜 네트워킹, 쇼핑, 금융 거래 등 일상의 거의 모든 행위가 디지털화됨에 따라 우리는 수많은 개인정보를 온라인에 저장하고 공유하는데요. 개인정보가 유출될 경우 신원 도용이나 금융 사기, 프라이버시 침해 등 심각한 문제를 초래할 수 있기 때문에 개인정보보호는 점점 더 중요한 이슈로 부각되고 있습니다.\r\r\n개인정보보호법은 이러한 개인정보의 처리 및 보호에 관한 사항을 정하여 개인의 자유와 권리를 보호하고, 개인의 존엄과 가치를 구현하기 위해 제정된 법입니다. NHN Cloud는 고객이 클라우드 환경에서 개인정보보호법을 준수할 수 있도록 다양한 서비스와 기능을 제공합니다. 「NHN Cloud 개인정보보호 준수 가이드」는 개인정보 및 개인정보보호법이 무엇인지 살펴보고, 개인정보의 안전성 확보조치 기준에 대해 알아본 뒤 NHN Cloud가 제공하는 보안 서비스를 이용해 개인정보를 보호할 수 있는 방안을 안내합니다.\r\r\n\r\r\n [NHN  Cloud 개인정보보호 준수 가이드 다운로드 바로 가기](https://www.nhncloud.com/resources/download/NHN%20Cloud_Personal_Information_Compliance_Guide_2024.pdf)\r\r\n<br>\r\r\n### **NHN Cloud 콘솔 보안 가이드**\r\r\n\r\r\n콘솔은 클라우드 서비스 이용자가 클라우드 서비스를 직접 생성, 사용, 관리, 삭제할 수 있는 접점이며 환경입니다. 따라서 클라우드 콘솔 보안은 매우 중요하며, 이용자가 직접 구성하고 관리한다는 점에서 클라우드 및 네트워크 환경과 보안 요소, 보안 관리 방법, 그리고 클라우드에서 제공하는 보안 기능에 대한 정확한 이해가 선행되어야 합니다.\r\r\n많은 CSP에서 클라우드 보안을 위한 다양한 기능들을 선보이고 있고, NHN Cloud 역시 Network Firewall, Security Groups, Network ACL, DDoS Guard, Security Monitoring, Webshell Threat Detector, Security Advisor, NHN Bastion 등의 서비스를 제공하며 안전한 클라우드 컴퓨팅 환경을 제공하기 위해 노력하고 있습니다. 「NHN Cloud 콘솔 보안 가이드」는 이와 같은 NHN Cloud의 다양한 서비스에서 제공하는 보안 기능을 이용하여 클라우드 환경에서 애플리케이션 및 서비스를 안전하게 구성할 수 있도록 권장되는 보안 설정들에 대해 안내합니다. 계정 관리, 네트워크 보안, 서버 보안, 스토리지 보안, 데이터베이스 보안, 데이터 보호 및 키 관리, 로깅 및 모니터링과 같은 8개 영역에서 점검하고 관리할 수 있는 항목들을 제시하고 설명하며, 클라우드 서비스 이용자는 이를 기준으로 NHN Cloud 콘솔에서 직접 보안 기능을 설정하고 점검할 수 있습니다.\r\r\n\r\r\n [NHN Cloud 콘솔 보안 가이드 다운로드 바로 가기](https://www.nhncloud.com/resources/download/NHN_Cloud_Console_Security_Guide_2023.pdf)\r\r\n<br>\r\r\n### **NHN Cloud 네트워크 아키텍처 보안 가이드**\r\r\n\r\r\n「NHN Cloud 네트워크 아키텍처 보안 가이드」는 NHN Cloud에서 제공하는 다양한 네트워크 기능과 네트워크 보안 서비스를 이용하여 클라우드 환경에서 가상 인프라 및 서비스를 안전하게 구성하고 제공할 수 있는 네트워크 보안 아키텍처를 설명합니다.\r\r\n클라우드 환경의 네트워크 구성 시 따라야 할 네트워크 분리, 접근 제어, 위협 대응 관련 컴플라이언스를 정리하여 안내하며, 이에 기반한 네트워크 아키텍처 보안 고려 사항 및 보안 설계 기준을 제시합니다. 또한 클라우드 환경에서 기업이나 공공 시스템을 설계할 때 참고할 수 있는 네트워크 보안 아키텍처를 사례별로 제시하기 때문에 환경에 따라 다를 수 있는 네트워크 분리 기준과 방법, 분리된 구간의 연결과 접근 통제 방식 등을 좀더 구체적이고 다양한 관점에서 살펴보고 이해할 수 있습니다.\r\r\n\r\r\n [NHN Cloud 네트워크 아키텍처 보안 가이드 다운로드 바로 가기](https://www.nhncloud.com/resources/download/NHN_Cloud_Network_Architecture_Security_Guide_2024.pdf)\r\r\n<br>\r\r\n### **NHN Cloud 랜섬웨어 대응 가이드**\r\r\n\r\r\n랜섬웨어(ransomware)란 사용자의 컴퓨터 시스템을 장악하거나 데이터를 암호화하여 정상적으로 사용하지 못하게 만든 뒤 암호 키 또는 해제 방법을 알려주는 대가로 금전을 요구하는 악성 코드입니다. 최근 몇 년간 랜섬웨어가 사이버 공격의 주요 형태로 떠오르며 기업과 공공 기관, 개인 모두에게 심각한 피해를 입히고 있습니다.\r\r\n「NHN Cloud 랜섬웨어 대응 가이드」는 일반 악성코드와 대비되는 랜섬웨어의 특성과 공격 방식 및 유형을 살펴보고, 랜섬웨어가 사용하는 기술이 무엇인지 설명합니다. 그리고 랜섬웨어에 대비하여 클라우드 서비스 이용자가 취할 수 있는 효과적인 대응 전략과 방안을 제시합니다.\r\r\n\r\r\n [NHN Cloud 랜섬웨어 대응 가이드 다운로드 바로 가기](https://www.nhncloud.com/resources/download/NHN_Cloud_Ransomware_Response_Guide_2024.pdf)\r\r\n<br>\r\r\n### **NHN Cloud 컨테이너 보안 가이드**\r\r\n\r\r\n컨테이너란 데스크톱, 온프레미스, 클라우드 등 어떤 환경에도 구애 받지 않고 실행할 수 있도록 애플리케이션 코드를 해당 라이브러리 및 종속 항목과 함께 패키징한 소프트웨어 실행 유닛입니다. NHN Cloud는 이러한 컨테이너 환경에서 다양한 애플리케이션을 개발하고 운영할 수 있도록 NHN Kubernetes Service(NKS), NHN Container Registry(NCR), NHN Container Service(NCS)를 제공합니다. 「NHN Cloud 컨테이너 보안 가이드」는 NHN Cloud의 컨테이너 서비스에서 제공하는 보안 기능과 Kubernetes 보안 방법을 소개합니다. 본 가이드를 통해 컨테이너의 개념과 주요 구성 요소, 컨테이너 환경의 보안 위협과 보호 대상, 컨테이너 환경과 컨테이너를 기반으로 서비스하는 워크로드를 보호하는 방법 등을 이해할 수 있습니다.\r\r\n\r\r\n [NHN Cloud 컨테이너 보안 가이드 다운로드 바로 가기](https://www.nhncloud.com/resources/download/NHN%20Cloud_Container%20Security%20Guide_2024.pdf)\r\r\n<br>\r\r\n## 마치며\r\r\n\r\r\n여기까지 NHN Cloud의 다양한 보안 가이드의 종류와 활용에 대해 알아보았는데요. 2024년 8월 기준, NHN Cloud는 위와 같이 「NHN Cloud 보안 백서」, 「NHN Cloud 개인정보보호 준수 가이드」, 「NHN Cloud 콘솔 보안 가이드」, 「NHN Cloud 네트워크 아키텍처 가이드」, 「NHN Cloud 랜섬웨어 대응 가이드」, 「NHN Cloud 컨테이너 보안 가이드」를 제공하고 있습니다. 보안 가이드는 NHN Cloud를 활용해 서비스를 개발하고 운영하시는 아키텍트 및 보안 업무 담당자, NHN Cloud를 도입하고 구축하고자 하는 기업의 IT 담당자, 그리고 클라우드와 클라우드 환경 전반의 보안에 대해 알고 싶은 분들 모두가 자유롭게 이용하실 수 있으며, [NHN Cloud 홈페이지 > 보안 센터 > 보안 가이드](https://www.nhncloud.com/kr/security-center/guide) 페이지에서 확인하실 수 있습니다.\r\r\n\r\r\n긴 글을 읽어 주셔서 감사드리며, 앞으로도 NHN Cloud에서 제공하는 다양한 보안 가이드에 대해 많은 기대와 관심을 부탁드립니다. \r\r\n\r\r\n[![NHN Cloud_meetup banner_footer_black_202408_900.png](https://image.toast.com/aaaadh/real/2024/techblog/NHN%20Cloudmeetup%20bannerfooterblack202408900.png)](https://www.nhncloud.com/kr)",
        "contentSnippet": "![NHN Cloud_meetup banner_security guides_202408_900.png](https://image.toast.com/aaaadh/real/2024/techblog/NHN%20Cloudmeetup%20bannersecurity%20guides202408900.png)\r\r\n\r\r\n## 들어가며\r\r\n\r\r\n다양한 산업 분야에서 클라우드 컴퓨팅의 확장성, 유연성, 데이터 분석 및 협업 기능을 활용하여 경쟁력을 강화하고, 서비스 운영 효율성을 높이고 있습니다. 이제 클라우드 전환은 선택이 아닌 필수가 된 것처럼 보입니다. 하지만 가상화 기술, 자원의 공유 및 인터넷을 통한 접속이라는 클라우드의 특성으로 인해 취약점 공격이나 악성 코드, DDoS와 같이 온프레미스 환경에서도 나타났던 보안 위협뿐만 아니라 기존에 없던 유형의 보안 위협도 다양하게 발생할 수 있다는 점에서 클라우드 보안에 대한 우려는 남아 있는 상태입니다.\r\r\n\r\r\n클라우드를 안전하게 이용하기 위해서는 온프레미스 인프라와 대비되는 클라우드의 구조와 보안 관리 방안을 정확히 이해하고, 클라우드 서비스 공급자와 이용자가 협력하여 각자의 책임 영역에서 적극적인 정보보호 활동을 수행할 수 있어야 합니다. 이를 [보안 책임 공유 모델(shared security responsibility, SSRM)](https://www.nhncloud.com/kr/security-center/ssrm)이라고 하는데요. 이 모델에서는 안전한 클라우드 서비스를 위해 클라우드 서비스 공급자와 이용자의 책임과 역할을 분류하고, 각자가 통제하는 요소를 보호하여 클라우드 전반의 안전하고 신뢰성 있는 보안을 확립합니다.\r\r\n\r\r\n보안 책임 공유 모델에서 클라우드 서비스 이용자는 가상 리소스와 데이터 보안을 위해 클라우드 및 보안 서비스를 활용해 보안을 고려한 서비스를 구성하고 관리할 책임을 갖습니다. 이를 위해서는 온프레미스 환경과 대비되는 클라우드 컴퓨팅 환경의 특성과 보안 전반에 대한 이해가 선행되어야 합니다. NHN Cloud는 보안을 위한 다양한 서비스와 기능을 제공할 뿐만 아니라, 다양한 보안 가이드를 제공하여 이용자가 데이터, 애플리케이션, 운영체제 단에서 직접 수행해야 하는 작업이나 반드시 숙지해야 할 사항 등을 안내합니다. 이를 통해 클라우드 서비스 이용자 책임 영역의 보안을 강화하고, 클라우드에 대한 위협과 대응 방안, 클라우드 영역별 보안, 정보보호 등에 대한 이해를 돕기 위한 노력을 지속하고 있습니다.\r\r\n\r\r\n이 글에서는 [NHN Cloud 보안 센터](https://www.nhncloud.com/kr/security-center)에서 제공하는 다양한 보안 가이드의 종류를 알아보고, 상황과 필요에 따라 적합한 문서를 활용하실 수 있도록 각 가이드에 대해 소개하고자 합니다.\r\r\n\r\r\n## NHN Cloud 보안 가이드의 종류와 소개\r\r\n\r\r\n![02_보안가이드메인.png](https://image.toast.com/aaaadh/real/2024/techblog/02uBCF4uC548uAC00uC774uB4DCuBA54uC778.png)\r\r\n\r\r\n### **NHN Cloud 보안 백서**\r\r\n\r\r\n고객이 클라우드 환경의 보안을 쉽게 이해할 수 있도록 돕고, NHN Cloud가 제공하는 보안 체계와 기술을 안내하기 위해 제작된 「NHN Cloud 보안 백서」는 NHN Cloud의 이름으로 발행된 첫 번째 백서입니다. 온프레미스 인프라와 대비되는 클라우드 컴퓨팅 환경의 특성과 그 특성에 기인한 보안 위협, 클라우드 보안 전반에 대해 안내하고, NHN Cloud가 고객의 클라우드 인프라와 서비스, 이용자의 개인정보와 데이터를 보호하기 위해 제공하는 다양한 보안 서비스와 기능을 소개합니다. 클라우드 서비스 이용 시 적절한 기술적 보안 대책을 마련하는 데 참고하거나 취약점 관리, 위협 탐지 및 대응, 인증, 컴플라이언스, 접근 통제, 데이터 보호 및 암호화 서비스를 이용한 안전한 서비스 인프라를 구성하는 데도 활용할 수 있을 것으로 기대합니다.\r\r\n\r\r\n [NHN Cloud 보안 백서 다운로드 신청 페이지 바로 가기](https://info.nhncloud.com/security-whitepaper.html?utm_source=nhncloud&utm_medium=home&utm_campaign=whitepapers&utm_content=security01&utm_term=cta)\r\r\n\r\r\n### **NHN Cloud 개인정보보호 준수 가이드**\r\r\n\r\r\n개인정보는 살아 있는 개인에 대한 정보로 이름, 주민등록번호, 영상 등을 통해 개인을 식별할 수 있는 정보를 의미합니다. 하나의 정보만으로 개인을 식별할 수 없더라도, 다른 정보와 결합하여 개인을 특정할 수 있다면 개인정보로 간주합니다. 인터넷 기술이 발전하고, 소셜 네트워킹, 쇼핑, 금융 거래 등 일상의 거의 모든 행위가 디지털화됨에 따라 우리는 수많은 개인정보를 온라인에 저장하고 공유하는데요. 개인정보가 유출될 경우 신원 도용이나 금융 사기, 프라이버시 침해 등 심각한 문제를 초래할 수 있기 때문에 개인정보보호는 점점 더 중요한 이슈로 부각되고 있습니다.\r\r\n개인정보보호법은 이러한 개인정보의 처리 및 보호에 관한 사항을 정하여 개인의 자유와 권리를 보호하고, 개인의 존엄과 가치를 구현하기 위해 제정된 법입니다. NHN Cloud는 고객이 클라우드 환경에서 개인정보보호법을 준수할 수 있도록 다양한 서비스와 기능을 제공합니다. 「NHN Cloud 개인정보보호 준수 가이드」는 개인정보 및 개인정보보호법이 무엇인지 살펴보고, 개인정보의 안전성 확보조치 기준에 대해 알아본 뒤 NHN Cloud가 제공하는 보안 서비스를 이용해 개인정보를 보호할 수 있는 방안을 안내합니다.\r\r\n\r\r\n [NHN  Cloud 개인정보보호 준수 가이드 다운로드 바로 가기](https://www.nhncloud.com/resources/download/NHN%20Cloud_Personal_Information_Compliance_Guide_2024.pdf)\r\r\n\r\r\n### **NHN Cloud 콘솔 보안 가이드**\r\r\n\r\r\n콘솔은 클라우드 서비스 이용자가 클라우드 서비스를 직접 생성, 사용, 관리, 삭제할 수 있는 접점이며 환경입니다. 따라서 클라우드 콘솔 보안은 매우 중요하며, 이용자가 직접 구성하고 관리한다는 점에서 클라우드 및 네트워크 환경과 보안 요소, 보안 관리 방법, 그리고 클라우드에서 제공하는 보안 기능에 대한 정확한 이해가 선행되어야 합니다.\r\r\n많은 CSP에서 클라우드 보안을 위한 다양한 기능들을 선보이고 있고, NHN Cloud 역시 Network Firewall, Security Groups, Network ACL, DDoS Guard, Security Monitoring, Webshell Threat Detector, Security Advisor, NHN Bastion 등의 서비스를 제공하며 안전한 클라우드 컴퓨팅 환경을 제공하기 위해 노력하고 있습니다. 「NHN Cloud 콘솔 보안 가이드」는 이와 같은 NHN Cloud의 다양한 서비스에서 제공하는 보안 기능을 이용하여 클라우드 환경에서 애플리케이션 및 서비스를 안전하게 구성할 수 있도록 권장되는 보안 설정들에 대해 안내합니다. 계정 관리, 네트워크 보안, 서버 보안, 스토리지 보안, 데이터베이스 보안, 데이터 보호 및 키 관리, 로깅 및 모니터링과 같은 8개 영역에서 점검하고 관리할 수 있는 항목들을 제시하고 설명하며, 클라우드 서비스 이용자는 이를 기준으로 NHN Cloud 콘솔에서 직접 보안 기능을 설정하고 점검할 수 있습니다.\r\r\n\r\r\n [NHN Cloud 콘솔 보안 가이드 다운로드 바로 가기](https://www.nhncloud.com/resources/download/NHN_Cloud_Console_Security_Guide_2023.pdf)\r\r\n\r\r\n### **NHN Cloud 네트워크 아키텍처 보안 가이드**\r\r\n\r\r\n「NHN Cloud 네트워크 아키텍처 보안 가이드」는 NHN Cloud에서 제공하는 다양한 네트워크 기능과 네트워크 보안 서비스를 이용하여 클라우드 환경에서 가상 인프라 및 서비스를 안전하게 구성하고 제공할 수 있는 네트워크 보안 아키텍처를 설명합니다.\r\r\n클라우드 환경의 네트워크 구성 시 따라야 할 네트워크 분리, 접근 제어, 위협 대응 관련 컴플라이언스를 정리하여 안내하며, 이에 기반한 네트워크 아키텍처 보안 고려 사항 및 보안 설계 기준을 제시합니다. 또한 클라우드 환경에서 기업이나 공공 시스템을 설계할 때 참고할 수 있는 네트워크 보안 아키텍처를 사례별로 제시하기 때문에 환경에 따라 다를 수 있는 네트워크 분리 기준과 방법, 분리된 구간의 연결과 접근 통제 방식 등을 좀더 구체적이고 다양한 관점에서 살펴보고 이해할 수 있습니다.\r\r\n\r\r\n [NHN Cloud 네트워크 아키텍처 보안 가이드 다운로드 바로 가기](https://www.nhncloud.com/resources/download/NHN_Cloud_Network_Architecture_Security_Guide_2024.pdf)\r\r\n\r\r\n### **NHN Cloud 랜섬웨어 대응 가이드**\r\r\n\r\r\n랜섬웨어(ransomware)란 사용자의 컴퓨터 시스템을 장악하거나 데이터를 암호화하여 정상적으로 사용하지 못하게 만든 뒤 암호 키 또는 해제 방법을 알려주는 대가로 금전을 요구하는 악성 코드입니다. 최근 몇 년간 랜섬웨어가 사이버 공격의 주요 형태로 떠오르며 기업과 공공 기관, 개인 모두에게 심각한 피해를 입히고 있습니다.\r\r\n「NHN Cloud 랜섬웨어 대응 가이드」는 일반 악성코드와 대비되는 랜섬웨어의 특성과 공격 방식 및 유형을 살펴보고, 랜섬웨어가 사용하는 기술이 무엇인지 설명합니다. 그리고 랜섬웨어에 대비하여 클라우드 서비스 이용자가 취할 수 있는 효과적인 대응 전략과 방안을 제시합니다.\r\r\n\r\r\n [NHN Cloud 랜섬웨어 대응 가이드 다운로드 바로 가기](https://www.nhncloud.com/resources/download/NHN_Cloud_Ransomware_Response_Guide_2024.pdf)\r\r\n\r\r\n### **NHN Cloud 컨테이너 보안 가이드**\r\r\n\r\r\n컨테이너란 데스크톱, 온프레미스, 클라우드 등 어떤 환경에도 구애 받지 않고 실행할 수 있도록 애플리케이션 코드를 해당 라이브러리 및 종속 항목과 함께 패키징한 소프트웨어 실행 유닛입니다. NHN Cloud는 이러한 컨테이너 환경에서 다양한 애플리케이션을 개발하고 운영할 수 있도록 NHN Kubernetes Service(NKS), NHN Container Registry(NCR), NHN Container Service(NCS)를 제공합니다. 「NHN Cloud 컨테이너 보안 가이드」는 NHN Cloud의 컨테이너 서비스에서 제공하는 보안 기능과 Kubernetes 보안 방법을 소개합니다. 본 가이드를 통해 컨테이너의 개념과 주요 구성 요소, 컨테이너 환경의 보안 위협과 보호 대상, 컨테이너 환경과 컨테이너를 기반으로 서비스하는 워크로드를 보호하는 방법 등을 이해할 수 있습니다.\r\r\n\r\r\n [NHN Cloud 컨테이너 보안 가이드 다운로드 바로 가기](https://www.nhncloud.com/resources/download/NHN%20Cloud_Container%20Security%20Guide_2024.pdf)\r\r\n\r\r\n## 마치며\r\r\n\r\r\n여기까지 NHN Cloud의 다양한 보안 가이드의 종류와 활용에 대해 알아보았는데요. 2024년 8월 기준, NHN Cloud는 위와 같이 「NHN Cloud 보안 백서」, 「NHN Cloud 개인정보보호 준수 가이드」, 「NHN Cloud 콘솔 보안 가이드」, 「NHN Cloud 네트워크 아키텍처 가이드」, 「NHN Cloud 랜섬웨어 대응 가이드」, 「NHN Cloud 컨테이너 보안 가이드」를 제공하고 있습니다. 보안 가이드는 NHN Cloud를 활용해 서비스를 개발하고 운영하시는 아키텍트 및 보안 업무 담당자, NHN Cloud를 도입하고 구축하고자 하는 기업의 IT 담당자, 그리고 클라우드와 클라우드 환경 전반의 보안에 대해 알고 싶은 분들 모두가 자유롭게 이용하실 수 있으며, [NHN Cloud 홈페이지 > 보안 센터 > 보안 가이드](https://www.nhncloud.com/kr/security-center/guide) 페이지에서 확인하실 수 있습니다.\r\r\n\r\r\n긴 글을 읽어 주셔서 감사드리며, 앞으로도 NHN Cloud에서 제공하는 다양한 보안 가이드에 대해 많은 기대와 관심을 부탁드립니다. \r\r\n\r\r\n[![NHN Cloud_meetup banner_footer_black_202408_900.png](https://image.toast.com/aaaadh/real/2024/techblog/NHN%20Cloudmeetup%20bannerfooterblack202408900.png)](https://www.nhncloud.com/kr)",
        "isoDate": "2024-08-25T23:38:45.000Z"
      }
    ]
  },
  {
    "name": "ZUM 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "SK Planet",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Spoqa tech blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "팀 왈도 번역팀",
    "category": "게임",
    "posts": []
  },
  {
    "name": "이한",
    "category": "개인",
    "posts": []
  },
  {
    "name": "근원님",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황의윤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "호돌맨",
    "category": "개인",
    "posts": []
  },
  {
    "name": "박우빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "문다영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "유수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "안건주",
    "category": "개인",
    "posts": []
  },
  {
    "name": "손현호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "STARTUP BIBLE",
    "category": "개인",
    "posts": [
      {
        "creator": "Kihong Bae",
        "title": "회사는 놀이터가 아니다",
        "link": "https://www.thestartupbible.com/2024/08/your-company-is-not-your-playground.html",
        "pubDate": "Sun, 25 Aug 2024 21:38:00 +0000",
        "content:encodedSnippet": "내가 약 5개월 전에 쓴 글 ‘개발자도 회사의 조직원이다’가 최근에 여기저기서 공유가 많이 된 것 같다. 뭐, 이곳은 내 개인적인 블로그라서 남 눈치 안 보고 그냥 내 생각을 끄적거리는데, 사람들이 세상을 보는 관점도 다르고, 특정 주제에 대한 생각도 달라서 그런지 많은 분들이 여러 가지 의견을 댓글로 남겨줬다.\n댓글, 댓글의 대댓글, 그리고 여기에 대한 주인장의 댓글을 모두 합치면 50개가 넘는 코멘트가 있다. 이 중, 그래도 이성적이고 논리적인 이야기가 가능한 분위기의 댓글에는 내가 최대한 진정성 있는 코멘트를 남겼는데, 그냥 개싸움이 될 것 같은 분위기의 댓글은 건드리지 않았다. 대신, 그런 코멘트에 대해서는 이번 포스팅을 통해서 아주 간략하게 내 생각을 종합적으로 다시 한번 공유하고 싶다.\n일단, 이 글에 이렇게 격한 반응을 해주신 걸 보니, 한국에도 돈을 많이 벌고 싶어 하고, 성공에 목마른 개발자들이 많은 것 같아서 너무 다행이다. 이런 분들이 더 많아져야지 스타트업도 잘 되고, 경쟁력 있는 회사들이 많이 나온다고 생각한다.\n한 가지 사과하고 명확하게 하고 싶은 건, 내가 개발자들을 공격하려는 의도로 이전 글을 쓴 건 아니라는 점이다. 기획자이든 마케터이든 개발자이든, 모든 직원은 회사의 조직원인데 굳이 개발자를 꼭 집어서 글을 썼던 이유는 내가 아는 대부분의 조직에선 제품을 만들고 판매해서 돈을 버는 핵심 업무를 하는 그룹 군에서 돈을 버는 기능에 가장 관심이 적은 조직이 개발 조직이기 때문이다. 물론, 이건 개인적인 관점이다.\n몇 개의 댓글을 읽어보면, 회사가 잘 돼 봤자 사장만 돈 버는데 내가 굳이 열심히 할 필요가 없다는 내용이다. 특히나 회사의 지분도 없는데. 이런 분들은 내 블로그에서 불평하지 말고, 소속된 회사의 사장과 이런 이야기를 하는 걸 권장한다. 회사에 돈을 벌어 주는 일을 열심히 하는 직원에게 스톡옵션 또는, 그 어떤 보상도 하지 않는 사장이라면 굳이 이런 회사에 계속 다닐 필욘 없을 것 같다. 그냥 다른 곳으로 가면 된다. 만약 본인이 열심히 일하지 않거나 실력이 없어서 보상받을 수준이 안되면 그냥 불평하지 말고 그 회사 계속 다니면 된다. 어쨌든 이런 불평을 하면서도 계속 그 회사에 다니고 있다면, 본인 자신의 실력을 의심해 봐야 한다.\n개발자로서 기술적 모험이 제한된다면 굳이 스타트업에 갈 필요가 없다고 한 분도 있다. 이런 의견에 대한 내 생각 두 가지를 공유한다. 일단 본인이 기술적 모험을 하고 싶다면, 그리고 이 모험이 회사의 비즈니스 방향과 크게 상관없다면(=돈을 벌 수 있는 기술이 아니라면) 이걸 허락하는 다른 곳으로 가면 된다. 그런데 돈 버는 거와 상관없는 기술적 모험을 허락하는 내가 아는 곳들은 학교 아니면 연구소다. 회사는 아닐 것이다. 또 다른 생각은, 스타트업을 포함한 모든 회사는 개발자들이 기술적인 모험을 하는 놀이터가 아니다. 남의 돈으로 빨리 돈을 벌어서 압축적인 성장을 해야 하는 조직이다. 회사는 돈 받고 그냥 하루 종일 놀다 퇴근하는 곳이 아니다.\n또한, 회사라는 조직은 분명히 회사라는 집단의 목표가 있고, 이를 달성해야 하지만, 어떤 분들이 주장하는 개인적인 발전도 동시에 균형 있게 가져가야 한다. 나도 이건 동의한다. 하지만, 우선순위를 매기자면 무조건 회사의 목표가 먼저이고, 이게 어느 정도 된 후에 회사의 목표를 같이 만드는 개인의 발전에 신경 써줄 수 있다. 회사의 목표는 무조건 돈 버는 게 돼야 하고, 여기에 먼저 동참할 수 없다면 개발자든 마케터든 회사에겐 부채가 되고, 부채는 가장 먼저 제거해야 하는 짐이 될 수밖에 없다.\n그리고 어떤 분들의 댓글을 보고 나는 정말로 이 사람들이 일하는 회사가 어딘지 궁금해지기도 했다. 그 회사 동료들이 너무 불쌍해서…\n이 글 밑에 분명히 멋진 댓글도 많이 달릴 거지만, 거지 같은 댓글도 많이 올라올 것이다. 그 수준과 정도를 종합적으로 판단해서, 필요하면 또 한 번 내 의견을 공유하는 포스팅을 올릴 계획이다. 그런데 키보드 뒤에서 인신공격적인 코멘트를 달거나, 너무 멍청한 코멘트를 다는 분들은 익명이 아니라 실명을 밝혀주시면 오히려 더 건설적인 이야기가 가능하지 않을까 싶다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2024/08/your-company-is-not-your-playground.html#comments",
        "content": "내가 약 5개월 전에 쓴 글 ‘개발자도 회사의 조직원이다’가 최근에 여기저기서 공유가 많이 된 것 같다. 뭐, 이곳은 내 개인적인 블로그라서 남 눈치 안 보고 그냥 내 생각을 끄적거리는데, 사람들이 세상을 보는 관점도 다르고, 특정 주제에 대한 생각도 달라서 그런지 많은 분들이 여러 가지 의견을 댓글로 남겨줬다. 댓글, 댓글의 대댓글, 그리고 여기에 대한 주인장의 댓글을(...)",
        "contentSnippet": "내가 약 5개월 전에 쓴 글 ‘개발자도 회사의 조직원이다’가 최근에 여기저기서 공유가 많이 된 것 같다. 뭐, 이곳은 내 개인적인 블로그라서 남 눈치 안 보고 그냥 내 생각을 끄적거리는데, 사람들이 세상을 보는 관점도 다르고, 특정 주제에 대한 생각도 달라서 그런지 많은 분들이 여러 가지 의견을 댓글로 남겨줬다. 댓글, 댓글의 대댓글, 그리고 여기에 대한 주인장의 댓글을(...)",
        "guid": "https://www.thestartupbible.com/?p=9188",
        "categories": [
          "Uncategorized",
          "korea",
          "people",
          "technology",
          "vc",
          "스타트업 바이블 QA"
        ],
        "isoDate": "2024-08-25T21:38:00.000Z"
      },
      {
        "creator": "Kihong Bae",
        "title": "제품도 없는데 수익은 어떻게?",
        "link": "https://www.thestartupbible.com/2024/08/how-do-you-make-a-profit-when-you-dont-have-a-product.html",
        "pubDate": "Wed, 21 Aug 2024 21:24:00 +0000",
        "content:encodedSnippet": "얼마 전에 TechCrunch에서 배양육 산업 관련 기사를 읽었다. 우리도 국내 최초의 배양육 스타트업 셀미트에 투자했기 때문에, 관심을 갖고 기사를 정독했다. 기사의 제목은 “Even after $1.6B in VC money, the lab-grown meat industry is facing ‘massive’ issues” 였고, 내용은 암울했다.\n내용을 요약하자면, 너도나도 대체 단백질과 배양육 시장에 투자하기 바쁠 땐, 거의 묻지마 투자 수준으로 많은 돈이 이 시장에 투입됐지만, 연구개발에 생각보다 많은 돈과 시간이 필요하고, 이후에 관계 정부 부서의 승인 받는 것도 어렵다는 걸 이제 많은 사람들이 깨닫고 있다. 하지만, 가장 어려운 현실은, 연구개발을 하고 승인을 받아도, 결국 돈을 벌기 위해선 배양육 제품을 팔아야 하는데, 시장에서 수용할 수 있는 가격대에 대량 생산하기 위해서는 상상 이상의 돈이 설비와 공장에 투입돼야 하므로 투자자들이 이젠 이 분야를 등한시하고 있다는 내용이다.\n실은, 순수 소프트웨어 사업이 아닌, 사람의 개입이 필요한 operation이 필수인 사업도 비슷한 문제에 항상 직면해 있긴 하다. 멀리 볼 필요도 없고 가까운 스트롱 포트폴리오 네트워크에만 보더라도 이런 회사들이 수두룩하다. 대표적인 예가 모바일 세탁소 세탁특공대인데, 앱으로 세탁을 맡길 수 있지만, 결국엔 회사에서 세탁물을 수거해서 본인들이 직접 운영하는 세탁공장으로 운반하고, 여기서 세탁한 후에 다시 고객들에게 배송해야 한다. 분명 소프트웨어 비즈니스이지만, 사업의 절반 이상이 전통적인 물류와 공장 운영이다. 굉장히 돈이 많이 필요하고, 상상 이상의 돈이 설비와 공장에 투입되어야 한다는 점은 위에서 언급한 배양육 회사와 크게 다르지 않다.\n하지만, 한 가지 다른 점이 있다면, 세탁이라는 업은 첫 매출을 만들기 위한 R&D는 필요 없다. 사업을 개선해서 더 많은 매출을 만들기 위한 R&D는 있지만, 이게 없어도 세탁업은 시작할 수 있고, 매출을 만들 수 있다. 이렇게 만든 매출과 다른 의미 있는 수치를 기반으로 계속 적당한 밸류에이션에 투자 받으면서 사업을 키울 수 있다.\n하지만, 배양육 사업은 오랜 기간 동안 아주 무거운 R&D 과정을 거치지 않으면, 제품 자체가 만들어지지 않기 때문에, 실제로 돈을 버는 건 시작도 못 한다. 사업을 시작하지 못하고, 돈을 아예 못 벌면, 투자받는 게 쉽지 않다. 경기가 아주 좋을 땐, 기술력을 평가하고 미래의 수익성을 기반으로 좋은 조건에 큰 투자를 하는 투자자들이 꽤 있다. 실은 우리 투자사 셀미트를 비롯한 이 분야의 많은 회사들이 몇 년 전만 해도 이런 식으로 투자를 잘 받았다. 하지만, 요새 같은 불경기에 투자자들이 회사를 판단하는 가장 중요한 기준은 매출이다. 투자자들은 매출을 선호하고, 더 나아가서 수익을 선호한다. 이 상황에서 팔 제품 자체가 없는 스타트업은 어떻게 수익을 만들고, 어떻게 투자를 받을 수 있을까?\n아마도 이런 상황에 놓인 창업가들이 꽤 있을 것 같고, 최근에 이런 고민을 하는 분과 잠깐 이야기를 했는데, 이분이 나한테 열변을 토했다. “아니, 아직 제품도 없는데 어떻게 매출을 만드나요? 어떻게 우리 같은 회사의 밸류에이션을 매출을 기반으로 산정합니까? 그러면 우린 밸류에이션이 0인 회사인데요.”\n이분은 시드 투자를 받아서 한 2년 동안 열심히 R&D를 해고, 연구 결과도 좋고 방향도 좋아서 실제 제품을 만들고 매출을 발생시키기 위해 추가 투자를 받아야 하는데, 만나는 대부분의 투자자들이 매출이 없어서 거절하거나, 관심 있는 투자자는 매출이 없어서 (본인이 생각하기엔) 터무니없이 낮은 기업 가치를 제시하는 좋지 않은 상황에 부닥쳐있다.\n솔직히 나도 이분에게 특별히 해 줄 말이 없었다. 경기가 좋고 시장에 돈이 넘쳐흐를 땐, 제품도 없고 매출이 없어도 기술 그 자체나 시장의 가능성에 투자하는 VC들이 많았지만, 이젠 대부분의 VC들이 매출이 발생하는 회사를 선호하고, 어떤 VC는 매출로도 부족하고 손익분기를 해서 이익이 발생하는 회사에만 투자하고 있기 때문에 위에서 말한 창업가가 투자받는 건 정말 힘들기 때문이다. 만약에 이런 상황에 처한 창업가가 있다면, 그냥 최대한 많은 투자자를 만나서 제품과 매출이 없는 회사에도 투자하는 곳을 찾는 수밖에 없다. 만약에 운 좋게 이런 곳을 찾더라도, 회사의 밸류에이션과 투자 조건을 결정하는 건 전적으로 투자자의 특권이 될 수밖에 없다. 이 말을 쉽게 해석해 보면, 투자받는 것도 mission impossible이고, 운 좋게 우리 회사에 관심 갖는 투자자를 찾더라도 좋지 않은 조건에 투자받아야 한다는 의미다.\n입장 바꿔서 이야기를 한번 해보고 싶다. 즉, 이런 회사들을 자주 만나는 VC의 입장에서,,,실은 지금 이런 상황에 부닥친 회사에 투자하면, 정말 매력적인 조건에 투자할 수 있다. 이 회사에 살아 남아서 정말로 좋은 기술로 좋은 제품을 만들 수 있다면, 시간은 오래 걸리지만, 매출이 발생하기 시작하면 확실한 해자를 만들면서 성장하기 때문에 멈출 수 없을 정도로 매출이 잘 나올 것이다. 특히나, 이런 기술을 잘 이해하고, 이 시장을 잘 이해하고 있는 대기업의 전략적 투자 부서가 이런 플레이를 스마트하게 하면, 그 대기업의 미래 먹거리를 생각보다 쉽게 확보할 수도 있다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2024/08/how-do-you-make-a-profit-when-you-dont-have-a-product.html#comments",
        "content": "얼마 전에 TechCrunch에서 배양육 산업 관련 기사를 읽었다. 우리도 국내 최초의 배양육 스타트업 셀미트에 투자했기 때문에, 관심을 갖고 기사를 정독했다. 기사의 제목은 “Even after $1.6B in VC money, the lab-grown meat industry is facing ‘massive’ issues” 였고, 내용은 암울했다. 내용을 요약하자면, 너도나도 대체 단백질과 배양육 시장에 투자하기 바쁠 땐, 거의 묻지마 투자 수준으로 많은 돈이(...)",
        "contentSnippet": "얼마 전에 TechCrunch에서 배양육 산업 관련 기사를 읽었다. 우리도 국내 최초의 배양육 스타트업 셀미트에 투자했기 때문에, 관심을 갖고 기사를 정독했다. 기사의 제목은 “Even after $1.6B in VC money, the lab-grown meat industry is facing ‘massive’ issues” 였고, 내용은 암울했다. 내용을 요약하자면, 너도나도 대체 단백질과 배양육 시장에 투자하기 바쁠 땐, 거의 묻지마 투자 수준으로 많은 돈이(...)",
        "guid": "https://www.thestartupbible.com/?p=9185",
        "categories": [
          "Uncategorized",
          "FoundersAtWork",
          "fundraising",
          "technology",
          "vc"
        ],
        "isoDate": "2024-08-21T21:24:00.000Z"
      }
    ]
  },
  {
    "name": "Build a Great Product",
    "category": "개인",
    "posts": []
  },
  {
    "name": "지금 써보러 갑니다",
    "category": "개인",
    "posts": []
  },
  {
    "name": "매거진 입맛",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "요즘 IT",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "쿠팡 엔지니어링",
    "category": "기업",
    "posts": []
  },
  {
    "name": "지마켓 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "리멤버 (드라마 앤 컴퍼니)",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Kimchi hill",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Hudi.blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "토스",
    "category": "기업",
    "posts": [
      {
        "title": "토스, 개발자 컨퍼런스 ‘슬래시24’ 참가 신청 시작",
        "link": "https://blog.toss.im/article/slash24-conference",
        "pubDate": "Mon, 26 Aug 2024 04:56:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}9월 12일(목) 코엑스에서 역대 최초 오프라인 개최… 개발자 45명 연사로 나서\n총 1,500명 추첨 통해 선발, 참가 접수 9월 2일까지\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1kxrhf3{white-space:pre-wrap;}토스가 개발자 컨퍼런스 '슬래시24(SLASH24, 이하 슬래시)'의 참가 신청을 시작했다.\n슬래시는 토스 커뮤니티의 개발자들이 기술적인 성취와 러닝을 공유하는 자리다. 4회째를 맞은 올해의 주제는 ‘No Limit: 풀지 못할 문제는 없다'로, 끊임없이 도전하고 시도하며 끝내 문제를 해결해 내는 토스의 개발 문화를 반영했다.\n이번 행사는 오프라인에서 최초로 개최된다는 점에서 특별하다. 9월 12일(목) 오전 10시부터 오후 4시까지 코엑스 그랜드볼룸에서 열린다. 토스, 토스뱅크, 토스증권, 토스페이먼츠, 토스플레이스 등 5개 법인에서 총 45명의 개발자들이 연사로 나선다.\n첫 번째 순서로는 토스의 테크놀로지 총괄 이형석 CTO가 발표를 진행한다. 이형석 CTO는 핀테크 업계의 지형을 바꿔온 토스가 혁신을 이루기 위해 겪은 도전과 실패를 이야기한다. 또한, 그 과정에서 토스 엔지니어들이 견지하는 태도와 이를 가능하게 하는 조직문화를 공유할 예정이다.\n메인 세션은 안드로이드(Android), 데이터(Data), 데브옵스(DevOps), 프론트엔드(Frontend), 인프라(Infra), Node.js, 파이썬(Python), 서버(Server), QA 등 총 9개 직군의 29개 발표로 구성했다. 스페셜 세션으로는 ‘빠르게 성장하고 싶은 주니어 개발자를 위한 소프트 스킬’, ‘팀에 위닝 멘탈리티를 불어넣는 리더십 스킬’, 토스뱅크와 토스증권의 CTO가 전하는 ‘미래의 CTO에게’ 등 3개 발표와 파트너사인 아마존웹서비스(AWS), 노션(Notion), 세일즈포스(Salesforce)의 발표가 준비돼 있다.\n다양한 부대 행사도 함께 마련했다. 슬래시 연사와 세션에 대한 질의나 기술적 고민을 나눌 수 있는 ‘데브챗(DevChat) 존’, 다양한 프로그램에서 4개 이상의 스탬프를 모으면 참여할 수 있는 ‘럭키드로우 존', 직무 상담이나 이력서에 대한 피드백을 받을 수 있는 ‘리크루팅 존'을 운영한다. 더불어 AWS, 베스핀글로벌, 노션, 세일즈포스, 시디즈 등 특별 협업 부스도 별도로 운영된다.\n이형석 CTO는 “이번 슬래시는 ‘No Limit’이라는 주제에 맞게 기술적 도전에 대한 토스 엔지니어들의 열정과 도전 정신을 함께 나눌 수 있는 자리가 될 것”이라며 “처음으로 오프라인에서 행사를 진행하는 만큼, 참가자들이 네트워킹을 통해 서로의 경험을 공유하고 더 큰 임팩트를 얻으실 수 있기를 기대한다”라고 전했다.\n참가 신청은 9월 2일(월) 23시 59분까지 토스 슬래시24 홈페이지에서 할 수 있다. 참가 신청을 완료하면 행사 종료 후 세션 발표 자료를 이메일로 제공한다. 신청한 인원 중 추첨을 통해 총 1,500명을 현장에 초대하며, 선정된 참가자에게는 9월 4일(수)에 개별적으로 안내를 진행할 예정이다.",
        "content": "“No Limit: 풀지 못할 문제는 없다”",
        "contentSnippet": "“No Limit: 풀지 못할 문제는 없다”",
        "guid": "https://blog.toss.im/article/slash24-conference",
        "isoDate": "2024-08-26T04:56:00.000Z"
      },
      {
        "title": "TDF, 우리 모두의 은퇴 준비 필수품",
        "link": "https://blog.toss.im/article/retirement-plans-05",
        "pubDate": "Fri, 23 Aug 2024 06:20:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-nv7vyi{margin:24px 0 8px;padding:16px 40px 32px;border-radius:16px;background-color:var(--adaptiveGrey100);}.css-123co55{font-size:19px;letter-spacing:0em;line-height:1.6;margin:24px 0 0;font-weight:400;color:var(--adaptiveGrey900);background-color:transparent;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}이 글에서 알 수 있는 것들\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1kxrhf3{white-space:pre-wrap;}퇴직연금에서 중요한 비중을 차지하는 TDF 개념 이해하기\n내가 계획하는 은퇴시점에 따라 TDF 고르는 기준 알아보기\n\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n은퇴 준비를 위한 자산 배분 이해하기\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n은퇴 준비를 하겠다고 마음 먹었을 때 가장 중요한 첫 번째는 적은 금액이라도 퇴직연금 계좌에 꾸준하게 모으는 것, 두 번째는 자산 배분이다. 만약 이미 은퇴에 가까운 나이라면 힘들게 모은 자산을 안전하게 관리하면서 가져가야 한다. 위험자산보다는 안전자산의 비중을 높여 너무 무리하지 않는 선에서 투자와 관리를 지속하는 것이다. 시장 분위기가 좋을 때 높은 수익을 가져다주는 위험자산은 언제나 유혹적이지만, 최근처럼 한국 주식이 급락해버리면 열심히 모아온 은퇴 자금이 위태로워지고 만다.\n반대로 아직 은퇴까지 20~30년의 시간이 있다면 위험자산을 이용해 적극적인 투자가 가능하다. 물론 자신이 얼마나 위험을 감수할 수 있는 성향인지 이해하고 이를 바탕으로 위험자산의 비중을 조정해야 하지만, 일반적으로 20대와 30대일 때는 전체 자산에서 위험자산의 비중이 중년기보다 많아도 된다고 말한다. 일시적으로 시장이 급락할지라도 은퇴 시점까지 회복할 시간이 충분히 있기 때문이다.\n모두에게 공평하게 적용되는 한 가지는 바로 시간이다. 시간이 흘러 나이를 먹으면서 모두가 점차 은퇴 시점에 가까워진다. .css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}그렇게 은퇴 시점에 가까워지면 자산 배분도 그에 맞게 변경되어야 한다. 30대의 주식과 채권 배분 비율과 50대의 비율은 당연히 다를 수밖에 없다. 시기에 따라 적절히 주식과 채권 상품을 사고 팔며 비율을 조정해야 한다는 뜻이다. 여기까지 이야기하면 대부분의 사람들이 이런 반응을 보인다.\n“먹고 살기도 바쁜데 어떻게 매번 그걸 체크하고 바꾸나요?”\n“배분 비율을 어떻게 바꿔야 하죠? 기준이 있나요?”\n투자에 관심이 많고 늘 시간을 들일 수 있는 사람이라면 충분히 가능한 일이다. 하지만 대다수의 사람들에게 ‘주기적으로 리밸런싱하고, 위험자산과 안전자산의 비율을 조정하라'는 건 사실 지속 가능하지 않은 방법이다. 그래서 등장한 은퇴용 투자상품이 바로 TDF(Target Date Fund)이다.\n은퇴를 위해 태어났어요, TDF\nTDF는 은퇴 시점을 정하고 투자하면 펀드를 운용하는 회사가 해당 시점에 맞춰 자산 배분을 알아서 관리해주는 상품이다. 따라서 보통 TDF 상품에는 숫자가 들어 있는데, 이 숫자가 바로 은퇴 연도를 뜻한다. 예를 들어 내가 은퇴하고자 하는 시점이 2040년이라면 상품명에 2040이 들어간 TDF를 고르면 된다.(이 숫자를 빈티지(vintage)라고 부른다.) 보통 TDF에 들어 있는 숫자는 2030, 2035, 2040처럼 5년 단위로 설정된다. 따라서 자신의 은퇴 희망 시점과 가장 가까운 숫자를 선택하면 된다.\n문제는 많은 사람들이 TDF에 대한 이해가 부족한 채 무분별하게 투자하고 있다는 데 있다. 실제로 IRP 계좌를 보유한 한 30대를 인터뷰해보니 TDF2035 상품과 TDF2050 상품을 모두 보유하고 있었다. 자신의 은퇴 희망 시점을 고려한 것이 아니라 상품을 권유한 판매자의 말대로 여러 TDF를 구매한 탓이었다. TDF가 만들어진 취지와 맞지 않을 뿐더러, 투자자가 투자 상품에 대해 이해하지 못한 채 돈을 넣어버린 잘못된 투자였다.\n한국 시장에서 TDF 상품이 수면 위로 떠오른 이유는 바로 디폴트옵션(사전지정운용제도) 때문이다. 4화 ‘.css-iynyr0{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);-webkit-text-decoration:underline!important;text-decoration:underline!important;}자꾸 디폴트옵션 설정하라고 알림이 와요’에서 말했듯이 오랫동안 저조했던 퇴직연금의 수익률을 개선하기 위해 등장한 디폴트옵션에는 TDF 상품이 매우 많이 포진되어 있다. 심지어 주식 배분이 80% 가까이 올라가도 TDF는 안전자산으로 분류되는 특징이 있다. 시간 흐름에 따라 은퇴 시점에 가까워질수록 안전자산 비중이 높아지면서 변화하기 때문이다. 은퇴 준비를 효과적으로 하기 위해서는 이러한 특징을 가진 TDF 상품을 적절하게 활용할 줄 알아야 한다.\nTDF의 핵심은 바로 글라이드 패스\n시간 흐름에 따라 알아서 자산을 배분해주는 TDF의 특징을 글라이드 패스(glide path)로 설명하곤 한다. 글라이드 패스는 비행기가 착륙할 때 그리는 경로를 뜻하는 말로, 하늘에서 땅으로 부드러운 곡선을 그리며 착륙하는 모습이 은퇴까지 아직 많은 시간이 남은 사회 초년기에는 주식 비중이 크고, 은퇴 시기에 가까워질수록 주식 비중이 줄어드는 흐름과 매우 닮아 있다. 따라서 TDF에서의 글라이드 패스를 쉽게 설명하자면, 가입 시점부터 은퇴 시점까지 시간 흐름에 따라 주식과 채권의 배분을 조정하는 방법이다. 시기에 따른 배분율은 사전에 정해져 있으며, 그 비율에 따라 은퇴 시점이 가까워지면 TDF는 포트폴리오의 주식 보유량을 줄이고 채권 보유량을 늘려준다. 이유는 간단하다. 채권이 주식에 비해 위험이 적다고 판단하기 때문이다.\n다음 그래프는 미국의 자산운용사 블랙록(Black Rock)의 2040 TDF 자산 배분 현황이다. 가로축에서 0은 은퇴 시점이고 5는 은퇴 시점 5년 전, 10은 10년 전을 나타낸다. 해당 포트폴리오의 2023년 상태, 즉 약 8년 정도 남은 상태를 보면 주식 비중은 약 55%이고, 은퇴 시점에는 40%로 줄어든 것을 확인할 수 있다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}은퇴를 기점으로 달라지는 블랙록의 2040 TDF 자산 배분 현황\n그래프처럼 주식 배분이 점점 줄어드는 스케줄이 바로 글라이드 패스다. 글라이드 패스의 높낮이는 TDF를 만드는 회사마다 다르다. 어떤 방식의 글라이드 패스가 정답이라고 말할 수는 없지만, 모든 글라이드 패스를 만들 때 공통적으로 고려하는 몇 가지가 있다.\n첫째, 은퇴 시점이 가까워질수록 주식보다 채권의 비중이 높아진다.\n둘째, 은퇴 시점이 가까워질수록 해외주식보다 자국 주식의 비중이 높아진다. 은퇴에 가까울수록 외환 위험에 노출되지 않도록 자국 주식의 비중을 높이는 방식이 미국에서는 정석으로 통용된다. (그런데 이것은 한국 주식시장의 저조한 실적을 고려하면 한국 TDF에도 맞다고 단언할 수는 없는 부분이다.)\n셋째, 은퇴 시점이 가까워질수록 수익률이 높고 만기가 긴 채권의 비중이 줄고 수익률이 좀 낮더라도 만기가 짧은 채권의 비중이 높아진다.\n넷째, 은퇴 시점부터는 물가연동채권(미국에서는 TIPS), 원자재, 부동산 등의 자산이 많이 포함된다.\n이처럼 글라이드 패스는 주식과 채권의 분배 비율을 담고 있기 때문에 TDF의 수익률을 좌우하는 매우 중요한 요소이다. TDF 상품을 이해하는 데 가장 중요한 정보이지만 아직까지는 어려운 용어로 가득한 투자상품 설명서를 읽어야 파악할 수 있게 되어 있어서 투자자에게 제일 전달되지 않는 정보이기도 하다.\n배분 비율에 따른 수익률 차이는?\nTDF 상품별로 얼마나 주식에 투자되고, 채권에 투자되는지에 따라 매년 수익률이 달라진다. 예를 들어 2024년 1월 1일부터 7월 31일까지의 수익률을 살펴보자. 물론 장기간 투자를 위해 만들어진 상품을 이렇게 단기간 수익률로 분석하는 방법은 상품의 본래 취지에 어긋날 순 있지만, 투자자들이 수익률 차이를 이해하는 데 있어서 중요한 부분이라고 생각한다.\n\n출처=.css-114ityv{white-space:pre-wrap;cursor:pointer;-webkit-text-decoration:underline!important;text-decoration:underline!important;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}아이랩 글라이드\n2040 빈티지인 TDF 상품들의 2024년 동안의 수익률을 보면 가장 좋은 수익률을 기록한 것은 ‘한국투자TDF알아서ETF포커스’로 7개월 수익률이 13.19%이다. 수익률이 가장 낮은 상품과 비교하면 무려 8% 넘게 차이가 난다. 2040년을 은퇴 시점으로 타깃하는 경우에는 주식 배분율 차이가 최대 77%에서 최소 57%로 다양하기 때문에 상당한 차이가 날 수밖에 없다. 이런 점을 이해한다면 같은 빈티지 안에서도 왜 이렇게 수익률이 다른지 이해할 수 있고, TDF를 고를 때 내가 주식에 더 많이 투자하고 싶다면 주식 배분율을 기준으로 상품을 고르는 방법도 가능하다.(하위 개념인 어떤 종목을 보유했느냐 또한 중요한 요소이지만, 수익률 차이를 가르는 데는 상위 개념인 어떤 자산을 얼마나 보유했느냐가 더 결정적인 역할을 한다.)\nTDF를 고르는 6가지 기준\n만약 내가 은퇴자금을 공격적으로 투자하고 싶다면 상품별로 주식-채권 배분율을 확인해보고, 주식 배분율이 높은 TDF를 고르면 된다. 이 배분율 차이는 곧 수익률, 변동성과 직결된다는 점, 그리고 위에서 살펴본 수익률 순위는 2024년 상반기 한정이며, 투자 기간 전체의 수익률이 아니라는 것도 잊지 않아야 한다.\n\n출처=아이랩 글라이드\n또한 나에게 맞는 TDF를 고르기 위해서는 조금 더 고려해야 할 사항들이 있다. 아래 6가지 기준을 소개한다.\n첫째가 앞서 말한 나의 은퇴 시점, 둘째가 주식 배분의 정도이다. 예를 들어 2045년 은퇴를 목표로 한다면 TDF 2045 빈티지 안에서 주식 배분율을 최소 57%에서 최대 79%까지 고를 수 있다.\n셋째는 미국 주식에 어느 정도 투자하고 싶은가다. 한국 TDF 상품은 미국 주식에 많이 투자하는데 역시 배분율이 조금씩 다르다. 만약 미국 주식에 많이 투자하고 싶다면 최대치를 선택할 수 있다.\n넷째, 수수료 차이를 고려해 패시브 펀드와 액티브 펀드 중 원하는 것을 선택한다. 지수를 따라가는 패시브 펀드는 액티브 펀드보다 수수료가 저렴하다. 또한 패시브 펀드로 구성된 TDF는 펀드 매니저가 종목을 골라 넣는 방식이 아니기 때문에 시장 환경에 따른 수익률 예측이 가능하다.\n다섯째, 위험도 선택이다. 상품설명서를 보면 펀드운용자가 정한 위험등급을 볼 수 있다. 이는 매우 높은 위험의 1부터 매우 낮은 위험의 6까지 구분된다. 자신이 얼마나 위험을 감수할 수 있을지를 고려한다.\n여섯째, 은퇴 시점의 주식 배분율을 고른다. 같은 빈티지 안에서도 은퇴 시점에 주식 배분이 조금 더 높은 상품이 있고 낮은 상품이 있다. 은퇴가 다가왔을 때 예상치 못한 시장 상황에 의한 갑작스러운 손실을 낮추고 싶다면 더 낮은 상품을 고르면 된다.\n위와 같은 질문을 통해 자신의 계획에 맞는 TDF 상품을 찾아갈 수 있다. 단순히 수익률만으로 상품을 고르기보다는 나의 성향에 맞춰 고르는 심층적인 방법이다.\n과거 수익률은 판단하기 위한 최소한의 단서\n상품을 고르는 데 있어서 과거 수익률은 중요한 정보다. 과거의 수익률이 미래 수익률을 보장하지는 않지만 그동안 얼마나 잘해왔는지를 살펴볼 수 있는 중요한 척도이므로, 광고만 보고 고르는 것보다는 낫다. 수익률을 잘 비교하기 위해서는 내 펀드의 수익률만 살펴보는 것이 아니라, 같은 빈티지의 다른 상품이 동일한 기간에 얼마나 수익을 올렸는지 살필 것을 권한다. 앞서 살펴본 것처럼 똑같은 2040 타깃의 TDF여도 최소 5%에서 최대 13%로 차이가 있기 때문이다. 만기를 채우지 않은 채 수시로 상품을 갈아타는 것을 추천할 수는 없지만, 만약 꾸준히 더 좋은 수익률을 내고 나에게 잘 맞는 상품이 있다면 당연히 바꾸어야 하지 않을까?\nTDF는 한국 금융시장에서 은퇴 준비에 있어서 점점 더 큰 부분을 차지하고 있는 상품이므로, 이번 시간을 통해 TDF에 대해 제대로 이해하는 투자자들이 많아지길 기대한다. 그리하여 나에게 맞는 TDF를 골라서 투자하고 다음 단계로 나아가기를 바란다. 퇴직연금 계좌에는 보통 다른 계좌보다 제약이 있기는 하지만 ETF, 자산 배분 펀드 등 다양한 상품이 존재한다. 이를 이용해서 장기투자와 단기투자를 섞거나, 투자에 더 익숙한 투자자라면 ETF를 이용해 자신만의 포트폴리오를 잘 구성해볼 수 있다. 다음 화에서는 퇴직연금으로 투자하는 ETF에 대해 다루어 보도록 하겠다.\n*<노후 준비 액션플랜> 시리즈는 국내 159개 대표 운용펀드의 TDF 글라이드 패스와 수익률을 한눈에 보기 쉽도록 전달하는 .css-1vsqqzg{white-space:pre-wrap;cursor:pointer;-webkit-text-decoration:underline!important;text-decoration:underline!important;font-weight:bold;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}아이랩 글라이드와 함께 만듭니다.\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 주소은, 김현미(아이랩) Graphic 조수희, 윤여진",
        "content": "퇴직연금을 운용하는 지속 가능한 방법",
        "contentSnippet": "퇴직연금을 운용하는 지속 가능한 방법",
        "guid": "https://blog.toss.im/article/retirement-plans-05",
        "isoDate": "2024-08-23T06:20:00.000Z"
      },
      {
        "title": "건강검진 지원부터 빈 용기 보증금 제도까지, 우리의 건강과 환경을 지키는 돈 되는 정책",
        "link": "https://blog.toss.im/article/money-policies-23",
        "pubDate": "Fri, 23 Aug 2024 01:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}우리의 건강과 환경, 안전을 지키는 정책과 제도를 살펴봅니다.  \n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n건강이 최우선 \n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}⓵ 생애주기별 국가건강검진제도\n일반건강검진부터 연령에 따른 암 검진, 영유아와 청소년까지 필수적인 검사를 지원합니다.\n.css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}일반건강검진은 보통 2년 주기로 받아요. 비만, 시청각 이상, 고혈압, 폐결핵, 신장질환, 빈혈, 당뇨병 여부 등을 공통으로 검사하고요. 연령에 따라 이상지질혈증, B형간염, 골밀도, 인지기능장애, 우울증 등의 검사를 추가로 받을 수 있어요.\n자세한 내용은 국민건강보험공단(www.nhis.or.kr)에서 확인할 수 있습니다.\n⓶ 암 환자 의료비 지원\n암 환자가 있는 가정의 경제적 부담을 덜어드리고 힘든 치료 과정을 잘 견뎌낼 수 있도록 의료비를 지원해요.\n성인 환자 기준, 의료급여 수급자나 차상위 본인 부담 경감대상자인 경우, 최대 3년간 연속으로 연간 최대 300만원을 지원합니다. 주소지 관할 보건소에서 신청할 수 있어요.\n⓷ 찾아가는 금연지원 서비스\n담배를 끊고자 하는 금연 의지가 있지만 프로그램에 참가하기 어려운 상황이라면, 직접 찾아가 관리해드립니다. 위기 청소년, 여성, 장애인, 소규모 사업장 근로자 등이 지원 대상이에요.\n전국 17개 지역금연지원센터를 통해 신청하면 6개월간 9회 이상 지속적인 금연 상담을 받을 수 있고요, 니코틴 보조제나 금연치료제를 지원 받을 수 있어요. 한국건강증진개발원(02-3781-2220)에 더 자세한 내용을 문의해보세요.\n안전을 체감할 수 있는 사회 \n⓸ 여성 긴급전화 1366\n가정폭력, 성폭력, 성매매, 스토킹, 교제폭력 등 폭력 피해자에게 상담 서비스를 지원합니다. 365일 24시간 운영되니 도움이 필요할 때 언제든 전화하면 됩니다. \n초기 상담부터 관련 지원 기관으로의 연계, 피해자와 동반가족이 최대 7일까지 머무를 수 있는 긴급 피난처까지 제공합니다. \n⓹ 안심 상속 원스톱 서비스\n사망자가 남긴 재산과 채무를 한번에 조회하는 서비스입니다. 예금, 대출, 보험, 증권 등 금융거래 내역부터 연금 가입 유무까지 확인할 수 있어요.\n사망일이 속한 달의 말일부터 1년 이내에 상속인(또는 후견인)이 신청할 수 있어요. 가까운 행정복지센터에 방문해도 되고, 정부24 홈페이지에서 온라인 신청도 가능합니다.\n환경을 지키는 돈 되는 정책 \n⓺ 폐가전 무상방문수거\n온라인이나 전화로 폐가전 처리 신청하면, 수거 전담반이 찾아가 무상 수거해 갑니다. 집에서 사용하지 않는 TV나 냉장고, 세탁기, 에어컨 등 부피가 크고 무거운 폐가전 제품을 배출할 때 꼭 확인해보세요. 소형 가전은 5개 이상인 경우 수거 가능합니다.\n폐가전제품 배출예약시스템(www.15990903.or.kr)이나 전화(1599-0903)로 신청할 수 있어요.\n⓻ 빈 용기 보증금 제도\n재사용 표시가 있는 병을 가까운 슈퍼나 대형마트에 반환하면 보증금을 돌려 받을 수 있어요. 돌려받을 수 있는 금액은 병의 용량에 따라 70원~350원으로 달라요.\n예를 들면 소주병은 1병당 100원인데, 제사 지낼 때 많이 쓰는 대형 청주 병은 개당 350원이랍니다. 제품 라벨에 금액이 표시돼 있어요.\n\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 정경화 Graphic 조수희",
        "content": "지키고 살피는 건강, 안전, 환경 서비스",
        "contentSnippet": "지키고 살피는 건강, 안전, 환경 서비스",
        "guid": "https://blog.toss.im/article/money-policies-23",
        "isoDate": "2024-08-23T01:00:00.000Z"
      },
      {
        "title": "대출 받을 때 알아야 할 3가지: 2024년 LTV, DTI, DSR",
        "link": "https://blog.toss.im/article/ltv-dti-dsr",
        "pubDate": "Tue, 20 Aug 2024 03:05:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}계속 바뀌는 대출 정책에 ‘내가 돈을 빌릴 수 있다는 건지, 없다는 건지' 헷갈릴 때가 많을 텐데요. 자주 등장하는 LTV, DTI, DSR 뜻만 제대로 알아도 얼마나 대출 받을 수 있는지 예상하기 편해질 거예요.\n.css-1c1qox8{font-size:30px;letter-spacing:0em;line-height:1.55;font-weight:bold;color:var(--adaptiveGrey900);margin:40px 0 4px;}\n.css-p4abj2{display:contents;line-height:1.55;}LTV\n집을 사기 위해서는 ‘주택담보대출'을 많이 받아요. 내가 살 집을 담보로 금융기관에서 돈을 빌리는 건데 이때 .css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}집값 대비 얼마까지 빌릴 수 있는지를 LTV(주택담보대출비율)라고 불러요. \n만약 5억원짜리 집을 사기 위해 집을 담보로 4억원을 빌렸다면, LTV는 80%가 되는 거예요.\nDTI\n소득에 비해 빚을 갚을 능력이 얼마나 되는지 알아보는 지표예요. 1년간 갚아야 할 주택대출의 원금+이자를 연소득으로 나눈 후 100을 곱해 구해요. 일반적으로 DTI가 낮을 때 빚을 갚을 능력이 높다고 여겨져요. \nDSR\n내가 가지고 있는 모든 빚을 기준으로 빌릴 수 있는 돈의 상한선을 정하는 거예요. \n이 때에는 주택담보대출뿐만 아니라 학자금대출, 마이너스대출*, 자동차할부, 카드론 등 모든 대출의 원리금을 합한 것을 기준으로 연소득 대비 일정 비율(%)까지 대출해줘요.\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}*마이너스대출은 빌린 금액이 아닌 한도금액, 즉 사용할 수 있는 마이너스대출 한도 전체를 더해요. \n.css-nv7vyi{margin:24px 0 8px;padding:16px 40px 32px;border-radius:16px;background-color:var(--adaptiveGrey100);}.css-123co55{font-size:19px;letter-spacing:0em;line-height:1.6;margin:24px 0 0;font-weight:400;color:var(--adaptiveGrey900);background-color:transparent;}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}DTI, DSR 비슷해보이는데 다른 건가요?\n네, 달라요! DTI는 주택담보대출의 원리금만 더하지만 DSR은 한 사람이 가진 거의 모든 빚을 더해 빌려줄 수 있는 돈을 정한다는 점에서 더 강력한 대출 규제라고 할 수 있어요. \n\n2024년부터는 \n스트레스 DSR이 적용돼요 \n스트레스 DSR이란 미래의 금리 인상 위험을 반영한 일정 수준의 ‘가산(스트레스) 금리’를 적용하는 거예요. 미래에 금리가 오를 경우 늘어날 원리금 상환 부담까지 반영하기 때문에 대출한도가 기존보다 줄어들 예정이에요. \n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}.css-wgpbp3{display:block;margin-top:6px;}스트레스 DSR 시행 단계\n스트레스 DSR은 총 3단계로 진행돼요. \n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n1단계는 2024년 2월 26일부터 8월 31일까지 적용돼요. 이때 적용되는 스트레스 금리는 0.38%*로 계산된 스트레스 금리(1.5%)의 25%만 반영했어요. 이에 따라 2024년 상반기 차주별 주택담보대출 한도가 2~4% 줄어들 것으로 예상돼요. \n*매년 2회(상, 하반기)에 걸쳐 주기적으로 변경돼요. 추후 결정되는 스트레스 금리는 .css-114ityv{white-space:pre-wrap;cursor:pointer;-webkit-text-decoration:underline!important;text-decoration:underline!important;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}은행연합회 홈페이지(kfb.or.kr)에서 확인할 수 있어요.\n2024년 9월부터는 2단계 스트레스 DSR을 시행해요. 기본 스트레스 금리의 50%인 0.75%p로 가산금리를 올리고, 은행권 신용대출과 2금융권 주택담보대출까지 포함해요. 여기에 은행권의 수도권 주택담보대출에 대해서는 스트레스 금리를 0.75%p 대신 1.2%p로 상향 적용해요. \n\n신용대출 받으려면\nDSR을 알아야 해요 \n나의 총 대출 금액이 1억원을 넘으면, DSR 40%까지만 대출받을 수 있기 때문이에요. 1년간 갚는 원리금이 연소득의 40%(비은행 50%)를 넘어가게 대출 받을 수 없다는 이야기예요 (전세대출, 중도금대출, 소액 신용대출 등은 제외). \n연봉까지만 빌릴 수 있던 신용대출을 연봉의 2~3배까지 빌릴 수 있도록 허용해주었지만, 사실상 필요한 돈이 1억원 이상이라면 DSR 40%내에서만 빌릴 수 있는 거예요. 상대적으로 연소득이 적은 청년층에 영향이 클 수밖에 없고요.\n\n한도 높이기 위해서는: 연소득이 높아지거나, 매년 내는 원리금 부담을 줄이면 되는데요. 최근 나온 .css-iynyr0{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);-webkit-text-decoration:underline!important;text-decoration:underline!important;}10년 만기 신용대출 등을 이용해 매년 내는 원리금 부담을 줄이면 일시적으로 한도를 높일 수 있어요.\n\n\n주택담보대출 받으려면\n3가지 모두 알아야 해요\n부동산은 크게 규제지역과 비규제지역으로 나누어지는데요. 2023년 1월 5일부터 강남, 서초, 송파, 용산 등 서울 4개구를 제외하고는 모두 규제지역(투기과열지구, 조정대상지역)에서 해제됐어요. \n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n1. 규제지역과 비규제지역의 LTV가 달라요 \n\n무주택자, 1주택자는 비규제지역에서는 70%, 규제지역에서는 50%의 LTV가 적용돼요. \n부부합산 연소득이 9,000만 원 이하이고, 규제지역의 주택가격 9억 원 이하, 무주택세대주의 요건을 모두 충족하면 6억 원 한도 내에서 LTV 70%까지 적용받을 수 있어요. \n생애 최초 구입이라면 규제지역 여부와 상관없이 집값의 80%까지 대출받을 수 있어요. 주택 소재 지역이나 주택 가격, 소득과 관계없이 최대 6억 원까지 대출받을 수 있어요. \n\n2. 다주택자도 규제지역에서 주택담보대출을 받을 수 있어요\n그동안 다주택자는 규제지역 내에서 주택담보대출을 받을 수 없었는데요. 2023년부터 규제지역에서도 집값의 최대 30%까지 대출받을 수 있게 됐어요 (LTV 0 → 30%). 비규제지역은 이전과 동일하게 LTV 60%가 적용돼요. \n3. DTI는 지역에 따라 달라요\n\n투기지역, 투기과열지구는 40% 적용해요. (서울 강남, 송파, 서초, 용산) \n조정대상지역은 50% 적용하고, 그 외에서는 60%가 적용돼요. \n생애 최초 구입자와 서민 등 실수요자는 투기지역 여부 관계없이 60%로 완화돼요.\n\n4. DSR도 적용돼요 \nLTV, DTI 규제가 완화됐지만 1억 원 넘게 대출받을 때 DSR 40% 규제는 유지돼요. 2024년부터는 위에서 설명한 스트레스 DSR도 추가되기 때문에, 내가 받는 대출이 해당하는지 살펴봐야 해요. \n\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 송수아 Graphic 이은호 이서영\n\n- 이 콘텐츠는 2022년 12월 19일 작성됐고, 2024년 8월 20일 업데이트됐어요.",
        "content": "주택담보대출에 LTV, DTI, DSR을 모두 적용하면 얼마까지 빌릴 수 있을까?",
        "contentSnippet": "주택담보대출에 LTV, DTI, DSR을 모두 적용하면 얼마까지 빌릴 수 있을까?",
        "guid": "https://blog.toss.im/article/ltv-dti-dsr",
        "isoDate": "2024-08-20T03:05:00.000Z"
      }
    ]
  },
  {
    "name": "모나미",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김진홍",
    "category": "개인",
    "posts": []
  }
]