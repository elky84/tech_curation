[
  {
    "name": "C++ Team Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Facebook Engineering",
    "category": "기업",
    "posts": [
      {
        "creator": "",
        "title": "RCCLX: Innovating GPU Communications on AMD Platforms",
        "link": "https://engineering.fb.com/2026/02/24/data-center-engineering/rrcclx-innovating-gpu-communications-amd-platforms-meta/",
        "pubDate": "Tue, 24 Feb 2026 21:30:54 +0000",
        "content:encodedSnippet": "We are open-sourcing the initial version of RCCLX – an enhanced version of RCCL that we developed and tested on Meta’s internal workloads. RCCLX is fully integrated with Torchcomms and aims to empower researchers and developers to accelerate innovation, regardless of their chosen backend.\nCommunication patterns for AI models are constantly evolving, as are hardware capabilities. We want to iterate on collectives, transports, and novel features quickly on AMD platforms. Earlier, we developed and open-sourced CTran, a custom transport library on the NVIDIA platform. With RCCLX, we have integrated CTran to AMD platforms, enabling the AllToAllvDynamic – a GPU-resident collective. While not all the CTran features are currently integrated into the open source RCCLX library, we’re aiming to have them available in the coming months. \nIn this post, we highlight two new features – Direct Data Access (DDA) and Low Precision Collectives. These features provide significant performance improvements on AMD platforms and we are excited to share this with the community. \nDirect Data Access (DDA) – Lightweight Intra-node Collectives\nLarge language model inference operates through two distinct computational stages, each with fundamentally different performance characteristics: \nThe prefill stage processes the input prompt, which can span thousands of tokens, to generate a key-value (KV) cache for each transformer layer of the model. This stage is compute-bound because the attention mechanism scales quadratically with sequence length, making it highly demanding on GPU computational resources.\nThe decoding stage then utilizes and incrementally updates the KV cache to generate tokens one by one. Unlike prefill, decoding is memory-bound, as the I/O time of reading memory dominates attention time, with model weights and the KV cache occupying the majority of memory.\nTensor parallelism enables models to be distributed across multiple GPUs by sharding individual layers into smaller, independent blocks that execute on different devices. However, one important challenge is the AllReduce communication operation can contribute up to 30% of end-to-end (E2E) latency. To address this bottleneck, Meta developed two DDA algorithms. \nThe DDA flat algorithm improves small message-size allreduce latency by allowing each rank to directly load memory from other ranks and perform local reduce operations, reducing latency from O(N) to O(1) by increasing the data exchange from O(n) to O(n²).\nThe DDA tree algorithm breaks the allreduce into two phases (reduce-scatter and all-gather) and uses direct data access in each step, moving the same amount of data as the ring algorithm but reducing latency to a constant factor for slightly larger message sizes.\n \nThe performance improvements of DDA over baseline communication libraries are substantial, particularly on AMD hardware. With AMD MI300X GPUs, DDA outperforms the RCCL baseline by 10-50% for decode (small message sizes) and yields 10-30% speedup for prefill. These improvements resulted in approximately 10% reduction in time-to-incremental-token (TTIT), directly enhancing the user experience during the critical decoding phase.\nLow-precision Collectives\nLow-precision (LP) collectives are a set of distributed communication algorithms — AllReduce, AllGather, AlltoAll, and ReduceScatter — optimized for AMD Instinct MI300/MI350 GPUs to accelerate AI training and inference workloads. These collectives support both FP32 and BF16 data types, leveraging FP8 quantization for up to 4:1 compression, which significantly reduces communication overhead and improves scalability and resource utilization for large message sizes (≥16MB). \nThe algorithms use parallel peer-to-peer (P2P) mesh communication, fully exploiting AMD’s Infinity Fabric for high bandwidth and low latency, while compute steps are performed in high precision (FP32) to maintain numerical stability. Precision loss is primarily dictated by the number of quantization operations — typically one or two per data type in each collective — and whether the data can be adequately represented within the FP8 range. \nBy dynamically enabling LP collectives, users can selectively activate these optimizations in E2E scenarios that benefit most from performance gains. Based on internal experiments, we have observed significant speed up for FP32 and notable improvements for BF16; it’s important to note that these collectives have been tuned for single-node deployments at this time. \nReducing the precision of types can potentially have an impact on numeric accuracy so we tested for this and we found that it provided acceptable numerical accuracy for our workloads. This flexible approach allows teams to maximize throughput while maintaining acceptable numerical accuracy, and is now fully integrated and available in RCCLX for AMD platforms — simply set the environment variable RCCL_LOW_PRECISION_ENABLE=1 to get started.\nMI300 – Float LP AllReduce speedup.\nMI300 – Float LP AllGather speedup.\nMI300 – Float LP AllToAll speedup.\nMI300 – Float LP ReduceScatter speedup.\nWe are observing the following results from E2E inference workload evaluations when selectively enabling LP collectives:\nApproximately ~0.3% delta on GSM8K evaluation runs.\n~9–10% decrease in latency.\n~7% increase in throughput.\nThe throughput measurements shown in the graphs were obtained using param-bench rccl-tests. For the MI300, the tests were run on RCCLX built with ROCm 6.4, and for the MI350, on RCCLX built with ROCm 7.0. Each test included 10 warmup iterations followed by 100 measurement iterations. The reported results represent the average throughput across the measurement iterations.\nEasy adaptation of AI models\nRCCLX is integrated with the Torchcomms API as a custom backend. We aim for this backend to have feature parity with our NCCLX backend (for NVIDIA platforms). Torchcomms allows users to have a single API for communication for different platforms. A user would not need to change the APIs they’re familiar with to port their applications across AMD, or other platforms even when using the novel features provided by CTran. \n\n\nRCCLX Quick Start Guide\nInstall Torchcomms with RCCLX backend by following the installation instructions in the Torchcomms repo.\nimport torchcomms\r\n\r\n# Eagerly initialize a communicator using MASTER_PORT/MASTER_ADDR/RANK/WORLD_SIZE environment variables \r\nprovided by torchrun.\r\n# This communicator is bound to a single device.\r\ncomm = torchcomms.new_comm(\"rcclx\", torch.device(\"hip\"), name=\"my_comm\")\r\nprint(f\"I am rank {comm.get_rank()} of {comm.get_size()}!\")\r\n\r\nt = torch.full((10, 20), value=comm.rank, dtype=torch.float)\r\n\r\n# run an all_reduce on the current stream\r\ncomm.allreduce(t, torchcomms.ReduceOp.SUM, async_op=False)\r\n\nAcknowledgements\nWe extend our gratitude to the AMD RCCL team for their ongoing collaboration. We also want to recognize the many current and former Meta employees whose contributions were vital in developing torchcomms and torchcomms-backends for production-scale training and inference. In particular, we would like to give special thanks to Dingming Wu, Qiye Tan, Pavan Balaji Yan Cui, Zhe Qu, Ahmed Khan, Ajit Mathews, CQ Tang, Srinivas Vaidyanathan, Harish Kumar Chandrappa, Peng Chen, Shashi Gandham, and Omar Baldonado\nThe post RCCLX: Innovating GPU Communications on AMD Platforms appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>We are open-sourcing the initial version of RCCLX – an enhanced version of RCCL that we developed and tested on Meta’s internal workloads. RCCLX is fully integrated with Torchcomms and aims to empower researchers and developers to accelerate innovation, regardless of their chosen backend. Communication patterns for AI models are constantly evolving, as are hardware [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2026/02/24/data-center-engineering/rrcclx-innovating-gpu-communications-amd-platforms-meta/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2026/02/24/data-center-engineering/rrcclx-innovating-gpu-communications-amd-platforms-meta/\">RCCLX: Innovating GPU Communications on AMD Platforms</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "We are open-sourcing the initial version of RCCLX – an enhanced version of RCCL that we developed and tested on Meta’s internal workloads. RCCLX is fully integrated with Torchcomms and aims to empower researchers and developers to accelerate innovation, regardless of their chosen backend. Communication patterns for AI models are constantly evolving, as are hardware [...]\nRead More...\nThe post RCCLX: Innovating GPU Communications on AMD Platforms appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=23617",
        "categories": [
          "AI Research",
          "Data Center Engineering",
          "ML Applications",
          "Networking & Traffic"
        ],
        "isoDate": "2026-02-24T21:30:54.000Z"
      }
    ]
  },
  {
    "name": "eBay Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Twitter Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Netflix TechBlog",
    "category": "기업",
    "posts": [
      {
        "creator": "Netflix Technology Blog",
        "title": "Mount Mayhem at Netflix: Scaling Containers on Modern CPUs",
        "link": "https://netflixtechblog.com/mount-mayhem-at-netflix-scaling-containers-on-modern-cpus-f3b09b68beac?source=rss----2615bd06b42e---4",
        "pubDate": "Sat, 28 Feb 2026 22:55:53 GMT",
        "content:encodedSnippet": "Authors: Harshad Sane, Andrew Halaney\nImagine this — you click play on Netflix on a Friday night and behind the scenes hundreds of containers spring to action in a few seconds to answer your call. At Netflix, scaling containers efficiently is critical to delivering a seamless streaming experience to millions of members worldwide. To keep up with responsiveness at this scale, we modernized our container runtime, only to hit a surprising bottleneck: the CPU architecture itself.\nLet us walk you through the story of how we diagnosed the problem and what we learned about scaling containers at the hardware level.\nThe Problem\nWhen application demand requires that we scale up our servers, we get a new instance from AWS. To use this new capacity efficiently, pods are assigned to the node until its resources are considered fully allocated. A node can go from no applications running to being maxed out within moments of being ready to receive these applications.\nAs we migrated more and more from our old container platform to our new container platform, we started seeing some concerning trends. Some nodes were stalling for long periods of time, with a simple health check timing out after 30 seconds. An initial investigation showed that the mount table length was increasing dramatically in these situations, and reading it alone could take upwards of 30 seconds. Looking at systemd’s stack it was clear that it was busy processing these mount events as well and could lead to complete system lockup. Kubelet also timed out frequently talking to containerd in this period. Examining the mount table made it clear that these mounts were related to container creation.\nThe affected nodes were almost all r5.metal instances, and were starting applications whose container image contained many layers (50+).\nChallenge\nMount Lock Contention\nThe flamegraph in Figure 1 clearly shows where containerd spent its time. Almost all of the time is spent trying to grab a kernel-level lock as part of the various mount-related activities when assembling the container’s root filesystem!\nFigure 1: Flamegraph depicting lock contention\nLooking closer, containerd executes the following calls for each layer if using user namespaces:\n\nopen_tree() to get a reference to the layer / directory\nmount_setattr() to set the idmap to match the container’s user range, shifting the ownership so this container can access the files\nmove_mount() to create a bind mount on the host with this new idmap applied\n\nThese bind mounts are owned by the container’s user range and are then used as the lowerdirs to create the overlayfs-based rootfs for the container. Once the overlayfs rootfs is mounted, the bind mounts are then unmounted since they are not necessary to keep around once the overlayfs is constructed.\nIf a node is starting many containers at once, every CPU ends up busy trying to execute these mounts and umounts. The kernel VFS has various global locks related to the mount table, and each of these mounts requires taking that lock as we can see in the top of the flamegraph. Any system trying to quickly set up many containers is prone to this, and this is a function of the number of layers in the container image.\nFor example, assume a node is starting 100 containers, each with 50 layers in its image. Each container will need 50 bind mounts to do the idmap for each layer. The container’s overlayfs mount will be created using those bind mounts as the lower directories, and then all 50 bind mounts can be cleaned up via umount. Containerd actually goes through this process twice, once to determine some user information in the image and once to create the actual rootfs. This means the total number of mount operations on the start up path for our 100 containers is 100 * 2 * (1 + 50 + 50) = 20200 mounts, all of which require grabbing various global mount related locks!\nDiagnosis\nWhat’s Different In The New Runtime?\nAs alluded to in the introduction, Netflix has been undergoing a modernization of its container runtime. In the past a virtual kubelet + docker solution was used, whereas now a kubelet + containerd solution is being used. Both the old runtime and the new runtime used user namespaces, so what’s the difference here?\n\nOld Runtime:\nAll containers shared a single host user range. UIDs in image layers were shifted at untar time, so file permissions matched when containers accessed files. This worked because all containers used the same host user.\nNew Runtime:\nEach container gets a unique host user range, improving security — if a container escapes, it can only affect its own files. To avoid the costly process of untarring and shifting UIDs for every container, the new runtime uses the kernel’s idmap feature. This allows efficient UID mapping per container without copying or changing file ownership, which is why containerd performs many mounts.\n\nFigure 2 below is a simplified example of how this idmap feature looks like:\nFigure 2: idmap feature\nWhy Does Instance Type Matter?\nAs noted earlier, the issue was predominantly occurring on r5.metal instances. Once we identified the root issue we could easily reproduce by creating a container image with many layers and sending hundreds of workloads using the image to a test node.\nTo better understand why this bottleneck was more profound on some instances compared to others, we benchmarked container launches on different AWS instance types:\n\nr5.metal (5th gen Intel, dual-socket, multiple NUMA domains)\nm7i.metal-24xl (7th gen Intel, single-socket, single NUMA domain)\nm7a.24xlarge (7th gen AMD, single-socket, single NUMA domain)\n\nBaseline Results\nFigure 3 shows the baseline results from scaling containers on each instance type\n\nAt low concurrency (≤ ~20 containers), all platforms performed similarly\nAs concurrency increased, r5.metal began to fail around 100 containers\n7th generation AWS instances maintained lower launch times and higher success rates as concurrency grew\nm7a instances showed the most consistent scaling behavior with the lowest failure rates even at high concurrency\n\nDeep Dive\nUsing perf record and custom microbenchmarks, we can see the hottest code path was in the Linux kernel’s Virtual Filesystem (VFS) path lookup code — specifically, a tight spin loop waiting on a sequence lock in path_init(). The CPU spent most of its time executing the pause instruction, indicating many threads were spinning, waiting for the global lock, as shown in the disassembly snippet below\npath_init():\n…mov mount_lock,%eax\ntest $0x1,%al\nje 7c\npause\n…\nUsing Intel’s Topdown Microarchitecture Analysis (TMA), we observed:\n\n95.5% of pipeline slots were stalled on contested accesses (tma_contested_accesses).\n57% of slots were due to false sharing (multiple cores accessing the same cache line).\nCache line bouncing and lock contention were the primary culprits.\n\nGiven a high amount of time being spent in contested accesses, the natural thinking from a perspective of hardware variations led to investigation of NUMA and Hyperthreading impact coming from the architecture to this subset\nNUMA Effects\nNon-Uniform Memory Access (NUMA) is a system design where each processor has its own local memory for faster access but relies on an interconnect to access the memory attached to a remote processor. Introduced in the 1990s to improve scalability in multiprocessor systems, NUMA boosts performance but also introduces higher latency when a CPU needs to access memory attached to another processor. Figure 4 is a simple image describing local vs remote access patterns of a NUMA architecture\nFigure 4: Source: https://pmem.io/images/posts/numa_overview.png\nAWS instances come in a variety of shapes and sizes. To obtain the largest core count, we tested the 2-socket 5th generation metal instances (r5.metal), on which containers were orchestrated by the titus agent. Modern dual-socket architectures implement NUMA design, leading to faster local but higher remote access latencies. Although container orchestration can maintain locality, global locks can easily run into high latency effects due to remote synchronization. In order to test the impact of NUMA, we tested an AWS 48xl sized instance with 2 NUMA nodes or sockets versus an AWS 24xl sized instance, which represents a single NUMA node or socket. As seen from Figure 5, the extra hop introduces high latencies and hence failures very quickly.\nFigure 5: Numa Impact\nHyperthreading Effects\n\nHyperthreading (HT): Disabling HT on m7i.metal-24xl (Intel) improved container launch latencies by 20–30% as seen in Figure 6, since hyperthreads compete for shared execution resources, worsening the lock contention. When hyperthreading is enabled, each physical CPU core is split into two logical CPUs (hyperthreads) that share most of the core’s execution resources, such as caches, execution units, and memory bandwidth. While this can improve throughput for workloads that are not fully utilizing the core, it introduces significant challenges for workloads that rely heavily on global locks. By disabling hyperthreading, each thread runs on its own physical core, eliminating this competition for shared resources between hyperthreads. As a result, threads can acquire and release global locks more quickly, reducing overall contention and improving latency for operations that generally share underlying resources.\nFigure 6: Hyperthreading impact\nWhy Does Hardware Architecture Matter?\nCentralized Cache Architectures\nSome modern server CPUs use a mesh-style interconnect to link cores and cache slices, with each intersection managing cache coherence for a subset of memory addresses. In these designs, all communication passes through a central queueing structure, which can only handle one request for a given address at a time. When a global lock (like the mount lock) is under heavy contention, all atomic operations targeting that lock are funneled through this single queue, causing requests to pile up and resulting in memory stalls and latency spikes.\nIn some well-known mesh-based architectures as shown in Figure 7 below, this central queue is called the “Table of Requests” (TOR), and it can become a surprising bottleneck when many threads are fighting for the same lock. If you’ve ever wondered why certain CPUs seem to “pause for breath” under heavy contention, this is often the culprit.\nFigure 7: Public document from one of the major CPU vendors Source:https://www.intel.com/content/dam/developer/articles/technical/ddio-analysis-performance-monitoring/Figure1.png\nDistributed Cache Architectures\nSome modern server CPUs use a distributed, chiplet-based architecture (Figure 8), where multiple core complexes, each with their own local last-level cache — are connected via a high-speed interconnect fabric. In these designs, cache coherence is managed within each core complex, and traffic between complexes is handled by a scalable control fabric. Unlike mesh-based architectures with centralized queueing structures, this distributed approach spreads contention across multiple domains, making severe stalls from global lock contention less likely. For those interested in the technical details, public documentation from major CPU vendors provides deeper insight into these distributed cache and chiplet designs.\nFigure 8: Public document from one of the major CPU vendors, Source: (AMD EPYC 9004 Genoa Chiplet Architecture 8x CCD — ServeTheHome)\nHere is a comparison of the same workload run on m7i (centralized cache architecture) vs m7a (distributed cache architecture). Note that, in order to make it closely comparable, Hyperthreading (HT) was disabled on m7i, given previous regression seen in Figure 6, and experiments were run using same core counts. The result clearly shows a fairly consistent difference in performance of approximately 20% as shown in Figure 9\nFigure 9: Architectural impact between m7i and m7a\nMicrobenchmark Results\nTo prove the above theory related to NUMA, HT and micro-architecture, we developed a small microbenchmark which basically invokes a given number of threads that then spins on a globally contended lock. Running the benchmark at increasing thread counts reveals the latency characteristics of the system under different scenarios. For example, Figure 10 below is the microbenchmark results with NUMA, HT and different microarchitectures.\nFigure 10: Global lock contention benchmark results\nResults from this custom synthetic benchmark (pause_bench) confirmed:\n\nOn r5.metal, eliminating NUMA by only using a single socket significantly drops latency at high thread counts\nOn m7i.metal-24xl, disabling hyperthreading further improves scaling\nOn m7a.24xlarge, performance scales the best, demonstrating that a distributed cache architecture handles cache-line contention in this case of global locks more gracefully.\n\nImproving Software Architecture\nWhile understanding the impacts of the hardware architecture is important for assessing possible mitigations, the root cause here is contention over a global lock. Working with containerd upstream we came to two possible solutions:\n\nUse the newer kernel mount API’s fsconfig() lowerdir+ support to supply the idmap’ed lowerdirs as fd’s instead of filesystem paths. This avoids the move_mount() syscall mentioned prior which requires global locks to mount each layer to the mount table\nMap the common parent directory of all the layers. This makes the number of mount operations go from O(n) to O(1) per container, where n is the number of layers in the image\n\nSince using the newer API requires using a new kernel, we opted to make the latter change to benefit more of the community. With that in place, no longer do we see containerd’s flamegraph being dominated by mount-related operations. In fact, as seen in Figure 11 below we had to highlight them in purple below to see them at all!\nFigure 11: Optimized solution\nConclusion\nOur journey migrating to a modern kubelet + containerd runtime at Netflix revealed just how deeply intertwined software and hardware architecture can be when operating at scale. While kubelet/containerd’s usage of unique container users brought significant security gains, it also surfaced new bottlenecks rooted in kernel and CPU architecture — particularly when launching hundreds of many layered container images in parallel. Our investigation highlighted that not all hardware is created equal for this workload: centralized cache management amplified cache contention while distributed cache design smoothly scaled under load.\nUltimately, the best solution combined hardware awareness with software improvements. For an immediate mitigation we chose to route these workloads to CPU architectures that scaled better under these conditions. By changing the software design to minimize per-layer mount operations, we eliminated the global lock as a launch-time bottleneck — unlocking faster, more reliable scaling regardless of the underlying CPU architecture. This experience underscores the importance of holistic performance engineering: understanding and optimizing both the software stack and the hardware it runs on is key to delivering seamless user experiences at Netflix scale.\nWe trust these insights will assist others in navigating the evolving container ecosystem, transforming potential challenges into opportunities for building robust, high-performance platforms.\nSpecial thanks to the Titus and Performance Engineering teams at Netflix.\n\nMount Mayhem at Netflix: Scaling Containers on Modern CPUs was originally published in Netflix TechBlog on Medium, where people are continuing the conversation by highlighting and responding to this story.",
        "dc:creator": "Netflix Technology Blog",
        "guid": "https://medium.com/p/f3b09b68beac",
        "categories": [
          "performance",
          "containers",
          "cpu",
          "netflix",
          "scaling"
        ],
        "isoDate": "2026-02-28T22:55:53.000Z"
      },
      {
        "creator": "Netflix Technology Blog",
        "title": "MediaFM: The Multimodal AI Foundation for Media Understanding at Netflix",
        "link": "https://netflixtechblog.com/mediafm-the-multimodal-ai-foundation-for-media-understanding-at-netflix-e8c28df82e2d?source=rss----2615bd06b42e---4",
        "pubDate": "Mon, 23 Feb 2026 18:24:32 GMT",
        "content:encodedSnippet": "Avneesh Saluja, Santiago Castro, Bowei Yan, Ashish Rastogi\nIntroduction\nNetflix’s core mission is to connect millions of members around the world with stories they’ll love. This requires not just an incredible catalog, but also a deep, machine-level understanding of every piece of content in that catalog, from the biggest blockbusters to the most niche documentaries. As we onboard new types of content such as live events and podcasts, the need to scalably understand these nuances becomes even more critical to our productions and member-facing experiences.\nMany of these media-related tasks require sophisticated long-form video understanding e.g., identifying subtle narrative dependencies and emotional arcs that span entire episodes or films. Previous work has found that to truly grasp the content’s essence, our models must leverage the full multimodal signal. For example, the audio soundtrack is a crucial, non-visual modality that can help more precisely identify clip-level tones or when a new scene starts. Can we use our collection of shows and movies to learn how to a) fuse modalities like audio, video, and subtitle text together and b) develop robust representations that leverage the narrative structure that is present in long form entertainment? Consisting of tens of millions of individual shots across multiple titles, our diverse yet entertainment-specific dataset provides the perfect foundation to train multimodal media understanding models that enable many capabilities across the company such as ads relevancy, clip popularity prediction, and clip tagging.\nFor these reasons, we developed the Netflix Media Foundational Model (MediaFM), our new, in-house, multimodal content embedding model. MediaFM is the first tri-modal (audio, video, text) model pretrained on portions of the Netflix catalog. Its core is a multimodal, Transformer-based encoder designed to generate rich, contextual embeddings¹ for shots from our catalog by learning the temporal relationships between them through integrating visual, audio, and textual information. The resulting shot-level embeddings are powerful representations designed to create a deeper, more nuanced, and machine-readable understanding of our content, providing the critical backbone for effective cold start of newly launching titles in recommendations, optimized promotional assets (like art and trailers), and internal content analysis tools.\nFigure 1: MediaFM Architecture\nInput Representation & Preprocessing\nThe model’s fundamental unit of input is a shot, derived by segmenting a movie or episode (collectively referred to as “title”) using a shot boundary detection algorithm. For each shot, we generate three distinct embeddings from its core modalities:\n\nVideo: an internal model called SeqCLIP (a CLIP-style model fine-tuned on video retrieval datasets) is used to embed frames sampled at uniform intervals from segmented shots\nAudio: the audio samples from the same shots are embedded using Meta FAIR’s wav2vec2\nTimed Text: OpenAI’s text-embedding-3-large model is used to encode the corresponding timed text (e.g., closed captions, audio descriptions, or subtitles) for each shot\n\nFor each shot, the three embeddings² are concatenated and unit-normed to form a single 2304-dimensional fused embedding vector. The transformer encoder is trained on sequences of shots, so each example in our dataset is a temporally-ordered sequence of these fused embeddings from the same movie or episode (up to 512 shots per sequence). We also have access to title-level metadata which is used to provide global context for each sequence (via the [GLOBAL]token). The title-level embedding is computed by passing title-level metadata (such as synopses and tags) through the text-embedding-3-large model.\nModel Architecture and Training Objective\nThe core of our model is a transformer encoder, architecturally similar to BERT. A sequence of preprocessed shot embeddings is passed through the following stages:\n\nInput Projection: The fused shot embeddings are first projected down to the model’s hidden dimension via a linear layer.\nSequence Construction & Special Tokens: Before entering the Transformer, two special embeddings are prepended to the sequence:\n• a learnable [CLS] embedding is added at the very beginning.\n• the title-level embedding is projected to the model’s hidden dimension and inserted after the [CLS] token as the [GLOBAL] token, providing title-level context to every shot in the sequence and participating in the self-attention process.\nContextualization: The sequence is enhanced with positional embeddings and fed through the Transformer stack to provide shot representations based on their surrounding context.\nOutput Projection: The contextualized hidden states from the Transformer are passed through a final linear layer, projecting them from the hidden layers back up to the 2304-dimensional fused embedding space for prediction.\n\nWe train the model using a Masked Shot Modeling (MSM) objective. In this self-supervised task, we randomly mask 20% of the input shot embeddings in each sequence by replacing them with a learnable [MASK] embedding. The model’s objective is to predict the original, unmasked fused embedding for these masked positions. The model is optimized by minimizing the cosine distance between its predicted embedding and the ground-truth embedding for each masked shot.\nWe optimized the hidden parameters with Muon and the remaining parameters with AdamW. It’s worth noting that the switch to Muon resulted in noticeable improvements.\nEvaluation\nTo evaluate the learned embeddings, we learn task-specific linear layers on top of frozen representations (i.e., linear probes). Most of the tasks are clip-level, i.e., each example is a short clip ranging from a few seconds to a minute which are often presented to our members while recommending a title to them. When embedding these clips, we find that “embedding in context”, namely extracting the embeddings from within a larger sequence (e.g., the episode containing the clip), naturally does much better than embedding only the shots from a clip.\nTasks\nOur embeddings are foundational and we find that they bring value to applications across Netflix. Here are a few:\n\nAd Relevancy: A multilabel classification task to categorize Netflix clips for relevant ad placement, measured by Average Precision. In this task, these representations operate at the retrieval stage, where they help in identifying the candidate set and in turn are fed into the ad serving system for relevance optimization.\nClip Popularity Ranking: A ranking task to predict the relative performance (in click-through rate, CTR) of a media clip relative to other clips from that show or movie, measured by a ten-fold with Kendall’s tau correlation coefficient.\nClip Tone: A multi-label classification of hook clips into 100 tone categories (e.g., creepy, scary, humorous) from our internal Metadata & Ratings team, measured by micro Average Precision (averaged across tone categories).\nClip Genre: A multi-label classification of clips into eleven core genres (Action, Anime, Comedy, Documentary, Drama, Fantasy, Horror, Kids, Romance, Sci-fi, Thriller) derived from the genre of the parent title, measured by macro Average Precision (averaged across genres).\nClip Retrieval: a binary classification of clips from movies or episodes into “clip-worthy” (i.e., a good clip to showcase the title) or not, as determined by human annotators, and as measured by Average Precision. The positive to negative clip ratio is 1:3, and for each title we select 6–10 positive clips and the corresponding number of negatives.\n\nIt’s worth noting that for the tasks above (as well as other tasks that use our model), the model outputs are utilized as information that the relevant teams use when driving to a decision rather than being used in a completely end-to-end fashion. Many of the improvements are also in various stages of deployment.\nResults\nFigure 2³ compares MediaFM to several strong baselines:\n\nThe previously mentioned SeqCLIP, which also provides the video embedding input for MediaFM\nGoogle’s VertexAI multimodal embeddings\nTwelveLabs’ Marengo 2.7 embeddings\nFigure 2: Performance of MediaFM vs. external and internal models.\nOn all tasks, MediaFM is better than the baselines. Improvements seem to be larger for tasks that require more detailed narrative understanding e.g., predicting the most relevant ads for an ad break given the surrounding context. We look further into this next.\nAblations\nMediaFM’s primary improvements over previous Netflix work stem from two key areas: combining multiple modalities and learning to contextualize shot representations. To determine the contribution of each factor across different tasks, we compared MediaFM to a baseline. This baseline concatenates the three input embeddings, essentially providing the same complete, shot-level input as MediaFM but without the contextualization step. This comparison allows us to isolate which tasks benefit most from the contextualization aspect.\n\nAdditional modalities help somewhat for tone but the main improvement comes from contextualization.\n\nOddly, multiple uncontextualized modalities hurts the clip popularity ranking model, but adding contextualization significantly improves performance.\n\nFor clip retrieval we see a natural progression of around 15% for each improvement.\nNext Steps\nMediaFM presents a way to learn how to fuse and/or contextualize shot-level information by leveraging Netflix’s catalog in a self-supervised manner. With this perspective, we are actively investigating how pretrained multimodal (audio, video/image, text) LLMs like Qwen3-Omni, where the modality fusion has already been learned, can provide an even stronger starting point for subsequent model generations.\nNext in this series of blog posts, we will present our method to embed title-level metadata and adapt it to our needs. Stay tuned!\nFootnotes\n\nWe chose embeddings over generative text outputs to prioritize modular design. This provides a tighter, cleaner abstraction layer: we generate the representation once, and it is consumed across our entire suite of services. This avoids the architectural fragility of fine-tuning, allowing us to enhance our existing embedding-based workflows with new modalities more flexibly.\nAll of our data has audio and video; we zero-pad for missing timed text data, which is relatively likely to occur (e.g., in shots without dialogue).\nThe title-level tasks couldn’t be evaluated with the VertexAI MM and Marengo embedding models as the videos exceed the length limit set by the APIs.\n\nAcknowledgements\nWe would like to thank Matt Thanabalan and Chaitanya Ekanadham for their contributions to this work.\n\nMediaFM: The Multimodal AI Foundation for Media Understanding at Netflix was originally published in Netflix TechBlog on Medium, where people are continuing the conversation by highlighting and responding to this story.",
        "dc:creator": "Netflix Technology Blog",
        "guid": "https://medium.com/p/e8c28df82e2d",
        "categories": [
          "foundation-models",
          "machine-learning",
          "multimodal",
          "artificial-intelligence",
          "media"
        ],
        "isoDate": "2026-02-23T18:24:32.000Z"
      }
    ]
  },
  {
    "name": "JetBrains: Developer Tools for Professionals and Teams – Company Blog | JetBrains",
    "category": "기업",
    "posts": [
      {
        "creator": "Marharyta Milovanova",
        "title": "Introducing TeamCity’s New Design, Phase II: Creation Flow",
        "link": "https://blog.jetbrains.com/teamcity/2026/02/introducing-teamcitys-new-design-phase-2/",
        "pubDate": "Thu, 26 Feb 2026 13:27:31 +0000",
        "content:encodedSnippet": "This is the second part in a series that dives into how and why we’re redesigning TeamCity. In Part One, we shared navigational and admin changes. In Part Two, we’ll dive deeper into the сreation flow redesign. We’ll also introduce you to the new UI and go into detail about the steps we’re taking to revamp TeamCity.\nIntroducing a more cohesive UI\nWe’re reimagining TeamCity’s design to meet the expectations of today’s developers. The goal is simple: help teams get from setup to their first successful build faster and with less friction. \nToday, creating a first build can take more than 20 clicks, and only a fraction of users explore advanced features. By rethinking this experience, we’re making TeamCity more approachable for new users and more efficient for experts.\nThe creation flow is a key part of how people experience a product. It’s often the first thing users see, and it helps determine whether the product feels easy and welcoming or confusing and heavy. \nA well-designed flow helps people get started without overthinking and guides them smoothly so they can focus on what they want to do, not how to do it.\n\n\n\n\nConcept exploration\nAs outlined in Part One, our product interviews uncovered a recurring pain point: new users often get stuck when creating projects in TeamCity. The flow wasn’t intuitive, and creating or reusing connections was more complex than it should have been. \nOur mission became simple: to make starting a new project effortless, straightforward, and enjoyable.\n\n\n\n\nThe most pressing problems were:\nA hidden entry point\nA cluttered UI with broken informational hierarchy\nMissing functionality that required the user to find workarounds\nOne major factor to keep in mind from the beginning is that we are bringing pipelines to TeamCity. So, the first challenge was to clearly communicate the difference between pipelines and build configurations and help users understand the distinct value each provides.\nThe second goal was to remove clutter and unnecessary information, guiding the user and displaying relevant settings when needed. TeamCity is one of the strongest CI tools on the market, but many of its strengths are hidden deep within the product. \nDuring interview sessions, users mentioned pain points that had already been solved by functionality the users were simply not aware of, such as templates or VCS reuse.\nWe started by drawing up a flow chart of what the new step-by-step process might look like:\n\n\n\n\nConcept → Prototype → Action\nThe design underwent multiple iterations and rounds of guerrilla testing before being handed over to the first client for evaluation. We conducted UX prototype testing with 10 clients, iterating after each session to refine and develop the mockups.\nOnce the design was validated, we worked closely with the engineering team to review all existing and new scenarios, ensuring complete coverage. Finally, we structured the delivery into iterations – and the first version is now live for users to explore.\nBefore\n\n\n\nConcept\n\n\n\nAfter\n\n\n\nFeatures\nSeparate flow for project creation\nIn the old UI, users were never sure what would happen after triggering the creation process – would it create a project, a build configuration, or both? Separating them into distinct flows brought much-needed clarity and predictability.\n\n\n\n\nCreate projects from an existing repository URL\nDuring the Journey Map study, we discovered the workarounds that users employed when attaching the VCS root. To streamline this process, we’ve added the option to create a project straight from a VCS root.\n\n\n\n\nEasier VCS integration setup\nConnecting TeamCity to your version control system is now simpler than ever. We’ve introduced a new connection interface that guides you through linking your GitHub, GitLab, or Bitbucket account before creating a VCS root. \nOnce the integration is set up, TeamCity can automatically find your repositories by name and help you configure the VCS root with just a few clicks.\nWe have added a setting to configure a new VCS connection in the creation flow. Setting up the connection both speeds up onboarding and enables TeamCity functionality to serve the user.\n\n\n\n\nCreate from template\nTemplates have always been one of TeamCity’s hidden gems. They simplify setup, reduce repetition, and make managing builds easier. \nIn the new design, we’ve made templates a visible part of the setup flow. Instead of digging through menus, users can opt to use a template in the early stages of build creation. This saves time and helps you get to your first successful build faster.\n\n\n\n\nWelcome to the new TeamCity\nWe’re excited for you to get your hands on the new TeamCity and can’t wait to hear your thoughts! \nPlease feel free to share them here in the comments, and don’t hesitate to contact our Support team if you have any questions. We’re always here to help!",
        "dc:creator": "Marharyta Milovanova",
        "content": "This is the second part in a series that dives into how and why we&#8217;re redesigning TeamCity. In Part One, we shared navigational and admin changes. In Part Two, we’ll dive deeper into the сreation flow redesign. We’ll also introduce you to the new UI and go into detail about the steps we’re taking to [&#8230;]",
        "contentSnippet": "This is the second part in a series that dives into how and why we’re redesigning TeamCity. In Part One, we shared navigational and admin changes. In Part Two, we’ll dive deeper into the сreation flow redesign. We’ll also introduce you to the new UI and go into detail about the steps we’re taking to […]",
        "guid": "https://blog.jetbrains.com/?post_type=teamcity&p=684008",
        "isoDate": "2026-02-26T13:27:31.000Z"
      },
      {
        "creator": "Kodee",
        "title": "15 Things To Do Before, During, and After KotlinConf’26",
        "link": "https://blog.jetbrains.com/kotlin/2026/02/15-things-to-do-before-during-and-after-kotlinconf-26/",
        "pubDate": "Thu, 26 Feb 2026 12:40:38 +0000",
        "content:encodedSnippet": "So, you’re coming to KotlinConf’26? Maybe it’s your first time in Munich, or even your first time at KotlinConf. You have your tickets, you’ve learned the schedule by heart, but it might still feel a little overwhelming. Let me show you how you can have the best possible experience by guiding you through all the things you can do.\nBelieve me, KotlinConf is so much more than a conference!\n1. Explore Munich (before things get busy)\nIf you’re arriving before the conference, try to set aside some time to explore the city. Munich has great food, interesting neighborhoods, and plenty of places to slow down before the schedule gets busy.\nNot sure what to see? Keep an eye out for my social media posts, I’ll definitely have some tips for you! ;-)\n\n\n\n\n2. Skip the line. Register early\nStanding in line on the first morning, half-awake and carrying a backpack, is not how you want to start KotlinConf.\nCome to the venue the day before the conference kicks off on May 20 between 2:00 and 5:00 pm. You’ll avoid large queues, save time, and keep your energy for what really matters. And believe me, you’ll need it.\nWhen you’re already checked in, you can walk in on Day 1, grab a coffee, find your seat, and focus on the talks instead of logistics. It’s a much better way to begin.\nSave your spot at KotlinConf’26\n         \n3. Start with a workshop\nIf you want to get even more out of KotlinConf, start with a full day of hands-on workshops on May 20.\nBuild Shared UI With Compose Multiplatform.\nGo Deeper Into Kotlin Multiplatform Architecture.\nMaster Coroutines and Asynchronous Programming.\nBuild High-Performance Backends With Spring Boot.\nCreate AI Agents in Kotlin.\nRefactor Toward Functional Kotlin.\n\n\n\n\n\nWorkshops are practical, focused, and led by Kotlin experts. You’ll leave with skills you can apply right away.\nSeats are limited, so make sure to save yours before they’re gone!\n4. Don’t miss the Keynote!\nJoin us for the opening Keynote to see the big picture. This is where we set the stage, introduce the year’s most ambitious ideas, and bring the entire community together. There is a specific energy to experiencing these reveals live – don’t settle for the recap.\n\n\n\n\n5. Take a selfie with me\nIf you spot me somewhere around the venue, don’t hesitate, come over and say “hello”. \nA quick selfie, a short chat, a shared laugh in between sessions, whatever, I’m down!\nI’m always happy to meet you, hear where you’re from, what you’re working on, and how KotlinConf is going for you. And who knows, you might even end up in one of my posts. Let’s create some memories!\n\n\n\n\n6. Join the Coding Challenge\nEngage in our Coding Challenge. It’s a good way to test yourself, learn something new, and see how you approach problems under a bit of pressure. It gets even more interesting when you are watching others code! And if you win? Well then, you’ve earned the right to brag a little.\n7. Wander around the expo \nDon’t be shy, after you’ve met everything Kotlin, go out and meet some of our partners!\nThis is where companies, communities, and partners set up booths to connect with all of you!\nSee how Kotlin is used in practice, and talk directly with engineers. Ask some questions and discover new tools, libraries, and platforms. Of course, do some networking and meet other developers. And also, get some swag for yourself and colleagues back home, it’s always nice to have some souvenirs!\n\n\n\n\n8. Go to the party\nOn the evening of May 21, put on your fancy clothes (maybe even your dancing shoes) and come to the party.\nThis is where you can reconnect with friends you haven’t seen in a while, continue conversations that started earlier on in the day, and meet new people along the way. Come for the music, stay for the conversations, and leave with a few more names in your contacts list!\n\n\n\n\n9. Wake up early for Day 2\nAfter a night of partying, I know waking up isn’t always the easiest. But you have another full day of learning ahead, starting from the Day 2 Keynote at 9:00 am, where Lena Reinhard will take the stage to set the tone for the day. Set your alarm, grab a coffee (no worries if you don’t have time for one: The team and plenty of coffee will be waiting for you at the venue), and head down to the conference. You’ll be glad you did. \n10.  Learn something new (and eat well)\nThe main reason you’re here is to learn – new tools, ideas, or ways of thinking.\nTake notes, ask questions, and give yourself time to reflect. And don’t forget to eat. Good food keeps you focused and energized, and don’t worry, KotlinConf has plenty of delicious eats on offer!\n\n\n\n\n11.  See the future! \nMake a wish, write a prediction, and place it in a time capsule. We’re going to open it and reveal what’s inside in 2031, so you’ll have to be patient and wait a bit to see if you were right! \n12. Take part in the games\nAfter all the learning and networking, it’s always good to relax. Use what you’ve just learned and play a game built with Compose Multiplatform for web, with a chance to win a prize. If I were you, I wouldn’t miss this! \n13.  Attend the Golden Kodee Awards\nThe Golden Kodee Awards celebrate individuals and communities who make a real impact by sharing knowledge, organizing events, and inspiring others. This year is special, because 2026 marks the very first time these awards are being presented.\n It’s a chance to recognize outstanding contributors and thank them for everything they do. And let’s be honest, gold looks great on me, don’t you agree?\n14.  Don’t forget to take a photo with me!\nDid I already mention that?\n\n\n\n\n15. Leave feedback and vote\nVote for all the sessions you attended. Leave your comments in the app about the talks. Reach out to us – don’t be shy, your feedback means a lot. We want to provide the best possible experience. The next KotlinConf might be even better than this one!\nSave your spot at KotlinConf’26\n         \n+ 16.  Mark your calendars\nBefore you head home and dive back into your inbox, take a moment to mark the dates for next year’s KotlinConf. It’s a small step, but it makes sure you won’t miss it once work gets busy.\nI already miss you all, so let’s make sure we meet again next year.",
        "dc:creator": "Kodee",
        "content": "So, you’re coming to KotlinConf’26? Maybe it’s your first time in Munich, or even your first time at KotlinConf. You have your tickets, you’ve learned the schedule by heart, but it might still feel a little overwhelming. Let me show you how you can have the best possible experience by guiding you through all the [&#8230;]",
        "contentSnippet": "So, you’re coming to KotlinConf’26? Maybe it’s your first time in Munich, or even your first time at KotlinConf. You have your tickets, you’ve learned the schedule by heart, but it might still feel a little overwhelming. Let me show you how you can have the best possible experience by guiding you through all the […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=683721",
        "categories": [
          "news",
          "cap-kodee",
          "kotlinconf"
        ],
        "isoDate": "2026-02-26T12:40:38.000Z"
      },
      {
        "creator": "Lana Novikova",
        "title": "Toolbox App 3.3: Introducing jetbrainsd, an Improved Linux Experience, and More",
        "link": "https://blog.jetbrains.com/toolbox-app/2026/02/toolbox-app-3-3-introducing-jetbrainsd-an-improved-linux-experience-and-more/",
        "pubDate": "Thu, 26 Feb 2026 11:31:29 +0000",
        "content:encodedSnippet": "Toolbox App 3.3 introduces jetbrainsd – a lightweight background service that lays the foundation for cross-IDE features like protocol handling. This release also brings significant stability improvements for Linux users, smoother plugin updates, and a number of bug fixes across all platforms.\njetbrainsd\nToolbox App 3.3 ships with the jetbrainsd service – a new lightweight background process that starts automatically when you launch the Toolbox App.\nWhat this means for you:\njetbrains:// links now route through the daemon instead of the Toolbox App itself, providing a more reliable experience when opening links from browsers, documentation, or external applications.\nThe service is managed automatically by the Toolbox App – it installs, starts, and updates alongside the Toolbox App.\nRead more in the docs. \nImproved Linux experience\nLinux users will notice several stability improvements in this release. Highlights include:\nThe Toolbox App widget no longer stays stuck on top of windows after the app restarts or updates on Linux.\nThe Toolbox App no longer shuts down instantly or fails to restart during the update process.\nIf you previously couldn’t log in to the Toolbox App on a fresh GNOME setup due to a missing secret collection, you can now authenticate successfully.\nThe .desktop file now uses relative icon paths instead of absolute ones, improving compatibility with different Linux setups.\nPlugin updates without restart\nPlugins can now be updated without restarting the application. Previously, after distributing a new plugin version to the plugin directory, you had to restart the Toolbox App to load the updated version. This is no longer necessary, as the Toolbox App will pick up plugin changes automatically.\nRemote development fixes\nThe Toolbox App remote agent now properly stops when you select Close and Stop and disconnect via SSH, instead of remaining active in the background.\nThe app no longer crashes with an RpcClient was cancelled error when navigating to SSH remote development targets after restarting your machine.\nDownload Toolbox App\n                                    \nWe’d love to hear your thoughts on Toolbox App 3.3! Your feedback helps us improve the product, so please share your experience in the comments.\nThe JetBrains Toolbox App team",
        "dc:creator": "Lana Novikova",
        "content": "Toolbox App 3.3 introduces jetbrainsd – a lightweight background service that lays the foundation for cross-IDE features like protocol handling. This release also brings significant stability improvements for Linux users, smoother plugin updates, and a number of bug fixes across all platforms. jetbrainsd Toolbox App 3.3 ships with the jetbrainsd service – a new lightweight [&#8230;]",
        "contentSnippet": "Toolbox App 3.3 introduces jetbrainsd – a lightweight background service that lays the foundation for cross-IDE features like protocol handling. This release also brings significant stability improvements for Linux users, smoother plugin updates, and a number of bug fixes across all platforms. jetbrainsd Toolbox App 3.3 ships with the jetbrainsd service – a new lightweight […]",
        "guid": "https://blog.jetbrains.com/?post_type=toolbox-app&p=683667",
        "categories": [
          "jetbrains-toolbox",
          "toolbox-app"
        ],
        "isoDate": "2026-02-26T11:31:29.000Z"
      },
      {
        "creator": "Siva Katamreddy",
        "title": "Migrating to Modular Monolith using Spring Modulith and IntelliJ IDEA",
        "link": "https://blog.jetbrains.com/idea/2026/02/migrating-to-modular-monolith-using-spring-modulith-and-intellij-idea/",
        "pubDate": "Wed, 25 Feb 2026 12:40:36 +0000",
        "content:encodedSnippet": "As applications grow in complexity, maintaining a clean architecture becomes increasingly challenging. The traditional package-by-layer approach of organizing code into controllers, services, repositories, and entities packages often leads to tightly coupled code that’s hard to maintain and evolve.\nSpring Modulith, combined with IntelliJ IDEA’s excellent tooling support, offers a powerful solution for building well-structured modular monoliths.\nIn this article, we will use a bookstore sample application as an example to demonstrate Spring Modulith features.\nIf you are interested in building a Modular Monolith using Spring and Kotlin, check out Building Modular Monoliths With Kotlin and Spring\n1. The Problem with Monoliths and Package-by-Layer\nMany Spring Boot applications are organized by technical layer rather than by business capability. A typical layout looks like this:\nbookstore\n  |-- config\n  |-- entities\n  |-- exceptions\n  |-- models\n  |-- repositories\n  |-- services\n  |-- web\nThis package-by-layer style causes several problems.\nThe Code Structure Doesn’t Express What the Application Does\nWhen you open the project, you see “repositories,” “services,” and “web,” but not “catalog,” “orders,” or “inventory.” The domain is hidden behind technical folders, which makes it harder for developers to find feature-related code and understand boundaries.\nEverything Tends to Become Public\nIn a layer-based layout, types in one package are often used from many others. To allow that, classes are made public, which effectively exposes them to the whole application. There is no clear “public API” per feature, and hence anything can depend on anything.\nTight Coupling and Spaghetti Code\nWith no explicit boundaries, services and controllers from different features depend on each other’s internals. For example, order logic might call catalog’s ProductService directly or reuse internal DTOs. Over time this turns into a tightly coupled “big ball of mud” where changing one feature risks breaking others.\nFragile Changes\nAdding or changing a feature often forces you to touch code in repositories, services, and web at once, with no clear “module” to test or reason about. Refactoring becomes risky because the impact is hard to see.\nIn short: package-by-layer encourages a single, undivided monolith with weak boundaries and unclear ownership. Spring Modulith addresses this by turning your codebase into an explicit set of modules with clear APIs and enforced boundaries.\n2. What Benefits Spring Modulith Brings\nSpring Modulith helps you build modular monoliths: one deployable application, but with clear, domain-driven modules and enforced structure.\nExplicit Module Boundaries\nModules are direct sub-packages of your application’s base package (e.g. com.example.bookstore.catalog, com.example.bookstore.orders). Spring Modulith treats each as a module and checks that:\nOther modules do not depend on internal types unless they are explicitly exposed.\nThere are no circular dependencies between modules.\nDependencies between modules are declared (e.g. via allowedDependencies), so the architecture stays intentional.\nClear Public APIs\nEach module can define a provided interface (public API): a small set of types and beans that other modules are allowed to use. Everything else is internal. This reduces coupling and makes it obvious how modules interact.\nEvent-Driven Communication\nSpring Modulith encourages events for cross-module communication (e.g. OrderCreatedEvent). It provides:\n@ApplicationModuleListener for module-aware event handling.\nEvent publication registry (e.g. JDBC) so events can be persisted and processed reliably.\nExternalized events (e.g. AMQP, Kafka) to integrate with message brokers and other applications.\n\n\n\n\nThis keeps modules loosely coupled and makes it easier to later extract a module into a separate service.\nTestability\nYou can test one module at a time with @ApplicationModuleTest, controlling which modules and beans are loaded. You mock other modules’ APIs instead of pulling in the whole application, which speeds up tests and keeps them focused.\nDocumentation and Verification\nSpring Modulith can:\nVerify modular structure in tests via ApplicationModules.of(...).verify().\nGenerate C4-style documentation from the same model.\nSo the documented architecture and the actual code stay in sync.\nGradual Migration Path\nYou can introduce Spring Modulith into an existing Spring Boot monolith step by step: first refactor to package-by-module, then add the Spring Modulith dependencies and ModularityTest, and fix violations one by one. You don’t need to rewrite the application.\n3. How to Add Spring Modulith to a Spring Boot Project\nAdd the Dependencies\nUse the Spring Modulith BOM and add the core and test starters:\n<properties>\n    <spring-modulith.version>2.0.3</spring-modulith.version>\n</properties>\n\n<dependencyManagement>\n    <dependencies>\n        <dependency>\n            <groupId>org.springframework.modulith</groupId>\n            <artifactId>spring-modulith-bom</artifactId>\n            <version>${spring-modulith.version}</version>\n            <type>pom</type>\n            <scope>import</scope>\n        </dependency>\n    </dependencies>\n</dependencyManagement>\n\n<dependencies>\n    <!-- other dependencies -->\n    <dependency>\n        <groupId>org.springframework.modulith</groupId>\n        <artifactId>spring-modulith-starter-core</artifactId>\n    </dependency>\n\n    <dependency>\n        <groupId>org.springframework.modulith</groupId>\n        <artifactId>spring-modulith-starter-test</artifactId>\n        <scope>test</scope>\n    </dependency>\n</dependencies>\nEnable IntelliJ IDEA Support\nSpring Modulith support is bundled in IntelliJ IDEA with the Ultimate Subscription and is enabled by default once the Spring Modulith dependencies are on the classpath.\nTo confirm the plugin is enabled:\nOpen Settings (Ctrl+Alt+S / Cmd+,).\nGo to Plugins → Installed.\nSearch for Spring Modulith and ensure it is checked.\nYou can then use module indicators in the project tree, the Structure tool window, and Modulith-specific inspections and quick-fixes.\nAdd a Modularity Test\nAdd a test that verifies your modular structure so that violations are caught in CI:\npackage com.sivalabs.bookstore;\n\nimport org.junit.jupiter.api.Test;\nimport org.springframework.modulith.core.ApplicationModules;\n\nclass ModularityTest {\n    static ApplicationModules modules = ApplicationModules.of(BookStoreApplication.class);\n\n    @Test\n    void verifiesModularStructure() {\n        modules.verify();\n    }\n}\nAfter refactoring to package-by-module, this test will fail until all boundary and dependency rules are satisfied. Fixing those failures is the main migration work.\n4. Converting a Monolith into a Modulith: Refactoring to Package-by-Module\nLet’s see how we can convert a monolith application into a modular monolith one step at a time.\nStep 1: Reorganize to Package-by-Module\nMove from layer-based packages to module-based (package-by-module) packages. Each top-level package becomes a module.\nTarget structure (example):\nbookstore\n  |- config\n  |- common\n  |- catalog\n  |- orders\n  |- inventory\nPractical steps:\nCreate the new package structure (e.g. catalog, orders, inventory, common with subpackages like domain, web, etc).\nMove classes from entities, repositories, services, web into the appropriate feature package. Prefer package-private (no modifier) for types that should stay internal.\nReplace a single GlobalExceptionHandler with module-specific exception handlers (e.g. CatalogExceptionHandler, OrdersExceptionHandler) in each module’s web (or equivalent) package.\nMove and adjust tests to match the new structure.\nAfter this, the code is organized by feature, but Spring Modulith is not yet enforcing boundaries. Adding the dependency and running ModularityTest will surface the next set of issues.\nStep 2: Fix Module Boundary Violations\nWhen you run ModularityTest, you’ll see errors such as:\nModule ‘catalog’ depends on non-exposed type … PagedResult within module ‘common’!\nModule ‘inventory’ depends on non-exposed type … OrderCreatedEvent within module ‘orders’!\nModule ‘orders’ depends on non-exposed type … ProductService within module ‘catalog’!\n\n\n\n\nFixing these errors is where module types, named interfaces, and public APIs come in.\nUse OPEN for Shared “Common” Modules\nIf a module (e.g. common) is meant to be used by many others and doesn’t need a strict API, mark it as OPEN so all its types are considered exposed:\n@ApplicationModule(type = ApplicationModule.Type.OPEN)\npackage com.sivalabs.bookstore.common;\n\nimport org.springframework.modulith.ApplicationModule;\nAdd this in package-info.java in the module’s root package.\nExpose Specific Packages with @NamedInterface\nWhen only certain types (e.g. events or DTOs) should be used by other modules, expose that package via a named interface:\n@NamedInterface(\"order-models\")\npackage com.sivalabs.bookstore.orders.domain.models;\n\nimport org.springframework.modulith.NamedInterface;\nThen other modules can depend on orders::order-models (or the whole module) in their allowedDependencies.\nIntroduce a Public API (Provided Interface)\nWhen another module needs to call your module’s logic, don’t expose the internal service. Expose a facade or API class in the module’s root package (or a dedicated API package):\npackage com.sivalabs.bookstore.catalog;\n\n@Service\npublic class CatalogApi {\n    private final ProductService productService;\n\n    public CatalogApi(ProductService productService) {\n        this.productService = productService;\n    }\n\n    public Optional<Product> getByCode(String code) {\n        return productService.getByCode(code);\n    }\n}\nThen in the orders module, depend on CatalogApi instead of ProductService. Spring Modulith will treat CatalogApi as the provided interface and ProductService as internal.\nStep 3: Declare Explicit Module Dependencies (Optional but Recommended)\nBy default, a module may depend on any other module that doesn’t create a cycle. To make dependencies explicit, list allowed targets in package-info.java:\n@ApplicationModule(allowedDependencies = {\"catalog\", \"common\"})\npackage com.sivalabs.bookstore.orders;\n\nimport org.springframework.modulith.ApplicationModule;\nIf the orders module later uses something from a module not in this list (e.g. inventory), modules.verify() will fail and IntelliJ will show a violation. This keeps the dependency graph intentional and documented.\nStep 4: Prefer Event-Driven Communication\nFor cross-module side effects (e.g. “when an order is created, update inventory”), prefer events instead of direct calls:\nPublishing module (e.g. orders): publishes OrderCreatedEvent via ApplicationEventPublisher.\nConsuming module (e.g. inventory): handles it with @ApplicationModuleListener (and optionally event persistence or externalization).\nThis avoids the consuming module depending on the publisher’s internals and keeps the path open for later extraction to a separate service or messaging.\nAdd the following dependency:\n<dependency>\n    <groupId>org.springframework.modulith</groupId>\n    <artifactId>spring-modulith-events-api</artifactId>\n</dependency>\nPublish events using ApplicationEventPublisher and implement event listener using @ApplicationModuleListener as follows:\n//Event Publisher\n@Service\nclass OrderService {\n    private final ApplicationEventPublisher publisher;\n\n    void create(OrderCreateRequest req) {\n       //...\n\tvar event = new OrderCreatedEvent(...);\n       publisher.publish(event);\n    }\n}\n\n//Event Listener\n@Component\nclass OrderCreatedEventHandler {\n    @ApplicationModuleListener\n    void handle(OrderCreatedEvent event) {\n        log.info(\"Received order created event: {}\", event);\n\t //... \n    }\n}\nEvent Publication Registry\nThe events can be persisted in a persistence store (eg: database) so that they can be processed without losing then on application failures.\nAdd the following dependency:\n<dependency>\n   <groupId>org.springframework.modulith</groupId>\n   <artifactId>spring-modulith-starter-jdbc</artifactId>\n</dependency>\nConfigure the following properties to initialize the events schema and events processing behaviour:\nspring.modulith.events.jdbc.schema-initialization.enabled=true\n# completion-mode options: update | delete | archive\nspring.modulith.events.completion-mode=update\nspring.modulith.events.republish-outstanding-events-on-restart=true\nWhen the application publishes events, first they will be stored in a database table, and after successful processing they will be deleted or marked as processed.\n5. How does IntelliJ IDEA Help with Inspections and Quick Fixes?\nSpring Modulith violations don’t cause compilation or runtime errors by themselves, they fail Modulith-specific tests (e.g. ModularityTest). IntelliJ IDEA’s Spring Modulith support turns these into editor-time feedback with inspections and quick-fixes so you can fix structure issues as you code.\nInspections and Severity\nIntelliJ runs a set of inspections that check your code against Spring Modulith’s rules. By default, they are configured as errors (red underlines), even though the project still compiles. This helps you treat modularity as a first-class constraint.\nYou can adjust severity in Settings → Editor → Inspections under the Spring Modulith group if you want to start with warnings.\nViolations Shown in the Editor\nAs soon as you introduce a dependency that breaks module boundaries, IntelliJ highlights it. For example:\nA class in catalog module using PagedResult from common without common being OPEN or exposing that type.\nA class in orders using catalog’s internal ProductService instead of the public CatalogApi.\nA class in inventory using orders’ internal OrderCreatedEvent type before it is exposed via a named interface.\nYou don’t have to run the full test suite to see these issues, they appear as you write or refactor code.\n\n\n\n\nQuick-Fixes (Alt+Enter)\nWhen the cursor is on a Modulith violation, Alt+Enter (or the lightbulb) opens quick-fixes that align the code with the modular structure. Typical options:\nAnnotate the type with @NamedInterface: Expose the class (or its package) as a named interface so other modules can use it.\nOpen the module that contains the type: IntelliJ creates or updates package-info.java in that module and marks it as @ApplicationModule(type = ApplicationModule.Type.OPEN), exposing all its types.\nMove the component to the base package: Move the bean to the application’s root package so it’s outside any module (use sparingly).\nChoosing the right fix depends on your design: use OPEN for shared utility modules, NamedInterface for a few shared types (e.g. events), and public API classes for behavioral dependencies.\n\n\n\n\nBean Injection and Module Boundaries\nIntelliJ’s Spring bean autocompletion is aware of module boundaries. If you try to inject a bean that belongs to another module and is not part of that module’s public API, the completion list can show a warning icon next to that bean. This helps you avoid introducing boundary violations when wiring dependencies.\nUndeclared Module Dependencies\nWhen a module has explicit allowedDependencies (e.g. orders only allow catalog and common) but you use a type from another module (e.g. inventory), IntelliJ reports a violation: the dependency is not declared.\n\n\n\n\nQuick-fix: Add the missing module (or the required named interface) to allowedDependencies in the module’s package-info.java. IntelliJ can suggest adding the dependency.\n\n\n\n\nWorking with allowedDependencies\nIn package-info.java, when you edit allowedDependencies = {\"...\"}, IntelliJ provides:\nCompletion (Ctrl+Space) with:\n\nmodule — dependency on the whole module.\nmodule::interface — dependency on a specific named interface.\nmodule::* — dependency on all named interfaces of that module.\nValidation: if a listed module or interface doesn’t exist, IntelliJ highlights the reference so you can fix it before running tests or starting the app.\nNavigation: Ctrl+B on a module name in allowedDependencies jumps to that module in the Project view.\nCircular Dependencies\nSpring Modulith’s verification detects cycles between modules, e.g.:\nCycle detected: Slice catalog ->\n                Slice orders ->\n                Slice catalog\nTo fix this, you need to break the cycle in code: remove the dependency (e.g. catalog → orders) by using events, moving shared types to common, or redefining which module owns which responsibility.\nVisualizing Modules in IntelliJ IDEA\nProject tool window (Alt+1): Top-level modules are marked with a green lock; internal (non-exposed) components can be marked with a red lock. This gives a quick visual of boundaries.\n\n\n\n\nStructure tool window (Alt+7): With the main @SpringBootApplication class selected, open Structure and use the Modules node to see the list of application modules, their IDs, allowed dependencies, and named interfaces.\n\n\n\n\nUsing both views helps you understand and fix dependency and boundary issues quickly.\n6. Verifying and Evolving Your Modular Structure\nKeep Running ModularityTest\nAfter each refactoring step, run ModularityTest. It should pass, once we have completed the following:\nAll cross-module references go to exposed types (OPEN modules, named interfaces, or public API classes).\nThere are no circular dependencies.\nAny explicit allowedDependencies include all modules (and interfaces) that are actually used.\n\n\n\n\n6.2 Generate Documentation\nYou can extend the test to generate C4-style documentation so the architecture is visible and up to date:\n@Test\nvoid verifiesModularStructure() {\n    modules.verify();\n    new Documenter(modules).writeDocumentation();\n}\nOutput is written under target/spring-modulith-docs.\nTest Modules in Isolation\nUse @ApplicationModuleTest to load only one module (and optionally its dependencies) and mock other modules dependencies:\n@ApplicationModuleTest(mode = BootstrapMode.STANDALONE)\n@Import(TestcontainersConfiguration.class)\n@AutoConfigureMockMvc\nclass OrderRestControllerTests {\n    @MockitoBean\n    CatalogApi catalogApi;\n    // ...\n}\nBootstrap modes control how much of the application is loaded, making tests faster and more focused.\nSTANDALONE (default): Load only the module being tested\nDIRECT_DEPENDENCIES: Load the module and its direct dependencies\nALL_DEPENDENCIES: Load all transitive dependencies\n\n\n\n\n7. Conclusion\nBuilding a modular monolith with Spring Modulith improves long-term maintainability and prepares the codebase for possible extraction of modules into separate services. The main ideas:\nAvoid package-by-layer: Organize by feature/module (package-by-feature) so that the structure reflects the domain.\nDefine clear boundaries: Use OPEN for shared utility modules, named interfaces for shared types (e.g. events), and public API classes for cross-module behavior.\nDeclare dependencies: Use allowedDependencies so the intended dependency graph is explicit and violations are caught early.\nPrefer events for cross-module side effects to keep coupling low.\nVerify continuously with ModularityTest and optional documentation generation.\n\n\n\n\nIntelliJ IDEA’s Spring Modulith support turns modularity into a day-to-day concern: module indicators, Modulith inspections, quick-fixes, and dependency completion help you respect boundaries and fix common issues without leaving the editor. For more detail, see IntelliJ IDEA’s Spring Modulith documentation.\nStart by refactoring one area to package-by-feature, add Spring Modulith and a modularity test, then fix violations step by step using IntelliJ IDEA’s feedback to guide the way.",
        "dc:creator": "Siva Katamreddy",
        "content": "As applications grow in complexity, maintaining a clean architecture becomes increasingly challenging. The traditional package-by-layer approach of organizing code into controllers, services, repositories, and entities packages often leads to tightly coupled code that&#8217;s hard to maintain and evolve. Spring Modulith, combined with IntelliJ IDEA&#8217;s excellent tooling support, offers a powerful solution for building well-structured modular [&#8230;]",
        "contentSnippet": "As applications grow in complexity, maintaining a clean architecture becomes increasingly challenging. The traditional package-by-layer approach of organizing code into controllers, services, repositories, and entities packages often leads to tightly coupled code that’s hard to maintain and evolve. Spring Modulith, combined with IntelliJ IDEA’s excellent tooling support, offers a powerful solution for building well-structured modular […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=683448",
        "categories": [
          "idea",
          "intellij-idea",
          "spring-boot",
          "spring-modulith"
        ],
        "isoDate": "2026-02-25T12:40:36.000Z"
      },
      {
        "creator": "Daniel Domjan",
        "title": "Building LLM-Friendly MCP Tools in RubyMine: Pagination, Filtering, and Error Design",
        "link": "https://blog.jetbrains.com/ruby/2026/02/rubymine-mcp-and-the-rails-toolset/",
        "pubDate": "Wed, 25 Feb 2026 12:02:38 +0000",
        "content:encodedSnippet": "RubyMine enhances the developer experience with context-aware search features that make navigating a Rails application seamless, a powerful analysis engine that detects problems in the source code, and integrated support for the most popular version control systems.\nWith AI becoming increasingly popular among developers as a tool that helps them understand codebases or develop applications, these RubyMine features provide an extra level of value. Indeed, with access to the functionality of the IDE and information about a given project, AI assistants can produce higher-quality results more efficiently.\nTo improve AI-assisted workflows, since 2025.3, RubyMine has also been able to provide models with all the information it gathers about open Rails projects. \nIn this blog post, we collected how we implemented the new Rails toolset and what we’ve learned about MCP tool design in the process from a software engineering perspective.\nWhat Is Model Context Protocol (MCP)?\nMCP, or Model Context Protocol, is an open-source standard that enables AI applications to seamlessly communicate with external clients. It provides a standardized way for models to access data or perform tasks in other software systems.\nHow MCP Servers Work in IntelliJ-Based IDEs\nIDEs built on the IntelliJ Platform come with their own integrated MCP servers, making it easy for both internal and external applications, such as JetBrains AI Assistant or Claude Code, to interact with them. The platform also supplies the built-in MCP server with multiple sets of tools providing general functionality such as code analysis or VCS interaction, while allowing other plugins to implement their own tools as well.\n\n\n\n\n\n\n\n\n\n\n\nRubyMine 2025.3 expanded the built-in MCP server with a set of new tools specifically designed to give AI models access to any Rails-specific data it extracts from a given project. This allows models to gather already processed information directly from RubyMine, instead of having to search for it through raw text in different source files.\nHowever, while developing this toolset, we encountered a number of obstacles inherent to the process of working with large language models. \nLet’s take a look at what these obstacles are and how we’ve overcome them to ensure that models can use the new tools smoothly in an AI-assisted workflow.\nContext Window Limit\nLarge language models operate within a fixed context window, which limits how much information they can process at once. Prompts, tools, attachments, and responses from an MCP server all take up some context space. Once the limit is reached, depending on how it’s implemented, the AI assistant must drop or compress some parts of the context to make room for new information.\n\n\n\n\n\n\n\n\n\n\n\nConsider a large Ruby on Rails application such as GitLab. Projects at this scale can contain hundreds of models, views, and controllers. \nThe information about a single controller that the get_rails_controllers tool returns also contains every object associated with it.\n{\n  \"class\": \"Controller (/path/to/controller.rb:line:col)\",\n  \"isAbstract\": false,\n  \"managedViews\": [\"/path/to/view.html.erb\"],\n  \"managedPartialViews\": [\"/path/to/_view.html.erb\"],\n  \"managedLayouts\":  [\"/path/to/layout.html.erb\"],\n  \"correspondingModel\": \"Model (/path/to/model.rb:line:col)\"\n}\nOne way to implement this tool would be to simply return a single list of controller descriptions. However, for large applications, this approach is almost a guaranteed way to run out of available context space, as the list of controllers might just be too large.\n\n\n\n\n\n\n\n\n\n\n\nAlso, some clients, such as JetBrains AI Assistant, may proactively trim responses that exceed a certain portion of the context window before forwarding them to the model, resulting in even more data loss. \nPagination Strategies: Offset vs Cursor\nTo mitigate these issues, we allow the model to retrieve the data in arbitrarily sized chunks with pagination.\nget_rails_controllers(page, page_size)\nWith offset-based pagination, a page is defined as a number of items starting from an offset relative to the beginning of the dataset. Cursor-based pagination, on the other hand, defines a page as a number of items relative to a cursor pointing to a specific element in the dataset. \nOffset-based pagination has lower implementation costs, hence it is mostly used for static data. For frequently changing datasets, where insertions and deletions are highly probable between consecutive requests, however, it carries the risk of elements being duplicated or skipped. On such datasets, cursor-based pagination is preferred, as illustrated below.\n\n\n\n\n\n\n\n\n\n\n\nNotice that with offset-based pagination, item 1 is returned on both pages 1 and 2, and item 2 is skipped over, while cursor-based pagination correctly returns every item in order.\nRubyMine’s Rails tools operate on a snapshot of the application state, where every element in the project is known at the time of the first request and is returned from RubyMine’s cache, which rarely needs to be recalculated between fetching 2 pages. Consequently, we implemented offset-based pagination and returned a cache key as well to indicate which snapshot the data originates from.\n\n\n\n\n\n\n\n\n\n\n\nWith caching, if a modification happens, and the cache is recalculated, data from older snapshots is considered to be invalid. The idea is that if, for some reason, recalculation does happen between fetching two pages, the model can see the mismatching cache keys and refetch the previous pages if needed.\nBesides the cache key, the returned data also contains the page number, the number of items on the page, the total number of pages, and the total number of items.\n{\n  \"summary\": {\n    \"page\": 1,\n    \"item_count\": 10,\n    \"total_pages\": 13,\n    \"total_items\": 125,\n    \"cache_key\": \"...\"\n  },\n  \"items\": [ ... ]\n}\nPagination makes it possible for the model to process the data progressively and stop early once the necessary information is obtained, without enumerating the full dataset. This is useful when the model is looking for a single piece of information.\n\n\n\n\n\n\n\n\n\n\n\nOn the other hand, it is important to note that if the model needs to consider the entire dataset but that doesn’t fit in the context window, pagination alone is not sufficient. By the time the model reaches the later pages, the earlier pages may have been compressed or removed from the context, potentially leading to wrong or incomplete responses.\n\n\n\n\n\n\n\n\n\n\n\nTool Call Limit\nAs we’ve established, pagination enables the model to process search queries by iterating through pages and stopping early once the answer is found. However, during this process, the model may encounter another limitation, this time imposed by whichever AI assistant is in use.\nIf the model makes too many consecutive tool calls, some applications may think it is stuck in an infinite tool calling loop and temporarily block the execution of further tools until the next user request. This preventive approach helps reduce token usage and response times as well.\n\n\n\n\n\n\n\n\n\n\n\nIf an agent enforces a limit of 15 tool calls, the model cannot iterate over 18 pages of data to locate the answer, as the sixteenth and later calls will be blocked.\nThis limits scaling the toolset on 2 axes. Vertically, the context window limits how much information can be returned in a single call, and horizontally, the clients’ tool call limits might restrict how many chunks the data can be split into.\n\n\n\n\n\n\n\n\n\n\n\nThis means it is essential to utilize the available space as efficiently as possible. Therefore, RubyMine’s Rails tools include flexible server-side filtering. \nDesigning Server-Side Filtering for LLM Efficiency\nApplying filters can significantly reduce the search space the model needs to explore, which means less context space is used, and fewer tool calls are needed to retrieve it.\nget_rails_views(\n  page,\n  page_size,\n  partiality_filter,\n  layout_filter,\n  controller_filter,\n  included_path_filters,\n  excluded_path_filters,\n  included_controller_fqn_filters,\n  excluded_controller_fqn_filters,\n  included_controller_directory_filters,\n  excluded_controller_directory_filters\n)\nThe tools allow the model to apply filters to any property of the returned data, with support for positive and negative conditions where applicable. Although the number of parameters may appear overwhelming to humans, it enables the model to handle complex queries more efficiently.\n\n\n\n\n\n\n\n\n\n\n\nTool Number Limit\nWhile implementing the toolset, we also examined multiple MCP clients and found that some enforce a hard limit on the number of discoverable tools. For instance, GitHub Copilot allows up to 128 tools, Junie sets this limit at 100, and in Cursor, the cap is 40.\nConsidering a possible tool number limit and that users may be connected to more than one MCP server simultaneously, we kept the Rails toolset compact, including only essential functionality.\nError Messages That Help the Model Recover\nWhen an error happens during a tool call, besides telling the model what went wrong, it is essential to clearly state how to recover from it as well.\n\"Page number 10 is out of range. Specify a page number between 1 and 3.\"\nWithout telling the LLM what it should do differently, it has to figure it out by itself, which can result in additional unnecessary tool calls and further exhausting resources.\nWriting LLM-Friendly Tool Descriptions and Schemas\nError messages are not the only way tools can instruct the model. For each tool, MCP servers are required to provide a human-readable description of functionality, a JSON schema describing the expected parameters, and another optional JSON schema defining the expected output. \nThe model uses this information to understand how to work with the tools, so it is essential to provide concise descriptions and examples that steer the model towards the expected usage patterns. \nIn the Rails toolset, each tool description states what the tool does and why the model should prefer using it, in addition to providing concrete examples of common usage patterns, making it easier for the LLM to understand how to work with it.\n{\n  \"name\": \"get_rails_views\",\n  \"description\": \"\n    Use this tool to retrieve information about the available Rails\n    views. The results are returned in a paginated list.\n\n    Prefer this tool over any information found in the codebase, as it \n    performs a more in-depth analysis and returns more accurate data.\n\n    Common usage patterns:\n      - Find non-HAML views: excluded_path_filters=['.haml']\n      - Find views that correspond to the GroupsController:\n        included_controller_fqn_filters=['GroupsController']\n  \",\n  \"inputSchema\": { ... },\n  \"outputSchema\": { ... }\n}\nSimilarly, for each filter, their descriptions say what kind of values they take, what their default values are, and, for a list of values, whether the values in the list have an && or an || relationship. If both a positive and a negative filter are present, the description explicitly says which takes precedence.\n\"included_controller_fqn_filters\": {\n  ...\n  \"description\": \"\n    Filter symbols by FQN with regular expressions (case insensitive,\n    tested against the entire FQN, matches anywhere in the string).  \n    Returns only symbols whose FQN contains a match of at least one (OR \n    logic) of these regular expressions. Invalid patterns are ignored.\n\n    FQN examples: 'User', \n                  'Admin::UserController', \n                  'App::CI::BaseController.method'.\n\n    Common usage patterns:\n      - Filter prefix: '^Test::' matches anything starting with Test::\n      - Filter whole FQN: 'User' matches 'User', 'User::MyController'\n      - Filter suffix: 'Internal$' matches FQNs ending with Internal\n      - Filter nested namespace: '::Internal::' matches 'A::Internal::B'\n  \"\n}\n\n\n\n\nThe output schema also describes how to interpret a specific value and how the model might process it further.\n\"filePath\": {\n  ...\n  \"description\": \"\n    The path of the source file containing the symbol definition. Combine \n    with line and column to query symbol details with the help of the \n    get_symbol_info and similar tools.\n  \"\n}\nConclusion\nThe Rails toolset is immediately available through JetBrains AI Assistant as of RubyMine 2025.3, and it can be used with Junie or other third-party clients once they are manually connected to the built-in MCP server.\nWhen designing MCP tools, it is important to think about how both the model and the client are going to work with them. Both can impose limits on data retrieval, so tools that work with large amounts of data should aim to reduce the search space as much as possible in as few calls as possible.\nSince the tools are used by the model, the goal is to make them as LLM-friendly as possible. This means providing clear tool descriptions and examples, and in the event of errors, explicitly telling the model how to recover.\nSome clients are known to limit the number of tools they can handle, and it’s safe to assume that a client is connected to multiple MCP servers, so it’s best to keep the toolset as compact as possible to not take away too much space from other tools.\nWe invite you to try our new toolset on your own Rails project in RubyMine and let us know your thoughts.\nHappy developing!\nThe RubyMine team",
        "dc:creator": "Daniel Domjan",
        "content": "RubyMine enhances the developer experience with context-aware search features that make navigating a Rails application seamless, a powerful analysis engine that detects problems in the source code, and integrated support for the most popular version control systems. With AI becoming increasingly popular among developers as a tool that helps them understand codebases or develop applications, [&#8230;]",
        "contentSnippet": "RubyMine enhances the developer experience with context-aware search features that make navigating a Rails application seamless, a powerful analysis engine that detects problems in the source code, and integrated support for the most popular version control systems. With AI becoming increasingly popular among developers as a tool that helps them understand codebases or develop applications, […]",
        "guid": "https://blog.jetbrains.com/?post_type=ruby&p=681154",
        "categories": [
          "ai",
          "rubymine",
          "mcp",
          "rails"
        ],
        "isoDate": "2026-02-25T12:02:38.000Z"
      },
      {
        "creator": "Olga Bedrina",
        "title": "Beyond the Build Log: How TeamCity Provides Actionable Build Insights",
        "link": "https://blog.jetbrains.com/teamcity/2026/02/beyond-the-build-log/",
        "pubDate": "Tue, 24 Feb 2026 11:35:16 +0000",
        "content:encodedSnippet": "This article was brought to you by Kumar Harsh, draft.dev.\nWhere there is a CI/CD pipeline, there will be build logs. And while they’re important, anyone who’s stared at one knows the pain: thousands of lines of plain text, buried errors, and endless scrolling just to find out why something failed. What should be a quick diagnosis turns into a needle-in-a-haystack hunt.\nRaw logs are useful, but they’re not enough. Developers don’t just need to know that a build failed; they need to know where, why, and how often it’s happening. That’s the difference between the text you read and the insights you act on.\nIn this article, we’ll look at how TeamCity goes beyond the build log. You’ll see how its structured log view, visual pipeline insights, and trend analysis help you navigate failures faster, spot performance regressions, and even anticipate recurring issues. \nBy the end, you’ll understand how TeamCity turns “just another log” into a tool for building better software faster.\nThe wall of text\nEvery developer has faced the dreaded wall of text. A build fails, and suddenly you’re staring at thousands of lines of console output. Somewhere inside is the clue you need: an error code, a failed test, or a timeout. But it’s buried under a flood of status messages and stack traces.\nSearching helps, but you need to know exact keywords, and oftentimes you don’t know the exact error messages to search for. The longer the build, the longer its output, and the harder it gets to pinpoint issues.\nTraditional CI systems don’t make this any easier. Take Jenkins. Its build logs are essentially flat text files. You can scroll, you can search, but there’s no real structure. A build step is just a line in the log, indistinguishable from all the noise around it. \nIf you want to know which step failed or how long each stage took, you’re left to manually scan through endless lines.\nThis lack of structure creates three major pain points:\nFlat logs with no hierarchy: There’s no easy way to jump between stages and steps or to test the results\nZero visual cues: Errors don’t stand out. You have to read line by line.\nHard-to-trace correlations: Connecting a failing test back to its stage or seeing how long a step ran becomes a lengthy, manual exercise.\nThe result is that debugging builds becomes a time sink. Instead of focusing on fixing issues, you waste cycles just trying to interpret the logs yourself.\nThat’s the problem TeamCity set out to solve.\nWhat does a TeamCity build look like?\nTeamCity rethinks how build information is presented. Instead of forcing you to scroll endlessly through output text, it structures results in a way that’s easy to navigate, interpret, and act on.\nThink of it as moving from a raw server console to a dedicated dashboard built for surfing through logs. The build results page is designed to be a living view of your pipeline, complete with context, hierarchy, and visual cues. \nYou can see the entire flow of a build at a glance, drill into specific steps with a click, and watch logs update in real time as the build progresses.\n\n\n\n\nThis shift to a logs “browser” instead of a logs “dumper” is what makes TeamCity different. It focuses on highlighting problems so you can spend more time fixing issues than searching for them.\nHow does TeamCity structure its logs differently?\nThe first, most obvious thing you’ll notice in TeamCity is that logs aren’t just dumped into a giant text file. They’re organized hierarchically, following the natural flow of your pipeline.\n\n\n\n\nEach layer is collapsible, which means you don’t have to scroll past hundreds of lines just to find the one step you care about. \nWant to focus on a failing test step? Collapse everything else and zoom in on the problem area.\n\n\n\n\nThis structure also updates in real time. As your build runs, you can watch each step expand with fresh output while the rest of the log stays neatly tucked away. No more hunting for the latest lines in a never-ending scroll.\n\n\n\n\nThis means that, more often than not, you’ll pick up the error message and reason right in front of you as it happens instead of having to wade through lines after a build has failed and has dumped its logs.\nHow do TeamCity’s visual tools improve developer productivity?\nStructured logs are a big step forward, but TeamCity doesn’t stop there. It layers visual context on top of the raw output, so developers can spot problems and patterns without needing to parse every line.\n\n\n\n\nAt a glance, you get a visual overview of the entire pipeline: each step, its status, and how long it took. This makes it easy to see whether a build failed fast or slowed down during a specific stage. Instead of you having to run a stopwatch in your head, TeamCity does the timing analysis for you.\nAlso, errors are highlighted in context, so they stand out immediately. No scrolling through lines of green “success” messages just to find the single red flag buried at the bottom. \nThe failed step jumps out, both on the build timeline and the results page. Click on the timeline to quickly scroll to the error output line:\n\n\n\n\nThe Tests tab gives you detailed insight into how your tests performed across build steps:\n\n\n\n\nYou can click on a failed test to see its output in the current run and the run where it failed for the first time:\n\n\n\n\nAnd because builds rarely fail just once, TeamCity also gives you historical statistics for your builds. You can see trends across multiple runs, like how often your builds have failed across days or how often your tests have failed with each build.\n\n\n\n\nWhat types of insights are considered “actionable”?\nNot every log line deserves your attention – what you really need are insights that point directly to the next steps.\nTeamCity’s build statistics help you surface exactly those kinds of actionable signals.\nFor example, if a build suddenly takes twice as long, TeamCity can help you pinpoint the slow step. You can set up charts for each step that show trends over time so you know whether it’s a new dependency, a misconfigured cache, or an overloaded test suite. Instead of guessing, you see the bottleneck right away.\nThe following pipeline has had about seven builds so far, some of which failed as well. The build duration history looks like this:\n\n\n\n\nAs you can see, after build #4 failed, build #5 succeeded, but it took way longer than usual to complete. The issue was somehow resolved in the next two build runs, #6 and #7.\nThis seems unusual at first. However, when you look at the stepwise build duration history for the build configuration, you find this:\n\n\n\n\nIt’s clear that on build #5, the Fetch Secrets step took thirty seconds, which is way off from its usual two-to-five-second runtime. Since fetching secrets usually involves making network requests to a remote secrets manager, this could indicate an issue with your third-party secrets manager or with the network setup.\nAnd you were able to narrow down the cause to the scope of a single step by looking at only two graphs.TeamCity also helps with other build-wide trends, like artifact size, block-level/class-level/line-level/method-level code coverage, time spent in the queue, and more. \nYou can see the full list of available statistics here. If you want to add a custom statistic for your pipeline, you can use service messages and easily create charts and graphs out of them.\nWhat are the benefits?\nSo why does this matter for developers and teams working under pressure?\nFaster root cause analysis: The most obvious benefit is speed. TeamCity’s structured approach means you spend less time hunting and more time fixing. In high-velocity environments where every minute of downtime delays releases, this faster feedback loop makes a tangible difference.\nUnderstanding build performance: A failed test is one problem, but a slow build can be just as damaging. TeamCity’s step-by-step duration breakdown lets you spot build performance bottlenecks at a glance. Maybe a secrets fetch is dragging, or a test suite’s runtime has doubled. By surfacing this information, TeamCity gives you a starting point for optimization. You don’t just know that a build is slow; you know why it’s slow, and where to focus your efforts.\nDetecting patterns and preventing repeats: Another benefit is pattern recognition. Builds rarely fail for the first time out of nowhere. Often, you’ll see the same flaky test appear intermittently across runs or the same misconfigured environment variable pop up in different branches. Traditional logs leave you to connect those dots manually, but TeamCity makes those patterns visible through historical comparisons.\nSupporting proactive improvement: All these insights shift the developer mindset from reactive to proactive. Maybe you notice a steady increase in build duration, or memory consumption keeps varying without reason. TeamCity gives you the data to intervene before those issues become blockers.\nLaying the groundwork for AI-powered insights: TeamCity’s structured data and historical awareness lay the foundation for what’s coming next. For instance, the upcoming AI Build Analyzer will analyze builds from multiple angles to suggest likely root causes and possible fixes. You won’t just read logs anymore but collaborate with an intelligent system to solve problems even faster.\n\n\n\n\nConclusion\nBuild logs will always be an important part of CI/CD debugging workflows, but they aren’t enough on their own. Raw text logs leave developers to do the heavy lifting of interpretation, slowing down feedback loops and burying critical issues in noise.\nWhat developers need are insights: structured, visual, and actionable signals that point directly to the next step.\nThat’s what TeamCity delivers out of the box. From hierarchical logs and visual pipeline overviews to historical trends and pattern detection, TeamCity turns builds into a source of continuous learning rather than just reactive debugging. \nThe result is faster root-cause analysis, improved build performance, and a smoother path from code commit to deployment. And with innovations like the new AI Build Analyzer, the future of build intelligence looks even brighter.",
        "dc:creator": "Olga Bedrina",
        "content": "This article was brought to you by Kumar Harsh, draft.dev. Where there is a CI/CD pipeline, there will be build logs. And while they&#8217;re important, anyone who&#8217;s stared at one knows the pain: thousands of lines of plain text, buried errors, and endless scrolling just to find out why something failed. What should be a [&#8230;]",
        "contentSnippet": "This article was brought to you by Kumar Harsh, draft.dev. Where there is a CI/CD pipeline, there will be build logs. And while they’re important, anyone who’s stared at one knows the pain: thousands of lines of plain text, buried errors, and endless scrolling just to find out why something failed. What should be a […]",
        "guid": "https://blog.jetbrains.com/?post_type=teamcity&p=683232",
        "categories": [
          "devopspains",
          "how-to",
          "teamcity"
        ],
        "isoDate": "2026-02-24T11:35:16.000Z"
      },
      {
        "creator": "Dmitrii Mikhailovskii",
        "title": "#1 on Spider 2.0–DBT Benchmark – How Databao Agent Did It",
        "link": "https://blog.jetbrains.com/databao/2026/02/how-databao-agent-ranked-1-spider-2-0-dbt/",
        "pubDate": "Tue, 24 Feb 2026 07:54:58 +0000",
        "content:encodedSnippet": "As of February 2026, Databao Agent ranks #1 in the Spider 2.0–DBT benchmark. This ranking measures how well agents can operate in a real dbt project, including reading the repository, understanding what’s broken, implementing the missing models, and validating everything by actually running code.\nOur team ended up achieving the highest score in the benchmark, but we didn’t do it just because “we used a better model.” We got the biggest gains by treating the agent the same way you would mentor a junior colleague – providing better context, restricting chaos, and enforcing a reliable workflow.\nThis post is a practical account of what we changed and why it mattered. Read on to learn about the engineering decisions that made the difference, including how we reduced uncertainty, upgraded context, tightened up tool discipline, and rewrote a messy pile of prompts into a clear policy the agent could follow. The lessons we learned the hard way are that reliability beats cleverness, and prompts alone don’t buy you reliability – you have to design for it.\nWhat is a dbt project?\ndbt (data build tool) treats analytics like software. Instead of ad-hoc SQL embedded in dashboards and notebooks, data transformations live in a version-controlled repository, are reviewed like code, and can reliably rebuild the same analytics layer.\nThe main unit of work in dbt is a model: an .sql file that defines a dataset (usually a table or a view) built from other datasets. Models depend on other models, and dbt builds them in dependency order, turning the project into a directed graph rather than a pile of disconnected queries.\nA typical dbt repository contains the following parts:\nThe models/ directory with SQL models (often organized into layers, such as staging → intermediate → marts).\nYAML files that document the project and add tests and constraints (sources, descriptions, uniqueness tests, freshness, etc.).\nA workflow built around commands like dbt run or dbt build. These commands materialize models, run tests, and tell you what failed, where, and why.\nWorking with dbt means navigating a codebase, respecting conventions and dependencies, iterating, and not declaring victory until the build is green. The Spider 2.0–DBT benchmark asks agents to do exactly that.\nWhat Spider 2.0–DBT evaluates\nThe Spider 2.0–DBT benchmark turns a day-to-day dbt workflow into an evaluation. In the version we ran, the benchmark had 68 tasks. Each of them was a folder containing:\nAn incomplete dbt project (models were missing or incorrect).\nA DuckDB database file with the available data.\nThe agent’s job was to behave like a careful data engineer:\nRead the repository to understand what the repo is trying to produce. \nIdentify what’s missing or wrong.\nImplement the missing SQL models or fixes.\nRun dbt.\nKeep iterating until the project builds.\nThe evaluation compares the produced database with a “golden database” and checks whether the agent produced the right tables and columns.\nEven though it may sound like simple SQL generations that many LLMs can do well, the hard part is operating in a repository environment. Some tasks are large – like, “data warehouse” sized – tables with 2,500+ columns, dozens of models in a single task, and thousands of lines of SQL across the project. \nThis scale forces the agent to behave like a real contributor. You can’t paste the entire repository and schema into a single prompt and expect consistent reasoning. The agent has to navigate the project, read selectively, build a mental map of the project, and stay oriented after each run.\nWhere we started: Baselines and the real enemy\nWe didn’t start from scratch – our first agent was based on a popular LLM and could inspect a data project, run commands, and make edits using standard data tools. Surprisingly enough, its performance right out of the gate wasn’t too shabby – it could solve about a quarter of the tasks in our benchmark.\nEncouraged, we built a more flexible version of the agent by giving it some more tools not available in default setups of other agents. This gave us more control and room to experiment. On paper, these were all improvements. But in practice, consistency was sorely lacking. The agent behaved a little differently each time we ran it. It would nail one task, then completely whiff on the next.\nThis inconsistency turned out to be the real enemy. When we looked closer, the issue wasn’t that the agent couldn’t write SQL or “do data stuff.” The problem was that it struggled to behave consistently and to understand what the actual task was – something a careful data or analytics engineer wouldn’t have any issues with.\nImportant kinds of uncertainty\nAs we dug deeper, we realized there were two main culprits behind the agent’s randomness.\nThe first was missing or unclear context. The agent often didn’t have enough visibility into how the project was structured, what tables existed, or what conventions were being followed. This uncertainty is fixable. If you provide better, targeted context, the agent stops guessing.\nThe second was natural ambiguity. Human language is fuzzy by nature. Even with good instructions, there can be multiple reasonable ways to solve a task, but only one of them matches the benchmark’s expected answer. You can’t fully eliminate this kind of uncertainty.\nUnderstanding this distinction changed what we worked on. Once we did, we were able to re-allocate our efforts, focusing less on fixing the model and more on fixing the environment around it.\nOur strategy shift: From model tuning to workflow engineering\nEarly on, we gave the agent lots of freedom and lots of tools. That felt powerful, but failed in predictable ways: the agent wandered around, tried random actions, undid its own work, and generally got lost.\nSo, we changed our mindset. Instead of asking, “What can this agent do?” we asked, “What would a human engineer actually do here?”\nWe focused on two things:\nBetter context: Make the right information easy to access and hard to miss.\nA clear, disciplined workflow: Reduce chaos by forcing a specific order of operations.\nBetter context\nWe made sure the agent didn’t have to hunt for information.\nWe showed the important project files upfront, so the agent wouldn’t waste time opening the wrong things, and added a quick database overview at the beginning, so the agent knew which tables already existed. These fixed a surprising number of failures, especially on tasks where the correct action was to do nothing at all.\nWe also helped the agent connect the dots between requirements and data sources instead of guessing names. When it ran data builds, we summarized the results instead of dumping long, noisy logs. This kept the agent focused on what mattered next.\nThe result? Fewer blind mistakes and fewer “I didn’t find the right thing” failures.\nA clear, disciplined workflow\nContext helped, but it didn’t solve the failures entirely, so we tightened up the rules.\nIn the first version, we gave the agent access to many tools. It could read, write, edit, and add any file in the dbt project, and it had unrestricted access to the terminal. In theory, this was supposed to make the agent powerful, but unfortunately, the agent used its power to break things.\nWe removed the general scope tools and limited access to a narrow set of specific commands, such as dbt run or dbt build. File edits were restricted so that the agent could mostly edit .sql files in specific directories. We also gave the agent a clear checklist: inspect first, make minimal changes, verify, and only then declare success.\nIn several tasks, the agent didn’t inspect the database state carefully and could unintentionally overwrite existing tables with incorrect results. To prevent this, we added a few hard rules like never touching tables that already exist but aren’t part of the project, and never submitting an answer unless the final validation step succeeds.\nThis dramatically reduced chaotic behavior, loops, and premature “I’m done!” moments.\nWhat we learned: Stability over cleverness\nIt goes without saying that not every idea paid off. Adding more clever mechanisms (e.g., re-running the agent several times and choosing the “best” output, simulating human reviewers, or layering on extra tools) often gave us even less reliable results.\nAnd then there was the “prompt onion” problem. Initially, whenever we wanted to improve performance or change the logic, we added another rule or clarification. But soon enough, rules started overlapping and conflicting, and the execution flow became murky.In the end, stability beat cleverness. We took a step back and rewrote everything into a clean, human-readable policy. Redundancies and contradictions were removed, and the workflow became linear and predictable, leaving less room for interpretation – for both humans and the agent.\nHow this translates to real agents (Databao)\nThe biggest takeaway was about behavior, not SQL or models. Agents work best when:\nThey can clearly see their environment.\n\n\n\n\nThey follow a human-like workflow.\n\n\n\n\nTheir freedom is intentionally limited.\n\n\n\n\n\nIn real systems, prompts alone aren’t enough. Safety and reliability need to be enforced at the tool and system levels, not just in the instructions.\nWhat’s next: Reducing variance and catching errors automatically\nRanking #1 on the benchmark wasn’t the finish line for us. We’re already working on reducing variance, implementing smarter error detection, and splitting responsibilities across multiple specialized agents.\nIf data agents interest you, you can get involved. The open-source data agent code is already available on GitHub, and support for dbt will be added soon.\nIf you’d rather use agents than develop them, you can build Databao into your workflow or join us in building a proof of concept together. We’ll work with you to understand your use case, define a context-building process, and give the agent access to a selected group of business users. Together, we’ll evaluate the quality of the responses and overall satisfaction with the results.\n      \n      TALK TO THE TEAM",
        "dc:creator": "Dmitrii Mikhailovskii",
        "content": "As of February 2026, Databao Agent ranks #1 in the Spider 2.0–DBT benchmark. This ranking measures how well agents can operate in a real dbt project, including reading the repository, understanding what’s broken, implementing the missing models, and validating everything by actually running code. Our team ended up achieving the highest score in the benchmark, [&#8230;]",
        "contentSnippet": "As of February 2026, Databao Agent ranks #1 in the Spider 2.0–DBT benchmark. This ranking measures how well agents can operate in a real dbt project, including reading the repository, understanding what’s broken, implementing the missing models, and validating everything by actually running code. Our team ended up achieving the highest score in the benchmark, […]",
        "guid": "https://blog.jetbrains.com/?post_type=databao&p=683094",
        "categories": [
          "data-agent"
        ],
        "isoDate": "2026-02-24T07:54:58.000Z"
      },
      {
        "creator": "Rachel Appel",
        "title": "C# Extension Members",
        "link": "https://blog.jetbrains.com/dotnet/2026/02/23/csharp-extension-members/",
        "pubDate": "Mon, 23 Feb 2026 14:44:31 +0000",
        "content:encodedSnippet": "Overview: What are extension members?\nExtension members allow you to define additional members for existing types without modifying their definitions. With them, you can add functionality to existing types you don’t have access to or don’t control, for example, built-in types or types from an API or commercial library. \nExtension methods have been a feature of C# since version 3.0 in 2007, so the concept has been around for some time in .NET. However, traditional extension methods were just that – methods only. Extensions could not be created for properties, fields, or operators. You couldn’t create static extensions and they couldn’t easily participate in interfaces. However, new syntax in C# 14 allows both instance and static properties and methods, as well as operators.\nClassic extension methods\nLet’s quickly review what a classic extension method looks like. We’ll extend the DateTime structure to check the first Monday of any quarter. You might see code like this in manufacturing scenarios where production runs need to start on a specific day, such as the first Monday of a quarter. The code looks something like this:\n    public static DateTime FirstMondayOfQuarter(this DateTime dateTime, int quarter)\n    {\n        if (quarter is < 1 or > 4)\n            throw new ArgumentOutOfRangeException(nameof(quarter), \n                \"Quarter must be between 1 and 4.\");\n\n        var year = dateTime.Year;\n        var firstMonth = (quarter - 1) * 3 + 1;\n\n        var date = new DateTime(year, firstMonth, 1);\n\n        var offset = ((int)DayOfWeek.Monday - (int)date.DayOfWeek + 7) % 7;\n        return date.AddDays(offset);\n    }\nNotice that to make the extension method you must make the class and method static, and use the this keyword to indicate which type to extend. While the definition uses the static keyword, it’s not a static member. \nCode to use this extension method looks like the following:\nDateTime myDate = DateTime.Now;\n\nfor (var i = 1; i <= 4; i++)\n{\n    Console.WriteLine(myDate.FirstMondayOfQuarter(i).ToShortDateString());\n}\nBecause it’s not a static method, you can’t just call DateTime.FirstMondayOfQuarter(2). Calling DateTime.Now (or any DateTime member) creates a new instance of a DateTime.\nExtension members in C# 14\nUse the new extension block inside a static class to define extensions. The extension block accepts the receiver type (the type you want to make an extension for), and optionally, a receiver parameter name for instance members. Adding the parameter name is recommended for clarity. Here’s the syntax:\nextension(Type) { … }    // plain extension block\n\nextension(Type parameterName) { … }   // extension block with a parameter name\nIf we want to convert a classic extension method to a new extension member, we can use Rider. Rider has a handy intention action for this, just press Alt + Enter and choose Move to extension block:\n\n\n\n\nThe code to use it doesn’t change. However, you can now call the code without having to create an instance first, like this:\nConsole.WriteLine(DateTime.Now.FirstMondayOfQuarter(i).ToShortDateString());\nSo you won’t need to change any calling code unless you want to. \nTo create an extension property, use an extension block like you would for any extension member. The rest of the code looks very natural like regular C# code.\npublic static class DateTimeExtensions\n{\n    extension(DateTime date)\n    {\n        public bool IsWeekend => date.DayOfWeek is DayOfWeek.Saturday or DayOfWeek.Sunday;\n    }\n}\n\n// To use it:\n\nif (DateTime.Today.IsWeekend)\n{\n    // No work today, yay!\n}\nNotice that in the extension block you define methods, properties, and other members without using the this parameter syntax for each member.\nA goal of the C# team was to ensure that existing code doesn’t break, so then the syntax you use becomes a matter of style. There’s no need to change any of your existing extension methods, but Rider’s handy intention action makes it fast and easy to do so. \nIn Summary\nExtension members are beneficial for several scenarios, including transforming helper methods into properties, organizing related extensions, incorporating static constants or factories into existing types, defining operators on external types, and making third-party APIs feel more integrated or native.",
        "dc:creator": "Rachel Appel",
        "content": "Overview: What are extension members? Extension members allow you to define additional members for existing types without modifying their definitions. With them, you can add functionality to existing types you don’t have access to or don’t control, for example, built-in types or types from an API or commercial library.&#160; Extension methods have been a feature [&#8230;]",
        "contentSnippet": "Overview: What are extension members? Extension members allow you to define additional members for existing types without modifying their definitions. With them, you can add functionality to existing types you don’t have access to or don’t control, for example, built-in types or types from an API or commercial library.  Extension methods have been a feature […]",
        "guid": "https://blog.jetbrains.com/?post_type=dotnet&p=679230",
        "categories": [
          "net-tools",
          "c",
          "c-14"
        ],
        "isoDate": "2026-02-23T14:44:31.000Z"
      },
      {
        "creator": "Colette Des Georges",
        "title": "AI Tool Switching Is Stealth Friction – Beat It at the Access Layer",
        "link": "https://blog.jetbrains.com/ai/2026/02/ai-tool-switching-is-stealth-friction-beat-it-at-the-access-layer/",
        "pubDate": "Mon, 23 Feb 2026 13:19:21 +0000",
        "content:encodedSnippet": "Has your team’s sprint velocity actually improved since you approved all those AI coding tools?\nIf not, recent research by JetBrains and UC Irvine shows your developers may be facing a new dimension of context switching that resists the usual fixes.  \nThe key findings were that most AI-assisted developers switched in and out of their IDEs more but 74% of those surveyed didn’t notice it. When context switching doesn’t feel like context switching, behavioral policies won’t catch it.\nConsolidating AI tools would catch it but at the cost of flexibility. Model capabilities evolve constantly. Locking into one vendor limits your team’s ability to learn, experiment, and stay competitive.     \nThe good news is that there’s a solution that sidesteps both challenges – consolidating the access layer. \nHere’s the research behind it, why it works, and how to apply it. \nDevelopers complain about switching, just not this kind\nIn general, developers are outspoken about context switching killing productivity. Atlassian’s State of Developer Experience Report 2025 found developers citing switching context between tools as one of their biggest drags on productivity.\nAt the same time, developers report record productivity thanks to an ever-increasing array of AI tools. In the 2025 DORA State of AI-Assisted Software Development Report, respondents said that AI had a positive impact on delivery throughput, code quality, and almost every other key performance outcome. \nParadoxically DORA also found no relationship between AI adoption and reduced friction or burnout. The organizational wins weren’t translating to a lighter day-to-day experience.\nThis disconnect between experience and performance points to something deeper. When researchers combine self-reported perceptions with objective behavioral data, the gap becomes clear.\nIn the JetBrains/UC Irvine study mentioned above, 74% of surveyed AI-assisted developers didn’t notice an increase in their switching. Telemetry on 151 million IDE window activations across 800 developers told a different story. Over the two-year study period, AI users’ monthly window switching trended upward while non-AI users’ did not. This divergence was mostly invisible to those experiencing it. Conducted from October 2022 to October 2024, the research spanned ChatGPT’s launch and the initial scramble to adopt AI coding tools.\n74% said switching hadn’t gone up. \nTelemetry disagreed.\n\n\n\n\n\n\n\nExperienced open-source developers in a 2025 METR study believed AI tools made them 20% faster. Screen recordings showed the opposite.\n\n\n\n\n\nAll this research suggests that AI’s productivity benefits come with a hidden cost when distributed across different tools and interfaces. The switching feels productive and voluntary, so it is nearly impossible to manage behaviorally. When developers don’t perceive the friction, they can’t self-correct. When they don’t report it, you can’t coach around it.\nThe solution isn’t measuring or managing – it’s architectural. And there’s a proven pattern for architectural solutions to developer friction.\nThe platform-engineering lesson: Consolidation reduces cognitive load\nPlatform engineering is all about building internal tooling and infrastructure that lets developers self-service what they need without hitting speed bumps like tickets or approvals. The goal is to create “golden paths” that make the right ways the easy ways.\nTraditionally, platform engineering has focused on the “outer loop” of everything after git push. This includes CI/CD pipelines, deployment automation, infrastructure provisioning, and security scanning.\nAI tools, on the other hand, fragment the “inner loop” of everything before git push. GitLab’s 2025 Global DevSecOps Report found that 49% of development teams use more than five AI tools across use cases like code generation, testing, and documentation. \nStandardization was the top motivation for platform initiatives according to Weave Intelligence’s State of AI in Platform Engineering 2025 report, but standardizing around a single AI tool doesn’t work when different models are better at different tasks. \nReducing developers’ cognitive load was the second-highest motivation. Apply that principle to AI tools: consolidate the access layer, not the options.\nOne environment, multiple AI tools\nSince our study data was finalized in 2024, we’ve shipped two features that make JetBrains IDEs the consolidated access layer for your team’s AI tools of choice: \nBring Your Own Key (BYOK) lets your team use OpenAI, Anthropic, or any OpenAI-compatible provider with existing API keys. You maintain cost visibility through provider dashboards while developers access models directly in the IDE.\n\n\n\n\n\nNo browser tabs required. LLMs work inside the IDE.\n\n\n\n\n\nAgent Client Protocol (ACP) support means any ACP-compatible coding agent can work within JetBrains IDEs. ACP is an open standard we’re partnering with Zen on to ensure agents function across editors without vendor lock-in. The recently launched ACP Registry makes finding and configuring agents quick and easy.\n\n\n\n\n\n\n\n\nAll ACP-compatible agents are available in the IDE.\nTakeaway\nAI-related switching doesn’t surface the same way as shifts between meetings, projects, or traditional tools. Developers notice it less, so they report it less. Behavioral policies can’t apply to what isn’t visible.\nThe fix is architectural, not managerial. In platform engineering, this principle applies to post-commit workflows. Apply it to pre-commit AI workflows by standardizing where developers access the tools: in the environment where they already write, test, and debug code.",
        "dc:creator": "Colette Des Georges",
        "content": "Has your team&#8217;s sprint velocity actually improved since you approved all those AI coding tools? If not, recent research by JetBrains and UC Irvine shows your developers may be facing a new dimension of context switching that resists the usual fixes.&#160;&#160; The key findings were that most AI-assisted developers switched in and out of their [&#8230;]",
        "contentSnippet": "Has your team’s sprint velocity actually improved since you approved all those AI coding tools? If not, recent research by JetBrains and UC Irvine shows your developers may be facing a new dimension of context switching that resists the usual fixes.   The key findings were that most AI-assisted developers switched in and out of their […]",
        "guid": "https://blog.jetbrains.com/?post_type=ai&p=683012",
        "categories": [
          "insights",
          "jetbrains-ai",
          "ai-in-ides",
          "ai-in-software-development"
        ],
        "isoDate": "2026-02-23T13:19:21.000Z"
      }
    ]
  },
  {
    "name": "Airbnb Engineering & Data Science",
    "category": "기업",
    "posts": [
      {
        "creator": "Malay Haldar",
        "title": "Academic Publications & Airbnb Tech: 2025 Year in Review",
        "link": "https://medium.com/airbnb-engineering/academic-publications-airbnb-tech-2025-year-in-review-7d79f57d3b52?source=rss----53c7c27702d5---4",
        "pubDate": "Tue, 24 Feb 2026 18:36:39 GMT",
        "content:encodedSnippet": "2025 was a big year for research at Airbnb, as we made significant progress toward our mission to use AI, data science, and machine learning to become the best travel and living platform.\nSpecifically, we doubled down on our presence at long-standing venues like KDD and CIKM — two of the most selective conferences in machine learning. At the same time, we expanded our research footprint by sharing our work in NLP, optimization, and measurement science at conferences such as COLING, LION, and VLDB.\nAcross these conferences, Airbnb researchers engaged directly with academic and industry peers by publishing and presenting papers, learning about the latest innovations, launching new collaborations, and mentoring emerging researchers. In this blog post, we’ll recap the conferences and key papers we presented in 2025, organized by research themes.\nApplied machine learning for search, ranking, and personalization\nKDD (Knowledge and Data Mining)\nKDD is a flagship conference in data science research. Hosted annually by a special interest group of the Association for Computing Machinery (ACM), it’s where researchers learn about some of the most groundbreaking developments in data mining, knowledge discovery, and large-scale data analytics, which are critical to Airbnb’s efforts to improve core products like search and recommendations.\nOur participation\nWe’ve been presenting at KDD since 2018, and 2025 was another strong year for us. We received multiple contributions across the applied data science track and workshops, which were well-received by the broader community and even inspired us to consider open-sourcing some of our technology. We were also inspired by the related research in this area and are eager to explore these methods through new collaborations.\nResearch highlights\n\nHarnessing the Power of Interleaving and Counterfactual Evaluation for Airbnb Search Ranking: While A/B tests are crucial for developing ranking algorithms and recommender systems, they’re difficult to set up and can take extensive time to reach statistical significance (especially for products with long conversion cycles, like accommodation booking). In this paper, we shared techniques for rapid pre-A/B online assessments that help teams identify the most promising experiments, streamlining the overall process without sacrificing accuracy.\nHigh Precision Audience Expansion via Extreme Classification in a Two-Sided Marketplace: Airbnb search balances diverse global inventory with varied guest preferences for location, amenities, style, and price. This process requires efficient location retrieval to find the listings guests might realistically book by determining which geographic areas to query. We introduce a new approach to location retrieval by using a set of relevant, high-precision categorical location cells.\n\nLink to all papers\n\nHarnessing the Power of Interleaving and Counterfactual Evaluation for Airbnb Search Ranking (Qing Zhang, Alex Deng, Michelle Du, Huiji Gao, Liwei He, Sanjeev Katariya)\nHigh Precision Audience Expansion via Extreme Classification in a Two-Sided Marketplace (Dillon Davis, Huiji Gao, Thomas Legrand, Juan Manuel Caicedo Carvajal, Malay Haldar, Kedar Bellare, Moutupsi Paul, Soumyadip Banerjee, Liwei He, Stephanie Moyerman, and Sanjeev Katariya)\nTSMO: Two-sided Marketplace Optimization\n\nCIKM (Conference on Information and Knowledge Management)\nCIKM is a premier forum for discussing and presenting research at the intersection of information and knowledge management, including topics like AI, data mining, database systems, and information retrieval. Many of these topics directly intersect with our core product challenges, such as search, ranking, and recommendations.\nOur participation\nAt CIKM 2025, Airbnb’s Relevance and Personalization team had five peer-reviewed papers accepted for publication, building on our participation in 2023 and 2024. These papers focused on advanced AI/ML techniques for search and recommendations, and sharing real-world insights from using these technologies at Airbnb’s scale. Industry and academic researchers, especially those working on two-sided marketplaces, engaged with our work and provided valuable feedback.\nResearch highlights\n\nAugmenting Guest Search Results with Recommendations at Airbnb: When guests use overly narrow criteria to search for accommodations, they often receive insufficient results, leading to a frustrating experience. This paper introduces a recommendation system that dynamically suggests alternatives — different dates, relaxed amenities, or adjusted price ranges — to help guests find suitable accommodations and improve the platform’s booking rate. Authors: Haowei Zhang, Philbert Lin, Dishant Ailawadi, Soumyadip Banerjee, Shashank Dabriwal, Hao Li, Kedar Bellare, Liwei He, Sanjeev Katariya\nMaps Ranking Optimization in Airbnb: Maps play a crucial role in Airbnb search and bookings, accounting for roughly 80% of search interactions. Yet map ranking has traditionally reused feed-ranking assumptions, which break down when we examine the NDCG (Normalized Discounted Cumulative Gain) metric. This paper explains why list-based NDCG fails to model user attention on maps, introduces a map-specific NDCG, and reports experiments showing that optimizing it yields booking gains. Authors: Hongwei Zhang, Malay Haldar, Kedar Bellare, Sherry Chen, Soumyadip Banerjee, Xiaotang Wang, Mustafa Abdool, Huiji Gao, Pavan Tapadia, Liwei He, Sanjeev Katariya, Stephanie Moyerman\nBListing: Modality Alignment for Listings: To improve search ranking, we introduce BiListing (Bimodal Listing) embeddings to use unstructured text and photo listing data as ranking signals. BiListing leverages large-language models and pretrained language-image models to create unified representations of diverse unstructured data into a single embedding vector per list and modality. Our experiment results show a 0.425% increase in NDCB (Normalized Discounted Cumulative Booking) gain and drove tens of millions in incremental revenue. Authors: Guillaume Guy, Mihajlo Grbovic, Chun How Tan, Han Zhao\nBeyond Pairwise Learning-To-Rank At Airbnb: In this paper, we introduce a method to improve the accuracy of pairwise learning-to-rank algorithms, the bedrock of modern search stacks. This approach captures interactions between items during pairwise comparisons, thereby giving us a better sense of what searchers truly want. We also share ways to implement this algorithm performantly, and results from online and offline experiments. Authors: Malay Haldar, Daochen Zha, Huiji Gao, Liwei He, Sanjeev Katariya\nLearning to Comparison-Shop: Traditional ranking models often evaluate items in isolation, disregarding the context in which users compare multiple items on a search results page. In this paper, we propose a novel ranking architecture, the Learning-to-Comparison-Shop (LTCS) System, that explicitly models and learns users’ comparison-shopping behaviors. Our experiments show statistically significant improvements of 1.7% in Normalized Discounted Cumulative Gain (NDCG) and 0.6% in booking conversion rate. Authors: Jie Tang, Daochen Zha, Xin Liu, Huiji Gao, Liwei He, Stephanie Moyerman, Sanjeev Katariya\n\nNLP & building LLM systems in production\nEMNLP (Empirical Methods in Natural Language Processing)\nEMNLP is a top-tier NLP conference that brings together practitioners and researchers to discuss new architectures and training strategies for language models, safety and evaluation strategies for LLMs, and real-world NLP applications. These research areas directly intersect with many of Airbnb’s product surfaces, such as customer support, search & discovery, and trust & safety. Additionally, each EMNLP cycle includes the release of new datasets, evaluation suites, and open-source libraries to help teams benchmark their progress against community standards.\nOur participation\nIn 2025, we sponsored EMNLP and presented two papers on humans-in-the-loop in AI systems and advanced summarization techniques. We also used EMNLP’s community datasets to benchmark our system, which showcased where we excel and where we can build upon our success with additional best practices. The conference deepened academic collaborations through discussions on LLM evaluation, safety, and agentic AI design, including mentoring students and early-career researchers.\nResearch highlights\n\nAgent-in-the-Loop, A Data Flywheel for Continuous Improvement in LLM-based Customer Support: To improve our LLM-based customer support system, this paper introduces an Agent-in-the-Loop (AITL) framework that leverages new interaction data to continuously enhance model performance. This flywheel can help the system stay up to date with new product features, shifting user preferences, and updated support policies and procedures. We launched a pilot in the US, and the results demonstrate significant improvement in accuracy and helpfulness. Authors: Cen Mia Zhao, Tiantian Zhang, Hanchen Su, Yufeng Wayne Zhang, Shaowei Su, Mingzhi Xu, Yu Elaine Liu, Wei Han, Jeremy Werner, Claire Na Cheng, Yashar Mehdad\nIncremental Summarization for Customer Support via Progressive Note-Taking and Agent Feedback: Customer service agents multitask during support interactions, identifying core issues, tracking prior actions, and producing accurate notes. To streamline this workflow, we introduced an incremental summarization system that intelligently determines when to generate concise bullet notes during conversations, reducing agents’ context-switching effort without sacrificing quality. To improve the system over time, we also introduced a learning framework that enables agents to make real-time edits, immediately refining online note generation. Authors: Yisha Wu, Cen Mia Zhao, Yuanpei Cao, Xiaoqing Su, Yashar Mehdad, Mindy Ji, Claire Na Cheng\n\nCOLING (International Conference on Computational Linguistics)\nCOLING is a top-tier NLP conference that covers both foundational research and industry applications of language models, including reasoning, evaluation, multilingual NLP, and real-world LLM systems. The work presented at this conference helps validate Airbnb’s technical direction and directly informs future investments.\nOur participation\nIn 2025, Airbnb presented at COLING for the first time, sharing a paper titled “LLM-Friendly Knowledge Representation for Customer Support” by Hanchen Su, Wei Luo, Wei Han, Yu Elaine Liu, Yufeng Wayne Zhang, Cen Mia Zhao, Ying Joy Zhang, and Yashar Mehdad. The paper presents a new format, Intent, Context, and Action (ICA), for structuring business knowledge in LLM-based QA and customer support workflows. Initial experiments in production show promising results. We also discovered relevant research in knowledge retrieval, LLM evaluation, and hallucination detection that will inspire future projects.\nOptimization, causal inference, and measurement science\nMIT CODE (Conference on Digital Experimentation)\nMIT CODE is one of the premier venues for researchers and practitioners to discuss topics in online digital experimentation, causal inference, and data-driven product innovation. The conference supports our commitment to data-driven decision-making and using experimentation to understand the long-term impacts on guests, hosts, and marketplace health.\nOur participation\nIn 2025, we had another strong showing at CODE, with a cohort of 6 data scientists and 3 academic collaborators. We gave talks in two sessions and presented a poster, which led to meaningful discussions with peer companies and interest in collaborating with academic research groups.\nResearch highlights\n\nBeyond the Experiment Window: Prospective Impacts Under Long-Term Ranking Dynamics: Product teams frequently leverage A/B tests to assess different rankers. While these experiments are typically conducted over shorter periods, we also recognize the value of understanding longer-term dynamics (such as seasonality and user evolution) to further support sustained business objectives, like marketplace health. To solve this problem, we developed a causal framework that allows us to estimate the long-term impacts of ranking changes with strategic goals (like marketplace health) using A/B testing data.\nTrustworthy Bayesian Inference in Batch-Adaptive Experimentation: Adaptive experimentation, like multi-arm bandit methods, can improve experiment efficiency by reallocating traffic toward promising treatments. Continued advancements in these approaches are expanding our ability to maintain high standards of statistical validity. This paper introduces a practical Bayesian framework for inference in batch-adaptive experiments, specifically tailored to the operational realities of online platforms.\n\nLink to all papers\n\nBeyond the Experiment Window: Prospective Impacts Under Long-Term Ranking Dynamics (Lo-Hua Yuan)\nTrustworthy Bayesian Inference in Batch-Adaptive Experimentation (Yicheng Li)\nExperimental Design for Product Launches with Collaborative User Networks (Monu Kala)\n\nINFORMS (Institute for Operations Research and the Management Sciences)\nINFORMS brings together academics and industry professionals to discuss and share research across data science, machine learning, economics, behavioral science, and analytics.\nOur participation\nIn 2025, our data science team was invited to INFORMS to present two talks in a session about bridging the gap between statistical methods and industry applications.\nResearch highlights\n\nBeyond Multi-Arm Bandits: Tackling Challenges in Adaptive Experiments at Airbnb. In this talk, we walked through the metrics and infrastructure challenges when using classic bandit algorithms, which make it difficult to operationalize adaptive experiments. We propose a hybrid approach that incorporates bandit algorithms into A/B experiments to enable adaptive testing. We also discussed how we onboard and validate adaptive experiments across individual product domains at Airbnb.\n\nLink to all papers\n\nBeyond the Experiment Window: Prospective Impacts Under Long-Term Ranking Dynamics (Lo-Hua Yuan)\nBeyond Multi-Arm Bandits: Tackling Challenges in Adaptive Experiments at Airbnb (Yicheng Li)\n\nLION (Learning and Intelligent Optimization)\nThe LION conference is a premier gathering of researchers exploring the intersection of machine learning, artificial intelligence, and mathematical optimization.\nOur participation\nWhile Airbnb has attended LION in the past, 2025 was the first time we presented at the conference. Nathan Brixius presented “Optimal Matched Block Design For Multi-Arm\nExperiments,” which introduces a new optimization formula using mixed-integer programming (MIP) to group subjects in multi-armed experiments, leading to more balanced groups and, in turn, more accurate experimental results. We also connected with leading experts in metaheuristics and AI fairness to help shape our future roadmap and sponsored the awards for the best papers presented at the conference.\nData systems\nVLDB (Very Large Data Bases)\nThe VLDB Conference is one of the top 2 flagship conferences in data management and large-scale data systems, with over 1,500 researchers and practitioners attending.\nOur participation\n“In 2025, we published our first paper at VLDB: ‘SQL:Trek Automated Index Design at Airbnb’ by Sam Lightstone and Ping Wang. The paper presents a novel approach for automated index design (code-named SQL:Trek). It uses query compiler cost models to identify effective indexes across many relational databases, including most MySQL and PostgreSQL derivatives. Additionally, the Airbnb team attended sessions on system efficiency, graph computing, and AI databases, and had the opportunity to meet other researchers.\nConclusion\nConferences remain a big part of our research program at Airbnb, helping us validate and refine our ideas through community feedback and providing a forum to share real-world insights that advance the field. In 2025, we doubled down on this vision by publishing papers for the first time at conferences in domains such as NLP, optimization, causal inference, and data systems, reflecting our ongoing commitment to using these technologies to create the best possible travel experiences.\nAs we look to 2026, we’re eager to expand our presence at these conferences and discover new ways to use AI, machine learning, and data science to build a best-in-class travel and living platform. If you’re interested in doing this type of work with us, consider joining us. Apply for one of our open positions.\n\nAcademic Publications & Airbnb Tech: 2025 Year in Review was originally published in The Airbnb Tech Blog on Medium, where people are continuing the conversation by highlighting and responding to this story.",
        "dc:creator": "Malay Haldar",
        "guid": "https://medium.com/p/7d79f57d3b52",
        "categories": [
          "machine-learning",
          "engineering",
          "ai",
          "data-science",
          "technology"
        ],
        "isoDate": "2026-02-24T18:36:39.000Z"
      }
    ]
  },
  {
    "name": "PayPal Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Visual Studio Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Mark Downie",
        "title": "Visual Studio February Update",
        "link": "https://devblogs.microsoft.com/visualstudio/visual-studio-february-update/",
        "pubDate": "Tue, 24 Feb 2026 22:16:30 +0000",
        "content:encodedSnippet": "This month’s Visual Studio update continues our focus on helping you move faster and stay in flow, with practical improvements across AI assistance, debugging, testing, and modernization. Building on the momentum from January’s editor updates, the February release brings smarter diagnostics and targeted support for real world development scenarios, from WinForms maintenance to C++ modernization.\nAll of the features highlighted are available in the Visual Studio 2026 Stable Channel as part of the February 2026 feature update (18.3). Please update to the latest version to try out these new features!\nWinForms Expert Agent\nThe WinForms Expert agent provides a focused guide for handling key challenges in WinForms development. It covers several important areas:\nDesigner vs. regular code: Understand which C# features apply to designer-generated code and business logic.\nModern .NET patterns: Updated for .NET 8-10, including MVVM with Community Toolkit, async/await with proper InvokeAsync overloads, Dark mode with high-DPI support, and nullable reference types.\nLayout: Advice on using TableLayoutPanel and FlowLayoutPanel for responsive, cross-device design.\nCodeDOM serialization: Rules for property serialization and avoiding common issues with [DefaultValue] and ShouldSerialize*() methods.\nException handling: Patterns for async event handlers and robust application-level error handling.\nThe agent serves as an expert reviewer for your WinForms code, providing comprehensive guidance on everything from naming controls to ensuring accessibility. The WinForms Agent is automatically implemented and included in the system prompt when necessary.\nSmarter Test Generation with GitHub Copilot\nVisual Studio now includes intelligent test generation with GitHub Copilot, making it faster to create and refine unit tests for your C# code. This purpose-built workflow works seamlessly with xUnit, NUnit, and MSTest.\n\nSimply type @Test in GitHub Copilot Chat, describe what you want to test, and Copilot generates the test code for you. Whether you’re starting fresh or improving coverage on existing projects, this feature helps you write tests faster without leaving your workflow.\nSlash Commands for Custom Prompts\nInvoke your favorite custom prompts faster using slash commands in Copilot Chat. Type / and your custom prompts appear at the top of the list, marked with a bookmark icon for easy identification.\n\nWe’ve also added two additional commands:\n– /generateInstructions: Automatically generate a copilot-instructions.md file for your repository using project context like coding style and preferences\n– /savePrompt: Extract a reusable prompt from your current chat thread and save it for later use via / commands\nThese shortcuts make it easier to build and reuse your workflow patterns.\nC++ App Modernization\nGitHub Copilot app modernization for C++ is now available in Public Preview. GitHub Copilot app modernization for C++ helps you update your C++ projects to use the latest versions of MSVC and to resolve upgrade-related issues. You can find our user documentation on Microsoft Learn.\n\nDataTips in IEnumerable Visualizer\nYou can now use DataTips in the IEnumerable Visualizer while debugging. Just hover over any cell in the grid to see the full object behind that value, the same DataTip experience you’re used to in the editor or Watch window.\nWhen you hover over a cell, a DataTip shows all the object’s properties in one place. This makes it much easier to debug collections with complex or nested data. Whether it’s a List<T> of objects or a dictionary with structured values, one hover lets you quickly inspect everything inside.\n\nAnalyze Call Stack with Copilot\nYou can now Analyze Call Stack with Copilot to help you quickly understand what your app is doing when debugging stops. When you pause execution, you can select Analyze with Copilot in the Call Stack window. Copilot reviews the current stack and explains why the app isn’t progressing whether the thread is waiting on work, looping, or blocked by something.\nThis makes the call stack more than just a list of frames. It becomes a helpful guide that shows what’s happening in your app so you can move faster toward the real fix.\nhttps://devblogs.microsoft.com/visualstudio/wp-content/uploads/sites/4/2026/02/callstackanalysis.mp4\n\nProfiler agent with Unit Test support\nThe Profiler Agent (@profiler) now works with unit tests. You can use your existing tests to check performance improvements, making it easier to measure and optimize your code in more situations. The agent can discovers relevant unit tests/BenchmarkDotNet benchmarks that exercise performance-critical code paths.\nIf no good tests or benchmarks are available, it automatically creates a small measurement setup so you can capture a baseline and compare results after changes. This unit-test-focused approach also makes the Profiler Agent useful for C++ projects, where benchmarks aren’t always practical, but unit tests often already exist.\n\nFaster and More Reliable Razor Hot Reload\nHot Reload for Razor files are now faster and more reliable. By hosting the Razor compiler inside the Roslyn process, edits to .razor files apply more quickly and avoid delays that previously slowed Blazor workflows. We also reduced the number of blocked edits, with more changes now applying without requiring a rebuild, including file renames and several previously unsupported code edits. When a rebuild is still required, Hot Reload can now automatically restart the app instead of ending the debug session, helping you stay in flow.\nWe are continuing to invest in features that help you understand, test, and improve existing code, not just write new code. Try these updates in the Visual Studio 2026 Stable Channel and let us know what is working well and where we can improve. Your feedback directly shapes what we build next.\nThe post Visual Studio February Update appeared first on Visual Studio Blog.",
        "enclosure": {
          "url": "https://devblogs.microsoft.com/visualstudio/wp-content/uploads/sites/4/2026/02/callstackanalysis.mp4",
          "length": "1732737",
          "type": "video/mp4"
        },
        "dc:creator": "Mark Downie",
        "comments": "https://devblogs.microsoft.com/visualstudio/visual-studio-february-update/#respond",
        "content": "<p>This month’s Visual Studio update continues our focus on helping you move faster and stay in flow, with practical improvements across AI assistance, debugging, testing, and modernization. Building on the momentum from January’s editor updates, the February release brings smarter diagnostics and targeted support for real world development scenarios, from WinForms maintenance to C++ modernization. [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/visual-studio-february-update/\">Visual Studio February Update</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "This month’s Visual Studio update continues our focus on helping you move faster and stay in flow, with practical improvements across AI assistance, debugging, testing, and modernization. Building on the momentum from January’s editor updates, the February release brings smarter diagnostics and targeted support for real world development scenarios, from WinForms maintenance to C++ modernization. […]\nThe post Visual Studio February Update appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=255690",
        "categories": [
          "GitHub Copilot",
          "Productivity",
          ".NET",
          "Debugging and Diagnostics"
        ],
        "isoDate": "2026-02-24T22:16:30.000Z"
      }
    ]
  },
  {
    "name": "Joshua",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권재명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김석기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선영",
    "category": "개인",
    "posts": [
      {
        "creator": "sunyzero",
        "title": "mobaXterm에서 한글 타이핑시 &quot;응답 없음&quot;으로 죽는 문제",
        "link": "https://sunyzero.tistory.com/325",
        "pubDate": "Mon, 23 Feb 2026 21:07:50 +0900",
        "author": "sunyzero",
        "comments": "https://sunyzero.tistory.com/325#entry325comment",
        "content": "<p data-ke-size=\"size16\">ssh접속을 위해 mobaXterm을 쓰다보면 한영 전환을 하거나 한글 타이핑을 하면 \"응답 없음\" 상태로 변하면서 프로세스가 죽는 문제가 생기곤 했다. 특히 한글을 타이핑하다가 오타가 발생해서 백스페이스로 자음이나 모음을 지울때 종종 발생했다. 그래서 mobaXterm 한글이 죽는 이유를 찾다보니 마이크로소프트가 IME(Input Method Editor)를 2가지를 가지고 있다는 것을 알았습니다. 그리고 최신의 IME(TSF방식)이 구형 프레임워크나 개발툴로 개발된 애플리케이션과 종종 충돌을 일으킨다는 것도 알게되었다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">1. 해결 방법</h2>\n<p data-ke-size=\"size16\">우선 해결 방법을 먼저 말하자면 <span style=\"background-color: #f6e199;\">설정</span>에서 \"시간 및 언어\", \"<span style=\"background-color: #99cefa;\">언어 및 지역</span>\", \"옵션\", \"<span style=\"background-color: #c1bef9;\">Microsoft 입력기</span>\" 메뉴에서 <span style=\"background-color: #f6e199;\">\"이전 버전의 Microsoft IME</span>\"를 <span style=\"color: #ee2323;\">켬(on)</span>으로 해두면 된다. 문제는 이 옵션이 꽤 깊숙한 곳에 있어서 찾아가는게 좀 어렵다. 그래서 찾아가는 방법을 한땀한땀 보여주도록 하겠다.</p>\n<p data-ke-size=\"size16\">먼저 \"설정\"을 실행하고, \"시간 및 언어\" 메뉴를 선택한다. 그리고 아래 그림처럼 \"<span style=\"color: #ee2323;\">한국어</span>\"의 점3개를 눌러서 \"<span style=\"background-color: #f6e199;\">언어 옵션</span>\"을 선택한다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1382\" data-origin-height=\"834\"><span data-url=\"https://blog.kakaocdn.net/dn/nMM6l/dJMcaaj2HBG/hpAqHc0N8u4CgKgBngxsd1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/nMM6l/dJMcaaj2HBG/hpAqHc0N8u4CgKgBngxsd1/img.png\" data-alt=\"윈11설정, 시간 및 언어, 언어 및 지역\"><img src=\"https://blog.kakaocdn.net/dn/nMM6l/dJMcaaj2HBG/hpAqHc0N8u4CgKgBngxsd1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FnMM6l%2FdJMcaaj2HBG%2FhpAqHc0N8u4CgKgBngxsd1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1382\" height=\"834\" data-origin-width=\"1382\" data-origin-height=\"834\"/></span><figcaption>윈11설정, 시간 및 언어, 언어 및 지역</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">언어 옵션을 선택해서 들어가면 아랫쪽에 키보드 메뉴가 있다. 여기서 아래 그림처럼 \"<span style=\"background-color: #f6e199;\">Microsoft 입력기</span>\"라는 것을 찾고, 점3개를 눌러서 \"<span style=\"color: #ee2323;\">키보드 옵션</span>\"을 선택한다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1516\" data-origin-height=\"604\"><span data-url=\"https://blog.kakaocdn.net/dn/b31lei/dJMcafZVygH/GRtg274xq5JNkqXfc4Y0d1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/b31lei/dJMcafZVygH/GRtg274xq5JNkqXfc4Y0d1/img.png\" data-alt=\"한국어, 키보드, Microsoft 입력기\"><img src=\"https://blog.kakaocdn.net/dn/b31lei/dJMcafZVygH/GRtg274xq5JNkqXfc4Y0d1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb31lei%2FdJMcafZVygH%2FGRtg274xq5JNkqXfc4Y0d1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1516\" height=\"604\" data-origin-width=\"1516\" data-origin-height=\"604\"/></span><figcaption>한국어, 키보드, Microsoft 입력기</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">키보드 옵션을 선택해서 들어가면 하단에 호환성 부분에 \"<span style=\"background-color: #ffc1c8;\">이전 버전의 Microsoft IME</span>\"를 <span style=\"color: #ee2323;\">켬(on)</span>으로 설정하면 끝난다.&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1319\" data-origin-height=\"971\"><span data-url=\"https://blog.kakaocdn.net/dn/nH5lc/dJMcaiPQYN2/AcIhJA59l6izLgAcnkXLqK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/nH5lc/dJMcaiPQYN2/AcIhJA59l6izLgAcnkXLqK/img.png\" data-alt=\"키보드 옵션, 호환성, 이전 버전의 Microsoft IME\"><img src=\"https://blog.kakaocdn.net/dn/nH5lc/dJMcaiPQYN2/AcIhJA59l6izLgAcnkXLqK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FnH5lc%2FdJMcaiPQYN2%2FAcIhJA59l6izLgAcnkXLqK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1319\" height=\"971\" data-origin-width=\"1319\" data-origin-height=\"971\"/></span><figcaption>키보드 옵션, 호환성, 이전 버전의 Microsoft IME</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">이렇게 한 뒤에 되도록이면 재부팅을 하는 것을 권장한다. 애초에 이런 설정이 필요없도록 하려면 tabby 같은 ssh client를 사용하는 것도 괜찮다. 다만 개인적으로는 mobaXterm이 더 편해서 이걸 주로 사용하는 편이다. 그리고 깨알 지식으로 mobaXterm을 사용할 때는 리가처 폰트(ligature font)를 사용하면 이상하게 화면 스크롤 속도가 느려진다. <span style=\"color: #f89009;\">따라서 되도록이면 ligature 글꼴 대신 일반 글꼴을 사용하는 것을 권장한다</span>.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">2. 기술적 배경 지식</h2>\n<p data-ke-size=\"size16\">왜 이런 문제가 생겼는지 알기 위해서는 IME의 변화에 대해서 알아야만 한다. 마이크로소프트는 XP에서 <span style=\"background-color: #9feec3;\">TSF(Text Services Framework)</span>라는 새로운 IME를 도입했다. 그리고 윈도10이나 윈도11에는 구형 IME인 <span style=\"background-color: #f6e199;\">IMM32</span>와 신형 IME인 TSF가 둘다 설치되고, 기본값으로는 TSF로 작동한다는 점이다.&nbsp;</p>\n<p data-ke-size=\"size16\">TSF의 특징은 비동기로 작동한다는 특징이 있다. 따라서 타이핑을 하는 것을 버퍼에 채워두었다가 완성시키거나 혹은 음성 변환이나 여러가지 기능이 있는데, 이게 기능을 추가하다보니 어느 시점부터 옛날 시스템과 뭔가 안맞는게 생겼던 것 같다. 게다가&nbsp; mobaXterm은 <span style=\"background-color: #f6e199;\">델파이(Delphi)</span>라고 굉장히 옛날 개발툴로 만들어지다보니 TSF와는 잘 맞지 않는 부분이 있는 것 같다. 그럼에도 불구하고 영어권은 큰 문제가 없어 보인다. 한글이나 중국 번체, 일어 한문등이 가장 큰 문제가 되는것 같은데, 이들 문자들의 특징은 여러 타이핑을 조합해서 하나의 문자가 생기는 케이스가 있다는 점이다. 영어는 hello를 칠때 h를 치면 즉각 h를 표시하면 그만이지만, 한글로 \"<span style=\"color: #ee2323;\">헬로</span>\"를 타이핑하려면 \"<span style=\"color: #ee2323;\">ㅎ</span> + <span style=\"color: #ee2323;\">ㅔ</span> + <span style=\"color: #ee2323;\">ㄹ</span>\" 까지 쳐야 \"<span style=\"color: #ee2323;\">헬</span>\" 글자 1개가 완성된다. 여기서 ㅎ 다음에 \"<span style=\"color: #ee2323;\">ㅔ</span>\" 대신에 \"<span style=\"color: #ee2323;\">ㅐ</span>\"를 잘못 타이핑했다면 backspace로 지울때 현재까지 완성된 \"<span style=\"color: #ee2323;\">해</span>\"를 지우는게 아니라 딱 \"<span style=\"color: #ee2323;\">ㅐ</span>\"만 지우고, \"<span style=\"color: #ee2323;\">ㅎ</span>\" 자음은 남겨야 하는데, 이런 부분이 오류를 만드는 원인이 되는 것 같다. 게다가 TSF가 비동기식이라 어떤 경우에는 잘 작동하지만, 어떤 경우에는 비동기 이벤트를 놓쳐서 \"응답 없음\"오류를 만드는 것 같다.</p>\n<p data-ke-size=\"size16\">물론 2026년을 기준으로 보면 대부분의 개발툴들은 TSF를 제대로 지원하는 경우가 많아서 큰 문제는 안되지만, 앞서 언급한 델파이나 아니면 cygwin, Qt을 이용하는 시스템에서는 문제가 종종 생기는 것 같다. 결국 문제가 생기는 애플리케이션을 주로 쓴다면 결국 TSF를 버리고 \"이전 버전의 Microsoft IME\"인 IMM32를 쓰는 수 밖에 없어 보인다. (<span style=\"color: #8a3db6;\">마소가 근본적인 문제를 고쳐서 TSF를 쓸때도 문제없게 해주면 좋겠지만, 솔직히 기대도 안한다. 왜냐하면 지금 윈11은 툭하면 업데이트 버그가 쏟아지기 때문이다. 사소한 버그도 해결 못하는 것을 보면 윈도 개발팀의 프로그래밍 능력이 수준 이하라고 생각된다.</span>)</p>\n<p data-ke-size=\"size16\">게다가 TSF를 쓰면 성능도 좋아진다고는 하지만 솔직히 요새 시스템에서 TSF를 써서 얻는 성능적 이점은 쥐꼬리의 털조각 1개만큼도 안되는 수준이라, 성능적 이점은 사실상 없다. 다만 TSF는 한자를 더 많이 지원하는 장점이 있다고 하는데, 요새 한자를 병용하거나 한자를 타이핑하는 경우는 드물기 때문에 큰 메리트가 없어 보인다.</p>\n<p data-ke-size=\"size16\">결론적으로 mobaXterm을 쓸때는 TSF를 쓰지 않고 IMM32를 쓰도록 \"이전 버전의 Microsoft IME\"를 설정하도록 하자.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">히스토리</h2>\n<p data-ke-size=\"size16\">2026.02.23 릴리즈</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "ssh접속을 위해 mobaXterm을 쓰다보면 한영 전환을 하거나 한글 타이핑을 하면 \"응답 없음\" 상태로 변하면서 프로세스가 죽는 문제가 생기곤 했다. 특히 한글을 타이핑하다가 오타가 발생해서 백스페이스로 자음이나 모음을 지울때 종종 발생했다. 그래서 mobaXterm 한글이 죽는 이유를 찾다보니 마이크로소프트가 IME(Input Method Editor)를 2가지를 가지고 있다는 것을 알았습니다. 그리고 최신의 IME(TSF방식)이 구형 프레임워크나 개발툴로 개발된 애플리케이션과 종종 충돌을 일으킨다는 것도 알게되었다.\n \n1. 해결 방법\n우선 해결 방법을 먼저 말하자면 설정에서 \"시간 및 언어\", \"언어 및 지역\", \"옵션\", \"Microsoft 입력기\" 메뉴에서 \"이전 버전의 Microsoft IME\"를 켬(on)으로 해두면 된다. 문제는 이 옵션이 꽤 깊숙한 곳에 있어서 찾아가는게 좀 어렵다. 그래서 찾아가는 방법을 한땀한땀 보여주도록 하겠다.\n먼저 \"설정\"을 실행하고, \"시간 및 언어\" 메뉴를 선택한다. 그리고 아래 그림처럼 \"한국어\"의 점3개를 눌러서 \"언어 옵션\"을 선택한다.\n윈11설정, 시간 및 언어, 언어 및 지역\n\n\n언어 옵션을 선택해서 들어가면 아랫쪽에 키보드 메뉴가 있다. 여기서 아래 그림처럼 \"Microsoft 입력기\"라는 것을 찾고, 점3개를 눌러서 \"키보드 옵션\"을 선택한다.\n한국어, 키보드, Microsoft 입력기\n\n\n키보드 옵션을 선택해서 들어가면 하단에 호환성 부분에 \"이전 버전의 Microsoft IME\"를 켬(on)으로 설정하면 끝난다. \n키보드 옵션, 호환성, 이전 버전의 Microsoft IME\n\n\n이렇게 한 뒤에 되도록이면 재부팅을 하는 것을 권장한다. 애초에 이런 설정이 필요없도록 하려면 tabby 같은 ssh client를 사용하는 것도 괜찮다. 다만 개인적으로는 mobaXterm이 더 편해서 이걸 주로 사용하는 편이다. 그리고 깨알 지식으로 mobaXterm을 사용할 때는 리가처 폰트(ligature font)를 사용하면 이상하게 화면 스크롤 속도가 느려진다. 따라서 되도록이면 ligature 글꼴 대신 일반 글꼴을 사용하는 것을 권장한다.\n \n \n2. 기술적 배경 지식\n왜 이런 문제가 생겼는지 알기 위해서는 IME의 변화에 대해서 알아야만 한다. 마이크로소프트는 XP에서 TSF(Text Services Framework)라는 새로운 IME를 도입했다. 그리고 윈도10이나 윈도11에는 구형 IME인 IMM32와 신형 IME인 TSF가 둘다 설치되고, 기본값으로는 TSF로 작동한다는 점이다. \nTSF의 특징은 비동기로 작동한다는 특징이 있다. 따라서 타이핑을 하는 것을 버퍼에 채워두었다가 완성시키거나 혹은 음성 변환이나 여러가지 기능이 있는데, 이게 기능을 추가하다보니 어느 시점부터 옛날 시스템과 뭔가 안맞는게 생겼던 것 같다. 게다가  mobaXterm은 델파이(Delphi)라고 굉장히 옛날 개발툴로 만들어지다보니 TSF와는 잘 맞지 않는 부분이 있는 것 같다. 그럼에도 불구하고 영어권은 큰 문제가 없어 보인다. 한글이나 중국 번체, 일어 한문등이 가장 큰 문제가 되는것 같은데, 이들 문자들의 특징은 여러 타이핑을 조합해서 하나의 문자가 생기는 케이스가 있다는 점이다. 영어는 hello를 칠때 h를 치면 즉각 h를 표시하면 그만이지만, 한글로 \"헬로\"를 타이핑하려면 \"ㅎ + ㅔ + ㄹ\" 까지 쳐야 \"헬\" 글자 1개가 완성된다. 여기서 ㅎ 다음에 \"ㅔ\" 대신에 \"ㅐ\"를 잘못 타이핑했다면 backspace로 지울때 현재까지 완성된 \"해\"를 지우는게 아니라 딱 \"ㅐ\"만 지우고, \"ㅎ\" 자음은 남겨야 하는데, 이런 부분이 오류를 만드는 원인이 되는 것 같다. 게다가 TSF가 비동기식이라 어떤 경우에는 잘 작동하지만, 어떤 경우에는 비동기 이벤트를 놓쳐서 \"응답 없음\"오류를 만드는 것 같다.\n물론 2026년을 기준으로 보면 대부분의 개발툴들은 TSF를 제대로 지원하는 경우가 많아서 큰 문제는 안되지만, 앞서 언급한 델파이나 아니면 cygwin, Qt을 이용하는 시스템에서는 문제가 종종 생기는 것 같다. 결국 문제가 생기는 애플리케이션을 주로 쓴다면 결국 TSF를 버리고 \"이전 버전의 Microsoft IME\"인 IMM32를 쓰는 수 밖에 없어 보인다. (마소가 근본적인 문제를 고쳐서 TSF를 쓸때도 문제없게 해주면 좋겠지만, 솔직히 기대도 안한다. 왜냐하면 지금 윈11은 툭하면 업데이트 버그가 쏟아지기 때문이다. 사소한 버그도 해결 못하는 것을 보면 윈도 개발팀의 프로그래밍 능력이 수준 이하라고 생각된다.)\n게다가 TSF를 쓰면 성능도 좋아진다고는 하지만 솔직히 요새 시스템에서 TSF를 써서 얻는 성능적 이점은 쥐꼬리의 털조각 1개만큼도 안되는 수준이라, 성능적 이점은 사실상 없다. 다만 TSF는 한자를 더 많이 지원하는 장점이 있다고 하는데, 요새 한자를 병용하거나 한자를 타이핑하는 경우는 드물기 때문에 큰 메리트가 없어 보인다.\n결론적으로 mobaXterm을 쓸때는 TSF를 쓰지 않고 IMM32를 쓰도록 \"이전 버전의 Microsoft IME\"를 설정하도록 하자.\n \n \n히스토리\n2026.02.23 릴리즈",
        "guid": "https://sunyzero.tistory.com/325",
        "categories": [
          "컴퓨터 관련/윈도 패밀리",
          "IME",
          "mobaXterm crash",
          "SSH Client",
          "이전 버전의 Microsoft IME",
          "한글 입력기"
        ],
        "isoDate": "2026-02-23T12:07:50.000Z"
      }
    ]
  },
  {
    "name": "강대명",
    "category": "개인",
    "posts": [
      {
        "creator": "charsyam",
        "title": "[책 리뷰] “우리, 프로그래머들”, 미래를 이해하기 위해, 과거를 봐야한다.",
        "link": "https://charsyam.wordpress.com/2026/02/28/%ec%b1%85-%eb%a6%ac%eb%b7%b0-%ec%9a%b0%eb%a6%ac-%ed%94%84%eb%a1%9c%ea%b7%b8%eb%9e%98%eb%a8%b8%eb%93%a4-%eb%af%b8%eb%9e%98%eb%a5%bc-%ec%9d%b4%ed%95%b4%ed%95%98%ea%b8%b0-%ec%9c%84%ed%95%b4/",
        "pubDate": "Sat, 28 Feb 2026 13:17:54 +0000",
        "content:encodedSnippet": "어릴적에 좋아하던게, 위인전을 읽는 것이었습니다. 개발자가 되고 나서는 그런 개발의 역사를 아는 것이 재미있기도 하지만, 새로운 기술을 이해하기 위한 밑바탕이 되는 것이, 어떤 기술이 어떤 목적으로 나왔는지에 대한 것이었습니다. 책의 2부에서는 컴퓨터 역사의 거장들에 대한 이야기가 나오는데, 특히 컴파일러라는 기술이 신기하고도 대단해보였던 저에게는 BNF 표현식과 최초의 고수준 언어 포트란을 만든 존 배커스에 대한 이야기와 최초의 개발자에 대한 그레이스 호퍼의 이야기, 사실 두 사람의 큰 위엄만 살짝 알고 있었지, 좀 더 자세한 내용을 모르고 있던 저에게는 상당히 재미나면서도 이런 일들이 있었구나라는 생각이 들게 해주었습니다. 그리고 유닉스를 만든 톰프슨,리치,커니핸의 유닉스 개발이야기 중에서 유닉스의 디스크 스케줄링 알고리즘 이야기, 유닉스에 관심있는 사람으로써, 몰랐던 사실을 알게되는…\n\n\n\n\n그리고 3부에서는 년도별 이야기가 나오는데, 여기서 마틴옹의 경험을 이야기해준다는 것이 신기했습니다. 저도 꽤 오랜기간의 개발 경험이 있지만, 아직 어리다보니, 60년대부터 컴퓨터에 대한 경험이라니… (그런데 마틴옹도 1964년에 겨우 12세이긴 하지만, 이때 본인이 프로그래머가 되었다고 합니다.) 우리, 프로그래머들은 막 신기술에 대해서 잘 알려주고 있는 책은 아닙니다. 물론 4부가 미래에 대한 이야기지만… 그러나 과거를 알아야 미래가 보인다라고 항상 이야기합니다. 그래서 새로운 기술을 배울때는 그 기술의 토대에 대해서, 역사를 살펴보라는 이야기를 자주하는데, “우리, 프로그래머들” 은 그런 부분에서 지적호기심을 채워줄 것 같습니다.",
        "dc:creator": "charsyam",
        "comments": "https://charsyam.wordpress.com/2026/02/28/%ec%b1%85-%eb%a6%ac%eb%b7%b0-%ec%9a%b0%eb%a6%ac-%ed%94%84%eb%a1%9c%ea%b7%b8%eb%9e%98%eb%a8%b8%eb%93%a4-%eb%af%b8%eb%9e%98%eb%a5%bc-%ec%9d%b4%ed%95%b4%ed%95%98%ea%b8%b0-%ec%9c%84%ed%95%b4/#respond",
        "content": "어릴적에 좋아하던게, 위인전을 읽는 것이었습니다. 개발자가 되고 나서는 그런 개발의 역사를 아는 것이 재미있기도 하지만, 새로운 기술을 이해하기 위한 밑바탕이 되는 것이, 어떤 기술이 어떤 목적으로 나왔는지에 대한 것이었습니다. 책의 2부에서는 컴퓨터 역사의 거장들에 대한 이야기가 나오는데, 특히 컴파일러라는 기술이 신기하고도 대단해보였던 저에게는 BNF 표현식과 최초의 고수준 언어 포트란을 만든 존 배커스에 대한 이야기와 최초의 [&#8230;]",
        "contentSnippet": "어릴적에 좋아하던게, 위인전을 읽는 것이었습니다. 개발자가 되고 나서는 그런 개발의 역사를 아는 것이 재미있기도 하지만, 새로운 기술을 이해하기 위한 밑바탕이 되는 것이, 어떤 기술이 어떤 목적으로 나왔는지에 대한 것이었습니다. 책의 2부에서는 컴퓨터 역사의 거장들에 대한 이야기가 나오는데, 특히 컴파일러라는 기술이 신기하고도 대단해보였던 저에게는 BNF 표현식과 최초의 고수준 언어 포트란을 만든 존 배커스에 대한 이야기와 최초의 […]",
        "guid": "http://charsyam.wordpress.com/?p=3631",
        "categories": [
          "Uncategorized"
        ],
        "isoDate": "2026-02-28T13:17:54.000Z"
      }
    ]
  },
  {
    "name": "줌구",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수보",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김시은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "곽민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김범진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민서",
    "category": "개인",
    "posts": []
  },
  {
    "name": "I am not Okay",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권창현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권기호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강태욱",
    "category": "개인",
    "posts": [
      {
        "title": "공학적 물리AI 모델 학습 기술 개발 방법",
        "link": "http://daddynkidsmakers.blogspot.com/2026/02/ai_26.html",
        "pubDate": "2026-02-26T11:38:00.000Z",
        "author": "Daddy Maker",
        "content": "<div style=\"text-align: left;\">이 글은&nbsp;공학적 물리AI 모델 학습 기술 개발 방법을 나눔한다.</div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEgVGIh9YBVvqmnHcwCWEnxrsaj8DDq4084DTmBnODROw46VtmdzD-aY9qWRqffE-T_y_mw8s-cPa7fSH79PpWxIZpg2uGjYA32ox-HAaT0gFWMQfsSLHzxhmoc7BS8h1FrmkA4SrBJlvTOoYm1K0fnAK2k6eciFlbEAg5okyvgGQhT_wqt2QnwM4swRQird\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"423\" data-original-width=\"1521\" height=\"178\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEgVGIh9YBVvqmnHcwCWEnxrsaj8DDq4084DTmBnODROw46VtmdzD-aY9qWRqffE-T_y_mw8s-cPa7fSH79PpWxIZpg2uGjYA32ox-HAaT0gFWMQfsSLHzxhmoc7BS8h1FrmkA4SrBJlvTOoYm1K0fnAK2k6eciFlbEAg5okyvgGQhT_wqt2QnwM4swRQird=w640-h178\" width=\"640\" /></a></div><br /></div><div style=\"text-align: left;\"><b>레퍼런스</b></div><div style=\"text-align: left;\"><ul style=\"text-align: left;\"><li><a href=\"https://www.sciencedirect.com/science/article/abs/pii/S0045782525008631\">Large language model-empowered next-generation computer-aided engineering - ScienceDirect</a></li><li><a href=\"https://arxiv.org/pdf/2510.11004\">Automating Structural Engineering Workflows with Large Language Model Agents</a></li><li><a href=\"https://www.mdpi.com/2504-2289/10/1/3\">DL-VLM: A Dynamic Lightweight Vision-Language Model for Bridge Health Diagnosis</a></li><li><a href=\"https://github.com/dataset-ninja/codebrim\">dataset-ninja/codebrim: CODEBRIM: COncrete DEfect BRidge IMage Dataset</a></li><li><a href=\"https://digitalcommons.usu.edu/all_datasets/48/\">\"SDNET2018: A concrete crack image dataset for machine learning applica\" by Marc Maguire, Sattar Dorafshan et al.</a></li><li><a href=\"https://huggingface.co/datasets/PrismaX/PhysUniBench\">PrismaX/PhysUniBench · Datasets at Hugging Face</a></li><li><a href=\"https://github.com/DelosLiang/masse\">DelosLiang/masse: Automating Structural Engineering Workflows with Large Language Model Agents</a></li><li><a href=\"https://zenodo.org/records/2620293\">CODEBRIM: COncrete DEfect BRidge IMage Dataset</a></li><li><a href=\"https://github.com/zhuminjie/OpenSeesPy\">zhuminjie/OpenSeesPy: OpenSeesPy versions, doc, and pip</a></li></ul></div>",
        "contentSnippet": "이 글은 공학적 물리AI 모델 학습 기술 개발 방법을 나눔한다.\n\n\n\n레퍼런스\n\nLarge language model-empowered next-generation computer-aided engineering - ScienceDirect\nAutomating Structural Engineering Workflows with Large Language Model Agents\nDL-VLM: A Dynamic Lightweight Vision-Language Model for Bridge Health Diagnosis\ndataset-ninja/codebrim: CODEBRIM: COncrete DEfect BRidge IMage Dataset\n\"SDNET2018: A concrete crack image dataset for machine learning applica\" by Marc Maguire, Sattar Dorafshan et al.\nPrismaX/PhysUniBench · Datasets at Hugging Face\nDelosLiang/masse: Automating Structural Engineering Workflows with Large Language Model Agents\nCODEBRIM: COncrete DEfect BRidge IMage Dataset\nzhuminjie/OpenSeesPy: OpenSeesPy versions, doc, and pip",
        "id": "tag:blogger.com,1999:blog-5201956450461596914.post-5269691995170829174",
        "isoDate": "2026-02-26T11:38:00.000Z"
      },
      {
        "title": "ViT 및 VLM 메커니즘 이해 및 코드 스크래치하기",
        "link": "http://daddynkidsmakers.blogspot.com/2026/02/vlm.html",
        "pubDate": "2026-02-24T11:15:00.000Z",
        "author": "Daddy Maker",
        "content": "<div style=\"text-align: left;\">이 글은&nbsp;VLM 스크래치하는 방법을 나눔한다.<br /></div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEhCcVVuSQvauRL8UwRWUmS88gpIymnXfWYUVYrEwyraFszdBz6g3J5K72KrQc4509lbQrtyqz_OxLa8YtDwZFZMq-bolQV3f_iJfq2HL2fb3R7S5OEpioZ7ZmGF_fWBkYqR4f6VlHUFZGdNEkkFa9hDaBRw1YN2UcDjMP9dTIBDQvWEoHw7eKt4WW1P4jj2\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"865\" data-original-width=\"1100\" height=\"315\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEhCcVVuSQvauRL8UwRWUmS88gpIymnXfWYUVYrEwyraFszdBz6g3J5K72KrQc4509lbQrtyqz_OxLa8YtDwZFZMq-bolQV3f_iJfq2HL2fb3R7S5OEpioZ7ZmGF_fWBkYqR4f6VlHUFZGdNEkkFa9hDaBRw1YN2UcDjMP9dTIBDQvWEoHw7eKt4WW1P4jj2=w400-h315\" width=\"400\" /></a></div><br /></div></div><div style=\"text-align: left;\"><b>VLM 레퍼런스</b></div><div style=\"text-align: left;\"><ul style=\"text-align: left;\"><li><a href=\"https://qiita.com/asaoka/items/fb8780fadeb24aaa552f\">Vision Language Model from scratch in Pytorch #vlm - Qiita</a></li><li><a href=\"https://github.com/AviSoori1x/seemore\">AviSoori1x/seemore: From scratch implementation of a vision language model in pure PyTorch</a></li><li><a href=\"https://huggingface.co/blog/nanovlm\">nanoVLM: The simplest repository to train your VLM in pure PyTorch</a></li><li><a href=\"https://github.com/huggingface/nanoVLM\">huggingface/nanoVLM: The simplest, fastest repository for training/finetuning small-sized VLMs.</a></li><li><a href=\"https://medium.com/@saptarshimt/training-a-vision-language-model-from-scratch-vlm-multi-modal-a0b43c5966b1\">Training a Vision Language Model from scratch (VLM multi-modal) | by Saptarshi MT | Medium</a></li><li><a href=\"https://medium.com/@achrafabbaoui/implementation-of-vision-language-models-vlm-from-scratch-a-comprehensive-technical-deep-dive-d348322f9b3c\">Implementation of Vision language models (VLM) from scratch: A Technical Deep Dive. | by Achraf Abbaoui | Medium</a></li><li><a href=\"https://medium.com/@govindarajpriyanthan/wiring-the-multimodal-mind-building-a-vision-language-model-vlm-from-scratch-part-1-1aee93f1d474\">Wiring the Multimodal Mind: Building a Vision Language Model (VLM) from Scratch - Part 1 | by Priyanthan Govindaraj | Medium</a></li><li><a href=\"https://huggingface.co/blog/AviSoori1x/seemore-vision-language-model\">seemore: Implement a Vision Language Model from Scratch</a></li><li><a href=\"https://github.com/Vidit-Ostwal/VLM-from-scratch\">Vidit-Ostwal/VLM-from-scratch: This is majorly for my own learning purpose.</a></li><li><a href=\"https://www.vizuaranewsletter.com/p/building-a-nano-vision-language-model\">Building a Nano Vision-Language Model from Scratch</a></li><li><a href=\"https://github.com/nipunbatra/vlm-from-scratch\">nipunbatra/vlm-from-scratch</a></li><li><a href=\"https://medium.com/@shanmuka.sadhu/building-paligemma-vlm-from-scratch-using-pytorch-7bc6bb58efd2\">Building PaliGemma VLM From Scratch using Pytorch | by Shanmuka Sadhu | Jan, 2026 | Medium</a></li><li><a href=\"https://huggingface.co/blog/smolvlm\">SmolVLM - small yet mighty Vision Language Model</a></li></ul><div><b>ViT 레퍼런스</b></div><div><ul style=\"text-align: left;\"><li><a href=\"https://www.kaggle.com/code/raufmomin/vision-transformer-vit-from-scratch\">Vision Transformer (ViT) from Scratch</a></li><li><a href=\"https://www.kaggle.com/code/sushant097/vit-scratch-implementation-pytorch/notebook\">ViT Scratch Implementation - PyTorch</a></li><li><a href=\"https://medium.com/@manindersingh120996/building-vision-transformers-vit-from-scratch-1f46a36ed44b\">Building Vision Transformers (ViT) from Scratch | by Maninder Singh | Medium</a></li><li><a href=\"https://www.uta-net.com/song/1358/\">今井美樹 彼女と TIP ON DUO 歌詞 - 歌ネット</a></li><li><a href=\"https://www.geeksforgeeks.org/deep-learning/building-a-vision-transformer-from-scratch-in-pytorch/\">Building a Vision Transformer from Scratch in PyTorch - GeeksforGeeks</a></li><li><a href=\"https://medium.com/@akshay.m.gokhale/training-a-vision-transformer-from-scratch-on-cifar-10-7804248048d9\">Training a Vision Transformer from Scratch on CIFAR-10:No Pre-training, No Problem | by Akshay Gokhale | Medium</a></li><li><a href=\"https://www.kaggle.com/code/trnaacthng/vision-transformer-for-cifar-10\">Vision Transformer For CIFAR-10</a></li></ul></div></div>",
        "contentSnippet": "이 글은 VLM 스크래치하는 방법을 나눔한다.\n\n\n\n\n\nVLM 레퍼런스\n\nVision Language Model from scratch in Pytorch #vlm - Qiita\nAviSoori1x/seemore: From scratch implementation of a vision language model in pure PyTorch\nnanoVLM: The simplest repository to train your VLM in pure PyTorch\nhuggingface/nanoVLM: The simplest, fastest repository for training/finetuning small-sized VLMs.\nTraining a Vision Language Model from scratch (VLM multi-modal) | by Saptarshi MT | Medium\nImplementation of Vision language models (VLM) from scratch: A Technical Deep Dive. | by Achraf Abbaoui | Medium\nWiring the Multimodal Mind: Building a Vision Language Model (VLM) from Scratch - Part 1 | by Priyanthan Govindaraj | Medium\nseemore: Implement a Vision Language Model from Scratch\nVidit-Ostwal/VLM-from-scratch: This is majorly for my own learning purpose.\nBuilding a Nano Vision-Language Model from Scratch\nnipunbatra/vlm-from-scratch\nBuilding PaliGemma VLM From Scratch using Pytorch | by Shanmuka Sadhu | Jan, 2026 | Medium\nSmolVLM - small yet mighty Vision Language Model\n\nViT 레퍼런스\n\nVision Transformer (ViT) from Scratch\nViT Scratch Implementation - PyTorch\nBuilding Vision Transformers (ViT) from Scratch | by Maninder Singh | Medium\n今井美樹 彼女と TIP ON DUO 歌詞 - 歌ネット\nBuilding a Vision Transformer from Scratch in PyTorch - GeeksforGeeks\nTraining a Vision Transformer from Scratch on CIFAR-10:No Pre-training, No Problem | by Akshay Gokhale | Medium\nVision Transformer For CIFAR-10",
        "id": "tag:blogger.com,1999:blog-5201956450461596914.post-4261089744151773268",
        "isoDate": "2026-02-24T11:15:00.000Z"
      },
      {
        "title": "가우시안 스플리터의 한계와 공간모델 개발",
        "link": "http://daddynkidsmakers.blogspot.com/2026/02/blog-post_24.html",
        "pubDate": "2026-02-24T10:32:25.942Z",
        "author": "Daddy Maker",
        "content": "<div style=\"background-color: #ffffff; color: #000000;\">\n  <p>오토데스크나 제조업에서 요구하는 진정한 '공간 지능'과 '파라메트릭 CAD'를 구현하려면, AI가 단순한 점과 면(Mesh)의 집합이 아닌 B-rep(경계 표현)이나 CSG(Constructive Solid Geometry) 같은 수학적 스케치와 돌출(Extrude) 명령어 시퀀스를 생성할 수 있어야 한다.</p>\n  <p>이러한 치수 제어 및 파라메트릭 모델링, 그리고 공간 지능(LWM)을 향해 연구되고 있는 오픈소스 및 프로젝트들을 엄선해 조사했다.</p>\n\n  <p><b>1. 파라메트릭 CAD 생성 및 절차적 3D 모델 (AI to CAD)</b></p>\n  <p>단순한 메쉬(.obj)가 아니라, 치수를 조절할 수 있는 STEP 파일이나 CAD 명령어 스크립트를 생성하는 프로젝트들이다.</p>\n\n  <p><b>DeepCAD (A Deep Generative Network for CAD Models)</b></p>\n  <p>설명: 3D CAD 모델을 단순한 3D 도형이 아니라, '스케치(Profile) → 돌출(Extrude) → 필렛(Fillet)' 같은 CAD 명령어의 시퀀스로 인식하고 생성하는 선구적인 프로젝트이다. AI가 설계자의 작업 순서를 학습하여 파라메트릭 수정이 가능한 데이터를 추출한다.<br>\n  특징: 출력물이 명령어 시퀀스이므로 Fusion 360이나 SolidWorks 같은 툴에서 치수를 즉각적으로 수정할 수 있다.<br>\n  GitHub: <a href=\"https://github.com/ChrisWu1997/DeepCAD\">ChrisWu1997/DeepCAD</a></p>\n\n  <p><img src=\"https://blogger.googleusercontent.com/img/a/AVvXsEjX0fAtriavQwVltbjX0t6kZfOMH82BnXtJRMRCK2spG6IeM4deE-xOkrmpbLYgVoCo4KGxE_sEYEYkjDFiUXzHXIbsoism5BsqBCsQe3N1FExs_FpBsABZc6Yq1dG2r0em0Q70MrJ-5fI4HYe5mBF2xUMdp-t5ZkXkGsxmghUjHtv83H4lwWx028WZ745s=w500-h150\" alt=\"DeepCAD Architecture\" /><br>\n  [3D 스캔/점군] → PointNet++ → z → Decoder → [CAD 시퀀스. L | A | E(θ,φ,e1,e2)]</p>\n\n  <p><b>Zoo Text-to-CAD API</b></p>\n  <p>설명: 텍스트를 입력하면 (예: \"20개의 톱니가 있고 중심축 구멍 지름이 5mm인 기어\") 즉석에서 파라메트릭 CAD 코드(KCL - KittyCAD Language)를 생성하여 STEP, IGES 등의 포맷으로 변환해 주는 프로젝트이다.<br>\n  특징: 기하학적 제약 조건(Constraints)을 AI가 이해하고 코드로 작성하기 때문에 완벽한 치수 제어가 가능하다. 핵심 엔진 부분을 오픈소스로 공개하며 발전하고 있다.<br>\n  GitHub: <a href=\"https://github.com/KittyCAD\">Zoo-dev / kittyCAD 인프라</a></p>\n\n  <p><b>Infinigen</b></p>\n  <p>설명: 자연계와 사물을 100% 절차적(Procedural)인 수학 공식과 노드(Node) 트리로 생성해 내는 거대한 3D 프레임워크이다.<br>\n  특징: \"나뭇잎의 길이\", \"의자 다리의 두께\" 등을 파라미터(수치)로 조절할 수 있다. 가우시안 덩어리가 아니라 처음부터 수학적 규칙으로 짜인 세계를 만들기 때문에 완벽한 편집이 가능하다.<br>\n  GitHub: <a href=\"https://github.com/princeton-vl/infinigen\">princeton-vl/infinigen</a></p>\n\n  <p><b>2. 공간 지능 (Spatial Intelligence) 및 LWM(Large World Model)</b></p>\n  <p>단순한 2D의 연속이 아니라 물리적 3D 공간의 깊이, 기하학, 영속성을 이해하는 기초 모델(Foundation Model) 연구이다.</p>\n\n  <p><b>LargeWorldModel (LWM) - UC Berkeley</b></p>\n  <p>설명: 프로젝트 이름 자체가 LWM이다. 100만(1M) 토큰의 컨텍스트 창을 가진 비디오/언어 모델이다.<br>\n  특징: 긴 영상이나 여러 장의 이미지를 보고 그 안의 3D 공간 구조를 기억하고 이해한다. 당장 CAD 모델을 뱉어내는 용도는 아니지만, AI가 다중 시점을 통해 공간의 3차원적 기하학(Geometry)을 스스로 깨우치게 만드는 '공간 지능'의 가장 대표적인 베이스라인 모델이다.<br>\n  GitHub: <a href=\"https://github.com/LargeWorldModel/LWM\">LargeWorldModel/LWM</a></p>\n  <p><img src=\"https://blogger.googleusercontent.com/img/a/AVvXsEjjBjjThP6y0dy1VHdsZdirL5U26wOcN-8Mi6Wm3aGWOtdfc0ybcWvXtxaMmBX0ilFpr8TS5WWbP_zEgCyvTveJS2Txz6pbP3d5WDfQQbOVnmNNtJQVXkfUO6PPODZHsKhVv3xmSq_7yi7agFS1D9AymEnEWfIJEokbgZozvnnouL_g44CrERJPO3eMEYYd=w287-h320\" alt=\"LWM Diagram\" /></p>\n\n  <p><b>Zero123</b></p>\n  <p>설명: 단일 이미지를 보고 물체의 보이지 않는 뒷면과 다른 각도의 시점을 기하학적으로 일관되게 추론해 내는 모델이다.<br>\n  특징: 이 기술 자체는 파라메트릭 CAD가 아니지만, 2D 이미지를 3D 파라메트릭 데이터로 역설계(Reverse Engineering)하기 위해 필수적으로 거쳐야 하는 \"공간의 시점 변화 이해\"를 담당한다.<br>\n  GitHub: <a href=\"https://github.com/SUDO-AI-3D/zero123plus\">SUDO-AI-3D/zero123plus</a></p>\n  <p><img src=\"https://blogger.googleusercontent.com/img/a/AVvXsEiqTffhGf7o0o3Y_V-oHfopChvBzLMichQAZkk57UgcboWGw0K4iGSyk0uQhsU5RPOEARh3mwgelUKSjGI5jh0LgXsuuP-uOptNb0NxHgTE4e5cFvCZSi_zykpAObhGGDRMhkVcv30uTR7EPGHt4e1zKg1U3BkOHkM7_5ogiLURlQsOFqE0a_P-jnYYCu-f=w400-h300\" alt=\"Zero123 Examples\" /></p>\n\n  <p><b>현재 기술의 한계와 돌파구</b></p>\n  <p>현재의 한계 (Image to 3D): 이미지를 보고 가우시안 스플래팅이나 메쉬(OBJ)를 만드는 것은 빠르지만, 산업용 설계나 정밀한 편집에는 한계가 명확하다.<br>\n  미래의 방향 (AI to CAD): LWM과 공간 지능이 발전함에 따라, AI가 이미지를 분석한 뒤 \"이것은 반지름 5cm의 원통과 10x10의 직육면체가 결합된 형태\"라고 수학적으로 분해(CSG)하여 코드를 짜주는 방식으로 발전하고 있다. 그 선두에 DeepCAD와 Zoo(Text-to-CAD) 같은 프로젝트가 위치해 있다. 가우시안 스플래팅(3DGS)은 시각적 복원에 초점을 맞추기 때문에 스케일이 없는(Non-scale) 폴리곤 메쉬만을 생성할 뿐, 산업용으로 조작 가능한 CSG나 B-rep 데이터를 만들지 못한다.</p>\n\n  <p><b>부록: 두 방식 발전 방향</b></p>\n  <p>두 방식 중 어느 것이 '더 좋은가'는 목적에 따라 완전히 갈리며, 페이페이 리(Fei-Fei Li) 교수의 월드랩스(World Labs)가 추구하는 거대 세계 모델(LWM)의 방향성도 이 두 기술의 교차점에 있다. 이를 심층적으로 분석하고 최신 SOTA 프로젝트를 조사한다.</p>\n\n  <p><b>1. 시퀀스 생성(DeepCAD 계열) vs 시각적 렌더링(3DGS 계열) 비교</b></p>\n  <p>결론부터 말하자면, 제조/설계(AEC/CAD) 분야에서는 DeepCAD 방식이 압도적으로 우월하고, 엔터테인먼트/가상현실/로보틱스 비전 분야에서는 3DGS 방식이 절대적으로 유리하다.</p>\n  <p>먼저 DeepCAD 계열(AI to CAD Sequence)은 산업용 설계 도면을 만들어내는 데 특화되어 있다. 이 기술의 핵심 원리는 3D 형상의 겉모습만 묘사하는 것이 아니라, 대상을 모델링하기 위한 수학적 명령어의 순서를 인공지능이 직접 추론해 내는 것이다. 그 결과물은 단순한 점토 덩어리가 아니라, 실제 설계 프로그램에서 즉시 다룰 수 있는 파라메트릭 CAD 데이터(STEP, IGES, CSG 스크립트 등) 형태로 출력된다. 이 방식의 가장 큰 무기는 완벽한 절대 치수 제어와 세밀한 곡률 반경 수정이 가능하다는 점이다. 하지만 수학적인 공식으로 딱 떨어지지 않는 자연물(사람, 나무 등)이나 비정형적이고 복잡한 형상을 표현하는 데는 뚜렷한 한계를 보인다.</p>\n  <p>반면 가우시안 스플래팅(Image to 3DGS/Mesh)은 현실 세계의 시각적인 복원에 모든 초점을 맞추고 있다. 빛의 반사와 색상 정보를 지닌 무수히 많은 타원체 입자를 3D 공간에 흩뿌려 세상을 사실적으로 표현하는 것이 핵심 원리이다. 그렇기 때문에 결과물 역시 속이 꽉 찬 설계 데이터가 아니라, 텅 빈 공간에 떠 있는 포인트 클라우드나 비정형 메쉬(PLY, OBJ) 형태로 도출된다. 이 방식은 사진처럼 정밀하고 압도적인 시각 효과를 주지만, 물리적인 절대 치수(Scale) 개념이 없고 임의의 상대 비율만 존재하여 토폴로지(구조) 편집이 원천적으로 불가능하다. 따라서 0.1mm의 오차도 허용되지 않는 산업용 금형 제작이나 정밀 조립을 위한 공차 설계 등에는 사용할 수 없다.</p>\n  <p>최근의 산업 트렌드는 이 둘을 결합하여, \"3DGS로 현실 세계를 빠르게 스캔한 뒤, AI가 그 포인트 클라우드에서 기하학적 특징(원통, 평면 등)을 역산하여 CAD 시퀀스로 변환하는 방식(Scan-to-BIM / Scan-to-CAD)\"으로 진화하고 있다.</p>\n\n  <p><b>2. 각 계열의 최신 SOTA 깃허브 프로젝트</b></p>\n  \n  <p><b>A. CAD 시퀀스 및 B-rep 생성 (DeepCAD의 진화형)</b></p>\n  <p>단순히 모양을 맞추는 것을 넘어, 위상(Topology)과 스케치 제약 조건(Constraints)을 완벽하게 학습하는 모델들이다.</p>\n  <p>SkexGen (Sketch-and-Extrude Generation)<br>\n  설명: DeepCAD를 발전시켜, 트랜스포머(Transformer) 구조를 이용해 2D 스케치 프로파일과 돌출(Extrude) 파라미터를 자동 회귀(Autoregressive) 방식으로 생성하는 최신 모델이다. 토폴로지 일관성이 훨씬 뛰어나다.<br>\n  GitHub: <a href=\"https://github.com/yccyenchiao/SkexGen\">yccyenchiao/SkexGen</a></p>\n  \n  <p>Hextree / SECAD-Net<br>\n  설명: CAD 모델의 모서리(Edge)와 면(Face)의 상호작용을 그래프(Graph) 신경망으로 학습하여, 훨씬 복잡한 솔리드(Solid) 모델을 B-rep 형태로 생성해 낸다.<br>\n  GitHub: <a href=\"https://github.com/Puhao11/SECAD-Net\">Puhao11/SECAD-Net</a></p>\n\n  <p><b>B. 기하학적 정밀도를 높인 가우시안 스플래팅 (3DGS의 진화형)</b></p>\n  <p>3DGS의 단점인 '수학적 표면(Surface)이 없다'는 문제를 해결하여, 고품질의 메쉬를 뽑아내기 위한 모델들이다.</p>\n  <p>SuGaR (Surface-Aligned Gaussian Splatting)<br>\n  설명: 가우시안 타원체들이 물체의 실제 표면에 납작하게 달라붙도록 강제(Alignment)하여, 3DGS에서 아주 깔끔하고 정확한 메쉬(Mesh)를 추출해 내는 SOTA 기술이다.<br>\n  GitHub: <a href=\"https://github.com/Anttwo/SuGaR\">Anttwo/SuGaR</a></p>\n  \n  <p>2D Gaussian Splatting (2DGS)<br>\n  설명: 3D 부피를 가진 타원체 대신 2D 디스크 형태의 가우시안을 사용하여 형상의 경계와 표면을 극도로 정밀하게 재구성한다. 자율주행이나 로보틱스 매핑에 많이 쓰인다.<br>\n  GitHub: <a href=\"https://github.com/hbb1/2d-gaussian-splatting\">hbb1/2d-gaussian-splatting</a></p>\n\n  <p><b>3. 페이페이 리 교수(World Labs)의 LWM 설계 방식 추론</b></p>\n  <p>그녀는 수학적 기반의 B-rep이나 파라메트릭 CAD 전문가는 아니지만, 컴퓨터 비전(ImageNet 창시자)과 로보틱스(Embodied AI)의 권위자로서 '카메라 렌즈를 통해 3D 물리 공간의 구조와 깊이를 추론하는 방식'에는 세계 최고 수준의 이해도를 가지고 있다.</p>\n  <p>따라서 월드랩스의 LWM(마블)은 제조용 CAD 생성이 아니라, 물리 법칙이 작용하는 시뮬레이션 환경 구축에 초점을 맞추어 다음과 같이 설계될 것으로 추론된다.</p>\n  \n  <p>입력 및 추론 (2D/비디오 파운데이션 기반): 디퓨전 모델이나 트랜스포머가 단일 이미지/텍스트를 입력받아 보이지 않는 뒷면과 공간의 깊이(Depth)를 추론한다. (Zero123과 유사한 공간 상상력).<br>\n  공간의 표현 (하이브리드 3DGS/NeRF): 생성된 공간을 B-rep이나 명령어 시퀀스가 아니라, 렌더링 속도가 빠른 3DGS나 Neural Fields로 빠르게 메모리에 올린다.<br>\n  물리적 지능 부여 (Semantic &amp; Physical Grounding): 여기가 마블(Marble)의 핵심이 될 것이다. 단순한 픽셀 덩어리(3DGS)에 분할(Segmentation) 라벨을 씌워 \"이 가우시안 덩어리는 '유리'이고 깨질 수 있다\", \"저 덩어리는 '의자'이며 중력의 영향을 받는다\"라는 물리적 속성을 부여한다.<br>\n  출력 (Interactive 3D World): 치수 측정이 가능한 CAD가 아니라, 언리얼 엔진이나 오토데스크 Maya에서 즉시 카메라를 돌려보고 객체를 물리적으로 움직여볼 수 있는 '인터랙티브 3D 씬(Scene)' 자체를 내뱉는다.</p>\n  \n  <p>CAD 진영(DeepCAD)은 설계 도면을 역공학하는 방향으로 발전하고 있고, 비전 진영(World Labs, 3DGS)은 카메라에 찍힌 세상에 물리 엔진을 덧씌워 가상 현실을 창조하는 방향으로 평행선을 달리고 있다.</p>\n  <p>최근의 역설계 SOTA 모델들은 이 두 가지(신경망의 패턴 인식 + 수학적 피팅)를 하나의 파이프라인으로 합친 미분 가능한 피팅(Differentiable Fitting) 방식을 사용한다.</p>\n  <p>신경망이 점들을 분류하고 치수를 대략 추정하면, 수학적 오차(Loss)가 발생한다. 이 오차 값을 역전파(Backpropagation) 시켜서 다시 신경망을 훈련하는 구조다. 즉, AI가 단순히 '비슷하게 생겼네'하고 끝내는 것이 아니라, \"내가 예측한 원통의 반지름이 실제 스캔 점들의 분포와 수학적으로 0.2mm 오차가 있으니 가중치를 수정해야겠다\"라고 스스로 학습하는 경지에 이르렀다. (관련 대표 오픈소스: ParseNet, HPNet)</p>\n\n  <p><b>레퍼런스</b></p>\n  <p><a href=\"https://github.com/fz-20/BGPSeg\">fz-20/BGPSeg: BGPSeg: Boundary-Guided Primitive Instance Segmentation of Point Clouds</a></p>\n</div>",
        "contentSnippet": "오토데스크나 제조업에서 요구하는 진정한 '공간 지능'과 '파라메트릭 CAD'를 구현하려면, AI가 단순한 점과 면(Mesh)의 집합이 아닌 B-rep(경계 표현)이나 CSG(Constructive Solid Geometry) 같은 수학적 스케치와 돌출(Extrude) 명령어 시퀀스를 생성할 수 있어야 한다.\n이러한 치수 제어 및 파라메트릭 모델링, 그리고 공간 지능(LWM)을 향해 연구되고 있는 오픈소스 및 프로젝트들을 엄선해 조사했다.\n1. 파라메트릭 CAD 생성 및 절차적 3D 모델 (AI to CAD)\n단순한 메쉬(.obj)가 아니라, 치수를 조절할 수 있는 STEP 파일이나 CAD 명령어 스크립트를 생성하는 프로젝트들이다.\nDeepCAD (A Deep Generative Network for CAD Models)\n설명: 3D CAD 모델을 단순한 3D 도형이 아니라, '스케치(Profile) → 돌출(Extrude) → 필렛(Fillet)' 같은 CAD 명령어의 시퀀스로 인식하고 생성하는 선구적인 프로젝트이다. AI가 설계자의 작업 순서를 학습하여 파라메트릭 수정이 가능한 데이터를 추출한다.\nChrisWu1997/DeepCAD\n\nZoo Text-to-CAD API\n설명: 텍스트를 입력하면 (예: \"20개의 톱니가 있고 중심축 구멍 지름이 5mm인 기어\") 즉석에서 파라메트릭 CAD 코드(KCL - KittyCAD Language)를 생성하여 STEP, IGES 등의 포맷으로 변환해 주는 프로젝트이다.\nZoo-dev / kittyCAD 인프라\nInfinigen\n설명: 자연계와 사물을 100% 절차적(Procedural)인 수학 공식과 노드(Node) 트리로 생성해 내는 거대한 3D 프레임워크이다.\nprinceton-vl/infinigen\n2. 공간 지능 (Spatial Intelligence) 및 LWM(Large World Model)\n단순한 2D의 연속이 아니라 물리적 3D 공간의 깊이, 기하학, 영속성을 이해하는 기초 모델(Foundation Model) 연구이다.\nLargeWorldModel (LWM) - UC Berkeley\n설명: 프로젝트 이름 자체가 LWM이다. 100만(1M) 토큰의 컨텍스트 창을 가진 비디오/언어 모델이다.\nLargeWorldModel/LWM\n\nZero123\n설명: 단일 이미지를 보고 물체의 보이지 않는 뒷면과 다른 각도의 시점을 기하학적으로 일관되게 추론해 내는 모델이다.\nSUDO-AI-3D/zero123plus\n\n현재 기술의 한계와 돌파구\n현재의 한계 (Image to 3D): 이미지를 보고 가우시안 스플래팅이나 메쉬(OBJ)를 만드는 것은 빠르지만, 산업용 설계나 정밀한 편집에는 한계가 명확하다.\n부록: 두 방식 발전 방향\n두 방식 중 어느 것이 '더 좋은가'는 목적에 따라 완전히 갈리며, 페이페이 리(Fei-Fei Li) 교수의 월드랩스(World Labs)가 추구하는 거대 세계 모델(LWM)의 방향성도 이 두 기술의 교차점에 있다. 이를 심층적으로 분석하고 최신 SOTA 프로젝트를 조사한다.\n1. 시퀀스 생성(DeepCAD 계열) vs 시각적 렌더링(3DGS 계열) 비교\n결론부터 말하자면, 제조/설계(AEC/CAD) 분야에서는 DeepCAD 방식이 압도적으로 우월하고, 엔터테인먼트/가상현실/로보틱스 비전 분야에서는 3DGS 방식이 절대적으로 유리하다.\n먼저 DeepCAD 계열(AI to CAD Sequence)은 산업용 설계 도면을 만들어내는 데 특화되어 있다. 이 기술의 핵심 원리는 3D 형상의 겉모습만 묘사하는 것이 아니라, 대상을 모델링하기 위한 수학적 명령어의 순서를 인공지능이 직접 추론해 내는 것이다. 그 결과물은 단순한 점토 덩어리가 아니라, 실제 설계 프로그램에서 즉시 다룰 수 있는 파라메트릭 CAD 데이터(STEP, IGES, CSG 스크립트 등) 형태로 출력된다. 이 방식의 가장 큰 무기는 완벽한 절대 치수 제어와 세밀한 곡률 반경 수정이 가능하다는 점이다. 하지만 수학적인 공식으로 딱 떨어지지 않는 자연물(사람, 나무 등)이나 비정형적이고 복잡한 형상을 표현하는 데는 뚜렷한 한계를 보인다.\n반면 가우시안 스플래팅(Image to 3DGS/Mesh)은 현실 세계의 시각적인 복원에 모든 초점을 맞추고 있다. 빛의 반사와 색상 정보를 지닌 무수히 많은 타원체 입자를 3D 공간에 흩뿌려 세상을 사실적으로 표현하는 것이 핵심 원리이다. 그렇기 때문에 결과물 역시 속이 꽉 찬 설계 데이터가 아니라, 텅 빈 공간에 떠 있는 포인트 클라우드나 비정형 메쉬(PLY, OBJ) 형태로 도출된다. 이 방식은 사진처럼 정밀하고 압도적인 시각 효과를 주지만, 물리적인 절대 치수(Scale) 개념이 없고 임의의 상대 비율만 존재하여 토폴로지(구조) 편집이 원천적으로 불가능하다. 따라서 0.1mm의 오차도 허용되지 않는 산업용 금형 제작이나 정밀 조립을 위한 공차 설계 등에는 사용할 수 없다.\n최근의 산업 트렌드는 이 둘을 결합하여, \"3DGS로 현실 세계를 빠르게 스캔한 뒤, AI가 그 포인트 클라우드에서 기하학적 특징(원통, 평면 등)을 역산하여 CAD 시퀀스로 변환하는 방식(Scan-to-BIM / Scan-to-CAD)\"으로 진화하고 있다.\n2. 각 계열의 최신 SOTA 깃허브 프로젝트\nA. CAD 시퀀스 및 B-rep 생성 (DeepCAD의 진화형)\n단순히 모양을 맞추는 것을 넘어, 위상(Topology)과 스케치 제약 조건(Constraints)을 완벽하게 학습하는 모델들이다.\nSkexGen (Sketch-and-Extrude Generation)\nyccyenchiao/SkexGen\nHextree / SECAD-Net\nPuhao11/SECAD-Net\nB. 기하학적 정밀도를 높인 가우시안 스플래팅 (3DGS의 진화형)\n3DGS의 단점인 '수학적 표면(Surface)이 없다'는 문제를 해결하여, 고품질의 메쉬를 뽑아내기 위한 모델들이다.\nSuGaR (Surface-Aligned Gaussian Splatting)\nAnttwo/SuGaR\n2D Gaussian Splatting (2DGS)\nhbb1/2d-gaussian-splatting\n3. 페이페이 리 교수(World Labs)의 LWM 설계 방식 추론\n그녀는 수학적 기반의 B-rep이나 파라메트릭 CAD 전문가는 아니지만, 컴퓨터 비전(ImageNet 창시자)과 로보틱스(Embodied AI)의 권위자로서 '카메라 렌즈를 통해 3D 물리 공간의 구조와 깊이를 추론하는 방식'에는 세계 최고 수준의 이해도를 가지고 있다.\n따라서 월드랩스의 LWM(마블)은 제조용 CAD 생성이 아니라, 물리 법칙이 작용하는 시뮬레이션 환경 구축에 초점을 맞추어 다음과 같이 설계될 것으로 추론된다.\n입력 및 추론 (2D/비디오 파운데이션 기반): 디퓨전 모델이나 트랜스포머가 단일 이미지/텍스트를 입력받아 보이지 않는 뒷면과 공간의 깊이(Depth)를 추론한다. (Zero123과 유사한 공간 상상력).\nCAD 진영(DeepCAD)은 설계 도면을 역공학하는 방향으로 발전하고 있고, 비전 진영(World Labs, 3DGS)은 카메라에 찍힌 세상에 물리 엔진을 덧씌워 가상 현실을 창조하는 방향으로 평행선을 달리고 있다.\n최근의 역설계 SOTA 모델들은 이 두 가지(신경망의 패턴 인식 + 수학적 피팅)를 하나의 파이프라인으로 합친 미분 가능한 피팅(Differentiable Fitting) 방식을 사용한다.\n신경망이 점들을 분류하고 치수를 대략 추정하면, 수학적 오차(Loss)가 발생한다. 이 오차 값을 역전파(Backpropagation) 시켜서 다시 신경망을 훈련하는 구조다. 즉, AI가 단순히 '비슷하게 생겼네'하고 끝내는 것이 아니라, \"내가 예측한 원통의 반지름이 실제 스캔 점들의 분포와 수학적으로 0.2mm 오차가 있으니 가중치를 수정해야겠다\"라고 스스로 학습하는 경지에 이르렀다. (관련 대표 오픈소스: ParseNet, HPNet)\n레퍼런스\nfz-20/BGPSeg: BGPSeg: Boundary-Guided Primitive Instance Segmentation of Point Clouds",
        "id": "tag:blogger.com,1999:blog-5201956450461596914.post-3574650709079284629",
        "isoDate": "2026-02-24T10:32:25.942Z"
      }
    ]
  },
  {
    "name": "권용진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for boyism Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성준의 린스타트업과 디자인씽킹",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권혁우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김준형",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강동혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고종범",
    "category": "개인",
    "posts": []
  },
  {
    "name": "cheese10yun",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구자철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "FSS",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권동준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김용일",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도균",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권윤학",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김만수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "엘키",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김슬기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김광현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강명훈",
    "category": "개인",
    "posts": [
      {
        "title": "Splunk의 eval과 rex - 5th",
        "link": "https://kangmyounghun.blogspot.com/2026/02/splunk-eval-rex-5th.html",
        "pubDate": "2026-02-28T11:13:00.002Z",
        "author": "강명훈",
        "content": "줄바꿈<span style=\"font-size: x-small;\">(\\n)</span> 문자를 이용해서 두 번째 라인의 계정 정보만을 검사하는 정규표현식.<div><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgBoCH8c7TRxn2dCLQdq5LnZSBeCBty49ru1NFq2PFvTeW1kPFZ8noQ-YCuLYyiCM96HYQrkMnptn8B_CfuG47q8xj3vdvVeFxooltAz6MJYdeu3BoyBPB9QTKfy5CWAiKtmY7KYviU1ISzzicMCvto3sDJII5JU9Ask0u-93O0vYDntiYDiJ7VFcn4KlzF/s1274/regex.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"711\" data-original-width=\"1274\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgBoCH8c7TRxn2dCLQdq5LnZSBeCBty49ru1NFq2PFvTeW1kPFZ8noQ-YCuLYyiCM96HYQrkMnptn8B_CfuG47q8xj3vdvVeFxooltAz6MJYdeu3BoyBPB9QTKfy5CWAiKtmY7KYviU1ISzzicMCvto3sDJII5JU9Ask0u-93O0vYDntiYDiJ7VFcn4KlzF/s16000/regex.png\" /></a></div></div><div><br /></div><div><span><a name='more'></a></span>그런데 같은 정규표현식이 replace 처리 과정에서 동작하지 않는다. 검사가 실패한 거면 원본이라도 반환해야 하는데 그것도 없음.</div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEit7R7uHCcDl8h97nzGE9bjJfTYyxgq9QnFNzSXpaPI8rnLzS7RisnyBgQwNUMJc3j3DrZ3ekKPybWWS-WVMDFyNb8on0zIEvQQjJRlg90Yq0gJOcOx6cpYDTwGscbMEL1MGzKSZr5NUnS7ryQ8lx8uMd5moiWlxDdV3qYuTqzXFlFNCgcfSV8BElqq3obu/s1280/eval_replace.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"717\" data-original-width=\"1280\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEit7R7uHCcDl8h97nzGE9bjJfTYyxgq9QnFNzSXpaPI8rnLzS7RisnyBgQwNUMJc3j3DrZ3ekKPybWWS-WVMDFyNb8on0zIEvQQjJRlg90Yq0gJOcOx6cpYDTwGscbMEL1MGzKSZr5NUnS7ryQ8lx8uMd5moiWlxDdV3qYuTqzXFlFNCgcfSV8BElqq3obu/s16000/eval_replace.png\" /></a></div><div><br /></div><div><a href=\"https://help.splunk.com/en/splunk-enterprise/spl-search-reference/9.1/evaluation-functions/multivalue-eval-functions\" target=\"_blank\">mvmap</a>으로 다중값에 대한 개별 접근을 시도하니 원본을 반환한다. 줄바꿈 문자를 포함한 정규표현식 검사가 실패했다는 얘기.</div><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhfi_07-HZFW2hPIw5ZjyTBBaHIBl0RSObQj4KcVGEErtgLvfUYJyy0JD0lh9Yy2zn8zFxLJQ_kENl32rGACwDHerMck6afyexC2TdUI2efHdddiAn64YD6QGCELTUdTI5QS7svIGxIao-DkbkeCEmv0CQrsb7SwIXHxTsVorDkFQomaN-y0PTUa5JlIpUp/s1280/eval_mvmap.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"720\" data-original-width=\"1280\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhfi_07-HZFW2hPIw5ZjyTBBaHIBl0RSObQj4KcVGEErtgLvfUYJyy0JD0lh9Yy2zn8zFxLJQ_kENl32rGACwDHerMck6afyexC2TdUI2efHdddiAn64YD6QGCELTUdTI5QS7svIGxIao-DkbkeCEmv0CQrsb7SwIXHxTsVorDkFQomaN-y0PTUa5JlIpUp/s16000/eval_mvmap.png\" /></a></div><br /><div>줄바꿈 문자를 빼고 검사하니 두 번째 데이터가 의도대로 추출된다. 다중값은 줄 구분된 하나의 데이터가 아니라 리스트 형식으로 나열된 개별 데이터라 mvmap이 아니면 접근이 안 되고, 줄바꿈 문자로 연결할 수도 없나 보구나.</div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEifqrH7FbxAxVbHK4UQe8am-j_2-K4JYoYr16qQL0S2c-hhW6N5OTQqoRgSP26r-wOr84UF29-5aAMbVC4SjeqXIjIMveX9b208JFOyBS3r5igSjTMwfte-9qLJAEGmza7SP_pMBTrot8ffcmt5-8aMBm_91_iLkEcPpuHpo7KdLtCW809gO5NGtqFundN4/s1280/eval_mvmap2.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"720\" data-original-width=\"1280\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEifqrH7FbxAxVbHK4UQe8am-j_2-K4JYoYr16qQL0S2c-hhW6N5OTQqoRgSP26r-wOr84UF29-5aAMbVC4SjeqXIjIMveX9b208JFOyBS3r5igSjTMwfte-9qLJAEGmza7SP_pMBTrot8ffcmt5-8aMBm_91_iLkEcPpuHpo7KdLtCW809gO5NGtqFundN4/s16000/eval_mvmap2.png\" /></a></div><br /><div>결국 제일 간단한 방법은 mvindex로 다중값 중 원하는 데이터를 선택하는 것.</div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjY4_YsAnbekkcZCgN4qfBQ0Awyq_TvZsLxZwUFAX2TluA9gkkMmjyLFAU5WTwOfuV9QmwGWTtcpd7CtY-MxOj8ceo-UIa47HgNPJl9geKEZLmyZLhdA65oYJTmyl3600geGF1zDYw8hGTXxb_hl2deK9QmODLYlCBxWmGixR8S8sMJyZVHJM_cLeHgaCym/s1257/eval_replace2.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"720\" data-original-width=\"1257\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjY4_YsAnbekkcZCgN4qfBQ0Awyq_TvZsLxZwUFAX2TluA9gkkMmjyLFAU5WTwOfuV9QmwGWTtcpd7CtY-MxOj8ceo-UIa47HgNPJl9geKEZLmyZLhdA65oYJTmyl3600geGF1zDYw8hGTXxb_hl2deK9QmODLYlCBxWmGixR8S8sMJyZVHJM_cLeHgaCym/s16000/eval_replace2.png\" /></a></div><div><br /></div><div>필드값을 통째로 바꾸려면 문자열 전체를 검사해야 하고, 검사 실패 시 원본을 반환하는 replace와 달리&nbsp;<a href=\"https://help.splunk.com/en/splunk-cloud-platform/spl-search-reference/10.1.2507/search-commands/rex\" target=\"_blank\">rex</a> 명령어는 원하는 구간만 검사할 수 있고, 검사 성공 결과만을 반환하기 때문에 깔끔해서 좋다. 대신 정책 적용이 안 됨. 실시간 실행만 가능하다는 얘기<span style=\"font-size: x-small;\">(..)</span></div><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjHP9h3vb19Yon1tvxn2j05D7XKblJi8-wDFBR9XJMMCGko5oAIk0pC9ZZEfjJ1X4g5B11k-9HCLDkidJISKtoHCeV3kVc755-XTve4uDIMAtIg60wjsRyqCW6q7XsEOLanl3j2_az-rI04hZqziOgfc0GdH8blKSdG1Tb0QAHqPxIRcnaMScRckgA2rjeE/s1257/rex.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"720\" data-original-width=\"1257\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjHP9h3vb19Yon1tvxn2j05D7XKblJi8-wDFBR9XJMMCGko5oAIk0pC9ZZEfjJ1X4g5B11k-9HCLDkidJISKtoHCeV3kVc755-XTve4uDIMAtIg60wjsRyqCW6q7XsEOLanl3j2_az-rI04hZqziOgfc0GdH8blKSdG1Tb0QAHqPxIRcnaMScRckgA2rjeE/s16000/rex.png\" /></a></div><br /><h1 style=\"text-align: left;\">줄바꿈 문자 테스트</h1><div><br /></div><div>줄바꿈 문자로 구분된 다중값처럼 보이지만, 사실 다중값이 아니다.&nbsp;</div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgiTbB7cyMqWZGEMhH1iSimzNO1KkSqBsnCqRaGt_KJd9o8zISDyaBJnLm700qgF8kRKeQtymzpM7NIzQALuzs53DvfZTbGSXyj9sH72FUICW38NZj-DVkZdyi8FW-3P00jj6K5QjkQomeYAGc-2KwG9-wAHwfbfp7S7fPS7OVNGYrY_pZx3yY4DLmSlWRQ/s1228/mv_newline.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"720\" data-original-width=\"1228\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgiTbB7cyMqWZGEMhH1iSimzNO1KkSqBsnCqRaGt_KJd9o8zISDyaBJnLm700qgF8kRKeQtymzpM7NIzQALuzs53DvfZTbGSXyj9sH72FUICW38NZj-DVkZdyi8FW-3P00jj6K5QjkQomeYAGc-2KwG9-wAHwfbfp7S7fPS7OVNGYrY_pZx3yY4DLmSlWRQ/s16000/mv_newline.png\" /></a></div><div><br /></div><div>그래서 줄바꿈 문자로 연결 검사 가능.</div><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjoJzGISHD29ixl1sZWHl8i3jf0UNiG8qu-IHNBHDnwSbqtBSfusn33awM5_3P82KIA4WyOzX91RzxU0g_0sJkD3Srxxky8FInhhpee96fVj5I8-9a8WzfaW7obdFePP1rCE7deCjU-7y-yevODiNaIXr_SnchhMuvbAR2deMpQHs9GANMof9EbejjV6AeU/s1228/mv_newline2.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"720\" data-original-width=\"1228\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjoJzGISHD29ixl1sZWHl8i3jf0UNiG8qu-IHNBHDnwSbqtBSfusn33awM5_3P82KIA4WyOzX91RzxU0g_0sJkD3Srxxky8FInhhpee96fVj5I8-9a8WzfaW7obdFePP1rCE7deCjU-7y-yevODiNaIXr_SnchhMuvbAR2deMpQHs9GANMof9EbejjV6AeU/s16000/mv_newline2.png\" /></a></div><br /><div>여러 단계의 전처리를 거쳐야 하는&nbsp;<a href=\"https://kangmyounghun.blogspot.com/2025/10/splunk.html\" target=\"_blank\">6단계<span style=\"font-size: x-small;\">(계산 필드 정책)</span></a>가 귀찮다면 2 단계에서 처리하는 게 대안이 될 수 있다. 2 단계는 리스트 형식의 다중값 필드 구조 완성 전이라 줄바꿈 문자도 사용 가능.</div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEimKu_9GLsxKY9be8j3QbOQcQmeJiHggLovunr9K9VqK4vy5bGxO02NbrMEuTKDd3-0Isno7Cw2iSEcFM4qLRADqOUbm15I1lEliohdPNzn4LyPCLc354-uUvyL02Px-NSyCQXCU_4Mc5lBdIVIL8mBjRM1I5ycLxLZ1ffVWnL772HU7uRh65Mmv7r8qvMJ/s1258/props_transforms.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"720\" data-original-width=\"1258\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEimKu_9GLsxKY9be8j3QbOQcQmeJiHggLovunr9K9VqK4vy5bGxO02NbrMEuTKDd3-0Isno7Cw2iSEcFM4qLRADqOUbm15I1lEliohdPNzn4LyPCLc354-uUvyL02Px-NSyCQXCU_4Mc5lBdIVIL8mBjRM1I5ycLxLZ1ffVWnL772HU7uRh65Mmv7r8qvMJ/s16000/props_transforms.png\" /></a></div><div><br /></div><div><div><b>관련 글</b></div><div><ul><li><a href=\"https://kangmyounghun.blogspot.com/2024/06/splunk-eval-rex-4th.html\">Splunk의 eval과 rex - 4th</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2021/08/splunk-eval-rex.html\">Splunk의 eval과 rex</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2024/02/splunk_25.html\">Splunk의 조건문</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2024/08/splunk-dedup.html\">Splunk의 dedup</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2026/01/splunk-xml.html\">Splunk의 xml 처리</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2024/08/blog-post_22.html\">Splunk의 비율 계산</a></li></ul></div></div>",
        "contentSnippet": "줄바꿈(\\n) 문자를 이용해서 두 번째 라인의 계정 정보만을 검사하는 정규표현식.\n\n\n\n\n그런데 같은 정규표현식이 replace 처리 과정에서 동작하지 않는다. 검사가 실패한 거면 원본이라도 반환해야 하는데 그것도 없음.\n\n\n\n\n\nmvmap으로 다중값에 대한 개별 접근을 시도하니 원본을 반환한다. 줄바꿈 문자를 포함한 정규표현식 검사가 실패했다는 얘기.\n\n\n\n줄바꿈 문자를 빼고 검사하니 두 번째 데이터가 의도대로 추출된다. 다중값은 줄 구분된 하나의 데이터가 아니라 리스트 형식으로 나열된 개별 데이터라 mvmap이 아니면 접근이 안 되고, 줄바꿈 문자로 연결할 수도 없나 보구나.\n\n\n\n\n결국 제일 간단한 방법은 mvindex로 다중값 중 원하는 데이터를 선택하는 것.\n\n\n\n\n\n필드값을 통째로 바꾸려면 문자열 전체를 검사해야 하고, 검사 실패 시 원본을 반환하는 replace와 달리 rex 명령어는 원하는 구간만 검사할 수 있고, 검사 성공 결과만을 반환하기 때문에 깔끔해서 좋다. 대신 정책 적용이 안 됨. 실시간 실행만 가능하다는 얘기(..)\n\n\n\n줄바꿈 문자 테스트\n\n\n줄바꿈 문자로 구분된 다중값처럼 보이지만, 사실 다중값이 아니다. \n\n\n\n\n\n그래서 줄바꿈 문자로 연결 검사 가능.\n\n\n\n여러 단계의 전처리를 거쳐야 하는 6단계(계산 필드 정책)가 귀찮다면 2 단계에서 처리하는 게 대안이 될 수 있다. 2 단계는 리스트 형식의 다중값 필드 구조 완성 전이라 줄바꿈 문자도 사용 가능.\n\n\n\n\n\n관련 글\n\nSplunk의 eval과 rex - 4th\nSplunk의 eval과 rex\nSplunk의 조건문\nSplunk의 dedup\nSplunk의 xml 처리\nSplunk의 비율 계산",
        "id": "tag:blogger.com,1999:blog-2597780270996323853.post-3991433145679089428",
        "isoDate": "2026-02-28T11:13:00.002Z"
      }
    ]
  },
  {
    "name": "김민장",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성중",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구교준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고명환",
    "category": "개인",
    "posts": [
      {
        "creator": "고명환",
        "title": "스타트업 수익 창출을 위한 초기 비즈니스 모델 설계 - 창업(스타트업",
        "link": "https://brunch.co.kr/@@LOc/335",
        "pubDate": "Fri, 27 Feb 2026 03:23:08 GMT",
        "author": "고명환",
        "content": "1. 배경 : 왜 지금 '수익 창출'이 중요한가?  과거에는 가입자 수만 많으면 적자가 나도 투자를 받을 수 있었습니다. 하지만 최근 유명 플랫폼들의 연쇄 파산 사태 이후 시장의 분위기는 완전히 바뀌었습니다. 이제 투자자들은 &quot;나중에 어떻게 돈 벌 건가요?&quot;가 아니라 &quot;지금 어떻게 돈을 벌고 있나요?&quot;를 묻습니다. 투자가 끊겨도 회사가 돌아갈 수 있는 '생<img src= \"https://img1.kakaocdn.net/thumb/R1280x0/?fname=http%3A%2F%2Ft1.kakaocdn.net%2Fbrunch%2Fservice%2Fuser%2FLOc%2Fimage%2FEPjpNBu_Ix8oWzC1DdwjG6cBckc.jpg\" width=\"500\" />",
        "contentSnippet": "1. 배경 : 왜 지금 '수익 창출'이 중요한가?  과거에는 가입자 수만 많으면 적자가 나도 투자를 받을 수 있었습니다. 하지만 최근 유명 플랫폼들의 연쇄 파산 사태 이후 시장의 분위기는 완전히 바뀌었습니다. 이제 투자자들은 \"나중에 어떻게 돈 벌 건가요?\"가 아니라 \"지금 어떻게 돈을 벌고 있나요?\"를 묻습니다. 투자가 끊겨도 회사가 돌아갈 수 있는 '생",
        "guid": "https://brunch.co.kr/@@LOc/335",
        "isoDate": "2026-02-27T03:23:08.000Z"
      },
      {
        "creator": "고명환",
        "title": "모두의 창업 프로젝트 최대 10억원까지 받는 법 - 창업(스타트업)",
        "link": "https://brunch.co.kr/@@LOc/334",
        "pubDate": "Thu, 26 Feb 2026 07:50:56 GMT",
        "author": "고명환",
        "content": "1. 배경 : 왜 모두의 창업 프로젝트가 중요한가요?  2026년 정부는 일자리를 '찾는 시대'에서 스스로 '만드는 시대'로의 패러다임 전환을 선언했습니다. 그 핵심이 바로&nbsp;모두의 창업 프로젝트입니다. 기존 지원 사업들이 이미 사업자 등록을 마친 기업 중심이었다면, 이번 프로젝트는 아직 사업을 시작하지 않은 일반인과 예비 창업자에게 문턱을 낮춘 것이 특징입<img src= \"https://img1.kakaocdn.net/thumb/R1280x0/?fname=http%3A%2F%2Ft1.kakaocdn.net%2Fbrunch%2Fservice%2Fuser%2FLOc%2Fimage%2FAcUCSqSASm3cNhhh5ux-90zr62Q.jpg\" width=\"500\" />",
        "contentSnippet": "1. 배경 : 왜 모두의 창업 프로젝트가 중요한가요?  2026년 정부는 일자리를 '찾는 시대'에서 스스로 '만드는 시대'로의 패러다임 전환을 선언했습니다. 그 핵심이 바로 모두의 창업 프로젝트입니다. 기존 지원 사업들이 이미 사업자 등록을 마친 기업 중심이었다면, 이번 프로젝트는 아직 사업을 시작하지 않은 일반인과 예비 창업자에게 문턱을 낮춘 것이 특징입",
        "guid": "https://brunch.co.kr/@@LOc/334",
        "isoDate": "2026-02-26T07:50:56.000Z"
      },
      {
        "creator": "고명환",
        "title": "셀프 서빙 식당 고객 관리, 고객 만족도 높이는 방법 - 창업(소상공인)",
        "link": "https://brunch.co.kr/@@LOc/333",
        "pubDate": "Wed, 25 Feb 2026 02:10:12 GMT",
        "author": "고명환",
        "content": "1. 배경 : 왜 무인 매장일수록 소통이 &nbsp;중요할까?  최근 인건비 상승과 구인난으로 인해&nbsp;무인 매장 고객 소통의 중요성이 날로 커지고 있습니다. 직원이 없는 셀프 서빙 식당은 운영 효율은 높지만, 고객 입장에서는 '방치되었다'는 느낌을 받기 쉽습니다. 이러한 심리적 거리감은 작은 불편함에도 고객이 쉽게 이탈하는 원인이 됩니다. 하지만 반대로 비대면 환경에<img src= \"https://img1.kakaocdn.net/thumb/R1280x0/?fname=http%3A%2F%2Ft1.kakaocdn.net%2Fbrunch%2Fservice%2Fuser%2FLOc%2Fimage%2F_61rNkk_mMW9bIfgmtkFHtzcoSo.jpg\" width=\"500\" />",
        "contentSnippet": "1. 배경 : 왜 무인 매장일수록 소통이  중요할까?  최근 인건비 상승과 구인난으로 인해 무인 매장 고객 소통의 중요성이 날로 커지고 있습니다. 직원이 없는 셀프 서빙 식당은 운영 효율은 높지만, 고객 입장에서는 '방치되었다'는 느낌을 받기 쉽습니다. 이러한 심리적 거리감은 작은 불편함에도 고객이 쉽게 이탈하는 원인이 됩니다. 하지만 반대로 비대면 환경에",
        "guid": "https://brunch.co.kr/@@LOc/333",
        "isoDate": "2026-02-25T02:10:12.000Z"
      },
      {
        "creator": "고명환",
        "title": "글로벌 고객이 찾아오는 구글맵 리뷰 전략 - 창업(소상공인)",
        "link": "https://brunch.co.kr/@@LOc/332",
        "pubDate": "Tue, 24 Feb 2026 06:43:37 GMT",
        "author": "고명환",
        "content": "1. 배경 : 왜 지금 구글맵에 주목해야 할까요?  과거에는 구글맵이 주로 해외여행이나 외국인 관광객을 위한 지도였다면, 최근 분위기는 완전히 달라졌습니다. 국내에서도 안드로이드폰 기본 탑재와 더불어, 광고성 정보가 적고 신뢰할 수 있다는 인식 덕분에 MZ세대를 중심으로 '진짜 맛집' 검색 도구로 자리 잡고 있습니다. 특히 엔데믹 이후 급증한 외국인 관광객<img src= \"https://img1.kakaocdn.net/thumb/R1280x0/?fname=http%3A%2F%2Ft1.kakaocdn.net%2Fbrunch%2Fservice%2Fuser%2FLOc%2Fimage%2FgQUA5hftHFIU-HFApDXYcAbYEgg.png\" width=\"500\" />",
        "contentSnippet": "1. 배경 : 왜 지금 구글맵에 주목해야 할까요?  과거에는 구글맵이 주로 해외여행이나 외국인 관광객을 위한 지도였다면, 최근 분위기는 완전히 달라졌습니다. 국내에서도 안드로이드폰 기본 탑재와 더불어, 광고성 정보가 적고 신뢰할 수 있다는 인식 덕분에 MZ세대를 중심으로 '진짜 맛집' 검색 도구로 자리 잡고 있습니다. 특히 엔데믹 이후 급증한 외국인 관광객",
        "guid": "https://brunch.co.kr/@@LOc/332",
        "isoDate": "2026-02-24T06:43:37.000Z"
      },
      {
        "creator": "고명환",
        "title": "수익 구조가 바뀌는 실전 외식업 메뉴 엔지니어링 - 창업(소상공인)",
        "link": "https://brunch.co.kr/@@LOc/331",
        "pubDate": "Mon, 23 Feb 2026 04:23:43 GMT",
        "author": "고명환",
        "content": "1. 배경 : 왜 메뉴 구성이 중요한가  음식점 경영에서 메뉴판은 단순한 안내판이 아니라 가장 강력한 마케팅 도구이자 설계도입니다. 많은 사장님이 '내가 잘하는 음식'을 모두 나열하기만 하지만, 이는 재고 관리의 어려움과 수익성 저하로 이어집니다. 메뉴 구성 전략이 잘 짜여 있으면 손님의 주문 고민 시간은 짧아지고, 주방의 조리 효율은 높아지며, 최종적으로<img src= \"https://img1.kakaocdn.net/thumb/R1280x0/?fname=http%3A%2F%2Ft1.kakaocdn.net%2Fbrunch%2Fservice%2Fuser%2FLOc%2Fimage%2FKuf8342ugCJ6AT-PNVk8XCTX8Nw.png\" width=\"500\" />",
        "contentSnippet": "1. 배경 : 왜 메뉴 구성이 중요한가  음식점 경영에서 메뉴판은 단순한 안내판이 아니라 가장 강력한 마케팅 도구이자 설계도입니다. 많은 사장님이 '내가 잘하는 음식'을 모두 나열하기만 하지만, 이는 재고 관리의 어려움과 수익성 저하로 이어집니다. 메뉴 구성 전략이 잘 짜여 있으면 손님의 주문 고민 시간은 짧아지고, 주방의 조리 효율은 높아지며, 최종적으로",
        "guid": "https://brunch.co.kr/@@LOc/331",
        "isoDate": "2026-02-23T04:23:43.000Z"
      }
    ]
  },
  {
    "name": "강성희",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강병수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김봉현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강형석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수로",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강미경",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강진우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권민재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태관",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도곤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "칡토스의 게임 개발",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "프리웨어 이야기",
    "category": "개인",
    "posts": [
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "ChatGPT, Gemini보다 강할 때? Claude가 빛을 발하는 5가지 핵심 업무",
        "link": "https://muzbox.tistory.com/483710",
        "pubDate": "Mon, 23 Feb 2026 11:35:25 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "https://muzbox.tistory.com/483710#entry483710comment",
        "content": "<div style=\"font-family: 'Noto Sans KR', sans-serif; line-height: 1.6; max-width: 800px; margin: 0 auto; font-size: 16px; box-sizing: border-box; color: #3c4043;\">\n<div style=\"background-color: #e8f4fd; padding: 15px; border-radius: 8px; font-style: italic; margin-bottom: 25px; font-size: 15px;\">안녕하세요! 생성형 AI를 업무에 활용하는 분들이라면 늘 고민하실 거예요. \"어떤 AI를 써야 가장 효율적일까?\" 특히 ChatGPT와 Gemini가 워낙 유명하다 보니, Claude는 과연 어떤 특별한 강점이 있을지 궁금해하시는 분들이 많죠. 오늘은 2026년 최신 벤치마크 데이터를 바탕으로, Claude가 다른 모델들보다 확실히 빛을 발하는 5가지 핵심 업무를 깊이 있게 분석해 보려 해요. 제 경험을 섞어 가면서, 여러분의 AI 선택에 실질적인 도움을 드릴 수 있도록 노력해 보겠습니다!</div>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"프로그래머의 손이 코드를 입력하고 금융 차트와 디지털 문서가 보이는 미래형 작업 공간. Claude의 코딩, 금융 분석, 문서 처리 강점을 나타내는 이미지..jpeg\" data-origin-width=\"1200\" data-origin-height=\"1200\"><span data-url=\"https://blog.kakaocdn.net/dn/CGe2u/dJMcadntMtA/PTmf5YHBxy3t3EiALHqthk/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/CGe2u/dJMcadntMtA/PTmf5YHBxy3t3EiALHqthk/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/CGe2u/dJMcadntMtA/PTmf5YHBxy3t3EiALHqthk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FCGe2u%2FdJMcadntMtA%2FPTmf5YHBxy3t3EiALHqthk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"프로그래머의 손이 코드를 입력하고 금융 차트와 디지털 문서가 보이는 미래형 작업 공간. Claude의 코딩, 금융 분석, 문서 처리 강점을 나타내는 이미지.\" loading=\"lazy\" width=\"500\" height=\"500\" data-filename=\"프로그래머의 손이 코드를 입력하고 금융 차트와 디지털 문서가 보이는 미래형 작업 공간. Claude의 코딩, 금융 분석, 문서 처리 강점을 나타내는 이미지..jpeg\" data-origin-width=\"1200\" data-origin-height=\"1200\"/></span></figure>\n\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">생성형 AI 시장은 이제 단순히 '더 좋은 AI'를 찾는 단계를 넘어섰어요. 이제는 <b>'특정 상황에서 어떤 모델이 최적인가'</b>를 고민해야 하는 시대가 된 거죠. 2026년 2월 현재, 주요 AI 모델들의 발전 속도를 보면 정말 놀랍습니다.</p>\n<p style=\"margin-bottom: 20;\" data-ke-size=\"size16\">간단히 주요 플레이어와 최신 모델들을 살펴볼까요?</p>\n<table style=\"width: 100%; border-collapse: collapse; margin-bottom: 25px; border: 1px solid #dadce0;\" data-ke-align=\"alignLeft\">\n<thead style=\"background-color: #e8eaed;\">\n<tr>\n<th style=\"padding: 12px; border: 1px solid #dadce0; text-align: left; color: #3c4043;\">회사</th>\n<th style=\"padding: 12px; border: 1px solid #dadce0; text-align: left; color: #3c4043;\">최신 모델 (2026년 기준)</th>\n<th style=\"padding: 12px; border: 1px solid #dadce0; text-align: left; color: #3c4043;\">주요 특징</th>\n</tr>\n</thead>\n<tbody>\n<tr style=\"background-color: white;\">\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\"><b>OpenAI</b></td>\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">GPT-5.2 / GPT-5.3 Codex</td>\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">균형 잡힌 성능, 빠른 응답 속도</td>\n</tr>\n<tr style=\"background-color: #f1f3f4;\">\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\"><b>Google</b></td>\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">Gemini 3.1 Pro</td>\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">추상 추론 강화, 과학 문제 해결 특화</td>\n</tr>\n<tr style=\"background-color: white;\">\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\"><b>Anthropic</b></td>\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">Claude Opus 4.6 / Sonnet 4.5</td>\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">코딩 최강, 금융 분석 최고</td>\n</tr>\n</tbody>\n</table>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이 강력한 AI 라인업 속에서, 과연 <b>Claude가 특별히 빛을 발하는 순간은 언제일까요?</b> 제가 직접 여러 프로젝트에서 사용해 본 경험과 함께, 최신 벤치마크 데이터를 토대로 Claude의 진정한 강점을 파헤쳐 보겠습니다.</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>1.   코딩 및 소프트웨어 개발: Claude의 독주</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">개발자라면 이 부분에 특히 주목해야 합니다. 2026년 현재, 코딩 분야에서 Claude의 성능은 정말 압도적이라고 해도 과언이 아니에요. 특히 <b>Claude Sonnet 4.5</b>와 <b>Opus 4.6</b>은 개발 워크플로우를 혁신적으로 바꿔놓을 잠재력을 가지고 있습니다.</p>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px; border-bottom: 2px solid #e8f0fe; padding-bottom: 5px;\" data-ke-size=\"size23\"><b>  최신 성능 지표가 말해주는 Claude의 힘</b></h3>\n<ul style=\"margin-bottom: 20px; padding-left: 20px;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 8px;\"><b>SWE-Bench Verified: 77.2%</b> &mdash; 이는 실제 소프트웨어 엔지니어링 벤치마크에서 높은 수준의 문제 해결 능력을 보여준다는 의미입니다.</li>\n<li style=\"margin-bottom: 8px;\">실제 GitHub 이슈 해결 성공률 <b>77% 향상</b> &mdash; 실제 오픈소스 프로젝트에 기여하는 데 얼마나 유용한지 보여주는 지표죠.</li>\n<li style=\"margin-bottom: 8px;\">복잡한 코드 리팩토링 작업 최대 <b>10배 빠름</b> &mdash; 개발 생산성에 엄청난 영향을 미칩니다.</li>\n<li style=\"margin-bottom: 8px;\"><b>Claude Code 2.0 지원</b> &mdash; 자동 체크포인트, 실행 취소(Undo), IDE 통합 등 개발 편의성을 대폭 개선했습니다.</li>\n</ul>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">대규모 코드베이스를 다루거나, 복잡한 시스템의 아키텍처를 이해하고 수정해야 할 때 Claude의 진가가 발휘되곤 합니다. 제가 직접 경험해본 바로는, 특히 수십만 라인에 달하는 레거시 코드를 분석하고 리팩토링할 때 Claude만큼 똑똑하고 끈기 있는 비서가 없었어요.</p>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px; border-bottom: 2px solid #e8f0fe; padding-bottom: 5px;\" data-ke-size=\"size23\"><b>  왜 Claude가 코딩에 유리한가?</b></h3>\n<ol style=\"margin-bottom: 20px; padding-left: 20px;\" data-ke-list-type=\"decimal\">\n<li style=\"margin-bottom: 8px;\"><b>긴 컨텍스트 처리 능력:</b> 방대한 코드 파일을 한 번에 읽고 맥락을 이해하는 능력이 탁월합니다.</li>\n<li style=\"margin-bottom: 8px;\"><b>코드 구조 전체 파악 및 리팩토링 능력:</b> 단순히 오류를 수정하는 것을 넘어, 전체적인 코드 품질과 설계를 개선하는 데 도움을 줍니다.</li>\n<li style=\"margin-bottom: 8px;\"><b>테스트 케이스 생성 정확도:</b> 버그를 찾고 예방하는 데 필수적인 고품질 테스트 코드를 효과적으로 생성해요.</li>\n<li style=\"margin-bottom: 8px;\"><b>버그 재현 및 원인 추적 정밀도:</b> 복잡한 버그의 발생 조건을 분석하고 근본 원인을 찾아내는 데 뛰어납니다.</li>\n</ol>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"개발자의 손이 파란색과 회색 테마의 코드 편집기에서 복잡한 코드를 입력하는 모습. Claude의 강력한 코딩 능력을 시각화.jpeg\" data-origin-width=\"1344\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/rq6Wo/dJMcaaj18Ze/L1I80hk3GLStNE6yZ187Y0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/rq6Wo/dJMcaaj18Ze/L1I80hk3GLStNE6yZ187Y0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/rq6Wo/dJMcaaj18Ze/L1I80hk3GLStNE6yZ187Y0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Frq6Wo%2FdJMcaaj18Ze%2FL1I80hk3GLStNE6yZ187Y0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"개발자의 손이 파란색과 회색 테마의 코드 편집기에서 복잡한 코드를 입력하는 모습. Claude의 강력한 코딩 능력을 시각화.\" loading=\"lazy\" width=\"1344\" height=\"768\" data-filename=\"개발자의 손이 파란색과 회색 테마의 코드 편집기에서 복잡한 코드를 입력하는 모습. Claude의 강력한 코딩 능력을 시각화.jpeg\" data-origin-width=\"1344\" data-origin-height=\"768\"/></span></figure>\n\n<div style=\"background-color: #e8f4fd; border-left: 4px solid #1a73e8; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">  <b>팁:</b> GPT-5.3 Codex도 코딩 벤치마크에서 77.3%라는 높은 점수를 기록하며 강력한 보조 선택지로 꼽히지만, 대형 프로젝트에서 긴 맥락을 안정적으로 유지하며 작업하는 측면에서는 Claude가 더 신뢰할 만하다는 평가가 지배적입니다. 복잡하고 큰 규모의 프로젝트라면 Claude를 먼저 고려해 보세요!</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>2.   금융 분석 및 비즈니스 인텔리전스: Claude Opus 4.6의 특화 영역</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">금융 분야는 정말 섬세하고 복잡한 데이터 처리가 필요한 영역이잖아요. 그런데 Claude는 이 분야에서 <b>독보적인 성능</b>을 보여주고 있습니다. 특히 <b>Claude Opus 4.6</b>은 금융 전문가들에게 강력한 도구가 될 것이라고 생각해요. 저도 최근에 재무 보고서 분석에 Claude를 활용해봤는데, 정말 놀라웠어요.</p>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px; border-bottom: 2px solid #e8f0fe; padding-bottom: 5px;\" data-ke-size=\"size23\"><b>  Finance Agent 벤치마크 1위!</b></h3>\n<ul style=\"margin-bottom: 20px; padding-left: 20px;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 8px;\">복잡한 재무 문서(IR 자료, 애널리스트 보고서 등)의 완벽한 처리 능력</li>\n<li style=\"margin-bottom: 8px;\">다중 보고서 간의 심층적인 비교 분석</li>\n<li style=\"margin-bottom: 8px;\">현금흐름표, 손익계산서, 대차대조표의 <b>교차 해석</b> 및 인사이트 도출</li>\n<li style=\"margin-bottom: 8px;\"><b>Claude for Excel beta 지원:</b> Excel 통합으로 재무 데이터 작업 효율 극대화</li>\n</ul>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">다른 모델들도 물론 재무 데이터를 다룰 수 있지만, <b>대규모 재무 보고서를 통째로 업로드해서 수많은 세부 조항들 간의 논리적 연결을 추적하고, 나아가 정성적인 리스크 분석까지 수행하는 능력</b>은 Claude Opus 4.6이 단연 최고였습니다. 저는 복잡한 기업공개(IPO) 문서 분석에 활용하면서 시간을 정말 많이 절약할 수 있었어요.</p>\n<div style=\"background-color: #e8f4fd; border-left: 4px solid #1a73e8; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">  <b>주목:</b> Gemini 3.1 Pro가 추상 추론에 강하고, GPT-5.2도 균형 잡힌 분석을 제공하지만, 금융 특화 벤치마크에서는 Claude Opus 4.6이 <b>가장 높은 점수</b>를 기록하며 이 분야의 강자로 자리매김했습니다. 투자를 하시거나 기업 전략을 세우시는 분들이라면 꼭 활용해보세요!</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>3.   장문 분석 및 대규모 문서 처리: Claude의 전통적 강점</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">Claude는 초기 모델부터 <b>압도적인 컨텍스트 창(context window)</b>이 가장 큰 장점으로 꼽혔습니다. 2026년에도 이 강점은 여전히 유효하고, 오히려 더욱 강력해졌습니다. 방대한 양의 텍스트를 한 번에 처리해야 하는 작업이 많다면 Claude가 아주 좋은 선택지가 될 거예요.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"여러 화면에 금융 보고서와 법률 문서가 가득한 디지털 문서를 분석하는 사람. Claude의 장문 문서 처리 능력을 상징..jpeg\" data-origin-width=\"1344\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/bkm4ta/dJMcagduEOK/uTcK151dD1mgODgeHO3i3K/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bkm4ta/dJMcagduEOK/uTcK151dD1mgODgeHO3i3K/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bkm4ta/dJMcagduEOK/uTcK151dD1mgODgeHO3i3K/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbkm4ta%2FdJMcagduEOK%2FuTcK151dD1mgODgeHO3i3K%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"여러 화면에 금융 보고서와 법률 문서가 가득한 디지털 문서를 분석하는 사람. Claude의 장문 문서 처리 능력을 상징.\" loading=\"lazy\" width=\"1344\" height=\"768\" data-filename=\"여러 화면에 금융 보고서와 법률 문서가 가득한 디지털 문서를 분석하는 사람. Claude의 장문 문서 처리 능력을 상징..jpeg\" data-origin-width=\"1344\" data-origin-height=\"768\"/></span></figure>\n\n<ul style=\"margin-bottom: 20px; padding-left: 20px;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 8px;\">대규모 연구 논문 수십 편을 한 번에 분석하고 핵심 요약</li>\n<li style=\"margin-bottom: 8px;\">100페이지가 넘는 법률 계약서 또는 정책 문서 검토</li>\n<li style=\"margin-bottom: 8px;\">수십 개의 보고서를 동시에 비교하고 공통점 및 차이점 도출</li>\n<li style=\"margin-bottom: 8px;\">기업 내부 문서들을 기반으로 한 지식베이스 구축</li>\n</ul>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">ChatGPT와 Gemini도 물론 문서 처리가 가능하지만, <b>'이 10개 문서에서 공통 리스크 요소만 추출하고, 연도별 변화까지 분석해줘'</b>와 같이 복합적이고 심층적인 질의를 할 때는 Claude가 훨씬 더 안정적이고 정확한 결과를 내놓는다는 것을 저도 여러 번 경험했습니다. 특히 중요한 문서일수록 AI의 안정성은 정말 중요하죠.</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>4. ✍️ 창의적 작업: 정교함이 필요할 땐 Claude Sonnet 4.5</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">창의적 작업이라고 하면 GPT가 먼저 떠오르실 수도 있습니다. 실제로 GPT-5.2는 빠른 응답 속도, 자연스러운 문체, 실시간 음성 기능, 그리고 Prism 협업 리서치 도구 등을 통해 초안 작성에 매우 유리한 강점을 가지고 있죠. 하지만 <b>'정교함'과 '안정적인 논리 구조'</b>가 핵심이라면 이야기가 달라집니다. 여기서 Claude Sonnet 4.5가 빛을 발합니다.</p>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px; border-bottom: 2px solid #e8f0fe; padding-bottom: 5px;\" data-ke-size=\"size23\"><b>  Claude의 창의성, 어떤 면이 특별할까요?</b></h3>\n<ul style=\"margin-bottom: 20px; padding-left: 20px;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 8px;\">더 <b>정교한 창작물</b> 생성: 특히 기술 블로그, 전문 리포트, 백서와 같은 형식을 요구하는 작업에서 탁월합니다.</li>\n<li style=\"margin-bottom: 8px;\"><b>전문 문서 작성에 강점:</b> 복잡한 정보를 체계적으로 정리하고, 설득력 있는 논리를 전개하는 데 강해요.</li>\n<li style=\"margin-bottom: 8px;\">슬라이드 및 애니메이션 생성 최적화: 시각적인 자료 제작을 위한 아이디어 구상과 내용 구성에 도움을 줍니다.</li>\n<li style=\"margin-bottom: 8px;\"><b>논리적 구조가 안정적:</b> 길고 복잡한 글에서도 일관된 논리 흐름을 유지합니다.</li>\n</ul>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">제 경험상, <b>빠른 아이데이션이나 초안 작성은 GPT-5.2</b>에 맡기고, <b>정밀하고 완성도 높은 기술 문서나 보고서 작성은 Claude Sonnet 4.5</b>에 맡기는 것이 가장 효율적인 조합이었습니다. 마치 빠른 스케치에는 연필을, 최종 작품에는 유화를 쓰는 것과 비슷한 느낌이랄까요?</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>5. ⚡ 속도와 비용 효율: 경량 모델의 활약</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">모든 작업에 최고 성능의 모델만 사용할 수는 없죠. 특히 속도가 중요하거나 비용 절감이 핵심이라면, 경량화된 모델들을 고려하는 것이 현명합니다. 이 부분에서는 Claude보다는 다른 모델들이 강점을 보입니다.</p>\n<table style=\"width: 100%; border-collapse: collapse; margin-bottom: 25px; border: 1px solid #dadce0;\" data-ke-align=\"alignLeft\">\n<thead style=\"background-color: #e8eaed;\">\n<tr>\n<th style=\"padding: 12px; border: 1px solid #dadce0; text-align: left; color: #3c4043;\">모델</th>\n<th style=\"padding: 12px; border: 1px solid #dadce0; text-align: left; color: #3c4043;\">특징</th>\n</tr>\n</thead>\n<tbody>\n<tr style=\"background-color: white;\">\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">GPT-5.2 Instant</td>\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">빠른 응답 속도, 저비용으로 일반적인 작업에 효율적</td>\n</tr>\n<tr style=\"background-color: #f1f3f4;\">\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">Gemini Flash</td>\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">가성비 최고, 빠르고 경제적인 선택지</td>\n</tr>\n<tr style=\"background-color: white;\">\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">Claude Haiku</td>\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">경량 모델, 빠른 응답과 효율성 추구</td>\n</tr>\n</tbody>\n</table>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">Claude도 Haiku라는 경량 모델을 가지고 있지만, 범용적인 빠른 처리와 비용 효율성 측면에서는 아직 GPT-5.2 Instant나 Gemini Flash가 더 경쟁력이 있다는 것이 제 생각입니다. 정말 급하거나 가볍게 테스트할 때는 이 모델들을 활용하는 것이 좋아요.</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  번외: 수학 및 추상적 논리 문제: Gemini의 영역</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이 부분은 Claude가 강하기보다는 Gemini가 압도적인 영역이라 잠시 짚고 넘어가고 싶었어요. 복잡한 알고리즘 문제, 수학 증명, 추상 패턴 인식과 같은 순수 추론 영역에서는 <b>Gemini 3.1 Pro</b>가 가장 높은 평균 점수를 기록하고 있습니다. Claude도 물론 강력하지만, 이 분야에서는 Gemini가 근소하게 앞서고 있다는 점을 기억해두시면 좋습니다.</p>\n<div style=\"background-color: #fce8e6; border-left: 4px solid #d93025; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">⚠️ <b>주의:</b> 복잡한 수학 문제나 고도의 추상적 논리 추론이 필요한 경우, Claude보다는 Gemini 3.1 Pro가 더 신뢰할 수 있는 결과를 제공할 가능성이 높습니다. 목적에 맞는 도구를 선택하는 것이 중요하니까요!</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  종합 벤치마크 요약: 어떤 AI를 선택해야 할까?</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">각 모델의 강점을 정리해 봤는데요, 전체적인 그림을 한눈에 보실 수 있도록 요약 표를 만들어봤어요.</p>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px; border-bottom: 2px solid #e8f0fe; padding-bottom: 5px;\" data-ke-size=\"size23\"><b>분야별 1위 모델</b></h3>\n<table style=\"width: 100%; border-collapse: collapse; margin-bottom: 25px; border: 1px solid #dadce0;\" data-ke-align=\"alignLeft\">\n<thead style=\"background-color: #e8eaed;\">\n<tr>\n<th style=\"padding: 12px; border: 1px solid #dadce0; text-align: left; color: #3c4043;\">분야</th>\n<th style=\"padding: 12px; border: 1px solid #dadce0; text-align: left; color: #3c4043;\">1위 모델</th>\n</tr>\n</thead>\n<tbody>\n<tr style=\"background-color: white;\">\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">코딩</td>\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\"><b>Claude Sonnet 4.5</b></td>\n</tr>\n<tr style=\"background-color: #f1f3f4;\">\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">금융 분석</td>\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\"><b>Claude Opus 4.6</b></td>\n</tr>\n<tr style=\"background-color: white;\">\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">장문 문서 처리</td>\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\"><b>Claude Opus 4.6</b></td>\n</tr>\n<tr style=\"background-color: #f1f3f4;\">\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">정교한 창의적 문서</td>\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\"><b>Claude Sonnet 4.5</b></td>\n</tr>\n<tr style=\"background-color: white;\">\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">추상 추론</td>\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">Gemini 3.1 Pro</td>\n</tr>\n<tr style=\"background-color: #f1f3f4;\">\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">속도</td>\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">GPT-5.2 Instant</td>\n</tr>\n<tr style=\"background-color: white;\">\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">비용 효율</td>\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">Gemini Flash</td>\n</tr>\n</tbody>\n</table>\n<div style=\"background-color: #f8f9fa; border: 1px solid #dadce0; border-radius: 8px; padding: 25px; margin: 30px 0; box-shadow: 0 4px 12px rgba(0,0,0,0.1);\">\n<div style=\"font-size: 26px; color: #1a73e8; font-weight: bold; margin-bottom: 15px; border-bottom: 2px solid #1a73e8; padding-bottom: 10px;\">  핵심 요약</div>\n<p style=\"font-size: 17px; margin-bottom: 15px;\" data-ke-size=\"size16\"><b>1.  ️ 복잡한 코드 개발 및 리팩토링:</b> Claude는 긴 컨텍스트와 심층적인 코드 이해력으로 개발 생산성을 극대화합니다.</p>\n<p style=\"font-size: 17px; margin-bottom: 15px;\" data-ke-size=\"size16\"><b>2.   전문 금융 데이터 분석:</b> 대용량 재무 보고서 교차 분석, 리스크 평가 등 금융 분야에 특화된 독보적인 성능을 보여줍니다.</p>\n<p style=\"font-size: 17px; margin-bottom: 15px;\" data-ke-size=\"size16\"><b>3.   방대한 장문 문서 처리:</b> 수백 페이지 분량의 논문이나 계약서를 안정적으로 처리하고 복합 질의에 정확히 답변합니다.</p>\n<p style=\"font-size: 17px; margin-bottom: 15px;\" data-ke-size=\"size16\"><b>4.   정교하고 논리적인 문서 창작:</b> 기술 블로그, 전문 리포트 등 완성도 높은 글쓰기에 탁월합니다.</p>\n<div style=\"font-size: 14px; color: #5f6368; margin-top: 20px; border-top: 1px dashed #dadce0; padding-top: 15px;\">결론적으로 AI 선택은 '무엇을 할 것인가'에 따라 달라집니다. Claude는 특정 전문 영역에서 '전문 작업용 엔진'으로서 진정한 가치를 발휘합니다.</div>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>❓ 자주 묻는 질문 (FAQ)</b></h2>\n<div style=\"margin-bottom: 15px;\">\n<h3 style=\"font-size: 18px; color: #1a73e8; margin-bottom: 5px;\" data-ke-size=\"size23\">Q1: Claude는 모든 면에서 ChatGPT나 Gemini보다 뒤떨어지나요?</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">아니요, 그렇지 않습니다. Claude는 특정 전문 분야, 예를 들어 코딩, 금융 분석, 장문 문서 처리, 그리고 정교한 전문 문서 작성에서 ChatGPT나 Gemini보다 훨씬 더 뛰어난 성능과 안정성을 보여줍니다. '모든 것을 평균 이상으로 잘하는 모델'이라기보다는, '특정 전문 영역에서 압도적인 완성도를 제공하는 모델'이라고 이해하는 것이 정확합니다.</p>\n</div>\n<div style=\"margin-bottom: 15px;\">\n<h3 style=\"font-size: 18px; color: #1a73e8; margin-bottom: 5px;\" data-ke-size=\"size23\">Q2: 개발자라면 무조건 Claude를 사용해야 하나요?</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">'무조건'은 아니지만, 복잡한 코드베이스를 다루거나, 대규모 리팩토링, 상세한 테스트 케이스 생성이 필요한 경우에는 Claude Sonnet 4.5나 Opus 4.6이 매우 강력한 선택이 될 것입니다. GPT-5.3 Codex도 훌륭하지만, 긴 코드 맥락 유지나 구조적 이해 측면에서 Claude가 더 안정적이라는 평가가 많습니다. 프로젝트의 규모와 복잡성에 따라 선택하는 것이 좋습니다.</p>\n</div>\n<div style=\"margin-bottom: 15px;\">\n<h3 style=\"font-size: 18px; color: #1a73e8; margin-bottom: 5px;\" data-ke-size=\"size23\">Q3: 비용 효율적인 작업에는 어떤 모델이 가장 좋나요?</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">속도와 비용 효율성이 최우선이라면, GPT-5.2 Instant나 Gemini Flash가 더 좋은 선택이 될 수 있습니다. Claude도 Haiku라는 경량 모델이 있지만, 범용적인 빠른 처리 및 비용 경쟁력 면에서는 아직 앞선 두 모델이 유리하다고 평가됩니다. 가벼운 작업이나 빠른 테스트에는 이러한 경량 모델들을 활용해보세요.</p>\n</div>\n<script type=\"application/ld+json\">\n  {\n    \"@context\": \"https://schema.org\",\n    \"@type\": \"FAQPage\",\n    \"mainEntity\": [\n      {\n        \"@type\": \"Question\",\n        \"name\": \"Claude는 모든 면에서 ChatGPT나 Gemini보다 뒤떨어지나요?\",\n        \"acceptedAnswer\": {\n          \"@type\": \"Answer\",\n          \"text\": \"아니요, 그렇지 않습니다. Claude는 특정 전문 분야, 예를 들어 코딩, 금융 분석, 장문 문서 처리, 그리고 정교한 전문 문서 작성에서 ChatGPT나 Gemini보다 훨씬 더 뛰어난 성능과 안정성을 보여줍니다. '모든 것을 평균 이상으로 잘하는 모델'이라기보다는, '특정 전문 영역에서 압도적인 완성도를 제공하는 모델'이라고 이해하는 것이 정확합니다.\"\n        }\n      },\n      {\n        \"@type\": \"Question\",\n        \"name\": \"개발자라면 무조건 Claude를 사용해야 하나요?\",\n        \"acceptedAnswer\": {\n          \"@type\": \"Answer\",\n          \"text\": \"'무조건'은 아니지만, 복잡한 코드베이스를 다루거나, 대규모 리팩토링, 상세한 테스트 케이스 생성이 필요한 경우에는 Claude Sonnet 4.5나 Opus 4.6이 매우 강력한 선택이 될 것입니다. GPT-5.3 Codex도 훌륭하지만, 긴 코드 맥락 유지나 구조적 이해 측면에서 Claude가 더 안정적이라는 평가가 많습니다. 프로젝트의 규모와 복잡성에 따라 선택하는 것이 좋습니다.\"\n        }\n      },\n      {\n        \"@type\": \"Question\",\n        \"name\": \"비용 효율적인 작업에는 어떤 모델이 가장 좋나요?\",\n        \"acceptedAnswer\": {\n          \"@type\": \"Answer\",\n          \"text\": \"속도와 비용 효율성이 최우선이라면, GPT-5.2 Instant나 Gemini Flash가 더 좋은 선택이 될 수 있습니다. Claude도 Haiku라는 경량 모델이 있지만, 범용적인 빠른 처리 및 비용 경쟁력 면에서는 아직 앞선 두 모델이 유리하다고 평가됩니다. 가벼운 작업이나 빠른 테스트에는 이러한 경량 모델들을 활용해보세요.\"\n        }\n      }\n    ]\n  }\n  </script>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">AI 선택은 결국 <b>여러분의 업무 구조와 목적에 달려 있습니다.</b> 모든 AI가 모든 작업에 완벽할 수는 없어요. 하지만 적절한 도구를 올바른 상황에 사용하는 것이 스마트한 워크플로우를 만드는 핵심이죠.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">만약 여러분이 개발자, 금융 분석가, 기술 블로거, 또는 방대한 자료를 다루는 연구자라면, Claude는 단순한 챗봇을 넘어 <b>'전문 작업용 엔진'</b>에 가깝습니다. 각자의 니즈에 맞춰 AI를 현명하게 활용하시길 바라며, 궁금한 점이 있다면 언제든지 댓글로 남겨주세요! 다음에 더 유익한 정보로 찾아뵙겠습니다.</p>\n</div>",
        "contentSnippet": "안녕하세요! 생성형 AI를 업무에 활용하는 분들이라면 늘 고민하실 거예요. \"어떤 AI를 써야 가장 효율적일까?\" 특히 ChatGPT와 Gemini가 워낙 유명하다 보니, Claude는 과연 어떤 특별한 강점이 있을지 궁금해하시는 분들이 많죠. 오늘은 2026년 최신 벤치마크 데이터를 바탕으로, Claude가 다른 모델들보다 확실히 빛을 발하는 5가지 핵심 업무를 깊이 있게 분석해 보려 해요. 제 경험을 섞어 가면서, 여러분의 AI 선택에 실질적인 도움을 드릴 수 있도록 노력해 보겠습니다!\n\n\n생성형 AI 시장은 이제 단순히 '더 좋은 AI'를 찾는 단계를 넘어섰어요. 이제는 '특정 상황에서 어떤 모델이 최적인가'를 고민해야 하는 시대가 된 거죠. 2026년 2월 현재, 주요 AI 모델들의 발전 속도를 보면 정말 놀랍습니다.\n간단히 주요 플레이어와 최신 모델들을 살펴볼까요?\n회사\n최신 모델 (2026년 기준)\n주요 특징\n\n\n\n\nOpenAI\nGPT-5.2 / GPT-5.3 Codex\n균형 잡힌 성능, 빠른 응답 속도\n\n\nGoogle\nGemini 3.1 Pro\n추상 추론 강화, 과학 문제 해결 특화\n\n\nAnthropic\nClaude Opus 4.6 / Sonnet 4.5\n코딩 최강, 금융 분석 최고\n\n\n\n이 강력한 AI 라인업 속에서, 과연 Claude가 특별히 빛을 발하는 순간은 언제일까요? 제가 직접 여러 프로젝트에서 사용해 본 경험과 함께, 최신 벤치마크 데이터를 토대로 Claude의 진정한 강점을 파헤쳐 보겠습니다.\n1.   코딩 및 소프트웨어 개발: Claude의 독주\n개발자라면 이 부분에 특히 주목해야 합니다. 2026년 현재, 코딩 분야에서 Claude의 성능은 정말 압도적이라고 해도 과언이 아니에요. 특히 Claude Sonnet 4.5와 Opus 4.6은 개발 워크플로우를 혁신적으로 바꿔놓을 잠재력을 가지고 있습니다.\n  최신 성능 지표가 말해주는 Claude의 힘\nSWE-Bench Verified: 77.2% — 이는 실제 소프트웨어 엔지니어링 벤치마크에서 높은 수준의 문제 해결 능력을 보여준다는 의미입니다.\n실제 GitHub 이슈 해결 성공률 77% 향상 — 실제 오픈소스 프로젝트에 기여하는 데 얼마나 유용한지 보여주는 지표죠.\n복잡한 코드 리팩토링 작업 최대 10배 빠름 — 개발 생산성에 엄청난 영향을 미칩니다.\nClaude Code 2.0 지원 — 자동 체크포인트, 실행 취소(Undo), IDE 통합 등 개발 편의성을 대폭 개선했습니다.\n대규모 코드베이스를 다루거나, 복잡한 시스템의 아키텍처를 이해하고 수정해야 할 때 Claude의 진가가 발휘되곤 합니다. 제가 직접 경험해본 바로는, 특히 수십만 라인에 달하는 레거시 코드를 분석하고 리팩토링할 때 Claude만큼 똑똑하고 끈기 있는 비서가 없었어요.\n  왜 Claude가 코딩에 유리한가?\n긴 컨텍스트 처리 능력: 방대한 코드 파일을 한 번에 읽고 맥락을 이해하는 능력이 탁월합니다.\n코드 구조 전체 파악 및 리팩토링 능력: 단순히 오류를 수정하는 것을 넘어, 전체적인 코드 품질과 설계를 개선하는 데 도움을 줍니다.\n테스트 케이스 생성 정확도: 버그를 찾고 예방하는 데 필수적인 고품질 테스트 코드를 효과적으로 생성해요.\n버그 재현 및 원인 추적 정밀도: 복잡한 버그의 발생 조건을 분석하고 근본 원인을 찾아내는 데 뛰어납니다.\n\n\n  팁: GPT-5.3 Codex도 코딩 벤치마크에서 77.3%라는 높은 점수를 기록하며 강력한 보조 선택지로 꼽히지만, 대형 프로젝트에서 긴 맥락을 안정적으로 유지하며 작업하는 측면에서는 Claude가 더 신뢰할 만하다는 평가가 지배적입니다. 복잡하고 큰 규모의 프로젝트라면 Claude를 먼저 고려해 보세요!\n2.   금융 분석 및 비즈니스 인텔리전스: Claude Opus 4.6의 특화 영역\n금융 분야는 정말 섬세하고 복잡한 데이터 처리가 필요한 영역이잖아요. 그런데 Claude는 이 분야에서 독보적인 성능을 보여주고 있습니다. 특히 Claude Opus 4.6은 금융 전문가들에게 강력한 도구가 될 것이라고 생각해요. 저도 최근에 재무 보고서 분석에 Claude를 활용해봤는데, 정말 놀라웠어요.\n  Finance Agent 벤치마크 1위!\n복잡한 재무 문서(IR 자료, 애널리스트 보고서 등)의 완벽한 처리 능력\n다중 보고서 간의 심층적인 비교 분석\n현금흐름표, 손익계산서, 대차대조표의 교차 해석 및 인사이트 도출\nClaude for Excel beta 지원: Excel 통합으로 재무 데이터 작업 효율 극대화\n다른 모델들도 물론 재무 데이터를 다룰 수 있지만, 대규모 재무 보고서를 통째로 업로드해서 수많은 세부 조항들 간의 논리적 연결을 추적하고, 나아가 정성적인 리스크 분석까지 수행하는 능력은 Claude Opus 4.6이 단연 최고였습니다. 저는 복잡한 기업공개(IPO) 문서 분석에 활용하면서 시간을 정말 많이 절약할 수 있었어요.\n  주목: Gemini 3.1 Pro가 추상 추론에 강하고, GPT-5.2도 균형 잡힌 분석을 제공하지만, 금융 특화 벤치마크에서는 Claude Opus 4.6이 가장 높은 점수를 기록하며 이 분야의 강자로 자리매김했습니다. 투자를 하시거나 기업 전략을 세우시는 분들이라면 꼭 활용해보세요!\n3.   장문 분석 및 대규모 문서 처리: Claude의 전통적 강점\nClaude는 초기 모델부터 압도적인 컨텍스트 창(context window)이 가장 큰 장점으로 꼽혔습니다. 2026년에도 이 강점은 여전히 유효하고, 오히려 더욱 강력해졌습니다. 방대한 양의 텍스트를 한 번에 처리해야 하는 작업이 많다면 Claude가 아주 좋은 선택지가 될 거예요.\n\n\n\n대규모 연구 논문 수십 편을 한 번에 분석하고 핵심 요약\n100페이지가 넘는 법률 계약서 또는 정책 문서 검토\n수십 개의 보고서를 동시에 비교하고 공통점 및 차이점 도출\n기업 내부 문서들을 기반으로 한 지식베이스 구축\nChatGPT와 Gemini도 물론 문서 처리가 가능하지만, '이 10개 문서에서 공통 리스크 요소만 추출하고, 연도별 변화까지 분석해줘'와 같이 복합적이고 심층적인 질의를 할 때는 Claude가 훨씬 더 안정적이고 정확한 결과를 내놓는다는 것을 저도 여러 번 경험했습니다. 특히 중요한 문서일수록 AI의 안정성은 정말 중요하죠.\n4. ✍️ 창의적 작업: 정교함이 필요할 땐 Claude Sonnet 4.5\n창의적 작업이라고 하면 GPT가 먼저 떠오르실 수도 있습니다. 실제로 GPT-5.2는 빠른 응답 속도, 자연스러운 문체, 실시간 음성 기능, 그리고 Prism 협업 리서치 도구 등을 통해 초안 작성에 매우 유리한 강점을 가지고 있죠. 하지만 '정교함'과 '안정적인 논리 구조'가 핵심이라면 이야기가 달라집니다. 여기서 Claude Sonnet 4.5가 빛을 발합니다.\n  Claude의 창의성, 어떤 면이 특별할까요?\n더 정교한 창작물 생성: 특히 기술 블로그, 전문 리포트, 백서와 같은 형식을 요구하는 작업에서 탁월합니다.\n전문 문서 작성에 강점: 복잡한 정보를 체계적으로 정리하고, 설득력 있는 논리를 전개하는 데 강해요.\n슬라이드 및 애니메이션 생성 최적화: 시각적인 자료 제작을 위한 아이디어 구상과 내용 구성에 도움을 줍니다.\n논리적 구조가 안정적: 길고 복잡한 글에서도 일관된 논리 흐름을 유지합니다.\n제 경험상, 빠른 아이데이션이나 초안 작성은 GPT-5.2에 맡기고, 정밀하고 완성도 높은 기술 문서나 보고서 작성은 Claude Sonnet 4.5에 맡기는 것이 가장 효율적인 조합이었습니다. 마치 빠른 스케치에는 연필을, 최종 작품에는 유화를 쓰는 것과 비슷한 느낌이랄까요?\n5. ⚡ 속도와 비용 효율: 경량 모델의 활약\n모든 작업에 최고 성능의 모델만 사용할 수는 없죠. 특히 속도가 중요하거나 비용 절감이 핵심이라면, 경량화된 모델들을 고려하는 것이 현명합니다. 이 부분에서는 Claude보다는 다른 모델들이 강점을 보입니다.\n모델\n특징\n\n\n\n\nGPT-5.2 Instant\n빠른 응답 속도, 저비용으로 일반적인 작업에 효율적\n\n\nGemini Flash\n가성비 최고, 빠르고 경제적인 선택지\n\n\nClaude Haiku\n경량 모델, 빠른 응답과 효율성 추구\n\n\n\nClaude도 Haiku라는 경량 모델을 가지고 있지만, 범용적인 빠른 처리와 비용 효율성 측면에서는 아직 GPT-5.2 Instant나 Gemini Flash가 더 경쟁력이 있다는 것이 제 생각입니다. 정말 급하거나 가볍게 테스트할 때는 이 모델들을 활용하는 것이 좋아요.\n  번외: 수학 및 추상적 논리 문제: Gemini의 영역\n이 부분은 Claude가 강하기보다는 Gemini가 압도적인 영역이라 잠시 짚고 넘어가고 싶었어요. 복잡한 알고리즘 문제, 수학 증명, 추상 패턴 인식과 같은 순수 추론 영역에서는 Gemini 3.1 Pro가 가장 높은 평균 점수를 기록하고 있습니다. Claude도 물론 강력하지만, 이 분야에서는 Gemini가 근소하게 앞서고 있다는 점을 기억해두시면 좋습니다.\n⚠️ 주의: 복잡한 수학 문제나 고도의 추상적 논리 추론이 필요한 경우, Claude보다는 Gemini 3.1 Pro가 더 신뢰할 수 있는 결과를 제공할 가능성이 높습니다. 목적에 맞는 도구를 선택하는 것이 중요하니까요!\n  종합 벤치마크 요약: 어떤 AI를 선택해야 할까?\n각 모델의 강점을 정리해 봤는데요, 전체적인 그림을 한눈에 보실 수 있도록 요약 표를 만들어봤어요.\n분야별 1위 모델\n분야\n1위 모델\n\n\n\n\n코딩\nClaude Sonnet 4.5\n\n\n금융 분석\nClaude Opus 4.6\n\n\n장문 문서 처리\nClaude Opus 4.6\n\n\n정교한 창의적 문서\nClaude Sonnet 4.5\n\n\n추상 추론\nGemini 3.1 Pro\n\n\n속도\nGPT-5.2 Instant\n\n\n비용 효율\nGemini Flash\n\n\n\n\n  핵심 요약\n1.  ️ 복잡한 코드 개발 및 리팩토링: Claude는 긴 컨텍스트와 심층적인 코드 이해력으로 개발 생산성을 극대화합니다.\n2.   전문 금융 데이터 분석: 대용량 재무 보고서 교차 분석, 리스크 평가 등 금융 분야에 특화된 독보적인 성능을 보여줍니다.\n3.   방대한 장문 문서 처리: 수백 페이지 분량의 논문이나 계약서를 안정적으로 처리하고 복합 질의에 정확히 답변합니다.\n4.   정교하고 논리적인 문서 창작: 기술 블로그, 전문 리포트 등 완성도 높은 글쓰기에 탁월합니다.\n결론적으로 AI 선택은 '무엇을 할 것인가'에 따라 달라집니다. Claude는 특정 전문 영역에서 '전문 작업용 엔진'으로서 진정한 가치를 발휘합니다.\n❓ 자주 묻는 질문 (FAQ)\nQ1: Claude는 모든 면에서 ChatGPT나 Gemini보다 뒤떨어지나요?\n아니요, 그렇지 않습니다. Claude는 특정 전문 분야, 예를 들어 코딩, 금융 분석, 장문 문서 처리, 그리고 정교한 전문 문서 작성에서 ChatGPT나 Gemini보다 훨씬 더 뛰어난 성능과 안정성을 보여줍니다. '모든 것을 평균 이상으로 잘하는 모델'이라기보다는, '특정 전문 영역에서 압도적인 완성도를 제공하는 모델'이라고 이해하는 것이 정확합니다.\nQ2: 개발자라면 무조건 Claude를 사용해야 하나요?\n'무조건'은 아니지만, 복잡한 코드베이스를 다루거나, 대규모 리팩토링, 상세한 테스트 케이스 생성이 필요한 경우에는 Claude Sonnet 4.5나 Opus 4.6이 매우 강력한 선택이 될 것입니다. GPT-5.3 Codex도 훌륭하지만, 긴 코드 맥락 유지나 구조적 이해 측면에서 Claude가 더 안정적이라는 평가가 많습니다. 프로젝트의 규모와 복잡성에 따라 선택하는 것이 좋습니다.\nQ3: 비용 효율적인 작업에는 어떤 모델이 가장 좋나요?\n속도와 비용 효율성이 최우선이라면, GPT-5.2 Instant나 Gemini Flash가 더 좋은 선택이 될 수 있습니다. Claude도 Haiku라는 경량 모델이 있지만, 범용적인 빠른 처리 및 비용 경쟁력 면에서는 아직 앞선 두 모델이 유리하다고 평가됩니다. 가벼운 작업이나 빠른 테스트에는 이러한 경량 모델들을 활용해보세요.\nAI 선택은 결국 여러분의 업무 구조와 목적에 달려 있습니다. 모든 AI가 모든 작업에 완벽할 수는 없어요. 하지만 적절한 도구를 올바른 상황에 사용하는 것이 스마트한 워크플로우를 만드는 핵심이죠.\n만약 여러분이 개발자, 금융 분석가, 기술 블로거, 또는 방대한 자료를 다루는 연구자라면, Claude는 단순한 챗봇을 넘어 '전문 작업용 엔진'에 가깝습니다. 각자의 니즈에 맞춰 AI를 현명하게 활용하시길 바라며, 궁금한 점이 있다면 언제든지 댓글로 남겨주세요! 다음에 더 유익한 정보로 찾아뵙겠습니다.",
        "guid": "https://muzbox.tistory.com/483710",
        "categories": [
          "AI, 미래기술/AI 인사이트",
          "2026 AI 벤치마크",
          "ai 모델 선택",
          "ai 생산성",
          "chatgpt 비교",
          "Claude 강점",
          "Claude 금융 분석",
          "Claude 코딩",
          "Gemini 비교",
          "대규모 문서 처리 AI",
          "생성형 ai 활용"
        ],
        "isoDate": "2026-02-23T02:35:25.000Z"
      }
    ]
  },
  {
    "name": "동우리의 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "하테나",
    "category": "개인",
    "posts": []
  },
  {
    "name": "늑돌이네 라지온",
    "category": "개인",
    "posts": []
  },
  {
    "name": "루리웹 - 루리웹 리뷰 게시판",
    "category": "게임",
    "posts": [
      {
        "creator": "(RULIWEB`Д')/",
        "title": "[MULTI] 신화가 되지 못한 소년들, 갓 오브 워 썬즈 오브 스파르타",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2425",
        "pubDate": "Fri, 27 Feb 2026 20:28:34 +0900",
        "author": "(RULIWEB`Д')/",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i2.ruliweb.com/thumb/26/02/27/19c9e8af3294c329e.webp\">",
        "contentSnippet": "",
        "categories": [
          "리뷰"
        ],
        "isoDate": "2026-02-27T11:28:34.000Z"
      },
      {
        "creator": "｜RULIWEB｜",
        "title": "악역영애 4컷 만화 - 40화, 계획대로데스와 ②",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2424",
        "pubDate": "Wed, 25 Feb 2026 16:38:48 +0900",
        "author": "｜RULIWEB｜",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i3.ruliweb.com/thumb/26/02/25/19c93bc49d551ad6b.webp\">",
        "contentSnippet": "",
        "categories": [
          "웹툰"
        ],
        "isoDate": "2026-02-25T07:38:48.000Z"
      },
      {
        "creator": "｜RULIWEB｜",
        "title": "비락탈, 마법의 보드 게임을 즐겨보자!",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2423",
        "pubDate": "Wed, 25 Feb 2026 16:34:48 +0900",
        "author": "｜RULIWEB｜",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i2.ruliweb.com/thumb/26/02/25/19c93b6e77e51ad6b.webp\">",
        "contentSnippet": "",
        "categories": [
          "게임툰"
        ],
        "isoDate": "2026-02-25T07:34:48.000Z"
      }
    ]
  },
  {
    "name": "Reasontobe",
    "category": "개인",
    "posts": []
  },
  {
    "name": "에스티마의 인터넷이야기 EstimaStory.com",
    "category": "개인",
    "posts": []
  },
  {
    "name": "나긋한 개발 - 데비안 리눅스와 프로그램 언어",
    "category": "개인",
    "posts": [
      {
        "creator": "summerandwinter",
        "title": "미국 직구 배송과 관세 이야기",
        "link": "https://sacstory.tistory.com/entry/%EB%AF%B8%EA%B5%AD-%EC%A7%81%EA%B5%AC-%EB%B0%B0%EC%86%A1-%EA%B1%B8%EB%A6%AC%EB%8A%94-%EC%8B%9C%EA%B0%84",
        "pubDate": "Sun, 22 Feb 2026 13:50:43 +0900",
        "author": "summerandwinter",
        "comments": "https://sacstory.tistory.com/entry/%EB%AF%B8%EA%B5%AD-%EC%A7%81%EA%B5%AC-%EB%B0%B0%EC%86%A1-%EA%B1%B8%EB%A6%AC%EB%8A%94-%EC%8B%9C%EA%B0%84#entry399comment",
        "content": "2025년 12월 5일\n미국 켄터키주에서 생산하는 작은 제품 2개를 구매했다.\n&nbsp;\n구매한 제품은 알리익스프레스와 아마존 등 종합 쇼핑몰에서 판매를 하지 않는 제품이라 본사 홈페이지에서 직접 구매했다.\n종합 쇼핑몰에서만 해외 제품을 사봤지, 직접 본사에서 구매하는건 처음이었다.\n&nbsp;\n알리의 배송 옵션처럼 이 제품에도 배송 옵션을 제공했다.\n가장 저렴한 배송도 길어야 14일 걸린다고 표기되어 있었다. 알리와 비슷하겠지... 라고 생각한게 큰..",
        "contentSnippet": "2025년 12월 5일\n미국 켄터키주에서 생산하는 작은 제품 2개를 구매했다.\n \n구매한 제품은 알리익스프레스와 아마존 등 종합 쇼핑몰에서 판매를 하지 않는 제품이라 본사 홈페이지에서 직접 구매했다.\n종합 쇼핑몰에서만 해외 제품을 사봤지, 직접 본사에서 구매하는건 처음이었다.\n \n알리의 배송 옵션처럼 이 제품에도 배송 옵션을 제공했다.\n가장 저렴한 배송도 길어야 14일 걸린다고 표기되어 있었다. 알리와 비슷하겠지... 라고 생각한게 큰..",
        "guid": "https://sacstory.tistory.com/399",
        "categories": [
          "Review"
        ],
        "isoDate": "2026-02-22T04:50:43.000Z"
      }
    ]
  },
  {
    "name": "일상을 여행처럼...",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Just hack'em",
    "category": "개인",
    "posts": []
  },
  {
    "name": "C++ Truths",
    "category": "개인",
    "posts": []
  },
  {
    "name": "jacking75",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Joel on Software",
    "category": "개인",
    "posts": []
  },
  {
    "name": "벤자민로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "악보쓰는 프로그래머",
    "category": "개인",
    "posts": []
  },
  {
    "name": "쭌안아빠",
    "category": "개인",
    "posts": []
  },
  {
    "name": "A Gangster World",
    "category": "개인",
    "posts": []
  },
  {
    "name": "요우의 내맘대로 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자스럽다",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Against All Odds.",
    "category": "개인",
    "posts": []
  },
  {
    "name": "움직이는 게임서버",
    "category": "개인",
    "posts": []
  },
  {
    "name": "이상욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "임철재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "어쩐지 오늘은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "oddpoet’s étude",
    "category": "개인",
    "posts": []
  },
  {
    "name": "0x00 - NULL",
    "category": "개인",
    "posts": []
  },
  {
    "name": "퇴근 후 서버다운",
    "category": "개인",
    "posts": [
      {
        "creator": "SIDNFT",
        "title": "구글 플레이 스토어 비공개 테스트 14일 요령",
        "link": "https://serverdown.tistory.com/1581",
        "pubDate": "Sat, 28 Feb 2026 23:29:54 +0900",
        "author": "SIDNFT",
        "comments": "https://serverdown.tistory.com/1581#entry1581comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"597\" data-origin-height=\"544\"><span data-url=\"https://blog.kakaocdn.net/dn/bsUGmO/dJMcabQO6Bx/6V0NSMLqFdKBQK0DkVKZt0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bsUGmO/dJMcabQO6Bx/6V0NSMLqFdKBQK0DkVKZt0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bsUGmO/dJMcabQO6Bx/6V0NSMLqFdKBQK0DkVKZt0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbsUGmO%2FdJMcabQO6Bx%2F6V0NSMLqFdKBQK0DkVKZt0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"597\" height=\"544\" data-origin-width=\"597\" data-origin-height=\"544\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">24년 부터였나 구글 플레이 스토어에 앱을 등록하려면&nbsp;</p>\n<p data-ke-size=\"size16\">- 테스터를 12명 모아&nbsp;<br /><span style=\"text-align: start;\">- 비공개테스트를 14일 간 진행</span></p>\n<p data-ke-size=\"size16\">이 조건이 추가로 생겼습니다.</p>\n<p data-ke-size=\"size16\">혼자개발하는 사람에겐 가혹한 조건이긴한데</p>\n<p data-ke-size=\"size16\">이것을 당송하는 요령을 요약해보겠습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">일단 기기 12개는 필요합니다.</p>\n<p data-ke-size=\"size16\">그렇다고 안드로이드 기계를 12개 사는건 무리구요</p>\n<p data-ke-size=\"size16\">물리적으로 사람이 4명 있어야합니다.</p>\n<p data-ke-size=\"size16\">- LD플레이어<br />- PC 용 구글 플레이 게임즈<br />- 안드로이드 기기</p>\n<p data-ke-size=\"size16\">한명당 3개 정도는 만들 수 있으니<br />4명이서 구글계정 3개를 돌리시면 됩니다.</p>\n<p data-ke-size=\"size16\">이 테스트는 사람수가 중요한게 아닙니다.<br />여러기기에서 돌려보았는가가 중요합니다.</p>\n<p data-ke-size=\"size16\">정 못모으겠다면&nbsp;</p>\n<p data-ke-size=\"size16\">LD 플레이어의 기기 정보를 고쳐가며 구글계겅 돌려가며 진행해도 됩니다..<br />매일 테스트할 필요는 없고 하루에 1번 정도는 플레이 하시면 일 수는 채워집니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">LD 플레이어에서 태스트하기</h2>\n<p data-ke-size=\"size16\">LD 플레이어 실행하시고 앱스토어 아이콘 옆에 크롬이 있습니다.</p>\n<p data-ke-size=\"size16\">크롭으로 가서 비공개테스트 링크를 붙여넣고 접속해보세요</p>\n<p data-ke-size=\"size16\">테스트 등록하기 버튼이 나오면 등록하시고</p>\n<p data-ke-size=\"size16\">안에 들어가면 하단에 1, 2 이런식으로 작은 글자가있는데</p>\n<p data-ke-size=\"size16\">2번에 스토러 링크를 제공합니다.&nbsp;<br />그걸로 들어가서 앱을 받으시면 됩니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">PC 용 구글 플레이 게임즈</h2>\n<p data-ke-size=\"size16\">이거는 크롬이 없기 때문에</p>\n<p data-ke-size=\"size16\">외부에서 브라우저로 지메일 로그인해서 링크 들어가 테스터 신청하시구요</p>\n<p data-ke-size=\"size16\">PC 용 구글 플레이 게임즈 앱을 실행 시키고 검색을 앱아이디로 하세요</p>\n<p data-ke-size=\"size16\">com.~~~.게임이름 이런식으로 빌드할때 앱ID 가 있습니다. 이걸 입력하시면 비공개테스트 앱도 검색이 됩니다.</p>\n<p data-ke-size=\"size16\">들어가서 앱 다운 받고 실행하시면 됩니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">글국 이렇게 해서 테스트 기길을 채우시면<br />통과할 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">테스터 수랑 테스트 기간도 채웠지만 연속 3번을 테스트 부족이 떠서&nbsp;</p>\n<p data-ke-size=\"size16\">알아낸 방법입니다.</p>\n<p data-ke-size=\"size16\">사람 수나 지메일 계정 수가 아니고 테스트 기기가 문제였습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "24년 부터였나 구글 플레이 스토어에 앱을 등록하려면 \n- 테스터를 12명 모아 \n- 비공개테스트를 14일 간 진행\n이 조건이 추가로 생겼습니다.\n혼자개발하는 사람에겐 가혹한 조건이긴한데\n이것을 당송하는 요령을 요약해보겠습니다.\n \n일단 기기 12개는 필요합니다.\n그렇다고 안드로이드 기계를 12개 사는건 무리구요\n물리적으로 사람이 4명 있어야합니다.\n- LD플레이어\n- PC 용 구글 플레이 게임즈\n- 안드로이드 기기\n한명당 3개 정도는 만들 수 있으니\n4명이서 구글계정 3개를 돌리시면 됩니다.\n이 테스트는 사람수가 중요한게 아닙니다.\n여러기기에서 돌려보았는가가 중요합니다.\n정 못모으겠다면 \nLD 플레이어의 기기 정보를 고쳐가며 구글계겅 돌려가며 진행해도 됩니다..\n매일 테스트할 필요는 없고 하루에 1번 정도는 플레이 하시면 일 수는 채워집니다.\n \nLD 플레이어에서 태스트하기\nLD 플레이어 실행하시고 앱스토어 아이콘 옆에 크롬이 있습니다.\n크롭으로 가서 비공개테스트 링크를 붙여넣고 접속해보세요\n테스트 등록하기 버튼이 나오면 등록하시고\n안에 들어가면 하단에 1, 2 이런식으로 작은 글자가있는데\n2번에 스토러 링크를 제공합니다. \n그걸로 들어가서 앱을 받으시면 됩니다.\n \nPC 용 구글 플레이 게임즈\n이거는 크롬이 없기 때문에\n외부에서 브라우저로 지메일 로그인해서 링크 들어가 테스터 신청하시구요\nPC 용 구글 플레이 게임즈 앱을 실행 시키고 검색을 앱아이디로 하세요\ncom.~~~.게임이름 이런식으로 빌드할때 앱ID 가 있습니다. 이걸 입력하시면 비공개테스트 앱도 검색이 됩니다.\n들어가서 앱 다운 받고 실행하시면 됩니다.\n \n \n글국 이렇게 해서 테스트 기길을 채우시면\n통과할 수 있습니다.\n \n테스터 수랑 테스트 기간도 채웠지만 연속 3번을 테스트 부족이 떠서 \n알아낸 방법입니다.\n사람 수나 지메일 계정 수가 아니고 테스트 기기가 문제였습니다.",
        "guid": "https://serverdown.tistory.com/1581",
        "categories": [
          "프로그래밍/개발메모"
        ],
        "isoDate": "2026-02-28T14:29:54.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "혼자 RPG 를 만드는 일은 미친짓이였다.",
        "link": "https://serverdown.tistory.com/1580",
        "pubDate": "Sat, 28 Feb 2026 21:59:18 +0900",
        "author": "SIDNFT",
        "comments": "https://serverdown.tistory.com/1580#entry1580comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"376\" data-origin-height=\"272\"><span data-url=\"https://blog.kakaocdn.net/dn/pfgWZ/dJMcacPKxsI/YlAVrh8FtAMTbSG7jPRQy0/img.webp\" data-phocus=\"https://blog.kakaocdn.net/dn/pfgWZ/dJMcacPKxsI/YlAVrh8FtAMTbSG7jPRQy0/img.webp\"><img src=\"https://blog.kakaocdn.net/dn/pfgWZ/dJMcacPKxsI/YlAVrh8FtAMTbSG7jPRQy0/img.webp\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FpfgWZ%2FdJMcacPKxsI%2FYlAVrh8FtAMTbSG7jPRQy0%2Fimg.webp\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"376\" height=\"272\" data-origin-width=\"376\" data-origin-height=\"272\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">디스코엘리시움의 찬양 글이였군요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=4Aed0uppZ-I\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=4Aed0uppZ-I</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=4Aed0uppZ-I\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/jklhN/dJMb8Qejz6E/NgfwIQ3zDK7pPNgn36Aje1/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/O4sT4/dJMb9gxiLBp/AgrbA9JyMAD9LnGlrjSwv1/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"기사 하나로 인생이 뒤집혔다 ― '디스코 엘리시움'을 꿈꾼 1인 개발 8년의 광기\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/4Aed0uppZ-I\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이분은 전투어려웠다는군요</p>\n<p data-ke-size=\"size16\">저는 대사 쓰는게 어려운데</p>\n<p data-ke-size=\"size16\">20년에 갈아엎었군요<br />지금이 25년인데 ㄷㄷㄷ</p>\n<p data-ke-size=\"size16\">이게 프로토타입 4호 군요</p>\n<p data-ke-size=\"size16\">24년 잔고가 바닥 났고 퍼플리셔는 없었고</p>\n<p data-ke-size=\"size16\">데모를 공개했고 누군가 기사를 써줬고 점점더 추천이 늘어나는 성공 스토리였군요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">Esoteric Ebb 라는 게임을 출시했군요</p>\n<p data-ke-size=\"size16\">스팀 링크: <a href=\"https://store.steampowered.com/app/2057760/Esoteric_Ebb/\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://store.steampowered.com/app/2057760/Esoteric_Ebb/</a></p>\n<p data-ke-size=\"size16\">트레일러 : <a href=\"https://www.youtube.com/watch?v=22wG-w-EnBo\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=22wG-w-EnBo</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=22wG-w-EnBo\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/bqGGed/dJMb8RjZjWo/Ae34urkX2z85bEEfbgeiWk/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/bcdOvz/dJMb8XkcKn5/afmDUpfiv0UFZdF3TUiRvk/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/b8imjX/dJMb8ZvyPvV/YO4Bvh2IZivKnhXOCHzPp1/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"Esoteric Ebb - Official Trailer | IGN Fan Fest 2025\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/22wG-w-EnBo\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">디스코엘리시움류 라는 장르가 있군요</p>\n<p data-ke-size=\"size16\">테무산 디스코엘리시움도 있구요</p>\n<p data-ke-size=\"size16\">큰영향을 준 게임임은 분명합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">훈훈한&nbsp; 내용이였습니다.</p>",
        "contentSnippet": "디스코엘리시움의 찬양 글이였군요\n \n영상: https://www.youtube.com/watch?v=4Aed0uppZ-I\n\n\n\n \n이분은 전투어려웠다는군요\n저는 대사 쓰는게 어려운데\n20년에 갈아엎었군요\n지금이 25년인데 ㄷㄷㄷ\n이게 프로토타입 4호 군요\n24년 잔고가 바닥 났고 퍼플리셔는 없었고\n데모를 공개했고 누군가 기사를 써줬고 점점더 추천이 늘어나는 성공 스토리였군요\n \nEsoteric Ebb 라는 게임을 출시했군요\n스팀 링크: https://store.steampowered.com/app/2057760/Esoteric_Ebb/\n트레일러 : https://www.youtube.com/watch?v=22wG-w-EnBo\n\n\n\n \n디스코엘리시움류 라는 장르가 있군요\n테무산 디스코엘리시움도 있구요\n큰영향을 준 게임임은 분명합니다.\n \n훈훈한  내용이였습니다.",
        "guid": "https://serverdown.tistory.com/1580",
        "categories": [
          "게임",
          "인디게임"
        ],
        "isoDate": "2026-02-28T12:59:18.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "439일차 - UI 연출 해보자 / 개발로그",
        "link": "https://serverdown.tistory.com/1579",
        "pubDate": "Sat, 28 Feb 2026 17:32:56 +0900",
        "author": "SIDNFT",
        "comments": "https://serverdown.tistory.com/1579#entry1579comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"452\" data-origin-height=\"459\"><span data-url=\"https://blog.kakaocdn.net/dn/bNyPrZ/dJMcabpM9Rm/Vk6l3UVun6IyK9e8Kw1KJk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bNyPrZ/dJMcabpM9Rm/Vk6l3UVun6IyK9e8Kw1KJk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bNyPrZ/dJMcabpM9Rm/Vk6l3UVun6IyK9e8Kw1KJk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbNyPrZ%2FdJMcabpM9Rm%2FVk6l3UVun6IyK9e8Kw1KJk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"452\" height=\"459\" data-origin-width=\"452\" data-origin-height=\"459\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=-_TmJO8O_aM\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=-_TmJO8O_aM</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=-_TmJO8O_aM\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/yZqpv/dJMb8UHMwZ9/O7lOYYrvLfRi0t1dWfR2O0/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"439일차 - UI 연출 해보자 / 별 3개 연출기\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/-_TmJO8O_aM\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">클리어 연출을 넣어야해서 기록 남겨봤습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"text-align: start;\">UI 연출을 잘하려면</span></h2>\n<p data-ke-size=\"size16\">결국 제가 말로 설명하는 부분을</p>\n<p data-ke-size=\"size16\">말이 필요 없게 만들면 됩니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">어느정도 잘해야 별을 3개 먹냐를 설명할 필요 없게 만드는게 참 힘드네요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=-_TmJO8O_aM\n\n\n\n클리어 연출을 넣어야해서 기록 남겨봤습니다.\n \nUI 연출을 잘하려면\n결국 제가 말로 설명하는 부분을\n말이 필요 없게 만들면 됩니다.\n \n어느정도 잘해야 별을 3개 먹냐를 설명할 필요 없게 만드는게 참 힘드네요",
        "guid": "https://serverdown.tistory.com/1579",
        "categories": [
          "프로그래밍/자작",
          "개발로그",
          "게임제작기",
          "유니티"
        ],
        "isoDate": "2026-02-28T08:32:56.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "438일차 - 또 실패한 프로덕션 검수 / 인디게임 지원사업 경험담",
        "link": "https://serverdown.tistory.com/1578",
        "pubDate": "Fri, 27 Feb 2026 04:36:24 +0900",
        "author": "SIDNFT",
        "comments": "https://serverdown.tistory.com/1578#entry1578comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"480\" data-origin-height=\"270\"><span data-url=\"https://blog.kakaocdn.net/dn/b4PvdO/dJMcaaYFHbC/VTgNb8GqsH7bSkSdBLJYRk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/b4PvdO/dJMcaaYFHbC/VTgNb8GqsH7bSkSdBLJYRk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/b4PvdO/dJMcaaYFHbC/VTgNb8GqsH7bSkSdBLJYRk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb4PvdO%2FdJMcaaYFHbC%2FVTgNb8GqsH7bSkSdBLJYRk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"480\" height=\"270\" data-origin-width=\"480\" data-origin-height=\"270\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">이게 438 일차 입니다.</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=puMFH_Urukc\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=puMFH_Urukc</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=puMFH_Urukc\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/uyRft/dJMb8RjY99h/rQ0PWTWkkPmq366TBp4MZK/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/b4MMpc/dJMb8QL9cuU/DCmiW7GFrQnSaypMnoHOIK/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/BsOIA/dJMb8QL9cuT/0tEdROg3Kdy3rJ6gRsAh6k/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"438일차 - 플레이스토어 2주차 테스트 또 실패 했습니다. / 인디게임지원사업 철지난 경험담\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/puMFH_Urukc\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">구글 플레이 스토어 프로덕션 전 2주 테스트가 2회차로 실패하는 이야기가 있습습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"597\" data-origin-height=\"544\"><span data-url=\"https://blog.kakaocdn.net/dn/GCcaN/dJMcabQOwxt/gXSAwSsJ2PTjcykyTB5Cq1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/GCcaN/dJMcabQOwxt/gXSAwSsJ2PTjcykyTB5Cq1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/GCcaN/dJMcabQOwxt/gXSAwSsJ2PTjcykyTB5Cq1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FGCcaN%2FdJMcabQOwxt%2FgXSAwSsJ2PTjcykyTB5Cq1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"597\" height=\"544\" data-origin-width=\"597\" data-origin-height=\"544\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">테스트로만 6 주를 보내고 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">주식 이야기로&nbsp;</p>\n<p data-ke-size=\"size16\">오라클 <span style=\"text-align: start;\">ORCL</span> <br />유니티 U<br />테이크투 TTWO<br />에픽게임즈 - 상장전</p>\n<p data-ke-size=\"size16\">이야기가 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">인디게임 지원사업 설명은 이영상을 참고했습니다.</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=MK5FKYHUf5Q\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=MK5FKYHUf5Q</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=MK5FKYHUf5Q\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/bTBP3N/dJMb8U8QRdF/7btk4rwWhBuTig3x2zxaPk/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/L3iU6/dJMb8Z3ouq5/l6O5q6KkOSEI5gkbBlwzu1/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"공고떴다! 인디게임 데브 캠프 지원사업 같이보기\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/MK5FKYHUf5Q\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "이게 438 일차 입니다.\n영상: https://www.youtube.com/watch?v=puMFH_Urukc\n\n\n\n \n구글 플레이 스토어 프로덕션 전 2주 테스트가 2회차로 실패하는 이야기가 있습습니다.\n\n\n테스트로만 6 주를 보내고 있습니다.\n \n \n주식 이야기로 \n오라클 ORCL \n유니티 U\n테이크투 TTWO\n에픽게임즈 - 상장전\n이야기가 있습니다.\n \n인디게임 지원사업 설명은 이영상을 참고했습니다.\n영상: https://www.youtube.com/watch?v=MK5FKYHUf5Q",
        "guid": "https://serverdown.tistory.com/1578",
        "categories": [
          "프로그래밍/자작",
          "모바일게임",
          "인디게임",
          "주식"
        ],
        "isoDate": "2026-02-26T19:36:24.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "436일차 - 근황 / 개발로그",
        "link": "https://serverdown.tistory.com/1577",
        "pubDate": "Wed, 25 Feb 2026 20:22:03 +0900",
        "author": "SIDNFT",
        "comments": "https://serverdown.tistory.com/1577#entry1577comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1453\" data-origin-height=\"871\"><span data-url=\"https://blog.kakaocdn.net/dn/oFsRj/dJMcaih5Adn/FPTM7nE47Y5h1k7lP23ji1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/oFsRj/dJMcaih5Adn/FPTM7nE47Y5h1k7lP23ji1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/oFsRj/dJMcaih5Adn/FPTM7nE47Y5h1k7lP23ji1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FoFsRj%2FdJMcaih5Adn%2FFPTM7nE47Y5h1k7lP23ji1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1453\" height=\"871\" data-origin-width=\"1453\" data-origin-height=\"871\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">436일차입니다.&nbsp;<br />438일차로 잘못말했군요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://youtu.be/6-p-l1GB7Ak\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://youtu.be/6-p-l1GB7Ak</a></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">2주간 유튜브를 쉬어서 의무감으로 하나 올렸습니다.</p>\n<p data-ke-size=\"size16\">진행중인 여자그림 퍼즐 게임 과</p>\n<p data-ke-size=\"size16\">또 다른 퍼즐 게임에 대한 이야기 입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">디펜스게임은 뭐라도 하나 추가한거 보여줘야할꺼 같아서 넣었습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">다음부턴 좀 이야기를 정리해서 말해야지 횡설수설 하는군요</p>",
        "contentSnippet": "436일차입니다. \n438일차로 잘못말했군요\n \n영상: https://youtu.be/6-p-l1GB7Ak\n \n2주간 유튜브를 쉬어서 의무감으로 하나 올렸습니다.\n진행중인 여자그림 퍼즐 게임 과\n또 다른 퍼즐 게임에 대한 이야기 입니다.\n \n디펜스게임은 뭐라도 하나 추가한거 보여줘야할꺼 같아서 넣었습니다.\n \n다음부턴 좀 이야기를 정리해서 말해야지 횡설수설 하는군요",
        "guid": "https://serverdown.tistory.com/1577",
        "categories": [
          "프로그래밍/자작"
        ],
        "isoDate": "2026-02-25T11:22:03.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "울티마 1 플레이하시는 유튜버 / 미믹",
        "link": "https://serverdown.tistory.com/1576",
        "pubDate": "Wed, 25 Feb 2026 02:32:25 +0900",
        "author": "SIDNFT",
        "comments": "https://serverdown.tistory.com/1576#entry1576comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"431\" data-origin-height=\"261\"><span data-url=\"https://blog.kakaocdn.net/dn/b8Syis/dJMcaaxBceM/urFohtR3hUFN3OgzQrNc51/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/b8Syis/dJMcaaxBceM/urFohtR3hUFN3OgzQrNc51/img.png\"><img src=\"https://blog.kakaocdn.net/dn/b8Syis/dJMcaaxBceM/urFohtR3hUFN3OgzQrNc51/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb8Syis%2FdJMcaaxBceM%2FurFohtR3hUFN3OgzQrNc51%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"431\" height=\"261\" data-origin-width=\"431\" data-origin-height=\"261\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=yGCITMDeGf4\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=yGCITMDeGf4</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=yGCITMDeGf4\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/zaKZH/dJMb8XR2Dkn/SztKM2N4ZCXAfks4SnOYaK/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/p26p4/dJMb8Zvys0U/ZolsYqPT4JhW5Dke5cXOok/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/fMROa/dJMb8XkcoV2/EkIf8QKwuDaIQXpoq5AA60/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"RPG의 시작 울티마1 공략 #CRPG\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/yGCITMDeGf4\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">와 멋지다.</p>\n<p data-ke-size=\"size16\">모험을 지켜보겠습니다.</p>\n<p data-ke-size=\"size16\">일단 사운드 는 잡음 수준이군요</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=yGCITMDeGf4\n\n\n\n \n와 멋지다.\n모험을 지켜보겠습니다.\n일단 사운드 는 잡음 수준이군요",
        "guid": "https://serverdown.tistory.com/1576",
        "categories": [
          "게임",
          "고전게임",
          "울티마"
        ],
        "isoDate": "2026-02-24T17:32:25.000Z"
      }
    ]
  },
  {
    "name": "coolspeed",
    "category": "개인",
    "posts": []
  },
  {
    "name": "오늘도 끄적끄적",
    "category": "개인",
    "posts": []
  },
  {
    "name": "dx11 Vanica's Lifelog - 夢が夢で終わらないように",
    "category": "개인",
    "posts": []
  },
  {
    "name": "초코사랑",
    "category": "개인",
    "posts": []
  },
  {
    "name": "ZeroCho Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "imays게임엔진개발자",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for hurinmon Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "기억보단 기록을",
    "category": "개인",
    "posts": [
      {
        "creator": "향로 (기억보단 기록을)",
        "title": "라식 수술 하지 않는 의사, Electron 사용하는 Claude",
        "link": "https://jojoldu.tistory.com/867",
        "pubDate": "Thu, 26 Feb 2026 13:12:00 +0900",
        "author": "향로 (기억보단 기록을)",
        "comments": "https://jojoldu.tistory.com/867#entry867comment",
        "content": "<p data-ke-size=\"size16\">안경을 오랫동안 쓰고 있다.<br />주변에서 라식이나 라섹을 추천하는 사람들이 꽤 있었다.<br />근데 정작 안과 의사분들 중에서도 \"빛 번짐, 안구건조증\" 때문에 안경을 쓰는 분들이 많다.<br />난 안경을 올해로 30년째 쓰고 있고, 여전히 안과에 가면 안경을 쓰신 의사분들을 종종 보게 된다.</p>\n<p data-ke-size=\"size16\">앤트로픽 CEO 다리오 아모데이가 \"코딩은 6~12개월 내에 해결된 문제가 될 것\"이라고 발언한 <a href=\"https://www.youtube.com/watch?v=7xMTIjJFHbI\">인터뷰</a>를 봤다.<br />AI가 코딩을 대체할 거라는 꽤나 강한 톤의 발언이다.</p>\n<p data-ke-size=\"size16\">근데 정작 Claude 데스크탑 앱은 <b>Electron</b>이다.<br />Electron은 웹 기술(HTML/CSS/JS)로 데스크탑 앱을 만들 수 있게 해주는 프레임워크다.<br />소수의 개발팀이 웹, 앱, 데스크탑을 일관되게 관리할 수 있어서, <b>개발자의 생산성</b>을 높여주는 도구로 널리 쓰인다.<br />슬랙도, VS Code도 다 Electron이고, 스타트업이나 제품의 본질에 집중해야 할 때 우선적으로 선택하게 된다.</p>\n<p data-ke-size=\"size16\">다만 그 대가로 용량도 크고, 속도도 네이티브 구현보다 훨씬 느리다.<br />즉, <b>사용자의 사용성을 어느 정도 포기하고 개발자의 생산성을 택하는 트레이드오프</b>다.</p>\n<p data-ke-size=\"size16\">여기서 의문이 생긴다.<br />AI가 코딩을 다 해결해 준다면서, 왜 자사 제품은 여전히 \"개발자 생산성 우선\"인 Electron을 쓰고 있을까?<br /><b>구현이 더 이상 비싸지 않다고 외치는 회사가, 정작 본인 제품에서는 구현 비용을 아끼는 선택을 하고 있다.</b></p>\n<p data-ke-size=\"size16\">최근 Claude가 레거시 COBOL 코드를 마이그레이션할 수 있다는 주장에&nbsp; IBM 주가가 폭락했다는 <a href=\"https://zdnet.co.kr/view/?no=20260224171043\">기사</a>도 봤다.</p>\n<p data-ke-size=\"size16\">개발 비용 제로 시대?<br />글쎄.</p>\n<p data-ke-size=\"size16\">Claude 앱부터 개발자의 생산성보다 사용자의 사용성에 더 유용한 네이티브로 전환한 다음에, IBM 레거시 이야기를 해도 늦지 않지 않을까.</p>\n<hr data-ke-style=\"style1\" />\n<p data-ke-size=\"size16\">AI에 대해 부정적으로 보는 게 아니다.<br />우리 팀에 쌓인 레거시들을 해결하는 데 실제로 큰 도움을 받고 있고, 앞으로 더 많이 활용해야 한다고 생각한다.</p>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">참고로 우린 PM/PD/개발을 포함한 프로덕트 전체가 Claude Team Premium Seat를 쓰고 있다.</p>\n</blockquote>\n<p data-ke-size=\"size16\">다만 <b>Hype에 대해서 너무 휩쓸리진 말자</b>라는 것이다.<br />AI 도구의 사용법 자체에만 매몰되어, 소프트웨어 엔지니어링 공부를 등한시하는 것이 걱정이다.</p>\n<p data-ke-size=\"size16\">모든 의사들이 라식 수술을 하지 않듯이, AI 코딩을 외치는 회사들도 여러 제품에서는 여전히 전통적인 선택을 하고 있다.</p>\n<p data-ke-size=\"size16\">물론 어느 시점에는 정말 그런 날이 오겠지만, <b>지금 당장의 FOMO에 휩쓸려서 엔지니어링 공부 자체를 소홀히 하면 안 된다.</b></p>\n<p data-ke-size=\"size16\">결국 AI가 해결해 주지 못하는 10%를 누군가는 해결해야 하고, 그게 우리의 역할이다.<br />그 10%를 해결할 수 있는 힘은 결국 꾸준히 쌓아온 엔지니어링 역량에서 나온다.</p>",
        "contentSnippet": "안경을 오랫동안 쓰고 있다.\n주변에서 라식이나 라섹을 추천하는 사람들이 꽤 있었다.\n근데 정작 안과 의사분들 중에서도 \"빛 번짐, 안구건조증\" 때문에 안경을 쓰는 분들이 많다.\n난 안경을 올해로 30년째 쓰고 있고, 여전히 안과에 가면 안경을 쓰신 의사분들을 종종 보게 된다.\n앤트로픽 CEO 다리오 아모데이가 \"코딩은 6~12개월 내에 해결된 문제가 될 것\"이라고 발언한 인터뷰를 봤다.\nAI가 코딩을 대체할 거라는 꽤나 강한 톤의 발언이다.\n근데 정작 Claude 데스크탑 앱은 Electron이다.\nElectron은 웹 기술(HTML/CSS/JS)로 데스크탑 앱을 만들 수 있게 해주는 프레임워크다.\n소수의 개발팀이 웹, 앱, 데스크탑을 일관되게 관리할 수 있어서, 개발자의 생산성을 높여주는 도구로 널리 쓰인다.\n슬랙도, VS Code도 다 Electron이고, 스타트업이나 제품의 본질에 집중해야 할 때 우선적으로 선택하게 된다.\n다만 그 대가로 용량도 크고, 속도도 네이티브 구현보다 훨씬 느리다.\n즉, 사용자의 사용성을 어느 정도 포기하고 개발자의 생산성을 택하는 트레이드오프다.\n여기서 의문이 생긴다.\nAI가 코딩을 다 해결해 준다면서, 왜 자사 제품은 여전히 \"개발자 생산성 우선\"인 Electron을 쓰고 있을까?\n구현이 더 이상 비싸지 않다고 외치는 회사가, 정작 본인 제품에서는 구현 비용을 아끼는 선택을 하고 있다.\n최근 Claude가 레거시 COBOL 코드를 마이그레이션할 수 있다는 주장에  IBM 주가가 폭락했다는 기사도 봤다.\n개발 비용 제로 시대?\n글쎄.\nClaude 앱부터 개발자의 생산성보다 사용자의 사용성에 더 유용한 네이티브로 전환한 다음에, IBM 레거시 이야기를 해도 늦지 않지 않을까.\nAI에 대해 부정적으로 보는 게 아니다.\n우리 팀에 쌓인 레거시들을 해결하는 데 실제로 큰 도움을 받고 있고, 앞으로 더 많이 활용해야 한다고 생각한다.\n참고로 우린 PM/PD/개발을 포함한 프로덕트 전체가 Claude Team Premium Seat를 쓰고 있다.\n다만 Hype에 대해서 너무 휩쓸리진 말자라는 것이다.\nAI 도구의 사용법 자체에만 매몰되어, 소프트웨어 엔지니어링 공부를 등한시하는 것이 걱정이다.\n모든 의사들이 라식 수술을 하지 않듯이, AI 코딩을 외치는 회사들도 여러 제품에서는 여전히 전통적인 선택을 하고 있다.\n물론 어느 시점에는 정말 그런 날이 오겠지만, 지금 당장의 FOMO에 휩쓸려서 엔지니어링 공부 자체를 소홀히 하면 안 된다.\n결국 AI가 해결해 주지 못하는 10%를 누군가는 해결해야 하고, 그게 우리의 역할이다.\n그 10%를 해결할 수 있는 힘은 결국 꾸준히 쌓아온 엔지니어링 역량에서 나온다.",
        "guid": "https://jojoldu.tistory.com/867",
        "categories": [
          "생각정리",
          "claude code",
          "Electron",
          "라식",
          "앤트로픽",
          "의사",
          "클로드코드"
        ],
        "isoDate": "2026-02-26T04:12:00.000Z"
      },
      {
        "creator": "향로 (기억보단 기록을)",
        "title": "벽돌 쌓기",
        "link": "https://jojoldu.tistory.com/866",
        "pubDate": "Mon, 23 Feb 2026 08:13:00 +0900",
        "author": "향로 (기억보단 기록을)",
        "comments": "https://jojoldu.tistory.com/866#entry866comment",
        "content": "<h1>보이지 않는 벽돌</h1>\n<p>얼마 전에 올린 <a href=\"https://www.youtube.com/watch?v=ewO9thSbbvs\">유튜브 영상</a>에 이런 댓글이 달렸다.</p>\n<blockquote data-ke-style=\"style1\"><p data-ke-size=\"size16\"><span style=\"font-family: 'Noto Serif KR';\"><p>&quot;침대에 누워서 영상을 보다가, 울컥 한 것도 처음이네요.<br>결국 못 참고 집 밖에서 &#39;끅끅&#39; 애써 참아가며 울다가 들어왔습니다.&quot;</p>\n</span></p></blockquote><p>요즘 개발자들 사이에서 <code>불안</code> 이라는 단어가 자주 보인다.<br>공부를 하고는 있는데 이게 맞는 건지 모르겠고, 열심히 하고 있는데 성장하고 있는 건지 느껴지지 않는다.<br>밖에서는 AI 때문에 점점 더 개발자의 자리가 없을거라고, 지금 하고 있는 노력들이 무용지물이 될 거라는 이야기가 계속 돈다.  </p>\n<hr>\n<p><code>빵집</code> 압축 프로그램을 만드신 양병규 개발자님이 이스터에그로 자신의 생각을 숨겨놓은 내용이 있다. </p>\n<p>마침 이 내용이 <a href=\"https://www.clien.net/service/board/park/3518580\">클리앙에도 올라와 있어서</a> 공유하고 싶었다.</p>\n<blockquote data-ke-style=\"style1\"><p data-ke-size=\"size16\"><span style=\"font-family: 'Noto Serif KR';\"><p>한강 강바닥에 벽돌을 쌓는다.<br>강변이 아니라 강바닥이다.<br>헤엄쳐서 내려가서, 벽돌 한 장 놓고 올라온다.<br>나와서 보면 당연히 아무것도 안 보인다.<br>다음 날도 한 장, 그 다음 날도 한 장.<br>사흘이고 열흘이고 한 달이고, 매일매일 벽돌을 쌓아도 수면 위에서는 아무 변화가 없다.</p>\n<p>이쯤 되면 의심이 생긴다.<br>이걸 계속 해야 하나.<br>의미가 있긴 한 건가.<br>그래서 많은 사람들이 포기한다.</p>\n<p>근데 포기하지 않고 계속 쌓으면, 열흘이고 한 달이고 1년이고 2년이고, 언젠가는 그 벽돌이 수면 위로 올라온다.<br><strong>그때부터는 벽돌 한 장을 쌓으면 한 장이 쌓인 게 보인다.</strong><br>내 눈에만 보이는 게 아니라 남들 눈에도 보인다.<br>그리고 더 중요한 건, 그때부터 재밌어진다는 거다.<br>쌓는 대로 올라가는 게 보이니까.</p>\n</span></p></blockquote><p>대학교 4학년 2학기부터 5학년 2학기까지 1년 반을 취업 준비했다.<br>SI 회사에 들어가서도 매일 6시에 일어나서 8시 전에 출근해서 한 시간이라도 공부했다.<br>이직한 뒤에도 계속 공부했다.<br>회사에서 잘하지 못했으니까.<br>그때는 내가 성장하고 있는 건지 아닌 건지 알 수가 없었다.<br>방향도 못 잡겠고, 옆에 있는 개발자들에 비해서 부족한 건 분명했고.  </p>\n<p>근데 계속 쌓았다.<br>그러다 어느 날부터 사람들이 나보고 잘한다고 하더라.<br><strong>그때부터 공부한 만큼 실력이 올라가는 게 느껴지기 시작했다</strong>.<br><strong>한번 그게 느껴지니까, 안 해도 될 때도 하게 됐다</strong>.<br>재밌으니까.</p>\n<p>댓글 중에 공감되는 이야기가 있었다.</p>\n<blockquote data-ke-style=\"style1\"><p data-ke-size=\"size16\"><span style=\"font-family: 'Noto Serif KR';\"><p>&quot;사람마다 수심이 다르다는 말 듣자마자 마음 속에 울림이 생기고 다시 용기가 생겼습니다.&quot;</p>\n</span></p></blockquote><p>우리가 회빙환 웹툰 주인공처럼 눈앞에 스탯 창이 떠서 경험치가 쌓이는 게 보이면 아무도 포기 안 할 거다.<br>올라가는 게 보이니까.<br>근데 현실은 그렇지 않다.<br>눈에 보이지 않는다.<br>그럼에도 <strong>보이지 않는데 쌓이는 건 분명히 있다</strong>.  </p>\n<p>각자가 빠져 있는 수심이 다르다.<br>누군가는 3년 만에 벽돌이 수면 위로 올라오고, 누군가는 5년, 누군가는 7년이 걸릴 수도 있다.</p>\n<p><strong>지금 쌓고 있는 벽돌은 보이지 않지만, 사라지지도 않는다.</strong></p>\n<p>그러니까 오늘도 벽돌 한 장 쌓으면 된다.<br>안 보여도 괜찮다.<br>분명 쌓이고 있다.</p>",
        "contentSnippet": "보이지 않는 벽돌\n얼마 전에 올린 유튜브 영상에 이런 댓글이 달렸다.\n\n\"침대에 누워서 영상을 보다가, 울컥 한 것도 처음이네요.\n결국 못 참고 집 밖에서 '끅끅' 애써 참아가며 울다가 들어왔습니다.\"\n\n요즘 개발자들 사이에서 불안 이라는 단어가 자주 보인다.\n공부를 하고는 있는데 이게 맞는 건지 모르겠고, 열심히 하고 있는데 성장하고 있는 건지 느껴지지 않는다.\n밖에서는 AI 때문에 점점 더 개발자의 자리가 없을거라고, 지금 하고 있는 노력들이 무용지물이 될 거라는 이야기가 계속 돈다.  \n빵집 압축 프로그램을 만드신 양병규 개발자님이 이스터에그로 자신의 생각을 숨겨놓은 내용이 있다. \n마침 이 내용이 클리앙에도 올라와 있어서 공유하고 싶었다.\n\n한강 강바닥에 벽돌을 쌓는다.\n강변이 아니라 강바닥이다.\n헤엄쳐서 내려가서, 벽돌 한 장 놓고 올라온다.\n나와서 보면 당연히 아무것도 안 보인다.\n다음 날도 한 장, 그 다음 날도 한 장.\n사흘이고 열흘이고 한 달이고, 매일매일 벽돌을 쌓아도 수면 위에서는 아무 변화가 없다.\n이쯤 되면 의심이 생긴다.\n이걸 계속 해야 하나.\n의미가 있긴 한 건가.\n그래서 많은 사람들이 포기한다.\n근데 포기하지 않고 계속 쌓으면, 열흘이고 한 달이고 1년이고 2년이고, 언젠가는 그 벽돌이 수면 위로 올라온다.\n그때부터는 벽돌 한 장을 쌓으면 한 장이 쌓인 게 보인다.\n내 눈에만 보이는 게 아니라 남들 눈에도 보인다.\n그리고 더 중요한 건, 그때부터 재밌어진다는 거다.\n쌓는 대로 올라가는 게 보이니까.\n\n대학교 4학년 2학기부터 5학년 2학기까지 1년 반을 취업 준비했다.\nSI 회사에 들어가서도 매일 6시에 일어나서 8시 전에 출근해서 한 시간이라도 공부했다.\n이직한 뒤에도 계속 공부했다.\n회사에서 잘하지 못했으니까.\n그때는 내가 성장하고 있는 건지 아닌 건지 알 수가 없었다.\n방향도 못 잡겠고, 옆에 있는 개발자들에 비해서 부족한 건 분명했고.  \n근데 계속 쌓았다.\n그러다 어느 날부터 사람들이 나보고 잘한다고 하더라.\n그때부터 공부한 만큼 실력이 올라가는 게 느껴지기 시작했다.\n한번 그게 느껴지니까, 안 해도 될 때도 하게 됐다.\n재밌으니까.\n댓글 중에 공감되는 이야기가 있었다.\n\n\"사람마다 수심이 다르다는 말 듣자마자 마음 속에 울림이 생기고 다시 용기가 생겼습니다.\"\n\n우리가 회빙환 웹툰 주인공처럼 눈앞에 스탯 창이 떠서 경험치가 쌓이는 게 보이면 아무도 포기 안 할 거다.\n올라가는 게 보이니까.\n근데 현실은 그렇지 않다.\n눈에 보이지 않는다.\n그럼에도 보이지 않는데 쌓이는 건 분명히 있다.  \n각자가 빠져 있는 수심이 다르다.\n누군가는 3년 만에 벽돌이 수면 위로 올라오고, 누군가는 5년, 누군가는 7년이 걸릴 수도 있다.\n지금 쌓고 있는 벽돌은 보이지 않지만, 사라지지도 않는다.\n그러니까 오늘도 벽돌 한 장 쌓으면 된다.\n안 보여도 괜찮다.\n분명 쌓이고 있다.",
        "guid": "https://jojoldu.tistory.com/866",
        "categories": [
          "생각정리",
          "개발자",
          "벽돌쌓기",
          "빵집",
          "양병규",
          "취업",
          "커리어"
        ],
        "isoDate": "2026-02-22T23:13:00.000Z"
      }
    ]
  },
  {
    "name": "WestwoodForever's Dev Log",
    "category": "개인",
    "posts": []
  },
  {
    "name": "허니몬(Honeymon)의 자바guru",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Wolf Loves Fox :: 일상",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Game Programmer Life",
    "category": "개인",
    "posts": []
  },
  {
    "name": "yuchi's dev",
    "category": "개인",
    "posts": []
  },
  {
    "name": "만화로 나누는 자유/오픈소스 소프트웨어 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "신현석(Hyeonseok Shin)",
    "category": "개인",
    "posts": []
  },
  {
    "name": "즐거운 개발자 :: 네이버  블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황제펭귄의 게임개발이야기 [여기는 한국]",
    "category": "개인",
    "posts": []
  },
  {
    "name": "LINE ENGINEERING",
    "category": "기업",
    "posts": [
      {
        "title": "LINE DEV AI 리포터즈의 여정을 공유합니다!",
        "link": "https://techblog.lycorp.co.jp/ko/introducing-the-journey-of-the-line-dev-ai-reporters",
        "pubDate": "Mon, 23 Feb 2026 01:30:00 GMT",
        "content": "요즘은 \"AI 써보셨어요?\"라는 질문이 더 이상 특별하게 느껴지지 않습니다. 이미 많은 개발자들이 각자의 방식으로 ChatGPT나 Claude Code 같은 AI 도구를 업무에 활...",
        "contentSnippet": "요즘은 \"AI 써보셨어요?\"라는 질문이 더 이상 특별하게 느껴지지 않습니다. 이미 많은 개발자들이 각자의 방식으로 ChatGPT나 Claude Code 같은 AI 도구를 업무에 활...",
        "guid": "https://techblog.lycorp.co.jp/ko/introducing-the-journey-of-the-line-dev-ai-reporters",
        "isoDate": "2026-02-23T01:30:00.000Z"
      }
    ]
  },
  {
    "name": "뱅크샐러드 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "우아한형제들 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "TOAST Meetup",
    "category": "기업",
    "posts": [
      {
        "title": "읽지 않는 코드의 시대",
        "link": "https://meetup.nhncloud.com/posts/408",
        "pubDate": "Mon, 23 Feb 2026 00:20:28 GMT",
        "content": "[![NHN Cloud_meetup banner_coding_202602_900.png](https://image.toast.com/aaaadh/real/2026/techblog/NHN%20Cloudmeetup%20bannercoding202602900.png)](https://www.nhncloud.com/kr)\r\r\n\r\r\n>  본 콘텐츠는 작성자가 사내 게시판에 공유한 글을 가공한 것으로, 작성자의 의도와 맥락을 충실히 전달하기 위해 원문의 문장 스타일을 그대로 유지하였습니다.\r\r\n\r\r\n\r\r\n---\r\r\n<br>\r\r\n\r\r\n나는 오랫동안 아름다운 코드를 꿈꿔 왔다.\r\r\n\r\r\n순수 함수들이 물 흐르듯 합성되고, 타입 시스템이 버그를 원천적으로 불가능하게 만들며, 수학적 증명처럼 견고한 로직이 펼쳐지는 그런 코드. 우리는 그것을 '장인 정신'이라 불렀고, 그 경지에 도달하기 위해 범주론을 공부하고, 타입 레벨 프로그래밍을 이해하려 씨름했다.\r\r\n\r\r\n그러나 어느 날 문득 깨달았다. 더 이상 아무도 코드를 읽지 않는다는 것을.\r\r\n<br>\r\r\n## 가독성의 정의가 바뀌다\r\r\n'가독성'이라는 단어의 의미가 조용히, 그러나 근본적으로 변하고 있다.\r\r\n과거의 가독성은 **인간의 인지**를 위한 것이었다.\r\r\n\r\r\n* 개발자가 로직을 머릿속에서 추적할 수 있는가\r\r\n* 동료가 코드 리뷰에서 오류를 발견할 수 있는가\r\r\n* 6개월 후의 내가 이 코드를 이해할 수 있는가\r\r\n\r\r\n우리는 이 질문들에 답하기 위해 클린 코드(Clean Code)를 논했고, SOLID 원칙을 세웠으며, 디자인 패턴이라는 공통 언어를 만들었다. 모두 인간의 제한된 작업 기억 용량 안에서 복잡성을 다루기 위한 몸부림이었다.\r\r\n그러나 이제 가독성은 기계의 패턴 인식을 위한 것이 되어 가고 있다.\r\r\n\r\r\n* AI가 이 코드의 패턴을 학습 데이터에서 본 적 있는가\r\r\n* AI가 수정 요청을 받았을 때 정확한 위치를 찾을 수 있는가\r\r\n* AI가 로컬 변경을 가했을 때 전체 시스템이 깨지지 않는가\r\r\n\r\r\n이 두 가지 가독성은 때로 겹치지만, 본질적으로 다른 것을 최적화한다. 인간을 위한 가독성은 **추상화와 압축**을 추구한다. 반복을 제거하고, 패턴을 이름 붙이며, 복잡성을 캡슐화한다. 기계를 위한 가독성은 **명시성과 예측 가능성**을 추구한다. 관습을 따르고, 구조를 일정하게 유지하며, 장황하고 지저분해지더라도 암묵적인 것을 명시적으로 드러낸다.\r\r\n<br>\r\r\n## 장인 정신의 비극적 위치\r\r\n\r\r\n함수형 프로그래밍이 약속했던 것은 명확했다. 인간의 인지적 한계를 코드로 극복하는 것.\r\r\n참조 투명성은 코드의 어떤 부분이든 독립적으로 추론할 수 있게 해주었다. 불변성은 시간에 따른 상태 변화를 머릿속에서 추적하는 부담을 덜어주었다. 강력한 타입 시스템은 컴파일러가 우리 대신 오류를 잡아주었다. 이 모든 것이 **인간의 한계를 보완**하기 위한 도구였다.\r\r\n\r\r\n그러나 AI에게는 보완할 한계가 없다.\r\r\n\r\r\nAI는 수백만 개의 코드베이스를 학습했다. 패턴 매칭의 원시적 힘으로 무장한 AI에게, 인간의 인지 부하를 줄여주는 우아한 추상화는 그저 노이즈에 가깝다. AI는 똑같은 CRUD 작업의 만 가지 변형을 보았다. 심혈을 기울여 작성한 우아한 모나드 트랜스포머 스택보다 평범하고 반복적인 명령형 코드가 AI에게는 더 익숙하다.\r\r\n여기서 장인 정신의 딜레마가 시작된다.\r\r\n\r\r\n함수형 프로그래밍의 지지자들은 수십 년간 같은 말을 해왔다.\r\r\n\r\r\n\"배우기는 어렵지만, 장기적 이점이 있습니다.\"\r\r\n\r\r\n그런데 AI가 명령형 프로그래밍의 진입 장벽을 무너뜨려버렸다. 이제 누구나 AI의 도움으로 명령형 코드를 빠르게 작성할 수 있다. 반면 함수형 프로그래밍의 학습 곡선은 여전히 가파르다.\r\r\n더욱 쓸쓸한 것은 함수형 프로그래밍의 아름다움을 감상할 줄 아는 사람들마저 더 이상 코드를 직접 읽지 않는다는 사실이다. 그들의 Claude Code가 대신 읽는다. 감상할 눈이 사라진 예술이 무슨 의미가 있을까.\r\r\n\r\r\n```\r\r\nClaude >> @PureFunctional OrderService::doStuff의 로직을 분석해서 설명해 줘\r\r\n```\r\r\n<br>\r\r\n## 매개체로 전락한 코드\r\r\n\r\r\n이제 코드의 존재론적 지위가 바뀌고 있다.\r\r\n과거에 코드는 인간의 영역이었다. 우리는 그 안에서 살았다. 매일 읽고, 고치고, 확장했다. 변수명 하나에 고민하고, 함수의 위치를 두고 토론했다. 코드는 우리의 생각이 물질화된 것이었고, 그래서 우리는 그것의 아름다움에 신경 썼다.\r\r\n이제 코드는 인간의 의도와 기계의 실행 사이를 잇는 매개체가 되어 가고 있다.\r\r\n\r\r\n```\r\r\n인간의 의도 → 자연어 명세 → AI → 코드(누가 신경이나 쓰는가) → 실행\r\r\n```\r\r\n\r\r\n이 모델에서 함수형 vs 객체지향 논쟁은 x86 vs ARM 논쟁과 비슷해진다. 특정 상황에서 성능 차이가 있을 수 있다. 그러나 그것은 더 이상 인간이 거주하는 층위가 아니다.\r\r\n우리는 집을 짓는 목수에서 집을 주문하는 건축주가 되어 가고 있다. 목수에게 나뭇결은 단순한 무늬가 아니다. 그것은 나무의 강도와 방향을 말해주고, 어디를 깎고 어디를 살려야 할지 알려주며, 완성된 작품이 세월을 어떻게 견딜지를 예언한다. 그러나 건축주는 문이 제대로 닫히면 그만이다.\r\r\n<br>\r\r\n## 새로운 미학의 등장\r\r\n\r\r\n그렇다면 AI 시대의 '좋은 코드'란 무엇인가? 새로운 미학이 필요하다.\r\r\n\r\r\n### 관용적 표현이 최적화를 이긴다\r\r\n\r\r\n```\r\r\n// AI 친화적: 수백만 번 본 패턴\r\r\nusers.stream().filter(User::isActive).toList();\r\r\n\r\r\n// AI 비친화적: 이게 뭐 하는 코드지?\r\r\nusers.stream().reduce(new ArrayList<>(),\r\r\n    (acc, u) -> { if(u.isActive()) acc.add(u); return acc; },\r\r\n    (a, b) -> { a.addAll(b); return a; });\r\r\n```\r\r\n\r\r\nAI는 익숙한 것을 잘 다룬다. 창의적인 최적화보다 평범한 관용구가 더 안전하다.\r\r\n\r\r\n### 추론의 지역성\r\r\n\r\r\n함수를 이해하는 데 필요한 모든 것이 눈에 보이거나, 한 번의 점프로 도달 가능해야 한다. Action at a distance는 금물이다. Dependency injection 트릭, aspect weaving, runtime proxy—이 모든 암묵적 메커니즘이 AI의 추론을 방해한다.\r\r\n\r\r\n### 예측 가능한 구조\r\r\n\r\r\n```\r\r\n/order\r\r\n  OrderController.java\r\r\n  OrderService.java\r\r\n  OrderRepository.java\r\r\n  Order.java\r\r\n```\r\r\n\r\r\nAI는 관습에서 맥락을 추론한다. 파일이 어디 있을지 예측할 수 있으면, 탐색 비용이 줄어든다. 관습은 압축된 정보다.\r\r\n\r\r\n### 명시적 상태 전이\r\r\n\r\r\n```\r\r\n// AI 친화적: 가능한 상태가 명시적으로 열거됨\r\r\nenum Status { DRAFT, SUBMITTED, FULFILLED }\r\r\n\r\r\n// AI 비친화적: 플래그 조합으로 상태를 유추해야 함\r\r\nboolean isSubmitted;\r\r\nboolean isFulfilled;\r\r\nboolean isDraft;\r\r\n```\r\r\n\r\r\n상태가 열거형으로 선언되어 있으면 AI는 전체 그림을 한눈에 파악한다. 여러 boolean 플래그를 조합해서 상태를 유추해야 하는 코드는 AI도 인간처럼 길을 잃는다. `isSubmitted`와 `isFulfilled`가 동시에 true면 무슨 상태인가?\r\r\n\r\r\n### 장황하지만 명확한 이름\r\r\n\r\r\n```\r\r\n// AI 친화적: 이름만 봐도 의도가 명확\r\r\npublic boolean isEligibleForRefundBasedOnPurchaseDateAndMembershipStatus()\r\r\n\r\r\n// AI 비친화적: 주석에 의존\r\r\n/** 구매일과 멤버십 상태에 따라 환불 가능 여부를 판단한다 */\r\r\npublic boolean canRefund()\r\r\n```\r\r\n\r\r\n인간에게는 간결한 이름과 상세한 주석이 읽기 좋을 수 있다. 그러나 AI는 주석보다 코드를 신뢰한다. 함수명 자체가 의도를 담고 있으면, AI는 별도의 맥락 없이도 정확하게 해당 함수를 활용할 수 있다.\r\r\n\r\r\n### 작은 파일, 단일 책임\r\r\n\r\r\n100줄짜리 파일 10개가 1000줄짜리보다 낫다. AI의 컨텍스트 윈도우는 실질적 제약이다. 작은 파일은 전체를 교체하기도, 부분을 수정하기도 쉽다.\r\r\n\r\r\n### 명세로서의 테스트\r\r\n\r\r\n```\r\r\n@Test\r\r\nvoid shouldRejectOrderWhenInventoryInsufficient() { ... }\r\r\n```\r\r\n\r\r\nAI는 테스트를 읽고 코드의 의도를 역으로 파악한다. 테스트 이름이 곧 요구 사항이 되고, 테스트 본문이 곧 예제가 된다.\r\r\n<br>\r\r\n## 아이러니: 함수형의 귀환\r\r\n\r\r\n흥미로운 반전이 있다.\r\r\nAI 친화적 코드의 원칙들—불변성, 명시적 상태, 작고 순수한 함수—은 함수형 프로그래밍의 원칙과 상당 부분 겹친다.\r\r\n함수형 프로그래밍은 살아남을 것이다. 그것이 아름다워서가 아니라, **기계가 읽기 좋아서**.\r\r\n\r\r\n고차원적 추상화와 이론적 우아함은 사라질 것이다. 그러나 불변 데이터, 순수 함수, 명시적 타입은 남을 것이다. 미학은 바뀌었지만, 핵심 원칙들은 다른 이유로 생명을 얻었다. 이것이 함수형 프로그래밍 애호가들에게 위안이 될지는 모르겠다. 사랑하는 것이 살아남았지만, 사랑 받는 이유가 완전히 달라졌으니.\r\r\n<br>\r\r\n## 결론\r\r\n\r\r\n우리는 아름다운 시대의 끝자락에 서 있다.\r\r\n코드를 매개로 인간과 인간이 소통하던 시대. 변수명 하나에 의도를 담고, 함수의 구조로 사고의 흐름을 표현하던 시대. 동료의 코드를 읽으며 그의 사고방식을 이해하고, 때로는 감탄하던 시대.\r\r\n\r\r\n그 시대가 저물고 있다.\r\r\n코드는 점점 인간의 눈을 거치지 않는 영역으로 이동하고 있다. 우리가 코드 안에서 살았기 때문에 그 아름다움에 신경 썼듯이, 우리가 코드 밖으로 나가면 그 아름다움은 의미를 잃는다. 장인 정신은 LP 레코드나 기계식 시계처럼—효율보다 과정을 사랑하는 이들의 영역으로 남게 될 것이다. 시장은 우아함을 알아봐주지 않는다. 시장은 속도를 원한다. 그리고 AI가 명령형 코드의 속도를 거의 무한히 빠르게 만들어 버렸다.\r\r\n\r\r\n그래도 우리는 가끔, 퇴근 후 조용한 사무실에서 마침내 완성한 순수 함수의 체인이 테스트를 통과하며 초록불이 켜지던 순간을 기억할 것이다. 타입 시스템이 버그를 컴파일 타임에 잡아주었을 때의 희열을. 코드가 단지 작동하는 것을 넘어, 그 자체로 하나의 증명이 되었을 때의 만족을.\r\r\n\r\r\n아름다운 추억이다.\r\r\n\r\r\n---\r\r\n\r\r\n>  본 콘텐츠는 작성자가 사내 게시판에 공유한 글을 가공한 것으로, 작성자의 의도와 맥락을 충실히 전달하기 위해 원문의 문장 스타일을 그대로 유지하였습니다.\r\r\n\r\r\n\r\r\n[![NHN Cloud_meetup banner_footer_202507-01.png](https://image.toast.com/aaaadh/real/2026/techblog/NHN%20Cloudmeetup%20bannerfooter20250701.png)](https://www.nhncloud.com/kr)",
        "contentSnippet": "[![NHN Cloud_meetup banner_coding_202602_900.png](https://image.toast.com/aaaadh/real/2026/techblog/NHN%20Cloudmeetup%20bannercoding202602900.png)](https://www.nhncloud.com/kr)\r\r\n\r\r\n>  본 콘텐츠는 작성자가 사내 게시판에 공유한 글을 가공한 것으로, 작성자의 의도와 맥락을 충실히 전달하기 위해 원문의 문장 스타일을 그대로 유지하였습니다.\r\r\n\r\r\n\r\r\n---\r\r\n\r\r\n\r\r\n나는 오랫동안 아름다운 코드를 꿈꿔 왔다.\r\r\n\r\r\n순수 함수들이 물 흐르듯 합성되고, 타입 시스템이 버그를 원천적으로 불가능하게 만들며, 수학적 증명처럼 견고한 로직이 펼쳐지는 그런 코드. 우리는 그것을 '장인 정신'이라 불렀고, 그 경지에 도달하기 위해 범주론을 공부하고, 타입 레벨 프로그래밍을 이해하려 씨름했다.\r\r\n\r\r\n그러나 어느 날 문득 깨달았다. 더 이상 아무도 코드를 읽지 않는다는 것을.\r\r\n\r\r\n## 가독성의 정의가 바뀌다\r\r\n'가독성'이라는 단어의 의미가 조용히, 그러나 근본적으로 변하고 있다.\r\r\n과거의 가독성은 **인간의 인지**를 위한 것이었다.\r\r\n\r\r\n* 개발자가 로직을 머릿속에서 추적할 수 있는가\r\r\n* 동료가 코드 리뷰에서 오류를 발견할 수 있는가\r\r\n* 6개월 후의 내가 이 코드를 이해할 수 있는가\r\r\n\r\r\n우리는 이 질문들에 답하기 위해 클린 코드(Clean Code)를 논했고, SOLID 원칙을 세웠으며, 디자인 패턴이라는 공통 언어를 만들었다. 모두 인간의 제한된 작업 기억 용량 안에서 복잡성을 다루기 위한 몸부림이었다.\r\r\n그러나 이제 가독성은 기계의 패턴 인식을 위한 것이 되어 가고 있다.\r\r\n\r\r\n* AI가 이 코드의 패턴을 학습 데이터에서 본 적 있는가\r\r\n* AI가 수정 요청을 받았을 때 정확한 위치를 찾을 수 있는가\r\r\n* AI가 로컬 변경을 가했을 때 전체 시스템이 깨지지 않는가\r\r\n\r\r\n이 두 가지 가독성은 때로 겹치지만, 본질적으로 다른 것을 최적화한다. 인간을 위한 가독성은 **추상화와 압축**을 추구한다. 반복을 제거하고, 패턴을 이름 붙이며, 복잡성을 캡슐화한다. 기계를 위한 가독성은 **명시성과 예측 가능성**을 추구한다. 관습을 따르고, 구조를 일정하게 유지하며, 장황하고 지저분해지더라도 암묵적인 것을 명시적으로 드러낸다.\r\r\n\r\r\n## 장인 정신의 비극적 위치\r\r\n\r\r\n함수형 프로그래밍이 약속했던 것은 명확했다. 인간의 인지적 한계를 코드로 극복하는 것.\r\r\n참조 투명성은 코드의 어떤 부분이든 독립적으로 추론할 수 있게 해주었다. 불변성은 시간에 따른 상태 변화를 머릿속에서 추적하는 부담을 덜어주었다. 강력한 타입 시스템은 컴파일러가 우리 대신 오류를 잡아주었다. 이 모든 것이 **인간의 한계를 보완**하기 위한 도구였다.\r\r\n\r\r\n그러나 AI에게는 보완할 한계가 없다.\r\r\n\r\r\nAI는 수백만 개의 코드베이스를 학습했다. 패턴 매칭의 원시적 힘으로 무장한 AI에게, 인간의 인지 부하를 줄여주는 우아한 추상화는 그저 노이즈에 가깝다. AI는 똑같은 CRUD 작업의 만 가지 변형을 보았다. 심혈을 기울여 작성한 우아한 모나드 트랜스포머 스택보다 평범하고 반복적인 명령형 코드가 AI에게는 더 익숙하다.\r\r\n여기서 장인 정신의 딜레마가 시작된다.\r\r\n\r\r\n함수형 프로그래밍의 지지자들은 수십 년간 같은 말을 해왔다.\r\r\n\r\r\n\"배우기는 어렵지만, 장기적 이점이 있습니다.\"\r\r\n\r\r\n그런데 AI가 명령형 프로그래밍의 진입 장벽을 무너뜨려버렸다. 이제 누구나 AI의 도움으로 명령형 코드를 빠르게 작성할 수 있다. 반면 함수형 프로그래밍의 학습 곡선은 여전히 가파르다.\r\r\n더욱 쓸쓸한 것은 함수형 프로그래밍의 아름다움을 감상할 줄 아는 사람들마저 더 이상 코드를 직접 읽지 않는다는 사실이다. 그들의 Claude Code가 대신 읽는다. 감상할 눈이 사라진 예술이 무슨 의미가 있을까.\r\r\n\r\r\n```\r\r\nClaude >> @PureFunctional OrderService::doStuff의 로직을 분석해서 설명해 줘\r\r\n```\r\r\n\r\r\n## 매개체로 전락한 코드\r\r\n\r\r\n이제 코드의 존재론적 지위가 바뀌고 있다.\r\r\n과거에 코드는 인간의 영역이었다. 우리는 그 안에서 살았다. 매일 읽고, 고치고, 확장했다. 변수명 하나에 고민하고, 함수의 위치를 두고 토론했다. 코드는 우리의 생각이 물질화된 것이었고, 그래서 우리는 그것의 아름다움에 신경 썼다.\r\r\n이제 코드는 인간의 의도와 기계의 실행 사이를 잇는 매개체가 되어 가고 있다.\r\r\n\r\r\n```\r\r\n인간의 의도 → 자연어 명세 → AI → 코드(누가 신경이나 쓰는가) → 실행\r\r\n```\r\r\n\r\r\n이 모델에서 함수형 vs 객체지향 논쟁은 x86 vs ARM 논쟁과 비슷해진다. 특정 상황에서 성능 차이가 있을 수 있다. 그러나 그것은 더 이상 인간이 거주하는 층위가 아니다.\r\r\n우리는 집을 짓는 목수에서 집을 주문하는 건축주가 되어 가고 있다. 목수에게 나뭇결은 단순한 무늬가 아니다. 그것은 나무의 강도와 방향을 말해주고, 어디를 깎고 어디를 살려야 할지 알려주며, 완성된 작품이 세월을 어떻게 견딜지를 예언한다. 그러나 건축주는 문이 제대로 닫히면 그만이다.\r\r\n\r\r\n## 새로운 미학의 등장\r\r\n\r\r\n그렇다면 AI 시대의 '좋은 코드'란 무엇인가? 새로운 미학이 필요하다.\r\r\n\r\r\n### 관용적 표현이 최적화를 이긴다\r\r\n\r\r\n```\r\r\n// AI 친화적: 수백만 번 본 패턴\r\r\nusers.stream().filter(User::isActive).toList();\r\r\n\r\r\n// AI 비친화적: 이게 뭐 하는 코드지?\r\r\nusers.stream().reduce(new ArrayList(),\r\r\n    (acc, u) -> { if(u.isActive()) acc.add(u); return acc; },\r\r\n    (a, b) -> { a.addAll(b); return a; });\r\r\n```\r\r\n\r\r\nAI는 익숙한 것을 잘 다룬다. 창의적인 최적화보다 평범한 관용구가 더 안전하다.\r\r\n\r\r\n### 추론의 지역성\r\r\n\r\r\n함수를 이해하는 데 필요한 모든 것이 눈에 보이거나, 한 번의 점프로 도달 가능해야 한다. Action at a distance는 금물이다. Dependency injection 트릭, aspect weaving, runtime proxy—이 모든 암묵적 메커니즘이 AI의 추론을 방해한다.\r\r\n\r\r\n### 예측 가능한 구조\r\r\n\r\r\n```\r\r\n/order\r\r\n  OrderController.java\r\r\n  OrderService.java\r\r\n  OrderRepository.java\r\r\n  Order.java\r\r\n```\r\r\n\r\r\nAI는 관습에서 맥락을 추론한다. 파일이 어디 있을지 예측할 수 있으면, 탐색 비용이 줄어든다. 관습은 압축된 정보다.\r\r\n\r\r\n### 명시적 상태 전이\r\r\n\r\r\n```\r\r\n// AI 친화적: 가능한 상태가 명시적으로 열거됨\r\r\nenum Status { DRAFT, SUBMITTED, FULFILLED }\r\r\n\r\r\n// AI 비친화적: 플래그 조합으로 상태를 유추해야 함\r\r\nboolean isSubmitted;\r\r\nboolean isFulfilled;\r\r\nboolean isDraft;\r\r\n```\r\r\n\r\r\n상태가 열거형으로 선언되어 있으면 AI는 전체 그림을 한눈에 파악한다. 여러 boolean 플래그를 조합해서 상태를 유추해야 하는 코드는 AI도 인간처럼 길을 잃는다. `isSubmitted`와 `isFulfilled`가 동시에 true면 무슨 상태인가?\r\r\n\r\r\n### 장황하지만 명확한 이름\r\r\n\r\r\n```\r\r\n// AI 친화적: 이름만 봐도 의도가 명확\r\r\npublic boolean isEligibleForRefundBasedOnPurchaseDateAndMembershipStatus()\r\r\n\r\r\n// AI 비친화적: 주석에 의존\r\r\n/** 구매일과 멤버십 상태에 따라 환불 가능 여부를 판단한다 */\r\r\npublic boolean canRefund()\r\r\n```\r\r\n\r\r\n인간에게는 간결한 이름과 상세한 주석이 읽기 좋을 수 있다. 그러나 AI는 주석보다 코드를 신뢰한다. 함수명 자체가 의도를 담고 있으면, AI는 별도의 맥락 없이도 정확하게 해당 함수를 활용할 수 있다.\r\r\n\r\r\n### 작은 파일, 단일 책임\r\r\n\r\r\n100줄짜리 파일 10개가 1000줄짜리보다 낫다. AI의 컨텍스트 윈도우는 실질적 제약이다. 작은 파일은 전체를 교체하기도, 부분을 수정하기도 쉽다.\r\r\n\r\r\n### 명세로서의 테스트\r\r\n\r\r\n```\r\r\n@Test\r\r\nvoid shouldRejectOrderWhenInventoryInsufficient() { ... }\r\r\n```\r\r\n\r\r\nAI는 테스트를 읽고 코드의 의도를 역으로 파악한다. 테스트 이름이 곧 요구 사항이 되고, 테스트 본문이 곧 예제가 된다.\r\r\n\r\r\n## 아이러니: 함수형의 귀환\r\r\n\r\r\n흥미로운 반전이 있다.\r\r\nAI 친화적 코드의 원칙들—불변성, 명시적 상태, 작고 순수한 함수—은 함수형 프로그래밍의 원칙과 상당 부분 겹친다.\r\r\n함수형 프로그래밍은 살아남을 것이다. 그것이 아름다워서가 아니라, **기계가 읽기 좋아서**.\r\r\n\r\r\n고차원적 추상화와 이론적 우아함은 사라질 것이다. 그러나 불변 데이터, 순수 함수, 명시적 타입은 남을 것이다. 미학은 바뀌었지만, 핵심 원칙들은 다른 이유로 생명을 얻었다. 이것이 함수형 프로그래밍 애호가들에게 위안이 될지는 모르겠다. 사랑하는 것이 살아남았지만, 사랑 받는 이유가 완전히 달라졌으니.\r\r\n\r\r\n## 결론\r\r\n\r\r\n우리는 아름다운 시대의 끝자락에 서 있다.\r\r\n코드를 매개로 인간과 인간이 소통하던 시대. 변수명 하나에 의도를 담고, 함수의 구조로 사고의 흐름을 표현하던 시대. 동료의 코드를 읽으며 그의 사고방식을 이해하고, 때로는 감탄하던 시대.\r\r\n\r\r\n그 시대가 저물고 있다.\r\r\n코드는 점점 인간의 눈을 거치지 않는 영역으로 이동하고 있다. 우리가 코드 안에서 살았기 때문에 그 아름다움에 신경 썼듯이, 우리가 코드 밖으로 나가면 그 아름다움은 의미를 잃는다. 장인 정신은 LP 레코드나 기계식 시계처럼—효율보다 과정을 사랑하는 이들의 영역으로 남게 될 것이다. 시장은 우아함을 알아봐주지 않는다. 시장은 속도를 원한다. 그리고 AI가 명령형 코드의 속도를 거의 무한히 빠르게 만들어 버렸다.\r\r\n\r\r\n그래도 우리는 가끔, 퇴근 후 조용한 사무실에서 마침내 완성한 순수 함수의 체인이 테스트를 통과하며 초록불이 켜지던 순간을 기억할 것이다. 타입 시스템이 버그를 컴파일 타임에 잡아주었을 때의 희열을. 코드가 단지 작동하는 것을 넘어, 그 자체로 하나의 증명이 되었을 때의 만족을.\r\r\n\r\r\n아름다운 추억이다.\r\r\n\r\r\n---\r\r\n\r\r\n>  본 콘텐츠는 작성자가 사내 게시판에 공유한 글을 가공한 것으로, 작성자의 의도와 맥락을 충실히 전달하기 위해 원문의 문장 스타일을 그대로 유지하였습니다.\r\r\n\r\r\n\r\r\n[![NHN Cloud_meetup banner_footer_202507-01.png](https://image.toast.com/aaaadh/real/2026/techblog/NHN%20Cloudmeetup%20bannerfooter20250701.png)](https://www.nhncloud.com/kr)",
        "isoDate": "2026-02-23T00:20:28.000Z"
      }
    ]
  },
  {
    "name": "ZUM 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "SK Planet",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Spoqa tech blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "팀 왈도 번역팀",
    "category": "게임",
    "posts": []
  },
  {
    "name": "근원님",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황의윤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "호돌맨",
    "category": "개인",
    "posts": []
  },
  {
    "name": "박우빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "문다영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "유수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "안건주",
    "category": "개인",
    "posts": []
  },
  {
    "name": "손현호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "STARTUP BIBLE",
    "category": "개인",
    "posts": [
      {
        "creator": "Kihong Bae",
        "title": "네임드롭핑",
        "link": "https://www.thestartupbible.com/2026/02/namedropping.html",
        "pubDate": "Wed, 25 Feb 2026 21:37:00 +0000",
        "content:encodedSnippet": "네임드롭핑(namedropping)에 대한 이야기를 내가 지난 몇 년 동안 꽤 자주 했는데, 최근에 이런 분들을 갑자기 몇 명 만나서 또 해보려고 한다.\nNamedropping은 말 그대로 “이름을 내뱉다”라는 의미인데, 쓸데없이 아는 사람의 이름을 파는 행위를 말한다. 아마도 이 글을 읽는 분들도 본인들이 직접 이런 경험이 있거나, 주변에 네임드롭핑을 하는 사람들이 있을 것이다. 나도 과거에 가끔 네임드롭핑을 했던 시기가 있고, 아직도 내 주변에는 본인이 아는 유명한 사람의 이름을 쉬지 않고 줄줄 내뱉는 사람들이 꽤 많다. 이렇게 하면 본인들이 돋보이는 줄 아는데, 실은 결과는 완전히 그 반대다.\n얼마전에 만났던 분이 있는데, 이 분은 내 인생 두번째 네임드롭퍼였다.(내 인생 일등의 네임드롭퍼는 세계 최강). 이 분과 35분 미팅했는데, 그 35분 동안 본인이 아는 투자자, 연예인, 정치인, 사업가의 이름 거의 20개를 나에게 배설했다. 실은 이 중 내가 아는 분들도 있었고, 꽤 친한 분들도 있었는데, 나는 다른 사람 아는체 하는걸 별로 안 좋아하고, 특히나 정말 친하지 않으면 절대로 친하다는 말을 안 하는 편이다. 이 분이 잘 안다고 하는 분들과 정말로 “형, 동생, 누님” 할 정도로 개인적으로 친한진 모르겠지만, 내가 전혀 모르고, 관심도 없는 사람들에 대한 험담까지 하자 조금 직설적으로 이 미팅은 끝났으니까 그냥 가라고 했다.\n“나는 당신이 누굴 아는지 관심도 없고, 당신에게 관심이 있어서 소중한 시간을 할애했다. 그리고 남의 이야기가 아니라 당신의 이야기를 듣고 싶었는데, 그렇게 당신에 대해서 할 말이 없다면 서로 시간 낭비하지 말자.”라는 말을 처음 보는 사람 면상에서 하자니 좀 불편하긴 했지만, 안 그랬으면 내가 나중에 시간 낭비한 것에 대해 스스로에게 화가 날 것 같았다.\n혹시 나랑 미팅이 잡혀 있는 분이 있다면, 이 포스팅의 내용을 명심하기 바란다. 나는 내가 미팅하는 분이 어떤 사람이고, 어떤 생각을 하고, 이 분이 창업한 회사는 어떤 회사인지 알고 싶다. 이 분이 누굴 알고, 누구랑 형, 동생 하면서 친하게 지내고, 아는 그 분이 얼마나 돈이 많고, 얼마짜리 차를 몰고 다니는지 전혀 관심 없다. 그 사람에게 관심이 있었다면, 내가 그 사람을 만났을 것이다.\n특히나 한국같이 사회적인 체면이 중요하고, 내가 뭘 아는가 보다, 누굴 아는가가 더 중요하다는 인식이 팽배한 곳에서는 네임드롭핑이 빈번하게 일어나는데, 어쨌든 나랑 만날 땐 제발 이 짓을 하지 않았으면 좋겠다.\n그리고 마지막으로, 네임드롭핑을 꼭 해야 한다면, 그 사람에 대해 칭찬해라. 험담은 말하는 자, 험담의 대상자, 그리고 듣는 자, 이렇게 세 명을 그 자리에서 죽인다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2026/02/namedropping.html#comments",
        "content": "네임드롭핑(namedropping)에 대한 이야기를 내가 지난 몇 년 동안 꽤 자주 했는데, 최근에 이런 분들을 갑자기 몇 명 만나서 또 해보려고 한다. Namedropping은 말 그대로 “이름을 내뱉다”라는 의미인데, 쓸데없이 아는 사람의 이름을 파는 행위를 말한다. 아마도 이 글을 읽는 분들도 본인들이 직접 이런 경험이 있거나, 주변에 네임드롭핑을 하는 사람들이 있을 것이다. 나도 과거에 가끔 네임드롭핑을 했던(...)",
        "contentSnippet": "네임드롭핑(namedropping)에 대한 이야기를 내가 지난 몇 년 동안 꽤 자주 했는데, 최근에 이런 분들을 갑자기 몇 명 만나서 또 해보려고 한다. Namedropping은 말 그대로 “이름을 내뱉다”라는 의미인데, 쓸데없이 아는 사람의 이름을 파는 행위를 말한다. 아마도 이 글을 읽는 분들도 본인들이 직접 이런 경험이 있거나, 주변에 네임드롭핑을 하는 사람들이 있을 것이다. 나도 과거에 가끔 네임드롭핑을 했던(...)",
        "guid": "https://www.thestartupbible.com/?p=9696",
        "categories": [
          "Uncategorized",
          "general",
          "people"
        ],
        "isoDate": "2026-02-25T21:37:00.000Z"
      },
      {
        "creator": "Kihong Bae",
        "title": "용기가 복리처럼 불어날 때",
        "link": "https://www.thestartupbible.com/2026/02/when-courage-compounds.html",
        "pubDate": "Sun, 22 Feb 2026 21:24:00 +0000",
        "content:encodedSnippet": "지난 2년은 대부분의 창업가에겐 20년 같이 느껴졌을 정도로 길고, 힘들었을 것이다. 우리 투자사 중에서도 남들보다 월등하게 잘하는 곳도 있지만, 이런 회사들은 아웃라이어이고, 대부분 정말 배고프고, 춥고, 스트레스 가득 차고, 하루가 이틀이었으면 하는 바람으로 창업가라는 왕관의 무게를 버텼다. 이 중 이젠 사라진 스타트업도 꽤 있고, 잘 살아남아서 이제 다시 성장의 준비를 하는 곳들도 있지만, 대부분 아직 데미지에서 서서히 회복하고 있는 것 같다.\n하지만, 힘든 시기를 겪으면서 이제 바닥에서 서서히 회복하고 있는 창업가분들과 이야기를 해보면 여전히 전반적인 분위기와 기조는 긍정적이어서 나에게는 희망이 보인다. 원래 내가 아는 좋은 창업가들은 고비를 잘 참고, 포기를 잘 모르기 때문에 어려운 상황에서도 이런 초긍정 태도를 유지할 수 있다고 생각하는 반면 나 같으면 저렇게 어려운 상황에서 계속 고개를 들고 현실을 직시하면서, 매일매일 크고 작은 불을 태연하게 끌 수 있을지 스스로에게 항상 물어본다. 최근에 이런 창업가들을 보고 머릿속에서 떠오르는 하나의 단어는 바로 ‘용기’라는 단어다. 어떻게 이 사람들은 절망적인 순간에 이런 대단한 용기를 보여줄 수 있을까.\n이런 창업가 몇 분과 이야기를 해보고, 여러 가지 기사와 팟캐스트를 들으면서 나만의 개똥 답안이 완성되긴 했다. 이들에겐 몇 가지 공통점이 있었다. 사업을 하면서 힘들었던 순간들이 기억할 수 없을 정도로 많았지만, 그중 기억나는 최악의 상황이 대부분 몇 번 있었다고 한다. 이런 최악의 상황이 닥쳤을 때, 이들이 최악의 상황 속에서 봤던 또 다른 이면은, 바로 이 최악의 상황이 “모든 게 다 괜찮을 거야”라고 할 정도로 희망적이진 않았지만, 실제로 걱정했던 것처럼 정말로 죽을 정도는 아니었다는 점이다. 그리고 죽을 정도는 아니라는 것을 느끼는 순간, 항상 했던 것처럼 최선을 다해 열심히 하다 보면 또 어떻게 길을 찾고, 잘 극복해서 살아 남는 경우가 꽤 많았다는 것이다.\n최악이라고, 정말 망할 수 있겠다고, 정말 죽을 수 있겠다고 생각했던 그 순간을 어찌어찌해서 살아 남으면, 여기서 말콤 글래드웰이 정의한 용기가 작용하는 것 같다. 글래드웰이 정의한 용기에 대한 포스팅은 여기서 확인할 수 있는데, 요약하자면 다음과 같다.\n“힘든 상황에서 자신을 용감하게 만드는 용기는 선천적인 게 아니다. 굉장히 힘든 상황을 극복했는데, 되돌아보니 이 상황이 생각만큼 힘들지 않았다고 느낄 때, 그때 후천적으로 습득하는 게 용기이다.”\n\n\n\n\n스타트업을 하다보면, 위에서 말 한 최악의 상황이 계속 발생한다. 한 번의 죽을 고비를 넘기면, 또 다른 고비가 오고, 고비가 올 때마다 실은 그 심각함과 나쁜 정도는 배가된다. 고비가 올 때마다 이번엔 정말 끝이라는 걱정을 하지만, 어찌어찌 죽지 않고 그 상황을 극복하고, 상황을 극복하고 뒤 돌아보면 또 그렇게 죽을 정도는 아니었다고 생각한다. 바로 이 생각이 몸에 학습되면서 용기가 생긴다. 그리고 이 과정을 반복하다 보면 용기에도 복리가 적용된다.\n이렇게 용기에 복리가 적용되면 초인이 된다. 슈퍼맨 같은 초인이 아니라 어려움과 장애물에 초인적인 태도를 보일 수 있는, 그런 강하고 용기있는 초인 말이다.\n힘들다. 바쁘다. 피곤하다. 어쩔 땐 정말 죽을 것 같다. 나도 이런 기분이 드는데, 초기 스타트업 창업가는 오죽하랴. 하지만, 내일 하루 더 싸우기 위해서 오늘 죽지 말고 버티자. 버티면 죽지 않을 것이고, 그럴 때마다 용기가 복리로 쌓일 것이다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2026/02/when-courage-compounds.html#comments",
        "content": "지난 2년은 대부분의 창업가에겐 20년 같이 느껴졌을 정도로 길고, 힘들었을 것이다. 우리 투자사 중에서도 남들보다 월등하게 잘하는 곳도 있지만, 이런 회사들은 아웃라이어이고, 대부분 정말 배고프고, 춥고, 스트레스 가득 차고, 하루가 이틀이었으면 하는 바람으로 창업가라는 왕관의 무게를 버텼다. 이 중 이젠 사라진 스타트업도 꽤 있고, 잘 살아남아서 이제 다시 성장의 준비를 하는 곳들도 있지만, 대부분 아직(...)",
        "contentSnippet": "지난 2년은 대부분의 창업가에겐 20년 같이 느껴졌을 정도로 길고, 힘들었을 것이다. 우리 투자사 중에서도 남들보다 월등하게 잘하는 곳도 있지만, 이런 회사들은 아웃라이어이고, 대부분 정말 배고프고, 춥고, 스트레스 가득 차고, 하루가 이틀이었으면 하는 바람으로 창업가라는 왕관의 무게를 버텼다. 이 중 이젠 사라진 스타트업도 꽤 있고, 잘 살아남아서 이제 다시 성장의 준비를 하는 곳들도 있지만, 대부분 아직(...)",
        "guid": "https://www.thestartupbible.com/?p=9693",
        "categories": [
          "Uncategorized",
          "compounding",
          "failure",
          "FoundersAtWork",
          "hustle",
          "inspiring",
          "Strong"
        ],
        "isoDate": "2026-02-22T21:24:00.000Z"
      }
    ]
  },
  {
    "name": "매거진 입맛",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "요즘 IT",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "쿠팡 엔지니어링",
    "category": "기업",
    "posts": []
  },
  {
    "name": "지마켓 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "리멤버 (드라마 앤 컴퍼니)",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Kimchi hill",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Hudi.blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "토스",
    "category": "기업",
    "posts": [
      {
        "title": "토스페이 신규 가맹점 결제 혜택: 2026년 3월",
        "link": "https://toss.im/tossfeed/article/tosspay-promotion-new",
        "pubDate": "Sat, 28 Feb 2026 15:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-1c1qox8{font-size:30px;letter-spacing:0em;line-height:1.55;font-weight:bold;color:var(--adaptiveGrey900);margin:40px 0 4px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-p4abj2{display:contents;line-height:1.55;}.css-1kxrhf3{white-space:pre-wrap;}이번 달 토스페이의 새로운 혜택은 무엇인가요?\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1iisb9p{display:contents;line-height:1.6;}2026년 3월 토스페이의 새로운 가맹점 혜택으로는 마뗑킴, 에즈이프캘리, 인바디, 유닉스, 말하다, 몽키트래블 등의 할인 혜택이 있어요. 쇼핑하기 전 확인하고 더 알뜰하게 결제하세요.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n2026년 3월 토스페이 신규 가맹점 자동 할인 혜택\n온라인몰에서 결제할 때 토스페이만 선택하면 자동으로 할인이 적용되는 신규 가맹점 혜택이에요.\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n👕 패션\n.css-nv7vyi{margin:24px 0 8px;padding:16px 40px 32px;border-radius:16px;background-color:var(--adaptiveGrey100);}.css-123co55{font-size:19px;letter-spacing:0em;line-height:1.6;margin:24px 0 0;font-weight:400;color:var(--adaptiveGrey900);background-color:transparent;}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}마뗑킴 결제 혜택\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n혜택: 4천 원 할인\n기간: 26.03.01 ~ 26.03.31\n조건: 토스페이로 마뗑킴에서 5만 원 이상 결제\n\n.css-1k0zzdk{white-space:pre-wrap;cursor:pointer;color:#4593fc;-webkit-text-decoration:underline!important;text-decoration:underline!important;font-weight:bold;}🔗 토스페이로 마뗑킴 할인 받기\n\n에즈이프캘리 결제 혜택\n\n혜택: 최대 4천 원 할인\n기간: 26.03.01 ~ 26.03.31\n조건: 토스페이로 에즈이프캘리에서 5만 원 이상 결제\n\n🔗 토스페이로 에즈이프캘리 할인 받기\n\n아레나 결제 혜택\n\n혜택: 최대 4천 원 할인\n기간: 26.03.01 ~ 26.03.31\n조건: 토스페이로 아레나에서 5만 원 이상 결제\n\n🔗 토스페이로 아레나 할인 받기\n\n메이블루 결제 혜택\n\n혜택: 최대 4천 원 할인\n기간: 26.03.01 ~ 26.03.31\n조건: 토스페이로 메이블루에서 5만 원 이상 결제\n\n🔗 토스페이로 메이블루 할인 받기\n\n📺 리빙 • 가전\n\n듀오백 결제 혜택\n\n혜택: 최대 7천 원 할인\n기간: 26.03.01 ~ 26.03.31\n조건: 토스페이로 듀오백에서 5만 원 이상 결제\n\n🔗 토스페이로 듀오백 할인 받기\n\n인바디 결제 혜택\n\n혜택: 최대 7천 원 할인\n기간: 26.03.01 ~ 26.03.31\n조건: 토스페이로 인바디에서 20만 원 이상 결제\n\n🔗 토스페이로 인바디 할인 받기\n\n유닉스 결제 혜택\n\n혜택: 최대 4천 원 할인\n기간: 26.03.01 ~ 26.03.31\n조건: 토스페이로 유닉스에서 5만 원 이상 결제\n\n🔗 토스페이로 유닉스 할인 받기\n\n퓨처테리어 결제 혜택\n\n혜택: 최대 4천 원 할인\n기간: 26.03.01 ~ 26.03.31\n조건: 토스페이로 퓨처테리어에서 20만 원 이상 결제\n\n🔗 토스페이로 퓨처테리어 할인 받기\n\n🏫 교육 • 여행\n\n말하다 결제 혜택\n\n혜택: 1% 즉시 할인 (최대 1만 원)\n기간: 26.03.01 ~ 26.03.31\n조건: 토스페이로 말하다에서 1원 이상 결제\n\n🔗 토스페이로 말하다 할인 받기\n\n몽키트래블 결제 혜택\n\n혜택: 최대 7천 원 할인\n기간: 26.03.01 ~ 26.03.31\n조건: 토스페이로 몽키트래블에서 20만 원 이상 결제\n\n🔗 토스페이로 몽키트래블 할인 받기\n\n\n결제 수단을 토스페이로 바꾸는 작은 습관만으로도 현금처럼 쓸 수 있는 혜택이 쌓여요. 다른 사람들은 이미 챙기고 있는 혜택이랍니다.\n복잡한 절차 없이 결제할 때 토스페이를 선택하고 똑똑한 소비를 시작해 보세요.\n\n토스페이는 어떻게 사용할 수 있나요?\n온라인에서 토스페이로 결제하기\n.css-hokoge{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;counter-reset:numberedList;}.css-hokoge ul,.css-hokoge ol{margin:16px 0 0;}.css-hokoge>li{counter-increment:numberedList;margin-bottom:16px;padding-left:24px;}.css-hokoge>li:last-of-type{margin-bottom:0;}.css-hokoge>li>span{position:relative;}.css-hokoge>li>span>:first-child::before{content:counter(numberedList) '.';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n쇼핑몰 결제창에서 결제 수단으로 토스페이를 선택해 주세요.\n토스 앱이 열리면 등록된 카드나 계좌 중 하나를 선택하고 간편하게 결제해요.\n\n\n지금 바로 토스페이로 결제하고 2026년 3월 신규 가맹점 결제 혜택을 받아보세요.",
        "content": "신규 가맹점 마뗑킴, 에즈이프캘리, 인바디, 유닉스, 말하다, 몽키트래블 등의 할인 혜택 확인하세요",
        "contentSnippet": "신규 가맹점 마뗑킴, 에즈이프캘리, 인바디, 유닉스, 말하다, 몽키트래블 등의 할인 혜택 확인하세요",
        "guid": "https://toss.im/tossfeed/article/tosspay-promotion-new",
        "isoDate": "2026-02-28T15:00:00.000Z"
      },
      {
        "title": "최대 25만 원, 소상공인 경영안정 바우처로 고정비 부담 덜어요",
        "link": "https://toss.im/tossfeed/article/money-policies-56_",
        "pubDate": "Fri, 27 Feb 2026 01:28:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}중소벤처기업부가 2월 9일부터 '소상공인 경영안정 바우처' 신청을 받고 있어요. 매달 반복되는 공과금과 보험료 부담이 큰 소상공인이라면 반가울 소식이에요.\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}소상공인 경영안정 바우처란?\n.css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}전기·가스·수도요금 같은 필수 고정비에 사용할 수 있는 디지털 바우처예요. 단순한 현금 지원에 그치지 않고, 실제 사업 운영에 꼭 필요한 곳에 요긴하게 쓰이도록 설계되어 더욱 직접적인 도움이 돼요.\n혜택 범위\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n공과금, 4대 보험료, 차량 연료비, 전통시장 화재공제료에 소요되는 비용 지원\n소상공인 1인당 바우처 최대 25만 원\n\n지원 대상\n다음 조건을 모두 충족해야 해요.\n\n2025년 연 매출액 0원 초과, 1억 400만 원 미만 소상공인\n2025년 12월 31일 이전에 개업한 사업체\n신청 시점에 실제 영업 중인 사업체\n\n※ 단, 유흥업, 도박·사행성 업종, 가상자산 매매업 등 정책 자금 제외 업종은 지원 대상에서 제외돼요.\n신청 방법\n\n.css-iynyr0{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);-webkit-text-decoration:underline!important;text-decoration:underline!important;}소상공인 경영안정 바우처 전용 홈페이지나 소상공인24 홈페이지에서 별도 서류 제출 없이 신청할 수 있어요.\n카드사를 고르면 그 카드로 바우처가 지급되고, 지정 사용처에서 카드로 결제하면 지원금이 자동으로 차감되는 방식이라 편리해요.\n\n이번 바우처는 소상공인들에게 큰 부담이 되는 고정비를 줄여준다는 점에서 직접적인 도움이 될 거예요. 가게 운영에 실질적인 보탬이 필요한 소상공인이라면 이 기회를 놓치지 마세요!\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 김예진 이지영 Graphic 조수희",
        "content": "공과금과 보험료가 부담되는 소상공인이라면 확인해 보세요",
        "contentSnippet": "공과금과 보험료가 부담되는 소상공인이라면 확인해 보세요",
        "guid": "https://toss.im/tossfeed/article/money-policies-56_",
        "isoDate": "2026-02-27T01:28:00.000Z"
      },
      {
        "title": "What does it take to grow beyond a unicorn?",
        "link": "https://toss.im/tossfeed/article/tossinnumbers",
        "pubDate": "Thu, 26 Feb 2026 08:59:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}1\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\nA SINGLE SUPER APP\n.css-1kxrhf3{white-space:pre-wrap;}All of Toss’ services come together in a single app. Transfers, asset management, loans, investments, insurance, and tax filing—financial services that were once scattered are now seamlessly connected in one place. This allows users to solve everyday inconveniences without the hassle of installing or signing up for multiple apps.\n30M+\nKOREA’S #1 FINANCIAL PLATFORM\nIn 2025, Toss surpassed 30 million total users, becoming a platform used by 6 out of 10 Koreans.\n3.2M+\nTHE VERY FIRST STEP IN FINANCE\nIn 2022, Toss launched Toss Teens, the first service in the industry designed for children and teenagers aged 7 to 18. Its flagship offering, the USS Card*, is a prepaid top-up card issued in the child’s own name. By using and managing their own card, young users begin building independent financial habits from an early age. Since its launch, more than 3.2 million USS Cards have been issued, creating a foundation for the next generation to actively learn and experience finance as true participants.\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}* From age 7 to 13, the consent of a legal guardian is required.\n** Based on May 2025\n\nA PLATFORM FOR EVERYONE\nThe age distribution of Toss users highlights its broad appeal. Today, Toss has become a platform embraced across all generations.\n90%+\nMAKING EVERY VISIT STICK\nNine out of ten people who use Toss once return the following month. In data terms, this is known as the retention rate, and Toss maintains a monthly retention of 90%. This shows that users aren’t just signing up once, they continue to use Toss as part of their daily lives.\n* Based on Sep 2025, Wiseapp.\n11 times\nPART OF EVERY DAY\nUsers open Toss for an average of 11 times every day. From transfers, investments to shopping, Toss is there at every step in the user’s daily life.\n* Based on Sep 2025, Wiseapp.\n100+\nBEYOND FINANCE, INTO EVERYDAY LIFE\nToday, Toss operates over 100 services within a single app—from online and offline payments to shopping and everyday lifestyle services—establishing itself as an essential app for convenient daily life.\n24,000 years\nTIME-SAVING INNOVATION\nBefore Toss introduced simple transfers, sending money with an accredited certificate took an average of three minutes. With Toss, it takes only 30 seconds. That means each transfer saves about 150 seconds. Across roughly 5 billion transfers made through Toss so far, that time adds up to the equivalent of 24,000 years saved.\n* Based on Sep 2025\n\nCONTINUOUS GROWTH\nToss’s operating revenue grew from ₩20,500,000,000 in 2017 to ₩1,955,600,000,000 in 2024. That same year, Toss achieved annual profitability for the first time, demonstrating both its ability to generate profit and sustain growth.\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nWriter Donghae Yoon",
        "guid": "https://toss.im/tossfeed/article/tossinnumbers",
        "isoDate": "2026-02-26T08:59:00.000Z"
      },
      {
        "title": "토스, ‘2026년 인디게임 데브캠프’ 협력기업 참여",
        "link": "https://toss.im/tossfeed/article/45501",
        "pubDate": "Mon, 23 Feb 2026 11:10:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}콘진원과 함께 인디게임 사업화글로벌 진출 지원\n‘앱인토스’ 기반 HTML5 게임 성장 생태계 강화\nIT 업계 상생 모델 주도…“창작자와 함께 성장하는 건강한 디지털 생태계 만들 것”\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n– 토스(운영사 비바리퍼블리카, 대표 이승건)가 유망 인디게임 프로젝트 발굴 및 지원을 위한 단계별 경쟁 선발 프로그램 ‘2026년 인디게임 데브캠프’에 협력기업으로 참여한다고 밝혔다. 초기 창업 기업과 예비창업자의 사업화 난관을 해소하고, 국내 인디게임의 경쟁력 강화를 지원하기 위해서다.\n‘2026년 인디게임 데브캠프’는 문화체육관광부(장관 최휘영)와 한국콘텐츠진흥원(원장직무대행 유현석, 이하 콘진원)이 인디게임 산업의 경쟁력 강화와 대한민국 게임산업의 성장 체력 확보를 목표로 추진하는 사업이다. 창의적 아이디어를 보유한 초기 창업 기업과 예비창업자를 발굴해 단계별 경쟁 선발을 거쳐 개발, 사업화, 투자 연계까지 체계적으로 지원한다.\n게임업계에서는 참신한 기획력과 기술력을 갖추고도 자금 부족, 마케팅 역량 미비, 글로벌 네트워크 한계 등으로 인해 실제 출시와 안정적인 서비스 운영 단계까지 이어지지 못하는 사례가 꾸준히 발생하고 있다. 이에 토스는 인디게임 기업이 직면한 구조적 제약을 보완하고, 실질적인 시장 안착을 지원하는 데 주력할 계획이다.\n특히 토스는 HTML5 기반 게임사의 기술적·경영적 한계 극복과 사업화 역량 강화를 핵심 과제로 삼는다. 지원사업 참여 기업을 대상으로 이용자 확보를 위한 마케팅을 체계적으로 지원하고, HTML5 기업 간 네트워킹을 통해 산업 내 협업 기반을 확대할 방침이다. 또한 사업성이 우수한 게임에 대해서는 투자 가능성도 적극 검토한다. 이를 통해 인디게임의 실질적인 사업화 성과 창출과 이용자 저변 확대를 견인한다는 전략이다.\n앞서 토스는 지난해 12월 열린 ‘코리아 인디게임 쇼케이스 2025’에서 국내 HTML5 게임 저변 확대를 지원하기 위해 콘진원과 MOU를 체결한 바 있다. 이번 참여는 당시 협약의 연장선에서 인디게임 생태계 지원을 한층 구체화한 행보다.\n토스는 IT 업계의 상생과 동반성장을 주도하며 실질적인 성과를 이어가고 있다. 토스의 미니앱 플랫폼 ‘앱인토스’는 지난 7월 정식 출시 이후 약 7개월 만에 제휴 미니앱 수 1,000개를 돌파했다. 토스 앱 내에서 첫 미니앱을 선보인 후 약 10개월 만에 거둔 성과다.\n특히 ‘게임’ 분야는 전체 미니앱의 약 50%를 차지하며 ‘앱인토스’ 초기 성장을 이끈 핵심 카테고리로 자리 잡았다. 별도의 앱 설치 없이 즉시 실행 가능한 구조 덕분에 이용자 편의성이 높고, 이는 게임 개발자의 수요와 맞물려 성공 사례로 이어지고 있다. 실제로 게임 ‘돌돌디’를 개발한 ‘마나바바’는 ‘앱인토스’ 제휴 이후 월 매출 2억 1,000만 원을 돌파하며 경영 위기를 극복하고 재도약의 발판을 마련했다.\n파트너사의 서비스 지속성 측면에서도 성과가 나타났다. 지난 10개월간 ‘앱인토스’와 제휴한 파트너사 중 95%가 현재까지 서비스를 운영 중인 것으로 집계됐다. 이는 초기 사용자 확보와 마케팅 부담 완화가 창업 초기 기업의 생존율 제고에 긍정적으로 작용한 결과로 분석된다. ‘앱인토스’에서는 게임 출시 이후 필요한 마케팅 솔루션을 무상으로 지원해 개발사가 콘텐츠 완성도 제고에 집중할 수 있도록 돕고 있다.\n토스 관계자는 “토스는 혁신적인 아이디어를 가진 인디게임 개발사가 시장에 안착하고 글로벌 무대로 확장할 수 있도록 실질적인 지원을 아끼지 않을 것”이라며 “앞으로도 사용자 중심 철학을 바탕으로 창작자와 함께 성장하는 건강한 디지털 생태계를 만들어가겠다”고 밝혔다.",
        "content": "문체부와 콘진원 사업 일환",
        "contentSnippet": "문체부와 콘진원 사업 일환",
        "guid": "https://toss.im/tossfeed/article/45501",
        "isoDate": "2026-02-23T11:10:00.000Z"
      }
    ]
  },
  {
    "name": "모나미",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김진홍",
    "category": "개인",
    "posts": []
  }
]