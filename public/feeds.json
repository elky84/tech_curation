[
  {
    "name": "ㅍㅍㅅㅅ",
    "category": "큐레이팅",
    "posts": []
  },
  {
    "name": "C++ Team Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Facebook Engineering",
    "category": "기업",
    "posts": [
      {
        "creator": "",
        "title": "Meta is getting ready for post-quantum cryptography",
        "link": "https://engineering.fb.com/2024/08/28/security/post-quantum-cryptography-meta/",
        "pubDate": "Wed, 28 Aug 2024 16:19:35 +0000",
        "content:encodedSnippet": "The Quantum Apocalypse is coming. The advent of quantum computers has raised real questions about the future of data privacy over the internet.  Someday, advances in quantum computing will make it possible to decrypt sensitive data that was encrypted using today’s complex cryptography systems.\nIn the latest episode of the Meta Tech Podcast you’ll meet Sheran and Rafael, two engineers leading Meta’s post-quantum readiness work. They sit down with Pascal Hartig (@passy) to discuss the threat of quantum computing and how Meta is working to keep today’s users safe from the quantum attacks of tomorrow.\nAnd for more on post-quantum readiness at Meta be sure to read their blog, Post-quantum readiness for TLS at Meta.\nDownload or listen to the podcast episode below:\n\nSpotify\nApple Podcasts\nPocketCasts\nOvercast\nThe Meta Tech Podcast is a podcast, brought to you by Meta, where we highlight the work Meta’s engineers are doing at every level – from low-level frameworks to end-user features.\nSend us feedback on Instagram, Threads, or X.\nAnd if you’re interested in learning more about career opportunities at Meta visit the Meta Careers page.\nThe post Meta is getting ready for post-quantum cryptography appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>The Quantum Apocalypse is coming. The advent of quantum computers has raised real questions about the future of data privacy over the internet.  Someday, advances in quantum computing will make it possible to decrypt sensitive data that was encrypted using today&#8217;s complex cryptography systems. In the latest episode of the Meta Tech Podcast you’ll meet Sheran [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2024/08/28/security/post-quantum-cryptography-meta/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2024/08/28/security/post-quantum-cryptography-meta/\">Meta is getting ready for post-quantum cryptography</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "The Quantum Apocalypse is coming. The advent of quantum computers has raised real questions about the future of data privacy over the internet.  Someday, advances in quantum computing will make it possible to decrypt sensitive data that was encrypted using today’s complex cryptography systems. In the latest episode of the Meta Tech Podcast you’ll meet Sheran [...]\nRead More...\nThe post Meta is getting ready for post-quantum cryptography appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=21662",
        "categories": [
          "Culture",
          "Security",
          "Meta Tech Podcast"
        ],
        "isoDate": "2024-08-28T16:19:35.000Z"
      },
      {
        "creator": "",
        "title": "How Meta enforces purpose limitation via Privacy Aware Infrastructure at scale",
        "link": "https://engineering.fb.com/2024/08/27/security/privacy-aware-infrastructure-purpose-limitation-meta/",
        "pubDate": "Tue, 27 Aug 2024 16:00:50 +0000",
        "content:encodedSnippet": "At Meta, we’ve been diligently working to incorporate privacy into different systems of our software stack over the past few years. Today, we’re excited to share some cutting-edge technologies that are part of our Privacy Aware Infrastructure (PAI) initiative. These innovations mark a major milestone in our ongoing commitment to honoring user privacy. \nPAI offers efficient and reliable first-class privacy constructs embedded in Meta infrastructure to address complex privacy issues. For example, we built Policy Zones that apply across our infrastructure to address restrictions on data, such as using it only for allowed purposes, providing strong guarantees for limiting the purposes of its processing.\nAs we expanded PAI across Meta, increasing its maturity, we gained valuable insights. Our understanding of the technology evolved, revealing the need for a larger investment than initially planned to create a cohesive ecosystem of libraries, tool suites, integrations, and more. These investments have been crucial in enforcing complex purpose limitation scenarios while ensuring scalability, reliability, and a streamlined developer experience.\nPurpose limitation, a core data protection principle, is about ensuring data is only processed for explicitly stated purposes. A crucial aspect of purpose limitation is managing data as it flows across systems and services. Commonly, purpose limitation can rely on “point checking” controls at the point of data processing. This approach involves using simple if statements in code (“code assets”) or access control mechanisms for datasets (“data assets”) in data systems. However, this approach can be fragile as it requires frequent and exhaustive code audits to ensure the continuous validity of these controls, especially as the codebase evolves. Additionally, access control mechanisms manage permissions for different datasets to reflect various purposes using mechanisms like access control lists (ACLs), which requires the physical separation of data into distinct assets to ensure each maintains a single purpose. When Meta started to address more and larger-scope purpose limitation requirements that crossed dozens of our systems, these point checking controls did not scale.\nAt Meta, millions of data assets are crucial for powering our product ecosystem, optimizing machine learning models for personalized experiences, and ensuring our products are high quality and meet user expectations. Identifying which code branches and data assets require protection is challenging due to complex propagation requirements and permissions models that need constant revision. For example, when a data consumer reads from one data asset (“source”) and stores the output in another (“sink”), point checking controls would require complex orchestration to ensure propagation from sources to sinks, which can become operationally unviable.\n\nTo address this problem, point checking controls can be enhanced by leveraging data flow signals. Data flows can be tracked from the same origin, where relevant data is collected, using various techniques such as static code analysis, logging, and post-query processing. This creates a graph, known as “data lineage,” that tracks the relationships between source and sink data assets. By utilizing data lineage, permissions can be applied to relevant data assets based on these source-to-sink relationships. The combination of point checking and data lineage, while viable at a small scale, leads to significant operational overhead as point checking still requires auditing many individual assets. \nBuilding on these insights, in our latest iteration, we found that the information flow control (IFC) model offers a more durable and sustainable approach by controlling not only data access but also how data is processed and transferred in real-time, rather than relying on point checking or out-of-band audits. Thus, we developed Policy Zones as our IFC-based technology and integrated it across major Meta systems to enhance our purpose limitation capabilities at scale. This effort was later expanded into the Privacy Aware Infrastructure (PAI) initiative, a transformative investment that integrates first-class privacy support into Meta’s infrastructure systems.\nWe believe PAI is the right investment to protect people’s privacy at scale and can effectively enforce purpose limitation requirements.\nWhy invest in Policy Zones?\nThrough our experience deploying purpose limitation solutions over the years, we identified several key themes:\nNeeds\nProblem\nSolution\n\n\nProgrammatic Control: We needed to rely more on programmatic controls instead of point checking human audits to control data flows, and do so in real-time\nTraditional point checking controls, combined with data lineage checks, can detect data transfers within a specific time frame but not in real-time. Addressing these risks requires implementing resource-intensive human audits at access points.\nIn contrast, PAI is designed to check data flows in real-time during code execution, blocking problematic data flows from occurring, facilitated by UX tooling, thus making it more scalable.\n\n\nGranular Flow Control: We needed to maximize the reuse of existing data and business logic on complex infra\nAccess control is easy to roll out when data is separated physically, but poses significant costs, complexity, and limitations when dealing with Meta’s complex infrastructure, where data for different purposes is often processed by shared code.\nPAI solves this by providing precise decision making at the granular level of individual requests, function calls, or data elements, achieving logical data separation at a relatively low compute cost even on complex infrastructures where it’s needed.\n\n\nAdaptable and Extensible Control: We needed to handle ever-evolving requirements, even multiple for the same data assets\nWe are facing a rapidly changing world for privacy. Data use restrictions can vary over time depending on evolving privacy and product requirements. A single data asset or different parts of it might be subject to multiple privacy requirements. While “point checking” can address this to some extent, it struggles to control downstream data flows, even combined with data lineage.\nPAI is designed to check multiple requirements involved in data flows and is highly flexible to adapt to changing requirements.\n\n\n\n \nHow Policy Zones works\nLet’s dive into what Policy Zones is and how we can leverage it to meet purpose limitation requirements. Policy Zones provides a comprehensive mechanism for encapsulating, evaluating, and propagating privacy constraints for data both “in transit” and “at rest,” including transitions between different systems. It conducts runtime evaluation of constraints, context propagation, and is deeply integrated with numerous data and code frameworks (e.g., HHVM, Presto, and Spark), representing a step change in how we approach information flow control.\nTo make the explanation more relatable and bring some levity to a serious topic, we’ll use a simple example: Let’s say a new requirement comes up, where banana data can only be used for the purposes of making smoothies and fruit baskets, but not for making banana bread. For simplicity, this example and the illustration below only demonstrate the first row of the above table. \n\nHow would developers leverage Policy Zones to implement such a requirement?\nFirst, to demarcate relevant data assets, they assign a metadata label (“data annotation,” e.g., BANANA_DATA) to data assets at different granularities. This annotation is associated with the purpose limitation requirement as a set of data flow rules that enable systems to understand the allowed purposes for the data.\n\nWhen annotated data is processed, Policy Zones kicks in and checks whether the data processing is allowed and data can flow downstream. Policy Zones has been built into different Meta systems, including:\nFunction-based systems that load, process, and propagate data through stacks of function calls in different programming languages. Examples include web frontend, middle-tier, and backend services.\nBatch-processing systems that process data rows in batch (mainly via SQL). Examples include real-time and data warehouse systems that power Meta’s AI and analytics workloads.\nLet’s dive deeper into how Policy Zones works for the function-based systems, while the same logic applies to the batch-processing systems as well.\nIn function-based systems, data is passed through parameters, variables, or return values in a stack of function calls. \nLet’s walk through an example: \nA web request, “BananaRequest,” loads annotated data from BananaDB, causing a data flow violation because the intent of the caller is unknown.\nTo remediate the data flow violation, we annotate BananaRequest with the BANANA_DATA label, creating a zone (“Banana Zone”) for the request. \nBehind the scenes at runtime, Policy Zones programmatically checks all data flows against the flow rules based on the context, flagging new data flow violations from BananaRequest to logB and logC. \nWe annotate logB as banana and remove the logging of banana data into logC to cut off the disallowed data flow. \nWith all data flow violations remediated, the zone can be moved from logging mode to enforcement. If a developer adds a write to a sink outside of the zone, it will be blocked automatically.\n\nIn a more complex scenario, a function, “makeBananaSmoothie()” from a web request, “BreakfastRequest” calls another function, “makeBanana().” Besides the previous data flow violations, we need to remediate another data flow violation: makeBanana() returns banana data to makeBananaSmoothie(). This means we can create a “Banana Zone” from the function makeBananaSmoothie() that includes all functions that it calls directly or indirectly.\n\nIn batch-processing systems, data is processed in batches for rows from tables that are annotated as containing relevant data. When a job runs a query (usually SQL-based) to process the data, a zone is created and Policy Zones flags any data flow violations. Remediation options are provided, similar to those for function-based systems. Once all violations have been remediated, the zone can be moved from logging mode to enforcement mode to prevent future data flow violations. Data annotation can be done at various levels of granularity, including table, column, row, or potentially even cell.\nWhen data flows across different systems (e.g., from frontend, to data warehouse, then to AI), Policy Zones ensures that relevant data is annotated correctly and thus continues to be protected according to the requirements. For some systems that don’t have Policy Zones integrated yet, the point checking control is still used to protect the data.\nHow we applied PAI to existing systems at scale\nThe above gives you a glimpse into how the technology is used to roll out a simple use case. However, adopting Policy Zones is a non-trivial task for complex requirements across tens or hundreds of systems. The requirement owner usually collaborates with other engineers who are code and data asset owners across Meta to implement different aspects of that requirement. In some cases, this may involve hundreds or thousands of engineers to complete the implementation and audits. To address this challenge, PAI offers Policy Zone Manager (PZM), a suite of UX tools that helps requirement owners to efficiently enforce privacy requirements using PAI.\nLet’s take a look at how PZM makes it easy for people to satisfy their purpose limitation needs in existing systems, using the above banana requirement as an example. At a high level, the requirement owner carries out the following workflow, facilitated by PZM:\nIdentify relevant assets: This is to identify which source assets need to be purpose limited for the given requirement.\nDiscover relevant data flows: This is to discover the downstream data flows from the source assets in order to integrate Policy Zones at scale.\nRemediate data flow violations: This is to allow people to choose which option to take to remediate data flow violations.\nContinuously enforce and monitor data flows: This is to turn on Policy Zones enforcement and monitor it to prevent new data flow violations. \n\nTo hear more about this process, check out our presentation at the PEPR conference in June 2024.\n\nStep 1 – Identify relevant assets\nFor a given requirement, we check the relevant product entry points (e.g., mobile apps, web requests, and databases) to pinpoint data assets that are collected. These assets may take the form of request parameters, database entries, or event log entries. We use data structures to represent (“schematize”) these data assets and fields, capturing relevant data at various granularities. In the running example, a table in the banana database might contain entirely banana data, a single banana column, or a mix of banana and other fruit data.\nIn addition to manual code inspection, we heavily rely on various techniques such as our scalable ML-based classifier to automatically identify data assets.\nStep 2 – Discover relevant data flows\nFrom a given annotated source, the requirement owner can identify its downstream data flows and sinks (see diagram below). The owner can then decide how to handle these data flows. However, this process can be time consuming when there are many data flows that are one or multiple hops away from the same origin. This often occurs when implementing a new requirement over existing data flows. \n\nAlthough data lineage presents significant operational overhead for point checking mechanisms, it can efficiently identify where to integrate Policy Zones into the codebase. Therefore, we have integrated data lineage into PZM, allowing requirement owners to discover multiple downstream assets from a given source simultaneously. Once the requirement has been fully implemented, we can rely solely on Policy Zones to enforce the requirements.\nStep 3 – Remediate data flow violations\nBy default, the data flow from a source asset to a sink must meet all of the requirements of the source. If not, it’s considered a data flow violation and needs remediation, enforced by Policy Zones programmatically at runtime. There are three main cases to remediate data flow violations (using the running example to help concretize the general cases):\nCase 1: Safe flow – relevant data is used for allowed purpose(s): Assign the banana annotation to the sink asset.\nCase 2: Unsafe flow – relevant data is used for disallowed purpose(s): Block data access and code execution to prevent further processing of banana data.\nCase 3: Reclassified flow – relevant data is not used or propagated: Annotate the data flow as reclassified as being permitted. Banana data from the source is not used or propagated to the sink.\n\nStep 4 – Continuously enforce and monitor data flows\nPAI is integrated into our major data systems to check data flows and catch violations at runtime. During the initial rollout of a new requirement, Policy Zones can be configured to allow remediations of flow violations in “logging mode.” Once Policy Zones enforcement is enabled, any data flow with unremediated violations is denied. This also prevents new data flow violations, even if code changes or new code is added.\nPAI continuously monitors the enforcement of requirements to ensure that it operates correctly. PZM provides a set of verifiers to check the accuracy of asset annotations and control configurations.\nLessons learned from adoption at scale across Meta\nAs PAI has been adopted by a multitude of purpose limitation requirements across Meta, we’ve learned several key lessons over the past few years:\nFocus on solving one specific end-to-end use case first\nInitially, we developed Policy Zones for batch-processing systems with some basic use cases. However, we realized that our designs for function-based systems were quite abstract and the adoption for a large-scale use case resulted in significant challenges, consequently, requiring considerable effort to map patterns to customer needs. Furthermore, refining the APIs and building missing operational support made it work effectively end-to-end across multiple systems. Only after addressing these challenges were we able to make it more generic and proceed with integrating Policy Zones across extensive platforms.\nStreamline integration complexity\nIntegrating PAI into major Meta systems coherently was a complex, lengthy, and challenging process. We encountered significant difficulties in integrating PAI with Meta’s diverse systems broadly. It took us years to overcome these challenges. For example, initially, product teams expended considerable effort to schematize data assets across different data systems. Then we developed reliable, computationally efficient, and widely applicable PAI libraries in various programming languages (Hack, C++, Python, etc.) that enabled a smoother integration with a broad range of Meta’s systems.\nInvest in computational and developer efficiency early on \nWe also undertook multiple iterations to simplify PAI and improve its computational efficiency. Our initial annotation APIs were overly complex, resulting in high cognitive overhead for engineers. Furthermore, the computational overhead of data flow checking was prohibitively high in Meta’s high-throughput systems. Through several rounds of refinement, we simplified policy lattice representation and evaluation, built language-level features to natively propagate Policy Zones context, and canonicalized policy annotation structures, achieving 10x improvements in computational efficiency.\nSimplified and independent annotations are a must to scale to a wide range of requirements\nInitially, we employed a monolithic annotation API to model intricate data flow rules and annotate relevant code and data. However, as data from multiple requirements were combined, propagating these annotations from sources to sinks became increasingly complex, resulting in data annotation conflicts that were difficult to resolve. To address this challenge, we implemented simplified data annotations to decouple data from requirements and separate data flow rules for different requirements. This significantly streamlined the annotation process, ultimately improving developer experiences.\nBuild tools; they are required \nWe have made significant efforts to ensure the use of PAI is easy and efficient, ultimately improving the developer experience. Initially, we focused on the correctness of the technology first before investing in tooling. Adopting Policy Zones required a lot of manual effort, and it was challenging for engineers to understand how to properly annotate their assets, which led to additional cleanup work later. To address this issue, we developed the PZM tool family, which includes built-in automated rules and classifiers. These tools guide teams through standard workflows, ensuring safe and efficient rollout of purpose limitation requirements and reducing engineering efforts by orders of magnitude.\nDurable privacy protection for everyone\nMeta is committed to protecting user privacy. The PAI initiative is a crucial step in safeguarding data and preserving privacy efficiently and reliably. It provides a robust foundation for Meta to sustainably tackle privacy challenges, meet high reliability standards, and address future privacy issues more efficiently than traditional solutions. While we’ve laid a strong groundwork, our journey is just beginning. We aim to build upon this foundation by expanding our capabilities and controls to accommodate a wider range of privacy requirements, enhancing the developer experience, and exploring new frontiers.\nWe hope our work sparks innovation and fosters collaboration across the industry in the field of privacy.\nAcknowledgements\nThe authors would like to acknowledge the contributions of many current and former Meta employees who have played a crucial role in productionizing and adopting PAI over the years. In particular, we would like to extend special thanks to (in alphabetical order) Adrian Zgorzalek, Alex Gorelik, Amritha Raghunath, Anuja Jaiswal, Brian Sniffen, Brian Romanko, Brian Spanton, David Detlefs, David Mortenson, David Taieb, Gabriela Jacques da Silva, Ian Carmichael, Iuliu Rus, Jafar Husain, Jerry Pan, Jiang Wu, Joel Krebs, Jun Fang, Komal Mangtani, Marc Celani, Mark Konetchy, Michael Levin, Perry Stoll, Peter Prelich, Pieter Viljoen, Prashant Dhamdhere, Rajesh Nishtala, Rajkishan Gunasekaran, Rishab Mangla, Sergey Doroshenko, Seth Silverman, Sriguru Chakravarthi, Tarek Sheasha, Thomas Georgiou, Uday Ramesh Savagaonkar, Vitalii Tsybulnyk, Vlad Fedorov, Wolfram Schulte, and Yi Huang. We would also like to express our gratitude to all reviewers of this post, including (in alphabetical order) Aleksandar Ilic, Benjamin Renard, Emil Vazquez, Emile Litvak, Harrison Fisk, Jason Hendrickson, Jessica Retka, Nimish Shah, Sabrina B Ross, and Sam Blatchford. We would like to especially thank Emily DiPietro for championing the idea, leading the editorial effort, and pulling all required support together to make this blog post happen.\nThe post How Meta enforces purpose limitation via Privacy Aware Infrastructure at scale appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>At Meta, we&#8217;ve been diligently working to incorporate privacy into different systems of our software stack over the past few years. Today, we&#8217;re excited to share some cutting-edge technologies that are part of our Privacy Aware Infrastructure (PAI) initiative. These innovations mark a major milestone in our ongoing commitment to honoring user privacy.  PAI offers [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2024/08/27/security/privacy-aware-infrastructure-purpose-limitation-meta/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2024/08/27/security/privacy-aware-infrastructure-purpose-limitation-meta/\">How Meta enforces purpose limitation via Privacy Aware Infrastructure at scale</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "At Meta, we’ve been diligently working to incorporate privacy into different systems of our software stack over the past few years. Today, we’re excited to share some cutting-edge technologies that are part of our Privacy Aware Infrastructure (PAI) initiative. These innovations mark a major milestone in our ongoing commitment to honoring user privacy.  PAI offers [...]\nRead More...\nThe post How Meta enforces purpose limitation via Privacy Aware Infrastructure at scale appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=21618",
        "categories": [
          "Security"
        ],
        "isoDate": "2024-08-27T16:00:50.000Z"
      },
      {
        "creator": "",
        "title": "RETINAS: Real-Time Infrastructure Accounting for Sustainability",
        "link": "https://engineering.fb.com/2024/08/26/data-infrastructure/retinas-real-time-infrastructure-accounting-for-sustainability/",
        "pubDate": "Mon, 26 Aug 2024 16:00:40 +0000",
        "content:encodedSnippet": "We are introducing a new metric— real-time server fleet utilization effectiveness —as part of the RETINAS initiative to help reduce emissions and achieve net zero emissions across our value chain in 2030.\nThis new metric allows us to measure server resource usage (e.g., compute, storage) and efficiency in our large-scale data center server fleet in near real-time.\nWe are sharing our learnings in adopting depreciation methods for accumulated carbon assets for internal fleet measurements, and encourage further industry improvement and development on these concepts. This is not intended to replace global emissions accounting standards for purposes of external reporting.\nSince 2020, Meta has maintained net zero emissions in our operations and matched 100% of our electricity use with renewable energy. However, we know our work doesn’t stop there, and we recognize our responsibility to decarbonize our footprint beyond our data centers and offices, including emissions from the server components our suppliers manufacture to our employees’ commutes. To align with the Paris Agreement, we have set a goal to reach net zero emissions across our value chain in 2030.\nMeta’s Net Zero Program has three foundational pillars: understanding our emissions, reducing our emissions, and removing remaining emissions. To understand our emissions, improving the granularity, accuracy, and near real-time measurement of our greenhouse gas data goes beyond carbon accounting. The right data will help us apply actionable metrics to advance decarbonization across our business operations and with our suppliers.\nWith this in mind, we have created the Real Time Infrastructure Accounting for Sustainability (RETINAS) initiative, which seeks to study and understand the impact of server reliability, performance, and operational optimization on Meta’s Scope 3 emissions.\nThis initiative has led to the development of a new internal metric— real-time server fleet utilization effectiveness —that enables us to take action to reduce the emissions associated with the embodied carbon of our data center servers and components.  Embodied carbon contributes to Meta’s upstream Scope 3 emissions, and includes the emissions associated with the full lifecycle of the manufacturing, assembly, and transportation of servers and materials in our physical infrastructure.\nOptimizing the utilization of our server fleet is important to reducing these emissions. Real-time server fleet utilization effectiveness provides a framework toward effective measurement and integration of embodied carbon into ubiquitous infrastructure metrics to drive informed decisions to manage our server fleet resource usage (e.g., compute and storage) and their impacts on Meta’s Scope 3 emissions. \nHow we measure greenhouse gas emissions at Meta\nSince 2011, Meta has reported our Scope 1 and 2 emissions. In 2017, we began reporting select Scope 3 emissions categories. Since 2019 we have reported annually on all relevant emissions defined by the Greenhouse Gas Protocol. We obtain limited assurance conducted by a third party for select environmental metrics. In our accounting, data center servers and their components are a significant driver of our Scope 3 emissions footprint, and we have taken numerous steps to deepen our understanding of those emissions in order to surface reduction opportunities. \nAn important reduction strategy we are focused on is the circularity of our servers and components. The more effectively and efficiently servers are utilized, the more sustainable the server fleet. We can extend the lifespans of servers, components, and network infrastructure with improvements to server reliability, efforts to reuse components based on their reliability expectations, and various performance optimizations and operational improvements (e.g., firmware/server upgrades and repairs).\nWhile implementing these circularity strategies, we observed limitations in current carbon accounting practices to understand and weigh Scope 3 emissions trade-offs in our server fleet against traditional power, performance, and total cost of ownership (TCO) metrics, such as performance per dollar, performance per watt, and performance per dollar per watt, in real-time. \nCurrent carbon accounting and reporting practices for Scope 3 emissions are static. For data center servers and components, in particular, this means that the entirety of the embodied emissions from the upstream supply chain, manufacturing, and logistics is attributed in the year of purchase. Benefits from circularity are not realized in our Scope 3 footprint until future purchases of new servers or components are deferred. This does not provide actionable information to our operational teams in real-time on how varying the usage or the expected life of the acquired servers can impact Meta’s Scope 3 emissions. \nWe see a need to develop internal metrics to monitor and incentivize greater efficiency, utilization, and extension of the expected life of servers, which will influence current and future server fleet management. \nIntroducing real-time server fleet utilization effectiveness\nThe RETINAS initiative, launched by Meta’s Infrastructure Engineering team, seeks to study and understand how server reliability, performance, and operational optimization impact Meta’s Scope 3 emissions. To understand this holistically, we introduced a standardized, fleet-wide metric for any given resource (e.g., a server or rack) that measures the utilization of embodied carbon:\n\n \nWhere: \n\n \n\n \nThis metric borrows depreciation concepts from finance and accounting practices and applies them to aspects of server reliability, efficiency, and useful life. The concept of depreciation is used to showcase the expected useful life of acquired assets. This concept also allows for tracking of acquisition and disposition of server resources at fleet scale and is reported on an ongoing basis. \nUtilization metrics like power usage effectiveness (PUE) and hardware usage effectiveness (HUE) measure the effective IT usage from a power perspective at the data center and server level, respectively.  Combining depreciated Scope 3 emissions with these utilization metrics allows us to standardize these measurements along with other fleet health measurements for a defined period of time. \nWe illustrate the usage of this metric with a set of servers and various circularity strategies. \nExample (current static state) \nLet’s consider an example set of servers purchased in 2023 which have associated embodied emissions attributed to the buyer with 1000 tons of CO2e. Here is how this would be represented using current, static carbon accounting methods: \n\nThere is no representation for the useful life of the example set of servers. If we change the server set’s useful life (UL) from four years to five years, the metric doesn’t move. \nExample (with proposed dynamic accounting)\nFor the same example of servers purchased in 2023 with 1000 units of CO2e Scope 3 emissions, we use the concept of depreciation over a period of useful life of four years (example time horizon):\nDepreciation in action:\n\nIf the server set’s useful life is modified from four years to five years, this would be visible as part of the depreciation metric and showcase the longevity of resource usage. \nEffective change in depreciation with extension (from 4y UL to 5y UL): \n\nWithin large-scale infrastructure, there are different layers of availability within the hardware and software stack, such as hardware, firmware, the kernel, the operating system, and the application.  At each layer, there are metrics associated with efficiency based on available capacity, resources, and their effective use. To represent the use of a depreciation-based metric, we examine the efficiency of a service at the application stack. The representative graph below showcases an example set of variations in the utilization effectiveness stemming from application improvements over a larger time scale.\n\nUtilization effectiveness is defined as:  Total resource available / Resource utilized \n\nCombining the depreciation of embodied emissions resources per unit time to the utilization effectiveness for a given unit of time (say, every year), we can arrive at a more real-time measurement of server fleet utilization effectiveness of embodied carbon. (Note: The measurements for utilization effectiveness in the chart are representative values).\nOur goal is to consistently minimize the real-time server fleet utilization effectiveness. Utilization effectiveness ideally is decreasing asymptotically towards 1, when resources available are 100% utilized.  Depreciation of Scope 3 emissions over a longer period of time due to a longer useful life will also minimize this metric. Combined, this metric allows for ranking of different efforts one must pursue within the server fleet and compare and contrast efficiency improvements, reliability efforts like extensions or initial component selection, and associated embodied carbon impacts. \nBelow is the comparison of real-time server fleet utilization effectiveness and the way the metric behaves under server life extension and efficiency improvements with the above considered scenarios.\n\nCharacteristics of the metric:\nThe metric above can enable relative comparison of circularity strategies on the server fleet. It can be sliced horizontally into any given timescale (from seconds to years) for understanding a resource’s (e.g., servers or racks) embodied emissions attribution giving fine-grained real-time insights for the server fleet. The metric can also be vertically sliced to obtain utilization effectiveness at different layers of the stack, from entire servers, to containers, to production workloads, to app residencies for short durations – combining that with the associated resource available for the chosen abstraction. \nTo illustrate how this metric can be used, using the same set example as above: \nIncreasing server useful life from five years to seven years lowers the ​metric by 28% due to slower depreciation. \nEnabling reuse of a component, pursuing an application efficiency improvement, or choosing server parts that have lower emissions will contribute towards the metric and enable cross-stack tradeoff.\nTo close, we can observe in this example that this single metric ties together different fleet operations towards a single goal of reducing embodied emissions, delivering  insights for decision making at any given time horizon. By integrating depreciation and utilization effectiveness to embodied carbon, our operational and server fleet management teams can leverage this metric to make data-driven decisions that address an important portion of Meta’s Scope 3 footprint.  \nThe post RETINAS: Real-Time Infrastructure Accounting for Sustainability appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>We are introducing a new metric— real-time server fleet utilization effectiveness —as part of the RETINAS initiative to help reduce emissions and achieve net zero emissions across our value chain in 2030. This new metric allows us to measure server resource usage (e.g., compute, storage) and efficiency in our large-scale data center server fleet in [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2024/08/26/data-infrastructure/retinas-real-time-infrastructure-accounting-for-sustainability/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2024/08/26/data-infrastructure/retinas-real-time-infrastructure-accounting-for-sustainability/\">RETINAS: Real-Time Infrastructure Accounting for Sustainability</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "We are introducing a new metric— real-time server fleet utilization effectiveness —as part of the RETINAS initiative to help reduce emissions and achieve net zero emissions across our value chain in 2030. This new metric allows us to measure server resource usage (e.g., compute, storage) and efficiency in our large-scale data center server fleet in [...]\nRead More...\nThe post RETINAS: Real-Time Infrastructure Accounting for Sustainability appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=21592",
        "categories": [
          "Data Center Engineering",
          "Data Infrastructure"
        ],
        "isoDate": "2024-08-26T16:00:40.000Z"
      }
    ]
  },
  {
    "name": "eBay Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Twitter Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Netflix TechBlog",
    "category": "기업",
    "posts": [
      {
        "creator": "Netflix Technology Blog",
        "title": "Recommending for Long-Term Member Satisfaction at Netflix",
        "link": "https://netflixtechblog.com/recommending-for-long-term-member-satisfaction-at-netflix-ac15cada49ef?source=rss----2615bd06b42e---4",
        "pubDate": "Thu, 29 Aug 2024 01:01:40 GMT",
        "content:encodedSnippet": "By Jiangwei Pan, Gary Tang, Henry Wang, and Justin Basilico\nIntroduction\nOur mission at Netflix is to entertain the world. Our personalization algorithms play a crucial role in delivering on this mission for all members by recommending the right shows, movies, and games at the right time. This goal extends beyond immediate engagement; we aim to create an experience that brings lasting enjoyment to our members. Traditional recommender systems often optimize for short-term metrics like clicks or engagement, which may not fully capture long-term satisfaction. We strive to recommend content that not only engages members in the moment but also enhances their long-term satisfaction, which increases the value they get from Netflix, and thus they’ll be more likely to continue to be a member.\nRecommendations as Contextual Bandit\nOne simple way we can view recommendations is as a contextual bandit problem. When a member visits, that becomes a context for our system and it selects an action of what recommendations to show, and then the member provides various types of feedback. These feedback signals can be immediate (skips, plays, thumbs up/down, or adding items to their playlist) or delayed (completing a show or renewing their subscription). We can define reward functions to reflect the quality of the recommendations from these feedback signals and then train a contextual bandit policy on historical data to maximize the expected reward.\n\nImproving Recommendations: Models and Objectives\nThere are many ways that a recommendation model can be improved. They may come from more informative input features, more data, different architectures, more parameters, and so forth. In this post, we focus on a less-discussed aspect about improving the recommender objective by defining a reward function that tries to better reflect long-term member satisfaction.\nRetention as Reward?\nMember retention might seem like an obvious reward for optimizing long-term satisfaction because members should stay if they’re satisfied, however it has several drawbacks:\n\nNoisy: Retention can be influenced by numerous external factors, such as seasonal trends, marketing campaigns, or personal circumstances unrelated to the service.\nLow Sensitivity: Retention is only sensitive for members on the verge of canceling their subscription, not capturing the full spectrum of member satisfaction.\nHard to Attribute: Members might cancel only after a series of bad recommendations.\nSlow to Measure: We only get one signal per account per month.\n\nDue to these challenges, optimizing for retention alone is impractical.\nProxy Rewards\nInstead, we can train our bandit policy to optimize a proxy reward function that is highly aligned with long-term member satisfaction while being sensitive to individual recommendations. The proxy reward r(user, item) is a function of user interaction with the recommended item. For example, if we recommend “One Piece” and a member plays then subsequently completes and gives it a thumbs-up, a simple proxy reward might be defined as r(user, item) = f(play, complete, thumb).\n\nClick-through rate (CTR)\nClick-through rate (CTR), or in our case play-through rate, can be viewed as a simple proxy reward where r(user, item) = 1 if the user clicks a recommendation and 0 otherwise. CTR is a common feedback signal that generally reflects user preference expectations. It is a simple yet strong baseline for many recommendation applications. In some cases, such as ads personalization where the click is the target action, CTR may even be a reasonable reward for production models. However, in most cases, over-optimizing CTR can lead to promoting clickbaity items, which may harm long-term satisfaction.\nBeyond CTR\nTo align the proxy reward function more closely with long-term satisfaction, we need to look beyond simple interactions, consider all types of user actions, and understand their true implications on user satisfaction.\nWe give a few examples in the Netflix context:\n\nFast season completion ✅: Completing a season of a recommended TV show in one day is a strong sign of enjoyment and long-term satisfaction.\nThumbs-down after completion ❌: Completing a TV show in several weeks followed by a thumbs-down indicates low satisfaction despite significant time spent.\nPlaying a movie for just 10 minutes ❓: In this case, the user’s satisfaction is ambiguous. The brief engagement might indicate that the user decided to abandon the movie, or it could simply mean the user was interrupted and plans to finish the movie later, perhaps the next day.\nDiscovering new genres ✅ ✅: Watching more Korean or game shows after “Squid Game” suggests the user is discovering something new. This discovery was likely even more valuable since it led to a variety of engagements in a new area for a member.\n\nReward Engineering\nReward engineering is the iterative process of refining the proxy reward function to align with long-term member satisfaction. It is similar to feature engineering, except that it can be derived from data that isn’t available at serving time. Reward engineering involves four stages: hypothesis formation, defining a new proxy reward, training a new bandit policy, and A/B testing. Below is a simple example.\n\nChallenge: Delayed Feedback\nUser feedback used in the proxy reward function is often delayed or missing. For example, a member may decide to play a recommended show for just a few minutes on the first day and take several weeks to fully complete the show. This completion feedback is therefore delayed. Additionally, some user feedback may never occur; while we may wish otherwise, not all members provide a thumbs-up or thumbs-down after completing a show, leaving us uncertain about their level of enjoyment.\n\nWe could try and wait to give a longer window to observe feedback, but how long should we wait for delayed feedback before computing the proxy rewards? If we wait too long (e.g., weeks), we miss the opportunity to update the bandit policy with the latest data. In a highly dynamic environment like Netflix, a stale bandit policy can degrade the user experience and be particularly bad at recommending newer items.\nSolution: predict missing feedback\nWe aim to update the bandit policy shortly after making a recommendation while also defining the proxy reward function based on all user feedback, including delayed feedback. Since delayed feedback has not been observed at the time of policy training, we can predict it. This prediction occurs for each training example with delayed feedback, using already observed feedback and other relevant information up to the training time as input features. Thus, the prediction also gets better as time progresses.\n\nThe proxy reward is then calculated for each training example using both observed and predicted feedback. These training examples are used to update the bandit policy.\nBut aren’t we still only relying on observed feedback in the proxy reward function? Yes, because delayed feedback is predicted based on observed feedback. However, it is simpler to reason about rewards using all feedback directly. For instance, the delayed thumbs-up prediction model may be a complex neural network that takes into account all observed feedback (e.g., short-term play patterns). It’s more straightforward to define the proxy reward as a simple function of the thumbs-up feedback rather than a complex function of short-term interaction patterns. It can also be used to adjust for potential biases in how feedback is provided.\nThe reward engineering diagram is updated with an optional delayed feedback prediction step.\n\nTwo types of ML models\nIt’s worth noting that this approach employs two types of ML models:\n\nDelayed Feedback Prediction Models: These models predict p(final feedback | observed feedbacks). The predictions are used to define and compute proxy rewards for bandit policy training examples. As a result, these models are used offline during the bandit policy training.\nBandit Policy Models: These models are used in the bandit policy π(item | user; r) to generate recommendations online and in real-time.\n\nChallenge: Online-Offline Metric Disparity\nImproved input features or neural network architectures often lead to better offline model metrics (e.g., AUC for classification models). However, when these improved models are subjected to A/B testing, we often observe flat or even negative online metrics, which can quantify long-term member satisfaction.\nThis online-offline metric disparity usually occurs when the proxy reward used in the recommendation policy is not fully aligned with long-term member satisfaction. In such cases, a model may achieve higher proxy rewards (offline metrics) but result in worse long-term member satisfaction (online metrics).\nNevertheless, the model improvement is genuine. One approach to resolve this is to further refine the proxy reward definition to align better with the improved model. When this tuning results in positive online metrics, the model improvement can be effectively productized. See [1] for more discussions on this challenge.\nSummary and Open Questions\nIn this post, we provided an overview of our reward engineering efforts to align Netflix recommendations with long-term member satisfaction. While retention remains our north star, it is not easy to optimize directly. Therefore, our efforts focus on defining a proxy reward that is aligned with long-term satisfaction and sensitive to individual recommendations. Finally, we discussed the unique challenge of delayed user feedback at Netflix and proposed an approach that has proven effective for us. Refer to [2] for an earlier overview of the reward innovation efforts at Netflix.\nAs we continue to improve our recommendations, several open questions remain:\n\nCan we learn a good proxy reward function automatically by correlating behavior with retention?\nHow long should we wait for delayed feedback before using its predicted value in policy training?\nHow can we leverage Reinforcement Learning to further align the policy with long-term satisfaction?\n\nReferences\n[1] Deep learning for recommender systems: A Netflix case study. AI Magazine 2021. Harald Steck, Linas Baltrunas, Ehtsham Elahi, Dawen Liang, Yves Raimond, Justin Basilico.\n[2] Reward innovation for long-term member satisfaction. RecSys 2023. Gary Tang, Jiangwei Pan, Henry Wang, Justin Basilico.\n\nRecommending for Long-Term Member Satisfaction at Netflix was originally published in Netflix TechBlog on Medium, where people are continuing the conversation by highlighting and responding to this story.",
        "dc:creator": "Netflix Technology Blog",
        "guid": "https://medium.com/p/ac15cada49ef",
        "categories": [
          "reward-engineering",
          "contextual-bandit",
          "recommendation-system",
          "machine-learning"
        ],
        "isoDate": "2024-08-29T01:01:40.000Z"
      },
      {
        "creator": "Netflix Technology Blog",
        "title": "Improve Your Next Experiment by Learning Better Proxy Metrics From Past Experiments",
        "link": "https://netflixtechblog.com/improve-your-next-experiment-by-learning-better-proxy-metrics-from-past-experiments-64c786c2a3ac?source=rss----2615bd06b42e---4",
        "pubDate": "Mon, 26 Aug 2024 15:46:24 GMT",
        "content:encodedSnippet": "By Aurélien Bibaut, Winston Chou, Simon Ejdemyr, and Nathan Kallus\n\nWe are excited to share our work on how to learn good proxy metrics from historical experiments at KDD 2024. This work addresses a fundamental question for technology companies and academic researchers alike: how do we establish that a treatment that improves short-term (statistically sensitive) outcomes also improves long-term (statistically insensitive) outcomes? Or, faced with multiple short-term outcomes, how do we optimally trade them off for long-term benefit?\nFor example, in an A/B test, you may observe that a product change improves the click-through rate. However, the test does not provide enough signal to measure a change in long-term retention, leaving you in the dark as to whether this treatment makes users more satisfied with your service. The click-through rate is a proxy metric (S, for surrogate, in our paper) while retention is a downstream business outcome or north star metric (Y). We may even have several proxy metrics, such as other types of clicks or the length of engagement after click. Taken together, these form a vector of proxy metrics.\nThe goal of our work is to understand the true relationship between the proxy metric(s) and the north star metric — so that we can assess a proxy’s ability to stand in for the north star metric, learn how to combine multiple metrics into a single best one, and better explore and compare different proxies.\nSeveral intuitive approaches to understanding this relationship have surprising pitfalls:\n\nLooking only at user-level correlations between the proxy S and north star Y. Continuing the example from above, you may find that users with a higher click-through rate also tend to have a higher retention. But this does not mean that a product change that improves the click-through rate will also improve retention (in fact, promoting clickbait may have the opposite effect). This is because, as any introductory causal inference class will tell you, there are many confounders between S and Y — many of which you can never reliably observe and control for.\nLooking naively at treatment effect correlations between S and Y. Suppose you are lucky enough to have many historical A/B tests. Further imagine the ordinary least squares (OLS) regression line through a scatter plot of Y on S in which each point represents the (S,Y)-treatment effect from a previous test. Even if you find that this line has a positive slope, you unfortunately cannot conclude that product changes that improve S will also improve Y. The reason for this is correlated measurement error — if S and Y are positively correlated in the population, then treatment arms that happen to have more users with high S will also have more users with high Y.\n\nBetween these naive approaches, we find that the second one is the easier trap to fall into. This is because the dangers of the first approach are well-known, whereas covariances between estimated treatment effects can appear misleadingly causal. In reality, these covariances can be severely biased compared to what we actually care about: covariances between true treatment effects. In the extreme — such as when the negative effects of clickbait are substantial but clickiness and retention are highly correlated at the user level — the true relationship between S and Y can be negative even if the OLS slope is positive. Only more data per experiment could diminish this bias — using more experiments as data points will only yield more precise estimates of the badly biased slope. At first glance, this would appear to imperil any hope of using existing experiments to detect the relationship.\nThis figure shows a hypothetical treatment effect covariance matrix between S and Y (white line; negative correlation), a unit-level sampling covariance matrix creating correlated measurement errors between these metrics (black line; positive correlation), and the covariance matrix of estimated treatment effects which is a weighted combination of the first two (orange line; no correlation).\nTo overcome this bias, we propose better ways to leverage historical experiments, inspired by techniques from the literature on weak instrumental variables. More specifically, we show that three estimators are consistent for the true proxy/north-star relationship under different constraints (the paper provides more details and should be helpful for practitioners interested in choosing the best estimator for their setting):\n\nA Total Covariance (TC) estimator allows us to estimate the OLS slope from a scatter plot of true treatment effects by subtracting the scaled measurement error covariance from the covariance of estimated treatment effects. Under the assumption that the correlated measurement error is the same across experiments (homogeneous covariances), the bias of this estimator is inversely proportional to the total number of units across all experiments, as opposed to the number of members per experiment.\nJackknife Instrumental Variables Estimation (JIVE) converges to the same OLS slope as the TC estimator but does not require the assumption of homogeneous covariances. JIVE eliminates correlated measurement error by removing each observation’s data from the computation of its instrumented surrogate values.\nA Limited Information Maximum Likelihood (LIML) estimator is statistically efficient as long as there are no direct effects between the treatment and Y (that is, S fully mediates all treatment effects on Y). We find that LIML is highly sensitive to this assumption and recommend TC or JIVE for most applications.\n\nOur methods yield linear structural models of treatment effects that are easy to interpret. As such, they are well-suited to the decentralized and rapidly-evolving practice of experimentation at Netflix, which runs thousands of experiments per year on many diverse parts of the business. Each area of experimentation is staffed by independent Data Science and Engineering teams. While every team ultimately cares about the same north star metrics (e.g., long-term revenue), it is highly impractical for most teams to measure these in short-term A/B tests. Therefore, each has also developed proxies that are more sensitive and directly relevant to their work (e.g., user engagement or latency). To complicate matters more, teams are constantly innovating on these secondary metrics to find the right balance of sensitivity and long-term impact.\nIn this decentralized environment, linear models of treatment effects are a highly useful tool for coordinating efforts around proxy metrics and aligning them towards the north star:\n\nManaging metric tradeoffs. Because experiments in one area can affect metrics in another area, there is a need to measure all secondary metrics in all tests, but also to understand the relative impact of these metrics on the north star. This is so we can inform decision-making when one metric trades off against another metric.\nInforming metrics innovation. To minimize wasted effort on metric development, it is also important to understand how metrics correlate with the north star “net of” existing metrics.\nEnabling teams to work independently. Lastly, teams need simple tools in order to iterate on their own metrics. Teams may come up with dozens of variations of secondary metrics, and slow, complicated tools for evaluating these variations are unlikely to be adopted. Conversely, our models are easy and fast to fit, and are actively used to develop proxy metrics at Netflix.\n\nWe are thrilled about the research and implementation of these methods at Netflix — while also continuing to strive for great and always better, per our culture. For example, we still have some way to go to develop a more flexible data architecture to streamline the application of these methods within Netflix. Interested in helping us? See our open job postings!\nFor feedback on this blog post and for supporting and making this work better, we thank Apoorva Lal, Martin Tingley, Patric Glynn, Richard McDowell, Travis Brooks, and Ayal Chen-Zion.\n\nImprove Your Next Experiment by Learning Better Proxy Metrics From Past Experiments was originally published in Netflix TechBlog on Medium, where people are continuing the conversation by highlighting and responding to this story.",
        "dc:creator": "Netflix Technology Blog",
        "guid": "https://medium.com/p/64c786c2a3ac",
        "categories": [
          "data-science",
          "experimentation",
          "machine-learning",
          "a-b-testing",
          "statistics"
        ],
        "isoDate": "2024-08-26T15:46:24.000Z"
      }
    ]
  },
  {
    "name": "JetBrains: Developer Tools for Professionals and Teams – Company Blog | JetBrains",
    "category": "기업",
    "posts": [
      {
        "creator": "Maria Sharobaeva",
        "title": "JetBrains Academy – August Digest",
        "link": "https://blog.jetbrains.com/education/2024/08/30/jetbrains-academy-july-digest-2/",
        "pubDate": "Fri, 30 Aug 2024 13:05:54 +0000",
        "content:encodedSnippet": "With the new academic year approaching, the JetBrains Academy team is excited to bring you fresh updates! Discover new programs and courses designed to advance your tech career. And for computer science tutors we have curated a playlist of videos packed with fun teaching ideas. Dive in now!\nCareer Programs\nNEW Java Backend Developer Career Program\nEnroll by September 9 for access to an interactive Java course, real-world tools, resume and LinkedIn support, and AI-driven mock interviews. Register today for 20% off!\nEnroll Now\n                                                    \nPython Developer Career Program\nJoin the program to study in a mentored group and learn Python. Over 15 weeks, you’ll build a portfolio of projects, gain confidence using real development tools, and discover which career path best suits you.\nLearn More\n                                                    \nNew Tech Courses\nFree IDE Course for Backend Development\nLearn how to build a backend application consisting of multiple microservices with Flask. \nTry Now\n                                                    \nCoding Machine Learning Algorithms\nUncover the secrets of top machine learning algorithms! Learn to implement them from scratch and build a solid foundation for mastering advanced models used by ML engineers.\nLearn More\n                                                    \nOur Students’ Achievements \nVictories at the International Math Competition\n Our students from Neapolis University Pafos and Constructor University dazzled at the International Mathematics Competition 2024 in Bulgaria! They clinched 8 first prizes, 1 second, 3 thirds, and 2 honorable mentions. Enroll in JetBrains Academy’s university programs to dive into computer science and achieve your own victories.\nLearn More\n                                                    \nTeach Computer Science Your Way\nLife Hacks and Tips for Educators\nExplore our playlist of livestreams on the JetBrains Academy YouTube channel to help you engage today’s students and prepare them for tech careers, all while making learning fun!\nWatch Now",
        "dc:creator": "Maria Sharobaeva",
        "content": "With the new academic year approaching, the JetBrains Academy team is excited to bring you fresh updates! Discover new programs and courses designed to advance your tech career. And for computer science tutors we have curated a playlist of videos packed with fun teaching ideas. Dive in now!",
        "contentSnippet": "With the new academic year approaching, the JetBrains Academy team is excited to bring you fresh updates! Discover new programs and courses designed to advance your tech career. And for computer science tutors we have curated a playlist of videos packed with fun teaching ideas. Dive in now!",
        "guid": "https://blog.jetbrains.com/?post_type=education&p=506535",
        "categories": [
          "digest",
          "jetbrains-academy",
          "newsletter"
        ],
        "isoDate": "2024-08-30T13:05:54.000Z"
      },
      {
        "creator": "Dmitrii Korovin",
        "title": "TeamCity 2024.07.2 Bug Fix Is Available",
        "link": "https://blog.jetbrains.com/teamcity/2024/08/teamcity-2024-07-2-bug-fix/",
        "pubDate": "Thu, 29 Aug 2024 17:50:47 +0000",
        "content:encodedSnippet": "The 2024.07.2 bug fix for TeamCity On-Premises just rolled out — download now and keep your servers at peak performance!\nWith every minor update, we deliver a significant number of bug fixes, resolve performance issues, and, most importantly, address security issues. Version 2024.07.2 addresses over 30 issues, including matrix build failures, incorrect information about the number of authorized agents, issues related to the newly released GitHub checks trigger, and more.\nFor the complete list of the issues fixed in this version, please refer to our release notes.\nAs with other minor updates, TeamCity 2024.07.2 shares the same data format with all 2024.07.x releases, allowing you to easily upgrade or downgrade within these versions without the need to back up or restore.\nWe recommend upgrading to apply the latest improvements and security fixes to your TeamCity server.\nBefore you start, read our upgrade notes and use one of the following options to upgrade:\nUpgrade from your recent version with our automatic update.\nDownload the new version from the JetBrains website.\nPull the TeamCity Docker image.\nThank you for submitting issues and voting on them. Your feedback is invaluable in helping us improve TeamCity. \nIf you encounter any problems or have suggestions, please report them via our forum or issue tracker.\nHappy building!",
        "dc:creator": "Dmitrii Korovin",
        "content": "The 2024.07.2 bug fix for TeamCity On-Premises just rolled out — download now and keep your servers at peak performance! With every minor update, we deliver a significant number of bug fixes, resolve performance issues, and, most importantly, address security issues. Version 2024.07.2 addresses over 30 issues, including matrix build failures, incorrect information about the [&#8230;]",
        "contentSnippet": "The 2024.07.2 bug fix for TeamCity On-Premises just rolled out — download now and keep your servers at peak performance! With every minor update, we deliver a significant number of bug fixes, resolve performance issues, and, most importantly, address security issues. Version 2024.07.2 addresses over 30 issues, including matrix build failures, incorrect information about the […]",
        "guid": "https://blog.jetbrains.com/?post_type=teamcity&p=506283",
        "categories": [
          "bug-fix",
          "news"
        ],
        "isoDate": "2024-08-29T17:50:47.000Z"
      },
      {
        "creator": "Oksana Mandryka",
        "title": "Grazie: What’s New in August",
        "link": "https://blog.jetbrains.com/grazie/2024/08/grazie-what-s-new-in-august/",
        "pubDate": "Thu, 29 Aug 2024 17:48:42 +0000",
        "content:encodedSnippet": "As August draws to a close, we’re eager to share the latest enhancements to the Grazie browser extension.\nIntroducing Text Playground\nText Playground is your new space to refine and polish your writing with AI-powered suggestions for spelling, grammar, and style. To try it, click on the Grazie icon in your browser’s toolbar and then on the Text Playground button. \n\n\n\n\nThis will open a new tab where you can start fresh or paste the text you’re working on. \n\n\n\n\n\n\n\n\nYour text is saved locally, so you can always pick up where you left off. Keep in mind that while you can work on the same text across different tabs, this isn’t possible across different browsers.\nNew login options\nYou can now use your GitHub, GitLab, Bitbucket, or WeChat accounts to access all the features Grazie offers. Just select your preferred platform to get started.\n\n\n\n\nAdditional updates\nGrazie now supports the Arc browser on Windows. Try it out and let us know your thoughts!\nBug fixes: Thanks to your valuable feedback, we’ve ironed out some bugs to improve your experience.\n\n\n\n\nYour input is crucial to us. Continue sharing your thoughts by leaving a comment here or using our feedback form, which you can access by clicking on the browser extension icon.\nFor more details on what Grazie can do for you, visit jetbrains.com/grazie.\nLet’s make your writing awesome together!\nYour JetBrains Team\nGet Grazie for Free\n                                                    \nPS\nThis text was proofread by Grazie.",
        "dc:creator": "Oksana Mandryka",
        "content": "As August draws to a close, we&#8217;re eager to share the latest enhancements to the Grazie browser extension. Introducing Text Playground Text Playground is your new space to refine and polish your writing with AI-powered suggestions for spelling, grammar, and style. To try it, click on the Grazie icon in your browser’s toolbar and then [&#8230;]",
        "contentSnippet": "As August draws to a close, we’re eager to share the latest enhancements to the Grazie browser extension. Introducing Text Playground Text Playground is your new space to refine and polish your writing with AI-powered suggestions for spelling, grammar, and style. To try it, click on the Grazie icon in your browser’s toolbar and then […]",
        "guid": "https://blog.jetbrains.com/?post_type=grazie&p=506314",
        "categories": [
          "news",
          "extensions",
          "grammar",
          "spellchecker",
          "writing-assistance"
        ],
        "isoDate": "2024-08-29T17:48:42.000Z"
      },
      {
        "creator": "Julia Shashkova",
        "title": "IntelliJ IDEA 2024.2.1 Is Out",
        "link": "https://blog.jetbrains.com/idea/2024/08/intellij-idea-2024-2-1/",
        "pubDate": "Thu, 29 Aug 2024 17:48:20 +0000",
        "content:encodedSnippet": "We’ve just released IntelliJ IDEA 2024.2.1. \nYou can update to this version from inside the IDE, via the Toolbox App, or by using snaps for Ubuntu. You can also download it from our website.\nThis release brings support for a variety of Java 23 language features, including module import declarations, basic Markdown comments, and primitive types in patterns, instanceof, and switch, as well as other minor JEPs.\nWe’ve also fixed a number of bugs. Here are some of the most notable updates:\nThe IDE no longer crashes on macOS when the terminal is open. [IJPL-157074]\nThe IDE no longer fails to start when non-ASCII characters are present in the installation path. [IJPL-156417, IJPL-35364]\nThe IDE now correctly recognizes java-test-fixtures as generated test sources. [IDEA-353172]\nThe IDE now saves projects more quickly upon closing, resolving the issue of occasional delays. [IJPL-148614]\nInspection once again works as expected for MVC path variables for @ModelAttribute in Spring projects. [IDEA-347097]\nWith the GitLab plugin enabled, you can once again open a new merge request after merging a previous one from the same branch. [IJPL-81309]\nActions in the JPA Buddy’s toolbar are working once again. [IDEA-356485]\nNumeric and alphabetic dynamic variables now work as intended in the HTTP Client. [IDEA-357259]\n\n\n\n\nTo find out more details about the issues resolved, please refer to the release notes.\nIf you encounter any bugs, please report them to our issue tracker.\nHappy developing!",
        "dc:creator": "Julia Shashkova",
        "content": "We’ve just released IntelliJ IDEA 2024.2.1. You can update to this version from inside the IDE, via the Toolbox App, or by using snaps for Ubuntu. You can also download it from our website. This release brings support for a variety of Java 23 language features, including module import declarations, basic Markdown comments, and primitive [&#8230;]",
        "contentSnippet": "We’ve just released IntelliJ IDEA 2024.2.1. You can update to this version from inside the IDE, via the Toolbox App, or by using snaps for Ubuntu. You can also download it from our website. This release brings support for a variety of Java 23 language features, including module import declarations, basic Markdown comments, and primitive […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=505113",
        "categories": [
          "releases",
          "2024-2",
          "bug-fix-update",
          "intellij-idea-2024-2",
          "intellij-idea-2024-2-1"
        ],
        "isoDate": "2024-08-29T17:48:20.000Z"
      },
      {
        "creator": "Maha Taqi",
        "title": "PyCharm 2024.2.1: What’s New! ",
        "link": "https://blog.jetbrains.com/pycharm/2024/08/pycharm-2024-2-1/",
        "pubDate": "Thu, 29 Aug 2024 16:15:03 +0000",
        "content:encodedSnippet": "PyCharm 2024.2.1 is here! This release’s key features include initial support for Python 3.13, improvements to the Data View tool window, and enhanced code assistance for Django.\nDon’t forget to visit our What’s New page to get all the new updates. Download the latest version from our website, or update your current version through our free Toolbox App.\nDownload PyCharm 2024.2.1\n                                                    \nPyCharm 2024.2.1 key features\nData View PRO\nPyCharm now provides two color-scheme options for the table heatmaps in the Data View tool window: the Diverging and Sequential color schemes. \nThe Diverging color scheme emphasizes variation relative to a norm. It consists of two contrasting colors that deviate from a central value in two opposite directions.\n\n\n\n\nThe Sequential color scheme consists of a single color or a range of closely related colors that vary in intensity.\n\n\n\n\nYou can apply the heatmap color schemes to the whole table or to each column separately, or you can use coloring only for Boolean values.\nPython 3.13\nPyCharm now recognizes TypeIs syntax, providing proper type inference and code completion for user-defined narrowed functions. As part of Python 3.13 support, the IDE is now also aware of ReadOnly keys in TypedDict and warns you if something is assigned to a ReadOnly member.\n\n\n\n    \nRead more\n                                                    \nDjango: Completion for ModelAdmin fields, and more PRO\nGet intelligent code completion, refactoring, and navigation for the fields in ModelAdmin classes. Other productivity enhancements include a warning about newly created apps that have not been added to the INSTALLED_APPS declaration, and the ability to insert an app’s tag into the manage.py console automatically when migrations are made from the Django Structure tool window.\n\n\n\n\nRead our release notes for the full breakdown and more details on all of the features in 2024.2.1. If you encounter any problems, please report them in our issue tracker so we can address them promptly. \nConnect with us on X (formerly Twitter) to share your thoughts on PyCharm 2024.2.1. We’re looking forward to hearing them!",
        "dc:creator": "Maha Taqi",
        "content": "PyCharm 2024.2.1 is here! This release’s key features include initial support for Python 3.13, improvements to the Data View tool window, and enhanced code assistance for Django. Don’t forget to visit our What’s New page to get all the new updates. Download the latest version from our website, or update your current version through our [&#8230;]",
        "contentSnippet": "PyCharm 2024.2.1 is here! This release’s key features include initial support for Python 3.13, improvements to the Data View tool window, and enhanced code assistance for Django. Don’t forget to visit our What’s New page to get all the new updates. Download the latest version from our website, or update your current version through our […]",
        "guid": "https://blog.jetbrains.com/?post_type=pycharm&p=506171",
        "categories": [
          "releases"
        ],
        "isoDate": "2024-08-29T16:15:03.000Z"
      },
      {
        "creator": "Anna Ruban",
        "title": "Join Us for JetBrains GameDev Days 2024",
        "link": "https://blog.jetbrains.com/dotnet/2024/08/28/join-us-for-jetbrains-gamedev-days-2024/",
        "pubDate": "Wed, 28 Aug 2024 08:50:24 +0000",
        "content:encodedSnippet": "We invite you to JetBrains GameDev Days 2024, a hybrid event we’re hosting on October 9-10, 2024.\nCOUNT ME IN!\n                                                    \nOnce a year, we invite community speakers to cover topics they are passionate about. We’ve lined up experts from different fields to deliver talks, lead discussions, and share helpful tips on creating exceptional games. Topics will include CI/CD processes, Unity’s DOTS, C# scripting, game development with Godot, and more.\nIn 2024, we’re again going hybrid. The event will kick off with a few in-person sessions on October 9, followed by the main online event on October 10. More details will be shared soon, so be sure to stay tuned!\n\n\n\n\nAgenda\nTurbocharge Your Unreal Engine Game Development With JetBrains Rider and TeamCity by Daniel Gallo and Matt Ellis\nDeveloper Experience in Mobile GameDev: How We Rebuilt a Plane in Flight by Ilya Bogin\nGodot Game Development Leveraging Kotlin by Pierre-Thomas Meisels, Tristan Grespinet, and Cedric Hippmann\nCSharpify Your Engine: A Guide to Embedding C# by Andreia Gaita\nGame Engines With C# and Rider by Alex Drum\nWhy DOTS Is Unity’s Silver Bullet by Johnny Thompson\nBuilding a Godot Addon by Johannes Ebner\nHow We Built the Backend Architecture for HAWKED: Principles, Technologies, and Tools by Vyacheslav Morov\nThere are more talks to come, so stay tuned for additional announcements.\nYou can choose whether to attend just a few individual sessions or watch every one of them. We hope you enjoy the talks, and we encourage you to ask questions!\nWe’ll stream the presentations live on YouTube, and all the sessions will remain available after the event is over so you can catch up on any you missed. You can also watch session recordings from the previous year.\nCheck out the full agenda here. We look forward to seeing you in October!",
        "dc:creator": "Anna Ruban",
        "content": "We invite you to JetBrains GameDev Days 2024, a hybrid event we&#8217;re hosting on October 9-10, 2024. Once a year, we invite community speakers to cover topics they are passionate about. We&#8217;ve lined up experts from different fields to deliver talks, lead discussions, and share helpful tips on creating exceptional games. Topics will include CI/CD [&#8230;]",
        "contentSnippet": "We invite you to JetBrains GameDev Days 2024, a hybrid event we’re hosting on October 9-10, 2024. Once a year, we invite community speakers to cover topics they are passionate about. We’ve lined up experts from different fields to deliver talks, lead discussions, and share helpful tips on creating exceptional games. Topics will include CI/CD […]",
        "guid": "https://blog.jetbrains.com/?post_type=dotnet&p=505899",
        "categories": [
          "net-tools",
          "events",
          "teamcity-2",
          "conferences",
          "gamedev",
          "gamedev-days-2024",
          "rider",
          "teamcity"
        ],
        "isoDate": "2024-08-28T08:50:24.000Z"
      },
      {
        "creator": "Alex Plate",
        "title": "Workspace Model",
        "link": "https://blog.jetbrains.com/platform/2024/08/workspace-model/",
        "pubDate": "Wed, 28 Aug 2024 07:58:52 +0000",
        "content:encodedSnippet": "The Workspace Model, which serves as the internal storage for project models, has exited its experimental phase. Plugin developers can now safely access and modify the workspace model, benefiting from a centralized API, bulk updates, coroutines, and a persistent data structure.\nThis update is particularly relevant for developers working on build tool integration plugins, such as Maven, Gradle, BSP, Bazel, and others. Additionally, it will be useful for any plugin developers who interact with the JPS project model, known for classes like Module, Library, Facet, ModuleManager, IdeModifiableModelsProvider, and others.\nNew Implementation of the JPS project model\nSome time ago, we announced the reimplementation of project models. The IntelliJ platform still supports old interfaces like Module and ModuleManager to maintain compatibility with existing plugins. However, the new Workspace Model API is now also available for public use. Plugin developers are encouraged to update their code from the old API to the new API. More information on code migration can be found here.\nThe Workspace Model is designed to store any entities, including those defined by plugins. However, defining custom entities is still an experimental part of the API and will be released later. Currently, working with the Workspace Model is limited to using entities provided by the platform.\nBenefits of the Workspace Model\nThe Workspace Model is designed as a persistent data structure, enabling it to handle various multithreading use cases. A snapshot of the storage is immutable and can be processed without a read lock. Batch operations like replaceBySource and applyChangesFrom are designed to support scenarios involving significant updates to the workspace model.\nCompared to the previous implementation of the project models, the Workspace Model keeps everything in one storage, there is a single entry point for all updates, and there is no need to create multiple modifiable models as before. Also, as the old project model API now delegates to the Workspace Model, accessing the new API directly may improve the performance, especially for massive operations or big projects.\nThe flexibility of the Workspace Model allows the entire IntelliJ Platform to change the way we work with the project model. Rather than using specific managers, the subsystem can define extension points that can be contributed by other subsystems. For example, the new WorkspaceFileIndex operates on entities provided by different parts of the IDE instead of directly using the ModuleManager.\nThe event flow allows you to observe all changes occurring within the storage. Every update can be used to incrementally affect subsystems that depend on Workspace Model data. This feature has been utilized to remove some internal implementations of AdditionalLibraryRootsProvider and DirectoryIndexExcludePolicy, which were recalculated from scratch on each change of the project models, leading to improved performance of JetBrains IDEs.\nFurther evolution\nThe new Workspace model is already used in several places. The Rider IDE was the first client of the Workspace Model, and it still actively uses it. The Maven import was rewritten to the new API, giving a boost in performance. Different parts of GoLand, WebStorm, and the Kotlin plugin also started to use the new approach, gaining different benefits.\nThe next steps for the Workspace Model will focus on allowing plugin developers to define and use their own entities. This will make it possible to describe the project model of a build tool with specific entities that accurately reflect the structure of the project.\nCurrently, updates to the Workspace Model occur under a write lock. Future updates will eliminate this requirement, allowing updates to happen without acquiring any locks.\nThe IntelliJ platform still mostly uses the old API for working with the project models, however, all new code will be written using the new Workspace Model API. The subsystems that will benefit from the performance of the new API will also be migrated.",
        "dc:creator": "Alex Plate",
        "content": "The Workspace Model, which serves as the internal storage for project models, has exited its experimental phase. Plugin developers can now safely access and modify the workspace model, benefiting from a centralized API, bulk updates, coroutines, and a persistent data structure. This update is particularly relevant for developers working on build tool integration plugins, such [&#8230;]",
        "contentSnippet": "The Workspace Model, which serves as the internal storage for project models, has exited its experimental phase. Plugin developers can now safely access and modify the workspace model, benefiting from a centralized API, bulk updates, coroutines, and a persistent data structure. This update is particularly relevant for developers working on build tool integration plugins, such […]",
        "guid": "https://blog.jetbrains.com/?post_type=platform&p=506070",
        "categories": [
          "intellij",
          "idea"
        ],
        "isoDate": "2024-08-28T07:58:52.000Z"
      },
      {
        "creator": "Olga Bedrina",
        "title": "TeamCity Pipelines Pulse, Issue #6: Introducing Self- Hosted Agents",
        "link": "https://blog.jetbrains.com/teamcity/2024/08/teamcity-pipelines-pulse-issue6-self-hosted-agents/",
        "pubDate": "Tue, 27 Aug 2024 14:22:34 +0000",
        "content:encodedSnippet": "Want total control over your CI/CD pipeline?\nWe’re introducing self-hosted agents in TeamCity Pipelines! Define your own build environments, manage your resources, and scale effortlessly. No more waiting in line for shared agents.\n\n\n\n\nYou can now choose whether to run jobs on JetBrains-hosted agents or your own. You can also add various requirements for the agents, such as a specific OS, CPU count, CPU arch, or RAM amount, or even go with custom requirements.\n\n\n\n\nJust like with JetBrains-hosted agents, you can open the terminal and connect it directly to the agent during a job to view logs, check installed software, or debug issues – all from the UI.\n\n\n\n\nLearn more about installing self-hosted agents in our docs.\nNew edit mode toggle for pipelines and jobs\nPreviously, it wasn’t obvious how to navigate from the pipeline editor to currently running jobs.\nWe decided to rethink the whole process and introduced the edit mode toggle. Now, you can easily switch between edit mode and run mode. Accessing pipeline and job settings has also become more convenient.\n\n\n\n\nBug fixes and improvements\nWe’ve added a bunch of bug fixes and improvements to TeamCity Pipelines. Here are the highlights.\nIn TeamCity Pipelines, you can run tests in parallel to speed up execution. The Open Terminal button is once again available during parallel tests.\n\n\n\n\nThe Create pipeline button is now completely hidden from users without proper permissions.\n\n\n\n\nWhen TeamCity Pipelines flags errors because settings are wrong, it will now allow you to save your changes after fixing the problems.\n\n\n\n\nTeamCity Pipelines once again correctly auto-detects runners like Maven, Gradle, or npm and suggests optimizations.\n\n\n\n\nAdding a repository to a pipeline no longer triggers a Repository should not be empty error for valid URLs.\n\n\n\n\nWhen duplicating an unsaved job, its dependencies are no longer ignored.\nDid you know?\nIn TeamCity Pipelines, you can define job dependencies conveniently and visually using the drag-and-drop editor. YAML is also available for those who prefer it.\n\n\n\n\nThat’s it for today! As always, feel free to share your feedback in the comments. If you’d like to give TeamCity Pipelines a try, the product is free during Beta.\nLearn more about TeamCity Pipelines\nYours truly,\nThe TeamCity Pipelines team",
        "dc:creator": "Olga Bedrina",
        "content": "Want total control over your CI/CD pipeline? We&#8217;re introducing self-hosted agents in TeamCity Pipelines! Define your own build environments, manage your resources, and scale effortlessly. No more waiting in line for shared agents. You can now choose whether to run jobs on JetBrains-hosted agents or your own. You can also add various requirements for the [&#8230;]",
        "contentSnippet": "Want total control over your CI/CD pipeline? We’re introducing self-hosted agents in TeamCity Pipelines! Define your own build environments, manage your resources, and scale effortlessly. No more waiting in line for shared agents. You can now choose whether to run jobs on JetBrains-hosted agents or your own. You can also add various requirements for the […]",
        "guid": "https://blog.jetbrains.com/?post_type=teamcity&p=505821",
        "categories": [
          "news",
          "releases",
          "release",
          "teamcity-pipelines",
          "teamcity-pipelines-pulse"
        ],
        "isoDate": "2024-08-27T14:22:34.000Z"
      },
      {
        "creator": "Anna Rovinskaia",
        "title": "New Livestream: Introduction to Workspaces in IntelliJ IDEA",
        "link": "https://blog.jetbrains.com/idea/2024/08/new-livestream-java-22-and-intellij-ideanew-livestream/",
        "pubDate": "Tue, 27 Aug 2024 06:59:09 +0000",
        "content:encodedSnippet": "Join us for a new IntelliJ IDEA Livestream episode, where we will explore how to take advantage of the new workspace functionality in your IntelliJ IDEA projects with Andrey Belyaev.\nDate: September 12, 2024\nTime: 3:00 pm – 4:00 pm UTC\nREGISTER FOR THE LIVESTREAM\n\n\n\n\nSession abstract\nThis session will provide a comprehensive overview of the new feature in IntelliJ IDEA: workspaces. Andrey will explain what workspaces are, how they function, and how they can be integrated into your current projects. We will demonstrate some practical examples to get you started: creating a workspace, adding projects, and running them within it.\nAsking questions\nAndrey will try to answer all of your questions during the session. If we run out of time, we’ll publish the answers to any remaining questions in a follow-up blog post.\nYour speaker and host\nSpeaker\nAndrey Belyaev\n\nAndrey Belyaev is a software developer on the IntelliJ IDEA Ultimate team. He works on various plugins and is now primarily focused on cloud and deployment support in IntelliJ IDEA.\n\nHost\nMala Gupta\n\nA Java Champion and JUG leader, Mala has authored multiple books with Manning, Packt, and O’Reilly Publications. She has more than two decades of experience in the software industry and is a regular speaker at industry conferences around the world. She is an active supporter of Java certification as a path to career advancement.\n\nHappy developing!",
        "dc:creator": "Anna Rovinskaia",
        "content": "Join us for a new IntelliJ IDEA Livestream episode, where we will explore how to take advantage of the new workspace functionality in your IntelliJ IDEA projects with Andrey Belyaev. Date: September 12, 2024 Time: 3:00 pm – 4:00 pm UTC REGISTER FOR THE LIVESTREAM Session abstract This session will provide a comprehensive overview of [&#8230;]",
        "contentSnippet": "Join us for a new IntelliJ IDEA Livestream episode, where we will explore how to take advantage of the new workspace functionality in your IntelliJ IDEA projects with Andrey Belyaev. Date: September 12, 2024 Time: 3:00 pm – 4:00 pm UTC REGISTER FOR THE LIVESTREAM Session abstract This session will provide a comprehensive overview of […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=505033",
        "categories": [
          "livestreams",
          "intellij-idea",
          "intellijidealivestream",
          "livestream",
          "webinars"
        ],
        "isoDate": "2024-08-27T06:59:09.000Z"
      },
      {
        "creator": "Aleksandra Aganezova",
        "title": "JetBrains JavaScript Day 2024 Registration Is Now Open",
        "link": "https://blog.jetbrains.com/webstorm/2024/08/jetbrains-javascript-day-2024-registration-is-now-open/",
        "pubDate": "Mon, 26 Aug 2024 15:47:01 +0000",
        "content:encodedSnippet": "Hey everyone! JetBrains JavaScript Day is back for year four, and this edition promises to be our best one yet!\n\n\n\n\n\nLet’s face it, keeping up with the rapid changes in the JavaScript ecosystem is no easy task – it can be hard for us, too. That’s exactly why we created JetBrains JavaScript Day! This year, as always, we brought together top experts to share their insights and discuss the latest trends of modern JavaScript and TypeScript development. Make sure to join us live to ask your questions and be a part of the conversation as it happens.\nWhen: October 24 at 9:00 am EDT (check your timezone)\nWhere: Online\nCost: Free\nRegister!\n                                                    \nHere is this year’s lineup of inspiring speakers and talks: \nVite and the Future of JavaScript Tooling, by Evan You\nTypeScript Generics: Practical Fun!, by Josh Goldberg\nThe Silent Open Source Crisis: When Maintainers Walk Away, by Bekah Hawrot Weigel\nYou Don’t Need JavaScript for That, by Kevin Powell \nEverything You Need to Know About React 19, by Shruti Kapoor\nDriving Your JavaScript Library Ecosystem With Nx, by Chau Tran\nEvolving Angular for the Long Run, by Jeremy Elbourn\nTypeScript and Your Codebase: They Deserve Each Other!, by Danny Thompson\nWe’ve also added an Ask Me Anything (AMA) session with the WebStorm team to our agenda for all of you who want to meet the people behind the JavaScript support for JetBrains IDEs.\nGrab your tickets today, and we’ll see you there!\nYour JetBrains team",
        "dc:creator": "Aleksandra Aganezova",
        "content": "Hey everyone! JetBrains JavaScript Day is back for year four, and this edition promises to be our best one yet! Let’s face it, keeping up with the rapid changes in the JavaScript ecosystem is no easy task – it can be hard for us, too. That’s exactly why we created JetBrains JavaScript Day! This year, [&#8230;]",
        "contentSnippet": "Hey everyone! JetBrains JavaScript Day is back for year four, and this edition promises to be our best one yet! Let’s face it, keeping up with the rapid changes in the JavaScript ecosystem is no easy task – it can be hard for us, too. That’s exactly why we created JetBrains JavaScript Day! This year, […]",
        "guid": "https://blog.jetbrains.com/?post_type=webstorm&p=505594",
        "categories": [
          "news",
          "javascript-day"
        ],
        "isoDate": "2024-08-26T15:47:01.000Z"
      },
      {
        "creator": "Andrei Kislitsyn",
        "title": "Track and Analyze GitHub Star Growth With  Kandy and Kotlin DataFrame",
        "link": "https://blog.jetbrains.com/kotlin/2024/08/track-and-analyze-github-star-growth-with-kandy-and-kotlin-dataframe/",
        "pubDate": "Mon, 26 Aug 2024 14:37:54 +0000",
        "content:encodedSnippet": "Kotlin DataFrame and Kandy are two powerful tools for data analysis in Kotlin. Kotlin DataFrame simplifies data manipulation and processing, while Kandy allows you to create visualizations directly within your Kotlin projects.\nIn this post, we’ll show you how these tools can be used together within Kotlin Notebook to analyze the star history of GitHub repositories. This isn’t just a simple exercise for demonstration purposes – it’s a tutorial that can help you learn how to analyze your own repositories, understand their popularity trends, and visualize your data effectively. All examples from this post are available as a Kotlin Notebook on GitHub or a Notebook on Datalore, a data science platform by JetBrains.\nAnalyze your GitHub star history\nUnderstanding the star history of a GitHub repository can provide insights into its popularity and growth over time. By analyzing this data, you can see how different events and activities impact the interest in your project. Our goal is to equip you with the knowledge and tools to perform this analysis on your own repositories.\nObtain repository stargazers data from GitHub\nFirst, we need to gather data about the users who have starred a given repository. To achieve this, we’ll use the GitHub GraphQL API, which requires a GitHub access token. Here’s a simple function to request data about repo stars, including the starring time and user login:\nimport io.ktor.client.request.*\nimport io.ktor.http.*\n\n/**\n*  We need to specify the repository owner and name, as well as the access token.\n* There can be up to 100 results on one response page.\n* For this example, we'll take only the first 3 results.\n* `endCursor` points to the end of the previous page (`null` for the first one). \n*/\nfun fetchStarHistoryPage(owner: String, name: String, token: String, first: Int = 100, endCursor: String? = null): NotebookHttpResponse {\n   // GraphQL query\n   val query = \"\"\"\n       query {\n         repository(owner: \"$owner\", name: \"$name\") {\n           stargazers(first: $first, after: $endCursor) {\n             edges {\n               starredAt\n               node {\n                 login\n               }\n             }\n             pageInfo {\n               endCursor\n               hasNextPage\n             }\n           }\n         }\n       }\n   \"\"\".trimIndent()\n   // `http` is the default Ktor `HttpClient` for Notebook;\n   // it has the same methods but without `suspend` modifiers, \n   // allowing you to make HTTP requests quickly and easily. \n   // Make a \"post\" request to the API with this query\n   return http.post(\"https://api.github.com/graphql\") {\n       // Set authorization header with token\n       bearerAuth(token)\n       // Set content type header\n       contentType(ContentType.Application.Json)\n       // Set query as body\n       setBody(buildJsonObject { put(\"query\", query) })\n   }\n}\nA convenient and easy way to set an environment variable is through the Kotlin Notebook settings:\n\n\n\n\nNext, specify the repository owner and name, and ensure your GitHub token is securely stored:\nval ownerKotlin = \"Kotlin\"\nval repoKandy = \"kandy\"\n// Keep your token safe as an environment variable or a system property!\n// For example, you can place it in environment variables in Kotlin Notebook settings.\nval token = System.getenv(\"GITHUB_TOKEN\")\nTo start, let’s query a single page with a few users to examine the data. \nval rawResponse = fetchStarHistoryPage(ownerKotlin, repoKandy, token, first = 3)\nrawResponse\n\n\n\n\nThe response from the API looks like this:\nHttpResponse[https://api.github.com/graphql, 200 OK]\nNext, we’ll deserialize the JSON response to a Kotlin data class using the .deserializeJson() extension provided by our Kotlin Notebook Ktor integration. This makes it easier to work with the response body data in Kotlin.\nval starHistorySimplePage = rawResponse.deserializeJson()\n// Take the JSON string for further work with DataFrame\nval responseAsJson = starHistorySimplePage.jsonString\nstarHistorySimplePage\nThe result is a structured object representing the data, which looks like this:\n{\n \"data\": {\n   \"repository\": {\n     \"stargazers\": {\n       \"edges\": [\n         {\n           \"starredAt\": \"2022-07-13T22:46:16Z\",\n           \"node\": {\n             \"login\": \"manojselvam\"\n           }\n  ...\n}\nAfter executing the cell above, starHistorySimplePage is converted to a data class, allowing us to easily access those of its properties that correspond to JSON fields. This seamless integration with IntelliJ IDEA autocompletion makes working with the response straightforward.\n\n\n\n\nFor example, we can extract all the starring times from the page:\nstarHistorySimplePage.data.repository.stargazers.edges.map { it.starredAt }\nOutput:\n[2022-07-13T22:46:16Z, 2022-11-05T14:21:10Z, 2022-11-05T18:42:37Z]\nNext, let’s parse the page data into a DataFrame. \nval starHistoryPageDF = DataFrame.readJsonStr(responseAsJson)\nstarHistoryPageDF\n\n\n\n\nWe need two columns: one showing the user logins and the other their starring times. We can retrieve these columns as follows:\nstarHistoryPageDF.data.repository.stargazers.edges\n   .single() // the `edges` column contains a single DataFrame with current page stargazers\n   .flatten() // `login` is a subcolumn of `node`, after `flatten()` it is a simple column\n\n\n\n\nAdditionally, we need page meta-information, including whether there is a next page and the current page end cursor.\nwith(starHistoryPageDF.data.repository.stargazers.pageInfo) {\n   // Both are columns with a single value\n   println(\"end cursor: ${endCursor.single()}\")\n   println(\"has next page: ${hasNextPage.single()}\")\n}\nThis code outputs the following:\nend cursor: Y3Vyc29yOnYyOpIAzhXiSlk=\nhas next page: true\nNow, let’s create a function that iteratively processes all pages with stargazers and returns a DataFrame with complete information:\n// Casts DataFrame to the type of a given DataFrame so we can use\n// extension columns that have already been generated.\n// Temporary workaround, will be available in future DataFrame releases\n// (https://github.com/Kotlin/dataframe/pull/747)\ninline fun <reified T> AnyFrame.castTo(df: DataFrame<T>): DataFrame<T> {\n   return cast<T>(verify = true)\n}\nimport io.ktor.client.statement.*\n\n// Provide repo owner, name, and access token\nfun fetchStarHistory(owner: String, name: String, token: String): AnyFrame {\n   var hasNextPage: Boolean = true\n   var endCursor: String? = null\n   var buffer: DataFrame<*> = DataFrame.Empty\n   while (hasNextPage) {\n       val response = fetchStarHistoryPage(owner, name, token, 100, endCursor)\n       // Cast type of DataFrame to the type of `starHistoryPageDF`,\n       // so we can use its already-generated extensions\n       val responseDF = DataFrame.readJsonStr(response.bodyAsText()).castTo(starHistoryPageDF)\n       val stargazers = responseDF.data.repository.stargazers\n       buffer = buffer.concat(stargazers.edges.first().flatten())\n       val pageInfo = stargazers.pageInfo\n       endCursor = \"\\\"${pageInfo.endCursor.single()}\\\"\"\n       hasNextPage = pageInfo.hasNextPage.single()\n   }\n   return buffer\n}\nUsing this function, we can now retrieve all the Kandy stargazers:\nval kandyStargazers = fetchStarHistory(ownerKotlin, repoKandy, token)\nkandyStargazers\n\n\n\n\nLook at the DataFrame summary using the .describe() method, which shows meta-information and accumulated statistics about DataFrame columns:\nkandyStargazers.describe()\n\n\n\n\nAll login values are unique, indicating that the dataset is correct. Additionally, there are no null values, so no further processing is needed.\nCreate a DataFrame for cumulative star count analysis\nWe now have two key pieces of information: user logins and the times they award stars. Our next step is to perform an initial analysis.\nWe’ll create a visualization showing the cumulative number of stars received over time, illustrating how user interest in our library grows and changes.\nThis approach will help us understand the dynamics of user engagement and the popularity of our library.\nHere’s how to transform this data:\nConvert the starredAt column to LocalDateTime.\nSort the DataFrame by  starredAt, in ascending order.\nAdd a starsCount column to track the total number of stars over time.\nPut the processing code into a function so that it can be reused later on.\nfun AnyFrame.processStargazers(): AnyFrame {\n   return castTo(kandyStargazers)\n       // Convert `starredAt` column to `LocalDateTime`\n       .convert { starredAt }.toLocalDateTime()\n       // Sort rows by `starredAt`\n       .sortBy { starredAt }\n       // Add `starsCount` column with total stars count at each row.\n       // The star count is simply the row index increased by 1\n       .add(\"starsCount\") { index() + 1 }\n}\nval kandyStarHistory = kandyStargazers.processStargazers()\nkandyStarHistory\n\n\n\n\nVisualize star history: plot with Kandy\nWith the data processed, we can now visualize the star history using Kandy. Here’s a simple line plot to show how the number of stars has changed over time. \nkandyStarHistory.plot {\n   line {\n       // The starring time corresponds to the `x` axis\n       x(starredAt) {\n           axis {\n               // Set the name for the `x` axis\n               name = \"date\"\n               // Set the format for axis breaks\n               breaks(format = \"%b, %Y\")\n           }\n       }\n       // The stars count corresponds to the `y` axis\n       y(starsCount) {\n           // Set the name for the `y` axis\n           axis.name = \"GitHub stars\"\n       }\n   }\n    layout {\n       title = \"Kandy GitHub star history\"\n       size = 800 to 500\n   }\n}\n\n\n\n\nThe plot displays the cumulative growth of stars, reflecting how interest in the Kandy library has evolved. Key points of significant increase can often be associated with major announcements or events related to the library.\nTo better understand how user interest in our library evolves over time, we’ll animate this chart using the Kotlin Jupyter API. This dynamic visualization will help us see how engagement patterns shift and grow, providing deeper insights than a static chart could offer.\nWe’ll start by creating a function that builds a star history chart for the first n star(s). \nfun kandyStarHistoryPlot(n: Int) = kandyStarHistory.plot {\n   line {\n       x(starredAt.take(n)) {\n           axis {\n               name = \"date\"\n               breaks(format = \"%b, %Y\")\n           }\n       }\n       y(starsCount.take(n)) {\n           axis.name = \"GitHub stars\"\n       }\n   }\n   layout {\n       title = \"Kandy GitHub star history\"\n       size = 800 to 500\n   }\n}\nThen, we’ll use the ANIMATE() function to update the cell output for a given set of frames. Each frame will be a star history plot, starting with one star and incrementing by one star each frame until we reach the maximum number of stars.\nANIMATE(50.milliseconds, kandyStarHistory.rowsCount()) { frameID ->\n   // frame with `frameID` contsins plot with `frameID + 1` stars\n   kandyStarHistoryPlot(frameID + 1)\n}\n\n\n\n\nAnalyze key events\nWe’ll look at how different events influenced the growth of stars. We’ll add mark lines with the most important events related to Kandy, such as the Kotlin Notebook video, the Kandy introductory post, the Plotting Financial Data in Kotlin with Kandy post, and KotlinConf 2024. Such analysis helps to identify what drives interest and engagement with the project.\nWe’ll look at events starting from October 2023, which was when we initiated our marketing activities:\nval starHistoryFiltered = kandyStarHistory.filter { starredAt >= LocalDateTime(2023, 10, 1, 0, 0, 0, 0) }\nThen we’ll add mark lines with the events:\nval ktnbYTVideodate = LocalDate(2023, 10, 25)\nval kandyIntroductoryPostDate = LocalDate(2023, 12, 14)\nval kandyFinancialPostDate = LocalDate(2024, 4, 9)\nval kotlinConf24Date = LocalDate(2024, 5, 22)\n\nval kandyEvents = listOf(\n   \"Kotlin Notebook\\nYouTube video\",\n   \"Kandy Introduction\\nKotlin Blog post\",\n   \"Financial Plotting\\nMedium post\",\n   \"KotlinConf 2024\"\n)\nval kandyEventsDates = listOf(ktnbYTVideodate, kandyIntroductoryPostDate, kandyFinancialPostDate, kotlinConf24Date)\n\n\n\n\nTo make the plot more visually engaging, we’ll create a custom color palette for these event markers.\nval eventColors = listOf(\n   Color.hex(\"#1f77b4\"),\n   Color.hex(\"#ff7f0e\"),\n   Color.hex(\"#d62728\"),\n   Color.hex(\"#2ca02c\"),\n)\nFinally, we’ll generate the plot with vertical lines representing these events, allowing us to see how each significant event influenced the star history.\nstarHistoryFiltered.plot {\n   // add vertical marklines with event dates\n   vLine {\n       color(kandyEvents, \"event\") { scale = categorical(eventColors, kandyEvents) }\n       xIntercept(kandyEventsDates)\n       width = 1.5\n       alpha = 0.9\n   }\n   line {\n       x(starredAt) {axis.name = \"date\" }\n       y(starsCount) { axis.name = \"GitHub stars\" }\n   }\n   layout {\n       title = \"Kandy GitHub star history & key events\"\n       size = 800 to 500\n       style {\n           legend.position = LegendPosition.Bottom\n       }\n   }\n}\n\n\n\n\nThis plot shows the number of stars Kandy received each month, with different colors representing key events that influenced these numbers. For example, the introductory post and other significant updates coincide with noticeable increases in stars, highlighting the influence of these activities on community engagement.\nAnalyze monthly star growth\nTo analyze the monthly growth of stars, we will create a bar chart to visually display the changes in the number of stars received each month. This visualization will help us identify key growth periods and evaluate the effectiveness of our marketing strategies.\nFirst, let’s define simple extension functions to convert the LocalDate/LocalDateTime to a month and four-figure year format.\nfun LocalDate.toMonthOfYear(): String = \"$month, $year\"\nfun LocalDateTime.toMonthOfYear(): String = \"$month, $year\"\nNow, we’ll add the “month” column to our DataFrame:\nval starHistoryWithMonth = starHistoryFiltered.add(\"month\") {\n   starredAt.toMonthOfYear()\n}\nstarHistoryWithMonth\n\n\n\n\nNext, we’ll group the DataFrame by the “month” column and count the number of stars in each group.\nval starsCountMonthly = starHistoryWithMonth.groupBy { month }.count()\nstarsCountMonthly\n\n\n\n\nNext, we’ll add information about key events to the DataFrame. We’ll include the events in the corresponding months and set the value to null if there were no events.\nFirst, create a DataFrame with events and their corresponding months:\nval eventsDF = dataFrameOf(\"event\" to kandyEvents, \"month\" to kandyEventsDates.map {\n   it.toMonthOfYear()\n})\nThen, perform a left join with our main DataFrame at the month column:\nval starsMonthlyWithEvent = starsCountMonthly.leftJoin(eventsDF) { month }\nstarsMonthlyWithEvent\n\n\n\n\nNow, we can create a bar plot to visualize the distribution of new stars by month, along with the key events.\nstarsMonthlyWithEvent.plot {\n   bars {\n       x(month)\n       y(count)\n       alpha = 0.8\n       fillColor(event) { scale = categorical(eventColors, kandyEvents) }\n   }\n   // add horizontal markline with median of monthly count\n   hLine {\n       val medianMonthly = count.median()\n       yIntercept.constant(medianMonthly)\n       type = LineType.DASHED\n       color = Color.hex(\"#4b0082\")\n       width = 2.0\n   }\n   layout {\n       title = \"Kandy GitHub star history (monthly count)\"\n       size = 800 to 500\n       style {\n           legend.position = LegendPosition.Bottom\n           xAxis.text { angle = 30.0 }\n       }\n   }\n}\n\n\n\n\nThis plot shows the monthly distribution of stars, with bars representing the number of stars each month. The colors of the bars indicate key events, providing a clear visualization of how these events impacted the star counts. The dashed horizontal line represents the median star count per month.\nUnlike the overall star history chart, which shows cumulative growth, the monthly statistics plot helps you pinpoint the exact timing and impact of key events. By creating similar plots for your own projects, you can better understand the effectiveness of your promotional efforts, identify seasonal patterns, and plan future activities more effectively.\nUnderstand your audience\nUnderstanding the top programming languages of your stargazers can provide insights into your audience. With this in mind, we’ll use the GitHub REST API to find out the most popular languages among Kandy stargazers and visualize this data as a pie chart.\nLet’s write a function that requests user repositories:\nimport io.ktor.http.*\n\nfun getUserRepos(login: String): AnyFrame {\n   return DataFrame.readJsonStr(http.get(\"https://api.github.com/users/$login/repos\") {\n       // Set authorization header with token\n       bearerAuth(token)\n       // Add GitHub API custom \"accept\" header\n       header(HttpHeaders.Accept, \"application/vnd.github.v3+json\")\n   }.deserializeJson().jsonString)\n}\nNext, we’ll test this function on our sample repositories:\nval myRepos = getUserRepos(\"Kotlin\")\nmyRepos\n\n\n\n\nEach column in this DataFrame corresponds to a repository and contains different information about that repository. We are interested in the language column. We can count the most frequent language using the .valueCounts() method, where the first entry represents the most popular language:\nval myLanguagesCounts = myRepos.language.valueCounts(dropNA = false) // Don't drop nulls\nmyLanguagesCounts\n\n\n\n\nBecause the rows are sorted by count by default, identifying the most popular language is straightforward – it’s the first one.\nmyLanguagesCounts.language.first()\nKotlin\nTo generalize this process, we’ll write an extension function for a DataFrame obtained from the user’s repositories. This extension function will retrieve the most popular language (returning null if the account is private, has no repositories, or lacks sufficient information).\nfun AnyFrame.getTopLanguage(): String? {\n   //  Handle non-default response bodies (private account, no repositories, etc.)\n   if (!containsColumn(\"language\")) return null\n   return castTo(myRepos).language\n       .valueCounts(dropNA = false)\n       .castTo(myLanguagesCounts)\n       .language.let { languages ->\n           val first = languages.firstOrNull()\n           //  Try to pick the second value if the first one is null\n           if (first == null && languages.size() >= 2) {\n               languages[1]\n           } else first\n       }\n}\nNow, let’s retrieve the most popular languages for all stargazers. Note that this process might take some time to execute:\nval stargazersLanguages = kandyStarHistory.select {\n   login and login.map { login -> getUserRepos(login).getTopLanguage() }.named(\"language\")\n}\nstargazersLanguages\n\n\n\n\nNext, we’ll count the occurrences of each language:\nval languageCounts = stargazersLanguages.language.valueCounts() // Drops null by default\nlanguageCounts\n\n\n\n\nFinally, let’s plot these counts as a pie chart. We’ll take the seven most popular languages and group the remaining ones into an “other” category:\nlanguageCounts.let {\n   val takeFirst = 7\n   it.take(takeFirst).concat(\n       dataFrameOf(\"language\" to listOf(\"other\"), \"count\" to listOf(it.drop(takeFirst).sum {count}))\n   )\n}.plot {\n   pie {\n       slice(\"count\")\n       fillColor(\"language\")\n       size = 25.0\n       hole = 0.3\n   }\n   layout {\n       title = \"Kandy stargazers' most popular languages\"\n       style(Style.Void)\n   }\n}\n\n\n\n\nThe pie chart shows that Kotlin is the most popular language among Kandy stargazers, confirming our primary audience as Kotlin developers. The presence of Java suggests potential for further engagement with related ecosystems. The inclusion of less-common languages highlights the diversity of our user base, which is important for understanding different use cases and potential feature requests.\nThese insights can help tailor your project’s documentation, tutorials, and marketing efforts to better serve and expand your audience.\nCompare star growth: Kandy vs. Kotlin DataFrame\nComparing star data across different projects can provide valuable insights into their popularity and user engagement. Here, we’ll look at the growth of stars for Kandy alongside Kotlin DataFrame. These two projects, launched within a year of each other, target the same audience of Kotlin developers.\nTo ensure a fair comparison, we’ll use the introduction post date as the starting point for both libraries and examine the six months that followed. This way, we can see how each project grew over the same timeframe, giving us a clearer picture of their growth patterns.\nval repoDataframe = \"dataframe\"\n// Use the already written methods to get star history for DataFrame\nval dataFrameStarHistory = fetchStarHistory(ownerKotlin, repoDataframe, token).processStargazers()\n\n\n\n\nDefining the introductory post date for DataFrame:\nval dataFrameIntroductoryPostDate = LocalDate(2022, 6, 30)\nNext, we’ll define a function to process the star history for the six months following the introduction post:\n// Function that will slightly transform the dataframe with star history for a given library: \n// 1) Take a period of six months after the introduction post date; \n// 2) Add a column \"daysAfterPost\" with the number of days after the post date; \n// 3) Take the maximum number of stars for the day; \n// 4) Add a column \"library\" corresponding to the name of the library.\nfun AnyFrame.proccessAfterPostPeriod(introductionPostDate: LocalDate, library: String): AnyFrame {\n   // Six-month period after `introductionPostDate`\n   val period = (introductionPostDate - DatePeriod(days = 1))..(introductionPostDate + DatePeriod(months = 6))\n   return castTo(kandyStarHistory)\n       // Only take stars placed during that period\n       .filter { starredAt.date in period }\n       // Add daysAfterPost column with number of days after post\n       .add(\"daysAfterPost\") {\n           introductionPostDate.daysUntil(starredAt.date)\n       }\n       // Group by number of days and take the max value of `starsCount` for each group\n       .groupBy(\"daysAfterPost\").max { starsCount }\n       // Add a column with library name\n       .add(\"library\") { library }\n}\nFinally, we’ll combine the star histories for Kandy and DataFrame into a single DataFrame for comparison:\n// Count six-month history for both libraries and concatenate them into one DataFrame\nval kandyAndDataFrameStarHistory = kandyStarHistory\n   .proccessAfterPostPeriod(kandyIntroductoryPostDate, \"Kandy\")\n   .concat(\n       dataFrameStarHistory.proccessAfterPostPeriod(dataFrameIntroductoryPostDate, \"DataFrame\")\n   )\nkandyAndDataFrameStarHistory\n\n\n\n\nNext, we’ll visualize the comparison:\nkandyAndDataFrameStarHistory.plot {\n   line {\n       x(daysAfterPost) {\n           axis {\n               name = \"days after post\"\n           }\n       }\n       y(starsCount) {\n           axis.name = \"GitHub stars\"\n       }\n       color(library)\n   }\n   layout {\n       title = \"Kandy vs. DataFrame GitHub stars history\\nwithin 6 months after the introductory post\"\n       size = 800 to 500\n   }\n}\n\n\n\n\nFrom the initial observation, we can see that before the introduction post, both Kandy and Kotlin DataFrame had similar star counts. However, immediately after the post, Kandy showed a significantly higher growth rate, achieving nearly twice as many stars as DataFrame within the first six months.\nThis difference suggests several things. Firstly, it shows the growing interest in Kotlin for data projects. The period of time that elapsed from the initial DataFrame post and the Kandy post was about a year and a half. While DataFrame helped establish a community of Kotlin data enthusiasts, Kandy attracted a new audience interested in visualization.\nAdditionally, Kandy had more intense promotional activities within the six months following its first post, which likely contributed to its rapid growth.\nShared stargazers\nIt’s also interesting to see how many users have starred both Kandy and DataFrame. We hypothesize that there will be a significant overlap, since both libraries serve the same community of Kotlin developers. Here’s how we can analyze this and get the relevant data:\n// inner join star history dataframes of repositories by login,\n// getting a dataframe with all common stargazers, taking its size to get a number of them\nval commonStargazers = kandyStarHistory.innerJoin(dataFrameStarHistory) { login }.rowsCount()\nval kandyTotalStargazers = kandyStarHistory.rowsCount()\nval kandyOnlyStargazers = kandyTotalStargazers - commonStargazers\nval dataFrameTotalStargazers = dataFrameStarHistory.rowsCount()\nval dataFrameOnlyStargazers = dataFrameTotalStargazers - commonStargazers\nPlot this data as a pie chart:\nplot {\n   pie {\n       slice(listOf(commonStargazers, kandyOnlyStargazers, dataFrameOnlyStargazers))\n       fillColor(listOf(\"Common\", \"Kandy only\", \"DataFrame only\")) {\n           scale = categorical(\n               \"Common\" to Color.hex(\"#4A90E2\"),\n               \"Kandy only\" to Color.hex(\"#F5A623\"),\n               \"DataFrame only\" to Color.hex(\"#7ED321\"),\n           )\n           legend.name = \"\"\n       }\n       size = 25.0\n   }\n   layout {\n       title = \"Kandy & DataFrame stargazers ratio\"\n       style(Style.Void)\n   }\n}\n\n\n\n\nThe analysis shows that the majority of stargazers are unique to DataFrame, with fewer users starring both DataFrame and Kandy. Specifically, the share of DataFrame stargazers who also starred Kandy is quite small. This is probably because many users use DataFrame for data tasks that don’t involve visualization, making Kandy less relevant to them.\nInterestingly, only about a quarter of Kandy stargazers have also starred DataFrame. This suggests that Kandy has attracted a new audience mainly interested in plotting, rather than data processing. This reveals a great opportunity to promote how both libraries can work together.\nUsing Kandy for visualization and DataFrame for data processing allows users to benefit from the strengths of both libraries. This combination, as we’ve shown in this post, can help create powerful and comprehensive data analysis solutions. By highlighting this synergy, we can encourage more users to explore how these tools can complement each other and enhance their data projects.\nConclusion\nIn this post, we explored how to use Kotlin DataFrame and Kandy to dive into the star history of GitHub repositories. But it wasn’t just about looking at the numbers – it was about uncovering the stories those numbers tell.\nOne big takeaway is how quickly Kandy gained traction after its launch, highlighting a growing interest in visualization tools within the Kotlin community. Yet, we also found that many Kandy users haven’t tried DataFrame, and vice versa. This shows there’s an opportunity to help developers see how these tools can complement each other.\nWe also noticed that certain events, like blog posts and conferences, had a noticeable impact on star counts. This kind of insight can help you time your own announcements to get the most attention.\nWhat’s next?\nNow it’s your turn! Apply these techniques to your own repositories, analyze their star history, and create your own visualizations within Kotlin Notebook. All examples from this post are available as a Kotlin Notebook on GitHub or a Notebook on Datalore.\nWe’d love to see your results and hear your feedback. Join us in the #datascience channel on Kotlin Slack, or reach out via GitHub issues for Kandy or Kotlin DataFrame.\nIf you find our repositories useful, we’d really appreciate it if you starred them. Your support helps us improve and develop these tools further.\nWhat else to read and watch\nFor more information, check out the following resources:\nKotlin for Data Analysis Overview\nGet started with Kotlin Notebook\nA Step-by-Step Guide to Performing Data Analysis With Kotlin DataFrame\nData Analytics With Kotlin Notebooks, DataFrame, and Kandy",
        "dc:creator": "Andrei Kislitsyn",
        "content": "Kotlin DataFrame and Kandy are two powerful tools for data analysis in Kotlin. Kotlin DataFrame simplifies data manipulation and processing, while Kandy allows you to create visualizations directly within your Kotlin projects. In this post, we’ll show you how these tools can be used together within Kotlin Notebook to analyze the star history of GitHub [&#8230;]",
        "contentSnippet": "Kotlin DataFrame and Kandy are two powerful tools for data analysis in Kotlin. Kotlin DataFrame simplifies data manipulation and processing, while Kandy allows you to create visualizations directly within your Kotlin projects. In this post, we’ll show you how these tools can be used together within Kotlin Notebook to analyze the star history of GitHub […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=504121",
        "categories": [
          "ecosystem",
          "data-analysis",
          "dataframe",
          "kandy",
          "notebooks"
        ],
        "isoDate": "2024-08-26T14:37:54.000Z"
      },
      {
        "creator": "Alena Guzharina",
        "title": "A Complete Guide to Credit Risk Analysis With Python and Datalore AI",
        "link": "https://blog.jetbrains.com/datalore/2024/08/26/a-complete-guide-to-credit-risk-analysis-with-python-and-datalore-ai/",
        "pubDate": "Mon, 26 Aug 2024 14:34:49 +0000",
        "content:encodedSnippet": "This is a guest blog post by Ryan O’Connell, CFA, FRM.\nUnderstanding the relationships between various economic indicators is crucial for navigating the financial landscape. These relationships significantly impact the overall state of the economy, affecting businesses, investors, and individuals alike. \n“In this tutorial, we’ll focus on the complex interplay between federal funds rates, 10-year Treasury yields, and corporate bond yields – key indicators that shape investment strategies, economic forecasts, and policy decisions.”\n\n            \nRyan O’Connell\n                                                                CFA, FRM\n                                    \nWe’ll analyze data spanning over two decades of financial history, leveraging the power of Python, the Federal Reserve Economic Data (FRED) API, and Datalore’s AI-assisted coding capabilities. Python is particularly well-suited for this analysis due to its ability to efficiently pull and process large amounts of financial data through APIs. This approach allows for easy automation and replication of the analysis, offering a significant advantage over traditional spreadsheet methods.\nOur goal is to uncover patterns, anomalies, and insights that illuminate the predictive power of yield curve changes on credit spreads. By using Python, we can create a workflow that’s not only powerful but also easily updatable for future analyses in just a few clicks.\n\n\n\n\nIn this tutorial, you’ll learn how to:\nSet up your Python environment in Datalore for financial data analysis.\nUse Datalore’s AI Assistant to generate code for data retrieval and preprocessing.\nCreate visualizations to analyze yield curve dynamics and credit spreads.\nImplement statistical analyses to explore the relationship between yield curves and credit risk.\nLeverage AI to help interpret results and generate insights.\nWhether you’re a credit risk analyst looking to leverage more of Python within your stack or a curious newcomer to the world of credit risk, this tutorial will provide you with the tools and techniques to conduct your own in-depth analysis using Python and Datalore AI assistance.\nLet’s dive in and start coding!\n      \n      Open Datalore Code\n\n\n\n\n\nDisclaimer: This article is for informational and educational purposes only and is not intended to serve as personal financial advice.\nThe Yield Curve: A Financial Crystal Ball?\nBefore we dive into the data, let’s establish some context. The yield curve, particularly the spread between long-term and short-term interest rates, has long been considered a powerful predictive tool in finance. But why?\nEconomic expectations: The yield curve reflects market expectations about future economic conditions. A normal, upward-sloping curve suggests optimism, while an inverted curve often signals pessimism.\nMonetary policy: It provides insights into the market’s view of future monetary policy decisions by central banks.\nCredit risk: The shape of the yield curve can influence lending behaviors and, consequently, credit risk in the economy.\n\n\n\n\nOur analysis focuses on three key components:\nThe federal funds rate: the short-term interest rate at which banks lend to each other overnight.\nThe 10-year Treasury yield: a benchmark for long-term interest rates in the US.\nCorporate bond yields: representing the cost of borrowing for corporations.\n\n\n\n\nBy examining the relationships between these factors, we aim to uncover insights that could help predict changes in credit spreads and, by extension, credit risk in the market.\nSetting up your environment and retrieving data\nBefore we dive into the analysis, you have two options to get started:\nStart a new Datalore notebook to follow along with this tutorial from scratch.\nIf you have a Datalore account, you can click Edit copy on this Datalore report. This option allows you to see the full analysis and modify it as you go.\nWhichever option you choose, we’ll need to set up our Python environment in Datalore and retrieve the necessary data. We’ll be using the Federal Reserve Economic Data (FRED) API to fetch historical data on federal funds rates, 10-year Treasury yields, and corporate bond yields.\nSetting up your FRED API key\nTo use the FRED API, you’ll need to obtain an API key. Here’s how to set it up in Datalore:\nGo to the FRED API Key documentation and click on Request API Key.\nRegister for an account or log in if you already have one.\nOnce you have your API key, go to Environment in your Datalore workspace.\nClick on Environment Variables.\nSelect + New Variable.\nSet up the variable as follows:\n\nVariable title: FRED_API_KEY\nKey: FRED_API_KEY\nValue: Your actual FRED API key\n\n\n\n\nInstalling required packages\nIn Datalore, you can easily install required packages. For this tutorial, we’ll need the fredapi package. To install it:\nGo to the Environment tab in Datalore.\nClick on Package Management.\nSearch for ”fredapi” and click Install.\n\n\n\n\nDatalore’s Environment Manager\n\n\n\nRetrieving fed funds rate data with AI assistance\nNow, let’s use Datalore’s AI assistance to help us write code to retrieve and plot 20 years of federal funds rate data. \nDatalore AI\n\n\n\nHere’s how you can prompt the AI:\n\nAI Prompt\nWrite Python code to retrieve the last 20 years of federal funds rate data using the FRED API. Please include the following steps:\n1. Import necessary libraries (fredapi and pandas)\n2. Set up the FRED API connection using the FRED_API_KEY environment variable\n3. Retrieve the federal funds rate data (series ID: FEDFUNDS) for the last 20 years\n4. Convert the data to a pandas DataFrame\n5. Display the first few rows of the DataFrame\n6. Plot the federal funds rate over time using matplotlib\nNote: Include comments explaining each step of the process.\n\n\n\n\n\nHere’s the code the AI might generate:\n# Import necessary libraries\nimport pandas as pd\nfrom fredapi import Fred\nimport matplotlib.pyplot as plt\nfrom datetime import datetime, timedelta\nimport os\n\n# Set up the FRED API connection using the environment variable\nfred = Fred(api_key=os.environ['FRED_API_KEY'])\n\n# Calculate the date 20 years ago from today\nend_date = datetime.now()\nstart_date = end_date - timedelta(days=20*365)\n\n# Retrieve the federal funds rate data (series ID: FEDFUNDS) for the last 20 years\nfed_funds_data = fred.get_series('FEDFUNDS', start_date, end_date)\n\n# Convert the data to a pandas DataFrame\nfed_funds_df = pd.DataFrame(fed_funds_data, columns=['Rate'])\nfed_funds_df.index.name = 'Date'\n\n# Display the first few rows of the DataFrame\nprint(fed_funds_df.head())\n\n# Plot the federal funds rate over time\nplt.figure(figsize=(12, 6))\nplt.plot(fed_funds_df.index, fed_funds_df['Rate'])\nplt.title('Federal Funds Rate (Last 20 Years)')\nplt.xlabel('Date')\nplt.ylabel('Rate (%)')\nplt.grid(True)\nplt.show()\n      \n      Open Datalore Code\n\n\n\n\n\nThe graph that this code plots can be seen below.\nFederal funds rate: navigating two decades of monetary policy\nNow that we’ve retrieved and plotted the data, let’s analyze the key trends and events visible in our graph:\n\n\n\n\nKey observations from our initial data exploration of the federal funds rate:\nCyclical nature: The federal funds rate exhibits clear cyclical patterns over the 20-year period, reflecting the economic cycles and the Federal Reserve’s monetary policy responses.\nPre-2008 financial crisis: From 2004 to 2006, we observe a steady increase in the rate, peaking at around 5.25% in 2006–2007. This period of rising rates was likely in response to a growing economy and inflationary pressures.\n2008 financial crisis: The rate drops dramatically starting in 2007 and accelerates in 2008, coinciding with the Global Financial Crisis. The Fed rapidly cut rates to near zero in an attempt to stimulate the economy.\nExtended low-rate environment: From 2009 to 2015, we see an unprecedented period of near-zero interest rates, often referred to as the “zero lower bound” era. This reflects the Fed’s aggressive monetary policy to support economic recovery post-crisis.\nGradual normalization: Starting in late 2015, there’s a gradual increase in rates as the Fed began to normalize monetary policy in response to improving economic conditions.\nCOVID-19 pandemic impact: In early 2020, we observe another sharp drop to near-zero rates, mirroring the Fed’s emergency response to the economic shock of the COVID-19 pandemic.\nRecent rapid increase: From 2022 to 2023, we see a steep and rapid increase in rates, reaching levels not seen since before the 2008 crisis. This reflects the Fed’s aggressive tightening to combat high inflation.\n\n\n\n\nThese observations set the stage for our deeper analysis of how federal funds rate changes interact with other key indicators and influence credit risk. Next, we’ll retrieve Treasury yields and corporate bond rates.\nRetrieving 10-year Treasury rate data with AI assistance\nIn this section, we’ll focus on retrieving historical data for 10-year US Treasury yields, a key indicator in financial markets. The 10-year Treasury yield is often used as a benchmark for other interest rates and is crucial for understanding broader economic trends.\nWe’ll use the FRED API to fetch 20 years of daily data, giving us a comprehensive view of long-term interest rate movements.\nLet’s start by prompting the AI to write our data retrieval and visualization code. Here’s the prompt we’ll use:\n\nAI Prompt\nWrite Python code to retrieve the last 20 years of 10-year Treasury yields data using the FRED API. Please include the following steps:\n1. Import necessary libraries (if not already imported)\n2. Use the existing FRED API connection (assuming it’s already set up)\n3. Retrieve the 10-year Treasury yields data (series ID: DGS10) for the last 20 years\n4. Convert the data to a pandas DataFrame\n5. Display the first few rows of the DataFrame\n6. Plot the 10-year Treasury yields over time using matplotlib\nNote: Include comments explaining each step of the process.\n\n\n\n\n\nHere’s the code the AI might generate:\n# Import necessary libraries (if not already imported)\nimport pandas as pd\nfrom fredapi import Fred\nimport matplotlib.pyplot as plt\nfrom datetime import datetime, timedelta\nimport os\n\n# Use the existing FRED API connection\nfred = Fred(api_key=os.environ['FRED_API_KEY'])\n\n# Calculate the date 20 years ago from today\nend_date = datetime.now()\nstart_date = end_date - timedelta(days=20*365)\n\n# Retrieve the 10-year Treasury yields data (series ID: DGS10) for the last 20 years\ntreasury_10y_data = fred.get_series('DGS10', start_date, end_date)\n\n# Convert the data to a pandas DataFrame\ntreasury_10y_df = pd.DataFrame(treasury_10y_data, columns=['Yield'])\ntreasury_10y_df.index.name = 'Date'\n\n# Display the first few rows of the DataFrame\nprint(treasury_10y_df.head())\n\n# Plot the 10-year Treasury yields over time\nplt.figure(figsize=(12, 6))\nplt.plot(treasury_10y_df.index, treasury_10y_df['Yield'])\nplt.title('10-Year Treasury Yields (Last 20 Years)')\nplt.xlabel('Date')\nplt.ylabel('Yield (%)')\nplt.grid(True)\nplt.show()\n      \n      Open Datalore Code\n\n\n\n\n\nNow, let’s take a look at the plot of 20 years of long-term Treasury data.\n10-year Treasury yields: two decades of fluctuations\n\n\n\n\nNow that we’ve retrieved and plotted the data, let’s analyze the key trends and events visible in our graph:\n2008 financial crisis impact: There’s a sharp decline in yields starting in late 2007 and accelerating through 2008, mirroring the flight to safety during the financial crisis, though less dramatic than the federal funds rate drop.\nPost-crisis volatility and recovery: After the initial drop, yields showed significant volatility between 2009 and 2012, followed by a gradual increase until 2018, reflecting the uncertain economic recovery and the effects of changing monetary policies.\nCOVID-19 pandemic shock: In early 2020, we observe a dramatic plunge in yields to historic lows below 1%, coinciding with the economic shock of the COVID-19 pandemic and aggressive Fed intervention.\nRecent rapid increase: From 2021 onwards, there’s a sharp upward trend in yields, reaching levels not seen since before the 2008 crisis, aligning with rising inflation concerns and the Fed’s tightening monetary policy.\n\n\n\n\nThese observations provide crucial context for understanding how both short-term and longer-term interest rates have behaved in response to economic conditions and policy changes over the past two decades. As we proceed, we’ll explore how these rate movements interact to shape the overall yield curve and influence credit risk in the market.\nRetrieving corporate bond yields with AI assistance\nHaving examined the 10-year Treasury yields, we now turn to corporate bond yields, which provide insights into borrowing costs for corporations and serve as a key component in our credit risk analysis. We’ll use the ICE BofA US Corporate Index Effective Yield as our benchmark, offering a broad measure of US dollar-denominated investment-grade corporate debt performance.\nLet’s use Datalore’s AI assistance to generate code that retrieves and visualizes 20 years of daily data from the FRED API. Here’s the prompt:\n\nAI Prompt\nWrite Python code to retrieve the last 20 years of corporate bond yield data using the FRED API. Please include the following steps:\n1. Use the existing FRED API connection\n2. Retrieve the ICE BofA US Corporate Index Effective Yield data (series ID: BAMLC0A0CMEY) for the last 20 years\n3. Convert the data to a pandas DataFrame\n4. Handle any missing values appropriately\n5. Display the first few rows of the DataFrame\n6. Plot the corporate bond yields over time using matplotlib\nNote: Include comments explaining each step of the process.\n\n\n\n\n\nMy Datalore AI Assistant produced this code:\n# Use the existing FRED API connection\n# Assuming fred is already defined and the API key is set up as an environment variable\n\n# Calculate the date 20 years ago from today\nend_date = datetime.now()\nstart_date = end_date - timedelta(days=20*365)\n\n# Retrieve the ICE BofA US Corporate Index Effective Yield data (series ID: BAMLC0A0CMEY) for the last 20 years\ncorporate_yield_data = fred.get_series('BAMLC0A0CMEY', start_date, end_date)\n\n# Convert the data to a pandas DataFrame\ncorporate_yield_df = pd.DataFrame(corporate_yield_data, columns=['Yield'])\ncorporate_yield_df.index.name = 'Date'\n\n# Handle missing values by forward filling (using the last known value)\ncorporate_yield_df = corporate_yield_df.fillna(method='ffill')\n\n# Display the first few rows of the DataFrame\nprint(corporate_yield_df.head())\n\n# Plot the corporate bond yields over time\nplt.figure(figsize=(12, 6))\nplt.plot(corporate_yield_df.index, corporate_yield_df['Yield'])\nplt.title('ICE BofA US Corporate Index Effective Yield (Last 20 Years)')\nplt.xlabel('Date')\nplt.ylabel('Yield (%)')\nplt.grid(True)\nplt.show()\n      \n      Open Datalore Code\n\n\n\n\n\nIn the next section, we will analyze the results of this code block.\nCorporate bond yields: two decades of risk and reward\n\n\n\n\nNow that we’ve retrieved and plotted the data, let’s analyze the key trends and events in corporate bond yields over the past 20 years:\n2008 financial crisis spike: The most dramatic feature of the graph is the sharp spike in yields during the 2008 financial crisis, reaching a peak of over 9%. This reflects the extreme risk aversion and liquidity concerns in the corporate bond market during this period.\nPre-crisis build-up: Leading up to the 2008 crisis, we observe a gradual increase in yields from 2004 to 2007, possibly indicating growing concerns about credit risk in the years preceding the financial crisis.\nPost-crisis decline and stabilization: Following the 2008 peak, yields declined rapidly and then stabilized, fluctuating between 3% and 4% for much of the period from 2010 to 2019. This reflects the impact of the Fed’s accommodative monetary policy and a general improvement in economic conditions.\nCOVID-19 pandemic impact: In early 2020, we see another significant, though less extreme, spike in yields coinciding with the onset of the COVID-19 pandemic. This spike was quickly reversed, likely due to swift central bank intervention.\nRecent upward trend: From 2021 onwards, we observe an upward trend in yields, reaching levels not seen since before the 2008 crisis. This aligns with rising inflation concerns and tightening monetary policy, reflecting increased borrowing costs for corporations.\n\n\n\n\nThese observations provide valuable insights into how corporate borrowing costs and perceived credit risk have evolved over the past two decades. In the next section, we’ll explore how these corporate bond yields interact with the federal funds rate and Treasury yields to shape the overall credit risk landscape.\nFed Funds Rate vs. 10-year Treasury yield and spread analysis\nAfter examining the federal funds rate and 10-year Treasury yields individually, we now turn our attention to the relationship between these two crucial indicators. The spread between these rates, often referred to as the yield curve slope, provides valuable insights into economic expectations and potential credit risk.\nThe yield curve spread is calculated as follows:\nYield Curve Spread = 10-Year Treasury Yield - Federal Funds Rate\nA positive spread indicates a “normal” yield curve, generally associated with economic growth expectations. Conversely, a negative spread signals an inverted yield curve, which is often seen as a predictor of economic downturns.\nLet’s use AI assistance to create a comprehensive line chart visualization that tracks these key elements. Here’s the prompt for the AI:\n\nAI Prompt\nPlot monthly Fed Funds Rate, Corporate Bond Yields, and their spread:\n1. Use ‘fed_funds_data’ for Fed Funds Rate\n2. Retrieve Corporate Bond Yield data (BAMLC0A0CMEY) from FRED\n3. Resample both to monthly frequency and align to common date range\n4. Calculate spread (Corporate Bond Yield minus Fed Funds Rate)\n5. Remove NaN values\n6. Plot all three lines with different colors\n7. Include legend, title, axis labels, and red dashed line at y=0\n8. Show summary statistics\n\n\n\n\n\nYour AI assistant should produce code that looks something like this:\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Resample both series to monthly frequency and align them\nfed_funds_monthly = fed_funds_data.resample('M').last()\ntreasury_10y_monthly = treasury_10y_data.resample('M').last()\n\n# Create a DataFrame with both series, using the common date range\nstart_date = max(fed_funds_monthly.index.min(), treasury_10y_monthly.index.min())\nend_date = min(fed_funds_monthly.index.max(), treasury_10y_monthly.index.max())\n\ndf = pd.DataFrame({\n    'Fed Funds Rate': fed_funds_monthly[start_date:end_date],\n    '10-Year Treasury Yield': treasury_10y_monthly[start_date:end_date]\n})\n\n# Calculate the spread\ndf['Spread'] = df['10-Year Treasury Yield'] - df['Fed Funds Rate']\n\n# Remove any rows with NaN values\ndf = df.dropna()\n\n# Plot the data\nplt.figure(figsize=(12, 6))\nplt.plot(df.index, df['Fed Funds Rate'], label='Fed Funds Rate', color='blue')\nplt.plot(df.index, df['10-Year Treasury Yield'], label='10-Year Treasury Yield', color='orange')\nplt.plot(df.index, df['Spread'], label='Spread', color='green')\n\nplt.title('Fed Funds Rate vs 10-Year Treasury Yield and Spread')\nplt.xlabel('Date')\nplt.ylabel('Rate (%)')\nplt.legend()\nplt.grid(True)\n\n# Add horizontal line at y=0\nplt.axhline(y=0, color='r', linestyle='--')\n\nplt.show()\n\n# Print some summary statistics\nprint(\"\\nSummary Statistics:\")\nprint(df.describe())\n      \n      Open Datalore Code\n\n\n\n\n\nIn the next section, we will dive into the plotted results of this code to draw some conclusions about the economy over time.\nInterpreting yield curve dynamics\n\n\n\n\nNow that we’ve visualized the data, let’s analyze the key trends and events in yield curve dynamics:\nPre-2008 inversion: Leading up to the 2008 financial crisis, we observe a period of yield curve inversion (negative spread), with the fed funds rate exceeding the 10-year Treasury yield. This inversion is often seen as a predictor of economic recessions. In this particular case, the yield curve inversion was an accurate leading indicator.\nPost-crisis widening: Following the 2008 crisis, we see a significant widening of the spread as the Fed Funds Rate dropped dramatically while the 10-year Treasury Yield declined more gradually. This wide spread reflects the Fed’s aggressive monetary easing and attempts to stimulate long-term borrowing and investment.\nExtended period of positive spread: From 2009 to 2019, the spread remained consistently positive, with long-term rates higher than short-term rates. This “normal” yield curve is generally associated with expectations of economic growth.\nRecent inversions: We observe two notable periods of inversion in recent years – a brief inversion in 2019 and a more pronounced one starting in 2022. These inversions coincide with economic uncertainties, including trade tensions and inflation concerns.\nPandemic impact and recovery: The spread widened sharply at the onset of the COVID-19 pandemic in 2020 as the Fed cut rates to near zero. Subsequently, we see a rapid narrowing and eventual inversion as the Fed aggressively raised rates to combat inflation. As of our analysis in 2024, we are currently experiencing an inverted yield curve, with short-term rates higher than long-term rates. Historically, such inversions have often preceded economic recessions, suggesting the possibility of an economic downturn in the coming years. However, it’s important to note that while yield curve inversions have been reliable predictors in the past, economic conditions can vary, and past performance doesn’t guarantee future outcomes.\n\n\n\n\nThese yield curve dynamics provide crucial context for understanding market expectations and potential economic turning points. The current inversion underscores the importance of monitoring these indicators closely in the coming months and years.\n10-year Treasury yield vs. corporate bond yields analysis\nIn this section, we’ll explore a crucial relationship in fixed-income markets: the comparison between 10-year Treasury yields and corporate bond yields. This analysis is fundamental to understanding credit risk in the economy.\nThe spread between these yields, known as the credit spread, is calculated as:\nCredit Spread = Corporate Bond Yield - 10-Year Treasury Yield\nThis spread represents the additional return investors demand for taking on the risk of lending to corporations rather than the US government. A widening spread typically indicates increased perceived risk, while a narrowing spread suggests improving conditions or increased risk appetite.\nLet’s use AI assistance to create a visualization that includes:\nThe 10-year Treasury yield.\nThe corporate bond yield (using the ICE BofA US Corporate Index Effective Yield as a proxy).\nThe spread between these rates.\n\n\n\n\nHere’s the prompt for the AI:\n\nAI Prompt\nPlot monthly 10-Year Treasury Yield, Corporate Bond Yields, and their spread:\n1. Use ‘treasury_10y_data’ for 10-Year Treasury Yield\n2. Retrieve Corporate Bond Yield data (BAMLC0A0CMEY) from FRED\n3. Resample both to monthly frequency and align to common date range\n4. Calculate spread (Corporate Bond Yield minus 10-Year Treasury Yield)\n5. Remove NaN values\n6. Plot all three lines with different colors\n7. Include legend, title, axis labels, and red dashed line at y=0\n8. Show summary statistics\n\n\n\n\n\nThe code output should look like this:\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom fredapi import Fred\nimport os\nfrom datetime import datetime, timedelta\n\n# Use the existing FRED API connection\nfred = Fred(api_key=os.environ['FRED_API_KEY'])\n\n# Calculate the date range\nend_date = datetime.now()\nstart_date = end_date - timedelta(days=20*365)\n\n# Retrieve the corporate bond yield data\ncorporate_yield_data = fred.get_series('BAMLC0A0CMEY', start_date, end_date)\n\n# Resample both series to monthly frequency\ntreasury_10y_monthly = treasury_10y_data.resample('M').last()\ncorporate_yield_monthly = corporate_yield_data.resample('M').last()\n\n# Create a DataFrame with both series, using the common date range\nstart_date = max(treasury_10y_monthly.index.min(), corporate_yield_monthly.index.min())\nend_date = min(treasury_10y_monthly.index.max(), corporate_yield_monthly.index.max())\n\ndf = pd.DataFrame({\n    '10-Year Treasury Yield': treasury_10y_monthly[start_date:end_date],\n    'Corporate Bond Yield': corporate_yield_monthly[start_date:end_date]\n})\n\n# Calculate the spread\ndf['Spread'] = df['Corporate Bond Yield'] - df['10-Year Treasury Yield']\n\n# Remove any rows with NaN values\ndf = df.dropna()\n\n# Plot the data\nplt.figure(figsize=(12, 6))\nplt.plot(df.index, df['10-Year Treasury Yield'], label='10-Year Treasury Yield', color='blue')\nplt.plot(df.index, df['Corporate Bond Yield'], label='Corporate Bond Yield', color='orange')\nplt.plot(df.index, df['Spread'], label='Spread', color='green')\n\nplt.title('10-Year Treasury Yield vs Corporate Bond Yield and Spread')\nplt.xlabel('Date')\nplt.ylabel('Rate (%)')\nplt.legend()\nplt.grid(True)\n\n# Add horizontal line at y=0\nplt.axhline(y=0, color='r', linestyle='--')\n\nplt.show()\n\n# Print some summary statistics\nprint(\"\\nSummary Statistics:\")\nprint(df.describe())\n      \n      Open Datalore Code\n\n\n\n\n\nNow, let’s dive into the results of this analysis in the next section.\nInterpreting credit spread dynamics\n\n\n\n\nNow that we’ve visualized the data, let’s analyze the key trends in credit spread dynamics:\n2008 financial crisis impact: The most striking feature of the graph is the dramatic widening of the spread during the 2008 financial crisis. This spike reflects a severe increase in perceived credit risk as investors fled to the safety of government bonds, demanding much higher yields for corporate debt.\nPre-crisis build-up: In the years leading up to the 2008 crisis, we observe a gradual narrowing of the spread, suggesting increasing investor comfort with corporate credit risk. This trend reversed sharply with the onset of the crisis.\nPost-crisis normalization: Following the crisis, the spread gradually narrowed but largely remained elevated compared to pre-crisis levels for several years, indicating a more cautious approach to credit risk in the aftermath of the financial turmoil.\nCOVID-19 pandemic spike: In early 2020, we see another significant, though less extreme, widening of the spread coinciding with the onset of the COVID-19 pandemic. This reflects the sudden increase in perceived corporate credit risk due to economic uncertainties.\nRecent trends: Since the pandemic spike, the spread has narrowed but remains above pre-pandemic levels, suggesting that while credit risk perceptions have improved, investors still maintain a degree of caution in the current economic environment.\n\n\n\n\nThese credit spread dynamics provide crucial insights for investors and policymakers. A widening spread often signals increasing economic stress and may precede broader market downturns. Conversely, a narrowing spread typically indicates improving conditions and increased confidence in corporate debt.\nHowever, it’s important to consider credit spreads alongside other economic indicators for a comprehensive view of market conditions and credit risk. In the next section, we’ll explore how these insights can be applied to predictive analysis and risk management strategies.\nCongratulations! You’ve made it this far into our tutorial. Want more? Read on to explore the relationship between yield curve changes and credit spreads.\n[Advanced] Yield curve changes and credit spreads\nIn this section, we’ll explore the predictive relationship between yield curve changes and credit spreads. This analysis is crucial for understanding how changes in interest rates might signal future shifts in credit risk.\nWe’ll focus on two key questions:\nDo changes in the yield curve precede changes in credit spreads?\nHave yield curve inversions historically led to widening credit spreads?\n\n\n\n\nLet’s use AI assistance to create a comprehensive Python script that analyzes these relationships:\n\nAI Prompt\nCreate a Python script to analyze yield curve slopes and credit spread changes:\n1. Use FRED API for 40 years of:\n– Federal funds rate\n– 10-year Treasury yield\n– Corporate bond yield\n2. Calculate:\n– Yield curve slope\n– Credit spread\n– Identify inversions\n3. Analyze periods: 1, 7, 14, 30, 60, 90, 180, 270, 365, 547, 730, 1095 days\nFor each:\n– Compute forward credit spread changes\n– Calculate correlations and mean changes (normal/inverted periods)\n– Perform t-tests (normal vs inverted)\n4. Store results in DataFrame\n5. Plot:\n– Correlation vs forward period\n– Mean changes vs forward period\n6. Print results\n\n\n\n\n\nTo check the resulting code, go to Datalore:\n      \n      Open Datalore Code\n\n\n\n\n\nLet’s delve deeper into the relationship between yield curve slopes and future changes in credit spreads. Our goal is to understand how yield curve inversions might predict future spikes in credit risk and, by extension, potential economic downturns.\nMethodology:\nWe analyzed the correlation between the yield curve slope (10-year Treasury yield minus fed funds rate) and forward changes in credit spreads (corporate bond yield minus 10-year Treasury yield) for various future time periods, ranging from 1 day to 3 years (1,095 days).\nAnalysis of correlation between yield curve slope and forward credit spread change\nKey observations:\nShort-term correlations (1–90 days): We observe weak negative correlations, suggesting limited predictive power in the immediate future.\nMedium-term correlations (180–547 days): There’s a stronger negative relationship, with the peak negative correlation occurring around the 547-day mark. This indicates that yield curve inversions tend to precede credit spread widening most reliably in this time frame.\nLong-term correlation (1,095 days): Interestingly, the correlation turns positive, suggesting a potential reversal or cyclical nature of the relationship over very long periods.\n\n\n\n\nImplications:\nThe strongest predictive power of yield curve inversions for credit spread widening appears to be in the 1–2 year range.\nThis aligns with the common observation that recessions often follow yield curve inversions by 12–24 months.\nThe positive correlation at 1,095 days warrants further investigation and could relate to long-term economic cycles.\n\n\n\n\nAnalysis of mean forward credit spread change\n\n\n\n\nThis graph illustrates the average change in credit spreads over various future time periods, comparing normal yield curve periods (blue line) to inverted yield curve periods (orange line).\nKey observations:\nNormal yield curve periods (blue line):\n\nThe line remains relatively flat and close to zero across all time periods.\nThere’s a slight dip into negative territory for medium-term periods (180–547 days), suggesting a tendency for mild credit improvement during normal economic conditions.\nLong-term periods (730–1,095 days) show a small positive change, indicating a slight widening of credit spreads over extended time frames.\nInverted yield curve periods (orange line):\n\nShort-term periods (1–90 days) show small positive changes, indicating slight immediate credit deterioration following inversions.\nMedium-term periods (180–547 days) exhibit large positive changes, peaking around the 547-day mark. This suggests significant credit spread widening in the 1–2 year period following yield curve inversions.\nLong-term periods (730–1,095 days) show a dramatic reversal, with the 1,095-day point dropping into negative territory. This indicates a potential improvement in credit conditions or a cyclical effect over very long time frames.\nComparison between normal and inverted periods:\n\nThe divergence between the two lines is most pronounced in the medium-term range (180–547 days), highlighting the predictive power of yield curve inversions for credit spread changes in this timeframe.\nThe convergence and eventual crossover of the lines in the long term (1,095 days) is particularly interesting, suggesting a potential “mean reversion” effect over extended periods.\n\n\n\n\nImplications:\nTiming of credit risk: The peak in the inverted line around 547 days suggests that the greatest credit risk following a yield curve inversion typically manifests between 1.5 to 2 years after the inversion occurs.\nMagnitude of impact: The large gap between normal and inverted lines in the medium term indicates that yield curve inversions precede significantly larger credit spread widenings compared to normal periods.\nRisk management strategies: Financial institutions and investors might consider implementing more conservative credit policies or increasing hedges against credit risk in the 1–2 year period following yield curve inversions.\nEconomic cycle insights: The reversal seen at 1,095 days could indicate the typical length of a credit cycle or the delayed effects of policy interventions following economic stress periods.\nPredictive power: This graph reinforces the idea that yield curve inversions can serve as early warning indicators for increased credit risk, with a lead time of approximately 1–2 years.\n\n\n\n\nWhile these patterns offer guidance, they should not be treated as infallible predictors. Economic conditions can vary, and past patterns may not always repeat in the same way. Nonetheless, this analysis offers a framework for understanding the relationship between yield curve dynamics and future credit risk, providing a valuable tool for economic forecasting and risk management.\n[Advanced] Credit spread analysis with economic events: a 90-day forward look\nIn this final section, we’ll explore the dynamic relationship between credit spreads and major economic events, focusing on a 90-day forward-looking perspective. This analysis provides crucial insights into how credit risk perceptions evolve over relatively short periods, offering a window into market sentiment and economic conditions.\nWe’ll use AI assistance to create a comprehensive Python script that combines data manipulation, statistical analysis, and advanced visualization techniques. Our analysis will:\nCalculate 90-day forward changes in credit spreads.\nIdentify and visualize outliers in credit spread changes.\nMap these changes to significant economic events from 2001 to 2020.\nCompare credit spread behavior during normal and inverted yield curve periods.\nConduct statistical tests to validate our observations.\n\n\n\n\nLet’s prompt the AI to help us create this analysis:\n\nAI Prompt\nCreate a Python script to analyze and visualize 90-day forward credit spread changes in relation to major economic events:\n1. Use existing DataFrame ‘df’ with credit spread data\n2. Calculate 90-day forward change in credit spreads: diff(periods=90).shift(-90)\n3. Identify outliers using IQR method\n4. Create a time series plot:\n– X-axis: Date (show every 5 years)\n– Y-axis: 90-day forward change in credit spread\n– Plot main line for spread changes\n– Highlight outliers as red scatter points\n5. Add vertical lines for economic events (2001-2020):\n– Enron Bankruptcy, WorldCom Bankruptcy, Lehman Brothers Bankruptcy\n– European Debt Crisis, 2019 Repo Spike, COVID-19 Pandemic Declaration\n6. Customize plot: large fonts, clear labels, grid, legend\n7. Print summary statistics:\n– Number and percentage of outliers\n– Top 10 positive and negative outliers\n– Mean spread change for normal and inverted yield curve periods\n8. Perform t-test comparing normal and inverted periods\nUse pandas for data manipulation, matplotlib for plotting, seaborn for styling, and scipy.stats for the t-test. Ensure the script is well-commented and follows Python best practices.\n\n\n\n\n\nTo check the generated code, go to Datalore:\n      \n      Open Datalore Code\n\n\n\n\n\nLet’s dive into the results of this code and get a unique look at the history of the United States through the lens of credit spread changes.\n\n\n\n\nNow that we’ve visualized the data and generated our statistics, let’s analyze the key trends and events:\nVolatility clusters: The graph reveals distinct periods of high volatility in credit spread changes, particularly around major economic events. This clustering of volatility suggests that credit risk perceptions can change rapidly and dramatically during times of economic uncertainty.\nAsymmetric outliers: We observe that the most extreme outliers (red dots) tend to be on the positive side, indicating sudden, large increases in credit spreads. This asymmetry suggests that credit risk can spike more sharply than it tends to decrease, reflecting the market’s sensitivity to negative news.\nMajor economic events:\n\nDot-com bubble (2000–2002): We see increased volatility and some outliers, reflecting the tech market crash and subsequent economic uncertainty.\n2008 financial crisis: The most dramatic spike in our dataset occurs around the Lehman Brothers bankruptcy, with extreme positive outliers indicating a severe credit crunch.\nEuropean debt crisis (2011): Another cluster of outliers is visible, showing how international events can impact US credit markets.\nCOVID-19 pandemic (2020): A sharp spike in credit spread changes, rivaling the 2008 crisis in magnitude, demonstrates the immediate and severe impact of the pandemic on credit risk perceptions.\nRecovery patterns: Following each major spike, we observe periods of negative changes in credit spreads, indicating a gradual return to lower credit risk perceptions. However, the recovery patterns vary in duration and stability.\nRecent trends: In the years leading up to 2020, we see relatively stable credit spread changes with fewer outliers, possibly reflecting the prolonged period of low interest rates and economic growth. The COVID-19 pandemic disrupts this stability dramatically.\nFrequency of outliers: Outliers appear to be more frequent and extreme during recognized periods of economic stress, serving as a visual indicator of market turmoil.\n\n\n\n\nLimitations:\nWhile this 90-day forward view provides valuable insights, it doesn’t capture longer-term trends or very short-term fluctuations. The causes behind these changes can be complex and multifaceted, often requiring additional context to fully interpret.\nThis analysis offers a nuanced view of credit risk dynamics over the past two decades. It highlights the market’s sensitivity to major economic events and provides a valuable tool for anticipating potential shifts in credit risk perceptions.\nConclusion: applying your new credit risk analysis skills\nCongratulations on completing this comprehensive tutorial on credit risk analysis using Python and AI-assisted coding in Datalore! Let’s recap what you’ve learned and how you can apply these skills in your own financial analyses:\nKey skills acquired\nData retrieval and preprocessing: You’ve learned how to use the FRED API to fetch economic data and prepare it for analysis using pandas.\nVisualization techniques: You’ve created various plots to visualize federal funds rates, Treasury yields, and corporate bond yields, enhancing your data presentation skills.\nYield curve analysis: You’ve explored how to calculate and interpret yield curve slopes and inversions, crucial indicators for economic forecasting.\nCredit spread calculation: You’ve computed and analyzed credit spreads, gaining insights into market risk perception.\nPredictive analysis: You’ve conducted forward-looking analyses to understand the relationship between yield curve changes and future credit spread movements.\nEvent impact assessment: You’ve examined how major economic events affect credit spreads, developing skills in contextual data interpretation.\nAI-assisted coding: Throughout the tutorial, you’ve leveraged AI to generate code, demonstrating how to use this powerful tool to streamline your workflow.\n\n\n\n\nApplying your skills\nCustom analyses: Use the code templates provided to analyze different time periods or other economic indicators that interest you.\nRisk management: Apply the yield curve inversion and credit spread analysis techniques to assess potential risks in your investment portfolio.\nEconomic forecasting: Utilize the predictive analysis methods to create your own forecasts for credit risk and economic conditions.\nData-driven decision making: Incorporate these data analysis techniques into your financial decision-making processes, whether for personal investments or professional applications.\nContinuous learning: As you’ve seen, economic conditions evolve. Use the skills you’ve learned to stay updated on market trends and continually refine your analysis techniques.\n\n\n\n\nNext steps\nExpand your dataset: Try incorporating additional economic indicators or international data to broaden your analysis.\nEnhance your models: Experiment with more advanced statistical methods or machine learning techniques to improve predictive power.\nAutomate your analyses: Create scripts that automatically update your analyses as new data becomes available with Datalore’s Scheduled runs feature.\nCollaborate and share: Use Datalore’s collaboration features to work with others and share your insights.\n\n\n\n\nWhile these tools and techniques are powerful, they should be used in conjunction with a nuanced understanding of economic principles and current market conditions. Stay curious, keep practicing, and continue to refine your credit risk analysis skills!\nIf you’d like to edit the full code of this tutorial in Datalore, including interactive elements and additional resources, click the button below:\n      \n      Open Datalore Code",
        "dc:creator": "Alena Guzharina",
        "content": "This is a guest blog post by Ryan O’Connell, CFA, FRM. Understanding the relationships between various economic indicators is crucial for navigating the financial landscape. These relationships significantly impact the overall state of the economy, affecting businesses, investors, and individuals alike. We&#8217;ll analyze data spanning over two decades of financial history, leveraging the power of [&#8230;]",
        "contentSnippet": "This is a guest blog post by Ryan O’Connell, CFA, FRM. Understanding the relationships between various economic indicators is crucial for navigating the financial landscape. These relationships significantly impact the overall state of the economy, affecting businesses, investors, and individuals alike. We’ll analyze data spanning over two decades of financial history, leveraging the power of […]",
        "guid": "https://blog.jetbrains.com/?post_type=datalore&p=505317",
        "categories": [
          "datalore-ai",
          "python-for-finance"
        ],
        "isoDate": "2024-08-26T14:34:49.000Z"
      }
    ]
  },
  {
    "name": "Airbnb Engineering & Data Science",
    "category": "기업",
    "posts": [
      {
        "creator": "Leo Wong",
        "title": "Building Postcards for “Airbnb” Scale",
        "link": "https://medium.com/airbnb-engineering/building-postcards-for-airbnb-scale-dfe0b71b12ec?source=rss----53c7c27702d5---4",
        "pubDate": "Wed, 28 Aug 2024 16:01:39 GMT",
        "content:encodedSnippet": "By: Leo Wong, Henry Johnson\nHow the Airbnb Media team built group travel Postcards for the 2024 Summer Release by leveraging a novel destination matching algorithm while advancing the platform’s image & localized text processing capabilities.\nAirbnb Postcards (see announcement).\nIntroduction\nFor Airbnb’s 2024 Summer Release, the Media Ingestion team at Airbnb took on the exciting challenge of creating a reliable postcard generation system to generate unique, hand-crafted Postcards. Postcards are a beautiful way to invite guests on a trip while keeping friends and family in the loop (see announcement). This feature required a novel solution to match relevant postcards to every possible destination that guests booked on Airbnb. It needed to render performantly not only on all our client platforms (iOS, Android, and Web), but also on different messaging platforms outside the Airbnb app, all while maintaining Airbnb’s high design standards.\nChallenges\n\nLocalized Text Layout: Postcards have strict design guidelines around character count per line, font leading & kerning per language, pixel perfect typography, line break rules, and language-specific styling.\nDesign & Product Flexibility: Text layout, color, fonts, text drop shadows and image transformations need to be flexible for product & design changes.\nDestination Matching: Postcards need to match the destination by including relevant artwork and localized destination names.\nAvailability On and Off Platform: Assets need to be surfaced on and off the platform, which necessitated a pre-generated server-side solution; client-only solutions wouldn’t work since we needed Open Graph compatible links for assets to render properly in iMessage and Instagram, for example.\nPerformance: Postcard presentation shouldn’t interrupt the product UX by taking significant time to render.\nPostcards “in vs. out” of product experience\nSolution\nPostcard Setup\nA Trips Postcard is the combination of (1) an artwork illustration, (2) a postcard template, and (3) a localized destination. A Postcard “template” is a data entity with a reference to the artwork illustration plus some additional metadata to describe how to render it. To render a Postcard in product, we need to have all artwork illustrations, postcard templates, and formatted localized destinations set up before a visitor sees the product flow.\nIn the example below, we have an illustration of a cliff side, a postcard template, and an English destination name of “Galway”. The Postcard template includes parameters to specify how to create the postcard, like text and Belo (Airbnb brand icon) color and positioning. In the example, the text and Belo are rendered in gray color and positioned at the bottom and top left, respectively.\nIllustration + Template Params + Localized Destination = Postcard\nDesign Flexibility — Postcard Templates\nTo accommodate changing design requirements, we built a flexible template data model that empowers our design team to configure various parameters like text positioning and text color while iterating on the designs. The postcard templates include all the metadata required to generate a Postcard and its surrounding presentation elements. It also includes a versioning capability so that we can publish changes to all users with a version bump whenever we have a design revision or visual defect.\nTemplate & Artwork Upload, Management & Preview\nTo make it easy for the creative team to self-serve and debug issues, we built a web-based internal tool for creating and managing templates, previewing postcards, and uploading artwork. This tool made it significantly easier to manage templates, and was especially useful during the team’s peak iteration period where we were constantly fixing bugs and changing designs.\nThe postcard template creation & management formIn the setup workflow, our operations team created Postcard templates, uploaded artwork, and managed them via the template form page.\nLocalized Text Layout\nWe wanted accurate translations of destinations that were properly formatted for each localized postcard. A programmatic solution for localized text layout would require, at the very least, language specific rules (right to left, word wrapping, etc.), knowledge of cultural conventions, accessibility considerations, and text rendering for special characters (diacritics, etc.). This would make business logic complex and brittle.\nWe compromised on this solution with the localization (l10n) team by manually formatting translations for destinations that made up our top booking destinations. These manually formatted translations involved getting our l10n scaled operations team to translate and format (line breaks, layout spacing, etc.) a shortlist of localized destinations, which we helped ingest into our typical i18n platform translated text workflow with some scripting. After ingestion, the Postcard generation system pulls from our i18n platform to get the desired localized formatted text layout for each Postcard.\nThe destinations shortlist was informed by our data science team, who helped gather the top booked destinations by language. This reduced the scale of required postcards to generate from all destinations in the full set of language locale destination combinations on the platform, to a magnitude of scale smaller destination subset. As a result, postcard QA was significantly easier. More importantly, it kept the overall system code and maintenance simple; no need for thousands of lines of language specific business logic!\nThe rest of the postcards that didn’t make the top destinations list followed a simple formula of word count and line breaks per language (e.g. Chinese, Korean, and Japanese had smaller word count limits because of the character size and no line break on spaces because it changes the meaning of the destination).\nEarly design prototype of text layout in a subset of the languages we support at Airbnb. The screenshot is for illustration purposes only.\nPostcard Generation\nDestination Matching\nDecision tree for determining the best postcard template for a given reservation\nTo find the best-matching postcard template for each destination, we have a matching algorithm that matches templates to reservations at booking time using four different criteria:\n\nBy listing — We wanted to be able to support listing-specific artwork. E.g. Our Icons listings show a golden ticket to commemorate the special moment when a guest wins the lottery for staying at an Icons listing.\nBy destination — For popular destinations (matching by city and country), we have curated artwork that showcases both a local artist and the destination. E.g. Trips to Santorini present the iconic Cycladic domes of Santorini as artwork (see diagram below).\nBy taxonomy — For all other artwork, we match destinations based on a set of taxonomy tags. We partnered with the knowledge graph team to apply taxonomy attributes to all of our listings in a few different categories: density (i.e. metropolitan, urban), climate (i.e. tropical, temperate) and geography (i.e. coastal, mountain, river). We ensured the taxonomy was accurate by cross referencing existing internal data and the expertise of our regional representatives teams. They then exposed an API that we called to fetch taxonomy by listing. On the operations side, our production team created taxonomy tagged artwork (e.g. an artwork tagged to be used for a coastal, temperate, metropolitan postcard). When generating postcards, we match the listing to the artwork with the highest number of overlapping tags.\nBy default — If a destination isn’t covered by the above categories, we show a fallback default artwork.\nThe 4 initial Postcard variants: Icons, Destination specific, Taxonomy, and Default.\nFormatted Translations\nWe take the listing of each booking request and fetch the city and country from the listing service and check to see if that destination was in our curated set of formatted destinations loaded into our i18n service. We then take the best fitting artwork and embed the localized destination text on it to generate the final postcard. If we don’t get a translation back, we fall back to serving the postcard without text.\nPerformance — Async Postcard Creation Flow\nPutting a localized destination and a Belo icon onto artwork is a time-consuming operation given the high resolution artwork we used. We knew the image processing flow could take over 8 seconds on average to process an image so we needed to come up with a way to make our postcard API respond quickly. We also wanted to transfer these generated postcards into our primary image storage so we could leverage our existing media serving infrastructure, which introduced an additional 1–2 seconds of latency.\nIn order to still be performant, we went with a partly asynchronous approach where, during the live in product request, we only serve postcards that we’ve already generated and stored internally. If there was a request for a new postcard, we would instead return a fallback postcard and publish an event to a Kafka queue where an async consumer would call the processing service, wait for the asset to be generated and then transfer it into our system to be used for future requests.\nAs shown in the diagram below, we fetched the listing information and taxonomy information in parallel before computing the best matching artwork for the trip. Based on a pattern in how the postcards are stored, we would check in our media service to see if the postcard was generated already before either returning the card if it was found or kicking off the asynchronous flow if it was not found. At that point, our media service’s Kafka consumer would complete the flow by transforming the asset into a postcard and storing it in our system.\nArchitecture Diagram of the Backend Postcard Generation flow\nPre-generation\nWe wanted to generate as many of the postcards as possible before the launch. If the postcard hasn’t been generated when a guest books a group trip, everyone on the booking will see the default, generic postcard. Our data science team helped determine top destinations, and we ran those inputs through our postcard generation pipeline to pre-generate as many postcards as possible and minimize the chance of falling back to a default postcard. Within a week of launching, more than 90% of trips had a custom postcard instead of a default and we inched closer to generating a postcard for all trips in the months after.\nDashboard numbers on Postcard template selection type and postcard usage hit rate. For illustrative purposes only, not real data.\nConclusion\nCreating postcards was a massive effort that required collaboration across multiple engineering, product, design, and data science teams to improve Airbnb’s group travel feature. Our frontline insights team continues to receive positive social media and external feedback on this update that adds delight to joining a group trip.\nThe solution highlights the importance of having the right internal tooling, image and text processing capabilities, and destination matching logic for solving something at Airbnb’s scale.\nPostcards is one of the first major image processing use cases that the Media team built to support a new Airbnb feature. It highlights the power of media capabilities and innovative features we can build with them. If you like the type of work we do at Airbnb, please contact us & check out our careers page!\nAcknowledgments\nThanks to the following engineers who helped to build this feature: Alan Wright, Aditya Punjani, Bill Lovotti, Jessica Chen, Miguel Jimenez\n\nBuilding Postcards for “Airbnb” Scale was originally published in The Airbnb Tech Blog on Medium, where people are continuing the conversation by highlighting and responding to this story.",
        "dc:creator": "Leo Wong",
        "guid": "https://medium.com/p/dfe0b71b12ec",
        "categories": [
          "front-end-development",
          "image-processing",
          "internationalization",
          "engineering",
          "media-processing"
        ],
        "isoDate": "2024-08-28T16:01:39.000Z"
      }
    ]
  },
  {
    "name": "Instagram Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "PayPal Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "article New updates to Planner comment notifications and settings in Planner Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Visual Studio Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Amy Nguyen",
        "title": "New GitHub Copilot features in Visual Studio 2022 17.11",
        "link": "https://devblogs.microsoft.com/visualstudio/new-github-copilot-features-in-visual-studio-2022-17-11/",
        "pubDate": "Thu, 29 Aug 2024 16:20:38 +0000",
        "content:encodedSnippet": "Visual Studio 2022 17.11 now brings exciting advancements from GitHub Copilot! This release significantly improves how GitHub Copilot integrates into your development workflow, offering smarter and more intuitive coding assistance.\nDiscover the new GitHub Copilot features in Visual Studio, such as enhanced context understanding, improved code completions, and AI insights for debugging and naming. These updates aim to boost your productivity and efficiency in coding. To try these new features, download the update, make sure to activate your GitHub Copilot account and check out the release notes for more detailed information.\nGitHub Copilot is getting smarter\nGitHub Copilot Chat now enables you to reference your complete solution, which allows you to gain an even deeper, holistic understanding of your solution to get better results! To reference your solution, simply use @workspace, and Copilot will respond to high-level questions regarding your solution, files, and their interactions.\n\nAdditionally, GitHub Copilot Enterprise users in Visual Studio can now use @GitHub to get answers enriched with context from their entire repository and Bing search results.\n\nNaming things made easy\nGitHub Copilot can now generate naming suggestions for your C++ identifiers (variables, methods, or classes) based on how your identifier is being used and the style of your code.\n\nTo try it out, you’ll need an active GitHub Copilot subscription. Navigate to any variable you wish to rename, right-click -> Rename (Keyboard: Ctrl+R, Ctrl+R). You’ll notice a GitHub Copilot sparkle icon that you can click or toggle to generate naming suggestions.\nAI-generated breakpoint expressions\nAI-generated expressions for conditional breakpoints and tracepoints are now supported in C++. GitHub Copilot analyzes your code and offers insightful breakpoint expressions, streamlining your debugging process.\n\nWhen you place the cursor in the condition text for a conditional breakpoint/tracepoint in the breakpoint settings window, GitHub Copilot will instantly generate AI-based expression suggestions tailored to your code. You can choose the condition that best suits your needs.\nUnderstand your symbols with GitHub Copilot\nWe’ve integrated GitHub Copilot into the tooltip on hover over symbols to provide AI-generated summaries of the selected symbol. This is available for both C# and C++ developers.\n\nThis feature assists developers in understanding descriptions of various symbols at different invocations within their codebase. By hovering over a symbol and selecting the ‘Tell me more’ option, GitHub Copilot can generate documentation for the selected symbol.\nRefine your GitHub Copilot suggestions\nIn Visual Studio 17.11, you can now refine code completions by adding context or asking questions without accepting them first. This update allows you to modify and retry GitHub Copilot’s suggestions before having to accept, saving you the hassle to accepting and refining again! Just press Alt+/ to modify, or if you’re happy with the suggestion, press tab to accept.\n\nGitHub Copilot is even more secure\nIntroducing GitHub Copilot Content Exclusion, a new feature that allows admins to Copilot to ignore specific files in a repository or organization, ensuring sensitive information is protected while using AI for efficient coding. This applies to Completions, Inline, Chat, for GitHub Copilot for Business and Enterprise users. Additionally, exclusions also apply to other non-chat features, like rename suggestions and hover text. Additionally, content exclusion works with repos on platforms other than GitHub, including Azure DevOps.\n\nWe hope you enjoy this update to Visual Studio and all the new developments happening within GitHub Copilot, and we look forward to hearing what you think. You can share feedback with us by using the thumbs up or down within the Chat, via Developer Community, by reporting issues via report a problem and share your suggestions for new features or improvements to existing ones.\nStay connected with the Visual Studio team by following us on Twitter, YouTube, and LinkedIn and on Microsoft Learn.\nThank you for using Visual Studio and happy coding!\nDownload Visual Studio 17.11\n\nThe post New GitHub Copilot features in Visual Studio 2022 17.11 appeared first on Visual Studio Blog.",
        "dc:creator": "Amy Nguyen",
        "content": "<p>Visual Studio 2022 17.11 now brings exciting advancements from GitHub Copilot! This release significantly improves how GitHub Copilot integrates into your development workflow, offering smarter and more intuitive coding assistance.<br />\nDiscover the new GitHub Copilot features in Visual Studio, such as enhanced context understanding,</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/new-github-copilot-features-in-visual-studio-2022-17-11/\">New GitHub Copilot features in Visual Studio 2022 17.11</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "Visual Studio 2022 17.11 now brings exciting advancements from GitHub Copilot! This release significantly improves how GitHub Copilot integrates into your development workflow, offering smarter and more intuitive coding assistance.\nThe post New GitHub Copilot features in Visual Studio 2022 17.11 appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=250390",
        "categories": [
          "Copilot",
          "Visual Studio",
          "GitHub Copilot",
          "Visual Studio 2022"
        ],
        "isoDate": "2024-08-29T16:20:38.000Z"
      },
      {
        "creator": "David Li",
        "title": "C++ Gaming Productivity Update for Visual Studio 2022 version 17.11",
        "link": "https://devblogs.microsoft.com/visualstudio/c-gaming-productivity-update-for-visual-studio-2022-version-17-11/",
        "pubDate": "Wed, 28 Aug 2024 10:00:20 +0000",
        "content:encodedSnippet": "Introduction\nIn Visual Studio 2022 version 17.11, you will find brand new productivity enhancements for your game development workflows. From faster conditional breakpoints to a swath of Unreal Engine enhancements, we have added various productivity boosters based on your feedback. Once again, thank you for sharing Developer Community feedback and answering our surveys. Your valuable feedback continues to drive the direction of the Visual Studio gaming team.\nGeneral C++ Game Development\nSupercharge Your IntelliSense Performance\nWe have received feedback from AAA developers about IntelliSense performance. While we have improved performance over the past releases, we understand that these performance improvements may be less impactful for large C++ projects.\nHere are some helpful tips to further boost the power for Visual Studio’s IntelliSense for developers with powerful hardware:\nEnsure 64-bit IntelliSense is activated.\n\n\nAdjust your memory limits (in MB) to reflect your hardware.\n\n\nFaster Conditional Breakpoints\nIn version 17.11, you will see a significant improvement in performance for conditional break points. Our initial assessment found that execution time is almost four times as fast, reducing execution time from 80 seconds to 21 seconds over 80,000 iterations.\nBuild Insights Quality of Life Improvements\nWe have added several quality-of-life enhancements to Build Insights. Starting in version 17.11, you can now group your results by project, view the relative path and file name in place of the full path, and see a better grouping of results in the Included Files view.\n\nUnreal Engine Integration\nAdding Unreal Engine Classes, Modules, and Plugins\nIn Visual Studio 2022 version 17.11, you can now add Unreal Engine class templates, modules, and plugins. These new productivity features are available for both vcxproj and uproject.\nTo get started, right-click on your project in Solution Explorer and select Add > Unreal Engine Item.\n\nIn the revamped Add New Item dialog, you can select several new choices.\n\nUnreal Engine Classes\nBased on your feedback, we have added additional Unreal Engine class templates. You can now find the common class templates in Visual Studio’s Add New Item dialog just as you would find in the Unreal Engine Editor. The new dialog provides a list of common Unreal Engine class templates that you can add to your project. You can also now add your class to a module of your choice.\n\nUnreal Engine Module\nYou can now also add an Empty Unreal Engine Module using the Add New Item dialog.\n\nUnreal Engine Plugin\nLastly, you can now add an Unreal Engine Plugin to your project through the Add New Item dialog.\n\nUnreal Engine Toolbar\nTo further streamline our integration with Unreal Engine, we have added the Unreal Engine toolbar in Visual Studio 2022 version 17.11. The toolbar contains new productivity features and shortcuts to existing integration.\n\nThe play icon and the dropdown work in tandem to quickly attach to processes while debugging. With the Unreal Editor running, you will see Unreal Engine related processes. Selecting one of the choices will allow you to easily attach to the process to start a debugging session. Additionally, you can type any process name to quickly attach to that process.\n\n\nThe start and stop button will control the Unreal Engine integration server, used for the Unreal Engine Test Adapter. The server runs as a background process that automatically updates your test information. If you have the Unreal Engine Test Adapter option active, the server will automatically start upon opening your UE project.\nThe Rescan Blueprints button will refresh your Unreal Engine Blueprint references.\nThe Unreal Engine Log button is a shortcut to open the Unreal Engine Log window, in case you close it accidentally.\nThe Configure Tools for Unreal Engine button is a shortcut to launch the Unreal Engine Integration Configuration window. The configuration page gives you an overview of the Unreal Engine Integration status and gives you help if certain integrations were not configured properly.\nBlueprints Update\nWe received feedback asking to improve the process of setting up Blueprint references in Unreal Projects. Starting in Visual Studio v17.10, you will no longer need the Unreal Engine Plugin “Visual Studio Integration Tool” to view Blueprint references. Blueprint references will automatically show up if you have the “Visual Studio Tools for Unreal Engine” component installed.\nSend us your feedback\nWe hope you enjoy this update to Visual Studio, and we look forward to hearing what you think. You can share feedback with us via Developer Community, by reporting issues via report a problem and share your suggestions for new features or improvements to existing ones.\nStay connected with the Visual Studio team by following us on Twitter, YouTube, LinkedIn, and on Microsoft Learn.\nThank you for using Visual Studio and happy coding!\nThe post C++ Gaming Productivity Update for Visual Studio 2022 version 17.11 appeared first on Visual Studio Blog.",
        "dc:creator": "David Li",
        "content": "<p>Introduction<br />\nIn Visual Studio 2022 version 17.11, you will find brand new productivity enhancements for your game development workflows. From faster conditional breakpoints to a swath of Unreal Engine enhancements, we have added various productivity boosters based on your feedback. Once again,</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/c-gaming-productivity-update-for-visual-studio-2022-version-17-11/\">C++ Gaming Productivity Update for Visual Studio 2022 version 17.11</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "Introduction\nThe post C++ Gaming Productivity Update for Visual Studio 2022 version 17.11 appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=250354",
        "categories": [
          "Cross-Platform",
          "Gaming",
          "Visual Studio",
          "Game Development",
          "Unreal Engine",
          "Visual Studio 2022"
        ],
        "isoDate": "2024-08-28T10:00:20.000Z"
      },
      {
        "creator": "Mads Kristensen",
        "title": "New IDE features in Visual Studio v17.11",
        "link": "https://devblogs.microsoft.com/visualstudio/new-ide-features-in-visual-studio-v17-11/",
        "pubDate": "Mon, 26 Aug 2024 15:53:30 +0000",
        "content:encodedSnippet": "In Visual Studio 2022 v17.11, you’ll discover several new features that address specific issues developers have reported. These updates don’t belong to a distinct category, but we’re dedicated to sharing them with you in this blog post. You can download the update and view the comprehensive release notes for full details.\nFind the code you’re looking for\nDo you ever feel like you’re seeing too many results in code search? Narrow down your focus with the newly added scoping options in Code Search.\n\nFor the default code search experience and each filter, you can now set the scope to Entire solution, Current project, or Current document and toggle inclusion of external files.\nYou can set different scopes for different filters. For example, the default experience can be set to look through Entire solution and members can be set to look through only current document. Your selections will be preserved past the current session.\nFamiliar keyboard shortcuts\nWhen moving between different IDEs and editors, it can be frustrating to have to relearn keyboard shortcuts. We’ve made some changes to some default keyboard shortcuts to make them more familiar and to preserve your muscle memory.\nToggle line comments\nYou’ve been able to toggle line comments in Visual Studio for a long time, but the default keyboard shortcut was Ctrl+K, Ctrl+/. We’ve now added Ctrl+/ as an alternative shortcut, which is the default in many other IDEs and editors.\n\nOpen Command Palette\nOr Feature Search as it’s called in Visual Studio. The default keyboard shortcut for this feature is now Ctrl+Shift+P, which should be familiar to VS Code users for opening the Command Palette.\n\nNever miss installing a component\nMany teams use *.vsconfig files to standardize their teams’ Visual Studio installations. The *.vsconfig files can be placed in a repo or a project’s solution directory, and Visual Studio will automatically detect if components specified in the *.vsconfig file are missing.\n\nIf any are missing, then a notification such as the one pictured below will appear.\n\nWe’ve made two improvements to this experience in Visual Studio 2022 version 17.11 Preview 1.\nFirst, Visual Studio can now detect if any local or network hosted extensions are missing from the installation, and if so, it’ll prompt you to install them. Previously, with respect to extensions, Visual Studio was only able to recognize if marketplace extensions were missing.\nSecondly, Visual Studio will now re-prompt the notification in certain situations, such as if the *.vsconfig file has changed because new components or extensions get added to it. Previously, the notification would only pop until you acted upon it, at which point it would be suppressed forever.\nImproved user authentication\nVisual Studio now uses the Web Account Manager (WAM) as its main authentication mechanism. This integration not only streamlines the authentication experience for Visual Studio, but it also enhances the security of your credentials.\nHere’s how the new WAM experience looks like:\n\nHow does this impact your experience?\nUsing WAM as the default authentication experience has many benefits, including:\nWindows integration: In addition to reducing the overall number of authentication prompts, you can now select existing Windows accounts instead of repeatedly entering credentials.\nBetter token protection: Refresh tokens are better secured as they are now device bound.\nSupport for the latest security features:\n\nLeverage rich OS capabilities such as Windows Hello & FIDO keys.\nAccess the latest and greatest Microsoft Entra ID capabilities and conditional access policies.\nNew Teams Toolkit templates\nTeams Toolkit now offers an empty Teams template for you to connect with your existing projects or use it as a starting point for new Teams apps.\nStart with this empty template to create a Teams app.\nIf you want to add Teams capability to your existing project, add Empty Teams App to your project and then connect two projects by making simple edits follow https://aka.ms/Config-Teams-app.\n\nTeams Toolkit supports authentication for Search Results from API Message Extensions app.\n\nWe hope you enjoy this update to Visual Studio, and we look forward to hearing what you think. You can share feedback with us via Developer Community, by reporting issues via report a problem and share your suggestions for new features or improvements to existing ones.\nStay connected with the Visual Studio team by following us on Twitter, YouTube, LinkedIn, and on Microsoft Learn.\nThank you for using Visual Studio and happy coding!\nDownload Visual Studio 17.11\n\n \nThe post New IDE features in Visual Studio v17.11 appeared first on Visual Studio Blog.",
        "dc:creator": "Mads Kristensen",
        "content": "<p>In Visual Studio 2022 v17.11, you&#8217;ll discover several new features that address specific issues developers have reported. These updates don&#8217;t belong to a distinct category, but we&#8217;re dedicated to sharing them with you in this blog post. You can download the update and view the comprehensive release notes for full details.</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/new-ide-features-in-visual-studio-v17-11/\">New IDE features in Visual Studio v17.11</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "In Visual Studio 2022 v17.11, you’ll discover several new features that address specific issues developers have reported. These updates don’t belong to a distinct category, but we’re dedicated to sharing them with you in this blog post. You can download the update and view the comprehensive release notes for full details.\nThe post New IDE features in Visual Studio v17.11 appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=250326",
        "categories": [
          "Productivity",
          "Team and Development",
          "Visual Studio",
          "code search",
          "Keyboard Shortcuts",
          "vsconfig"
        ],
        "isoDate": "2024-08-26T15:53:30.000Z"
      }
    ]
  },
  {
    "name": "Instagram Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Dropbox Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Joshua",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권재명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김석기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권진호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강대명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권정혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "줌구",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수보",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김시은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "곽민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김범진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민서",
    "category": "개인",
    "posts": []
  },
  {
    "name": "I am not Okay",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권창현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권기호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강태욱",
    "category": "개인",
    "posts": [
      {
        "title": "인공지능 딥러닝 모델 성능 지표",
        "link": "http://daddynkidsmakers.blogspot.com/2024/08/blog-post.html",
        "pubDate": "2024-08-25T09:46:00.000Z",
        "author": "Daddy Maker",
        "content": "<div style=\"text-align: left;\">이 글은&nbsp;인공지능 딥러닝 모델 성능 지표를 간략히 정리한 것이다. 개발 목적에 따라 다양한 딥러닝 모델을 사용하고, 그에 따라 적절한 성능 지표를 모니터링해 튜닝 등 품질을 개선하는 것이 좋다. 필요할 때 찾아보기 귀찮으니 정리해 놓기로 한다. 이와 관련된 다양한 성능지표를 확인해 본다.</div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEid4gFMYYST6FBuhnZnTi_81U3sox36neNlc6Zl88lIXUyUXN5H8A9jDHJOYBqf0FIxS5oiOWpHUT4Cemd_IIhROVJhMvsmzVh7Mw6puJ__pXHubj9tmQuZDmDjBKGSAxKrqmkvxxZ3yo7ChuqqRYh3GFcDYWzKn_1yhcQLOl2KBeROGvVvhd_8tNnN9lm1\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"480\" data-original-width=\"720\" height=\"213\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEid4gFMYYST6FBuhnZnTi_81U3sox36neNlc6Zl88lIXUyUXN5H8A9jDHJOYBqf0FIxS5oiOWpHUT4Cemd_IIhROVJhMvsmzVh7Mw6puJ__pXHubj9tmQuZDmDjBKGSAxKrqmkvxxZ3yo7ChuqqRYh3GFcDYWzKn_1yhcQLOl2KBeROGvVvhd_8tNnN9lm1\" width=\"320\" /></a></div></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\"><b>개요</b></div><div style=\"text-align: left;\">많은 딥러닝 모델 개발의 경우, 성능 지표를 미리 고민하지 않고, 개발을 하였다가 뒤늦게 관련 기능을 추가하느라 고생하는 경우가 있다. 이런 경우를 대비해, 미리 어떤 지표가 있는 지 확인해 본다.</div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\"><b>본론</b></div><div style=\"text-align: left;\">가장 단순한 성능 지표부터 시작해, LLM에서 많이 사용되는 지표도 확인해 보자.&nbsp;</div><div style=\"text-align: left;\">여기서 수식은 n개의 데이터 셋을 가진 입력 변수 x에 대한 참 값 y가 있다고 가정한다. ŷ 은 입력 x 에 대한 f(x)의 결과로 가정한다. f(x)의 참 값은 y이다.&nbsp;</div><div style=\"text-align: left;\"><ul style=\"text-align: left;\"><li>MSE (Mean Squared Error) : 편차의 제곱을 n으로 나눈 편차 평균</li></ul></div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEh69EAXcrN8uA6Nmo9DcVlTgn4EJJ2f4Aqa9iWQenvcLJ2N9UL8l5_pHkB80SsIa5yno-r18Xi6uNeo7U5gm7FXtVpAKxU7_4-2dUSv1akMEiPhnZGDYS8NMa8d0zuimOwLjr0Lt8yILzR55oPyMWdfS7j8xqDmuLxT1N-RoW8V9tRtOCwYu0qM_JK-KUsd\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"85\" data-original-width=\"262\" height=\"64\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEh69EAXcrN8uA6Nmo9DcVlTgn4EJJ2f4Aqa9iWQenvcLJ2N9UL8l5_pHkB80SsIa5yno-r18Xi6uNeo7U5gm7FXtVpAKxU7_4-2dUSv1akMEiPhnZGDYS8NMa8d0zuimOwLjr0Lt8yILzR55oPyMWdfS7j8xqDmuLxT1N-RoW8V9tRtOCwYu0qM_JK-KUsd=w196-h64\" width=\"196\" /></a></div><ul style=\"text-align: left;\"><li>RMSE (Root Mean Squared Error): 예측값과 실제값의 편차 평균의 제곱근 값</li></ul><div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEgSQHJRltZB-1O4lzoVcSBAiL7NAhs3t6TEtxHNenraOIthWZl2H3e3GArY0nSY5NwAok0zx3p88tTwullR-i-AAuZZNGx2R1U0lDH3V5nArvaIfs6oJnIiKRiAnwh619tTqbOU2ocPS1vwPWdxaNPL2mWs0Y3AMeEd40nEITq2VEcwSdBXbpOCbwgheGkm\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"85\" data-original-width=\"307\" height=\"60\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEgSQHJRltZB-1O4lzoVcSBAiL7NAhs3t6TEtxHNenraOIthWZl2H3e3GArY0nSY5NwAok0zx3p88tTwullR-i-AAuZZNGx2R1U0lDH3V5nArvaIfs6oJnIiKRiAnwh619tTqbOU2ocPS1vwPWdxaNPL2mWs0Y3AMeEd40nEITq2VEcwSdBXbpOCbwgheGkm=w217-h60\" width=\"217\" /></a></div></div><ul style=\"text-align: left;\"><li>CvRMSE (Coefficent of Variation of RMSE): RMSE를 표준화하여 데이터 변동성을 알려주는 지표. RMSE의 백분율임. 데이터 평균에 대한 RMSE의 백분류로 계산</li></ul><div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEj2s3ScOnAhYLIEBw9NSKf3QWd2rGMoya9pPEHMm-VGGA5UV1aNQXo2iVcH9UlnrubLLV486LdFWuvbJezRn-7fF8uWqVhqFmuaWOsG4dwFnfYb6LbwlhdQV95S-8-BsHZEVDl-2CGFAQJMBjCELAsVyauUCJALAGEWFFxdKa3NYE9RxXcQcoQDfKGCKR7I\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"69\" data-original-width=\"303\" height=\"49\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEj2s3ScOnAhYLIEBw9NSKf3QWd2rGMoya9pPEHMm-VGGA5UV1aNQXo2iVcH9UlnrubLLV486LdFWuvbJezRn-7fF8uWqVhqFmuaWOsG4dwFnfYb6LbwlhdQV95S-8-BsHZEVDl-2CGFAQJMBjCELAsVyauUCJALAGEWFFxdKa3NYE9RxXcQcoQDfKGCKR7I=w218-h49\" width=\"218\" /></a></div></div><ul style=\"text-align: left;\"><li>MAE (Mean Absolute Error) : 편차값에 가까운 절대 차이 평균값</li></ul><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEjSaWNJ11wjB8baPUkxN5k1Ib2u0TnJnfsdpSXVkTm-I8CioNRokhfI72BBcV8b7LUCX9o3M7HOkarrql7SL_dTlSgPg4bnSZN_X2-OaT_Ap79OKeeBsbJ82NbZULsArpVaoIXny-A45IwbG1J2LQBUZNIyVZDYdgoLM4aII8ovy3JpVUsxskldFJOgB_UV\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"85\" data-original-width=\"265\" height=\"61\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEjSaWNJ11wjB8baPUkxN5k1Ib2u0TnJnfsdpSXVkTm-I8CioNRokhfI72BBcV8b7LUCX9o3M7HOkarrql7SL_dTlSgPg4bnSZN_X2-OaT_Ap79OKeeBsbJ82NbZULsArpVaoIXny-A45IwbG1J2LQBUZNIyVZDYdgoLM4aII8ovy3JpVUsxskldFJOgB_UV=w189-h61\" width=\"189\" /></a></div><ul style=\"text-align: left;\"><li>Accuray : 모델이 정확히 값을 예측했는 지 지표. 분류 모델 등 사용. 여기서 1은 조건 부합 시 참(1), 거짓(0)을 반환하는 indicator function 임</li></ul><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEjO1y7n-M_EW3a3wnrFQKqTNdyvMOYfKVgYxf1yTAgt1wFEhJBVYd0C4ayetZuIgXoz-M2WZ5gvTVlrceOvtJPmaqZurwNOBSmwWKNIOUfe6YnVMAYG8FkPX3AmXOPcL2oTRErhideW_bzB_uFhnB-FbUZ8SjEReolSj-DHuScBruZmzTBZgXodRb5ydHO0\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"89\" data-original-width=\"315\" height=\"62\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEjO1y7n-M_EW3a3wnrFQKqTNdyvMOYfKVgYxf1yTAgt1wFEhJBVYd0C4ayetZuIgXoz-M2WZ5gvTVlrceOvtJPmaqZurwNOBSmwWKNIOUfe6YnVMAYG8FkPX3AmXOPcL2oTRErhideW_bzB_uFhnB-FbUZ8SjEReolSj-DHuScBruZmzTBZgXodRb5ydHO0=w219-h62\" width=\"219\" /></a></div><ul style=\"text-align: left;\"><li>MAPE (Mean Abslute Percentage Error): 회귀분석 모델 예측에 주로 사용되는 지표.&nbsp;</li></ul></div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEhVLddPwwpb5fzh78A7OuFqjQcjW74tEgVtZZ5XWi---S8xLB9sFC-89hapWA2252PssVLYN9bNpg4CMdDra7JtHTbRoGiM5atC4m7XHna4odMw1EDDmXNSpOij2dFKtFY6k4jG78wUJVE8dvQqhSrZTxGFc83fWEd5pdaMMUGUq2l2UmEPIWOIK-OXcsKf\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"83\" data-original-width=\"336\" height=\"54\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEhVLddPwwpb5fzh78A7OuFqjQcjW74tEgVtZZ5XWi---S8xLB9sFC-89hapWA2252PssVLYN9bNpg4CMdDra7JtHTbRoGiM5atC4m7XHna4odMw1EDDmXNSpOij2dFKtFY6k4jG78wUJVE8dvQqhSrZTxGFc83fWEd5pdaMMUGUq2l2UmEPIWOIK-OXcsKf=w217-h54\" width=\"217\" /></a></div></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\">이외에, LLM에 주로 사용되는 ROGUE, BLEU, 컴퓨터 비전에 주로 사용되는 mAP, IoU, F1, call, recall 등 지표가 있다.&nbsp;</div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\"><br /></div>",
        "contentSnippet": "이 글은 인공지능 딥러닝 모델 성능 지표를 간략히 정리한 것이다. 개발 목적에 따라 다양한 딥러닝 모델을 사용하고, 그에 따라 적절한 성능 지표를 모니터링해 튜닝 등 품질을 개선하는 것이 좋다. 필요할 때 찾아보기 귀찮으니 정리해 놓기로 한다. 이와 관련된 다양한 성능지표를 확인해 본다.\n\n\n\n\n개요\n많은 딥러닝 모델 개발의 경우, 성능 지표를 미리 고민하지 않고, 개발을 하였다가 뒤늦게 관련 기능을 추가하느라 고생하는 경우가 있다. 이런 경우를 대비해, 미리 어떤 지표가 있는 지 확인해 본다.\n\n\n본론\n가장 단순한 성능 지표부터 시작해, LLM에서 많이 사용되는 지표도 확인해 보자. \n여기서 수식은 n개의 데이터 셋을 가진 입력 변수 x에 대한 참 값 y가 있다고 가정한다. ŷ 은 입력 x 에 대한 f(x)의 결과로 가정한다. f(x)의 참 값은 y이다. \n\nMSE (Mean Squared Error) : 편차의 제곱을 n으로 나눈 편차 평균\n\n\n\n\nRMSE (Root Mean Squared Error): 예측값과 실제값의 편차 평균의 제곱근 값\n\n\n\nCvRMSE (Coefficent of Variation of RMSE): RMSE를 표준화하여 데이터 변동성을 알려주는 지표. RMSE의 백분율임. 데이터 평균에 대한 RMSE의 백분류로 계산\n\n\n\nMAE (Mean Absolute Error) : 편차값에 가까운 절대 차이 평균값\n\n\n\nAccuray : 모델이 정확히 값을 예측했는 지 지표. 분류 모델 등 사용. 여기서 1은 조건 부합 시 참(1), 거짓(0)을 반환하는 indicator function 임\n\n\n\nMAPE (Mean Abslute Percentage Error): 회귀분석 모델 예측에 주로 사용되는 지표. \n\n\n\n\n\n이외에, LLM에 주로 사용되는 ROGUE, BLEU, 컴퓨터 비전에 주로 사용되는 mAP, IoU, F1, call, recall 등 지표가 있다.",
        "id": "tag:blogger.com,1999:blog-5201956450461596914.post-5149285106406844516",
        "isoDate": "2024-08-25T09:46:00.000Z"
      }
    ]
  },
  {
    "name": "권용진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권영재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김승호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김병환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for boyism Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성준의 린스타트업과 디자인씽킹",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권혁우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김준형",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강동혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고종범",
    "category": "개인",
    "posts": [
      {
        "creator": "고종범",
        "title": "GPT, Brain, and Running",
        "link": "https://brunch.co.kr/@@24SO/46",
        "pubDate": "Fri, 30 Aug 2024 01:27:15 GMT",
        "author": "고종범",
        "content": "사용할수록 사용방법이 떠오르는 GPT ChatGPT 가 등장하고 충격을 주었지만 사실 많은 사람이 잘 사용한다고 보기 어려운 것이 GPT 란 생각이었다. 유투버들은 언어 공부를 하는 방법, 블로그 글쓰기 등 다양한 방법들을 제시하기도 하고 이미지 생성이나 음성 합성등의 기능을 사용하기도 한다. 몇몇의 서비스들은 GPT를 붙여서 자신들의 서비스를 고도화하기도",
        "contentSnippet": "사용할수록 사용방법이 떠오르는 GPT ChatGPT 가 등장하고 충격을 주었지만 사실 많은 사람이 잘 사용한다고 보기 어려운 것이 GPT 란 생각이었다. 유투버들은 언어 공부를 하는 방법, 블로그 글쓰기 등 다양한 방법들을 제시하기도 하고 이미지 생성이나 음성 합성등의 기능을 사용하기도 한다. 몇몇의 서비스들은 GPT를 붙여서 자신들의 서비스를 고도화하기도",
        "guid": "https://brunch.co.kr/@@24SO/46",
        "isoDate": "2024-08-30T01:27:15.000Z"
      },
      {
        "creator": "고종범",
        "title": "가을이 되는 느낌? 독서",
        "link": "https://brunch.co.kr/@@24SO/45",
        "pubDate": "Mon, 26 Aug 2024 00:54:06 GMT",
        "author": "고종범",
        "content": "여유가 주는 바쁨 진행하던 프로젝트가 너무 잘 진행되어 여유가 생겼다. 1차 고개를 넘은 터라 한 달 정도 여유 있을 거라 생각했는데 2달은 여유가 있을 듯싶다. 그래서 그 여유를 즐기기 위해 그동안 정리 못하고 있던 것들을 정리하기 시작했다. 잔뜩 쌓였던 나의 주제 단지를 열어보니 생각보다 많은 주제가 있었다. 게다가 끝난 줄 알았던 주제에 꼬리가 붙어서",
        "contentSnippet": "여유가 주는 바쁨 진행하던 프로젝트가 너무 잘 진행되어 여유가 생겼다. 1차 고개를 넘은 터라 한 달 정도 여유 있을 거라 생각했는데 2달은 여유가 있을 듯싶다. 그래서 그 여유를 즐기기 위해 그동안 정리 못하고 있던 것들을 정리하기 시작했다. 잔뜩 쌓였던 나의 주제 단지를 열어보니 생각보다 많은 주제가 있었다. 게다가 끝난 줄 알았던 주제에 꼬리가 붙어서",
        "guid": "https://brunch.co.kr/@@24SO/45",
        "isoDate": "2024-08-26T00:54:06.000Z"
      }
    ]
  },
  {
    "name": "cheese10yun",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구자철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "FSS",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권동준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김용일",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도균",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김상훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김동우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권윤학",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김만수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "엘키",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김슬기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김광현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김영우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강명훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민장",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕홍",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성중",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구교준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고명환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성희",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강병수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김봉현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강형석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수로",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강미경",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강진우",
    "category": "개인",
    "posts": [
      {
        "creator": "강진우",
        "title": "위임 못하는 리더의 숨겨진 속마음 - 질투심 - 리더가 된 후, 이런 고민들을 하고 있습니다. #2",
        "link": "https://brunch.co.kr/@@3Y0/79",
        "pubDate": "Fri, 30 Aug 2024 13:00:22 GMT",
        "author": "강진우",
        "content": "대부분의 리더십 책이나 블로그를 보면 위임을 잘하는 리더가 되라고 이야기한다.&nbsp;위임, 어떤 일을 책임 지워 맡긴다는 뜻을 가진 이 단어는 리더가 더 많은 영향력을 발휘하고 더 많은 성과를 만들어내기 위해 꼭 필요한 역량 중 하나이다. 하지만 위임을 잘한다는 것은 꽤나 어려운 일이다. 그리고 위임을 어렵게 만드는 것에는 다양한 이유가 있겠지만, 질투심도 그중",
        "contentSnippet": "대부분의 리더십 책이나 블로그를 보면 위임을 잘하는 리더가 되라고 이야기한다. 위임, 어떤 일을 책임 지워 맡긴다는 뜻을 가진 이 단어는 리더가 더 많은 영향력을 발휘하고 더 많은 성과를 만들어내기 위해 꼭 필요한 역량 중 하나이다. 하지만 위임을 잘한다는 것은 꽤나 어려운 일이다. 그리고 위임을 어렵게 만드는 것에는 다양한 이유가 있겠지만, 질투심도 그중",
        "guid": "https://brunch.co.kr/@@3Y0/79",
        "isoDate": "2024-08-30T13:00:22.000Z"
      }
    ]
  },
  {
    "name": "권민재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태관",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도곤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "칡토스의 게임 개발",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김놀부",
    "category": "개인",
    "posts": []
  },
  {
    "name": "프리웨어 이야기",
    "category": "개인",
    "posts": [
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "Markdown을 활용한 최상의 노트 작성, 옵시디언(Obsidian)",
        "link": "http://muzbox.tistory.com/483464",
        "pubDate": "Fri, 30 Aug 2024 11:36:46 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483464#entry483464comment",
        "content": "<p data-ke-size=\"size18\">옵시디언(Obsidian)은 개인화되고 유연한 노트 작성 애플리케이션으로, 사용자의 사고방식에 맞게 조정됩니다. 수많은 플러그인과 테마로 사용자의 필요에 맞게 커스터마이징할 수 있으며, 데이터를 안전하게 저장하고 관리할 수 있는 강력한 도구입니다.</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<table style=\"border-collapse: collapse; width: 95.6979%; height: 248px;\" border=\"1\" data-ke-align=\"alignLeft\">\n<tbody>\n<tr style=\"height: 62px;\"><!-- 첫 번째 열에 배경색을 노란색으로 설정 -->\n<td style=\"width: 13.1835%; height: 62px; text-align: center; background-color: #555555;\"><span style=\"color: #ffffff;\"><b>분류</b></span></td>\n<td style=\"width: 22.4483%; height: 62px; text-align: center;\">생산성/노트</td>\n<td style=\"width: 64.3682%; height: 248px; text-align: center;\" rowspan=\"4\"><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Obsidian 05-Photoroom.png\" data-origin-width=\"1280\" data-origin-height=\"693\"><span data-url=\"https://blog.kakaocdn.net/dn/boGCp3/btsJk803dLh/dieYheFtkKyNNnOy9IYsS0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/boGCp3/btsJk803dLh/dieYheFtkKyNNnOy9IYsS0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/boGCp3/btsJk803dLh/dieYheFtkKyNNnOy9IYsS0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FboGCp3%2FbtsJk803dLh%2FdieYheFtkKyNNnOy9IYsS0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"Obsidian 05-Photoroom.png\" data-origin-width=\"1280\" data-origin-height=\"693\"/></span></figure>\n</td>\n</tr>\n<tr style=\"height: 62px;\"><!-- 첫 번째 열에 배경색을 노란색으로 설정 -->\n<td style=\"width: 13.1835%; height: 62px; text-align: center; background-color: #555555;\"><span style=\"color: #ffffff;\"><b>사용범위</b></span></td>\n<td style=\"width: 22.4483%; height: 62px; text-align: center;\">무료(개인)</td>\n</tr>\n<tr style=\"height: 62px;\"><!-- 첫 번째 열에 배경색을 노란색으로 설정 -->\n<td style=\"width: 13.1835%; height: 62px; text-align: center; background-color: #555555;\"><span style=\"color: #ffffff;\"><b>사용환경</b></span></td>\n<td style=\"width: 22.4483%; height: 62px; text-align: center;\">Windows,&nbsp;macOS,&nbsp;<br />Linux,&nbsp;iOS,&nbsp;Android</td>\n</tr>\n<tr style=\"height: 62px;\"><!-- 첫 번째 열에 배경색을 노란색으로 설정 -->\n<td style=\"width: 13.1835%; height: 62px; text-align: center; background-color: #555555;\"><span style=\"color: #ffffff;\"><b>제작사</b></span></td>\n<td style=\"width: 22.4483%; height: 62px; text-align: center;\"><a href=\"https://obsidian.md/\" target=\"_blank\" rel=\"noopener\">Obsidian</a></td>\n</tr>\n</tbody>\n</table>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><b> 프로그램 소개</b></h2>\n<p data-ke-size=\"size18\">&nbsp; 현대의&nbsp;정보&nbsp;사회에서는&nbsp;누구나&nbsp;다양한&nbsp;아이디어를&nbsp;기록하고,&nbsp;정리하고,&nbsp;연결하는&nbsp;일이&nbsp;중요해졌습니다.&nbsp;이런&nbsp;필요를&nbsp;해결해주는&nbsp;대표적인&nbsp;도구&nbsp;중&nbsp;하나가&nbsp;바로&nbsp;Obsidian입니다.&nbsp;</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\">&nbsp;Obsidian은 사용자 중심의 노트 작성 애플리케이션으로, 개인의 고유한 사고방식과 업무 흐름에 맞게 유연하게 조정할 수 있는 강력한 기능을 제공합니다. 이제 Obsidian이 어떻게 여러분의 창의력을 증진하고, 지식을 구조화하며, 효과적으로 관리할 수 있는지 자세히 알아보겠습니다.</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Markdown을 활용한 최상의 노트 작성, 옵시디언.png\" data-origin-width=\"500\" data-origin-height=\"500\"><span data-url=\"https://blog.kakaocdn.net/dn/3rElW/btsJk0hOBJa/okv5d3XWoxKSUTQrlFWeU1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/3rElW/btsJk0hOBJa/okv5d3XWoxKSUTQrlFWeU1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/3rElW/btsJk0hOBJa/okv5d3XWoxKSUTQrlFWeU1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F3rElW%2FbtsJk0hOBJa%2Fokv5d3XWoxKSUTQrlFWeU1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"Markdown을 활용한 최상의 노트 작성, 옵시디언(Obsidian)\" data-filename=\"Markdown을 활용한 최상의 노트 작성, 옵시디언.png\" data-origin-width=\"500\" data-origin-height=\"500\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><b> 옵시디언(Obsidian) &nbsp;주요 기능</b></h2>\n<p data-ke-size=\"size18\">Obsidian은&nbsp;기본&nbsp;제공되는&nbsp;22개의&nbsp;코어&nbsp;플러그인과&nbsp;197개의&nbsp;커뮤니티&nbsp;플러그인으로&nbsp;이루어져&nbsp;있어,&nbsp;사용자의&nbsp;요구에&nbsp;맞게&nbsp;소프트웨어를&nbsp;완전히&nbsp;커스터마이즈할&nbsp;수&nbsp;있습니다.&nbsp;여기에는&nbsp;그래프&nbsp;뷰,&nbsp;페이지&nbsp;미리보기,&nbsp;백링크&nbsp;기능,&nbsp;일일&nbsp;노트&nbsp;생성,&nbsp;태그&nbsp;창,&nbsp;중요&nbsp;노트&nbsp;북마크,&nbsp;파일&nbsp;탐색기&nbsp;등&nbsp;다양한&nbsp;도구가&nbsp;포함되어&nbsp;있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Obsidian 03.jpg\" data-origin-width=\"1119\" data-origin-height=\"544\"><span data-url=\"https://blog.kakaocdn.net/dn/cj6Oop/btsJlKFpYZA/knI90lgiF0eZWq3KvGgYl1/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/cj6Oop/btsJlKFpYZA/knI90lgiF0eZWq3KvGgYl1/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/cj6Oop/btsJlKFpYZA/knI90lgiF0eZWq3KvGgYl1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fcj6Oop%2FbtsJlKFpYZA%2FknI90lgiF0eZWq3KvGgYl1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"Obsidian 03.jpg\" data-origin-width=\"1119\" data-origin-height=\"544\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\"><br />이러한&nbsp;플러그인들은&nbsp;노트&nbsp;작성&nbsp;경험을&nbsp;더욱&nbsp;풍부하고&nbsp;유연하게&nbsp;만들어&nbsp;줍니다.&nbsp;예를&nbsp;들어,&nbsp;'그래프&nbsp;뷰'는&nbsp;모든&nbsp;노트와&nbsp;그&nbsp;연결을&nbsp;시각적으로&nbsp;나타내어,&nbsp;지식&nbsp;네트워크의&nbsp;전반적인&nbsp;구조를&nbsp;쉽게&nbsp;파악할&nbsp;수&nbsp;있게&nbsp;해줍니다.&nbsp;'페이지&nbsp;미리보기'&nbsp;기능은&nbsp;링크된&nbsp;내용을&nbsp;미리&nbsp;볼&nbsp;수&nbsp;있게&nbsp;하여,&nbsp;여러&nbsp;노트&nbsp;간의&nbsp;빠른&nbsp;전환과&nbsp;검토를&nbsp;가능하게&nbsp;합니다.&nbsp;또한&nbsp;'백링크'&nbsp;기능을&nbsp;사용하면&nbsp;해당&nbsp;노트로&nbsp;링크된&nbsp;다른&nbsp;노트를&nbsp;쉽게&nbsp;찾을&nbsp;수&nbsp;있어,&nbsp;새로운&nbsp;연결과&nbsp;아이디어를&nbsp;발견할&nbsp;수&nbsp;있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Obsidian 01.jpg\" data-origin-width=\"2928\" data-origin-height=\"1728\"><span data-url=\"https://blog.kakaocdn.net/dn/Q7K1N/btsJjWglVux/S9bhvv5TSZJHHkKw7U66bK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/Q7K1N/btsJjWglVux/S9bhvv5TSZJHHkKw7U66bK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/Q7K1N/btsJjWglVux/S9bhvv5TSZJHHkKw7U66bK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FQ7K1N%2FbtsJjWglVux%2FS9bhvv5TSZJHHkKw7U66bK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"Obsidian 01.jpg\" data-origin-width=\"2928\" data-origin-height=\"1728\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\"><b>1. Markdown 기반</b><span style=\"background-color: #fcfcfc; color: #666666; text-align: left;\">: 옵시디언은 마크다운을 사용하여 포맷팅하며, 이는 가볍고 휴대가능한 텍스트 포맷을 가능하게 합니다.</span><br /><br /><b>2. 로컬 저장소</b><span style=\"background-color: #fcfcfc; color: #666666; text-align: left;\">: 모든 노트는 플레인 텍스트 파일로 기기에 로컬로 저장되어 데이터 개인 정보 보호 및 소유권을 보장합니다.</span></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Obsidian 04.jpg\" data-origin-width=\"1256\" data-origin-height=\"620\"><span data-url=\"https://blog.kakaocdn.net/dn/ccbpZI/btsJls54E4W/BdfQlnxCgCOqK6KuIlIjq0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/ccbpZI/btsJls54E4W/BdfQlnxCgCOqK6KuIlIjq0/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/ccbpZI/btsJls54E4W/BdfQlnxCgCOqK6KuIlIjq0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FccbpZI%2FbtsJls54E4W%2FBdfQlnxCgCOqK6KuIlIjq0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"Obsidian 04.jpg\" data-origin-width=\"1256\" data-origin-height=\"620\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\"><span style=\"background-color: #fcfcfc; color: #666666; text-align: left;\"></span><br /><br /><b>3. 링크 및 그래프 뷰</b><span style=\"background-color: #fcfcfc; color: #666666; text-align: left;\">: 옵시디언은 노트 간의 연결을 생성하는 데 뛰어나며, 아이디어 간의 관계를 볼 수 있는 시각적 그래프 뷰를 제공합니다.</span></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Obsidian 02.jpg\" data-origin-width=\"1143\" data-origin-height=\"547\"><span data-url=\"https://blog.kakaocdn.net/dn/T9Yt4/btsJkdvstai/lKy6beGYLCsLHOSF1r3g61/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/T9Yt4/btsJkdvstai/lKy6beGYLCsLHOSF1r3g61/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/T9Yt4/btsJkdvstai/lKy6beGYLCsLHOSF1r3g61/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FT9Yt4%2FbtsJkdvstai%2FlKy6beGYLCsLHOSF1r3g61%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"Obsidian 02.jpg\" data-origin-width=\"1143\" data-origin-height=\"547\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\"><span style=\"background-color: #fcfcfc; color: #666666; text-align: left;\"></span><br /><br /><b>4. 사용자 정의 가능</b><span style=\"background-color: #fcfcfc; color: #666666; text-align: left;\">: 앱은 플러그인과 테마를 지원하여 사용자가 필요에 따라 경험을 맞춤 설정할 수 있습니다.</span><br /><br /><b>5. 크로스 플랫폼</b><span style=\"background-color: #fcfcfc; color: #666666; text-align: left;\">: Windows, macOS, Linux, iOS, Android에서 사용 가능합니다.</span></p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><b>  프로그램 장단점</b></h2>\n<p data-ke-size=\"size18\">&nbsp;Obsidian은 사용자의 작업 공간을 최적화하기 위해 다양한 화면 분할 및 고정 기능을 제공합니다. 화면을 무한대로 분할하고 크기를 조절할 수 있어, 여러 노트를 동시에 열어보며 교차 참조를 손쉽게 할 수 있습니다. 특정 노트를 고정하여 해당 내용이 항상 표시되도록 하거나, 서로 다른 노트의 다른 뷰를 보여주는 방식으로 연결할 수도 있습니다. 이러한 기능들은 큰 화면을 사용하는 사용자나, 짧고 핵심적인 노트를 다루는 사용자에게 특히 유용합니다. <br /><br />또한,&nbsp;'빠른&nbsp;전환기'&nbsp;기능은&nbsp;키보드만으로도&nbsp;원하는&nbsp;노트로&nbsp;즉시&nbsp;이동하거나&nbsp;새&nbsp;노트를&nbsp;만들&nbsp;수&nbsp;있게&nbsp;하여,&nbsp;작업&nbsp;효율성을&nbsp;극대화합니다.&nbsp;'명령어&nbsp;팔레트'를&nbsp;통해서는&nbsp;마우스를&nbsp;사용하지&nbsp;않고도&nbsp;모든&nbsp;기능을&nbsp;활용할&nbsp;수&nbsp;있어,&nbsp;보다&nbsp;빠르고&nbsp;직관적인&nbsp;작업&nbsp;흐름을&nbsp;유지할&nbsp;수&nbsp;있습니다. <br /><br />Obsidian&nbsp;의&nbsp;장점과&nbsp;단점은&nbsp;다음과&nbsp;같습니다.</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<h4 data-ke-size=\"size20\"><b> 장점</b></h4>\n<blockquote data-ke-style=\"style3\">1. 강력한 링크 및 지식 관리 기능을 갖추고 있습니다. <br />2. 플러그인 및 테마로 고도로 사용자 정의가 가능합니다. <br />3. 개인 사용은 무료입니다. <br />4. 로컬 저장소는 데이터 개인 정보 보호 및 소유권을 보장합니다. <br />5. 빠른 성능과 반응형 인터페이스를 제공합니다.</blockquote>\n<h4 data-ke-size=\"size20\"><b> 단점</b></h4>\n<blockquote data-ke-style=\"style3\">1. 마크다운에 익숙하지 않은 사람들에게는 배우기가 어렵습니다. <br />2. 웹 버전이 없습니다. <br />3. 일부 사용자가 매력적이지 않다고 여기는 기본 인터페이스 미학입니다. <br />4. 데이터가 로컬에 저장되므로 수동 백업이 필요합니다.</blockquote>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<h2 style=\"color: #000000; text-align: start;\" data-ke-size=\"size26\"><b>  라이센스 정책</b></h2>\n<p data-ke-size=\"size18\">&nbsp;Obsidian은 개인 사용에 대해서는 무료로 제공됩니다. 개인적인 노트 작성, 학습, 연구 목적으로 누구나 제한 없이 사용할 수 있습니다. 즉, 개인이 비상업적인 목적으로 노트를 작성하고 관리하는 데 사용하는 경우 별도의 비용을 지불할 필요가 없습니다. <br /><br />옵시디언은 아래와 같이 여러 가격 등급을 제공합니다.</p>\n<blockquote data-ke-style=\"style3\"><span style=\"color: #ee2323;\"><b>1. 개인 사용: 모든 핵심 기능을 포함하여 무료입니다.</b></span> <br />2. 상업적 사용: 사용자당 연 $50입니다. <br />3. 동기화 추가 기능: 기기 간 동기화를 위해 월 $4-$5입니다. <br />4. 출판 추가 기능: 웹 출판을 위해 사이트당 월 $8-$10입니다.</blockquote>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p style=\"color: #333333; text-align: start;\" data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><b>⬇️ 프로그램 다운로드</b></h2>\n\n<p data-ke-size=\"size16\">&nbsp;</p>\n<figure id=\"og_1724985332600\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"Obsidian - Sharpen your thinking\" data-og-description=\"Obsidian is the private and flexible note‑taking app that adapts to the way you think.\" data-og-host=\"obsidian.md\" data-og-source-url=\"https://obsidian.md/\" data-og-url=\"https://obsidian.md/\" data-og-image=\"https://scrap.kakaocdn.net/dn/kmOmh/hyWVTCIJWX/TSivGeOqIuF2vpGuzCV1Tk/img.png?width=1200&amp;height=688&amp;face=0_0_1200_688,https://scrap.kakaocdn.net/dn/w0mNd/hyWVRSsWIR/0RCvMtadCktQP4I7oVAJLk/img.png?width=1200&amp;height=688&amp;face=0_0_1200_688,https://scrap.kakaocdn.net/dn/dk90tE/hyWV45jiOh/Mgy3qeFsm2KKjVTxcIo9gK/img.png?width=2899&amp;height=1757&amp;face=0_0_2899_1757\"><a href=\"https://obsidian.md/\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://obsidian.md/\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/kmOmh/hyWVTCIJWX/TSivGeOqIuF2vpGuzCV1Tk/img.png?width=1200&amp;height=688&amp;face=0_0_1200_688,https://scrap.kakaocdn.net/dn/w0mNd/hyWVRSsWIR/0RCvMtadCktQP4I7oVAJLk/img.png?width=1200&amp;height=688&amp;face=0_0_1200_688,https://scrap.kakaocdn.net/dn/dk90tE/hyWV45jiOh/Mgy3qeFsm2KKjVTxcIo9gK/img.png?width=2899&amp;height=1757&amp;face=0_0_2899_1757');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">Obsidian - Sharpen your thinking</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">Obsidian is the private and flexible note‑taking app that adapts to the way you think.</p>\n<p class=\"og-host\" data-ke-size=\"size16\">obsidian.md</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "옵시디언(Obsidian)은 개인화되고 유연한 노트 작성 애플리케이션으로, 사용자의 사고방식에 맞게 조정됩니다. 수많은 플러그인과 테마로 사용자의 필요에 맞게 커스터마이징할 수 있으며, 데이터를 안전하게 저장하고 관리할 수 있는 강력한 도구입니다.\n \n\n분류\n생산성/노트\n\n\n\n\n사용범위\n무료(개인)\n\n\n사용환경\nWindows, macOS, \nLinux, iOS, Android\n\n\n제작사\nObsidian\n\n\n\n \n 프로그램 소개\n  현대의 정보 사회에서는 누구나 다양한 아이디어를 기록하고, 정리하고, 연결하는 일이 중요해졌습니다. 이런 필요를 해결해주는 대표적인 도구 중 하나가 바로 Obsidian입니다. \n \n Obsidian은 사용자 중심의 노트 작성 애플리케이션으로, 개인의 고유한 사고방식과 업무 흐름에 맞게 유연하게 조정할 수 있는 강력한 기능을 제공합니다. 이제 Obsidian이 어떻게 여러분의 창의력을 증진하고, 지식을 구조화하며, 효과적으로 관리할 수 있는지 자세히 알아보겠습니다.\n \n\n\n \n \n \n 옵시디언(Obsidian)  주요 기능\nObsidian은 기본 제공되는 22개의 코어 플러그인과 197개의 커뮤니티 플러그인으로 이루어져 있어, 사용자의 요구에 맞게 소프트웨어를 완전히 커스터마이즈할 수 있습니다. 여기에는 그래프 뷰, 페이지 미리보기, 백링크 기능, 일일 노트 생성, 태그 창, 중요 노트 북마크, 파일 탐색기 등 다양한 도구가 포함되어 있습니다.\n\n\n\n이러한 플러그인들은 노트 작성 경험을 더욱 풍부하고 유연하게 만들어 줍니다. 예를 들어, '그래프 뷰'는 모든 노트와 그 연결을 시각적으로 나타내어, 지식 네트워크의 전반적인 구조를 쉽게 파악할 수 있게 해줍니다. '페이지 미리보기' 기능은 링크된 내용을 미리 볼 수 있게 하여, 여러 노트 간의 빠른 전환과 검토를 가능하게 합니다. 또한 '백링크' 기능을 사용하면 해당 노트로 링크된 다른 노트를 쉽게 찾을 수 있어, 새로운 연결과 아이디어를 발견할 수 있습니다.\n\n\n \n \n1. Markdown 기반: 옵시디언은 마크다운을 사용하여 포맷팅하며, 이는 가볍고 휴대가능한 텍스트 포맷을 가능하게 합니다.\n2. 로컬 저장소: 모든 노트는 플레인 텍스트 파일로 기기에 로컬로 저장되어 데이터 개인 정보 보호 및 소유권을 보장합니다.\n\n\n\n3. 링크 및 그래프 뷰: 옵시디언은 노트 간의 연결을 생성하는 데 뛰어나며, 아이디어 간의 관계를 볼 수 있는 시각적 그래프 뷰를 제공합니다.\n\n\n\n4. 사용자 정의 가능: 앱은 플러그인과 테마를 지원하여 사용자가 필요에 따라 경험을 맞춤 설정할 수 있습니다.\n5. 크로스 플랫폼: Windows, macOS, Linux, iOS, Android에서 사용 가능합니다.\n \n \n  프로그램 장단점\n Obsidian은 사용자의 작업 공간을 최적화하기 위해 다양한 화면 분할 및 고정 기능을 제공합니다. 화면을 무한대로 분할하고 크기를 조절할 수 있어, 여러 노트를 동시에 열어보며 교차 참조를 손쉽게 할 수 있습니다. 특정 노트를 고정하여 해당 내용이 항상 표시되도록 하거나, 서로 다른 노트의 다른 뷰를 보여주는 방식으로 연결할 수도 있습니다. 이러한 기능들은 큰 화면을 사용하는 사용자나, 짧고 핵심적인 노트를 다루는 사용자에게 특히 유용합니다. \n또한, '빠른 전환기' 기능은 키보드만으로도 원하는 노트로 즉시 이동하거나 새 노트를 만들 수 있게 하여, 작업 효율성을 극대화합니다. '명령어 팔레트'를 통해서는 마우스를 사용하지 않고도 모든 기능을 활용할 수 있어, 보다 빠르고 직관적인 작업 흐름을 유지할 수 있습니다. \nObsidian 의 장점과 단점은 다음과 같습니다.\n \n 장점\n1. 강력한 링크 및 지식 관리 기능을 갖추고 있습니다. \n2. 플러그인 및 테마로 고도로 사용자 정의가 가능합니다. \n3. 개인 사용은 무료입니다. \n4. 로컬 저장소는 데이터 개인 정보 보호 및 소유권을 보장합니다. \n5. 빠른 성능과 반응형 인터페이스를 제공합니다.\n 단점\n1. 마크다운에 익숙하지 않은 사람들에게는 배우기가 어렵습니다. \n2. 웹 버전이 없습니다. \n3. 일부 사용자가 매력적이지 않다고 여기는 기본 인터페이스 미학입니다. \n4. 데이터가 로컬에 저장되므로 수동 백업이 필요합니다.\n \n \n \n  라이센스 정책\n Obsidian은 개인 사용에 대해서는 무료로 제공됩니다. 개인적인 노트 작성, 학습, 연구 목적으로 누구나 제한 없이 사용할 수 있습니다. 즉, 개인이 비상업적인 목적으로 노트를 작성하고 관리하는 데 사용하는 경우 별도의 비용을 지불할 필요가 없습니다. \n옵시디언은 아래와 같이 여러 가격 등급을 제공합니다.\n1. 개인 사용: 모든 핵심 기능을 포함하여 무료입니다. \n2. 상업적 사용: 사용자당 연 $50입니다. \n3. 동기화 추가 기능: 기기 간 동기화를 위해 월 $4-$5입니다. \n4. 출판 추가 기능: 웹 출판을 위해 사이트당 월 $8-$10입니다.\n \n \n \n⬇️ 프로그램 다운로드\n \n\n \nObsidian - Sharpen your thinking\nObsidian is the private and flexible note‑taking app that adapts to the way you think.\nobsidian.md",
        "guid": "http://muzbox.tistory.com/483464",
        "categories": [
          "추천 프리웨어/문서,업무",
          "markdown 파일",
          "OBSIDIAN",
          "노트 작성 소프트웨어",
          "데이터 보안",
          "커스터마이징",
          "플러그인",
          "화면 분할"
        ],
        "isoDate": "2024-08-30T02:36:46.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "Hasleo Disk Clone 4.5 PRO 버전 라이센스 무료 제공",
        "link": "http://muzbox.tistory.com/483463",
        "pubDate": "Wed, 28 Aug 2024 11:22:58 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483463#entry483463comment",
        "content": "<p data-ke-size=\"size16\">Hasleo Disk Clone Pro v4.5의 전체 버전을 무료로 얻으세요! 이 강력한 디스크 복제 소프트웨어로 Windows OS와 데이터를 쉽게 복제, 마이그레이션, 백업할 수 있습니다. 이 제한된 기간의 혜택을 놓치지 마세요.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"600\" data-origin-height=\"400\"><span data-url=\"https://blog.kakaocdn.net/dn/cQd2xe/btsJg64hTpF/WdrABJbGO33sCSj5Ky9G40/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/cQd2xe/btsJg64hTpF/WdrABJbGO33sCSj5Ky9G40/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/cQd2xe/btsJg64hTpF/WdrABJbGO33sCSj5Ky9G40/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcQd2xe%2FbtsJg64hTpF%2FWdrABJbGO33sCSj5Ky9G40%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"Hasleo Disk Clone 4.5 PRO 버전 라이센스 무료 제공\" data-origin-width=\"600\" data-origin-height=\"400\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;디스크 복제 소프트웨어는 데이터를 안전하게 유지하면서 시스템 업그레이드나 드라이브 교체를 가능하게 해주는 중요한 도구입니다. 특히, Hasleo Disk Clone Pro v4.5는 복잡한 절차 없이 간편하게 Windows 운영 체제와 데이터를 복제할 수 있는 강력한 솔루션을 제공합니다. 이 소프트웨어를 통해 시스템을 새 드라이브로 마이그레이션하거나, 기존 데이터를 백업하는 작업이 훨씬 쉬워집니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>Hasleo Disk Clone Pro 소개</b></span></h2>\n<p data-ke-size=\"size16\"><b>Hasleo Disk Clone Pro</b>는 Windows 11, 10, 8, 7, Vista 및 Server에서 사용 가능한 올인원 디스크 복제 도구로, 사용자들이 새로운 드라이브로 운영 체제를 복제하거나, 디스크를 다른 디스크로 복사하거나, 파티션을 다른 파티션으로 복사할 수 있도록 도와줍니다. 이 도구는 시스템 업그레이드 중 이전 기기의 데이터를 안전하게 유지하며, 전체 드라이브 또는 파티션을 전송하고 Windows를 쉽게 마이그레이션할 수 있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Hasleo Disk Clone Pro 01.jpg\" data-origin-width=\"720\" data-origin-height=\"521\"><span data-url=\"https://blog.kakaocdn.net/dn/baEpUP/btsJiqG89io/UDSqnmmtXFPl3JO8KVRsjk/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/baEpUP/btsJiqG89io/UDSqnmmtXFPl3JO8KVRsjk/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/baEpUP/btsJiqG89io/UDSqnmmtXFPl3JO8KVRsjk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbaEpUP%2FbtsJiqG89io%2FUDSqnmmtXFPl3JO8KVRsjk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"Hasleo Disk Clone Pro 01.jpg\" data-origin-width=\"720\" data-origin-height=\"521\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><b><span style=\"color: #000000;\"><i>주요 기능 및 장점</i></span></b></h3>\n<p data-ke-size=\"size16\">Hasleo Disk Clone Pro는 사용자가 드라이브 업그레이드를 위해 데이터를 동일하게 복제하거나, 파티션을 변경하지 않고 복사할 수 있는 기능을 제공합니다. 이 과정에서 데이터 손실의 걱정 없이 중요한 파티션의 백업도 가능하며, MBR에서 GPT로, 또는 GPT에서 MBR로 변환할 수 있는 기능도 제공합니다. 이 변환은 데이터 손실 없이 수행되며, 변환 후 Windows가 정상적으로 부팅될 수 있도록 보장합니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Hasleo Disk Clone Pro 03.jpg\" data-origin-width=\"720\" data-origin-height=\"521\"><span data-url=\"https://blog.kakaocdn.net/dn/dUaPxN/btsJiMwqC3A/K5GU5bbYA1KUKOxMeK86N0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/dUaPxN/btsJiMwqC3A/K5GU5bbYA1KUKOxMeK86N0/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/dUaPxN/btsJiMwqC3A/K5GU5bbYA1KUKOxMeK86N0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdUaPxN%2FbtsJiMwqC3A%2FK5GU5bbYA1KUKOxMeK86N0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"Hasleo Disk Clone Pro 03.jpg\" data-origin-width=\"720\" data-origin-height=\"521\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><i><b>GUI의 편리함</b></i></h3>\n<p data-ke-size=\"size16\">Hasleo Disk Clone Pro는 마법사 기반의 그래픽 사용자 인터페이스(GUI)를 제공하여 사용자가 복제 작업을 쉽게 수행할 수 있도록 도와줍니다. 사용자는 소스와 대상, 기타 몇 가지 옵션만 설정하면 복제를 시작할 수 있으며, 복제 전에 파티션을 이동하거나 수정할 수 있는 기능도 제공합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>Hasleo Disk Clone Pro 무료 라이센스 등록방법</b></span></h2>\n<p data-ke-size=\"size16\">Hasleo Disk Clone Pro의 무료 라이선스를 활성화하려면 다음 단계를 따르십시오:</p>\n<ol style=\"list-style-type: decimal;\" data-ke-list-type=\"decimal\">\n<li><b>소프트웨어 다운로드:</b><br />개발자 페이지에서 소프트웨어의 무료 버전을 다운로드합니다.<br /><a href=\"https://www.easyuefi.com/disk-clone/download\" target=\"_blank\" rel=\"noopener\">Hasleo Disk Clone Pro 다운로드</a></li>\n<li><b>소프트웨어 설치 및 실행:</b><br />다운로드한 파일을 설치하고, 설치가 완료되면 소프트웨어를 실행합니다. 실행 후 기본 사용자 인터페이스(UI)가 나타납니다.</li>\n<li><b>메뉴 버튼 찾기:</b><br />UI에서 메뉴 버튼을 찾으십시오. 메뉴 버튼은 아래쪽 화살표가 있는 작은 상자처럼 보입니다.</li>\n<li><b>라이센스 코드 등록:</b><br />드롭다운 메뉴에서 \"등록\"을 선택하고 아래에 제공된 라이센스 코드를 입력합니다:<br /><b>A3TANDZ3-ZATGLVME-QL99LQ7H-X4D7T27P-TJNWZA33-L95HP4ML</b></li>\n<li><b>등록 완료:</b><br />코드를 입력하고 \"Register(등록)\" 버튼을 눌러 라이센스를 활성화합니다.</li>\n</ol>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Hasleo Disk Clone Pro 02.jpg\" data-origin-width=\"1177\" data-origin-height=\"704\"><span data-url=\"https://blog.kakaocdn.net/dn/b6jRIw/btsJhCaFjN2/1PstUEFkBj3jdxcaCiyHI1/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/b6jRIw/btsJhCaFjN2/1PstUEFkBj3jdxcaCiyHI1/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/b6jRIw/btsJhCaFjN2/1PstUEFkBj3jdxcaCiyHI1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb6jRIw%2FbtsJhCaFjN2%2F1PstUEFkBj3jdxcaCiyHI1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"Hasleo Disk Clone Pro 02.jpg\" data-origin-width=\"1177\" data-origin-height=\"704\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>마치며</b></span></h2>\n<p data-ke-size=\"size16\">Hasleo Disk Clone Pro는 Windows 운영 체제와 데이터를 안전하게 복제하고 마이그레이션할 수 있는 필수 도구입니다. 이번 기회를 놓치지 말고, 무료 라이선스를 통해 이 강력한 소프트웨어를 경험해 보세요. 시스템 업그레이드, 데이터 보호, 디스크 변환 등 다양한 작업을 간편하게 수행할 수 있습니다.</p>",
        "contentSnippet": "Hasleo Disk Clone Pro v4.5의 전체 버전을 무료로 얻으세요! 이 강력한 디스크 복제 소프트웨어로 Windows OS와 데이터를 쉽게 복제, 마이그레이션, 백업할 수 있습니다. 이 제한된 기간의 혜택을 놓치지 마세요.\n\n\n \n 디스크 복제 소프트웨어는 데이터를 안전하게 유지하면서 시스템 업그레이드나 드라이브 교체를 가능하게 해주는 중요한 도구입니다. 특히, Hasleo Disk Clone Pro v4.5는 복잡한 절차 없이 간편하게 Windows 운영 체제와 데이터를 복제할 수 있는 강력한 솔루션을 제공합니다. 이 소프트웨어를 통해 시스템을 새 드라이브로 마이그레이션하거나, 기존 데이터를 백업하는 작업이 훨씬 쉬워집니다.\n \n \nHasleo Disk Clone Pro 소개\nHasleo Disk Clone Pro는 Windows 11, 10, 8, 7, Vista 및 Server에서 사용 가능한 올인원 디스크 복제 도구로, 사용자들이 새로운 드라이브로 운영 체제를 복제하거나, 디스크를 다른 디스크로 복사하거나, 파티션을 다른 파티션으로 복사할 수 있도록 도와줍니다. 이 도구는 시스템 업그레이드 중 이전 기기의 데이터를 안전하게 유지하며, 전체 드라이브 또는 파티션을 전송하고 Windows를 쉽게 마이그레이션할 수 있습니다.\n\n\n \n \n주요 기능 및 장점\nHasleo Disk Clone Pro는 사용자가 드라이브 업그레이드를 위해 데이터를 동일하게 복제하거나, 파티션을 변경하지 않고 복사할 수 있는 기능을 제공합니다. 이 과정에서 데이터 손실의 걱정 없이 중요한 파티션의 백업도 가능하며, MBR에서 GPT로, 또는 GPT에서 MBR로 변환할 수 있는 기능도 제공합니다. 이 변환은 데이터 손실 없이 수행되며, 변환 후 Windows가 정상적으로 부팅될 수 있도록 보장합니다.\n\n\n \n \nGUI의 편리함\nHasleo Disk Clone Pro는 마법사 기반의 그래픽 사용자 인터페이스(GUI)를 제공하여 사용자가 복제 작업을 쉽게 수행할 수 있도록 도와줍니다. 사용자는 소스와 대상, 기타 몇 가지 옵션만 설정하면 복제를 시작할 수 있으며, 복제 전에 파티션을 이동하거나 수정할 수 있는 기능도 제공합니다.\n \n \n \nHasleo Disk Clone Pro 무료 라이센스 등록방법\nHasleo Disk Clone Pro의 무료 라이선스를 활성화하려면 다음 단계를 따르십시오:\n소프트웨어 다운로드:\n개발자 페이지에서 소프트웨어의 무료 버전을 다운로드합니다.\nHasleo Disk Clone Pro 다운로드\n소프트웨어 설치 및 실행:\n다운로드한 파일을 설치하고, 설치가 완료되면 소프트웨어를 실행합니다. 실행 후 기본 사용자 인터페이스(UI)가 나타납니다.\n메뉴 버튼 찾기:\nUI에서 메뉴 버튼을 찾으십시오. 메뉴 버튼은 아래쪽 화살표가 있는 작은 상자처럼 보입니다.\n라이센스 코드 등록:\n드롭다운 메뉴에서 \"등록\"을 선택하고 아래에 제공된 라이센스 코드를 입력합니다:\nA3TANDZ3-ZATGLVME-QL99LQ7H-X4D7T27P-TJNWZA33-L95HP4ML\n등록 완료:\n코드를 입력하고 \"Register(등록)\" 버튼을 눌러 라이센스를 활성화합니다.\n\n\n \n \n마치며\nHasleo Disk Clone Pro는 Windows 운영 체제와 데이터를 안전하게 복제하고 마이그레이션할 수 있는 필수 도구입니다. 이번 기회를 놓치지 말고, 무료 라이선스를 통해 이 강력한 소프트웨어를 경험해 보세요. 시스템 업그레이드, 데이터 보호, 디스크 변환 등 다양한 작업을 간편하게 수행할 수 있습니다.",
        "guid": "http://muzbox.tistory.com/483463",
        "categories": [
          "NEWS/윈도우10 한시적 무료앱",
          "hasleo disk clone pro",
          "windows 복제",
          "데이터 백업",
          "디스크 복제",
          "무료 라이선스",
          "운영 체제 마이그레이션",
          "파티션 복사"
        ],
        "isoDate": "2024-08-28T02:22:58.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "윈도우용 추천 프리웨어 (2024.8.26) 모니터밝기조절, 파일관리, Linux에뮬레이션, CAD뷰어, 데이터시각화, 프로젝트관리",
        "link": "http://muzbox.tistory.com/483462",
        "pubDate": "Mon, 26 Aug 2024 08:37:38 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483462#entry483462comment",
        "content": "<p style=\"text-align: left;\" data-ke-size=\"size18\"><span style=\"background-color: #ffffff; color: #0d0d0d; text-align: start;\">&nbsp;네이버 소프트웨어와 같은 프로그램 소개 사이트가 종료된 후, 윈도우 운영체제를 사용하는 이용자들을 위해 공개 프리웨어 및 오픈소스 프로그램을 소개합니다. 유용한 무료 소프트웨어를 찾고자 하는 사용자들에게 정기적으로 알찬 정보를 제공합니다.</span></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"freeware.png\" data-origin-width=\"500\" data-origin-height=\"500\"><span data-url=\"https://blog.kakaocdn.net/dn/l9JVa/btsJe7uOawY/WatS3qwKv992v68b9uBeE0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/l9JVa/btsJe7uOawY/WatS3qwKv992v68b9uBeE0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/l9JVa/btsJe7uOawY/WatS3qwKv992v68b9uBeE0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fl9JVa%2FbtsJe7uOawY%2FWatS3qwKv992v68b9uBeE0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"윈도우용 추천 프리웨어 (2024.8.26)\" data-filename=\"freeware.png\" data-origin-width=\"500\" data-origin-height=\"500\"/></span></figure>\n</p>\n<p style=\"text-align: left;\" data-ke-size=\"size18\">&nbsp;</p>\n<p style=\"text-align: left;\" data-ke-size=\"size18\"><span style=\"color: #333333; text-align: left;\">&nbsp;윈도우용 응용프로그램 (Application)은 수없이 많은 종류가 많은 개발자들에 의해 하루에도 수백,수천개가 새로 출시되고 그보다 더 많은 수의 프로그램들이 업데이트 됩니다. 이들 응용프로그램 (Application)은 비율을 지불해야하는<span>&nbsp;</span></span><b><span style=\"color: #009a87;\">상용프로그램</span></b><span style=\"color: #333333; text-align: left;\">과 정품 구매를 확대하기 위해 공급하는 일종의 샘플 개념의<span>&nbsp;</span></span><span style=\"color: #ee2323;\"><b>쉐어웨어</b></span><span style=\"color: #333333; text-align: left;\">, 무료로 사용할 수 있는<span>&nbsp;</span></span><b><span style=\"color: #ef6f53;\">프리웨어</span></b>등으로 크게 3가지로 나뉘게 되는데요.</p>\n<p style=\"text-align: left;\" data-ke-size=\"size18\"><br />&nbsp;물론 프리웨어에도 개인만 사용할 있다던가, 기업이나 관공서에서도 사용이 가능하다던가, 소스까지 같이 공개하여 맘대로 수정과 배포가 가능한 완전 무료등의 추가 분류가 필요합니다. 하지만, 개발자가 공개하는 무료배포의 의미가 정확하지 않는 프로그램도 많고, 저작권의 정의도 각양각색이라 본 블로그에서 소개하는 프리웨어도 <span style=\"color: #006dd7;\"><b>최대한 확인이 가능한 범위에서 개인 또는 기업에서 사용가능한지를 구분하여 소개</b></span>하고 있습니다.</p>\n<p style=\"text-align: left;\" data-ke-size=\"size18\">&nbsp;</p>\n<p style=\"text-align: left;\" data-ke-size=\"size18\">&nbsp;</p>\n<p style=\"text-align: center;\" data-ke-size=\"size18\">'어떤오후의 프리웨어 이야기'에서 추천하는<br /><span style=\"color: #409d00;\">&nbsp;<b>2024년 8월 26일자 공개자료실 윈도우용 추천 프리웨어</b></span>입니다.</p>\n<p id=\"no_1\" data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><i><b>1. Bright Master (트레이 아이콘에서 휠 회전으로 모니터 밝기 조정)<br /></b></i></span></h2>\n<p data-ke-size=\"size18\">&nbsp; 설치가&nbsp;필요&nbsp;없는&nbsp;모니터&nbsp;밝기&nbsp;조절&nbsp;도구입니다. <br />DDC/CI를&nbsp;지원하는&nbsp;외부&nbsp;모니터와&nbsp;WMI&nbsp;서비스가&nbsp;비활성화되지&nbsp;않은&nbsp;노트북,&nbsp;올인원&nbsp;PC,&nbsp;윈도우&nbsp;태블릿의&nbsp;내장&nbsp;디스플레이에서&nbsp;작동합니다. <br />주요&nbsp;기능으로는&nbsp;모든&nbsp;기기의&nbsp;동기화된&nbsp;밝기&nbsp;변경,&nbsp;제3자&nbsp;소프트웨어에&nbsp;의한&nbsp;밝기&nbsp;변경&nbsp;추적,&nbsp;디지털&nbsp;밝기&nbsp;표시,&nbsp;자동&nbsp;시작,&nbsp;마우스&nbsp;휠을&nbsp;이용한&nbsp;밝기&nbsp;조절,&nbsp;밝기&nbsp;조절&nbsp;단계&nbsp;선택,&nbsp;한&nbsp;번의&nbsp;클릭으로&nbsp;최소&nbsp;밝기&nbsp;설정&nbsp;등이&nbsp;있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Bright Master.png\" data-origin-width=\"504\" data-origin-height=\"304\"><span data-url=\"https://blog.kakaocdn.net/dn/CCuKC/btsJfiXcAQ5/hkfwcbBPBrbsN3fro1pF70/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/CCuKC/btsJfiXcAQ5/hkfwcbBPBrbsN3fro1pF70/img.png\"><img src=\"https://blog.kakaocdn.net/dn/CCuKC/btsJfiXcAQ5/hkfwcbBPBrbsN3fro1pF70/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FCCuKC%2FbtsJfiXcAQ5%2FhkfwcbBPBrbsN3fro1pF70%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"Bright Master.png\" data-origin-width=\"504\" data-origin-height=\"304\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">▶프리웨어 - 개인</p>\n<p data-ke-size=\"size18\">▶ Windows 10/11</p>\n<p data-ke-size=\"size18\">▶무료 다운로드◀</p>\n<figure id=\"og_1724628763665\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"Bright Master / Screen dimmer\" data-og-description=\"Ru Bright Master Simple screen dimmer The program is designed to adjust the brightness of monitors, laptop displays and other equipment. Runs on Windows 7+ and does not require installation. Works with all external monitors that have DDC/CI support, as wel\" data-og-host=\"brightmaster.ru\" data-og-source-url=\"https://brightmaster.ru/en\" data-og-url=\"https://brightmaster.ru/en\" data-og-image=\"\"><a href=\"https://brightmaster.ru/en\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://brightmaster.ru/en\">\n<div class=\"og-image\" style=\"background-image: url();\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">Bright Master / Screen dimmer</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">Ru Bright Master Simple screen dimmer The program is designed to adjust the brightness of monitors, laptop displays and other equipment. Runs on Windows 7+ and does not require installation. Works with all external monitors that have DDC/CI support, as wel</p>\n<p class=\"og-host\" data-ke-size=\"size16\">brightmaster.ru</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"no_2\" data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><i><b>2. Cygwin (Linux 기능을 사용할 수 있는 유연한 에뮬레이션 도구)</b></i></span></h2>\n<p data-ke-size=\"size18\">&nbsp; Windows&nbsp;사용자가&nbsp;Linux의&nbsp;기능을&nbsp;경험할&nbsp;수&nbsp;있게&nbsp;해주는&nbsp;에뮬레이션&nbsp;레이어입니다. <br />사용자는&nbsp;원하는&nbsp;Linux&nbsp;기능을&nbsp;선택하여&nbsp;설치할&nbsp;수&nbsp;있으며,&nbsp;프로그램은&nbsp;사용자&nbsp;친화적이고&nbsp;잘&nbsp;조직된&nbsp;구조를&nbsp;가지고&nbsp;있습니다.&nbsp;오디오&nbsp;드라이버,&nbsp;그래픽&nbsp;소프트웨어,&nbsp;LXDE,&nbsp;GNOME,&nbsp;KDE&nbsp;등&nbsp;다양한&nbsp;Linux&nbsp;기능을&nbsp;제공합니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Cygwin.png\" data-origin-width=\"1083\" data-origin-height=\"668\"><span data-url=\"https://blog.kakaocdn.net/dn/b2AN3z/btsJfGXIURN/NeV5FdKmPcffTyNmWppCfk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/b2AN3z/btsJfGXIURN/NeV5FdKmPcffTyNmWppCfk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/b2AN3z/btsJfGXIURN/NeV5FdKmPcffTyNmWppCfk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb2AN3z%2FbtsJfGXIURN%2FNeV5FdKmPcffTyNmWppCfk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"Cygwin.png\" data-origin-width=\"1083\" data-origin-height=\"668\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">▶프리웨어 - 개인/기업(오픈소스)</p>\n<p data-ke-size=\"size18\">▶Windows 10/11</p>\n<p data-ke-size=\"size18\">▶무료 다운로드 ◀</p>\n<figure id=\"og_1724628796923\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"Cygwin\" data-og-description=\"Cygwin Get that Linux feeling - on Windows This is the home of the Cygwin project What... ...is it? Cygwin is: a large collection of GNU and Open Source tools which provide functionality similar to a Linux distribution on Windows. a DLL (cygwin1.dll) which\" data-og-host=\"www.cygwin.com\" data-og-source-url=\"https://www.cygwin.com/\" data-og-url=\"https://www.cygwin.com/\" data-og-image=\"\"><a href=\"https://www.cygwin.com/\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://www.cygwin.com/\">\n<div class=\"og-image\" style=\"background-image: url();\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">Cygwin</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">Cygwin Get that Linux feeling - on Windows This is the home of the Cygwin project What... ...is it? Cygwin is: a large collection of GNU and Open Source tools which provide functionality similar to a Linux distribution on Windows. a DLL (cygwin1.dll) which</p>\n<p class=\"og-host\" data-ke-size=\"size16\">www.cygwin.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"no_3\" data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><i><b>3. Rename Master (다기능적인&nbsp;파일&nbsp;이름&nbsp;변경&nbsp;솔루션)</b></i></span></h2>\n<p data-ke-size=\"size18\">&nbsp;사용자가&nbsp;다양한&nbsp;도구를&nbsp;통해&nbsp;파일&nbsp;이름을&nbsp;효율적이고&nbsp;접근하기&nbsp;쉽게&nbsp;변경할&nbsp;수&nbsp;있게&nbsp;해주는&nbsp;프로그램입니다.&nbsp;주요&nbsp;기능은&nbsp;'Renaming&nbsp;Script'&nbsp;탭에서&nbsp;찾을&nbsp;수&nbsp;있으며,&nbsp;단어/숫자&nbsp;제거,&nbsp;표현&nbsp;변경,&nbsp;기존&nbsp;이름&nbsp;교체,&nbsp;카운터&nbsp;추가&nbsp;등&nbsp;다양한&nbsp;옵션을&nbsp;제공합니다. <br />프로그램은&nbsp;일반&nbsp;사용자를&nbsp;위한&nbsp;기본&nbsp;기능뿐만&nbsp;아니라&nbsp;고급&nbsp;사용자를&nbsp;위한&nbsp;'Textfile&nbsp;Wizard'&nbsp;같은&nbsp;기능도&nbsp;제공합니다.&nbsp;전반적으로&nbsp;Rename&nbsp;Master는&nbsp;사용하기&nbsp;쉬우면서도&nbsp;고급&nbsp;사용자를&nbsp;위한&nbsp;충분한&nbsp;구성&nbsp;옵션을&nbsp;제공하는&nbsp;신뢰할&nbsp;수&nbsp;있는&nbsp;종합&nbsp;솔루션입니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Rename Master.png\" data-origin-width=\"1030\" data-origin-height=\"647\"><span data-url=\"https://blog.kakaocdn.net/dn/vUqbY/btsJfElmKdd/sEbM4woMxpjLG6fgE8TpTk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/vUqbY/btsJfElmKdd/sEbM4woMxpjLG6fgE8TpTk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/vUqbY/btsJfElmKdd/sEbM4woMxpjLG6fgE8TpTk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FvUqbY%2FbtsJfElmKdd%2FsEbM4woMxpjLG6fgE8TpTk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"Rename Master.png\" data-origin-width=\"1030\" data-origin-height=\"647\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">▶프리웨어 - 개인</p>\n<p data-ke-size=\"size18\">▶Windows 10/11&nbsp;</p>\n<p data-ke-size=\"size18\">▶무료 다운로드 ◀</p>\n<figure id=\"og_1724628842166\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"JoeJoe's freeware utilities - [Rename Master]\" data-og-description=\"Rename Master is a freeware utility designed to rename multiple files with a just few clicks. Anyone that has worked with websites, file archives, or collections of music, videos, or pictures has probably spent way too much time renaming hundreds of files.\" data-og-host=\"www.joejoesoft.com\" data-og-source-url=\"https://www.joejoesoft.com/vcms/108/\" data-og-url=\"https://www.joejoesoft.com/vcms/108/\" data-og-image=\"\"><a href=\"https://www.joejoesoft.com/vcms/108/\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://www.joejoesoft.com/vcms/108/\">\n<div class=\"og-image\" style=\"background-image: url();\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">JoeJoe's freeware utilities - [Rename Master]</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">Rename Master is a freeware utility designed to rename multiple files with a just few clicks. Anyone that has worked with websites, file archives, or collections of music, videos, or pictures has probably spent way too much time renaming hundreds of files.</p>\n<p class=\"og-host\" data-ke-size=\"size16\">www.joejoesoft.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"no_4\" data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><i><b>4. VariCAD Viewer (다기능&nbsp;CAD&nbsp;파일&nbsp;뷰어)<br /></b></i></span></h2>\n<p data-ke-size=\"size18\">&nbsp;단순히&nbsp;CAD&nbsp;도면을&nbsp;보는&nbsp;것&nbsp;이상의&nbsp;기능을&nbsp;제공합니다.&nbsp;2D&nbsp;DWG,&nbsp;3D&nbsp;STEP,&nbsp;2D/3D&nbsp;VariCAD&nbsp;등&nbsp;다양한&nbsp;형식의&nbsp;파일을&nbsp;지원하며,&nbsp;간단한&nbsp;조정과&nbsp;인쇄&nbsp;기능도&nbsp;갖추고&nbsp;있습니다.&nbsp;이&nbsp;프로그램은&nbsp;3D&nbsp;모델링에&nbsp;대해&nbsp;잘&nbsp;아는&nbsp;전문가들을&nbsp;위해&nbsp;설계되었습니다.</p>\n<p data-ke-size=\"size18\">&nbsp;인터페이스는 현대적이지만 다양한 기능으로 인해 다소 복잡해 보일 수 있습니다. 그러나 CAD 경험이 있는 사용자라면 직관적으로 사용할 수 있을 것입니다. 도구 모음의 배치를 사용자가 원하는 대로 조정할 수 있는 것도 장점입니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"VariCAD Viewer.png\" data-origin-width=\"1360\" data-origin-height=\"757\"><span data-url=\"https://blog.kakaocdn.net/dn/Zxvkp/btsJeQ7R4Ia/5zkpqgQItCCEUbKkidGFhk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/Zxvkp/btsJeQ7R4Ia/5zkpqgQItCCEUbKkidGFhk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/Zxvkp/btsJeQ7R4Ia/5zkpqgQItCCEUbKkidGFhk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FZxvkp%2FbtsJeQ7R4Ia%2F5zkpqgQItCCEUbKkidGFhk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"VariCAD Viewer.png\" data-origin-width=\"1360\" data-origin-height=\"757\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">▶프리웨어 - 개인</p>\n<p data-ke-size=\"size18\">▶Windows 10/11</p>\n<p data-ke-size=\"size18\">▶무료 다운로드 ◀</p>\n<figure id=\"og_1724628874152\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"Products | VariCAD - 3D/2D CAD system\" data-og-description=\"Products VariCAD - 3D / 2D mechanical CAD software We have a simple strategy - to sell VariCAD, with all its features, for one very affordable price. VariCAD is the best value you will find anywhere for this type of modeling and designing software. VariCAD\" data-og-host=\"www.varicad.com\" data-og-source-url=\"https://www.varicad.com/en/home/products/products/\" data-og-url=\"https://www.varicad.com/en/home/products/products/\" data-og-image=\"\"><a href=\"https://www.varicad.com/en/home/products/products/\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://www.varicad.com/en/home/products/products/\">\n<div class=\"og-image\" style=\"background-image: url();\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">Products | VariCAD - 3D/2D CAD system</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">Products VariCAD - 3D / 2D mechanical CAD software We have a simple strategy - to sell VariCAD, with all its features, for one very affordable price. VariCAD is the best value you will find anywhere for this type of modeling and designing software. VariCAD</p>\n<p class=\"og-host\" data-ke-size=\"size16\">www.varicad.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"no_5\" data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><i><b>5. TreeSheets (다목적 데이터 조직화 및 시각화 도구)</b></i></span></h2>\n<p data-ke-size=\"size18\">&nbsp; 스프레드시트,&nbsp;마인드맵,&nbsp;노트&nbsp;애플리케이션의&nbsp;기능을&nbsp;하나의&nbsp;사용하기&nbsp;쉬운&nbsp;인터페이스로&nbsp;결합한&nbsp;프로그램입니다.&nbsp;복잡한&nbsp;데이터&nbsp;구조를&nbsp;쉽게&nbsp;다룰&nbsp;수&nbsp;있는&nbsp;것이&nbsp;주요&nbsp;특징입니다.</p>\n<p data-ke-size=\"size18\"><br />이&nbsp;프로그램은&nbsp;프로젝트&nbsp;관리,&nbsp;일정&nbsp;계획,&nbsp;브레인스토밍,&nbsp;할&nbsp;일&nbsp;목록&nbsp;작성&nbsp;등&nbsp;다양한&nbsp;용도로&nbsp;사용할&nbsp;수&nbsp;있습니다.&nbsp;사용자는&nbsp;데이터를&nbsp;계층적&nbsp;트리,&nbsp;스프레드시트&nbsp;그리드,&nbsp;마인드맵&nbsp;등&nbsp;다양한&nbsp;형태로&nbsp;시각화할&nbsp;수&nbsp;있습니다. <br />또한&nbsp;색상과&nbsp;테두리&nbsp;등을&nbsp;사용자&nbsp;지정하여&nbsp;시트의&nbsp;외관을&nbsp;개선할&nbsp;수&nbsp;있으며,&nbsp;작업을&nbsp;우선순위화하고&nbsp;마감일을&nbsp;설정하는&nbsp;등의&nbsp;기능을&nbsp;통해&nbsp;생산성을&nbsp;높일&nbsp;수&nbsp;있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"TreeSheets.png\" data-origin-width=\"1149\" data-origin-height=\"761\"><span data-url=\"https://blog.kakaocdn.net/dn/bareS8/btsJelm7E7B/nMJiF5wlkyZskOHMQ57w20/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bareS8/btsJelm7E7B/nMJiF5wlkyZskOHMQ57w20/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bareS8/btsJelm7E7B/nMJiF5wlkyZskOHMQ57w20/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbareS8%2FbtsJelm7E7B%2FnMJiF5wlkyZskOHMQ57w20%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"TreeSheets.png\" data-origin-width=\"1149\" data-origin-height=\"761\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">▶프리웨어 - 개인/기업 (오픈소스)</p>\n<p data-ke-size=\"size18\">▶Windows 10/11</p>\n<p data-ke-size=\"size18\">▶무료 다운로드 ◀</p>\n<figure id=\"og_1724628900387\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"TreeSheets\" data-og-description=\"Open Source Free Form Data Organizer (Hierarchical Spreadsheet) D O W N L O A D : Download LATEST from github releases: Windows / OS X / Linux Click HERE, pick your platform from the latest release. &nbsp; A &quot;hierarchical spreadsheet&quot; that is a great replaceme\" data-og-host=\"strlen.com\" data-og-source-url=\"https://strlen.com/treesheets/\" data-og-url=\"https://strlen.com/treesheets/\" data-og-image=\"https://scrap.kakaocdn.net/dn/bndYPd/hyWSfzKILl/YLEhMi5yuQXXxgdNMPthdk/img.png?width=607&amp;height=498&amp;face=0_0_607_498\"><a href=\"https://strlen.com/treesheets/\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://strlen.com/treesheets/\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/bndYPd/hyWSfzKILl/YLEhMi5yuQXXxgdNMPthdk/img.png?width=607&amp;height=498&amp;face=0_0_607_498');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">TreeSheets</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">Open Source Free Form Data Organizer (Hierarchical Spreadsheet) D O W N L O A D : Download LATEST from github releases: Windows / OS X / Linux Click HERE, pick your platform from the latest release. &nbsp; A \"hierarchical spreadsheet\" that is a great replaceme</p>\n<p class=\"og-host\" data-ke-size=\"size16\">strlen.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "네이버 소프트웨어와 같은 프로그램 소개 사이트가 종료된 후, 윈도우 운영체제를 사용하는 이용자들을 위해 공개 프리웨어 및 오픈소스 프로그램을 소개합니다. 유용한 무료 소프트웨어를 찾고자 하는 사용자들에게 정기적으로 알찬 정보를 제공합니다.\n\n\n \n 윈도우용 응용프로그램 (Application)은 수없이 많은 종류가 많은 개발자들에 의해 하루에도 수백,수천개가 새로 출시되고 그보다 더 많은 수의 프로그램들이 업데이트 됩니다. 이들 응용프로그램 (Application)은 비율을 지불해야하는 상용프로그램과 정품 구매를 확대하기 위해 공급하는 일종의 샘플 개념의 쉐어웨어, 무료로 사용할 수 있는 프리웨어등으로 크게 3가지로 나뉘게 되는데요.\n 물론 프리웨어에도 개인만 사용할 있다던가, 기업이나 관공서에서도 사용이 가능하다던가, 소스까지 같이 공개하여 맘대로 수정과 배포가 가능한 완전 무료등의 추가 분류가 필요합니다. 하지만, 개발자가 공개하는 무료배포의 의미가 정확하지 않는 프로그램도 많고, 저작권의 정의도 각양각색이라 본 블로그에서 소개하는 프리웨어도 최대한 확인이 가능한 범위에서 개인 또는 기업에서 사용가능한지를 구분하여 소개하고 있습니다.\n \n \n'어떤오후의 프리웨어 이야기'에서 추천하는\n 2024년 8월 26일자 공개자료실 윈도우용 추천 프리웨어입니다.\n \n \n1. Bright Master (트레이 아이콘에서 휠 회전으로 모니터 밝기 조정)\n\n  설치가 필요 없는 모니터 밝기 조절 도구입니다. \nDDC/CI를 지원하는 외부 모니터와 WMI 서비스가 비활성화되지 않은 노트북, 올인원 PC, 윈도우 태블릿의 내장 디스플레이에서 작동합니다. \n주요 기능으로는 모든 기기의 동기화된 밝기 변경, 제3자 소프트웨어에 의한 밝기 변경 추적, 디지털 밝기 표시, 자동 시작, 마우스 휠을 이용한 밝기 조절, 밝기 조절 단계 선택, 한 번의 클릭으로 최소 밝기 설정 등이 있습니다.\n\n\n▶프리웨어 - 개인\n▶ Windows 10/11\n▶무료 다운로드◀\n\n \nBright Master / Screen dimmer\nRu Bright Master Simple screen dimmer The program is designed to adjust the brightness of monitors, laptop displays and other equipment. Runs on Windows 7+ and does not require installation. Works with all external monitors that have DDC/CI support, as wel\nbrightmaster.ru\n\n \n \n \n \n \n \n2. Cygwin (Linux 기능을 사용할 수 있는 유연한 에뮬레이션 도구)\n  Windows 사용자가 Linux의 기능을 경험할 수 있게 해주는 에뮬레이션 레이어입니다. \n사용자는 원하는 Linux 기능을 선택하여 설치할 수 있으며, 프로그램은 사용자 친화적이고 잘 조직된 구조를 가지고 있습니다. 오디오 드라이버, 그래픽 소프트웨어, LXDE, GNOME, KDE 등 다양한 Linux 기능을 제공합니다.\n\n\n▶프리웨어 - 개인/기업(오픈소스)\n▶Windows 10/11\n▶무료 다운로드 ◀\n\n \nCygwin\nCygwin Get that Linux feeling - on Windows This is the home of the Cygwin project What... ...is it? Cygwin is: a large collection of GNU and Open Source tools which provide functionality similar to a Linux distribution on Windows. a DLL (cygwin1.dll) which\nwww.cygwin.com\n\n \n \n \n \n \n \n3. Rename Master (다기능적인 파일 이름 변경 솔루션)\n 사용자가 다양한 도구를 통해 파일 이름을 효율적이고 접근하기 쉽게 변경할 수 있게 해주는 프로그램입니다. 주요 기능은 'Renaming Script' 탭에서 찾을 수 있으며, 단어/숫자 제거, 표현 변경, 기존 이름 교체, 카운터 추가 등 다양한 옵션을 제공합니다. \n프로그램은 일반 사용자를 위한 기본 기능뿐만 아니라 고급 사용자를 위한 'Textfile Wizard' 같은 기능도 제공합니다. 전반적으로 Rename Master는 사용하기 쉬우면서도 고급 사용자를 위한 충분한 구성 옵션을 제공하는 신뢰할 수 있는 종합 솔루션입니다.\n\n\n▶프리웨어 - 개인\n▶Windows 10/11 \n▶무료 다운로드 ◀\n\n \nJoeJoe's freeware utilities - [Rename Master]\nRename Master is a freeware utility designed to rename multiple files with a just few clicks. Anyone that has worked with websites, file archives, or collections of music, videos, or pictures has probably spent way too much time renaming hundreds of files.\nwww.joejoesoft.com\n\n \n \n \n \n \n \n4. VariCAD Viewer (다기능 CAD 파일 뷰어)\n\n 단순히 CAD 도면을 보는 것 이상의 기능을 제공합니다. 2D DWG, 3D STEP, 2D/3D VariCAD 등 다양한 형식의 파일을 지원하며, 간단한 조정과 인쇄 기능도 갖추고 있습니다. 이 프로그램은 3D 모델링에 대해 잘 아는 전문가들을 위해 설계되었습니다.\n 인터페이스는 현대적이지만 다양한 기능으로 인해 다소 복잡해 보일 수 있습니다. 그러나 CAD 경험이 있는 사용자라면 직관적으로 사용할 수 있을 것입니다. 도구 모음의 배치를 사용자가 원하는 대로 조정할 수 있는 것도 장점입니다.\n\n\n▶프리웨어 - 개인\n▶Windows 10/11\n▶무료 다운로드 ◀\n\n \nProducts | VariCAD - 3D/2D CAD system\nProducts VariCAD - 3D / 2D mechanical CAD software We have a simple strategy - to sell VariCAD, with all its features, for one very affordable price. VariCAD is the best value you will find anywhere for this type of modeling and designing software. VariCAD\nwww.varicad.com\n\n \n \n \n \n \n \n5. TreeSheets (다목적 데이터 조직화 및 시각화 도구)\n  스프레드시트, 마인드맵, 노트 애플리케이션의 기능을 하나의 사용하기 쉬운 인터페이스로 결합한 프로그램입니다. 복잡한 데이터 구조를 쉽게 다룰 수 있는 것이 주요 특징입니다.\n이 프로그램은 프로젝트 관리, 일정 계획, 브레인스토밍, 할 일 목록 작성 등 다양한 용도로 사용할 수 있습니다. 사용자는 데이터를 계층적 트리, 스프레드시트 그리드, 마인드맵 등 다양한 형태로 시각화할 수 있습니다. \n또한 색상과 테두리 등을 사용자 지정하여 시트의 외관을 개선할 수 있으며, 작업을 우선순위화하고 마감일을 설정하는 등의 기능을 통해 생산성을 높일 수 있습니다.\n\n\n▶프리웨어 - 개인/기업 (오픈소스)\n▶Windows 10/11\n▶무료 다운로드 ◀\n\n \nTreeSheets\nOpen Source Free Form Data Organizer (Hierarchical Spreadsheet) D O W N L O A D : Download LATEST from github releases: Windows / OS X / Linux Click HERE, pick your platform from the latest release.   A \"hierarchical spreadsheet\" that is a great replaceme\nstrlen.com",
        "guid": "http://muzbox.tistory.com/483462",
        "categories": [
          "NEWS/프리웨어 뉴스",
          "cad뷰어",
          "linux에뮬레이션",
          "기업무료프로그램",
          "데이터시각화",
          "모니터밝기조절",
          "무료프로그램",
          "추천프로그램",
          "파일관리",
          "프로젝트관리",
          "프리웨어"
        ],
        "isoDate": "2024-08-25T23:37:38.000Z"
      }
    ]
  },
  {
    "name": "동우리의 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "하테나",
    "category": "개인",
    "posts": []
  },
  {
    "name": "늑돌이네 라지온",
    "category": "개인",
    "posts": [
      {
        "creator": "늑돌이",
        "title": "한국 이북리더 명맥 잇나? 예스24 크레마 페블 예약판매",
        "link": "https://lazion.com/2513722",
        "pubDate": "Tue, 27 Aug 2024 18:45:01 +0900",
        "author": "늑돌이",
        "comments": "https://lazion.com/2513722#entry2513722comment",
        "content": "<h3 data-ke-size=\"size23\">예스24(YES24)에서 새로운 6인치 이북 리더 <b>크레마 페블(Crema&nbsp;Pebble)</b> 예약판매를 시작합니다.</h3>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #006dd7;\"><b>크레마 페블, 달라진 점</b></span><span style=\"color: #006dd7;\"></span></h3>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"1846260943_20240827112408_4712478486_web.jpg\" data-origin-width=\"3000\" data-origin-height=\"1688\"><span data-url=\"https://blog.kakaocdn.net/dn/cg9Fgs/btsJgIoRoqA/UkFx6aQKEKzdt1rPnjoKxk/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/cg9Fgs/btsJgIoRoqA/UkFx6aQKEKzdt1rPnjoKxk/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/cg9Fgs/btsJgIoRoqA/UkFx6aQKEKzdt1rPnjoKxk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fcg9Fgs%2FbtsJgIoRoqA%2FUkFx6aQKEKzdt1rPnjoKxk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"1846260943_20240827112408_4712478486_web.jpg\" data-origin-width=\"3000\" data-origin-height=\"1688\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">6인치 화면 크기에 전작인 크레마 모티프에서 51g 경량화한 <b>139g의 무게</b>로 같은 화면 크기의 이북 리더 가운데에는 가장 가벼운 이 제품은 손에 착 감기는 그립감과 함께 조약돌(Pebble)처럼 부드러운 외관을 자랑합니다. </p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">1448x1072 해상도의 카르타(Carta) 6인치 e-ink 패널과 쿼드코어 프로세서, 안드로이드 11 OS를 가지고 있으며 구글 플레이도 지원합니다. RAM은 전작보다 1GB 늘어난 4GB로 더 쾌적한 반응 속도를 제공합니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"upgradeDef01.jpg\" data-origin-width=\"430\" data-origin-height=\"409\"><span data-url=\"https://blog.kakaocdn.net/dn/s3qtj/btsJioPQqLt/VjLIqkNvbj6Gcvb3FkC0C0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/s3qtj/btsJioPQqLt/VjLIqkNvbj6Gcvb3FkC0C0/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/s3qtj/btsJioPQqLt/VjLIqkNvbj6Gcvb3FkC0C0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fs3qtj%2FbtsJioPQqLt%2FVjLIqkNvbj6Gcvb3FkC0C0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"upgradeDef01.jpg\" data-origin-width=\"430\" data-origin-height=\"409\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">색상은 하양과 까망 2종이며 기본 저장소로 32GB 내장, 마이크로SD 슬롯을 통해 최대 512GB까지 확장 가능합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #006dd7;\"><b>크레마 페블 가격과 예약판매 이벤트</b></span></h3>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><b>크레마 페블 본체의 가격은 21만9천원</b>이며, 액세서리와 함께 파는 패키지도 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">예스24는 크레마 페블 출시를 기념하여 <a href=\"http://app.ac/HqpJYK203\" target=\"_blank\" rel=\"noopener\"><b>예약판매 이벤트</b>도 진행</a>합니다. 예약 판매 기간인 9월 2일까지 예스24 홈페이지에서 크레마 페블을 구매할 경우 10명을 추첨해 YES상품권 5만원을 증정합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"img0701.jpg\" data-origin-width=\"600\" data-origin-height=\"470\"><span data-url=\"https://blog.kakaocdn.net/dn/ZNW8a/btsJieGIpBP/8cY0qWkyyNZWcgvzPBVkvk/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/ZNW8a/btsJieGIpBP/8cY0qWkyyNZWcgvzPBVkvk/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/ZNW8a/btsJieGIpBP/8cY0qWkyyNZWcgvzPBVkvk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FZNW8a%2FbtsJieGIpBP%2F8cY0qWkyyNZWcgvzPBVkvk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"img0701.jpg\" data-origin-width=\"600\" data-origin-height=\"470\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">새로운 6인치 e-ink 리더 <b>크레마 페블의 정식 출시는 9월 3일</b>입니다.<br /><br /></p>\n<p data-ke-size=\"size16\">더 자세한 내용은 <b><span style=\"color: #0593d3;\"><a href=\"http://app.ac/HqpJYK203\" target=\"_blank\" rel=\"noopener\">이곳에서 참고하시기 바랍니다.</a></span></b></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"text-align: right;\" data-ke-size=\"size16\"><span style=\"color: #1a5490;\">이 포스트에 포함된 링크를 통해 제품을 구매하는 경우 라지온에서 판매 수수료를 받을 수 있습니다.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"text-align: right;\" data-ke-size=\"size16\">(출처 : 예스24)</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<div class=\"notranslate\" style=\"all: initial;\">&nbsp;</div>",
        "contentSnippet": "예스24(YES24)에서 새로운 6인치 이북 리더 크레마 페블(Crema Pebble) 예약판매를 시작합니다.\n \n크레마 페블, 달라진 점\n \n\n\n \n6인치 화면 크기에 전작인 크레마 모티프에서 51g 경량화한 139g의 무게로 같은 화면 크기의 이북 리더 가운데에는 가장 가벼운 이 제품은 손에 착 감기는 그립감과 함께 조약돌(Pebble)처럼 부드러운 외관을 자랑합니다. \n \n1448x1072 해상도의 카르타(Carta) 6인치 e-ink 패널과 쿼드코어 프로세서, 안드로이드 11 OS를 가지고 있으며 구글 플레이도 지원합니다. RAM은 전작보다 1GB 늘어난 4GB로 더 쾌적한 반응 속도를 제공합니다.\n\n\n색상은 하양과 까망 2종이며 기본 저장소로 32GB 내장, 마이크로SD 슬롯을 통해 최대 512GB까지 확장 가능합니다.\n \n \n크레마 페블 가격과 예약판매 이벤트\n \n크레마 페블 본체의 가격은 21만9천원이며, 액세서리와 함께 파는 패키지도 있습니다.\n \n예스24는 크레마 페블 출시를 기념하여 예약판매 이벤트도 진행합니다. 예약 판매 기간인 9월 2일까지 예스24 홈페이지에서 크레마 페블을 구매할 경우 10명을 추첨해 YES상품권 5만원을 증정합니다.\n \n\n\n \n새로운 6인치 e-ink 리더 크레마 페블의 정식 출시는 9월 3일입니다.\n\n더 자세한 내용은 이곳에서 참고하시기 바랍니다.\n \n \n이 포스트에 포함된 링크를 통해 제품을 구매하는 경우 라지온에서 판매 수수료를 받을 수 있습니다.\n \n(출처 : 예스24)",
        "guid": "https://lazion.com/2513722",
        "categories": [
          "#작은PC/#태블릿#e북리더",
          "crema",
          "crema pebble",
          "e-ink",
          "ebook",
          "eBook Reader",
          "new",
          "Tablet",
          "yes24"
        ],
        "isoDate": "2024-08-27T09:45:01.000Z"
      }
    ]
  },
  {
    "name": "루리웹 - 루리웹 리뷰 게시판",
    "category": "게임",
    "posts": [
      {
        "creator": "［RULIWEB］",
        "title": "[MULTI] 엔진도 손님도 없는 폐허의 종이비행기, 콘코드",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2245",
        "pubDate": "Thu, 29 Aug 2024 17:08:20 +0900",
        "author": "［RULIWEB］",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i2.ruliweb.com/thumb/24/08/29/1919d29f6325104c1.jpg\">",
        "contentSnippet": "",
        "categories": [
          "리뷰"
        ],
        "isoDate": "2024-08-29T08:08:20.000Z"
      },
      {
        "creator": "샤말란의눈",
        "title": "[MULTI] ‘성검전설다움’을 아로새기는 여행, 비전스 오브 마나",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2244",
        "pubDate": "Tue, 27 Aug 2024 10:19:16 +0900",
        "author": "샤말란의눈",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i1.ruliweb.com/thumb/24/08/27/19191a184494c329e.jpg\">",
        "contentSnippet": "",
        "categories": [
          "리뷰"
        ],
        "isoDate": "2024-08-27T01:19:16.000Z"
      },
      {
        "creator": "｜RULIWEB｜",
        "title": "[게임툰] 하중 계산은 어려워, 월드 오브 구 2",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2243",
        "pubDate": "Mon, 26 Aug 2024 20:04:42 +0900",
        "author": "｜RULIWEB｜",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i3.ruliweb.com/thumb/24/08/26/1918e4c2d2151ad6b.jpg\">",
        "contentSnippet": "",
        "categories": [
          "게임툰"
        ],
        "isoDate": "2024-08-26T11:04:42.000Z"
      },
      {
        "creator": "샤말란의눈",
        "title": "[MULTI] 게임스컴 2024, 공식 방송 및 관련 기사 종합",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2242",
        "pubDate": "Mon, 26 Aug 2024 08:12:38 +0900",
        "author": "샤말란의눈",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i3.ruliweb.com/thumb/24/08/25/191884a1ee413b2a1.jpg\">",
        "contentSnippet": "",
        "categories": [
          "특집"
        ],
        "isoDate": "2024-08-25T23:12:38.000Z"
      }
    ]
  },
  {
    "name": "Reasontobe",
    "category": "개인",
    "posts": [
      {
        "creator": "Reasontobe",
        "title": "행복이 가득한 서귀포 테라스하우스 - 서귀포 신시가지, 테라스 하우스를 매매합니다.",
        "link": "https://brunch.co.kr/@@34qN/43",
        "pubDate": "Thu, 29 Aug 2024 04:55:47 GMT",
        "author": "Reasontobe",
        "content": "#서귀포주택 #제주테라스하우스 #강정동테라스하우스 #강정코아루 #서귀포테라스하우스 #강정코아루더테라스 #제주세컨하우스 #서귀포세컨하우스 #서귀포바다뷰주택 #제주바다뷰주택 #서귀포아파트 #제주아파트 #서귀포바다뷰아파트 #제주바다뷰아파트   안녕하세요! 저희 가족의 추억이 깃든 서귀포 테라스하우스를 매매합니다.  제주에서 거주 환경이 가장 좋은 신서귀포 신시가<img src= \"https://img1.daumcdn.net/thumb/R1280x0/?fname=http%3A%2F%2Ft1.daumcdn.net%2Fbrunch%2Fservice%2Fuser%2F34qN%2Fimage%2FgdF5xxyJsLyJ2639BfoAnb5QXoM.jpg\" width=\"500\" />",
        "contentSnippet": "#서귀포주택 #제주테라스하우스 #강정동테라스하우스 #강정코아루 #서귀포테라스하우스 #강정코아루더테라스 #제주세컨하우스 #서귀포세컨하우스 #서귀포바다뷰주택 #제주바다뷰주택 #서귀포아파트 #제주아파트 #서귀포바다뷰아파트 #제주바다뷰아파트   안녕하세요! 저희 가족의 추억이 깃든 서귀포 테라스하우스를 매매합니다.  제주에서 거주 환경이 가장 좋은 신서귀포 신시가",
        "guid": "https://brunch.co.kr/@@34qN/43",
        "isoDate": "2024-08-29T04:55:47.000Z"
      }
    ]
  },
  {
    "name": "자유로운 생활",
    "category": "개인",
    "posts": []
  },
  {
    "name": "에스티마의 인터넷이야기 EstimaStory.com",
    "category": "개인",
    "posts": []
  },
  {
    "name": "나긋한 개발 - 데비안 리눅스와 프로그램 언어",
    "category": "개인",
    "posts": []
  },
  {
    "name": "일상을 여행처럼...",
    "category": "개인",
    "posts": []
  },
  {
    "name": "khris'log",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Just hack'em",
    "category": "개인",
    "posts": []
  },
  {
    "name": "C++ Truths",
    "category": "개인",
    "posts": []
  },
  {
    "name": "jacking75",
    "category": "개인",
    "posts": [
      {
        "title": "C# - 모던 하이퍼포먼스 C# 2023 Edition",
        "link": "https://jacking75.github.io/NET_20240830/",
        "pubDate": "Fri, 30 Aug 2024 00:00:00 +0900",
        "content": "<iframe width=\"1024\" height=\"1024\" src=\"https://docs.google.com/document/d/e/2PACX-1vSOZa_T1RtsFY18izYR6r4QVzUhTfHUApd8kBR5_wEEqMgp8EGd02eZLDt15lSJ8D0CLjCWiVxj4X25/pub?embedded=true\"></iframe>\n\n",
        "contentSnippet": "",
        "guid": "https://jacking75.github.io/NET_20240830/",
        "isoDate": "2024-08-29T15:00:00.000Z"
      }
    ]
  },
  {
    "name": "Joel on Software",
    "category": "개인",
    "posts": []
  },
  {
    "name": "벤자민로그",
    "category": "개인",
    "posts": [
      {
        "title": "Ruby의 unless 쉽게 읽기",
        "link": "https://jeho.page/essay/2024/08/28/ruby-unless.html",
        "pubDate": "2024-08-28T02:30:00.000Z",
        "author": "김재호",
        "content": "<p>Ruby 에는 <code class=\"language-plaintext highlighter-rouge\">unless</code> 문법이 있습니다.<br />\n<code class=\"language-plaintext highlighter-rouge\">if !current_user</code>를 <code class=\"language-plaintext highlighter-rouge\">unless current_user</code>로 쓸 수 있습니다.</p>\n\n<p>간단한 조건에서는 좋은 것 같습니다.<br />\n자연어처럼 읽히거든요.</p>\n<div class=\"language-ruby highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">return</span> <span class=\"k\">unless</span> <span class=\"n\">user_logged_in</span> <span class=\"c1\"># 깔끔</span>\n</code></pre></div></div>\n\n<p>그런데 조건이 여러 개 있는 경우에는?</p>\n<div class=\"language-ruby highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">unless</span> <span class=\"n\">file</span><span class=\"p\">.</span><span class=\"nf\">exist?</span> <span class=\"o\">&amp;&amp;</span> <span class=\"n\">file</span><span class=\"p\">.</span><span class=\"nf\">owner</span> <span class=\"o\">==</span> <span class=\"n\">current_user</span> <span class=\"o\">&amp;&amp;</span> <span class=\"n\">permission</span> <span class=\"o\">!=</span> <span class=\"ss\">:readonly</span>\n  <span class=\"c1\"># do something</span>\n<span class=\"k\">end</span>\n</code></pre></div></div>\n\n<p>하, 머리가 팽팽 돕니다.<br />\n어떤 개새가 이렇게 코드를 써놨어?<br />\n<code class=\"language-plaintext highlighter-rouge\">unless</code> 로 복잡한 조건을 적은 코드를 볼 때마다 <code class=\"language-plaintext highlighter-rouge\">if</code> 로 고치곤 했습니다.</p>\n\n<p>어느 날, 같이 일하던 동생에게 흥미로운 조언을 들었습니다.</p>\n<blockquote>\n  <p><code class=\"language-plaintext highlighter-rouge\">unless</code>를 <code class=\"language-plaintext highlighter-rouge\">assert</code> 처럼 생각하고 읽으면 좋아요.</p>\n</blockquote>\n\n<p>아래 코드 처럼 생각하면 좋다는 것이었습니다.</p>\n<div class=\"language-ruby highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">assert</span><span class=\"p\">(</span><span class=\"n\">file</span><span class=\"p\">.</span><span class=\"nf\">exist?</span> <span class=\"o\">&amp;&amp;</span> <span class=\"n\">file</span><span class=\"p\">.</span><span class=\"nf\">owner</span> <span class=\"o\">==</span> <span class=\"n\">current_user</span> <span class=\"o\">&amp;&amp;</span> <span class=\"n\">permission</span> <span class=\"o\">!=</span> <span class=\"ss\">:readonly</span><span class=\"p\">)</span>\n</code></pre></div></div>\n<p>즉, 반드시 파일이 존재해야 하고,<br />\n소유자는 현재 사용자이며,<br />\n읽기 전용이 아니어야 다음 코드로 진행할 수 있다.</p>\n\n<p>함수 시작부에 <code class=\"language-plaintext highlighter-rouge\">assert</code> 를 쓰듯이 <code class=\"language-plaintext highlighter-rouge\">unless</code>를 비슷한 용도로 쓰면 읽기가 오히려 편한 경우가 있다고.</p>\n\n<div class=\"language-ruby highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">raise</span> <span class=\"no\">FileNotExist</span> <span class=\"k\">unless</span> <span class=\"n\">file</span><span class=\"p\">.</span><span class=\"nf\">exist?</span>\n<span class=\"k\">raise</span> <span class=\"no\">AccessDenied</span> <span class=\"k\">unless</span> <span class=\"n\">file</span><span class=\"p\">.</span><span class=\"nf\">owner</span> <span class=\"o\">==</span> <span class=\"n\">current_user</span> <span class=\"o\">&amp;&amp;</span> <span class=\"n\">permission</span> <span class=\"o\">!=</span> <span class=\"ss\">:readonly</span>\n</code></pre></div></div>\n\n<p>오 뭐야? 좋은데?<br />\n낯설음을 뒤로하고 저는 이걸 받아들였습니다.<br />\n더 이상 <code class=\"language-plaintext highlighter-rouge\">unless</code>를 <code class=\"language-plaintext highlighter-rouge\">if</code> 로 고치지 않고 적절히 섞어 쓰게 됐습니다.</p>\n\n<p>오늘도 이런 <code class=\"language-plaintext highlighter-rouge\">unless</code> 코드를 쓰다가 조언해 준 동생 생각이 났습니다.<br />\n알려줘서 고맙다.😁</p>\n\n<p>P.S. 하지만… 알려줬던 동생은 이젠 기억도 못하는 것 같습니다.</p>\n\n<p><img src=\"/assets/img/unless_assert.png\" alt=\"얼간의 동생과의 카톡 대화\" /></p>\n\n<p><br />\n<em>함께 읽으면 좋은 글:</em></p>\n<ul>\n  <li><a href=\"/essay/2022/02/18/ruby.html\">Ruby는 프로그래머를 위한 선물</a></li>\n  <li><a href=\"/essay/2023/01/04/dont-say-ruby-is-slow.html\">루비가 느리다고?</a></li>\n</ul>",
        "contentSnippet": "Ruby 에는 unless 문법이 있습니다.\nif !current_user를 unless current_user로 쓸 수 있습니다.\n간단한 조건에서는 좋은 것 같습니다.\n\nreturn unless user_logged_in # 깔끔\n\n\n그런데 조건이 여러 개 있는 경우에는?\n\nunless file.exist? && file.owner == current_user && permission != :readonly\n  # do something\nend\n\n\n하, 머리가 팽팽 돕니다.\nunless 로 복잡한 조건을 적은 코드를 볼 때마다 if 로 고치곤 했습니다.\n어느 날, 같이 일하던 동생에게 흥미로운 조언을 들었습니다.\nunless를 assert 처럼 생각하고 읽으면 좋아요.\n아래 코드 처럼 생각하면 좋다는 것이었습니다.\n\nassert(file.exist? && file.owner == current_user && permission != :readonly)\n\n\n즉, 반드시 파일이 존재해야 하고,\n함수 시작부에 assert 를 쓰듯이 unless를 비슷한 용도로 쓰면 읽기가 오히려 편한 경우가 있다고.\n\nraise FileNotExist unless file.exist?\nraise AccessDenied unless file.owner == current_user && permission != :readonly\n\n\n오 뭐야? 좋은데?\nunless를 if 로 고치지 않고 적절히 섞어 쓰게 됐습니다.\n오늘도 이런 unless 코드를 쓰다가 조언해 준 동생 생각이 났습니다.\nP.S. 하지만… 알려줬던 동생은 이젠 기억도 못하는 것 같습니다.\n\n\n함께 읽으면 좋은 글:\nRuby는 프로그래머를 위한 선물\n루비가 느리다고?",
        "summary": "Ruby 에는 unless 문법이 있습니다. if !current_user를 unless current_user로 쓸 수 있습니다.",
        "id": "https://jeho.page/essay/2024/08/28/ruby-unless",
        "isoDate": "2024-08-28T02:30:00.000Z"
      },
      {
        "title": "매일 커밋에 실패했던 날",
        "link": "https://jeho.page/essay/2024/08/26/daily-commit-failed.html",
        "pubDate": "2024-08-26T05:00:00.000Z",
        "author": "김재호",
        "content": "<p>2020년, 코로나가 시작되고 루틴이라는 게 생기기 시작했습니다.<br />\n약속도 없고 방구석에만 있다 보니 자연스레 루틴이 잡혔습니다.</p>\n\n<p>아침 9시에 일어난다.<br />\n드르륵드르륵 커피를 간다.<br />\n커피잔을 들고 방에 들어가서 컴퓨터 앞에 앉는다.<br />\n코딩을 한다.</p>\n\n<p>매일 코딩을 했습니다.<br />\nGitHub 잔디도 빽빽이 잘 쌓였습니다.</p>\n\n<p>와 이거 멋진걸.<br />\n2021년에는 진짜로 잔디를 꽉 한 번 채워봐야겠다.</p>\n\n<p><img src=\"/assets/img/daily_coding.png\" alt=\"2021년 커밋 기록\" /><br />\n<em>2021년 GitHub</em></p>\n\n<p>하… 잘나가다가 실패해버렸습니다. 6/16일.</p>\n\n<p>6/16일은 가평에 놀러 갔던 날입니다.<br />\n호텔 방에 돌아왔더니 생각이 났습니다.<br />\n노느라 오늘 코딩을 못했네. 지금이라도 코딩해야지.<br />\n밤 10시쯤 집중해서 코딩하다가..<br />\n문득 시계를 보니 자정이 넘어버린 겁니다.</p>\n\n<blockquote>\n  <p>헉… 망했다. 아직 커밋 안 했는데.</p>\n</blockquote>\n\n<p>이렇게 무너진 건가? 끝난거야?<br />\n어찌나 허무하던지. 미리 커밋부터 정리해둘걸..</p>\n\n<p>아쉬워 하다가 이런 생각이 들었습니다.</p>\n<blockquote>\n  <p>잠깐. 난 잘못한 거 없잖아. 억울하다고.<br />\n놀다가 놓친 것도 아니고 진짜로 코딩하고 있었는걸.<br />\n시간을 돌려서 커밋을 집어넣을까?<br />\n이건 반칙이 아닌 것 같은데?</p>\n</blockquote>\n\n<p>1분쯤 고민했습니다.<br />\nGit 명령어를 찾아보기까지 했습니다.<br />\n하지만 그러지 않기로 했습니다.</p>\n\n<p>반칙이 아니긴 뭐가 아니야. 반칙 맞잖아.<br />\n그렇게 하는 순간 의미가 없어져 버려.<br />\n못한 건 못한 거지, 이게 뭐라고.</p>\n\n<p>마음이 편해졌습니다.<br />\n노력은 하되 실패한 날은 실패한 날대로 두자.</p>\n\n<p>이후로는 그다지 신경쓰며 하지 않았는데도 잔디는 여전히 푸릇푸릇합니다.<br />\n너무 신경 쓰며 할 때보다 오히려 지금이 더 좋습니다.</p>\n\n<p><img src=\"/assets/img/commits.png\" alt=\"최근 5년간 커밋\" /></p>\n\n<p><br />\n<em>함께 읽으면 좋은 글:</em></p>\n<ul>\n  <li><a href=\"/essay/2022/01/05/daily-coding.html\">매일매일 코딩하기</a></li>\n  <li><a href=\"/essay/2024/08/01/commit-count.html\">1년에 몇 개나 커밋하세요?</a></li>\n</ul>",
        "contentSnippet": "2020년, 코로나가 시작되고 루틴이라는 게 생기기 시작했습니다.\n아침 9시에 일어난다.\n매일 코딩을 했습니다.\n와 이거 멋진걸.\n\n2021년 GitHub\n하… 잘나가다가 실패해버렸습니다. 6/16일.\n6/16일은 가평에 놀러 갔던 날입니다.\n헉… 망했다. 아직 커밋 안 했는데.\n이렇게 무너진 건가? 끝난거야?\n아쉬워 하다가 이런 생각이 들었습니다.\n잠깐. 난 잘못한 거 없잖아. 억울하다고.\n1분쯤 고민했습니다.\n반칙이 아니긴 뭐가 아니야. 반칙 맞잖아.\n마음이 편해졌습니다.\n이후로는 그다지 신경쓰며 하지 않았는데도 잔디는 여전히 푸릇푸릇합니다.\n\n\n함께 읽으면 좋은 글:\n매일매일 코딩하기\n1년에 몇 개나 커밋하세요?",
        "summary": "2020년, 코로나가 시작되고 루틴이라는 게 생기기 시작했습니다. 약속도 없고 방구석에만 있다 보니 자연스레 루틴이 잡혔습니다.",
        "id": "https://jeho.page/essay/2024/08/26/daily-commit-failed",
        "isoDate": "2024-08-26T05:00:00.000Z"
      }
    ]
  },
  {
    "name": "악보쓰는 프로그래머",
    "category": "개인",
    "posts": []
  },
  {
    "name": "쭌안아빠",
    "category": "개인",
    "posts": []
  },
  {
    "name": "A Gangster World",
    "category": "개인",
    "posts": []
  },
  {
    "name": "요우의 내맘대로 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자스럽다",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Against All Odds.",
    "category": "개인",
    "posts": []
  },
  {
    "name": "움직이는 게임서버",
    "category": "개인",
    "posts": []
  },
  {
    "name": "이상욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "임철재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "어쩐지 오늘은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "oddpoet’s étude",
    "category": "개인",
    "posts": []
  },
  {
    "name": "0x00 - NULL",
    "category": "개인",
    "posts": []
  },
  {
    "name": "퇴근 후 서버다운",
    "category": "개인",
    "posts": [
      {
        "creator": "SIDNFT",
        "title": "미항공모함 USS 포레스탈 화재 사건으로 배우는 청라 전기차 화재의 대응 방법",
        "link": "http://serverdown.tistory.com/795",
        "pubDate": "Fri, 30 Aug 2024 14:14:50 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/795#entry795comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://youtu.be/5wEoy35mWBk?t=3269\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://youtu.be/5wEoy35mWBk?t=3269</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=5wEoy35mWBk\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/bkuLWW/hyWVSqllzC/XMJISgqjPhWMgWZuXZj2N0/img.jpg?width=1280&amp;height=720&amp;face=266_284_1136_444\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"올뉴 삼테성즈! 2024년 8월호.  전기차 화재의 본질과 로봇 관절 기술의 혁명!\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/5wEoy35mWBk\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">은 개뿔이고 스프릴쿨러 오작동한다고 민원 넣지마라</p>\n<p data-ke-size=\"size16\">원래 물 벼락은 가끔 맞는거나</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">라는 교훈을 얻을 수 있습니다.</p>\n<p data-ke-size=\"size16\">스프링쿨러를 켜지못하게 막는 사람이 혼나면 되는 심플함이 필요한 시대입니다.</p>",
        "contentSnippet": "영상: https://youtu.be/5wEoy35mWBk?t=3269\n\n\n\n \n은 개뿔이고 스프릴쿨러 오작동한다고 민원 넣지마라\n원래 물 벼락은 가끔 맞는거나\n \n라는 교훈을 얻을 수 있습니다.\n스프링쿨러를 켜지못하게 막는 사람이 혼나면 되는 심플함이 필요한 시대입니다.",
        "guid": "http://serverdown.tistory.com/795",
        "categories": [
          "유튜브",
          "사건사고"
        ],
        "isoDate": "2024-08-30T05:14:50.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "유니티 툴 꿀팁 / 단축키",
        "link": "http://serverdown.tistory.com/794",
        "pubDate": "Fri, 30 Aug 2024 08:18:13 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/794#entry794comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=_uQb4Q8iSdU\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=_uQb4Q8iSdU</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=_uQb4Q8iSdU\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/Q64qB/hyWVW0t8ZV/wyd21MO7TuruXjCEPPf2ok/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"국가권력급 유니티 꿀팁 정리\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/_uQb4Q8iSdU\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">신기한게 많군요</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=_uQb4Q8iSdU\n\n\n\n \n신기한게 많군요",
        "guid": "http://serverdown.tistory.com/794",
        "categories": [
          "프로그래밍/개발메모",
          "유니티"
        ],
        "isoDate": "2024-08-29T23:18:13.000Z"
      }
    ]
  },
  {
    "name": "coolspeed",
    "category": "개인",
    "posts": []
  },
  {
    "name": "오늘도 끄적끄적",
    "category": "개인",
    "posts": []
  },
  {
    "name": "dx11 Vanica's Lifelog - 夢が夢で終わらないように",
    "category": "개인",
    "posts": []
  },
  {
    "name": "초코사랑",
    "category": "개인",
    "posts": []
  },
  {
    "name": "ZeroCho Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Hybrid's Notes",
    "category": "개인",
    "posts": []
  },
  {
    "name": "imays게임엔진개발자",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for hurinmon Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "기억보단 기록을",
    "category": "개인",
    "posts": [
      {
        "creator": "향로 (기억보단 기록을)",
        "title": "아무도 없어도 규칙을 지키는 사람",
        "link": "https://jojoldu.tistory.com/802",
        "pubDate": "Thu, 29 Aug 2024 00:45:39 +0900",
        "author": "향로 (기억보단 기록을)",
        "comments": "https://jojoldu.tistory.com/802#entry802comment",
        "content": "<p data-ke-size=\"size16\">늦은 시간에 퇴근을 하면 종종 신기한 경험을 하게 된다.<br />너무 늦은 시간에 퇴근을 하면 보통은 바로 회사 택시를 불러 타고 가곤 하는데, 그날은 머리도 식힐겸 조금은 걷다가 택시를 타려고 했다.</p>\n<p data-ke-size=\"size16\">저녁 11시가 넘는 늦은 시간.<br />주변에 아무도 없는, 지나가는 차도 없는 아주 조용한 횡단보도의 신호등을 기다리는 사람을 본 적이 있다.</p>\n<p data-ke-size=\"size16\"><b>지켜보는 사람 하나 없는 곳에서도 규칙을 지키는 사람</b>이 있다는 것에 걸음을 멈추고 한동안 지켜보게 되었다.<br />신호등의 불이 켜지고나서야 건너가는 모습을 보면서 멋지다는 생각을 했다.</p>\n<p data-ke-size=\"size16\">누군가에게는 융통성이 없는 것일 수 있다.<br />지나가는 차 하나 없어 사고날 일이 없고,<br />지켜보는 사람도 없으니 누군가 이상한 눈길로 볼 일도 없을 것이다.<br />그러면 굳이 기다리지 않고 횡단보도를 지나가는 것이 늦은 시간에 집에 빨리 갈 수 있고, 우린 이걸 융통성이라고 부른다.</p>\n<hr contenteditable=\"false\" data-ke-type=\"horizontalRule\" data-ke-style=\"style1\" />\n<p data-ke-size=\"size16\">아주 예전에 이경규씨가 진행한 \"양심냉장고\" 라는 프로그램이 있다.<br />1화의 양심 주제는 \"차량 정지선을 지키는 사람\" 을 찾는 것이였다.</p>\n<p data-ke-size=\"size16\">새벽 4시까지도 그 어느 차량도 지키지 않았다.<br />같이 진행하시는 분도 \"우리나라 사람은 법대로 살면 손해 본다고!\" 라고 외치는 와중에 <b>4시 13분이 되어서야 하나의 소형 차량이 아무도 없는 그 시간에 정지선을 지켰다</b>.</p>\n<p data-ke-size=\"size16\">알고보니 그 차량은 장애인 부부가 운전을 하고 있었고, 이경규씨는 \"왜 신호를 지키셨나요?\" 라는 질문을 한다.<br />\"아무도 지키지 않는데...\" 를 생략했지만 말이다.</p>\n<p data-ke-size=\"size16\">그리고 말을 제대로 하지 못하는 지체장애인 남편분께서 하신 답변은 \"내...가...늘...지켜요.\" 였다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><a href=\"https://cafe.daum.net/SoulDresser/FLTB/781737?svc=cafeapi\">무릎팍도사 - 양심냉장고 1화</a></li>\n</ul>\n<p data-ke-size=\"size16\">이 1화 방송이 나가고, 다음날 신문의 제목은 \"누가 장애인인가... 사실은 우리가 장애인\" 이였다.</p>\n<hr contenteditable=\"false\" data-ke-type=\"horizontalRule\" data-ke-style=\"style1\" />\n<p data-ke-size=\"size16\">효율성, 융통성을 이야기하면서 눈에 보이는 것들의 이득을 취하게 된다.<br />그렇게 융통성을 이유로 \"<b>눈에 보이지 않는 어떤 무언가가 계속해서 마모되어오진 않았을까</b>\" 라는 생각을 하게 된다.<br />\"융통성\" 이란 말로 나는 얼마나 마모 되어왔을까?</p>\n<p data-ke-size=\"size16\">꼭 이런 점이 아니더라도,<br />나 스스로 약속한 것들이 있다.<br /><b>남이 보지 않아도,</b><br /><b>주변에서 알아봐주지 않아도&nbsp;</b><br /><b>나 스스로 한 약속이기에 지키는 그런 사람.</b><br /><br />그런 사람이 되고 싶다.</p>",
        "contentSnippet": "늦은 시간에 퇴근을 하면 종종 신기한 경험을 하게 된다.\n너무 늦은 시간에 퇴근을 하면 보통은 바로 회사 택시를 불러 타고 가곤 하는데, 그날은 머리도 식힐겸 조금은 걷다가 택시를 타려고 했다.\n저녁 11시가 넘는 늦은 시간.\n주변에 아무도 없는, 지나가는 차도 없는 아주 조용한 횡단보도의 신호등을 기다리는 사람을 본 적이 있다.\n지켜보는 사람 하나 없는 곳에서도 규칙을 지키는 사람이 있다는 것에 걸음을 멈추고 한동안 지켜보게 되었다.\n신호등의 불이 켜지고나서야 건너가는 모습을 보면서 멋지다는 생각을 했다.\n누군가에게는 융통성이 없는 것일 수 있다.\n지나가는 차 하나 없어 사고날 일이 없고,\n지켜보는 사람도 없으니 누군가 이상한 눈길로 볼 일도 없을 것이다.\n그러면 굳이 기다리지 않고 횡단보도를 지나가는 것이 늦은 시간에 집에 빨리 갈 수 있고, 우린 이걸 융통성이라고 부른다.\n아주 예전에 이경규씨가 진행한 \"양심냉장고\" 라는 프로그램이 있다.\n1화의 양심 주제는 \"차량 정지선을 지키는 사람\" 을 찾는 것이였다.\n새벽 4시까지도 그 어느 차량도 지키지 않았다.\n같이 진행하시는 분도 \"우리나라 사람은 법대로 살면 손해 본다고!\" 라고 외치는 와중에 4시 13분이 되어서야 하나의 소형 차량이 아무도 없는 그 시간에 정지선을 지켰다.\n알고보니 그 차량은 장애인 부부가 운전을 하고 있었고, 이경규씨는 \"왜 신호를 지키셨나요?\" 라는 질문을 한다.\n\"아무도 지키지 않는데...\" 를 생략했지만 말이다.\n그리고 말을 제대로 하지 못하는 지체장애인 남편분께서 하신 답변은 \"내...가...늘...지켜요.\" 였다.\n무릎팍도사 - 양심냉장고 1화\n이 1화 방송이 나가고, 다음날 신문의 제목은 \"누가 장애인인가... 사실은 우리가 장애인\" 이였다.\n효율성, 융통성을 이야기하면서 눈에 보이는 것들의 이득을 취하게 된다.\n그렇게 융통성을 이유로 \"눈에 보이지 않는 어떤 무언가가 계속해서 마모되어오진 않았을까\" 라는 생각을 하게 된다.\n\"융통성\" 이란 말로 나는 얼마나 마모 되어왔을까?\n꼭 이런 점이 아니더라도,\n나 스스로 약속한 것들이 있다.\n남이 보지 않아도,\n주변에서 알아봐주지 않아도 \n나 스스로 한 약속이기에 지키는 그런 사람.\n그런 사람이 되고 싶다.",
        "guid": "https://jojoldu.tistory.com/802",
        "categories": [
          "생각정리",
          "규칙",
          "양심냉장고",
          "이경규"
        ],
        "isoDate": "2024-08-28T15:45:39.000Z"
      },
      {
        "creator": "향로 (기억보단 기록을)",
        "title": "1. TS를 만나고 - 디자인",
        "link": "https://jojoldu.tistory.com/801",
        "pubDate": "Mon, 26 Aug 2024 12:43:13 +0900",
        "author": "향로 (기억보단 기록을)",
        "comments": "https://jojoldu.tistory.com/801#entry801comment",
        "content": "<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">JVM 컨퍼런스가 있으면 \"Java 세상에서 살던 사람이 처음 TS 세계를 만나고 느낀 여러가지 차이점\" 을 발표하려고했는데, 시간도 너무 지났고, 발표 준비하기도 쉽지 않은 것 같아 블로그에 시리즈로 시작한다.<br />Java가 구린 언어다를 표현하기 위한 글이기 보다는 <a href=\"https://jojoldu.tistory.com/687\">전작(다른 언어로 성장하기)</a>과 마찬가지로 타 생태계를 통해 성장할 수 있음을 알리는 글이다</p>\n</blockquote>\n<p data-ke-size=\"size16\">자바를 처음 배울때 <code>getter/setter</code> 에 대한 이야기를 많이 들었다.<br />캡슐화 등의 장점을 들으면서 클래스 안에는 항상 무분별하게 <code>getter/setter</code> 를 생성했다.<br />(그때는 Lombok을 배우지 못했던 터라) IDE의 자동 생성 기능을 사용하면서 열심히 <code>getter/setter</code>를 생성했다.</p>\n<p data-ke-size=\"size16\">물론 예전부터 많은 분들은 무분별한 getter/setter를 사용하지말라는 글과 토론을 나누었다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><a href=\"https://www.yegor256.com/2014/09/16/getters-and-setters-are-evil.html\">2014.09.16 - getters-and-setters-are-evil</a></li>\n</ul>\n<p data-ke-size=\"size16\">다만, 내가 배울때 법칙?처럼 <code>getter/setter</code> 만든다로 배워서 그렇게 했다.<br />(지금이야 getter/setter를 쓰지 않고, <a href=\"https://martinfowler.com/bliki/TellDontAsk.html\">Tell, Don't Ask</a> 를 당연한 것처럼 다뤄지고 있지만 말이다.)</p>\n<p data-ke-size=\"size16\">여튼, 배우던 당시에는 무분별하게 <code>getter/setter</code>를 만들다보니 \"<b>어차피 단순한 data holders로 사용하는데 그냥 public으로 열면 안되나</b>\" 같은 생각이 들었다.</p>\n<p data-ke-size=\"size16\">이를 테면 다음과 같다.<br />매번 아래와 같이 생성하는데,</p>\n<pre class=\"cpp\"><code>public class Course {\n    private int price;\n\n    public int getPrice() {\n        return price;\n    }\n\n    public void setPrice(int price) {\n        this.price = price;\n    }\n}</code></pre>\n<p data-ke-size=\"size16\">아래와 같이 \"그냥 <code>public</code> 으로 열어두는 것과 무엇이 다르지?\" 라는 생각인 것이다.</p>\n<pre class=\"angelscript\"><code>public class Course {\n    public int price;\n}</code></pre>\n<p data-ke-size=\"size16\">어차피 값을 넣고 빼는 역할 밖에 없는데, 똑같지 않나? 라는 생각을 하곤 했다.</p>\n<p data-ke-size=\"size16\">그러다가 기능이 여러가지로 확장되는 상황을 만나니 접근자를 통해서 사용해야하는 것의 중요성을 알게 되었다.</p>\n<p data-ke-size=\"size16\">예를 들어 단순히 <code>price</code>에 값을 넣기만 하면 되는 로직에서 아래와 같이 <b>부가세 10%가 추가된 가격으로 반환해야한다</b>는 조건이 추가되니 단순히 <code>public</code> 으로 열어두는 것은 기존의 코드를 모두 바꿔야하는 문제가 생겼다.</p>\n<pre class=\"angelscript\"><code>public class Course {\n    ...\n\n    public int getPrice() {\n        return (int) (price * 1.1); // 부가세 10% 적용\n    }\n}\n\ncoursePrice = course.price; // &lt;&lt;&lt; 이렇게 호출되는 코드들이\ncoursePrice = course.getPrice(); // &lt;&lt;&lt; 이 코드로 모두 변경되어야만 했다.</code></pre>\n<p data-ke-size=\"size16\">접근자를 통해서 처음 구현해두지 않으니, 이런 경우가 발생했다.<br />그래서 \"<b>처음부터 접근자를 생성해두고, 이를 호출자들이 사용하도록 해야만 이런 문제를 겪지 않는 다</b>\" 는 것을 알게되었다.</p>\n<p data-ke-size=\"size16\">다만, 그럼 \"매번 이렇게 접근자를 생성해두고 코드를 작성해야하는 불편함과 귀찮음은 어쩔 수 없는 것인가\" 라는 생각은 계속 들었다.</p>\n<p data-ke-size=\"size16\">그러던 중, JavaScript/TypeScript 코드들을 보게 되었는데, 여기서는 <code>get/set</code> 접근자를 언어 레벨에서 지원했다.</p>\n<p data-ke-size=\"size16\">즉, <b>아래 2개 코드는 호출자 입장에서 동일한 방법으로 호출할 수 있다</b>.</p>\n<pre class=\"kotlin\"><code>// 1. 접근자 없이 public 필드\nclass Course {\n    public price: number;\n\n    constructor(price: number) {\n        this.price = price;\n    }\n}\n\n// 2. 접근자를 통한 접근\nclass Course {\n    private _price: number;\n\n    ...\n\n    get price(): number {\n        return this._price;\n    }\n}\n\nval price = course.price; // 1, 2 모두 동일한 코드로 호출</code></pre>\n<p data-ke-size=\"size16\">이건 코틀린도 동일한데, 코틀린 역시 <code>get/set</code> 접근자를 언어 레벨에서 지원한다.</p>\n<pre class=\"kotlin\"><code>// 1. 접근자 없이 public 필드\nclass Course(var price: Int)\n\n// 2. 접근자를 통한 접근\nclass Course(private var _price: Int) {\n    var price: Int\n        get() = (_price * 1.1).toInt() // 부가세 10% 적용\n}\n\nval coursePrice = course.price</code></pre>\n<p data-ke-size=\"size16\">(코틀린과 자바를 굳이 다른 생태계라고 구분하지는 않지만)<br />이런 개념이 요즘의 모던한 언어들에게는 기본적으로 내장되어있다.</p>\n<p data-ke-size=\"size16\">Java를 처음 배우는 입장에서는 \"public 필드를 사용하면 안되고, private 필드를 사용하고 이에 대한 접근자를 무조건 생성해야한다\" 를 배워야만 했다.<br />이걸 그나마 편하게 하기 위해 Lombok 라이브러리 등의 도입도 알아야만 한다.<br />만약 이 모든걸 무시하고 처음 배운 클래스에서 단순히 public 필드를 사용하면 이후에 큰 비용을 지불하게 된다.</p>\n<p data-ke-size=\"size16\">반면, <b>JS, TS, Kotlin 등의 언어를 배우는 입장에서는 이런 것이 고민 거리이자 배워야할 내용이 되지 않는다</b>.<br />public 필드를 사용하는 것과 접근자를 통한 접근이 모두 <b>동일한 인터페이스를 지원하기 때문에 내가 알게되는 지식이 늘어난다고해서 기존의 코드들이 전체 교체 될 일은 거의 없다</b>.<br />즉, 프로그래밍을 배우고 사용할때 중요한 고민거리가 하나 없어지게 되는 셈이다.</p>\n<p data-ke-size=\"size16\">이런 사례는 <b>언어 레벨에서 좋은 디자인 인터페이스를 지원한다</b> 라는 의미로 다가왔다.</p>\n<p data-ke-size=\"size16\">처음 클래스를 배울때 단순하게 public으로 모든 필드를 선언하고 코드를 작성하더라도 이후에 <b>접근자 (accessor) 개념을 배우고 클래스 코드를 변경하더라도 기존 호출자 코드에 변경이 필요하지 않는다</b>는 것을 초보 개발자들에게 알려줄 수 있는 셈이다.</p>\n<p data-ke-size=\"size16\">이걸로 변경에 유연한 디자인을 아주 쉽게 익히게 된다.<br />Lombok 같은 외부의 라이브러리를 도입해야한다거나,<br />접근자 (accessor) 에 대한 개념을 배운다던가 그런 언어 외적인 추가적인 학습없이 말이다.</p>\n<h2 data-ke-size=\"size26\">마무리</h2>\n<p data-ke-size=\"size16\">좋은 언어는 그 자체로 좋은 디자인을 배울 수 있어야 한다는 생각을 한다.<br />그런면에서 문법 설탕에 불과하다고 이야기하는 사람들도 있지만, 특정 프레임워크, 라이브러리의 도움으로 해결하는 문제들을 언어 레벨에서 직접 해결해주고 있다는 점이 참 좋았다.</p>\n<p data-ke-size=\"size16\">그리고 그런 개념들이 TS, Kotlin 등 Java가 아닌 다른 언어에서는 당연하게도 들어가 있다는 점이 섬세하게도 느껴졌다.<br />(물론 Kotlin과 Java 사이에 큰 차이가 있냐는 의견에도 동의하지만 말이다.)</p>\n<h2 data-ke-size=\"size26\">함께 보면 좋은 글</h2>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><a href=\"https://jojoldu.tistory.com/687\">다른 언어로 성장하기</a></li>\n</ul>",
        "contentSnippet": "JVM 컨퍼런스가 있으면 \"Java 세상에서 살던 사람이 처음 TS 세계를 만나고 느낀 여러가지 차이점\" 을 발표하려고했는데, 시간도 너무 지났고, 발표 준비하기도 쉽지 않은 것 같아 블로그에 시리즈로 시작한다.\nJava가 구린 언어다를 표현하기 위한 글이기 보다는 전작(다른 언어로 성장하기)과 마찬가지로 타 생태계를 통해 성장할 수 있음을 알리는 글이다\n자바를 처음 배울때 getter/setter 에 대한 이야기를 많이 들었다.\n캡슐화 등의 장점을 들으면서 클래스 안에는 항상 무분별하게 getter/setter 를 생성했다.\n(그때는 Lombok을 배우지 못했던 터라) IDE의 자동 생성 기능을 사용하면서 열심히 getter/setter를 생성했다.\n물론 예전부터 많은 분들은 무분별한 getter/setter를 사용하지말라는 글과 토론을 나누었다.\n2014.09.16 - getters-and-setters-are-evil\n다만, 내가 배울때 법칙?처럼 getter/setter 만든다로 배워서 그렇게 했다.\n(지금이야 getter/setter를 쓰지 않고, Tell, Don't Ask 를 당연한 것처럼 다뤄지고 있지만 말이다.)\n여튼, 배우던 당시에는 무분별하게 getter/setter를 만들다보니 \"어차피 단순한 data holders로 사용하는데 그냥 public으로 열면 안되나\" 같은 생각이 들었다.\n이를 테면 다음과 같다.\n매번 아래와 같이 생성하는데,\npublic class Course {\n    private int price;\n\n    public int getPrice() {\n        return price;\n    }\n\n    public void setPrice(int price) {\n        this.price = price;\n    }\n}\n아래와 같이 \"그냥 public 으로 열어두는 것과 무엇이 다르지?\" 라는 생각인 것이다.\npublic class Course {\n    public int price;\n}\n어차피 값을 넣고 빼는 역할 밖에 없는데, 똑같지 않나? 라는 생각을 하곤 했다.\n그러다가 기능이 여러가지로 확장되는 상황을 만나니 접근자를 통해서 사용해야하는 것의 중요성을 알게 되었다.\n예를 들어 단순히 price에 값을 넣기만 하면 되는 로직에서 아래와 같이 부가세 10%가 추가된 가격으로 반환해야한다는 조건이 추가되니 단순히 public 으로 열어두는 것은 기존의 코드를 모두 바꿔야하는 문제가 생겼다.\npublic class Course {\n    ...\n\n    public int getPrice() {\n        return (int) (price * 1.1); // 부가세 10% 적용\n    }\n}\n\ncoursePrice = course.price; // <<< 이렇게 호출되는 코드들이\ncoursePrice = course.getPrice(); // <<< 이 코드로 모두 변경되어야만 했다.\n접근자를 통해서 처음 구현해두지 않으니, 이런 경우가 발생했다.\n그래서 \"처음부터 접근자를 생성해두고, 이를 호출자들이 사용하도록 해야만 이런 문제를 겪지 않는 다\" 는 것을 알게되었다.\n다만, 그럼 \"매번 이렇게 접근자를 생성해두고 코드를 작성해야하는 불편함과 귀찮음은 어쩔 수 없는 것인가\" 라는 생각은 계속 들었다.\n그러던 중, JavaScript/TypeScript 코드들을 보게 되었는데, 여기서는 get/set 접근자를 언어 레벨에서 지원했다.\n즉, 아래 2개 코드는 호출자 입장에서 동일한 방법으로 호출할 수 있다.\n// 1. 접근자 없이 public 필드\nclass Course {\n    public price: number;\n\n    constructor(price: number) {\n        this.price = price;\n    }\n}\n\n// 2. 접근자를 통한 접근\nclass Course {\n    private _price: number;\n\n    ...\n\n    get price(): number {\n        return this._price;\n    }\n}\n\nval price = course.price; // 1, 2 모두 동일한 코드로 호출\n이건 코틀린도 동일한데, 코틀린 역시 get/set 접근자를 언어 레벨에서 지원한다.\n// 1. 접근자 없이 public 필드\nclass Course(var price: Int)\n\n// 2. 접근자를 통한 접근\nclass Course(private var _price: Int) {\n    var price: Int\n        get() = (_price * 1.1).toInt() // 부가세 10% 적용\n}\n\nval coursePrice = course.price\n(코틀린과 자바를 굳이 다른 생태계라고 구분하지는 않지만)\n이런 개념이 요즘의 모던한 언어들에게는 기본적으로 내장되어있다.\nJava를 처음 배우는 입장에서는 \"public 필드를 사용하면 안되고, private 필드를 사용하고 이에 대한 접근자를 무조건 생성해야한다\" 를 배워야만 했다.\n이걸 그나마 편하게 하기 위해 Lombok 라이브러리 등의 도입도 알아야만 한다.\n만약 이 모든걸 무시하고 처음 배운 클래스에서 단순히 public 필드를 사용하면 이후에 큰 비용을 지불하게 된다.\n반면, JS, TS, Kotlin 등의 언어를 배우는 입장에서는 이런 것이 고민 거리이자 배워야할 내용이 되지 않는다.\npublic 필드를 사용하는 것과 접근자를 통한 접근이 모두 동일한 인터페이스를 지원하기 때문에 내가 알게되는 지식이 늘어난다고해서 기존의 코드들이 전체 교체 될 일은 거의 없다.\n즉, 프로그래밍을 배우고 사용할때 중요한 고민거리가 하나 없어지게 되는 셈이다.\n이런 사례는 언어 레벨에서 좋은 디자인 인터페이스를 지원한다 라는 의미로 다가왔다.\n처음 클래스를 배울때 단순하게 public으로 모든 필드를 선언하고 코드를 작성하더라도 이후에 접근자 (accessor) 개념을 배우고 클래스 코드를 변경하더라도 기존 호출자 코드에 변경이 필요하지 않는다는 것을 초보 개발자들에게 알려줄 수 있는 셈이다.\n이걸로 변경에 유연한 디자인을 아주 쉽게 익히게 된다.\nLombok 같은 외부의 라이브러리를 도입해야한다거나,\n접근자 (accessor) 에 대한 개념을 배운다던가 그런 언어 외적인 추가적인 학습없이 말이다.\n마무리\n좋은 언어는 그 자체로 좋은 디자인을 배울 수 있어야 한다는 생각을 한다.\n그런면에서 문법 설탕에 불과하다고 이야기하는 사람들도 있지만, 특정 프레임워크, 라이브러리의 도움으로 해결하는 문제들을 언어 레벨에서 직접 해결해주고 있다는 점이 참 좋았다.\n그리고 그런 개념들이 TS, Kotlin 등 Java가 아닌 다른 언어에서는 당연하게도 들어가 있다는 점이 섬세하게도 느껴졌다.\n(물론 Kotlin과 Java 사이에 큰 차이가 있냐는 의견에도 동의하지만 말이다.)\n함께 보면 좋은 글\n다른 언어로 성장하기",
        "guid": "https://jojoldu.tistory.com/801",
        "categories": [
          "Architecture",
          "Java",
          "kotlin",
          "node.js",
          "typescript",
          "인터페이스",
          "자바",
          "코틀린",
          "타입스크립트"
        ],
        "isoDate": "2024-08-26T03:43:13.000Z"
      }
    ]
  },
  {
    "name": "WestwoodForever's Dev Log",
    "category": "개인",
    "posts": []
  },
  {
    "name": "허니몬(Honeymon)의 자바guru",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Wolf Loves Fox :: 일상",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Game Programmer Life",
    "category": "개인",
    "posts": []
  },
  {
    "name": "IT 프리랜서 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "yuchi's dev",
    "category": "개인",
    "posts": []
  },
  {
    "name": "만화로 나누는 자유/오픈소스 소프트웨어 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "신현석(Hyeonseok Shin)",
    "category": "개인",
    "posts": [
      {
        "title": "Puppeteer로 웹페이지 열고 조작하기",
        "link": "https://hyeonseok.com/blog/916",
        "pubDate": "Sun, 25 Aug 2024 17:26:34 GMT",
        "content": "<p>화면 없이 웹 브라우징을 할 수 있는 제품으로 기억나는 최초는 <a href=\"https://phantomjs.org/\">팬텀(PhantomJS)</a>이다. 화면도 없이 브라우저를 열고 스크린 샷도 찍고 탐색하는 것이 엄청 신기했다. 지금은 개발이 중단되었다. 팬텀의 불편함을 극복해보고자 <a href=\"https://github.com/casperjs/casperjs\">캐스퍼(CasperJS)</a>도 나왔었는데 이것 역시 지금은 개발이 중단되었다. 아마도 <a href=\"https://pptr.dev/\">퍼피티어(Puppeteer)</a>와 <a href=\"https://playwright.dev/\">플레이라이트(Playwright)</a>같은 대안 프로젝트들이 구글과 마이크로소프트 같은 큰 회사에서 나와서 그렇게 된 것 같다.</p>\r\n\r\n<p>플레이라이트가 퍼피티어를 포크해서 나왔다고 하는데 두 프로젝트는 지향하는 바가 다르다. 퍼피티어가 헤드리스 크롬이나 <a href=\"https://hacks.mozilla.org/2024/08/puppeteer-support-for-firefox/\">파이어폭스</a>를 편하게 활용할 수 있게 고안되었다면 플레이라이트는 테스트를 위한 스위트에 가깝다. 나는 테스트를 돌리기 보다는 브라우저에서의 작업이 필요해서 퍼피티어를 선택했다.</p>\r\n\r\n<p>API는 상당히 직관적이어서 <a href=\"https://pptr.dev/#example\">예제</a>를 보면 바로 브라우저를 실행해서 테스트 해 볼 수 있다. 브라우저 열고 페이지 열고 등 코드만 봐도 바로 이해가 간다. 나는 처리해야 하는 작업이 많아서 별도 스크립트를 <a href=\"https://pptr.dev/api/puppeteer.page.__eval/\"><code>page.$$eval</code></a>을 사용해서 실행했다.</p>\r\n\r\n<pre><code>const imageCount = await page.$$eval(\"img\", (imgs) => imgs.length)</code></pre>\r\n\r\n<p>서로 다른 컨텍스트를 직관적으로 연결해줘서 아주 사용하기 편하다. 예전과 비교하면 정말 좋아졌다.</p>\r\n\r\n<p>페이지를 열려면 <code>const browser = await puppeteer.launch()</code>로 브라우저를 실행하고 <code>const page = await browser.newPage()</code>로 페이지를 열어서 사용하게 된다. 처음에는 매번 브라우저를 여는 시간도 아깝고 보통 브라우저 사용하듯이 하나 실행해 놓고 페이지만 열고 닫으며 사용해봤다. 이렇게 하니 평소에 브라우저가 메모리 많이 사용하고 있다고 욕하던 상황이 서버에서 벌어져서 서버가 죽었다. 프로세스가 열리는 것을 보니 페이지 하나만 열어도 크롬 관련 프로세스가 열개가 넘게 뜨고 <code>await page.close()</code>로 페이지를 닫아줘도 일부 프로세스들이 계속 남아 있었다. 결국 계속 쓸수록 메모리 점유가 늘어났다. <code>await browser.close()</code>로 실행된 브라우저를 닫아줘야 프로세스가 모두 정리가 된다.</p>\r\n\r\n<p><a href=\"https://accessibility.kr/\">accessibility.kr</a>에서 지금까지는 자바스크립트로 생성되는 페이지를 검사할 수 없었는데 이제 검사할 수 있는 사이트가 많이 늘어났다. 리다이렉션 처리도 많이 개선되었다.</p>",
        "contentSnippet": "화면 없이 웹 브라우징을 할 수 있는 제품으로 기억나는 최초는 팬텀(PhantomJS)이다. 화면도 없이 브라우저를 열고 스크린 샷도 찍고 탐색하는 것이 엄청 신기했다. 지금은 개발이 중단되었다. 팬텀의 불편함을 극복해보고자 캐스퍼(CasperJS)도 나왔었는데 이것 역시 지금은 개발이 중단되었다. 아마도 퍼피티어(Puppeteer)와 플레이라이트(Playwright)같은 대안 프로젝트들이 구글과 마이크로소프트 같은 큰 회사에서 나와서 그렇게 된 것 같다.\n\r\n\r\n플레이라이트가 퍼피티어를 포크해서 나왔다고 하는데 두 프로젝트는 지향하는 바가 다르다. 퍼피티어가 헤드리스 크롬이나 파이어폭스를 편하게 활용할 수 있게 고안되었다면 플레이라이트는 테스트를 위한 스위트에 가깝다. 나는 테스트를 돌리기 보다는 브라우저에서의 작업이 필요해서 퍼피티어를 선택했다.\n\r\n\r\nAPI는 상당히 직관적이어서 예제를 보면 바로 브라우저를 실행해서 테스트 해 볼 수 있다. 브라우저 열고 페이지 열고 등 코드만 봐도 바로 이해가 간다. 나는 처리해야 하는 작업이 많아서 별도 스크립트를 page.$$eval을 사용해서 실행했다.\n\r\n\r\nconst imageCount = await page.$$eval(\"img\", (imgs) => imgs.length)\n\r\n\r\n서로 다른 컨텍스트를 직관적으로 연결해줘서 아주 사용하기 편하다. 예전과 비교하면 정말 좋아졌다.\n\r\n\r\n페이지를 열려면 const browser = await puppeteer.launch()로 브라우저를 실행하고 const page = await browser.newPage()로 페이지를 열어서 사용하게 된다. 처음에는 매번 브라우저를 여는 시간도 아깝고 보통 브라우저 사용하듯이 하나 실행해 놓고 페이지만 열고 닫으며 사용해봤다. 이렇게 하니 평소에 브라우저가 메모리 많이 사용하고 있다고 욕하던 상황이 서버에서 벌어져서 서버가 죽었다. 프로세스가 열리는 것을 보니 페이지 하나만 열어도 크롬 관련 프로세스가 열개가 넘게 뜨고 await page.close()로 페이지를 닫아줘도 일부 프로세스들이 계속 남아 있었다. 결국 계속 쓸수록 메모리 점유가 늘어났다. await browser.close()로 실행된 브라우저를 닫아줘야 프로세스가 모두 정리가 된다.\n\r\n\r\naccessibility.kr에서 지금까지는 자바스크립트로 생성되는 페이지를 검사할 수 없었는데 이제 검사할 수 있는 사이트가 많이 늘어났다. 리다이렉션 처리도 많이 개선되었다.",
        "guid": "https://hyeonseok.com/blog/916",
        "isoDate": "2024-08-25T17:26:34.000Z"
      }
    ]
  },
  {
    "name": "한상곤 - Sigmadream",
    "category": "개인",
    "posts": [
      {
        "creator": "Sangkon Han",
        "title": "우부콘 2024 간략한 후기",
        "link": "https://www.sangkon.com/ubukon-2024/",
        "pubDate": "Fri, 30 Aug 2024 18:15:40 GMT",
        "content:encodedSnippet": "느슨하지만 열정적인 조직\n이토록 느슨한 조직이 이렇게 대단한 행사를 진행할 수 있다는 것에 항상 감탄을 금하지 못합니다. 오픈소스 커뮤니티의 특성상 누군가의 피.땀.시간을 매몰해야 된긴 하지만(예를 들어, 우리 커뮤니티의 대장과 고문님) 대부분의 업무는 \"분할 정복 알고리즘\"에 기반한 \"태스크\" 할당으로 효율적으로 진행됩니다. 멀리서 지켜보면 행사 준비가 굉장히 느슨하게 이뤄지고 있지만, 모든 운영진의 노력과 열정 덕분에 느슨하지만 알차게 준비할 수 있었습니다. 회의록이나 기타 기록 등을 다시 되돌아보아도 의사결정 과정과 진행사항 및 처리 과정 등이 약간의 혼선이 있었지만, 슬기롭게 잘 대처한 듯 합니다.\n\n올해는 몇몇 운영진분들이 데비안 컨퍼런스 지원을 하면서 동시에 우분콘도 준비를 하시느라 다른 운영진에 비해서 몇배는 빠듯한 일정을 소화하시기도 했습니다. 노력과 열정 덕분에 올해 우부콘 2024도 즐겁고 신나게 막을 내릴 수 있었고, 내년도 우부콘을 준비할 수 있는 원동력이 되었습니다. 내년에는 올해보다 좀 더 개선된 버전으로 찾아뵐 수 있도록 하겠습니다.\n\n도움을 주신 모든 분\n이번 행사가 성공적일 수 있었던 가장 큰 이유는 151분의 참석자입니다. 올해에도 어김없이 참석해 주신 모든 분들에게 다시 한번 감사의 인사를 드립니다. 이런 큰 행사를 진행함에 있어서 외부에서 많은 도움을 주셨습니다. Ubuntu, Microsoft Korea, NHN Cloud, 안랩 클라우드메이트, GroMetric, WhaTap Labs와 한빛미디어에서 큰 도움을 주셨습니다.**\n무엇보다 서울 시내에서 원활하게 행사를 진행할 수 있도록 올해도 도움을 주신 Microsoft Korea의 공로를 뺴놓을 수 없습니다. ”우분투 리눅스“에서 주최하는 커뮤니티 행사를 위해서 금요일 저녁과 토요일 아침에 지원을 와주신 MS Korea 담당자님에게 다시 한번 감사드립니다. 서울 시내에 위치한 경관좋은 곳에서 이런 큰 행사를 진행할 수 있도록 지원해주신 Microsoft Korea뿐만 아니라 분들에게 감사의 인사를 드립니다. 내년에도 혹은 다음에도 좋은 인연으로 계속할 수 있기를 바랍니다.\n배포\n올해 주제는 ‘배포’입니다. 아마 국내에서 가장 많은 사용자를 가지고 있는 리눅스 배포판은 AL2일 것으로 예상됩니다. 도커와 같은 가상화 도구가 많이 활용되면서 어쩌면 Alpine Linux가 많이 활용될지도 모르겠습니다. 웹서비스를 사용하는 대부분의 팀은 최종 배포에 리눅스 운영체제를 선택하는 경우가 많아지고 있습니다.\n단순히 서비스를 배포한다는 관점에서 벗어나서 “전달” 혹은 “연결”이라는 개념을 포괄해서 구성된 세션으로 구성되었습니다. 개발의 끝단이자, 서비스의 시작이라 할 수 있는 배포라는 개념을 여러 분야의 활용 사례를 보여드릴 수 있도록 노력하였습니다. 리눅스 그 중에서 우분투 리눅스를 활용해서 서비스를 “전달”하고, 이기종 컴퓨터를 “연결”하고, 더 나아가 우리가 만든 소프트웨어를 “배포”하는데 활용할 수 있다는 개념이나 관점이 작게나마 전달되었기를 바랍니다. 올해 행사가 많은 분들에게 리눅스에서 무언가를 전달하는 것에 대한 개념이나 관점에 작은 도움이 되었기를 희망해봅니다.\n마지막으로, 2025년에 다시 뵙겠습니다.",
        "dc:creator": "Sangkon Han",
        "content": "<h2 id=\"%EB%8A%90%EC%8A%A8%ED%95%98%EC%A7%80%EB%A7%8C-%EC%97%B4%EC%A0%95%EC%A0%81%EC%9D%B8-%EC%A1%B0%EC%A7%81\">&#xB290;&#xC2A8;&#xD558;&#xC9C0;&#xB9CC; &#xC5F4;&#xC815;&#xC801;&#xC778; &#xC870;&#xC9C1;</h2>\n<p>&#xC774;&#xD1A0;&#xB85D; &#xB290;&#xC2A8;&#xD55C; &#xC870;&#xC9C1;&#xC774; &#xC774;&#xB807;&#xAC8C; &#xB300;&#xB2E8;&#xD55C; &#xD589;&#xC0AC;&#xB97C; &#xC9C4;&#xD589;&#xD560; &#xC218; &#xC788;&#xB2E4;&#xB294; &#xAC83;&#xC5D0; &#xD56D;&#xC0C1; &#xAC10;&#xD0C4;&#xC744; &#xAE08;&#xD558;&#xC9C0; &#xBABB;&#xD569;&#xB2C8;&#xB2E4;</p>",
        "contentSnippet": "느슨하지만 열정적인 조직\n이토록 느슨한 조직이 이렇게 대단한 행사를 진행할 수 있다는 것에 항상 감탄을 금하지 못합니다",
        "guid": "66d207374d836e346732cd6d",
        "categories": [
          "Etc..."
        ],
        "isoDate": "2024-08-30T18:15:40.000Z"
      }
    ]
  },
  {
    "name": "개발자 울이 노트",
    "category": "개인",
    "posts": []
  },
  {
    "name": "즐거운 개발자 :: 네이버  블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황제펭귄의 게임개발이야기 [여기는 한국]",
    "category": "개인",
    "posts": []
  },
  {
    "name": "LINE ENGINEERING",
    "category": "기업",
    "posts": [
      {
        "title": "기기와 앱의 무결성 보장부터 서비스 요청 보호까지: LINE의 기기 증명 서비스 - 2편",
        "link": "https://techblog.lycorp.co.jp/ko/line-device-attestation-2",
        "pubDate": "Fri, 30 Aug 2024 02:00:00 GMT",
        "content": "들어가며\n안녕하세요. Auth & Account Dev 팀의 김은찬, 김종민, 권기범, 정의엽, 허원영입니다. Auth & Account Dev 팀은 LY Corporation 그...",
        "contentSnippet": "들어가며\n안녕하세요. Auth & Account Dev 팀의 김은찬, 김종민, 권기범, 정의엽, 허원영입니다. Auth & Account Dev 팀은 LY Corporation 그...",
        "guid": "https://techblog.lycorp.co.jp/ko/line-device-attestation-2",
        "isoDate": "2024-08-30T02:00:00.000Z"
      },
      {
        "title": "쿠버네티스 커스텀 리소스 정의하고 관리하기(feat.컨트롤러)",
        "link": "https://techblog.lycorp.co.jp/ko/define-and-manage-kubernetes-custom-resources-with-controller",
        "pubDate": "Wed, 28 Aug 2024 02:00:00 GMT",
        "content": "안녕하세요. Cloud DBS 팀에서 사내 클라우드인 Verda의 데이터베이스와 OpenSearch 서비스 개발을 맡고 있는 강인배, 문현균입니다. 이번 글에서는 저희 팀에서 쿠버...",
        "contentSnippet": "안녕하세요. Cloud DBS 팀에서 사내 클라우드인 Verda의 데이터베이스와 OpenSearch 서비스 개발을 맡고 있는 강인배, 문현균입니다. 이번 글에서는 저희 팀에서 쿠버...",
        "guid": "https://techblog.lycorp.co.jp/ko/define-and-manage-kubernetes-custom-resources-with-controller",
        "isoDate": "2024-08-28T02:00:00.000Z"
      },
      {
        "title": "Kafka와 ETL을 활용해 대용량 데이터 마이그레이션하기",
        "link": "https://techblog.lycorp.co.jp/ko/migrating-large-data-with-kafka-and-etl",
        "pubDate": "Mon, 26 Aug 2024 02:00:00 GMT",
        "content": "들어가며\n안녕하세요. LINE Plus에서 Global E-Commerce Platform 개발을 맡고 있는 장효택입니다. \nLINE Brand Catalog와 통합 커머스 검색 ...",
        "contentSnippet": "들어가며\n안녕하세요. LINE Plus에서 Global E-Commerce Platform 개발을 맡고 있는 장효택입니다. \nLINE Brand Catalog와 통합 커머스 검색 ...",
        "guid": "https://techblog.lycorp.co.jp/ko/migrating-large-data-with-kafka-and-etl",
        "isoDate": "2024-08-26T02:00:00.000Z"
      }
    ]
  },
  {
    "name": "뱅크샐러드 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "우아한형제들 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "TOAST Meetup",
    "category": "기업",
    "posts": [
      {
        "title": "NHN Cloud의 보안 가이드를 소개합니다",
        "link": "https://meetup.nhncloud.com/posts/384",
        "pubDate": "Sun, 25 Aug 2024 23:38:45 GMT",
        "content": "![NHN Cloud_meetup banner_security guides_202408_900.png](https://image.toast.com/aaaadh/real/2024/techblog/NHN%20Cloudmeetup%20bannersecurity%20guides202408900.png)\r\r\n\r\r\n## 들어가며\r\r\n\r\r\n다양한 산업 분야에서 클라우드 컴퓨팅의 확장성, 유연성, 데이터 분석 및 협업 기능을 활용하여 경쟁력을 강화하고, 서비스 운영 효율성을 높이고 있습니다. 이제 클라우드 전환은 선택이 아닌 필수가 된 것처럼 보입니다. 하지만 가상화 기술, 자원의 공유 및 인터넷을 통한 접속이라는 클라우드의 특성으로 인해 취약점 공격이나 악성 코드, DDoS와 같이 온프레미스 환경에서도 나타났던 보안 위협뿐만 아니라 기존에 없던 유형의 보안 위협도 다양하게 발생할 수 있다는 점에서 클라우드 보안에 대한 우려는 남아 있는 상태입니다.\r\r\n\r\r\n클라우드를 안전하게 이용하기 위해서는 온프레미스 인프라와 대비되는 클라우드의 구조와 보안 관리 방안을 정확히 이해하고, 클라우드 서비스 공급자와 이용자가 협력하여 각자의 책임 영역에서 적극적인 정보보호 활동을 수행할 수 있어야 합니다. 이를 [보안 책임 공유 모델(shared security responsibility, SSRM)](https://www.nhncloud.com/kr/security-center/ssrm)이라고 하는데요. 이 모델에서는 안전한 클라우드 서비스를 위해 클라우드 서비스 공급자와 이용자의 책임과 역할을 분류하고, 각자가 통제하는 요소를 보호하여 클라우드 전반의 안전하고 신뢰성 있는 보안을 확립합니다.\r\r\n\r\r\n보안 책임 공유 모델에서 클라우드 서비스 이용자는 가상 리소스와 데이터 보안을 위해 클라우드 및 보안 서비스를 활용해 보안을 고려한 서비스를 구성하고 관리할 책임을 갖습니다. 이를 위해서는 온프레미스 환경과 대비되는 클라우드 컴퓨팅 환경의 특성과 보안 전반에 대한 이해가 선행되어야 합니다. NHN Cloud는 보안을 위한 다양한 서비스와 기능을 제공할 뿐만 아니라, 다양한 보안 가이드를 제공하여 이용자가 데이터, 애플리케이션, 운영체제 단에서 직접 수행해야 하는 작업이나 반드시 숙지해야 할 사항 등을 안내합니다. 이를 통해 클라우드 서비스 이용자 책임 영역의 보안을 강화하고, 클라우드에 대한 위협과 대응 방안, 클라우드 영역별 보안, 정보보호 등에 대한 이해를 돕기 위한 노력을 지속하고 있습니다.\r\r\n\r\r\n이 글에서는 [NHN Cloud 보안 센터](https://www.nhncloud.com/kr/security-center)에서 제공하는 다양한 보안 가이드의 종류를 알아보고, 상황과 필요에 따라 적합한 문서를 활용하실 수 있도록 각 가이드에 대해 소개하고자 합니다.\r\r\n\r\r\n## NHN Cloud 보안 가이드의 종류와 소개\r\r\n\r\r\n![02_보안가이드메인.png](https://image.toast.com/aaaadh/real/2024/techblog/02uBCF4uC548uAC00uC774uB4DCuBA54uC778.png)\r\r\n\r\r\n### **NHN Cloud 보안 백서**\r\r\n\r\r\n고객이 클라우드 환경의 보안을 쉽게 이해할 수 있도록 돕고, NHN Cloud가 제공하는 보안 체계와 기술을 안내하기 위해 제작된 「NHN Cloud 보안 백서」는 NHN Cloud의 이름으로 발행된 첫 번째 백서입니다. 온프레미스 인프라와 대비되는 클라우드 컴퓨팅 환경의 특성과 그 특성에 기인한 보안 위협, 클라우드 보안 전반에 대해 안내하고, NHN Cloud가 고객의 클라우드 인프라와 서비스, 이용자의 개인정보와 데이터를 보호하기 위해 제공하는 다양한 보안 서비스와 기능을 소개합니다. 클라우드 서비스 이용 시 적절한 기술적 보안 대책을 마련하는 데 참고하거나 취약점 관리, 위협 탐지 및 대응, 인증, 컴플라이언스, 접근 통제, 데이터 보호 및 암호화 서비스를 이용한 안전한 서비스 인프라를 구성하는 데도 활용할 수 있을 것으로 기대합니다.\r\r\n\r\r\n [NHN Cloud 보안 백서 다운로드 신청 페이지 바로 가기](https://info.nhncloud.com/security-whitepaper.html?utm_source=nhncloud&utm_medium=home&utm_campaign=whitepapers&utm_content=security01&utm_term=cta)\r\r\n<br>\r\r\n### **NHN Cloud 개인정보보호 준수 가이드**\r\r\n\r\r\n개인정보는 살아 있는 개인에 대한 정보로 이름, 주민등록번호, 영상 등을 통해 개인을 식별할 수 있는 정보를 의미합니다. 하나의 정보만으로 개인을 식별할 수 없더라도, 다른 정보와 결합하여 개인을 특정할 수 있다면 개인정보로 간주합니다. 인터넷 기술이 발전하고, 소셜 네트워킹, 쇼핑, 금융 거래 등 일상의 거의 모든 행위가 디지털화됨에 따라 우리는 수많은 개인정보를 온라인에 저장하고 공유하는데요. 개인정보가 유출될 경우 신원 도용이나 금융 사기, 프라이버시 침해 등 심각한 문제를 초래할 수 있기 때문에 개인정보보호는 점점 더 중요한 이슈로 부각되고 있습니다.\r\r\n개인정보보호법은 이러한 개인정보의 처리 및 보호에 관한 사항을 정하여 개인의 자유와 권리를 보호하고, 개인의 존엄과 가치를 구현하기 위해 제정된 법입니다. NHN Cloud는 고객이 클라우드 환경에서 개인정보보호법을 준수할 수 있도록 다양한 서비스와 기능을 제공합니다. 「NHN Cloud 개인정보보호 준수 가이드」는 개인정보 및 개인정보보호법이 무엇인지 살펴보고, 개인정보의 안전성 확보조치 기준에 대해 알아본 뒤 NHN Cloud가 제공하는 보안 서비스를 이용해 개인정보를 보호할 수 있는 방안을 안내합니다.\r\r\n\r\r\n [NHN  Cloud 개인정보보호 준수 가이드 다운로드 바로 가기](https://www.nhncloud.com/resources/download/NHN%20Cloud_Personal_Information_Compliance_Guide_2024.pdf)\r\r\n<br>\r\r\n### **NHN Cloud 콘솔 보안 가이드**\r\r\n\r\r\n콘솔은 클라우드 서비스 이용자가 클라우드 서비스를 직접 생성, 사용, 관리, 삭제할 수 있는 접점이며 환경입니다. 따라서 클라우드 콘솔 보안은 매우 중요하며, 이용자가 직접 구성하고 관리한다는 점에서 클라우드 및 네트워크 환경과 보안 요소, 보안 관리 방법, 그리고 클라우드에서 제공하는 보안 기능에 대한 정확한 이해가 선행되어야 합니다.\r\r\n많은 CSP에서 클라우드 보안을 위한 다양한 기능들을 선보이고 있고, NHN Cloud 역시 Network Firewall, Security Groups, Network ACL, DDoS Guard, Security Monitoring, Webshell Threat Detector, Security Advisor, NHN Bastion 등의 서비스를 제공하며 안전한 클라우드 컴퓨팅 환경을 제공하기 위해 노력하고 있습니다. 「NHN Cloud 콘솔 보안 가이드」는 이와 같은 NHN Cloud의 다양한 서비스에서 제공하는 보안 기능을 이용하여 클라우드 환경에서 애플리케이션 및 서비스를 안전하게 구성할 수 있도록 권장되는 보안 설정들에 대해 안내합니다. 계정 관리, 네트워크 보안, 서버 보안, 스토리지 보안, 데이터베이스 보안, 데이터 보호 및 키 관리, 로깅 및 모니터링과 같은 8개 영역에서 점검하고 관리할 수 있는 항목들을 제시하고 설명하며, 클라우드 서비스 이용자는 이를 기준으로 NHN Cloud 콘솔에서 직접 보안 기능을 설정하고 점검할 수 있습니다.\r\r\n\r\r\n [NHN Cloud 콘솔 보안 가이드 다운로드 바로 가기](https://www.nhncloud.com/resources/download/NHN_Cloud_Console_Security_Guide_2023.pdf)\r\r\n<br>\r\r\n### **NHN Cloud 네트워크 아키텍처 보안 가이드**\r\r\n\r\r\n「NHN Cloud 네트워크 아키텍처 보안 가이드」는 NHN Cloud에서 제공하는 다양한 네트워크 기능과 네트워크 보안 서비스를 이용하여 클라우드 환경에서 가상 인프라 및 서비스를 안전하게 구성하고 제공할 수 있는 네트워크 보안 아키텍처를 설명합니다.\r\r\n클라우드 환경의 네트워크 구성 시 따라야 할 네트워크 분리, 접근 제어, 위협 대응 관련 컴플라이언스를 정리하여 안내하며, 이에 기반한 네트워크 아키텍처 보안 고려 사항 및 보안 설계 기준을 제시합니다. 또한 클라우드 환경에서 기업이나 공공 시스템을 설계할 때 참고할 수 있는 네트워크 보안 아키텍처를 사례별로 제시하기 때문에 환경에 따라 다를 수 있는 네트워크 분리 기준과 방법, 분리된 구간의 연결과 접근 통제 방식 등을 좀더 구체적이고 다양한 관점에서 살펴보고 이해할 수 있습니다.\r\r\n\r\r\n [NHN Cloud 네트워크 아키텍처 보안 가이드 다운로드 바로 가기](https://www.nhncloud.com/resources/download/NHN_Cloud_Network_Architecture_Security_Guide_2024.pdf)\r\r\n<br>\r\r\n### **NHN Cloud 랜섬웨어 대응 가이드**\r\r\n\r\r\n랜섬웨어(ransomware)란 사용자의 컴퓨터 시스템을 장악하거나 데이터를 암호화하여 정상적으로 사용하지 못하게 만든 뒤 암호 키 또는 해제 방법을 알려주는 대가로 금전을 요구하는 악성 코드입니다. 최근 몇 년간 랜섬웨어가 사이버 공격의 주요 형태로 떠오르며 기업과 공공 기관, 개인 모두에게 심각한 피해를 입히고 있습니다.\r\r\n「NHN Cloud 랜섬웨어 대응 가이드」는 일반 악성코드와 대비되는 랜섬웨어의 특성과 공격 방식 및 유형을 살펴보고, 랜섬웨어가 사용하는 기술이 무엇인지 설명합니다. 그리고 랜섬웨어에 대비하여 클라우드 서비스 이용자가 취할 수 있는 효과적인 대응 전략과 방안을 제시합니다.\r\r\n\r\r\n [NHN Cloud 랜섬웨어 대응 가이드 다운로드 바로 가기](https://www.nhncloud.com/resources/download/NHN_Cloud_Ransomware_Response_Guide_2024.pdf)\r\r\n<br>\r\r\n### **NHN Cloud 컨테이너 보안 가이드**\r\r\n\r\r\n컨테이너란 데스크톱, 온프레미스, 클라우드 등 어떤 환경에도 구애 받지 않고 실행할 수 있도록 애플리케이션 코드를 해당 라이브러리 및 종속 항목과 함께 패키징한 소프트웨어 실행 유닛입니다. NHN Cloud는 이러한 컨테이너 환경에서 다양한 애플리케이션을 개발하고 운영할 수 있도록 NHN Kubernetes Service(NKS), NHN Container Registry(NCR), NHN Container Service(NCS)를 제공합니다. 「NHN Cloud 컨테이너 보안 가이드」는 NHN Cloud의 컨테이너 서비스에서 제공하는 보안 기능과 Kubernetes 보안 방법을 소개합니다. 본 가이드를 통해 컨테이너의 개념과 주요 구성 요소, 컨테이너 환경의 보안 위협과 보호 대상, 컨테이너 환경과 컨테이너를 기반으로 서비스하는 워크로드를 보호하는 방법 등을 이해할 수 있습니다.\r\r\n\r\r\n [NHN Cloud 컨테이너 보안 가이드 다운로드 바로 가기](https://www.nhncloud.com/resources/download/NHN%20Cloud_Container%20Security%20Guide_2024.pdf)\r\r\n<br>\r\r\n## 마치며\r\r\n\r\r\n여기까지 NHN Cloud의 다양한 보안 가이드의 종류와 활용에 대해 알아보았는데요. 2024년 8월 기준, NHN Cloud는 위와 같이 「NHN Cloud 보안 백서」, 「NHN Cloud 개인정보보호 준수 가이드」, 「NHN Cloud 콘솔 보안 가이드」, 「NHN Cloud 네트워크 아키텍처 가이드」, 「NHN Cloud 랜섬웨어 대응 가이드」, 「NHN Cloud 컨테이너 보안 가이드」를 제공하고 있습니다. 보안 가이드는 NHN Cloud를 활용해 서비스를 개발하고 운영하시는 아키텍트 및 보안 업무 담당자, NHN Cloud를 도입하고 구축하고자 하는 기업의 IT 담당자, 그리고 클라우드와 클라우드 환경 전반의 보안에 대해 알고 싶은 분들 모두가 자유롭게 이용하실 수 있으며, [NHN Cloud 홈페이지 > 보안 센터 > 보안 가이드](https://www.nhncloud.com/kr/security-center/guide) 페이지에서 확인하실 수 있습니다.\r\r\n\r\r\n긴 글을 읽어 주셔서 감사드리며, 앞으로도 NHN Cloud에서 제공하는 다양한 보안 가이드에 대해 많은 기대와 관심을 부탁드립니다. \r\r\n\r\r\n[![NHN Cloud_meetup banner_footer_black_202408_900.png](https://image.toast.com/aaaadh/real/2024/techblog/NHN%20Cloudmeetup%20bannerfooterblack202408900.png)](https://www.nhncloud.com/kr)",
        "contentSnippet": "![NHN Cloud_meetup banner_security guides_202408_900.png](https://image.toast.com/aaaadh/real/2024/techblog/NHN%20Cloudmeetup%20bannersecurity%20guides202408900.png)\r\r\n\r\r\n## 들어가며\r\r\n\r\r\n다양한 산업 분야에서 클라우드 컴퓨팅의 확장성, 유연성, 데이터 분석 및 협업 기능을 활용하여 경쟁력을 강화하고, 서비스 운영 효율성을 높이고 있습니다. 이제 클라우드 전환은 선택이 아닌 필수가 된 것처럼 보입니다. 하지만 가상화 기술, 자원의 공유 및 인터넷을 통한 접속이라는 클라우드의 특성으로 인해 취약점 공격이나 악성 코드, DDoS와 같이 온프레미스 환경에서도 나타났던 보안 위협뿐만 아니라 기존에 없던 유형의 보안 위협도 다양하게 발생할 수 있다는 점에서 클라우드 보안에 대한 우려는 남아 있는 상태입니다.\r\r\n\r\r\n클라우드를 안전하게 이용하기 위해서는 온프레미스 인프라와 대비되는 클라우드의 구조와 보안 관리 방안을 정확히 이해하고, 클라우드 서비스 공급자와 이용자가 협력하여 각자의 책임 영역에서 적극적인 정보보호 활동을 수행할 수 있어야 합니다. 이를 [보안 책임 공유 모델(shared security responsibility, SSRM)](https://www.nhncloud.com/kr/security-center/ssrm)이라고 하는데요. 이 모델에서는 안전한 클라우드 서비스를 위해 클라우드 서비스 공급자와 이용자의 책임과 역할을 분류하고, 각자가 통제하는 요소를 보호하여 클라우드 전반의 안전하고 신뢰성 있는 보안을 확립합니다.\r\r\n\r\r\n보안 책임 공유 모델에서 클라우드 서비스 이용자는 가상 리소스와 데이터 보안을 위해 클라우드 및 보안 서비스를 활용해 보안을 고려한 서비스를 구성하고 관리할 책임을 갖습니다. 이를 위해서는 온프레미스 환경과 대비되는 클라우드 컴퓨팅 환경의 특성과 보안 전반에 대한 이해가 선행되어야 합니다. NHN Cloud는 보안을 위한 다양한 서비스와 기능을 제공할 뿐만 아니라, 다양한 보안 가이드를 제공하여 이용자가 데이터, 애플리케이션, 운영체제 단에서 직접 수행해야 하는 작업이나 반드시 숙지해야 할 사항 등을 안내합니다. 이를 통해 클라우드 서비스 이용자 책임 영역의 보안을 강화하고, 클라우드에 대한 위협과 대응 방안, 클라우드 영역별 보안, 정보보호 등에 대한 이해를 돕기 위한 노력을 지속하고 있습니다.\r\r\n\r\r\n이 글에서는 [NHN Cloud 보안 센터](https://www.nhncloud.com/kr/security-center)에서 제공하는 다양한 보안 가이드의 종류를 알아보고, 상황과 필요에 따라 적합한 문서를 활용하실 수 있도록 각 가이드에 대해 소개하고자 합니다.\r\r\n\r\r\n## NHN Cloud 보안 가이드의 종류와 소개\r\r\n\r\r\n![02_보안가이드메인.png](https://image.toast.com/aaaadh/real/2024/techblog/02uBCF4uC548uAC00uC774uB4DCuBA54uC778.png)\r\r\n\r\r\n### **NHN Cloud 보안 백서**\r\r\n\r\r\n고객이 클라우드 환경의 보안을 쉽게 이해할 수 있도록 돕고, NHN Cloud가 제공하는 보안 체계와 기술을 안내하기 위해 제작된 「NHN Cloud 보안 백서」는 NHN Cloud의 이름으로 발행된 첫 번째 백서입니다. 온프레미스 인프라와 대비되는 클라우드 컴퓨팅 환경의 특성과 그 특성에 기인한 보안 위협, 클라우드 보안 전반에 대해 안내하고, NHN Cloud가 고객의 클라우드 인프라와 서비스, 이용자의 개인정보와 데이터를 보호하기 위해 제공하는 다양한 보안 서비스와 기능을 소개합니다. 클라우드 서비스 이용 시 적절한 기술적 보안 대책을 마련하는 데 참고하거나 취약점 관리, 위협 탐지 및 대응, 인증, 컴플라이언스, 접근 통제, 데이터 보호 및 암호화 서비스를 이용한 안전한 서비스 인프라를 구성하는 데도 활용할 수 있을 것으로 기대합니다.\r\r\n\r\r\n [NHN Cloud 보안 백서 다운로드 신청 페이지 바로 가기](https://info.nhncloud.com/security-whitepaper.html?utm_source=nhncloud&utm_medium=home&utm_campaign=whitepapers&utm_content=security01&utm_term=cta)\r\r\n\r\r\n### **NHN Cloud 개인정보보호 준수 가이드**\r\r\n\r\r\n개인정보는 살아 있는 개인에 대한 정보로 이름, 주민등록번호, 영상 등을 통해 개인을 식별할 수 있는 정보를 의미합니다. 하나의 정보만으로 개인을 식별할 수 없더라도, 다른 정보와 결합하여 개인을 특정할 수 있다면 개인정보로 간주합니다. 인터넷 기술이 발전하고, 소셜 네트워킹, 쇼핑, 금융 거래 등 일상의 거의 모든 행위가 디지털화됨에 따라 우리는 수많은 개인정보를 온라인에 저장하고 공유하는데요. 개인정보가 유출될 경우 신원 도용이나 금융 사기, 프라이버시 침해 등 심각한 문제를 초래할 수 있기 때문에 개인정보보호는 점점 더 중요한 이슈로 부각되고 있습니다.\r\r\n개인정보보호법은 이러한 개인정보의 처리 및 보호에 관한 사항을 정하여 개인의 자유와 권리를 보호하고, 개인의 존엄과 가치를 구현하기 위해 제정된 법입니다. NHN Cloud는 고객이 클라우드 환경에서 개인정보보호법을 준수할 수 있도록 다양한 서비스와 기능을 제공합니다. 「NHN Cloud 개인정보보호 준수 가이드」는 개인정보 및 개인정보보호법이 무엇인지 살펴보고, 개인정보의 안전성 확보조치 기준에 대해 알아본 뒤 NHN Cloud가 제공하는 보안 서비스를 이용해 개인정보를 보호할 수 있는 방안을 안내합니다.\r\r\n\r\r\n [NHN  Cloud 개인정보보호 준수 가이드 다운로드 바로 가기](https://www.nhncloud.com/resources/download/NHN%20Cloud_Personal_Information_Compliance_Guide_2024.pdf)\r\r\n\r\r\n### **NHN Cloud 콘솔 보안 가이드**\r\r\n\r\r\n콘솔은 클라우드 서비스 이용자가 클라우드 서비스를 직접 생성, 사용, 관리, 삭제할 수 있는 접점이며 환경입니다. 따라서 클라우드 콘솔 보안은 매우 중요하며, 이용자가 직접 구성하고 관리한다는 점에서 클라우드 및 네트워크 환경과 보안 요소, 보안 관리 방법, 그리고 클라우드에서 제공하는 보안 기능에 대한 정확한 이해가 선행되어야 합니다.\r\r\n많은 CSP에서 클라우드 보안을 위한 다양한 기능들을 선보이고 있고, NHN Cloud 역시 Network Firewall, Security Groups, Network ACL, DDoS Guard, Security Monitoring, Webshell Threat Detector, Security Advisor, NHN Bastion 등의 서비스를 제공하며 안전한 클라우드 컴퓨팅 환경을 제공하기 위해 노력하고 있습니다. 「NHN Cloud 콘솔 보안 가이드」는 이와 같은 NHN Cloud의 다양한 서비스에서 제공하는 보안 기능을 이용하여 클라우드 환경에서 애플리케이션 및 서비스를 안전하게 구성할 수 있도록 권장되는 보안 설정들에 대해 안내합니다. 계정 관리, 네트워크 보안, 서버 보안, 스토리지 보안, 데이터베이스 보안, 데이터 보호 및 키 관리, 로깅 및 모니터링과 같은 8개 영역에서 점검하고 관리할 수 있는 항목들을 제시하고 설명하며, 클라우드 서비스 이용자는 이를 기준으로 NHN Cloud 콘솔에서 직접 보안 기능을 설정하고 점검할 수 있습니다.\r\r\n\r\r\n [NHN Cloud 콘솔 보안 가이드 다운로드 바로 가기](https://www.nhncloud.com/resources/download/NHN_Cloud_Console_Security_Guide_2023.pdf)\r\r\n\r\r\n### **NHN Cloud 네트워크 아키텍처 보안 가이드**\r\r\n\r\r\n「NHN Cloud 네트워크 아키텍처 보안 가이드」는 NHN Cloud에서 제공하는 다양한 네트워크 기능과 네트워크 보안 서비스를 이용하여 클라우드 환경에서 가상 인프라 및 서비스를 안전하게 구성하고 제공할 수 있는 네트워크 보안 아키텍처를 설명합니다.\r\r\n클라우드 환경의 네트워크 구성 시 따라야 할 네트워크 분리, 접근 제어, 위협 대응 관련 컴플라이언스를 정리하여 안내하며, 이에 기반한 네트워크 아키텍처 보안 고려 사항 및 보안 설계 기준을 제시합니다. 또한 클라우드 환경에서 기업이나 공공 시스템을 설계할 때 참고할 수 있는 네트워크 보안 아키텍처를 사례별로 제시하기 때문에 환경에 따라 다를 수 있는 네트워크 분리 기준과 방법, 분리된 구간의 연결과 접근 통제 방식 등을 좀더 구체적이고 다양한 관점에서 살펴보고 이해할 수 있습니다.\r\r\n\r\r\n [NHN Cloud 네트워크 아키텍처 보안 가이드 다운로드 바로 가기](https://www.nhncloud.com/resources/download/NHN_Cloud_Network_Architecture_Security_Guide_2024.pdf)\r\r\n\r\r\n### **NHN Cloud 랜섬웨어 대응 가이드**\r\r\n\r\r\n랜섬웨어(ransomware)란 사용자의 컴퓨터 시스템을 장악하거나 데이터를 암호화하여 정상적으로 사용하지 못하게 만든 뒤 암호 키 또는 해제 방법을 알려주는 대가로 금전을 요구하는 악성 코드입니다. 최근 몇 년간 랜섬웨어가 사이버 공격의 주요 형태로 떠오르며 기업과 공공 기관, 개인 모두에게 심각한 피해를 입히고 있습니다.\r\r\n「NHN Cloud 랜섬웨어 대응 가이드」는 일반 악성코드와 대비되는 랜섬웨어의 특성과 공격 방식 및 유형을 살펴보고, 랜섬웨어가 사용하는 기술이 무엇인지 설명합니다. 그리고 랜섬웨어에 대비하여 클라우드 서비스 이용자가 취할 수 있는 효과적인 대응 전략과 방안을 제시합니다.\r\r\n\r\r\n [NHN Cloud 랜섬웨어 대응 가이드 다운로드 바로 가기](https://www.nhncloud.com/resources/download/NHN_Cloud_Ransomware_Response_Guide_2024.pdf)\r\r\n\r\r\n### **NHN Cloud 컨테이너 보안 가이드**\r\r\n\r\r\n컨테이너란 데스크톱, 온프레미스, 클라우드 등 어떤 환경에도 구애 받지 않고 실행할 수 있도록 애플리케이션 코드를 해당 라이브러리 및 종속 항목과 함께 패키징한 소프트웨어 실행 유닛입니다. NHN Cloud는 이러한 컨테이너 환경에서 다양한 애플리케이션을 개발하고 운영할 수 있도록 NHN Kubernetes Service(NKS), NHN Container Registry(NCR), NHN Container Service(NCS)를 제공합니다. 「NHN Cloud 컨테이너 보안 가이드」는 NHN Cloud의 컨테이너 서비스에서 제공하는 보안 기능과 Kubernetes 보안 방법을 소개합니다. 본 가이드를 통해 컨테이너의 개념과 주요 구성 요소, 컨테이너 환경의 보안 위협과 보호 대상, 컨테이너 환경과 컨테이너를 기반으로 서비스하는 워크로드를 보호하는 방법 등을 이해할 수 있습니다.\r\r\n\r\r\n [NHN Cloud 컨테이너 보안 가이드 다운로드 바로 가기](https://www.nhncloud.com/resources/download/NHN%20Cloud_Container%20Security%20Guide_2024.pdf)\r\r\n\r\r\n## 마치며\r\r\n\r\r\n여기까지 NHN Cloud의 다양한 보안 가이드의 종류와 활용에 대해 알아보았는데요. 2024년 8월 기준, NHN Cloud는 위와 같이 「NHN Cloud 보안 백서」, 「NHN Cloud 개인정보보호 준수 가이드」, 「NHN Cloud 콘솔 보안 가이드」, 「NHN Cloud 네트워크 아키텍처 가이드」, 「NHN Cloud 랜섬웨어 대응 가이드」, 「NHN Cloud 컨테이너 보안 가이드」를 제공하고 있습니다. 보안 가이드는 NHN Cloud를 활용해 서비스를 개발하고 운영하시는 아키텍트 및 보안 업무 담당자, NHN Cloud를 도입하고 구축하고자 하는 기업의 IT 담당자, 그리고 클라우드와 클라우드 환경 전반의 보안에 대해 알고 싶은 분들 모두가 자유롭게 이용하실 수 있으며, [NHN Cloud 홈페이지 > 보안 센터 > 보안 가이드](https://www.nhncloud.com/kr/security-center/guide) 페이지에서 확인하실 수 있습니다.\r\r\n\r\r\n긴 글을 읽어 주셔서 감사드리며, 앞으로도 NHN Cloud에서 제공하는 다양한 보안 가이드에 대해 많은 기대와 관심을 부탁드립니다. \r\r\n\r\r\n[![NHN Cloud_meetup banner_footer_black_202408_900.png](https://image.toast.com/aaaadh/real/2024/techblog/NHN%20Cloudmeetup%20bannerfooterblack202408900.png)](https://www.nhncloud.com/kr)",
        "isoDate": "2024-08-25T23:38:45.000Z"
      }
    ]
  },
  {
    "name": "ZUM 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "SK Planet",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Spoqa tech blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "팀 왈도 번역팀",
    "category": "게임",
    "posts": []
  },
  {
    "name": "이한",
    "category": "개인",
    "posts": []
  },
  {
    "name": "근원님",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황의윤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "호돌맨",
    "category": "개인",
    "posts": []
  },
  {
    "name": "박우빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "문다영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "유수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "안건주",
    "category": "개인",
    "posts": []
  },
  {
    "name": "손현호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "STARTUP BIBLE",
    "category": "개인",
    "posts": [
      {
        "creator": "Kihong Bae",
        "title": "자신감에 대해서 – part 1",
        "link": "https://www.thestartupbible.com/2024/08/on-confidence-part-1.html",
        "pubDate": "Wed, 28 Aug 2024 21:33:00 +0000",
        "content:encodedSnippet": "요새 나는 한국보단 해외 투자자들을 훨씬 더 많이 만나서 이들에게 돈을 받기 위해 노력하고 있다. 남에게 돈 받는 건 항상 어려운 일이고, 특히나 요새 같이 이자율이 높고 경제 상황이 좋지 않은 불경기엔 펀딩이 더욱더 힘들어 진다.(VC들의 펀딩이 이렇게 어렵다 보니, 우리 같은 VC에게 투자받아야 하는 창업가들의 펀딩은 더 어렵고 시간이 오래 걸릴 수밖에 없다).\n하지만, 몇 년 전과 비교해 보면 좋아진 점도 있는데, 그건 바로 한국이라는 나라의 이미지와 한국의 벤처 시장이 과거와는 비교할 수 없을 정도로 좋아졌다는 것이다. 전에는 잠재 LP들에게 왜 스트롱 같이 한국에 투자하는 VC에 출자해야 하는지 설명하는 데만 상당히 많은 시간을 할애했고, 이 설명의 기간이 어떤 경우엔 수년이 걸렸다. 하지만, 이젠 대부분의 투자자들이 한국이라는 시장에 대한 의문이나 의심은 없을 정도로 한국의 벤처생태계가 그동안 많은 발전을 했다.\n내가 잠재 LP들에게 최근에 가장 많이 받은 질문은 어떻게 이렇게 상대적으로 짧은 기간 안에 한국의 스타트업 시장이 좋아졌냐인데, 이 질문에 대한 짧은 답변은 아주 간단하게 그냥 한국 창업가들의 수준이 매우 높아졌다는 것이다. 그럼, 왜 한국 창업가들의 수준이 이렇게 좋아졌을까? 여기에 대한 여러 가지 이론, 생각, 그리고 각자의 경험이 있지만, 내가 딱 한 가지만 강조하자면, 그건 ‘자신감’이라고 생각한다.\n창업가의 자신감은 정말 중요하다. 내가 하는 사업에 대한 확신과 자신감, 내가 만들고 있는 제품에 대한 자신감, 그리고 나 스스로에 대한 자신감은 안 되는 사업도 되게 하고, 못 받던 펀딩도 받게 한다. 평소에 잘 안되던 것들이 자신감과 이로 인한 파급 효과로 인해서 하나씩 만들어지는 걸 경험하는 순간, 잠재의식 속에서는 더 큰 자신감이 무의식적으로 생기고, 이건 결국엔 성공의 확률을 높일 수밖에 없다. 창업가들이 이렇게 자신감으로 무장되면, 기업가치 300억 원의 회사를 만들겠다던 목표가 1,000억 원이 된다. 그리고 이 목표가 계속 커져서 결국엔 10조 원짜리 데카콘까지 바라볼 수 있게 만드는 게 창업가의 자신감이다.\n비공식적인 기록이지만, 한국에는 유니콘 기업이 22개나 있다. 작은 나라치곤 엄청나게 많은 유니콘이다. 이런 사실도 한국 창업가들에겐 큰 자신감을 준다. 이렇게 작은 나라에서 기업가치가 1조 원 이상인 비상장 회사가 이렇게 많다는 점, 이 중 몇 개의 기업은 본인이 개인적으로 아는 창업가들이 만들었는데, 그들도 그냥 나랑 비슷한 평범한 사람이라는 점, 그래서 어쩌면, 그리고 언젠가는 나도 수천억 원의 펀딩을 받고 유니콘 기업을 만들 수 있다는 생각만으로도 이 창업가의 자신감은 하늘을 찌를 수 있다.\n쿠팡의 뉴욕증권거래소 상장은 한국 창업가들의 마음에 큰불을 질렀다. 한국 시장만을 상대로 이커머스 사업을 하는 회사가 미국에서 IPO를 했고, 지금은 좀 내려갔지만, 한때는 기업가치가 100조 원에 육박했다는 사실은 한국 창업가들에게 엄청난 자신감을 준 큰 사건이었다. 그동안 항상 한국 시장이 작고, 한국 기업이 미국에서 상장하는 건 불가능하다는 부정적인 이야기만 들었고, 한국인들도 항상 곧 망할 거라고 확신했던 쿠팡이라는 회사를, 김범석이라는 창업가가 이런 비관론자들에게 마치 fuck you를 날리듯 보기 좋게 성공시켰다.\n배달의민족 엑싯도 한국 창업가들에게 큰 자신감을 줬다. 국내에서 학교를 다녔고, 국내에서만 일 한 경험이 있는 순수 토종 창업가 김봉진 대표가 만든 한국의 스타트업이 수조 원의 기업가치에 외국 회사에 인수됐을 때, 많은 한국의 창업가들이 “아, 유니콘은 외국에서 공부한 엄친아들만 만들 수 있는 줄 알았는데, 그게 아니구나. 나도 더 열심히 하면 배달의민족보다 훨씬 더 큰 회사를 만들 수도 있겠다.”와 비슷한 생각을 하면서 할 수 있다는 아주 큰 자신감이 생겼을 것이다.\n그리고 이 자신감은 창업가들에게만 해당하는 건 아니다. 이들에게 투자했던 VC들에도 해당한다. 스타트업에 투자해서 큰돈을 버는 건 외국 VC에만 해당하는 먼 나라 이야기라고 생각했던 국내 VC들도 투자한 회사들이 유니콘이 되고, 이들이 엑싯했을 때 엄청나게 큰돈을 벌면서, 앞으로 더욱더 많은 유니콘 회사를 발굴해서 투자할 수 있다는 자신감이 생겼다. 이 자신감으로 이들은 더 큰 펀드를 만들고, 더 큰 펀드로 더 많은 좋은 회사에 투자하고 있다.\n이런 자신감들이 처음에는 작게 생기다가, 시간이 지나면서 여기저기서 생기고, 이게 계속 쌓이면서 어느 순간 폭발적으로 커지는데, 이럴 때 대단한 일들이 벌어진다.\n지금이 바로 한국 스타트업 생태계에서 이런 일들이 일어나고 있다고 나는 생각하고, 앞으로 한국의 스타트업 시장은 더욱더 좋아질 거라고 확신한다.\nPart 2에서도 자신감 관련 이야기를 조금 더 해보고 싶다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2024/08/on-confidence-part-1.html#respond",
        "content": "요새 나는 한국보단 해외 투자자들을 훨씬 더 많이 만나서 이들에게 돈을 받기 위해 노력하고 있다. 남에게 돈 받는 건 항상 어려운 일이고, 특히나 요새 같이 이자율이 높고 경제 상황이 좋지 않은 불경기엔 펀딩이 더욱더 힘들어 진다.(VC들의 펀딩이 이렇게 어렵다 보니, 우리 같은 VC에게 투자받아야 하는 창업가들의 펀딩은 더 어렵고 시간이 오래 걸릴 수밖에 없다). 하지만,(...)",
        "contentSnippet": "요새 나는 한국보단 해외 투자자들을 훨씬 더 많이 만나서 이들에게 돈을 받기 위해 노력하고 있다. 남에게 돈 받는 건 항상 어려운 일이고, 특히나 요새 같이 이자율이 높고 경제 상황이 좋지 않은 불경기엔 펀딩이 더욱더 힘들어 진다.(VC들의 펀딩이 이렇게 어렵다 보니, 우리 같은 VC에게 투자받아야 하는 창업가들의 펀딩은 더 어렵고 시간이 오래 걸릴 수밖에 없다). 하지만,(...)",
        "guid": "https://www.thestartupbible.com/?p=9192",
        "categories": [
          "Uncategorized",
          "confidence",
          "FoundersAtWork",
          "fundraising",
          "korea",
          "Strong",
          "vc"
        ],
        "isoDate": "2024-08-28T21:33:00.000Z"
      },
      {
        "creator": "Kihong Bae",
        "title": "회사는 놀이터가 아니다",
        "link": "https://www.thestartupbible.com/2024/08/your-company-is-not-your-playground.html",
        "pubDate": "Sun, 25 Aug 2024 21:38:00 +0000",
        "content:encodedSnippet": "내가 약 5개월 전에 쓴 글 ‘개발자도 회사의 조직원이다’가 최근에 여기저기서 공유가 많이 된 것 같다. 뭐, 이곳은 내 개인적인 블로그라서 남 눈치 안 보고 그냥 내 생각을 끄적거리는데, 사람들이 세상을 보는 관점도 다르고, 특정 주제에 대한 생각도 달라서 그런지 많은 분들이 여러 가지 의견을 댓글로 남겨줬다.\n댓글, 댓글의 대댓글, 그리고 여기에 대한 주인장의 댓글을 모두 합치면 50개가 넘는 코멘트가 있다. 이 중, 그래도 이성적이고 논리적인 이야기가 가능한 분위기의 댓글에는 내가 최대한 진정성 있는 코멘트를 남겼는데, 그냥 개싸움이 될 것 같은 분위기의 댓글은 건드리지 않았다. 대신, 그런 코멘트에 대해서는 이번 포스팅을 통해서 아주 간략하게 내 생각을 종합적으로 다시 한번 공유하고 싶다.\n일단, 이 글에 이렇게 격한 반응을 해주신 걸 보니, 한국에도 돈을 많이 벌고 싶어 하고, 성공에 목마른 개발자들이 많은 것 같아서 너무 다행이다. 이런 분들이 더 많아져야지 스타트업도 잘 되고, 경쟁력 있는 회사들이 많이 나온다고 생각한다.\n한 가지 사과하고 명확하게 하고 싶은 건, 내가 개발자들을 공격하려는 의도로 이전 글을 쓴 건 아니라는 점이다. 기획자이든 마케터이든 개발자이든, 모든 직원은 회사의 조직원인데 굳이 개발자를 꼭 집어서 글을 썼던 이유는 내가 아는 대부분의 조직에선 제품을 만들고 판매해서 돈을 버는 핵심 업무를 하는 그룹 군에서 돈을 버는 기능에 가장 관심이 적은 조직이 개발 조직이기 때문이다. 물론, 이건 개인적인 관점이다.\n몇 개의 댓글을 읽어보면, 회사가 잘 돼 봤자 사장만 돈 버는데 내가 굳이 열심히 할 필요가 없다는 내용이다. 특히나 회사의 지분도 없는데. 이런 분들은 내 블로그에서 불평하지 말고, 소속된 회사의 사장과 이런 이야기를 하는 걸 권장한다. 회사에 돈을 벌어 주는 일을 열심히 하는 직원에게 스톡옵션 또는, 그 어떤 보상도 하지 않는 사장이라면 굳이 이런 회사에 계속 다닐 필욘 없을 것 같다. 그냥 다른 곳으로 가면 된다. 만약 본인이 열심히 일하지 않거나 실력이 없어서 보상받을 수준이 안되면 그냥 불평하지 말고 그 회사 계속 다니면 된다. 어쨌든 이런 불평을 하면서도 계속 그 회사에 다니고 있다면, 본인 자신의 실력을 의심해 봐야 한다.\n개발자로서 기술적 모험이 제한된다면 굳이 스타트업에 갈 필요가 없다고 한 분도 있다. 이런 의견에 대한 내 생각 두 가지를 공유한다. 일단 본인이 기술적 모험을 하고 싶다면, 그리고 이 모험이 회사의 비즈니스 방향과 크게 상관없다면(=돈을 벌 수 있는 기술이 아니라면) 이걸 허락하는 다른 곳으로 가면 된다. 그런데 돈 버는 거와 상관없는 기술적 모험을 허락하는 내가 아는 곳들은 학교 아니면 연구소다. 회사는 아닐 것이다. 또 다른 생각은, 스타트업을 포함한 모든 회사는 개발자들이 기술적인 모험을 하는 놀이터가 아니다. 남의 돈으로 빨리 돈을 벌어서 압축적인 성장을 해야 하는 조직이다. 회사는 돈 받고 그냥 하루 종일 놀다 퇴근하는 곳이 아니다.\n또한, 회사라는 조직은 분명히 회사라는 집단의 목표가 있고, 이를 달성해야 하지만, 어떤 분들이 주장하는 개인적인 발전도 동시에 균형 있게 가져가야 한다. 나도 이건 동의한다. 하지만, 우선순위를 매기자면 무조건 회사의 목표가 먼저이고, 이게 어느 정도 된 후에 회사의 목표를 같이 만드는 개인의 발전에 신경 써줄 수 있다. 회사의 목표는 무조건 돈 버는 게 돼야 하고, 여기에 먼저 동참할 수 없다면 개발자든 마케터든 회사에겐 부채가 되고, 부채는 가장 먼저 제거해야 하는 짐이 될 수밖에 없다.\n그리고 어떤 분들의 댓글을 보고 나는 정말로 이 사람들이 일하는 회사가 어딘지 궁금해지기도 했다. 그 회사 동료들이 너무 불쌍해서…\n이 글 밑에 분명히 멋진 댓글도 많이 달릴 거지만, 거지 같은 댓글도 많이 올라올 것이다. 그 수준과 정도를 종합적으로 판단해서, 필요하면 또 한 번 내 의견을 공유하는 포스팅을 올릴 계획이다. 그런데 키보드 뒤에서 인신공격적인 코멘트를 달거나, 너무 멍청한 코멘트를 다는 분들은 익명이 아니라 실명을 밝혀주시면 오히려 더 건설적인 이야기가 가능하지 않을까 싶다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2024/08/your-company-is-not-your-playground.html#comments",
        "content": "내가 약 5개월 전에 쓴 글 ‘개발자도 회사의 조직원이다’가 최근에 여기저기서 공유가 많이 된 것 같다. 뭐, 이곳은 내 개인적인 블로그라서 남 눈치 안 보고 그냥 내 생각을 끄적거리는데, 사람들이 세상을 보는 관점도 다르고, 특정 주제에 대한 생각도 달라서 그런지 많은 분들이 여러 가지 의견을 댓글로 남겨줬다. 댓글, 댓글의 대댓글, 그리고 여기에 대한 주인장의 댓글을(...)",
        "contentSnippet": "내가 약 5개월 전에 쓴 글 ‘개발자도 회사의 조직원이다’가 최근에 여기저기서 공유가 많이 된 것 같다. 뭐, 이곳은 내 개인적인 블로그라서 남 눈치 안 보고 그냥 내 생각을 끄적거리는데, 사람들이 세상을 보는 관점도 다르고, 특정 주제에 대한 생각도 달라서 그런지 많은 분들이 여러 가지 의견을 댓글로 남겨줬다. 댓글, 댓글의 대댓글, 그리고 여기에 대한 주인장의 댓글을(...)",
        "guid": "https://www.thestartupbible.com/?p=9188",
        "categories": [
          "Uncategorized",
          "korea",
          "people",
          "technology",
          "vc",
          "스타트업 바이블 QA"
        ],
        "isoDate": "2024-08-25T21:38:00.000Z"
      }
    ]
  },
  {
    "name": "Build a Great Product",
    "category": "개인",
    "posts": []
  },
  {
    "name": "지금 써보러 갑니다",
    "category": "개인",
    "posts": []
  },
  {
    "name": "매거진 입맛",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "요즘 IT",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "쿠팡 엔지니어링",
    "category": "기업",
    "posts": []
  },
  {
    "name": "지마켓 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "리멤버 (드라마 앤 컴퍼니)",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Kimchi hill",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Hudi.blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "토스",
    "category": "기업",
    "posts": [
      {
        "title": "국내 숙박 상품 최대 3만 원 할인받을 수 있어요: 대한민국 숙박 세일 페스타",
        "link": "https://blog.toss.im/article/money-policies-24",
        "pubDate": "Fri, 30 Aug 2024 01:21:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}문화체육관광부와 한국관광공사에서 ‘대한민국 숙박 세일 페스타’를 개최하고, 추석 연휴에도 사용할 수 있는 숙박 시설 할인권 20만 장을 지급해요.\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n국내 숙박 상품 최대 3만 원 할인받을 수 있어요\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}할인권 발급 기간: .css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}8월 27(화)~9월 20일(일)\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}*매일 오전 10시부터 선착순 발급\n입실 기간 : 9월 9일(월)~10월 13일(일)\n사용 지역 : 비수도권 지역(서울, 경기, 인천 제외)\n할인 혜택\n\n7만원 이상 국내 숙박상품 예약시 3만원 할인\n7만원 미만 국내 숙박상품 예약 시 2만원 할인\n\n*단, 부가세 포함 2만원 이상 숙박상품 구매 시\n\n\n\n사용 방법\n.css-hokoge{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;counter-reset:numberedList;}.css-hokoge ul,.css-hokoge ol{margin:16px 0 0;}.css-hokoge>li{counter-increment:numberedList;margin-bottom:16px;padding-left:24px;}.css-hokoge>li:last-of-type{margin-bottom:0;}.css-hokoge>li>span{position:relative;}.css-hokoge>li>span>:first-child::before{content:counter(numberedList) '.';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n38개 참여 온라인 여행사에서 할인권 발급받기\n가고 싶은 국내 숙박* 선택하기\n*호텔, 콘도, 리조트, 펜션 등\n숙박 할인권으로 할인받기\n안전하고 행복한 국내 여행 즐기기\n\n\n유의 사항\n\n준비된 쿠폰 물량 소진 시 조기 종료될 수 있어요.\n미등록 숙박시설이나 대실은 사용할 수 없어요.\n사업 기간, 참여 여행사 등 일부 내용이 변동될 수 있어요.\n\n자세한 내용은 대한민국 구석구석 누리집(.css-iynyr0{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);-webkit-text-decoration:underline!important;text-decoration:underline!important;}https://ktostay.visitkorea.or.kr/) 또는 콜센터(1670-3980)에서 확인할 수 있어요.",
        "content": "숙박시설 할인권 20만 장을 지급해요. ",
        "contentSnippet": "숙박시설 할인권 20만 장을 지급해요.",
        "guid": "https://blog.toss.im/article/money-policies-24",
        "isoDate": "2024-08-30T01:21:00.000Z"
      },
      {
        "title": "토스, 개발자 컨퍼런스 ‘슬래시24’ 참가 신청 시작",
        "link": "https://blog.toss.im/article/slash24-conference",
        "pubDate": "Mon, 26 Aug 2024 04:56:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}9월 12일(목) 코엑스에서 역대 최초 오프라인 개최… 개발자 45명 연사로 나서\n총 1,500명 추첨 통해 선발, 참가 접수 9월 2일까지\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1kxrhf3{white-space:pre-wrap;}토스가 개발자 컨퍼런스 '슬래시24(SLASH24, 이하 슬래시)'의 참가 신청을 시작했다.\n슬래시는 토스 커뮤니티의 개발자들이 기술적인 성취와 러닝을 공유하는 자리다. 4회째를 맞은 올해의 주제는 ‘No Limit: 풀지 못할 문제는 없다'로, 끊임없이 도전하고 시도하며 끝내 문제를 해결해 내는 토스의 개발 문화를 반영했다.\n이번 행사는 오프라인에서 최초로 개최된다는 점에서 특별하다. 9월 12일(목) 오전 10시부터 오후 4시까지 코엑스 그랜드볼룸에서 열린다. 토스, 토스뱅크, 토스증권, 토스페이먼츠, 토스플레이스 등 5개 법인에서 총 45명의 개발자들이 연사로 나선다.\n첫 번째 순서로는 토스의 테크놀로지 총괄 이형석 CTO가 발표를 진행한다. 이형석 CTO는 핀테크 업계의 지형을 바꿔온 토스가 혁신을 이루기 위해 겪은 도전과 실패를 이야기한다. 또한, 그 과정에서 토스 엔지니어들이 견지하는 태도와 이를 가능하게 하는 조직문화를 공유할 예정이다.\n메인 세션은 안드로이드(Android), 데이터(Data), 데브옵스(DevOps), 프론트엔드(Frontend), 인프라(Infra), Node.js, 파이썬(Python), 서버(Server), QA 등 총 9개 직군의 29개 발표로 구성했다. 스페셜 세션으로는 ‘빠르게 성장하고 싶은 주니어 개발자를 위한 소프트 스킬’, ‘팀에 위닝 멘탈리티를 불어넣는 리더십 스킬’, 토스뱅크와 토스증권의 CTO가 전하는 ‘미래의 CTO에게’ 등 3개 발표와 파트너사인 아마존웹서비스(AWS), 노션(Notion), 세일즈포스(Salesforce)의 발표가 준비돼 있다.\n다양한 부대 행사도 함께 마련했다. 슬래시 연사와 세션에 대한 질의나 기술적 고민을 나눌 수 있는 ‘데브챗(DevChat) 존’, 다양한 프로그램에서 4개 이상의 스탬프를 모으면 참여할 수 있는 ‘럭키드로우 존', 직무 상담이나 이력서에 대한 피드백을 받을 수 있는 ‘리크루팅 존'을 운영한다. 더불어 AWS, 베스핀글로벌, 노션, 세일즈포스, 시디즈 등 특별 협업 부스도 별도로 운영된다.\n이형석 CTO는 “이번 슬래시는 ‘No Limit’이라는 주제에 맞게 기술적 도전에 대한 토스 엔지니어들의 열정과 도전 정신을 함께 나눌 수 있는 자리가 될 것”이라며 “처음으로 오프라인에서 행사를 진행하는 만큼, 참가자들이 네트워킹을 통해 서로의 경험을 공유하고 더 큰 임팩트를 얻으실 수 있기를 기대한다”라고 전했다.\n참가 신청은 9월 2일(월) 23시 59분까지 토스 슬래시24 홈페이지에서 할 수 있다. 참가 신청을 완료하면 행사 종료 후 세션 발표 자료를 이메일로 제공한다. 신청한 인원 중 추첨을 통해 총 1,500명을 현장에 초대하며, 선정된 참가자에게는 9월 4일(수)에 개별적으로 안내를 진행할 예정이다.",
        "content": "“No Limit: 풀지 못할 문제는 없다”",
        "contentSnippet": "“No Limit: 풀지 못할 문제는 없다”",
        "guid": "https://blog.toss.im/article/slash24-conference",
        "isoDate": "2024-08-26T04:56:00.000Z"
      }
    ]
  },
  {
    "name": "모나미",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김진홍",
    "category": "개인",
    "posts": []
  }
]