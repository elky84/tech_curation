[
  {
    "name": "C++ Team Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Facebook Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "eBay Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Twitter Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Netflix TechBlog",
    "category": "기업",
    "posts": [
      {
        "creator": "Netflix Technology Blog",
        "title": "AV1 — Now Powering 30% of Netflix Streaming",
        "link": "https://netflixtechblog.com/av1-now-powering-30-of-netflix-streaming-02f592242d80?source=rss----2615bd06b42e---4",
        "pubDate": "Thu, 04 Dec 2025 20:09:30 GMT",
        "content:encodedSnippet": "AV1 — Now Powering 30% of Netflix Streaming\nLiwei Guo, Zhi Li, Sheldon Radford, Jeff Watts\nStreaming video has become an integral part of our daily lives. At Netflix, our top priority is delivering the best possible entertainment experience to our members, regardless of their devices or network conditions. One of the key technologies enabling this is AV1, a modern, open video codec that is rapidly transforming both how we stream content and how users experience it. Today, AV1 powers approximately 30% of all Netflix viewing, marking a major milestone in our efforts to bring more efficient and higher-quality streaming to our members.\nIn this post, we’ll revisit Netflix’s AV1 journey to date, highlight emerging use cases, and share adoption trends across the device ecosystem. Having witnessed AV1’s significant impact，and with AV2 on the horizon, we’re more excited than ever about how open codecs will continue to revolutionize streaming for everyone.\nAV1: A Modern, Open Codec\nSince entering the streaming business in 2007, Netflix has primarily relied on H.264/AVC as its streaming format. However, we quickly recognized that a modern, open codec would benefit not only Netflix, but the entire multimedia industry. In 2015, together with a group of like-minded industry leaders, Netflix co-founded the Alliance for Open Media (AOMedia) to develop and promote next generation, open source media technologies. The AV1 codec became the first major project of this collaboration, with ambitious goals: to deliver significant improvements in compression efficiency over state-of-the-art codecs, and to introduce rich features that enable new use cases. After three years of collaborative development, AV1 was officially released in 2018.\nNetflix’s AV1 Journey: From Android to TVs and Beyond\nPiloting on Android Mobile\nWhen we first set out to bring AV1 streaming to Netflix members, Android was the ideal starting point. Android’s flexibility allowed us to quickly integrate a software AV1 decoder using the efficient dav1d library, which was already optimized for ARM chipsets in mobile devices.\nAV1’s superior compression efficiency was especially valuable for mobile users, many of whom are mindful of their data usage and network conditions. By adopting AV1, we were able to deliver noticeably better video quality at lower bitrates. For members relying on cellular data, this meant crisper images with fewer compression artifacts, even when bandwidth was limited. Launching AV1 support on Android in 2020 marked a significant step forward for Netflix on mobile, making high-quality streaming more accessible and enjoyable for members everywhere.\nFront-and-Center for Netflix VOD Streaming\nThe success of our AV1 launch on Android proved its value for Netflix streaming, motivating us to expand support to smart TVs and other large-screen devices, where most of our members watch their favorite shows.\nSmart TVs depend on hardware decoders for efficient high-quality playback. We worked closely with device manufacturers and SoC vendors to certify these devices, ensuring they are both conformant and performant. This collaborative effort enabled our AV1 streaming to TV devices in late 2021. Shortly thereafter, we expanded AV1 streaming to web browsers (in 2022) and continued to broaden device support. In 2023, this included Apple devices with the introduction of AV1 hardware support in the new M3 and A17 Pro chips.\nAs more devices began shipping with AV1 hardware support, a rapidly growing share of our members could enjoy the benefits of this advanced codec. Combined with our investment in adding AV1 streams across the entire catalog, AV1 viewing share has been consistently increasing in recent years. Today, AV1 accounts for approximately 30% of all Netflix streaming, making it our second most-used codec — and it’s on track to become number one very soon. The payoff has been substantial.\n\nElevating Streaming Experience Across the Board: Large-screen TVs and other devices demand higher bitrates to deliver stunning 4K, high frame rate (HFR) experiences. AV1’s superior compression efficiency has allowed us to provide these experiences using less data, making high-quality streaming more accessible and reliable. On average, AV1 streaming sessions achieve VMAF scores¹ that are 4.3 points higher than AVC and 0.9 points higher than HEVC sessions. At the same time, AV1 sessions use one-third less bandwidth than both AVC and HEVC, resulting in 45% fewer buffering interruptions. Moreover, Netflix’s diverse content catalog benefits universally from AV1, with improvements across all content types.\nDriving Network Efficiency Worldwide: Netflix streams are delivered through our own content delivery network (Open Connect), in partnership with local ISPs around the globe. With more than 300 million members, Netflix streaming constitutes a non-trivial portion of global internet traffic. Because AV1 is a more efficient codec, its streams are smaller in size (while providing even better visual quality). By shifting a substantial share of our streaming to AV1, we reduce overall internet bandwidth consumption, and lessen system and network load for both Netflix and our partners.\n\nUnlocking Advanced Experiences\nIn addition to its superior compression efficiency, AV1 was designed to support a rich set of features. Once we established a robust framework for the continuous expansion of AV1 streaming, we quickly shifted our focus towards exploring AV1’s unique features to unlock even more advanced and immersive experiences for our members.\nHigh-Dynamic-Range(HDR)\nHDR brings enhanced detail, vivid colors, and greater clarity to images. As a premium streaming service, Netflix has been a pioneer in adopting HDR, offering HDR streaming since 2016. In March 2025, we launched AV1 HDR streaming. We chose HDR10+ as the HDR format for its use of dynamic metadata, which enabled us to adapt the tone mapping per device in a scene-dependent manner.\nAs anticipated, the combination of AV1 and HDR10+ allows us to deliver images with greater detail, more vibrant colors, and an overall heightened sense of immersion for our members. At the moment, 85% of our HDR catalog (from the perspective of view-hours) has AV1-HDR10+ coverage, and this number is expected to reach 100% in the next couple of months.\nPhotographs of devices displaying the same (cropped) frame with HDR10 metadata (left) and HDR10+ metadata (right). Notice the preservation of the flashlight detail in the HDR10+ capture, and the over-exposure of the region under the flashlight in the HDR10 one.\nCinematic Film Grain\nFilm grain is a hallmark of the cinematic experience, widely used in the movie industry to enhance a film’s depth, texture, and realism. However, because film grain is inherently random, faithfully representing it in digital video requires a significant amount of data. This presents a unique challenge for streaming: restricting the bitrate can result in grain that appears unnatural or distorted, while increasing the bitrate to accurately preserve cinematic grain almost inevitably leads to elevated rebuffering. The AV1 specification incorporates a unique solution called Film Grain Synthesis (FGS). Instead of encoding grain as part of every frame, the grain is stripped out before encoding and then resynthesized at the decoder using parameters sent in the bitstream, delivering a realistic cinematic film grain experience without the usual data costs.\nThis approach represents a significant shift from traditional compression and streaming techniques. Our team invested substantial effort in fine-tuning the media processing pipeline, ensuring FGS delivers robust performance at scale. In July 2025, we successfully productized AV1 FGS, and the results were astonishing: AV1 with FGS could deliver videos with cinematic film grain at a bitrate well within the capabilities of typical household internet connections. For non-FGS AV1 encodings, even at much higher bitrate, they may not be able to achieve comparable quality.\nThe same (cropped) frame from source (left), regular AV1 stream encoded at 8274kbps (middle) and AV1 FGS stream encoded at 2804 kbps (right). The AV1 FGS stream reduces the bitrate by 66% while delivering clearly better quality.\nBeyond VOD Streaming\nSo far, our AV1 journey has been mainly on VOD, but we see significant opportunities for AV1 beyond traditional VOD streaming. On a mission to entertain the world, Netflix has constantly explored and established other ways to bring joy to our members, and we believe AV1 could contribute to the success of these new products.\nLive Streaming\nDebuting in 2023, live streaming has experienced rapid growth at Netflix, becoming a key part of our streaming offerings in just two short years. We are actively evaluating the use of AV1 in live streaming, as we believe it could help further scale Netflix’s live programming:\n\nHyper-scale concurrent viewership: Live streaming at Netflix means delivering content to tens of millions of viewers simultaneously. AV1’s superior compression efficiency could significantly reduce the required bandwidth, enabling us to deliver high-quality live experiences to large audiences without compromising video quality.\nCustomizable graphics overlay: for live sport events such as football, tennis and boxing, graphics overlays have become an integral part of the member experience — from embedding game statistics to delivering sponsorships. AV1 offers an opportunity to make the graphics highly customizable: layered coding is supported in AV1’s main profile, allowing encoding the main content in the base layer, and graphics in the enhancement layer, and easily swapping out one version of the enhancement layer with another. We envision that the use of AV1’s layered coding can greatly simplify the live streaming workflow and reduce delivery costs.\n\nCloud Gaming\nCloud gaming is a new Netflix offering that is currently in the beta phase and is available to members in select countries. The game engines run on cloud servers, while the rendered graphics are streamed directly to members’ devices. By removing barriers and transforming every Netflix-enabled device into a game console, Cloud gaming aims to deliver a seamless, “play anywhere” experience for our members. For a glimpse of this in action, watch as Co-CEO Greg Peters and CTO Elizabeth Stone play a round of Boggle Party — powered entirely by Netflix’s cloud gaming platform!\nUnlike traditional video streaming, cloud gaming requires that every player action is reflected instantly on the screen to ensure a responsive and immersive experience. This makes delivering high-quality video frames with extremely low latency, despite fluctuating network conditions, one of the biggest challenges in cloud gaming.\nOur team is actively working on productizing AV1 for cloud gaming. Given AV1’s high compression efficiency, we can reduce frame sizes, helping video frames get through even when network conditions become challenging. This positions AV1 as a promising technology for enabling a high-quality, low-latency gaming experience across a wide range of devices.\nA Device Ecosystem United for AV1\nNetflix is a streaming company, and we have worked diligently to create highly efficient and standards-conformant AV1 streams for our catalog. However, an equally, if not more, important factor in AV1’s success is the widespread support from device manufacturers. Throughout our AV1 journey, we have been impressed by the unprecedented pace at which the device ecosystem has embraced AV1.\nJust six months after the AV1 specification was finalized, the open-source AV1 decoder library sponsored by AOM, dav1d, was released. Small, performant, and highly resource-efficient, dav1d bridged the gap for early adopters like Netflix while hardware solutions were still in development. Continuous improvements to its performance and compatibility have made dav1d the preferred choice for a wide range of platforms and practical applications. Today, it serves as Android’s default software decoder. Additionally, it plays a key role in web browsers — for Netflix, it powers approximately 40% of our browser playback. This broad adoption has significantly expanded access to high-quality AV1 streaming, even in the absence of dedicated hardware decoders.\nNetflix maintains a close working relationship with device manufacturers and SoC vendors, and we have witnessed first-hand their enthusiasm for adopting AV1. To ensure optimal streaming performance, Netflix has a rigorous certification process to verify proper support for our streaming formats on devices. AV1 was added to this certification process in 2019, and since then, we have seen a steady increase in the number of devices with full AV1 decoding capabilities. Over the past five years (2021–2025), 88% of large-screen devices, including TVs, set-top boxes, and streaming sticks, submitted for Netflix certification have supported AV1, with the vast majority offering full 4K@60fps capability. Notably, since 2023, almost all devices we have received for certification are AV1-capable.\nWe have also been impressed by the robustness of AV1 implementations across these devices. As mentioned earlier, FGS is an innovative tool that departs from traditional codec architectures and was not included in our initial full-scale AV1 streaming rollout. When we launched FGS this July, we worked closely with our partners to ensure broad device compatibility. We are pleased with the successful progress made, and AV1 with FGS is now supported across a significant and growing number of in-field devices.\nLooking Ahead: AV1 Today, AV2 Tomorrow\nAs we reflect on our AV1 journey, it’s clear that the codec has already transformed the streaming experience for hundreds of millions of Netflix members worldwide. Thanks to industry-wide collaboration and rapid device adoption, AV1 is delivering higher quality, greater efficiency, and new cinematic features to more screens than ever before.\nLooking ahead, we are excited about the forthcoming release of AV2, announced by the Alliance for Open Media for the end of 2025. AV2 is poised to set a new benchmark for compression efficiency and streaming capabilities, building on the solid foundation laid by AV1. At Netflix, we remain committed to adopting the best open technologies to delight our members around the globe. While AV2 represents the future of streaming, AV1 is very much the present — serving as the backbone of our platform and powering exceptional entertainment experiences across a vast and ever-expanding ecosystem of devices.\nAcknowledgement\nThe success of AV1 at Netflix is the result of the dedication, expertise, and collaboration of many teams across the company — including Encoding, Clients, Device Certification, Partner Engineering, Data Science & Engineering, Infra, Platform, etc.\nWe would also like to thank Artem Danylenko, Aditya Mavlankar, Anne Aaron, Cyril Concolato, Allan Zhou and Anush Moorthy for their valuable comments and feedback on earlier drafts of this post.\nFootnotes\n\nThese numbers represent a snapshot of data from November 13, 2025. Actual values may vary slightly from day to day and across different regions, depending on the mix of content, devices, and internet connectivity.\n\nAV1 — Now Powering 30% of Netflix Streaming was originally published in Netflix TechBlog on Medium, where people are continuing the conversation by highlighting and responding to this story.",
        "dc:creator": "Netflix Technology Blog",
        "guid": "https://medium.com/p/02f592242d80",
        "categories": [
          "av1",
          "video-encoding",
          "streaming",
          "aomedia",
          "netflix"
        ],
        "isoDate": "2025-12-04T20:09:30.000Z"
      }
    ]
  },
  {
    "name": "JetBrains: Developer Tools for Professionals and Teams – Company Blog | JetBrains",
    "category": "기업",
    "posts": [
      {
        "creator": "Ksenia Shneyveys",
        "title": "How Backend Development Teams Use Kotlin in 2025: Insights from a Certified Trainer",
        "link": "https://blog.jetbrains.com/kotlin/2025/12/how-backend-development-teams-use-kotlin-in-2025/",
        "pubDate": "Tue, 09 Dec 2025 23:52:47 +0000",
        "content:encodedSnippet": "This is the first guest post in a two-part series from José Luis González. José Luis has a PhD in software development and is a JetBrains-certified Kotlin Trainer, who works with developers and engineering teams to deepen their Kotlin skills and apply the language effectively in real projects. At Hyperskill, he runs Kotlin instructor-led training for teams at Hyperskill that focus on advanced topics and practical problem-solving rather than theory.\n1. What are the top 3 Kotlin anti-patterns from self-taught teams, and how do you fix each one?\nThis is a good question. The basic anti-pattern I see in self-taught Kotlin teams is that they still design hierarchies of abstract classes, factories, and deep inheritance trees because that’s how they learned Java. But Kotlin thrives on data-oriented, sealed, and expression-based designs. Overusing inheritance leads to fragile hierarchies, bloated APIs, and code that fights Kotlin’s strengths.\nThe simplest improvement is to flatten your design. Use sealed classes, data classes, and when expressions to model domain state declaratively instead of relying on polymorphism. Prefer composition and smart constructors over inheritance.\nMoving to what’s catching my attention in the last 2 years, I see subtler issues from teams that already “know Kotlin,” but haven’t kept up with how the language evolved. \nA major issue I still see is the use of ambient singletons: things like global object repositories or custom service locators. They make code look simpler at first, but in reality they hide dependencies and make testing much harder. \nContext parameters would fix it: the successor to context receivers, so functions declare the services they need and callers supply them, no globals required:\ninterface Clock { \n  fun now(): Instant\n}\n\ncontext(_: Clock) \nfun stamp() = now()\n\nwith(object: Clock{ override fun now() = Clock.System.now() }) { \n  stamp() \n}\nThis is Beta in Kotlin 2.2 and replaces context receivers with IDE-assisted migration.\nAnother common trap is the illusion of type safety through typealias.\ntypealias UserId = String doesn’t create a new type as it’s only an alias, so UserId and String are fully interchangeable. In 2025, the idiomatic solution is to use value classes (inline classes), which introduce true domain types while remaining allocation-free at runtime.\n@JvmInline \nvalue class UserId(\n  val v: String\n)\n\nfun load(u: UserId) {}\n\n// load(\"abc\")    // not good\n\nload(UserId(\"abc\")) // better\nA more subtle anti-pattern I still see is treating coroutines as ‘threads with nicer syntax.’ The telltale signs are GlobalScope.launch, random runBlocking calls in production, and code that ignores structured concurrency entirely. The modern fix: stop launching in GlobalScope, tie every coroutine to a real scope or lifecycle, keep runBlocking in main() or tests, and use coroutineScope/supervisorScope to compose concurrent work instead of escaping it.\nsuspend fun load() = supervisorScope {\n  val a = async { repo.a() }; \n  val b = async { repo.b() }; \n  a.await() to b.await()\n}\nGlobalScope is a @DelicateCoroutinesApi escape hatch, and official guidance frames runBlocking as a bridge for tests and entry points, not production call paths.\n(Author’s remark: since Kotlin 2.0, K2 is the default compiler across JVM/Native/JS/Wasm: lean on these features confidently in KMP codebases.)\n2. When teams ask you about testing async Kotlin code, what’s the exact testing pattern you show them that works reliably in CI/CD?\n I show them one reliable pattern that scales and never flakes. The key is to inject dispatchers, not hardcode Dispatchers.IO, and test with runTest plus a StandardTestDispatcher (or MainDispatcherRule on Android). This lets you control virtual time deterministically using advanceTimeBy() or advanceUntilIdle(), so no real delays or sleeps are needed. Always assert both results and cancellation: tests should prove that CancellationException propagates and does not get swallowed.\nHere’s the compact pattern:\n@OptIn(ExperimentalCoroutinesApi::class)\n@Test fun flow_is_deterministic() = runTest {\n    val testDispatcher = StandardTestDispatcher(testScheduler)\n    val repo = Repo(svc = FakeSvc(), dispatchers = object : AppDispatchers {\n        override val io = testDispatcher; override val default = testDispatcher\n    })\n\n    val job = launch { assertEquals(\"A\" to \"B\", repo.load()) }\n    advanceUntilIdle()              // run coroutines deterministically\n    assertTrue(job.isCompleted)     // also test job.cancel() + advanceUntilIdle()\n}\nIf you’re testing a Flow, use Turbine instead of assertEquals:\nflow.test {\n    assertEquals(\"A\", awaitItem())\n    cancelAndIgnoreRemainingEvents()\n}\nThis pattern works consistently in CI/CD because it avoids timing flakiness, doesn’t rely on real delays, and enforces proper structured concurrency.\n3. A team just deployed their first Kotlin microservice and it’s using 3x more memory than expected. What’s your diagnostic checklist, and what are the most likely culprits?\nIf a new Kotlin microservice suddenly uses three times more memory than expected, I start by checking whether it’s really a Kotlin issue or just how the JVM behaves under load. The first thing is to see what kind of memory grows.\nIf the heap is flat but RSS keeps rising, it’s usually thread stacks or direct buffers. Each thread costs around 1-2 MB, and Dispatchers.IO can easily spin up hundreds under blocking I/O. Limit it:\n val io = Dispatchers.IO.limitedParallelism(64)\n❗ And make sure you’re not using raw threads where coroutines would do. That’s a common “Java habit” that quietly kills memory efficiency.\nNext, if the heap itself grows, look for unbounded coroutines or collections: things like Channel.UNLIMITED, flow.buffer() without limits, or caches that never evict. Backpressure fixes most of these:\nflow.buffer(256, onBufferOverflow = BufferOverflow.DROP_OLDEST)\nThen check the HTTP layer. Frameworks like Ktor with CIO or Netty may buffer entire requests in memory. Stream instead of aggregating:\ncall.receiveChannel().copyTo(File(\"upload.bin\").outputStream())\nOn the JVM side, always set explicit container limits so it doesn’t grab all available RAM:\n-XX:MaxRAMPercentage=60 -XX:MaxMetaspaceSize=128m -XX:MaxDirectMemorySize=128m\nFinally, profile before guessing. I usually attach an async-profiler or JDK Flight Recorder to see where allocations come from, and combine that with jcmd VM.native_memory summary for off-heap diagnostics.\nIn short: use real coroutines, not threads; set memory caps; limit dispatcher parallelism; bound every buffer; and verify with profiling. That’s how you fix 90 % of “why is our Kotlin service eating all the RAM?” cases.\nJosé Luis González\nJosé Luis González, PhD, is a JetBrains-certified Kotlin Trainer who teaches Kotlin and advanced techniques to development teams. If your team has more questions about Kotlin anti-patterns, idiomatic design, or wants to learn how to write more maintainable Kotlin code, explore his instructor-led Kotlin workshops at Hyperskill.",
        "dc:creator": "Ksenia Shneyveys",
        "content": "This is the first guest post in a two-part series from José Luis González. José Luis has a PhD in software development and is a JetBrains-certified Kotlin Trainer, who works with developers and engineering teams to deepen their Kotlin skills and apply the language effectively in real projects. At Hyperskill, he runs Kotlin instructor-led training [&#8230;]",
        "contentSnippet": "This is the first guest post in a two-part series from José Luis González. José Luis has a PhD in software development and is a JetBrains-certified Kotlin Trainer, who works with developers and engineering teams to deepen their Kotlin skills and apply the language effectively in real projects. At Hyperskill, he runs Kotlin instructor-led training […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=667478",
        "categories": [
          "news"
        ],
        "isoDate": "2025-12-09T23:52:47.000Z"
      },
      {
        "creator": "Roman Prokashev",
        "title": "Sky’s the Limit: The Cloud9 × JetBrains Global Hackathon Is Live",
        "link": "https://blog.jetbrains.com/blog/2025/12/09/sky-s-the-limit-the-cloud9-jetbrains-global-hackathon-is-live/",
        "pubDate": "Tue, 09 Dec 2025 19:03:47 +0000",
        "content:encodedSnippet": "Last month, we announced that JetBrains is now the Official AI-Powered Coding Partner of Cloud9. The response from the community has been incredible, and today, we’re taking the next step in that journey.\nWe’re excited to launch Sky’s the Limit, a global hackathon designed for developers, esports fans, analysts, and creators who want to push competitive gaming forward. Whether you’re fascinated by data-driven coaching, obsessed with the pick/ban phase, or love building interactive fan experiences, this is your chance to make something game-changing.\nAnd yes, the prizes are epic!\n\n\n\n\nYour mission: build the future of esports\nChoose from four categories inspired directly by real workflows to support Cloud9’s teams using official esports data from GRID for League of Legends and VALORANT. These are meaningful, high-impact challenges that players and coaches face daily.\nCategory 1: Comprehensive assistant coach\nBuild an assistant coach that merges micro-level player analytics with macro-level strategic review. Inspired by the analytical approach popularized in Moneyball, this near-real-time application works with historical match data to provide a holistic performance picture. Your tool might detect recurring individual mistakes, quantify their impact on team-level strategy, and convert those insights into clear, actionable recommendations for players and coaching staff.\nCategory 2: Automated scouting report generator\nCreate an application that automatically scours recent official esport GRID match data to generate concise and informative scouting reports for upcoming opponents. Your system could highlight strategic tendencies, preferred playstyles, default site setups in VALORANT, or frequently played comps in VALORANT or League of Legends. The goal is to help teams prepare smarter, faster, and with more confidence.\nCategory 3: AI drafting assistant or draft predictor (LoL)\nDevelop a tool that analyzes a wide range of historical information such as champion pools, comp synergies, win rates, patch trends, and recent match histories to generate optimized pick/ban recommendations. Your solution should support coaches during the draft phase with intelligent guidance tailored to specific opponents and scenarios, making drafting more strategic and data-driven.\nCategory 4: Event minigame\nDesign a fun and engaging minigame that fans can play at Cloud9 or JetBrains booths during LCS or VCT events. This is your chance to build something playful, fast, and memorable. The winning project may even be showcased at a future Cloud9 event activation.\nIn addition to the main prizes, the hackathon also features three bonus categories: Best Video Submission, Most Valuable JetBrains Software or Junie Feedback, and Best Written Blog Post.\nPrizes\nMain Category Winners\nUSD 4,000–6,000\nUSD 100 Cloud9 Store gift card\nA one-year JetBrains All Products Pack subscription\nGDC event ticket\nAll-expenses-paid trip to GDC (flight + hotel)\nBonus Category Winners\nUSD 1,000\nUSD 100 Cloud9 Store gift card\nA one-year JetBrains All Products Pack subscription\nFor the full details on eligibility, prize structures, and judging, be sure to review the official rules. All submissions will be reviewed by a panel of judges from Cloud9 and JetBrains.\nImportant Dates\nRegistration and Submission:\nJudging Period:\nWinners Announced:\nWhy This Hackathon Matters\nEsports is evolving quickly, and the tools used behind the scenes have a real impact on team performance, player improvement, and fan engagement. We want developers around the world to push technical creativity even further and encourage them to use JetBrains IDEs and our AI coding agent Junie along the way\nWe can’t wait to see what you build! Some of the most innovative ideas in esports analytics and the fan experience come from passionate, curious coders like you. This hackathon is your launchpad. Sky’s the Limit.\nReady to Join?\nhere.",
        "dc:creator": "Roman Prokashev",
        "content": "Last month, we announced that JetBrains is now the Official AI-Powered Coding Partner of Cloud9. The response from the community has been incredible, and today, we’re taking the next step in that journey. We’re excited to launch Sky’s the Limit, a global hackathon designed for developers, esports fans, analysts, and creators who want to push [&#8230;]",
        "contentSnippet": "Last month, we announced that JetBrains is now the Official AI-Powered Coding Partner of Cloud9. The response from the community has been incredible, and today, we’re taking the next step in that journey. We’re excited to launch Sky’s the Limit, a global hackathon designed for developers, esports fans, analysts, and creators who want to push […]",
        "guid": "https://blog.jetbrains.com/?post_type=blog&p=666042",
        "isoDate": "2025-12-09T19:03:47.000Z"
      },
      {
        "creator": "Alexandra Charikova",
        "title": "JetBrains Joins the Agentic Artificial Intelligence Foundation",
        "link": "https://blog.jetbrains.com/blog/2025/12/09/jetbrains-joins-the-agentic-artificial-intelligence-foundation/",
        "pubDate": "Tue, 09 Dec 2025 17:43:26 +0000",
        "content:encodedSnippet": "JetBrains is joining the new Agentic Artificial Intelligence Foundation (AAIF) hosted by the Linux Foundation. The AAIF brings together leading organizations contributing to the next generation of open agentic technologies.\nThe foundation launches with several key open-source projects – including MCP, goose, and AGENTS.md – which already form an emerging ecosystem for shared standards and tooling.\nAs highlighted in the foundation’s announcement:\n“We are seeing AI enter a new phase, as conversational systems shift to autonomous agents that can work together. Within just one year, MCP, goose, and AGENTS.md have become essential tools for developers building this new class of agentic technologies. Bringing these projects together under the AAIF ensures they can grow with the transparency and stability that only open governance provides. The Linux Foundation is proud to serve as the neutral home where they will continue to build AI infrastructure the world will rely on.”\n— Jim Zemlin, Executive Director of the Linux Foundation.\nWhy we are joining\nFor 25 years, JetBrains IDEs have been where software is made. With the rise of agentic systems, developers will increasingly rely on tools that can plan, coordinate, and execute work across their environments. This direction is directly reflected in how we build Junie, our AI coding agent, and how we continue to evolve JetBrains AI Assistant, which brings intelligent assistance directly into our IDEs. In addition, Claude Agent is already integrated into our IDEs, and we plan to add more coding agents in the future. JetBrains will remain an open platform offering a choice of coding agents both in IDEs and in the cloud. This supports our vision of hybrid human-agent teams collaborating on software creation and maintenance throughout the life cycle, without loss in quality.\nWe want this shift to progress in an open, well-governed and trustworthy manner.\n\n“Agentic AI represents a foundational shift in how software is built and operated. Open, interoperable agentic systems will be critical to the next generation of software development. By participating in the Linux Foundation’s new Agentic AI Foundation, JetBrains is eager to bring our engineering expertise to a community committed to building these systems in a neutral, collaborative, and responsible way. \nWe will ensure these technologies remain transparent, extensible, and beneficial to the global developer community.” \n— Arun Gupta, VP, Developer Experience at JetBrains\nOpen collaboration has shaped every major transition in software development, and we expect the same here. Shared protocols, clear interfaces, and transparent behavior are essential for systems that interact with code, data, tools, and developer workflows.\nBy joining the AAIF, we commit to helping build the foundations this ecosystem requires: specifications, tooling, governance models, documentation, and support for maintainers. Our goal is to help ensure that agentic systems integrate safely and consistently with IDEs and development environments.\nChallenges such as interoperability, security, governance, evaluation, and integration cannot be solved by a single organization. They require a neutral space where peers, competitors, researchers, and practitioners work together – and the AAIF makes this possible.\nWe see this work as shared infrastructure that the industry will depend on, and we believe it should be developed in the open. This lowers the cost and democratizes agent-driven software for users and companies that build on top of this shared infrastructure.\nLooking ahead\nWe look forward to participating through strategic investment, community building, and shared development of open standards.\nWe will continue to enhance our IDEs, evolve Junie, advance AI Assistant, onboard a wide selection of agents, and deliver next-level agentic experiences in the cloud – with a focus on reliability, transparency, and interoperability. Our participation in the AAIF will help us align these efforts with emerging standards and contribute to the shared practices that support developers and tool builders across the ecosystem.",
        "dc:creator": "Alexandra Charikova",
        "content": "JetBrains is joining the new Agentic Artificial Intelligence Foundation (AAIF) hosted by the Linux Foundation. The AAIF brings together leading organizations contributing to the next generation of open agentic technologies. The foundation launches with several key open-source projects – including MCP, goose, and AGENTS.md – which already form an emerging ecosystem for shared standards and [&#8230;]",
        "contentSnippet": "JetBrains is joining the new Agentic Artificial Intelligence Foundation (AAIF) hosted by the Linux Foundation. The AAIF brings together leading organizations contributing to the next generation of open agentic technologies. The foundation launches with several key open-source projects – including MCP, goose, and AGENTS.md – which already form an emerging ecosystem for shared standards and […]",
        "guid": "https://blog.jetbrains.com/?post_type=blog&p=667284",
        "isoDate": "2025-12-09T17:43:26.000Z"
      },
      {
        "creator": "Nikita Kuchur",
        "title": "Preventing Resource Leaks in Go: How GoLand Helps You Write Safer Code",
        "link": "https://blog.jetbrains.com/go/2025/12/09/preventing-resource-leaks-in-go-how-goland-helps-you-write-safer-code/",
        "pubDate": "Tue, 09 Dec 2025 17:13:17 +0000",
        "content:encodedSnippet": "Every Go application uses resources, such as files, network connections, HTTP responses, and database query results. But when a resource is left unclosed, it can cause a leak, which drains memory, exhausts system limits, introduces subtle bugs, and eventually brings even the most robust service to failure. Recently, we’ve introduced resource leak analysis in GoLand to address this problem and help you detect unclosed resources before they cause leaks in production.\nWhat is a resource leak?\nA resource is any entity that holds an external system handle or state that must be explicitly closed when it’s no longer needed. In Go, such types typically implement the io.Closer interface, which defines a single Close() method for cleaning up underlying resources.\nHere are some common implementations of io.Closer:\n*os.File: an open file descriptor obtained via functions like os.Open and os.Create.\nnet.Conn: a network connection (TCP, UDP, etc.) created by net.Dial, net.Listen.Accept, or similar functions.\n*http.Response: the response object returned by http.Get, http.Post, and similar functions. Its Body field is a resource because it implements io.ReadCloser.\n*sql.Rows and *sql.Conn: database query results and connections.\nA resource leak occurs when one of these resources isn’t properly closed after use. In such cases, they continue to occupy memory and other limited system resources such as file descriptors, network sockets, or database connections. Over time, all the open resources may lead to performance degradation, instability, or even application failure.\n\nThe more you know…\nCan’t Go’s garbage collector handle this? After all, it automatically frees unused memory, so why not resources, too?\nGo’s garbage collector (GC) is designed specifically to reclaim memory, not to manage external resources like open files or network connections. In some rare cases, it can help. For example, in the standard library, a finalizer can be set to call Close() when a file becomes unreachable. However, this technique is used only as a last resort to protect developers from resource leaks, and you can’t rely on it completely.\nGarbage collection is non-deterministic. It might occur seconds or minutes later, or not at all, leading to system limits being reached. That’s why the only safe and reliable way to avoid leaks is to explicitly close every file or connection as soon as you’re done with it.\n\n\n\n\n\nTips to prevent resource leaks\nWhat can you do to prevent resource leaks in Go applications? A few consistent habits can help you minimize them.\nTip 1: Use defer to close resources\nThe defer statement ensures that cleanup happens even if a function returns early or panics. As shown in the example below, we close the created resource right after successfully opening it using defer f.Close(), which is one of the simplest and most effective ways to avoid resource leaks.\nf, err := os.Open(\"data.txt\")\nif err != nil {\n    return err\n}\ndefer f.Close()\nSince the defer statement executes after the surrounding function’s return, you must handle errors first and only then defer the resource closure. This ensures that you don’t defer operations on invalid or uninitialized resources. Also, avoid placing defer inside loops that create many resources in succession, as this can lead to excessive memory usage.\nTip 2: Test your application under load\nMost resource leaks affect your application only under high load, so it’s a good idea to run load and stress tests to see how it behaves. For example, if you’re developing a backend service, you can use load-testing tools like k6, wrk, Vegeta, or others. This testing helps you uncover not only potential resource leaks but also performance bottlenecks and scalability issues before they affect your users.\nTip 3: Use static code analysis tools\nStatic analysis tools can also help you automatically detect unclosed resources in your code. For instance, golangci-lint includes linters such as bodyclose and sqlclosecheck, which track HTTP response bodies and SQL-related resources to ensure you haven’t forgotten to close them.\nResource leak analysis in GoLand 2025.3 takes this a step further. It scans your code as you write it, verifies that resources are properly closed across all execution paths, and highlights any potential issues in real time. Getting this feedback right in your IDE helps you catch leaks early. Moreover, it works with any type that implements io.Closer, including your custom resource implementations.\n\n\n\n\nWhen one missing Close() breaks everything\nAre resource leaks really that critical? Let’s take a look at two common cases to see how a single missing Close() call can cause serious issues or even break your application over time.\nCase 1: Leaking HTTP response bodies\nSending HTTP requests is a common practice in Go, often used to fetch data from external services. Suppose we have a small function that pings an HTTP server:\nfunc ping(url string) (string, error) {\n    resp, err := http.Get(url)\n    if err != nil {\n        return \"\", err\n    }\n    return resp.Status, nil\n}\nWhen you write code like this, GoLand warns you about a potential resource leak because of an unclosed response body. But why does it do that? We aren’t even using the body in this example!\n\n\n\n\nWell, let’s try running this code and see what happens. To simulate high-load conditions, we can call our function in a loop like this:\nvar total int\nfor {\n   _, err := ping(\"http://127.0.0.1:8080/health\")\n   if err != nil {\n      slog.Error(err.Error())\n      continue\n   }\n\n   total++\n   if total%500 == 0 {\n      slog.Info(\"500 requests processed\", \"total\", total)\n   }\n   time.Sleep(10 * time.Millisecond)\n}\nAt first glance, everything seems fine – the client sends requests and receives responses as expected. However, if you monitor memory usage, you’ll notice that it gradually increases with every request the program sends, which is a clear indicator that something is wrong:\n\n\n\n\nAfter some time, the client becomes completely unable to send new requests, and the logs start filling up with errors like this:\n\n\n\n\nWhy does this happen? When you make an HTTP request in Go, the client sets up a TCP connection and processes the server’s response. The headers are read automatically, but the body remains open until you close it.\nEven if you don’t read or use the body, Go’s HTTP client keeps the connection alive, waiting for you to signal that you’re finished with it. If you don’t close it, the TCP connection stays open and cannot be reused. Over time, as more requests are sent, these unclosed connections accumulate, leading to resource leaks and eventually exhausting the available system resources.\nThat’s exactly what happens in our example. Each iteration of ping() leaves an open response body behind, memory usage grows steadily, and after a while, the client can no longer open new connections, resulting in the can’t assign requested address error.\nLet’s correct the mistake and run the code again:\nfunc ping(url string) (string, error) {\n    resp, err := http.Get(url)\n    if err != nil {\n        return \"\", err\n    }\n    defer resp.Body.Close() // Important: close the response body\n\n    return resp.Status, nil\n}\nAfter applying this fix, the memory footprint remains minimal, and you’ll no longer see the previous errors.\nIt’s worth mentioning that the code snippet above uses Go’s default http.Client for simplicity, which is generally not recommended in production. By default, it has no request timeout, so a slow or unresponsive server can cause requests to hang indefinitely, potentially leading to stalled goroutines and resource exhaustion. A better practice is to create a custom http.Client with reasonable timeouts to keep your application responsive and resilient under poor network conditions.\nCase 2: Forgetting to close SQL rows\nAnother common and destructive source of leaks in Go applications involves database resources, particularly when using the standard database/sql package. Let’s take a look at a simple function that retrieves user names by country from a database:\nfunc (s *Store) GetUserNamesByCountry(country string) ([]string, error) {\n    rows, err := s.db.Query(`SELECT name FROM users WHERE country = $1`, country)\n    if err != nil {\n        return nil, err\n    }\n\n    var names []string\n    for rows.Next() {\n        var name string\n        if err := rows.Scan(&name); err != nil {\n            return nil, err\n        }\n        names = append(names, name)\n    }\n\n    rows.Close()\n\n    return names, rows.Err()\n}\nEven though we call rows.Close() explicitly, GoLand still warns us about a possible leak. But why?\n\n\n\n\nLet’s say our table looks something like this:\n\n\n\n\nHave you spotted the problem? That’s right, there’s a user without a name. Мore precisely, there is a NULL instead of a string, and the GetUserNamesByCountry function doesn’t handle such cases properly. When rows.Scan tries to assign a NULL to a Go string variable, it returns an error. Issues like this can happen to anyone, and that nameless user probably ended up in our table by mistake. Still, it may seem that such a small issue couldn’t cause any dramatic consequences. After all, that’s exactly why we tried to handle errors properly, right?\nLet’s simulate real conditions by calling the function with different input parameters in a loop:\nvar total int\nfor {\n    for _, country := range countries {\n        _, err := s.GetUserNamesByCountry(country)\n        if err != nil {\n            slog.Error(err.Error())\n            continue\n        }\n\n        total++\n        if total%100 == 0 {\n            slog.Info(\"100 queries processed\", \"total\", total)\n        }\n        time.Sleep(10 * time.Millisecond)\n    }\n}\nWhen we launch the program, everything seems fine, and we only get occasional errors as expected:\n\n\n\n\nHowever, after running and processing SQL queries for some time, our program completely breaks down, and the logs are full of errors like this:\n\n\n\n\nWe’ve run out of client connections, and our application is unable to retrieve any data from the database!\nThe issue is that one of the execution paths in GetUserNamesByCountry leaves the query result unclosed when an error occurs during scanning. If rows is not closed, the corresponding database connection remains in use. Over time, this reduces the number of available connections, and eventually, the connection pool becomes exhausted. That’s exactly what happened in our case.\nSurprisingly, just one incorrect row in our table is enough to take down the entire application, simply because we forgot to close the resource properly.\nThe best way to prevent this mistake is to use defer. As we discussed previously, this should be your preferred way of handling resources whenever possible:\nfunc (s *Store) GetUserNamesByCountry(country string) ([]string, error) {\n    rows, err := s.db.Query(`SELECT name FROM users WHERE country = $1`, country)\n    if err != nil {\n        return nil, err\n    }\n    defer rows.Close() // Important: close the rows using 'defer'\n\n    var names []string\n    for rows.Next() {\n        var name string\n        if err := rows.Scan(&name); err != nil {\n            return nil, err\n        }\n        names = append(names, name)\n    }\n\n    return names, rows.Err()\n}\nMaking the invisible visible\nThere are many ways a resource leak can creep into your program, and the examples above are just the tip of the iceberg. Such mistakes are easy to make and hard to trace. Your code compiles, tests pass, and everything appears to work, until your service slows down or starts failing under load. Finding the root cause can be time-consuming, especially in large codebases.\nGoLand’s resource leak analysis makes these issues visible right where they start, as you write code. It tracks how resources are used across all execution paths and warns you if something might remain unclosed. This early feedback helps you quickly identify resources in your code and fix potential leaks right away.\nThe feature is especially helpful for beginners who are still learning the language and might not yet know which resources require explicit cleanup. Experienced developers benefit as well, since it saves time when working with unfamiliar codebases and custom types that implement io.Closer.\nIn essence, resource leak analysis turns a subtle, hard-to-detect problem into something you can catch instantly, helping you write more reliable and maintainable Go code.\nKeeping your Go applications leak-free\nResource leaks are among the most subtle yet destructive bugs in Go applications. They rarely cause immediate crashes, but over time, they can silently degrade performance, create instability, and even bring down production environments.\nBy using defer consistently, testing under realistic load, and taking advantage of GoLand’s new resource leak analysis, you can catch these issues early and keep your applications stable and reliable. Try out the new feature in the latest GoLand release and let us know what you think!\nTry GoLand",
        "dc:creator": "Nikita Kuchur",
        "content": "Every Go application uses resources, such as files, network connections, HTTP responses, and database query results. But when a resource is left unclosed, it can cause a leak, which drains memory, exhausts system limits, introduces subtle bugs, and eventually brings even the most robust service to failure. Recently, we’ve introduced resource leak analysis in GoLand [&#8230;]",
        "contentSnippet": "Every Go application uses resources, such as files, network connections, HTTP responses, and database query results. But when a resource is left unclosed, it can cause a leak, which drains memory, exhausts system limits, introduces subtle bugs, and eventually brings even the most robust service to failure. Recently, we’ve introduced resource leak analysis in GoLand […]",
        "guid": "https://blog.jetbrains.com/?post_type=go&p=666656",
        "categories": [
          "features",
          "goland",
          "news",
          "golang"
        ],
        "isoDate": "2025-12-09T17:13:17.000Z"
      },
      {
        "creator": "Olga Bedrina",
        "title": "Is Your CI/CD Tool Helping or Hindering Performance?",
        "link": "https://blog.jetbrains.com/teamcity/2025/12/is-your-ci-cd-tool-helping-or-hindering-performance/",
        "pubDate": "Tue, 09 Dec 2025 13:45:22 +0000",
        "content:encodedSnippet": "Every engineering leader would love to work with a team of elite performers who deploy 182x more frequently, recover from failures 2,293x faster, and achieve 127x faster lead times than low performers. (Yes, that’s the actual difference in performance of real teams from the 2024 DORA research report).\n\n\n\n\nBut how do you improve your team’s performance if you’re nowhere near the elite?\nIf you’re benchmarking against the four DORA metrics – deployment frequency, lead time for changes, change failure rate, and mean time to recovery – you’ll notice that bottlenecks tend to come from a combination of three things: people, processes, and tooling.\nWhile teams tend to tackle process issues first, and rightly so, engineering leaders should ask whether their teams have the right tools to do their job well.\nIn fact, the root cause of several process and culture issues often stems from your tooling.\nYour CI/CD platform shapes how teams work and how they feel about that work, which in turn affects your organization’s capacity for innovation and risk management. Manual configurations, brittle plugin ecosystems, and limited observability make it difficult to achieve strong DORA scores, regardless of how talented or motivated your teams are. \nTeams can spend up to half of their effort maintaining tooling instead of delivering value, creating a “technical debt tax” that grows with every release cycle.\nModern CI/CD platforms with built-in automation, intelligent resource management, and comprehensive observability free engineers to focus on business logic and innovation, creating a compound advantage over time.\nThis article unpacks how your tooling affects each of the DORA metrics to help you determine whether your CI/CD setup is helping or hindering your team’s performance.\nDeployment frequency: The velocity indicator\nDeployment frequency measures how often application changes are deployed to production. In other words, how quickly can your teams get value into the hands of customers?\nWhy it matters\nElite performers deploy to production multiple times per day, while low performers manage only once a month or even less.\nOrganizations deploying multiple times per day can respond to customer feedback in hours, not quarters. They can experiment with features, validate market hypotheses, and pivot based on real user behavior while competitors plan their next monthly release.\nEven if you don’t deploy daily, small, frequent deployments also reduce risk and build customer trust through continuous improvement rather than disruptive “big bang” releases.\nTooling’s impact on deployment\nLegacy CI/CD systems create an invisible ceiling on deployment velocity because their architecture introduces scaling bottlenecks. They were designed around static servers, long-lived agents, and plugin ecosystems, which is fine for a handful of apps but fragile when hundreds of pipelines and contributors pile on.\n\n\n\n\nAs you scale, build jobs start queuing behind overloaded agents, plugin dependencies break under version mismatches, and pipelines stall while engineers debug infrastructure instead of shipping code. Even as you add more developers, deployment throughput plateaus because the underlying tool can’t keep pace.\nEnvironmental management limitations amplify the problem. Legacy systems typically operate on static environments, which suffer from configuration drift and resource contention as more teams share them. \nConflicts that should be isolated instead spill across projects, forcing serialized releases and rework. What should be a smooth, automated pipeline turns into an error-prone coordination exercise.\nModern CI/CD platforms with configuration as code and automated pipeline templates dramatically reduce maintenance overhead, allowing teams to provision new deployment pipelines in minutes rather than days. \nFor instance, TeamCity offers ephemeral, autoscaled build agents that spin up on demand in containers or cloud instances, then shut down cleanly when idle.\n💡 Read more: Hosting Build Agents in Cloud\nIntelligent environment orchestration with containerization support eliminates resource contention. Teams get on-demand access to consistent, isolated environments that scale automatically. \nFor example, TeamCity runs each build in an isolated container, with configuration declared in version-controlled Kotlin DSL, eliminating drift and ensuring consistency across runs.\nFurthermore, smart resource allocation and parallel processing can optimize utilization during peak periods, while built-in scalability handles enterprise growth without degrading performance. This enables the platform to scale transparently while maintaining deployment velocity.\nLead time for changes: From code to customer value\nWhile deployment frequency tells you how often you deliver, lead time for changes shows you how fast. It measures the duration from the moment the code is committed to when it’s running in production.\nWhy it matters\nElite performers achieve lead times of less than one hour, while low performers require between one week and one month to get code from commit to production.\nReduced lead time means faster time to market for new features and immediate response to competitive pressures. When a critical bug is discovered or a market opportunity emerges, organizations with hourlong lead times can respond the same day, while those with weeklong lead times watch opportunities pass by.\nFor development teams, shorter lead times create a virtuous cycle of productivity. Developers get faster feedback on their changes, can iterate more quickly, and spend less time context-switching between different features.\nTooling’s impact on lead time\nCI/CD systems with manual configuration management create delays and increase the chances of human error. Each deployment often requires someone to manually verify settings, update configurations, and troubleshoot inevitable issues that arise from inconsistent environments.\nHeavy reliance on custom scripts and plugins stretches lead time even further. New features or compliance requirements often demand bespoke scripts, which then have to be debugged, reviewed, and maintained. \nPipelines break whenever dependencies change or plugins fall out of sync, forcing developers to stop feature work and fix tooling instead. Instead of commits flowing quickly into production, changes queue up behind brittle automation, extending lead time and making delivery unpredictable.\n\n\n\n\nThe lack of intelligent resource allocation compounds these problems. Build queues grow during peak usage periods, forcing teams to wait for available resources. Without smart scheduling and parallel processing capabilities, even simple changes can sit idle for hours while the system processes other jobs sequentially.\n💡Read more: Solving the CI/CD Build Queue Bottleneck Problem\nBy contrast, modern platforms use declarative configuration and environment-as-code principles. Deployments land in reproducible environments automatically, cutting out manual checks and accelerating lead time.\nModern platforms are also architected to minimize lead time through intelligent automation and resource optimization. \nFor instance, TeamCity’s advanced parallel processing capabilities automatically identify opportunities to run tasks concurrently, dramatically reducing total pipeline execution time. Instead of waiting for sequential steps to complete, multiple processes run simultaneously whenever dependencies allow.\n\n\n\n\nNative dependency management and intelligent caching eliminate redundant work. The platform automatically identifies which components have changed and which can be reused from previous builds, significantly reducing build times for incremental changes. This intelligence extends to test execution, where only relevant test suites run based on code changes.\nSeamless integrations with modern development tools eliminate the custom scripting overhead. Instead of maintaining brittle connectors between disparate tools, teams get native integrations that work reliably without needing ongoing maintenance. Smart resource allocation and cloud bursting capabilities prevent queue delays by automatically scaling compute resources during peak usage periods.\nChange failure rate: Quality under pressure\nShipping faster is only an advantage if your releases are reliable. Change failure rate measures the percentage of deployments that require immediate remediation, whether through hotfixes, rollbacks, or patches. It captures both engineering quality and business risk.\nWhy it matters\nElite performers achieve change failure rates of 0–15 percent, while low performers experience 30 percent or higher failure rates.\nEach deployment failure carries significant business costs beyond the immediate technical impact. Industry estimates suggest that application downtime costs IT enterprises an average of $5,600 per minute. Beyond direct revenue loss, each failed deployment results in lost customer trust.\nThe operational costs of failed deployments also compound quickly. Engineering teams must context-switch from planned work to emergency remediation. Customer support teams field complaints and escalations. \nSales teams face difficult conversations with prospects and existing customers. The ripple effects of a single deployment failure can impact organizational productivity for days.\nAlso, high change failure rates create a culture of fear around deployment. Teams become risk-averse, deploy less frequently, and accumulate technical debt. This defensive approach makes the system more fragile and failures more catastrophic when they do occur.\nTooling’s impact on quality\nCI/CD systems with limited native-testing-integration capabilities force teams to rely heavily on third-party plugins and custom integrations. Each plugin introduces potential failure points, version-compatibility issues, and maintenance overhead that can compromise testing reliability.\nManual testing orchestration creates dangerous gaps in coverage and consistency. Without automated test selection and execution based on code changes, teams either run exhaustive test suites that slow deployment, or they skip critical tests that could catch failures. \nTo add to that, the human element in test coordination introduces variability. What gets tested depends on who’s managing the deployment and how much time pressure they’re under.\n\n\n\n\nSystems without sophisticated rollback mechanisms create further issues when failures do occur. For example, rolling back might require manual intervention, custom scripts, and coordination across multiple systems. In these cases, database rollbacks, infrastructure changes, and configuration updates must be handled separately, which extends recovery time and increases the risk of incomplete remediation.\nPerhaps most importantly, poor observability makes it nearly impossible to predict and prevent deployment failures. Without comprehensive monitoring and intelligent alerting, teams operate blindly, discovering problems only after customers are affected.\nModern CI/CD platforms treat quality as a first-class requirement, not an afterthought. Comprehensive testing-framework integration ensures thorough quality validation with minimal setup overhead. The platform is intelligent enough to automatically orchestrate appropriate test suites based on code changes, run tests in parallel to minimize time impact, and provide clear feedback on test results and coverage.\nInstead of offering a one-size-fits-all rollback button, modern platforms provide the building blocks for creating robust, automated rollback workflows. That includes support for reverting not just code but also database schema changes and infrastructure configurations. \nWhen failures occur, teams can wire these primitives into automated pipelines that trigger and coordinate rollbacks across all affected systems, ensuring complete and consistent remediation. This approach dramatically reduces mean time to recovery and minimizes the scope of customer impact.\nAdvanced monitoring and alerting systems provide early warning capabilities that can prevent failures from reaching production. By correlating deployment activities with system performance metrics, these platforms can detect anomalies and automatically halt deployments before they cause customer-facing issues.\nMean time to recovery: Resilience when things go wrong\nEven the best teams know that failures are inevitable. What sets elite performers apart from the rest is how quickly they recover. Mean time to recovery (MTTR) measures the average duration required to restore service when a deployment goes wrong.\nWhy it matters\nThe difference in performance for MTTR is stark: Elite performers restore service in less than one hour, while low performers require between one week and one month to fully recover from deployment-related incidents.\nMTTR capability determines your organization’s overall resilience and risk profile. Faster recovery protects revenue by minimizing downtime costs, preserves customer trust by demonstrating operational competence, and safeguards brand reputation by preventing minor incidents from becoming public relations disasters.\nOrganizations with elite MTTR performance can take calculated risks and deploy more frequently because they have confidence in their recovery capabilities.\nTooling’s impact on recovery\nCI/CD systems that turn incident response into a manual, error-prone process extend downtime. Manual rollback calls for custom pipeline scripts and plugin coordination, which introduces complexity and risk precisely when teams need speed and reliability.\nLimited visibility into pipeline execution makes root cause identification painfully slow. Without comprehensive logging, distributed tracing, and correlation between deployment activities and system performance, teams resort to guesswork and trial-and-error debugging. This blind troubleshooting results in extended recovery time and the increased likelihood of incomplete fixes that cause recurring issues.\nThe lack of automated recovery mechanisms forces organizations to rely entirely on human intervention during high-stress situations. Poor integration with monitoring and alerting systems compounds these problems by delaying incident detection. Teams often learn about failures from customers rather than proactive monitoring.\n\n\n\n\nInstead, you want to use a CI/CD platform that offers automated, intelligent response capabilities. For instance, TeamCity’s built-in observability for the CI/CD platform itself tracks server load, agent utilization, build queue health, and pipeline performance. These metrics can be exported to Prometheus and visualized in Grafana so that platform teams can monitor their CI/CD backbone alongside application and infrastructure metrics.\nMost modern CI/CD platforms are built with high availability in mind, using multinode configurations and automated failover mechanisms to prevent the system itself from becoming a single point of failure. \nThis resilience means that even during incidents, the deployment system remains operational, allowing teams to focus on recovery without worrying about the platform going down simultaneously.\nSeamless integration with enterprise monitoring and alerting systems makes rapid incident detection and automated response workflows possible. \nFor instance, teams can connect TeamCity’s metrics to existing monitoring stacks so that anomaly detection triggers rollback procedures automatically, often before customers feel the impact.\n\n\n\n\nConclusion\nCI/CD platforms that require extensive customization, external plugins, and specialized expertise increase operational overhead and introduce security risks, holding your team back. \nThe strategic advantage belongs to organizations that modernize their CI/CD approach with integrated platforms designed for enterprise scale and elite performance.\nEven if you know your legacy solution is holding you back, at what point does it warrant the pain of migration? For some teams, the return on investment is not worth the effort. \nTo make an informed decision, you must quantify the risks of staying with your legacy system compared to the rewards of migration.\nThis article was brought to you by Kumar Harsh, draft.dev.",
        "dc:creator": "Olga Bedrina",
        "content": "Every engineering leader would love to work with a team of elite performers who deploy 182x more frequently, recover from failures 2,293x faster, and achieve 127x faster lead times than low performers. (Yes, that&#8217;s the actual difference in performance of real teams from the 2024 DORA research report). But how do you improve your team&#8217;s [&#8230;]",
        "contentSnippet": "Every engineering leader would love to work with a team of elite performers who deploy 182x more frequently, recover from failures 2,293x faster, and achieve 127x faster lead times than low performers. (Yes, that’s the actual difference in performance of real teams from the 2024 DORA research report). But how do you improve your team’s […]",
        "guid": "https://blog.jetbrains.com/?post_type=teamcity&p=666841",
        "categories": [
          "best-practices",
          "insights",
          "devopspains",
          "metrics"
        ],
        "isoDate": "2025-12-09T13:45:22.000Z"
      },
      {
        "creator": "Regina Muradova",
        "title": "Hyperskill Gets Its Own Plugin Inside JetBrains IDEs",
        "link": "https://blog.jetbrains.com/education/2025/12/09/hyperskill-gets-its-own-plugin-inside-jetbrains-ides/",
        "pubDate": "Tue, 09 Dec 2025 12:42:11 +0000",
        "content:encodedSnippet": "Hyperskill is introducing its own free dedicated plugin inside JetBrains IDEs. This new plugin is built specifically for the Hyperskill learning experience and replaces the previous integration inside the JetBrains Academy plugin. Starting December 11, Hyperskill courses will be available exclusively through the new Hyperskill Academy plugin. \nThe new Hyperskill Academy plugin provides a more focused and consistent learning environment with all features, tasks, and settings conveniently located in one place. It is designed and maintained directly by the Hyperskill team.\nWhat you’ll get with the new plugin:\nA unified environment aligned with the Hyperskill platform.\nFaster updates, improvements, and fixes.\nSimpler navigation in a single dedicated plugin.\nThis makes learning smoother and more intuitive, especially for long-term projects.\n\n\n\n\nIf you’re currently using Hyperskill courses through the JetBrains Academy plugin, here’s what you need to know and what to do next.\nWhat changes\nYou’ll need to install the new free Hyperskill Academy plugin from the Marketplace tab in IDE, available after December 11.\nThe JetBrains Academy plugin will remain available for JetBrains Academy learning courses and Coursera, but it will no longer include Hyperskill courses and projects after the upcoming update. \nYour existing Hyperskill projects will still work. No manual migration is needed – your progress and projects will stay safely on Hyperskill and appear automatically once you sign in.\nHow to continue using Hyperskill courses\nThe new Hyperskill Academy plugin will be available after December 11, and you’ll be able to install it in your IDE:\nUpdate the JetBrains Academy plugin to the latest version.\nInstall the new Hyperskill Academy plugin from the Marketplace tab in IDE.\nSign in with your Hyperskill account via Settings/Preferences | Tools | Hyperskill.\nOpen your projects and continue learning right where you left off.\nNo manual migration is needed – your progress and projects will stay safely on Hyperskill and appear automatically once you sign in.\nWe understand that you might have questions regarding this change, so we’ve prepared an FAQ list to address the most common topics.\nWhat will happen to the JetBrains Academy plugin?\nThe JetBrains Academy plugin will continue to support JetBrains Academy learning courses, but Hyperskill projects will no longer be part of it. For Hyperskill courses and projects, use the new Hyperskill Academy plugin. We recommend updating the JetBrains Academy plugin as usual. This will allow both plugins to work without issues.\nWhen will the Hyperskill plugin be available?\nYou’ll be able to install the new Hyperskill plugin starting December 11, 2025. Make sure to switch to the Hyperskill Academy plugin right away, as Hyperskill courses won’t be supported in the JetBrains Academy plugin after this date.\nHow will I be notified when the Hypserkill Academy plugin is live?\nOn the Hyperskill platform: You’ll see a banner with a direct install button on the Study plan page.\nInside the JetBrains Academy plugin: After updating the plugin, you’ll see in‑plugin messages with guidance once the release is live.\nWill this affect my IDE settings?\nNo. Your IDE preferences (themes, fonts, keymaps, and third‑party plugins) won’t change. Our plugin works on top of your current setup.\nWill my existing projects on Hyperskill still work after installing the Hyperskill Academy plugin? \nYes. You can open and continue working on your existing Hyperskill projects after installing the new plugin – no migration required.\nWho should I contact if I have questions about the new Hyperskill Academy plugin?\nPlease reach out to Hyperskill Support, or send an email to hello@hyperskill.org. \nWe’re sure this update will elevate your learning experience and make working with Hyperskill even more seamless and efficient.\nHappy learning!\nThe JetBrains Academy team",
        "dc:creator": "Regina Muradova",
        "content": "Hyperskill is introducing its own free dedicated plugin inside JetBrains IDEs. This new plugin is built specifically for the Hyperskill learning experience and replaces the previous integration inside the JetBrains Academy plugin. Starting December 11, Hyperskill courses will be available exclusively through the new Hyperskill Academy plugin.&#160; The new Hyperskill Academy plugin provides a more [&#8230;]",
        "contentSnippet": "Hyperskill is introducing its own free dedicated plugin inside JetBrains IDEs. This new plugin is built specifically for the Hyperskill learning experience and replaces the previous integration inside the JetBrains Academy plugin. Starting December 11, Hyperskill courses will be available exclusively through the new Hyperskill Academy plugin.  The new Hyperskill Academy plugin provides a more […]",
        "guid": "https://blog.jetbrains.com/?post_type=education&p=666290",
        "categories": [
          "jetbrains-academy-plugin",
          "hyperskill",
          "jetbrainsacademy-2"
        ],
        "isoDate": "2025-12-09T12:42:11.000Z"
      },
      {
        "creator": "Stanislav Garkusha",
        "title": "DataSpell 2025.3: Visualization Cells, Multi-Agent Support, Jupyter Improvements.",
        "link": "https://blog.jetbrains.com/dataspell/2025/12/dataspell-2025-3-visualization-cells-multi-agent-support-jupyter-improvements/",
        "pubDate": "Tue, 09 Dec 2025 11:58:47 +0000",
        "content:encodedSnippet": "With the 2025.3 release, DataSpell continues its mission to make data analysts more productive with the help of AI. In addition to improving DataSpell’s own AI agent, this release expands your options by introducing direct access to Claude Agent from the IDE – with more agents coming soon. DataSpell 2025.3 also includes major visualization workflow enhancements and Jupyter improvements.\nRead on to discover everything that’s new in DataSpell 2025.3.\n\n\n\n\nDownload DataSpell 2025.3 \nMultiple agents in DataSpell\nFor the first time, DataSpell supports multiple AI agents. You can choose between:\nDataSpell AI Agent – designed to operate and control DataSpell features via requests made directly in the AI chat.\n\n\n\n\nClaude Agent – great for code assistance and documentation.\n\n\n\n\n\nSimply open the AI chat, pick your agent, and start collaborating. More agents will be added in future updates.\n\n\n\n\nVisualization enhancements\nIn-chat visualizations\nIt’s now possible to generate and view charts directly in the AI chat – no extra steps required.\nDataSpell AI agent can:\nUnderstand datasets automatically.\n\n\n\n\nGenerate visualizations as JSON-based specs.\n\n\n\n\nDisplay visualizations in the chat or in dedicated visualization cells.\n\n\n\n\n\nThis makes exploratory data analysis smoother and more interactive.\n\n\n\n\nVisualization cells in notebooks\nWe’ve added support for visualization cells, a new, no-code way to explore and present data in notebooks. You can now:\nAdd visualizations without writing code.\nInstantly view visualizations inline.\nEdit charts directly in the new no-code chart editor.\n\n\n\n\nJupyter improvements\nDataSpell now automatically detects:\nMissing values\nOutliers\nDuplicates\nFormat inconsistencies\nCorrelated or redundant features\n\n\n\n\n\nYou’ll get AI-powered suggestions to fix these issues instantly. Click Fix with AI to insert a new cell in the same Jupyter notebook with code generated to resolve the relevant issue.\n\n\n\n\nDatabase updates\nQuery files\nFollowing their addition to DataGrip, DataSpell now also uses query files in place of query consoles for a smoother and more consistent SQL workflow. Upon first launch after updating, you’ll be prompted to migrate your existing consoles automatically.\n\n\n\n\nCloud database connections\nDataSpell now integrates with AWS, Azure, and Google Cloud. Connect your cloud accounts directly from the IDE, browse available databases, and create new data sources with a single click. All connected accounts appear under the Cloud tab in the Data Sources and Drivers dialog.\n\n\n\n\nIslands theme by default\nThe Islands interface theme is now the default for DataSpell and is available in both dark and light variants. This update modernizes the visual experience without altering your workflows. To turn the new theme on or off, open the IDE Settings dialog and navigate to the Appearance & Behavior settings page.\n\n\n\n\nWe hope you enjoy exploring DataSpell 2025.3! This release marks another milestone in making DataSpell the most intelligent, context-aware IDE for data professionals. If you encounter a bug or have a feature suggestion, please share it on our issue tracker.\nStay up to date on new features and data analysis tips – subscribe to our blog and follow us on X!",
        "dc:creator": "Stanislav Garkusha",
        "content": "With the 2025.3 release, DataSpell continues its mission to make data analysts more productive with the help of AI. In addition to improving DataSpell’s own AI agent, this release expands your options by introducing direct access to Claude Agent from the IDE – with more agents coming soon. DataSpell 2025.3 also includes major visualization workflow [&#8230;]",
        "contentSnippet": "With the 2025.3 release, DataSpell continues its mission to make data analysts more productive with the help of AI. In addition to improving DataSpell’s own AI agent, this release expands your options by introducing direct access to Claude Agent from the IDE – with more agents coming soon. DataSpell 2025.3 also includes major visualization workflow […]",
        "guid": "https://blog.jetbrains.com/?post_type=dataspell&p=659190",
        "isoDate": "2025-12-09T11:58:47.000Z"
      },
      {
        "creator": "Iryna Pisklyarova",
        "title": "Join the RubyMine Team on Reddit AMA Session",
        "link": "https://blog.jetbrains.com/ruby/2025/12/join-the-rubymine-team-on-reddit-ama-session/",
        "pubDate": "Tue, 09 Dec 2025 09:53:42 +0000",
        "content:encodedSnippet": "The RubyMine team will be stopping by r/jetbrains on December 11 from 1–5 pm CET and doing an Ask Me Anything (AMA) thread. You’re invited to join us!\nThis isn’t a product launch or a marketing campaign – it’s a chance to have an open conversation about RubyMine and the challenges you face as a Ruby and Rails developer. \nHow to Participate\nWhen: December 11, 1:00–5:00 pm CET (7:00–11:00 am EST)\nWhere: r/jetbrains\nFormat:Drop your questions in the AMA thread anytime during the session.\nWe’ll be online responding in real time, but if you can’t make it live, you can post your questions early. This AMA is your chance to tell us what matters most, what’s working well, what’s not, and where we can do better.\nWho You’ll Be Talking To\nThe following members of the RubyMine team will be there to answer your questions: \nDmitry Pogrebnoy (u/DmitryPogrebnoy) – RubyMine Team Lead\nMikhail Veselov (u/MikhailVeselov) – RubyMine Product Manager\nOlga Kuvardina (u/SeekingRuby) – RubyMine Support Engineer\nJan-Niklas Wortmann (u/jan-niklas-wortmann) – Developer Advocate for AI\nWhy We’re Hosting This AMA\nWe know that great tools are built in collaboration with the people who use them every day. That’s why we want to talk directly with you about not only features, but how RubyMine actually fits into your daily workflows.\nYour feedback is foundational to our roadmap. It helps us boost performance, refine the tools you already rely on, and choose what to build next.\nSo ask away! Whether you’re curious about the new RubyMine 2025.3 release, the debugger, code navigation, existing features, or the latest AI enhancements – we’re here to chat.\nPart of JetBrains AMA Week\nThe RubyMine AMA is part of JetBrains AMA Week, a series of live Reddit discussions where teams from across JetBrains are connecting directly with their communities. Each AMA focuses on a specific product, giving users a space to share their experiences, ideas, and feedback.\nIf you have questions about JetBrains AI Assistant features specifically, the AI team is doing an AMA on December 12 at 1:00–5:00 pm CET, where they’ll be able to answer questions about their strategy and the direction they’re headed in. We’re happy to discuss how AI features work in RubyMine and your feedback on them, but for more general questions about JetBrains AI, you’ll be better off consulting the AI team.\nSee the full AMA Week schedule here.\nWe’re looking forward to hearing from you on December 11 at 1:00 pm CET!\nThe RubyMine team",
        "dc:creator": "Iryna Pisklyarova",
        "content": "The RubyMine team will be stopping by r/jetbrains on December 11 from 1–5 pm CET and doing an Ask Me Anything (AMA) thread. You&#8217;re invited to join us! This isn’t a product launch or a marketing campaign – it’s a chance to have an open conversation about RubyMine and the challenges you face as a [&#8230;]",
        "contentSnippet": "The RubyMine team will be stopping by r/jetbrains on December 11 from 1–5 pm CET and doing an Ask Me Anything (AMA) thread. You’re invited to join us! This isn’t a product launch or a marketing campaign – it’s a chance to have an open conversation about RubyMine and the challenges you face as a […]",
        "guid": "https://blog.jetbrains.com/?post_type=ruby&p=666493",
        "categories": [
          "news",
          "ama",
          "reddit",
          "ruby",
          "rubymine"
        ],
        "isoDate": "2025-12-09T09:53:42.000Z"
      },
      {
        "creator": "Ilia Afanasiev",
        "title": "PyCharm 2025.3 – Unified IDE, Jupyter notebooks in remote development, uv as default, and more",
        "link": "https://blog.jetbrains.com/pycharm/2025/12/pycharm-2025-3-unified-ide-jupyter-notebooks-in-remote-development-uv-as-default-and-more/",
        "pubDate": "Mon, 08 Dec 2025 16:57:36 +0000",
        "content:encodedSnippet": "We’re excited to announce that PyCharm 2025.3 is here! This release continues our mission to make PyCharm the most powerful Python IDE for web, data, and AI/ML development.\nIt marks the migration of Community users to the unified PyCharm and brings full support for Jupyter notebooks in remote development, uv as the default environment manager, proactive data exploration, new LSP tools support, the introduction of Claude Agent, and over 300 bug fixes.\nDownload now\n                                                    \nCommunity user migration to the unified PyCharm\nAs announced earlier, PyCharm 2025.2 was the last major release of the Community Edition. With PyCharm 2025.3, we’re introducing a smooth migration path for Community users to the unified PyCharm.\nThe unified version brings everything together in a single product – Community users can continue using PyCharm for free and now also benefit from built-in Jupyter support.\nWith a one-click option to start a free Pro trial, it’s easier than ever to explore PyCharm’s advanced features for data science, AI/ML, and web development.\nLearn more in the full What’s New post →\n\n\n\n\nJupyter notebooks\nJupyter notebooks are now fully supported in remote development. You can open, edit, and run notebooks directly on a remote machine without copying them to your local environment.\nThe Variables tool window also received sorting options, letting you organize notebook variables by name or type for easier data exploration.\nRead more about Jupyter improvements →\n\n\n\n\nuv now the default for new projects\nWhen uv is detected on your system, PyCharm now automatically suggests it as the default environment manager in the New Project wizard.\nFor projects managed by uv, uv run is also used as the default command for your run configurations.\n\n\n\n\nProactive data exploration Pro\nPyCharm now automatically analyzes your pandas DataFrames to detect the most common data quality issues. If any are found, you can review them and use Fix with AI to generate cleanup code automatically.\nThe analysis runs quietly in the background to keep your workflow smooth and uninterrupted.\n\n\n\n\nSupport for new LSP tools\nPyCharm 2025.3 expands its LSP integration with support for Ruff, ty, Pyright, and Pyrefly.\nThese bring advanced formatting, type checking, and inline type hints directly into your workflow.\nMore on LSP tools.\n\n\n\n\nAI features\nMulti-agent experience: Junie and Claude Agent\nWork with your preferred AI agent from a single chat: Junie by JetBrains and Claude Agent can now be used directly in the AI interface. \nClaude Agent is the first third-party AI agent natively integrated into JetBrains IDEs.\n\n\n\n\nBring Your Own Key (BYOK) is coming soon to JetBrains AI\nBYOK will let you connect your own API keys from OpenAI, Anthropic, or any OpenAI API-compatible local model, giving you more flexibility and control over how you use AI in JetBrains IDEs.\nRead more\nTransparent in-IDE AI quota tracking \nMonitoring and managing your AI resources just got a lot easier, as you can now view your remaining AI Credits, renewal date, and top-up balance directly inside PyCharm.\n\n\n\n\nUIX changes\nIslands theme\nThe new Islands theme is now the default for all users, offering improved contrast, balanced layouts, and a softer look in both dark and light modes.\n\n\n\n\nNew Welcome screen\nWe’ve introduced a new non-modal Welcome screen that keeps your most common actions within reach and provides a smoother start to your workflow.\n\n\n\n\nLooking for more?\nVisit our What’s New page to learn about all 2025.3 features and bug fixes.\nRead the release notes for the full breakdown of the changes.\nIf you encounter any problems, please report them via our issue tracker so we can address them promptly.\nWe’d love to hear your feedback on PyCharm 2025.3 – leave your comments below or connect with us on X and BlueSky.",
        "dc:creator": "Ilia Afanasiev",
        "content": "We’re excited to announce that PyCharm 2025.3 is here! This release continues our mission to make PyCharm the most powerful Python IDE for web, data, and AI/ML development. It marks the migration of Community users to the unified PyCharm and brings full support for Jupyter notebooks in remote development, uv as the default environment manager, [&#8230;]",
        "contentSnippet": "We’re excited to announce that PyCharm 2025.3 is here! This release continues our mission to make PyCharm the most powerful Python IDE for web, data, and AI/ML development. It marks the migration of Community users to the unified PyCharm and brings full support for Jupyter notebooks in remote development, uv as the default environment manager, […]",
        "guid": "https://blog.jetbrains.com/?post_type=pycharm&p=666528",
        "categories": [
          "releases"
        ],
        "isoDate": "2025-12-08T16:57:36.000Z"
      },
      {
        "creator": "Ekaterina Prigara",
        "title": "The Future of Fleet",
        "link": "https://blog.jetbrains.com/fleet/2025/12/the-future-of-fleet/",
        "pubDate": "Mon, 08 Dec 2025 14:59:39 +0000",
        "content:encodedSnippet": "TL;DR\nFleet started as our attempt to explore a new generation of JetBrains IDEs, developed in parallel with those based on the IntelliJ Platform. Over time, we learned that having two general-purpose IDE families created confusion and diluted our focus. Rebuilding the full capabilities of IntelliJ-based IDEs inside Fleet did not create enough value, and positioning Fleet as yet another editor did not justify maintaining two overlapping product lines.\nStarting December 22, 2025, Fleet will no longer be available for download. We are now building a new product focused on agentic development.\nFleet vs. IntelliJ-based IDEs\nFor many years, JetBrains focused on IntelliJ-based IDEs, which served as the primary environment for most developers. When we started Fleet, our goal was to explore a lighter architecture, a modern UI model, and a more flexible environment free from decades of legacy architectural decisions. It was a worthwhile experiment, and from both a technical and design perspective, it was a success. Many Fleet components now power JetBrains IDEs, and several UX and UI concepts have been adopted throughout our product lineup.\nHowever, Fleet did not succeed as a standalone product. We could neither replace IntelliJ IDEA with Fleet nor narrow it into a clear, differentiated niche. We suddenly had two IDE families aimed at largely the same audience, with overlapping purposes. Users kept asking which one to choose, and the answer was never short or satisfying. Two similar products created friction and raised questions about ownership and long-term investment.\nWhat we tried with Fleet\nWe initially positioned Fleet as a lightweight multi-language IDE and then as an editor with smart coding assistance. For some time, we seriously considered whether Fleet could become a second flagship IDE family alongside IntelliJ-based tools. User feedback was consistent: If you already work with IntelliJ IDEA, Rider, WebStorm, PyCharm, or any other JetBrains IDE, switching to Fleet required a strong reason – and Fleet did not offer enough value to justify the transition from IDEs you already know and love.\nWhen AI matured, we explored Fleet as an AI-first editor. We built new workflows and conducted large-scale user research to understand potential differentiation and long-term value. We confirmed that another AI editor would not stand out, especially in a market filled with AI-first VS Code forks. It became increasingly clear that the best path forward was to strengthen AI workflows in our existing IDEs. However, rapid progress in AI revealed a different niche where Fleet fits much more naturally.\nWhat this new niche looks like\nWhile we worked on AI within the editor, a new development workflow began to take shape. Developers started delegating meaningful tasks to agents – updating tests, cleaning code, refactoring modules, exploring unfamiliar code paths, and even building new features. These tasks run asynchronously and return full patches. The developer doesn’t write the code themselves. They guide the agent and review its output. This is fundamentally different from the classic IDE workflow, which is based on immediate feedback, synchronous control, and a single stable local state.\nThe agentic loop relies on structured task definition, context assembly, multiple asynchronous runs, isolated execution, and review-first workflows. Combining them in a single tool results in a disjointed experience, so the Fleet team chose to stop competing with IDEs and code editors and instead build a product focused on agentic workflows. This led to a pivot to a new product: an agentic development environment. Based on the Fleet platform, this new environment will ship as a new product with a new name. The technology, team, and long-term direction continue – but the product identity and the target market evolve.\nWhat changes for current Fleet users\nWe will stop releasing any further updates for Fleet. Distribution will also end, so you will no longer be able to download Fleet from the Toolbox App or other channels starting December 22, 2025.\nIf you have already downloaded Fleet, you can continue using it. However, some features that rely on our server-side services, including AI Assistant, may stop working over time.\nWe will continue to share updates about the new product as the work progresses. Stay tuned!",
        "dc:creator": "Ekaterina Prigara",
        "content": "TL;DR Fleet started as our attempt to explore a new generation of JetBrains IDEs, developed in parallel with those based on the IntelliJ Platform. Over time, we learned that having two general-purpose IDE families created confusion and diluted our focus. Rebuilding the full capabilities of IntelliJ-based IDEs inside Fleet did not create enough value, and [&#8230;]",
        "contentSnippet": "TL;DR Fleet started as our attempt to explore a new generation of JetBrains IDEs, developed in parallel with those based on the IntelliJ Platform. Over time, we learned that having two general-purpose IDE families created confusion and diluted our focus. Rebuilding the full capabilities of IntelliJ-based IDEs inside Fleet did not create enough value, and […]",
        "guid": "https://blog.jetbrains.com/?post_type=fleet&p=666261",
        "categories": [
          "general",
          "news"
        ],
        "isoDate": "2025-12-08T14:59:39.000Z"
      },
      {
        "creator": "Hanna Yakush",
        "title": "PhpStorm 2025.3 Is Now Out",
        "link": "https://blog.jetbrains.com/phpstorm/2025/12/phpstorm-2025-3-is-now-out/",
        "pubDate": "Mon, 08 Dec 2025 13:35:43 +0000",
        "content:encodedSnippet": "Welcome to PhpStorm 2025.3! This release brings native Claude Agent integration, out-of-the-box Laravel support, support for PHP 8.5, improvements in generics, a new Islands theme, and more.\nDownload PhpStorm 2025.3\n\n\n\n\nPHP\nPHP 8.5 support\nPhpStorm 2025.3 supports all of the changes introduced in the recently released PHP 8.5. \nAs usual, you can try new features by setting the project language level to PHP 8.5. You can do so in the settings (by going to PHP | PHP language level), by specifying the requirement in composer.json, or by simply using PhpStorm’s Switch to PHP 8.5 language level quick-fix.\n\n\n\n\nCloning objects with properties\nPHP 8.5 changes clone from a standalone keyword to a language construct that optionally accepts a second array parameter. Now, clone can clone an object and modify its properties in one expression, and PhpStorm helps you detect the syntax that can be updated in your code and replace it.\n\n\n\n\nIn addition, PhpStorm 2025.3 ensures the proper usage of clone when it is promoted to a function and used as a callable.\n\n\n\n\nClosures in constant expressions\nPHP 8.5 allows you to use closures in the constructs that previously accepted only constant expressions. PhpStorm supports this with code checks and quick-fixes that ensure the proper usage of closures as attribute parameters, constants and class constants, or default values of properties and parameters.\n\n\n\n\n\n\n\n\n\n\n\n\nPipe operator\nPHP 8.5’s pipe operator (|>) takes the return value of the left-side callable and passes it to the right-side callable, thus chaining multiple callables together.\nPhpStorm ensures that the pipe operator is used correctly in your code, highlighting invalid callables in a pipe chain, improper syntax, incompatible types, or type mismatches. \n\n\n\n\nThe latest release of Xdebug supports pipes in PHP 8.5 as well. You can see the intermediate values passing through PHP’s pipes during a debugging session in PhpStorm.\n#[NoDiscard] attribute\nPHP 8.5 introduces a new #[NoDiscard] attribute, which indicates that a function’s or method’s return value cannot be ignored. PhpStorm adds support for this attribute as well.\n\n\n\n\n\n\n\n\nOther PHP 8.5 features\nHere are a few more PHP 8.5 features now supported in PhpStorm:\nFinal property promotion, where a __constructor parameter marked with final is considered promoted and treated like other promoted properties.\n\n\n\n\n\nAsymmetric visibility for static properties, similar to asymmetric visibility for object properties, which was implemented in PHP 8.4.\nThe array_first() and array_last() functions, which return the first and last values of an array.\nAttributes for constants that are allowed to target the constants declared in their own statements.\nGenerics improvements: support for nested generic types\nPhpStorm 2025.3 further advances support for type annotations in PHPDoc comments. Now it can infer the variable type in nested generic type declarations such as Inner<Inner<\\DateTime>>. \n\n\n\n\nTo display the type, place the caret at the required variable or expression and press Ctrl+Shift+P or select View | Type info in the main menu.\nLaravel\nOut-of-the-box Laravel support\nA while ago, we announced that the Laravel Idea plugin had been made free for PhpStorm users. In PhpStorm 2025.3, we’ve bundled the Laravel Idea plugin into the IDE. Now PhpStorm offers full-featured support for every aspect of Laravel development out of the box, with no need to install additional plugins. \nThe developer of Laravel Idea, Adel Faizrakhmanov, will keep working on new Laravel support features, which will now be delivered as part of the PhpStorm IDE.\n\n\n\n\n\n\nPest 4 support \nPhpStorm 2025.3 supports usage of all the new features introduced in the Pest v4 testing framework, including Playwright-powered browser testing. \nWhen debugging browser tests with the ->debug() method in PhpStorm, use the Continue Test Run button on the test results toolbar to resume a paused test.  \n\n\n\n\nJetBrains AI\nJetBrains AI is evolving to give you more choice, transparency, and flexibility in how you use AI inside your IDE. You can work with Claude Agent and Junie from a single chat interface, track your AI credits directly in the IDE, and soon you’ll be able to connect your own AI provider keys with BYOK.  \nGet started\nMulti-agent experience: Junie and Claude Agent\nClaude Agent has become the first third-party AI agent natively integrated into JetBrains IDEs. With its addition, JetBrains introduces a multi-agent experience that brings even more flexibility and power to your development workflow. Now that Claude Agent and Junie are available in the same chat interface, you can switch between agents seamlessly and get the right kind of assistance for every task.\nThe easiest way to start working with any agent now is to launch it directly from the AI chat. However, the Junie plugin will still be available for you if you prefer it this way.\n\n\n\n\nBring Your Own Key: More freedom and control Coming soon\nBYOK will let you connect your own API keys from OpenAI, Anthropic, or any OpenAI API-compatible local model, giving you more flexibility and control over how you use AI in JetBrains IDEs. You’ll be able to use your favorite AI chat and agents without logging into JetBrains AI, which is perfect for developers who already have API keys and want to work with their preferred provider. Learn more in this blog post.\nThe feature is expected to roll out in the upcoming 2025.3.x releases.\nTransparent AI quota tracking in IDE\nYou can now view your remaining AI credits, renewal date, and top-up balance directly inside your IDE, and if you run out of credits, you can initiate a top-up from there as well.\nThis update makes it easier to monitor and manage your AI resources – bringing more clarity and convenience to your AI usage. \nLearn more about AI quotas in this blog post.\nStreamlined MCP server setup\nIn PhpStorm 2025.3, we’ve improved the way MCP server configurations are imported from other tools. When you first open a project with an mcp.json file in it, PhpStorm will automatically fetch the configured MCP servers and prompt you to view or enable them in the IDE settings. \n\n\n\n\nWe’ve improved Laravel Boost setup as well. Now PhpStorm does more than just pick the server configuration automatically – it also suggests enabling the server when it is disabled.   \nDisclaimer: some AI features may work differently or be unavailable in your region. Learn more here.\nDatabases\nA farewell to consoles\nStarting from the 2025.3 release, PhpStorm and other JetBrains IDEs with database support will stop using the term query console. From now on, we’ll use query file – because consoles were essentially files all along, and it’s time the UI reflected that. We’ve also made the workflow simpler, more discoverable, and more consistent.\nTo learn more, check out this blog post.\nConnection to cloud providers\nPhpStorm now works with cloud database providers! In the new version, you can connect your AWS, Azure, and Google Cloud accounts to the IDE, browse the list of databases you have in those accounts, and choose the ones you’d like to connect to. PhpStorm will create new data sources and fill in all the connection details.\nTo connect to your cloud account, click New | Data Source from Cloud Provider and select the cloud provider.\n\n\n\n\nAll the cloud accounts connected to your IDE are displayed on the Clouds tab of the Data Sources and Drivers dialog.\n\n\n\n\nUser experience\nIslands theme\nThe Islands theme is now the default look in PhpStorm. More than just a visual refresh, it reflects our commitment to providing the ultimate comfort throughout your development experience.\n\n\n\n\nInstantly recognizable tabs, improved in-editor contrast, clear separation between working areas, and rounded corners create a soft and balanced environment that was designed around one goal: helping you stay focused and code with ease.\nLearn more in this blog post.\nCompletion in the terminal\nThe terminal is a tool developers use every day. Now, you can be even more productive in it, thanks to completion that suggests commands, option names, and path parameters. Don’t remember the exact name of a Git branch? Need a long file path? Forgot a specific switch? \nJust start typing and PhpStorm will suggest parameters for the given command.",
        "dc:creator": "Hanna Yakush",
        "content": "Welcome to PhpStorm 2025.3! This release brings native Claude Agent integration, out-of-the-box Laravel support, support for PHP 8.5, improvements in generics, a new&#160;Islands&#160;theme, and more. Download PhpStorm 2025.3 PHP PHP 8.5 support PhpStorm 2025.3 supports all of the changes introduced in the recently released PHP 8.5.&#160; As usual, you can try new features by setting [&#8230;]",
        "contentSnippet": "Welcome to PhpStorm 2025.3! This release brings native Claude Agent integration, out-of-the-box Laravel support, support for PHP 8.5, improvements in generics, a new Islands theme, and more. Download PhpStorm 2025.3 PHP PHP 8.5 support PhpStorm 2025.3 supports all of the changes introduced in the recently released PHP 8.5.  As usual, you can try new features by setting […]",
        "guid": "https://blog.jetbrains.com/?post_type=phpstorm&p=656429",
        "categories": [
          "releases",
          "2025-3",
          "release"
        ],
        "isoDate": "2025-12-08T13:35:43.000Z"
      },
      {
        "creator": "Alina Dolgikh",
        "title": "Kubernetes Made Simple: A Guide for JVM Developers",
        "link": "https://blog.jetbrains.com/kotlin/2025/12/kubernetes-made-simple-a-guide-for-jvm-developers/",
        "pubDate": "Mon, 08 Dec 2025 13:28:13 +0000",
        "content:encodedSnippet": "This article was written by an external contributor.\nMichael Nyamande\nA digital product manager by day, Michael is a tech enthusiast who is always tinkering with different technologies. His interests include web and mobile frameworks, NoCode development, and blockchain development.\nMichael on social media\nKubernetes is a container orchestration system for deploying, scaling, and managing containerized applications. If you build services on the Java virtual machine (JVM), you likely know that most microservices run on Kubernetes. Kubernetes has become the de facto standard for running containerized microservices at scale. However, Kubernetes is famously complex, with many new concepts (Pods, Deployments, Services, etc.) to master, and thus, has a steep learning curve.\nThis tutorial helps ease that complexity for JVM developers. It focuses on what you need to ship a Kotlin or Java Spring Boot app to a cluster, step-by-step, with simple explanations and runnable examples.\nYou’ll learn the basics of Kubernetes by deploying a Kotlin Spring Boot application onto a Kubernetes cluster. You’ll also cover what deployment and services are, how to manage configurations using ConfigMaps and Secrets, and what the best practices are for running JVM applications on Kubernetes.\nPrerequisites\nBefore diving in, make sure you have the following:\nDocker: Install and run this locally. Docker builds a container image of your app.\nKubernetes: Install a Kubernetes environment. For this tutorial, you’ll use Minikube, a local single-node cluster, and the kubectl CLI for interacting with the cluster. You can download Minikube on their official site, and it comes bundled with kubectl.\nDocker registry: Create, for example, a Docker Hub account to push and pull your image. You can also use Minikube’s local Docker registry.\nRepository with the companion code for the article\nGo to GitHub\n                                                    \nSet Up the Sample Kotlin Spring Boot App (Optional)\nWhile you can use an existing Kotlin Spring Boot application for this tutorial, if you want to follow along with the code used here, you can create a new project with Spring Initializr. If you’re using an existing Spring Boot application, you can jump directly to the next section.\nSelect Kotlin as your language and Java 21 as our runtime. Make sure to add Spring Web, Spring Data JPA, and H2 as dependencies. You’ll use Spring Web to create REST endpoints, Spring Data JPA to connect to a PostgreSQL database, and H2 (an in-memory database) to test the database logic locally:\n\n\n\n\nAfter creating and downloading the project, locate your main application file. If you used Spring Initializr, the file will be named after your application with Application.kt appended— for example, a project named Demo will have a file called DemoApplication.kt. Add the following code to create a @RestController that returns Hello World, which will let you verify the deployment is working:\nimport org.springframework.boot.autoconfigure.SpringBootApplication\nimport org.springframework.boot.runApplication\nimport org.springframework.web.bind.annotation.GetMapping\nimport org.springframework.web.bind.annotation.RestController\n\n@SpringBootApplication\nclass DemoApplication\n\nfun main(args: Array<String>) {\n    runApplication<DemoApplication>(*args)\n}\n\n@RestController\nclass HelloController {\n    @GetMapping(\"/hello\")\n    fun hello(): String = \"Hello World\"\n}\nThe entire Spring Boot app and REST controller fit in just a few lines, thanks to Kotlin features like type inference and single-expression functions.\nContainerize a JVM App Using Docker\nTo deploy your application to Kubernetes, you need to initially package it into a container image using Docker. Create a Dockerfile in the project root:\nFROM openjdk:21-jdk-slim\n\nWORKDIR /app\n\n# Copy the JAR file from builder stage\nCOPY build/libs/*-SNAPSHOT.jar app.jar\n\n# Expose port 8080\nEXPOSE 8080\n\n# Run the application\nENTRYPOINT [\"java\", \"-jar\", \"app.jar\"]\nThis Dockerfile uses a lightweight Java 21 base image, copies in the built JAR file, and runs it. Kotlin and Java interoperability means the Spring Boot JAR runs just like any Java app in the container.\nTo build the image, you initially need to create a JAR file with gradle build or mvn clean package, depending on which build manager you’re using. If using Maven, update the Dockerfile to use target/*.jar instead of build/libs/*-SNAPSHOT.jar.\nAfter that, build the image:\ndocker build -t kotlin-app:latest .\nBefore you can push the image to Docker Hub, you need to execute this command to log in:\ndocker login\nNote that you may be prompted to enter your Docker Hub credentials to complete the login step.\n\n\n\n\nNext, push the image to Docker Hub or another registry so your Kubernetes cluster can access it:\ndocker tag kotlin-app:latest YOUR_DOCKERHUB_USER/kotlin-app:latest\ndocker push YOUR_DOCKERHUB_USER/kotlin-app:latest\nDeploy the Application to a Kubernetes Cluster\nTo run your application on Kubernetes, you need to tell Kubernetes how to configure and run it. You do this using manifest files, which are typically written in YAML. These files declaratively define the desired state of your application in the cluster. For a basic deployment, you need two key Kubernetes objects: a Deployment manifest and a Service manifest.\nAdd the Deployment Manifest\nA Deployment manages replicated Pods and handles rolling updates. A Pod is Kubernetes’s smallest unit that runs your container. Deployments ensure your specified number of Pods stay running and update them safely without downtime.\nCreate a file named k8s/deployment.yaml that defines your Deployment so that Kubernetes can run the application:\n\n\n\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kotlin-app-deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: kotlin-app\n  template:\n    metadata:\n      labels:\n        app: kotlin-app\n    spec:\n      containers:\n      - name: kotlin-k8s-app\n        image: <your-username>/kotlin-app:latest\n        ports:\n        - containerPort: 8080\nThe manifest above makes these declarations:\nkind: Deployment specifies the type of object.\nspec.replicas: 1 tells Kubernetes how many instances of the application you want running.\nspec.selector.matchLabels is how the Deployment knows which Pods to manage. It looks for Pods with the label app: kotlin-app.\nspec.template is the blueprint for the Pods. It defines the container(s) to run inside the Pod.\nspec.containers.image specifies the Docker image to pull.\nspec.containers.ports.containerPort informs Kubernetes that your application inside the container listens on port 8080.\n\n\n\n\n\nInclude the Service Manifest\nWhile a Deployment ensures your Pods are running, those Pods are ephemeral; each time they restart, they get a new internal IP address. A Service solves this by acting as a stable entry point with a fixed IP and DNS name, automatically routing traffic to the Pods identified by its label selector. This guarantees that even if Pods restart or change IPs, traffic still reaches the intended application.\n\n\n\n\nCreate a file named service.yaml in the k8s folder:\napiVersion: v1\nkind: Service\nmetadata:\n  name: kotlin-app-service\nspec:\n  selector:\n    app: kotlin-app\n  ports:\n    - protocol: TCP\n      port: 8080\n      targetPort: 8080\n  type: NodePort\nThe manifest defines:\nkind: Service specifies the object type.\nspec.selector must match the labels of the Pods (app: kotlin-app). This is how the Service knows where to send traffic.\nspec.ports maps the Service’s port (port: 8080) to the container’s port (targetPort: 8080).\nspec.type: NodePort exposes the application on a static port on each node in the cluster, making it accessible for local development with Minikube. In a cloud environment, you typically use a LoadBalancer.\n\n\n\n\n\nDeploy to a Cluster Using Minikube\nTo deploy this to a cluster, run Minikube with minikube start and apply the manifests using the following commands:\nkubectl apply -f k8s/deployment.yaml\nkubectl apply -f k8s/service.yaml\nAfter applying, you can verify that everything is running using kubectl get pods. You should then get a result like this:\nNAME                                    READY   STATUS    RESTARTS      AGE\nkotlin-app-deployment-744476956-bfwg4   1/1     Running   0             20s\nTo access your application, run minikube service kotlin-app-service. This command finds the service in Minikube and opens a URL in your host browser via port forwarding. The output shows an IP and port (eg http://192.168.49.2:30000). Visiting http://<minikube-ip>:30000/hello should call your Spring app and return the Hello World message.\nExtend the Kotlin App with ConfigMap\nHard-coding configuration in images forces rebuilds for simple changes and risks exposing sensitive data. Kubernetes provides ConfigMaps for non-sensitive configuration and Secrets for sensitive data, like passwords.\nTo demonstrate ConfigMaps, replace the hard-coded greeting with one that can be set through a configuration.\nTo do this, update the controller to read the message from an environment variable:\n@RestController\nclass HelloController {\n    @Value(\"\\${greeting.message:Hello}\")\n    lateinit var greetingMsg: String\n\n    @GetMapping(\"/hello\")\n    fun hello(): String = greetingMsg\n}\nThis code snippet declares a variable greetingMsg, which pulls a value from the environment or defaults to \"Hello\" if it doesn’t find the specific environment variable.\nNow, create a configmap.yaml file in the k8s folder; this sets the greeting configuration so you can change it without rebuilding the image:\n\n\n\n\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: kotlin-app-config\ndata:\n  application.properties: |\n    greeting.message=Hello from a ConfigMap!\nTo use this ConfigMap, you need to mount it as a volume into the Pod. This approach prevents configuration values from being accidentally logged in process lists and allows for configuration updates without restarting the Pod.\nAdditionally, ConfigMaps can store larger configuration files and support multiple configuration formats.\nUpdate your k8s/deployment.yaml so that it uses the new ConfigMap that you defined earlier:\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kotlin-app-deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: kotlin-app\n  template:\n    metadata:\n      labels:\n        app: kotlin-app\n    spec:\n      containers:\n      - name: kotlin-k8s-app\n        image: <your-username>/kotlin-app:v2\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - name: config-volume\n          mountPath: /app/config\n      volumes:\n      - name: config-volume\n        configMap:\n          name: kotlin-app-config\nThis manifest adds a volumes section that defines a volume named config-volume, which sources its data from the kotlin-app-config ConfigMap. It also adds a volumeMounts entry to the container specification, mounting this volume at /app/config. This setup allows Spring Boot to automatically detect and load the application.properties file from the /config directory, making it easy to manage configuration through Kubernetes.\nThe deployment also updates the image to an updated Docker image. Let’s create this image by rebuilding the application and creating a new Docker image with an updated tag (eg v2). Then push it to your registry so Kubernetes can pull the latest version:\n# 1) Rebuild the Kotlin app \n./gradlew clean build            # Gradle\n# or\nmvn clean package                # Maven\n\n# 2) Build a new Docker image with a new tag (v2)\ndocker build -t <your-username>/kotlin-app:v2 .\n\n# 3) Push the image so the cluster can pull it (skip if using Minikube's Docker daemon)\ndocker push <your-username>/kotlin-app:v2\nAfter pushing the new image, apply the new configmap.yaml and the updated deployment.yaml:\nkubectl apply -f k8s/configmap.yaml\nkubectl apply -f k8s/deployment.yaml\nConnect to a Database\nWhen your application needs to store and retrieve data, such as user accounts or business records, you need to manage persistent storage alongside your deployments. Kubernetes lets you run databases like PostgreSQL as managed Deployments, using persistent volumes for data durability and Secrets for credentials.\nLet’s walk through deploying PostgreSQL and connecting it to your application.\nTo keep your credentials out of the container and enable safe injection into Pods, you need to define a Secret. A Kubernetes Secret is like a ConfigMap but intended for confidential info (passwords, tokens). Create postgres-secret.yaml to safely store the database credentials:\napiVersion: v1\nkind: Secret\nmetadata:\n  name: postgres-secret\ntype: Opaque\nstringData:\n  POSTGRES_USER: \"postgres\"\n  POSTGRES_PASSWORD: \"mysecretpassword\"\n  POSTGRES_DB: \"greetingsdb\"\nNote: stringData is used for convenience; Kubernetes stores this as a Base64-encoded value.\nCreate deployments/postgres.yaml to run PostgreSQL and expose it with a stable DNS name:\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: postgres\n  labels:\n    app: postgres\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: postgres\n  template:\n    metadata:\n      labels:\n        app: postgres\n    spec:\n      containers:\n      - name: postgres\n        image: postgres:15\n        ports:\n        - containerPort: 5432\n        env:\n        - name: POSTGRES_DB\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: POSTGRES_DB\n        - name: POSTGRES_USER\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: POSTGRES_USER\n        - name: POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: POSTGRES_PASSWORD\n        volumeMounts:\n        - name: postgres-storage\n          mountPath: /var/lib/postgresql/data\n      volumes:\n      - name: postgres-storage\n        emptyDir: {}\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: postgres-service\nspec:\n  selector:\n    app: postgres\n  ports:\n  - port: 5432\n    targetPort: 5432\n  type: NodePort\nThis manifest does two things:\nCreates a Service named postgres-service so your application can connect to the database using a stable DNS name.\nCreates a Deployment that runs PostgreSQL, using the Secret for the password. It mounts /var/lib/postgresql/data to a volume (here, an emptyDir for simplicity). In production, you’d use a StatefulSet and a PersistentVolumeClaim to ensure data persists across Pod restarts and node failures.\n\n\n\n\n\nLet’s also update the Kotlin app to connect to a PostgreSQL database. In this example, the app returns a custom greeting with the user’s details that it pulls from the database. You can use Spring Data JPA.\nTo connect to a PostgreSQL database and use JPA, you need to add the PostgreSQL Java Database Connectivity (JDBC) driver. The PostgreSQL driver is essential because it allows your application to communicate with the database running in Kubernetes. Add this to the dependencies block in your build.gradle.kts (or pom.xml if you’re using Maven) so it’s available at compile and runtime:\nimplementation(\"org.postgresql:postgresql\")\nFor local development, the application uses H2 (which you added earlier as a dependency) as a lightweight option for testing without having to spin up a full PostgreSQL instance. The application interacts only with PostgreSQL when deployed to the Kubernetes cluster.\nCreate a file and name it User.kt. Use this to model the users table. Additionally, create a Spring Data JPA repository for database lookups:\nimport jakarta.persistence.*\nimport org.springframework.data.jpa.repository.JpaRepository\nimport org.springframework.stereotype.Repository\n\n@Entity\n@Table(name = \"users\")\nclass User(\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    val id: Long = 0,\n\n    @Column(nullable = false)\n    val name: String = \"\",\n\n    @Column(nullable = false)\n    val email: String = \"\"\n)\n\n@Repository\ninterface UserRepository : JpaRepository<User, Long> {\n    fun findByName(name: String): User?\n}\nThis snippet uses a Kotlin class to define a User entity. With Kotlin’s primary constructor syntax, you can declare mutable properties and initialize the object in a single definition, eliminating the need for boilerplate getters and setters required in Java entities. The snippet also defines a UserRepository that handles retrieving user details from the database.\nUpdate the main controller with this GetMapping to return dynamic greetings based on username:\nimport org.springframework.web.bind.annotation.PathVariable\n\n@RestController\nclass HelloController(private val userRepository: UserRepository) {\n\n    @GetMapping(\"/hello\")\n    fun hello(): String = \"Hello World\"\n\n    @GetMapping( \"/hello/{name}\")\n    fun getGreeting( @PathVariable name: String = \"world\"): String =\n        userRepository.findByName(name)\n            ?.let { \"Hello ${it.name}! Your email is ${it.email}.\" \n            ?: \"Hello $name! (User not found in database)\"\n}\nThis code injects the UserRepository into the Controller, allowing you to use it in the getGreeting method. This method returns the user’s name, along with their email, if the user exists in the database; otherwise, it outputs that the user wasn’t found. It uses Kotlin null safety features to produce a response without unsafe casts or a NullPointerException.\nNext, update the src/main/resources/application.properties file with the PostgreSQL configuration:\nspring.jpa.hibernate.ddl-auto=update\nspring.jpa.properties.hibernate.dialect=org.hibernate.dialect.PostgreSQLDialect\nThe properties file configures Spring Data JPA settings. The hibernate.ddl-auto=update property enables automatic schema updates based on the @Entity definitions. This ensures that the User table is created at runtime if it doesn’t exist in the database. The spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.PostgreSQLDialect tells hibernate to use PostgreSQL-specific queries.\nTo use the updated code, rebuild the application and Docker image with the changes, and update the Deployment to include the new environment variables as Secrets:\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kotlin-app-deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: kotlin-app\n  template:\n    metadata:\n      labels:\n        app: kotlin-app\n    spec:\n      containers:\n      - name: kotlin-k8s-app\n        image: <your-username>/kotlin-app:v3\n        ports:\n        - containerPort: 8080\n        env:\n        - name: SPRING_DATASOURCE_URL\n          value: \"jdbc:postgresql://postgres-service:5432/greetingsdb\"\n        - name: SPRING_DATASOURCE_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: POSTGRES_USER\n        - name: SPRING_DATASOURCE_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: POSTGRES_PASSWORD\nThe configuration now contains a new env section that defines the database URL, username, and password from the Secrets definition. Spring uses these variables to connect to the database.\nApply the new manifests using this command:\nkubectl apply -f k8s/postgres-secret.yaml\nkubectl apply -f k8s/postgres.yaml\nkubectl apply -f k8s/deployment.yaml\nYou can use minikube service kotlin-app-service to expose the application using an external IP address and navigate to <url>/hello/<username> to test. If the username doesn’t exist in the User table of the PostgreSQL database, you’ll get this output:\nHello <username>! (User not found in database)\nDynamic routing using Ingress\nSometimes you might want to roll out new features to a subset of users to test out how they work before a full production release, for example, during beta testing. To do this, you can have route traffic from your Kubernetes cluster to different services depending on certain rules. This is done via an Ingress. An Ingress sits at the edge of the cluster and routes HTTP traffic to Services based on rules like host, path, or headers.\nIn this example, you’ll route normal traffic to v2 of the application and route all traffic with a special header to the new v3 image. This allows you to test a new database feature on a subset of users or clients before a full, stable rollout.\nTo enable the NGINX Ingress controller in Minikube:\nminikube addons enable ingress\nCreate a new v2-application file that contains the deployment and Service for the v2 version of the app, save it to k8s/v2-app.yaml:\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kotlin-app-v2-deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: kotlin-app-v2\n  template:\n    metadata:\n      labels:\n        app: kotlin-app-v2\n    spec:\n      containers:\n        - name: kotlin-k8s-app-v2\n          image: <your-username>/kotlin-app:v2\n          ports:\n            - containerPort: 8080\n          volumeMounts:\n            - name: config-volume\n              mountPath: /app/config\n      volumes:\n        - name: config-volume\n          configMap:\n            name: kotlin-app-config\n---\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: kotlin-app-config\ndata:\n  application.properties: |\n    greeting.message=Hello from a v2 stable app!\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: kotlin-app-v2-service\nspec:\n  selector:\n    app: kotlin-app-v2\n  ports:\n    - port: 8080\n      targetPort: 8080\n  type: ClusterIP\nThe example above is similar to the Deployment and Service you set up earlier, except the Service type is now ClusterIP instead of NodePort. ClusterIP only exposes the Service within the cluster, making it accessible to other Pods but not directly from outside the cluster. In contrast, NodePort exposes the Service on a static port on each node’s IP, allowing external access. Since the Ingress handles external traffic routing, you use ClusterIP for internal communication between the Ingress and your Services.\nWith Services in place, you can add the Ingress resources. Create a new ingress file to receive traffic and direct it to the v2 version of your service, and save it as k8s/ingress.yaml:\n\n\n\n\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: kotlin-app\nspec:\n  ingressClassName: nginx\n  rules:\n  - http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: kotlin-app-v2-service\n            port:\n              number: 8080\nTo direct traffic to the v3 version of the application, you can utilize the canary annotations of the ingress controller. Create another ingress definition file and save it to k8s/ingress-canary.yaml:\n\n\n\n\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: kotlin-app-canary\n  annotations:\n    nginx.ingress.kubernetes.io/canary: \"true\"\n    nginx.ingress.kubernetes.io/canary-by-header: \"X-Client-Version\"\n    nginx.ingress.kubernetes.io/canary-by-header-value: \"v3\"\nspec:\n  ingressClassName: nginx\n  rules:\n  - http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: kotlin-app-service\n            port:\n              number: 8080\nThe canary Ingress above uses NGINX’s canary annotations to implement header-based routing. When a request includes the header X-Client-Version: v3, the Ingress controller routes it to the kotlin-app-service (your v3 Pods). All other requests without this header go to kotlin-app-v2-service (your stable v2 Pods). This pattern lets you safely test new features in production with a subset of users, such as internal testers or beta users, while the majority of traffic continues to hit the stable version.\nThe canary: \"true\" annotation tells NGINX this Ingress is a canary rule, and the canary-by-header annotations define the matching logic.\nApply the new manifests using the following commands:\nkubectl apply -f k8s/v2-app.yaml\nkubectl apply -f k8s/ingress.yaml\nkubectl apply -f k8s/ingress-canary.yaml\nTo test this out, run minikube tunnel to tunnel your minikube instance and make it available on localhost. To view our application you simply need to navigate to http://localhost/hello.\nYou can verify the routing behavior with curl. A request without the header goes to v2:\ncurl  http://127.0.0.1/hello \nThis returns “Hello from a v2 stable app!”.\nRunning the same request with the X-Client-Version header, returns a response from v3 of the application:\n$ curl -H \"X-Client-Version:v3\" http://127.0.0.1/hello\nHello World\nYou can also run the same on with /hello/{name} to verify it routes to v3 of the application:\ncurl -H \"X-Client-Version:v3\" http://127.0.0.1/hello/mike\nHello mike! (User not found in database)\nYou can find the tutorial’s full codebase on this GitHub repository. Switch between different branches to access different parts of the tutorial.\nFollow These Best Practices\n\nWhen deploying JVM-based microservices on Kubernetes, keep these practices in mind:\nConfigure Health Checks (Liveness and Readiness Probes)\nKubernetes needs to know if your application is healthy and ready to serve traffic. Health checks let Kubernetes direct traffic to healthy Pods and restart failing ones. Spring Boot Actuator provides /actuator/health/liveness and /actuator/health/readiness endpoints. Kubernetes sends HTTP requests to these endpoints, and non-2xx responses trigger container restarts.\nUse ConfigMap and Secret Manifests\nDo not hard-code environment-specific or sensitive data into your image. As you learned in this tutorial, it’s best to store non-sensitive configs (like feature flags, greeting messages) in ConfigMaps and more confidential data (passwords, tokens) in Secrets. This makes it easy to change settings without rebuilding containers.\nSet CPU/Memory Resource Limits\nKubernetes allows you to set memory and cpu requests and limits. This prevents your app from consuming unlimited resources and impacting other pods. Without limits, a runaway JVM can crash your entire node or be killed unexpectedly, so proper limits ensure cluster stability and cost control.\nConclusion\nThis tutorial showed you how to containerize and deploy a Kotlin Spring Boot application on Kubernetes. Along the way, you learned important Kubernetes fundamentals, like Pods, Deployments, Services, ConfigMaps, and Secrets.\nYou also saw why Kotlin is a good choice for server-side development, especially with Spring, because of Kotlin features, like null safety, data classes, and coroutines. If you use Java, you can introduce Kotlin gradually into existing Spring projects without rewriting your stack. Explore more on Kotlin for server-side development on their official landing page.",
        "dc:creator": "Alina Dolgikh",
        "content": "This article was written by an external contributor. Kubernetes is a container orchestration system for deploying, scaling, and managing containerized applications. If you build services on the Java virtual machine (JVM), you likely know that most microservices run on Kubernetes. Kubernetes has become the de facto standard for running containerized microservices at scale. However, Kubernetes [&#8230;]",
        "contentSnippet": "This article was written by an external contributor. Kubernetes is a container orchestration system for deploying, scaling, and managing containerized applications. If you build services on the Java virtual machine (JVM), you likely know that most microservices run on Kubernetes. Kubernetes has become the de facto standard for running containerized microservices at scale. However, Kubernetes […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=662365",
        "categories": [
          "news",
          "backend",
          "guide"
        ],
        "isoDate": "2025-12-08T13:28:13.000Z"
      }
    ]
  },
  {
    "name": "Airbnb Engineering & Data Science",
    "category": "기업",
    "posts": []
  },
  {
    "name": "PayPal Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Visual Studio Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Jessie Houghton",
        "title": "Unlocking the Power of Web with Copilot Chat’s New URL Context",
        "link": "https://devblogs.microsoft.com/visualstudio/unlocking-the-power-of-web-with-copilot-chats-new-url-context/",
        "pubDate": "Thu, 04 Dec 2025 13:00:24 +0000",
        "content:encodedSnippet": "There are many scenarios where Copilot Chat can feel limited by the built-in model training data. Maybe you want guidance on the latest web framework, documentation, or project-specific resources—but Copilot’s responses just aren’t specific enough. For developers who rely on up-to-date or esoteric answers, this gap can be a real frustration. \n\nURL Context: Bringing the web into Copilot Chat \nWith the new URL context feature, Copilot Chat can now access and use information directly from web pages you specify. By pasting a URL into your Copilot Chat prompt, you empower Copilot to pull real-time, relevant information from the source. This means more tailored responses. \n\nHow to use reference URLs in Copilot Chat \nGetting started is easy. When you need Copilot to answer using a specific web resource, simply paste the desired URL into your chat prompt. Copilot will then process the contents of that page, giving you context-aware answers that go beyond its original training. This opens the door to more personalized support. \nLimitations to keep in mind \nWhile the URL context feature is powerful, there are a few things to remember. Copilot’s ability to extract and understand content depends on the accessibility of the web page and the clarity of its information. Some sites might have authentication restrictions or have dynamic content that limit Copilot’s ability to read the web page’s content. Always review responses for accuracy and completeness, especially when referencing complex or highly technical sources. \nCheck out the new Visual Studio Hub \nStay connected with everything Visual Studio in one place! Visit the Visual Studio Hub for the latest release notes, YouTube videos, social updates, and community discussions. \nAppreciation for your feedback \nYour feedback helps us improve Visual Studio, making it an even more powerful tool for developers. We are immensely grateful for your contributions and look forward to your continued support. By sharing your thoughts, ideas, and any issues you encounter through Developer Community, you help us improve and shape the future of Visual Studio. \nThe post Unlocking the Power of Web with Copilot Chat’s New URL Context appeared first on Visual Studio Blog.",
        "dc:creator": "Jessie Houghton",
        "comments": "https://devblogs.microsoft.com/visualstudio/unlocking-the-power-of-web-with-copilot-chats-new-url-context/#comments",
        "content": "<p>There are many scenarios where Copilot Chat can feel limited by the built-in model training data. Maybe you want guidance on the latest web framework, documentation, or project-specific resources—but Copilot’s responses just aren’t specific enough. For developers who rely on up-to-date or esoteric answers, this gap can be a real frustration.  URL Context: Bringing the web into Copilot Chat  With the new URL context feature, Copilot Chat can now access [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/unlocking-the-power-of-web-with-copilot-chats-new-url-context/\">Unlocking the Power of Web with Copilot Chat’s New URL Context</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "There are many scenarios where Copilot Chat can feel limited by the built-in model training data. Maybe you want guidance on the latest web framework, documentation, or project-specific resources—but Copilot’s responses just aren’t specific enough. For developers who rely on up-to-date or esoteric answers, this gap can be a real frustration.  URL Context: Bringing the web into Copilot Chat  With the new URL context feature, Copilot Chat can now access […]\nThe post Unlocking the Power of Web with Copilot Chat’s New URL Context appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=255002",
        "categories": [
          "Visual Studio"
        ],
        "isoDate": "2025-12-04T13:00:24.000Z"
      },
      {
        "creator": "Simona Liao",
        "title": "Visual Studio November Update – Visual Studio 2026, Cloud Agent Preview, and more",
        "link": "https://devblogs.microsoft.com/visualstudio/visual-studio-november-update-visual-studio-2026-cloud-agent-preview-and-more/",
        "pubDate": "Wed, 03 Dec 2025 16:00:24 +0000",
        "content:encodedSnippet": "Visual Studio 2026 is here!\nIf you haven’t heard the news yet, we’re excited to share with you that Visual Studio 2026 is now generally available! This new version can better assist you with several performance improvements, a redesigned user experience, and a major leap in AI-driven development. Read more about it here and get started with VS 2026 today!\nBelow updates are all available in Visual Studio 2026 only. \nGitHub Cloud Agent Preview is now available in Visual Studio\nThe Cloud Agent is now in preview and ready to help you offload repetitive or time-consuming work. Enable it via the Copilot badge dropdown → Settings & Options → Coding Agent (Preview).\nNote: You’ll need to restart Visual Studio after enabling.\n Requires: A solution connected to a GitHub repo.\nOnce enabled, you can delegate tasks directly from Visual Studio—UI cleanups, refactors, doc updates, multi-file edits, and anything you want Copilot to draft so you can review later.\nWe’re actively improving this experience, and your feedback is essential. Soon, you’ll see direct PR links inside Visual Studio, so you can review agent-generated changes without breaking your flow.\nWe’re excited to help you work faster by letting the Cloud Agent handle the tedious parts while you stay focused on building and debugging the core of your project.\nCopilot Actions in your Context Menu\nWe are excited to announce that you can now interact with Copilot directly from your context menu in Visual Studio! With just one click, you can now get Copilot’s assistance with no typing required. Whether you are looking to quickly generate comments or explanations of a class, Copilot is right there when you need it.\n\nNote that “Optimize Selection” requires you to select code to trigger. Copilot will analyze the selected code and its surrounding context, offering targeted suggestions directly in the editor. Copilot will suggest improvements in performance, maintainability, reliability, and architecture.\nCopilot Intent Detection for All-In-One Search\nHave you ever forgotten the name of a file while coding, and thus couldn’t search or find it easily? The new Did You Mean feature is here to help! When you search using All-In-One Search and Copilot detects a better match than the top result – perhaps because of a typo or a fuzzy memory – it will suggest what you might have meant.\nWhen you type a search term, Copilot analyzes your input and suggests a more relevant term if it finds one that more closely matches your intent. This feature helps with whether the search results are empty or when the top result isn’t what you intended.\ndocument.createElement('video');\nhttps://devblogs.microsoft.com/visualstudio/wp-content/uploads/sites/4/2025/09/DidYouMeanVideo.mp4\n\nThank you for reading till the end! We will skip the December blog post as we are approaching the end of year and holiday season. See you soon in the January update blog post!\nThe post Visual Studio November Update – Visual Studio 2026, Cloud Agent Preview, and more appeared first on Visual Studio Blog.",
        "enclosure": {
          "url": "https://devblogs.microsoft.com/visualstudio/wp-content/uploads/sites/4/2025/09/DidYouMeanVideo.mp4",
          "length": "525367",
          "type": "video/mp4"
        },
        "dc:creator": "Simona Liao",
        "comments": "https://devblogs.microsoft.com/visualstudio/visual-studio-november-update-visual-studio-2026-cloud-agent-preview-and-more/#comments",
        "content": "<p>Visual Studio 2026 is here! If you haven’t heard the news yet, we’re excited to share with you that Visual Studio 2026 is now generally available! This new version can better assist you with several performance improvements, a redesigned user experience, and a major leap in AI-driven development. Read more about it here and get [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/visual-studio-november-update-visual-studio-2026-cloud-agent-preview-and-more/\">Visual Studio November Update – Visual Studio 2026, Cloud Agent Preview, and more</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "Visual Studio 2026 is here! If you haven’t heard the news yet, we’re excited to share with you that Visual Studio 2026 is now generally available! This new version can better assist you with several performance improvements, a redesigned user experience, and a major leap in AI-driven development. Read more about it here and get […]\nThe post Visual Studio November Update – Visual Studio 2026, Cloud Agent Preview, and more appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=255104",
        "categories": [
          "GitHub Copilot",
          "Visual Studio",
          "Visual Studio 2026"
        ],
        "isoDate": "2025-12-03T16:00:24.000Z"
      },
      {
        "creator": "Mads Kristensen",
        "title": "Why changing keyboard shortcuts in Visual Studio isn’t as simple as it seems",
        "link": "https://devblogs.microsoft.com/visualstudio/why-changing-keyboard-shortcuts-in-visual-studio-isnt-as-simple-as-it-seems/",
        "pubDate": "Wed, 03 Dec 2025 15:00:13 +0000",
        "content:encodedSnippet": "A straight look at what’s behind the keys\nWe’ve all tried unlearning a keyboard shortcut – it feels like forgetting how to breathe. Muscle memory doesn’t mess around. We wrestle with this every time someone suggest a “quick” shortcut change. It’s not just editing a keybinding but navigating a history that makes Visual Studio so customizable for developers like us.\nPicture yourself deep in code, chugging coffee, ready to close a tab. You hit Ctrl+W because Chrome, VS Code, and every other tool uses it. But in Visual Studio? You likely need Ctrl+F4, a combo straight out of the Windows 98 era. Or maybe you try commenting out a line if code with Ctrl+/, a standard elsewhere, but Visual Studio adopted it late. Why? The team isn’t clueless – every shortcut ties to years of workflows we depend on.\nLet’s walk through why that history powers Visual Studio and why changing a shortcut like Ctrl+W is such a challenge.\nOne command, multiple shortcuts\nVisual Studio lets you handle the same task with different shortcuts to match your workflow. To close a tab, you can hit Ctrl+F4, a go-to for longtime users. If you come from tools like VS Code or Chrome and prefer Ctrl+W, Visual Studio supports that too. This flexibility rocks – you stick with what you know or adopt newer standards without losing your groove.\nBut it gets tricky. Many key combos in Visual Studio already do something and reassigning one can disrupt established workflows. For example, Ctrl+W closes tabs in most tools, but in Visual Studio, it selects the current word – a shortcut coders have relied on since the 2000s. If that’s wired into your fingers, changing it could derail you. Visual Studio keeps both shortcuts, letting you use what works while supporting everyone else’s habits.\nThat ability to support multiple shortcuts is just the start of Visual Studio’s customization, though – it goes deeper with how it tailors the IDE to you.\nDeveloper profiles\nWhen you launch Visual Studio, it doesn’t throw you into a generic setup. It prompts you to choose a developer profile – General, Web, C#, C++, and others. This choice shapes your shortcuts, layout, and entire coding experience to fit how you work. Visual Studio’s history of letting developers carry over habits from other IDEs or editors ensures your shortcuts feel right from the start.\nHere’s the catch: the same command can use different shortcuts based on your profile. In the C# profile, you build a solution with F6. In the General profile, you hit Ctrl+Shift+B. It’s not chaos – it stems from years of developers like us telling the team what fits our work.\nProfiles aren’t the only way Visual Studio adapts to your coding style, though – there’s another layer that makes switching tools even smoother.\nKeyboard schemes\nTo make jumping between tools less jarring, Visual Studio offers keyboard schemes – like VS Code’s shortcuts or ReSharper’s keymap. It’s like plugging your own keyboard into a shared machine. These schemes build on Visual Studio’s history of supporting diverse coding styles, letting you dive in without starting from scratch.\n\nBut with all this customization, how do we know what shortcuts you’re actually using and why? That’s where things get murky.\nThe intent behind the shortcut\nWhen we consider changing a shortcut, we dig into telemetry to see how you use Visual Studio. It reveals which shortcuts you hit, how often, and when. But here’s the tough part: it doesn’t explain why. If you press Ctrl+W, do you select a word, as Visual Studio intends, or expect to close a tab because VS Code or Chrome does that? We see the keypresses, but your intent remains a mystery.\nThat’s where the art lies. Some of us rely on Ctrl+W for its original role; others follow muscle memory from another tool. Without knowing who’s who, changing a shortcut risk breaking someone’s workflow.\nThis uncertainty complicates things further when you factor in how Visual Studio organizes shortcuts behind the scenes.\nScopes\nVisual Studio’s commanding system has a killer feature: scoped shortcuts. Every shortcut applies to a specific scope, so you can bind the same shortcut to different commands in different contexts. To close a tab with Ctrl+W, we register it in the Global scope. But any scope can override that. For example, Ctrl+W selects the current word in the Text Editor scope. The active scope depends on where your focus is – the editor, Solution Explorer, or another tool window.\nTo remap Ctrl+W to close tabs, we register it in the Global scope and ensure no other scope overrides it. This setup gives you flexibility but adds complexity when changing shortcuts, as we must account for every scope’s bindings.\nAnd just when you think you’ve got a handle on that, another wrinkle shows up in how some shortcuts are structured.\nSequenced shortcuts\nVisual Studio supports sequenced shortcuts, where you press multiple keys to trigger a command. For example, in the Text Editor scope, Ctrl+E, Ctrl+W toggles word wrap. Many sequenced shortcuts start with Ctrl+E, followed by another key. If we bind a command to just Ctrl+E, it fires immediately, cutting off any chance for the second key in the sequence to register. This breaks all those Ctrl+E-based sequences, as Visual Studio stops listening for additional keypresses once it detects Ctrl+E.\nThis means we must carefully check existing sequences before assigning single-key shortcuts to avoid breaking workflows that rely on multi-key combos.\nWith all these layers – multiple shortcuts, profiles, schemes, scopes, sequences, and unknown user intent – changing a shortcut becomes a high-stakes juggling act.\nThe balancing act\nEvery shortcut in Visual Studio connects to our coding habits – late-night bug hunts, team workflows we’ve refined for years. When we add or change a shortcut, we don’t just pick a new key. We examine the entire keyboard, identify what’s in use, and sometimes shuffle other shortcuts to make room. For instance, if we set Ctrl+W to close tabs to align with modern tools, we might need to reassign “Select Current Word” to avoid leaving anyone stranded. It’s a delicate balance to keep every developer’s flow intact, and that history of customization makes Visual Studio ours.\nCtrl+W in Visual Studio 2026\nThis walked you through the process we followed to map Ctrl+W to close the current tab in Visual Studio 2026. For C# profile users, we held off on this change to avoid disrupting existing workflows, especially given potential conflicts with sequenced shortcuts. If you’re using the C# profile and want Ctrl+W to close tabs, you can easily set it up yourself in the keybinding settings.\nWhat’s next?\nSo, what shortcuts do you want to see next? Got a key combo you need or one that’s driving you nuts? Throw it in the comments – the team’s reading, and your input could help steer where Visual Studio goes from here.\nResources\nKeyboard Hero: An extension that teaches you the shortcuts you didn’t use\nVideo: How do keyboard shortcuts work?\nIdentify and customize keyboard shortcuts in Visual Studio\nThe post Why changing keyboard shortcuts in Visual Studio isn’t as simple as it seems appeared first on Visual Studio Blog.",
        "dc:creator": "Mads Kristensen",
        "comments": "https://devblogs.microsoft.com/visualstudio/why-changing-keyboard-shortcuts-in-visual-studio-isnt-as-simple-as-it-seems/#comments",
        "content": "<p>A straight look at what’s behind the keys We’ve all tried unlearning a keyboard shortcut &#8211; it feels like forgetting how to breathe. Muscle memory doesn’t mess around. We wrestle with this every time someone suggest a “quick” shortcut change. It’s not just editing a keybinding but navigating a history that makes Visual Studio so [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/why-changing-keyboard-shortcuts-in-visual-studio-isnt-as-simple-as-it-seems/\">Why changing keyboard shortcuts in Visual Studio isn’t as simple as it seems</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "A straight look at what’s behind the keys We’ve all tried unlearning a keyboard shortcut – it feels like forgetting how to breathe. Muscle memory doesn’t mess around. We wrestle with this every time someone suggest a “quick” shortcut change. It’s not just editing a keybinding but navigating a history that makes Visual Studio so […]\nThe post Why changing keyboard shortcuts in Visual Studio isn’t as simple as it seems appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=255101",
        "categories": [
          "Visual Studio",
          "Keyboard Shortcuts",
          "Visual Studio 2026"
        ],
        "isoDate": "2025-12-03T15:00:13.000Z"
      }
    ]
  },
  {
    "name": "Joshua",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권재명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김석기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강대명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권정혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "줌구",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수보",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김시은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "곽민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김범진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민서",
    "category": "개인",
    "posts": []
  },
  {
    "name": "I am not Okay",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권창현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권기호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강태욱",
    "category": "개인",
    "posts": [
      {
        "title": "독일 뮌헨 공과대학교(TUM) 세계 최대 규모 오픈소스 3D 건물 지도 데이터셋 글로벌 빌딩 아틀라스 기술 개발 이야기",
        "link": "http://daddynkidsmakers.blogspot.com/2025/12/tum-3d.html",
        "pubDate": "2025-12-06T05:17:00.000Z",
        "author": "Daddy Maker",
        "content": "이 글은 독일 뮌헨 공과대학교(TUM) 연구팀이 개발하여 공개한 세계 최대 규모의 3D 건물 지도 데이터셋인 글로벌 빌딩 아틀라스(Global Building Atlas) 프로젝트에 대해 설명한다. 특히, 인공지능과 위성 영상 분석 기술을 결합하여 전 세계에 존재하는 건물을 3차원 모델로 구현한 방법을 기술적 관점에서 이야기나눈다.<div><br /><div style=\"text-align: center;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEg3LbJnUJllU1t1Nxn-3rBW0LlrcrltG90ragCgGQ9DwlVOC5hkJkvepKgds97V0iQeW2JZAMfpxI94O2WXIIr6JmuzlNVV1hlCf4tnIIbjYvysKbc8Kxy9U5s6Y-htmLMNM1jwaH3lHi2WF1l0azd13oZUVXz4fPxb_GnPGhwvA-YWCcfYq1D_1NDWLD9G\" style=\"margin-left: 1em; margin-right: 1em;\"><span style=\"color: black;\"><img alt=\"\" data-original-height=\"853\" data-original-width=\"1280\" height=\"266\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEg3LbJnUJllU1t1Nxn-3rBW0LlrcrltG90ragCgGQ9DwlVOC5hkJkvepKgds97V0iQeW2JZAMfpxI94O2WXIIr6JmuzlNVV1hlCf4tnIIbjYvysKbc8Kxy9U5s6Y-htmLMNM1jwaH3lHi2WF1l0azd13oZUVXz4fPxb_GnPGhwvA-YWCcfYq1D_1NDWLD9G=w400-h266\" width=\"400\" /></span></a></div></div><div style=\"text-align: center;\"><a href=\"https://gizmodo.com/literally-a-map-showing-all-the-buildings-in-the-world-2000694696?fbclid=IwY2xjawOgcRRleHRuA2FlbQIxMQBzcnRjBmFwcF9pZBAyMjIwMzkxNzg4MjAwODkyAAEeLTTZi2UIbomLy1jhGXnSRsWsBQeH2PN-FUn78IJvH8hX0omf6Z4R1AFzMKg_aem_8suI2e-Y0eY-u6yDWIBaiQ\"><span style=\"color: black;\">Literally a Map Showing All the Buildings in the World</span></a></div><br />이 결과는 오픈소스로 공개되었으며, 기존에 가장 방대하다고 알려진 데이터셋이 포함하던 약 17억 개의 건물 수치를 대폭 상회하는 규모로 개발되었다. 그동안 디지털 지도 데이터에서 소외되었던 아프리카, 남미, 아시아의 농촌 지역 건물들까지 정밀하게 포착해냈다는 점에서 기술적 진보를 보여준다.<br /><br /><b>개발과정<br /></b>지도의 기반이 된 데이터는 주로 2019년에 촬영된 플래닛스코프(PlanetScope) 위성 이미지를 활용하였으며, 연구팀은 이를 통해 각 건물의 2D 바닥 면적뿐만 아니라 높이 정보까지 정밀하게 추출했다. 이 지도가 제공하는 높이 데이터의 해상도는 3x3미터 수준으로, 기존의 글로벌 건물 높이 데이터셋들이 주로 90미터 해상도에 그쳤던 것과 비교하면 약 30배 이상 정밀도가 향상된 수치이다. 제공되는 데이터는 건물의 대략적인 형태와 높이를 단순화하여 표현하는 LoD1(Level of Detail 1) 수준의 3D 모델 형식을 따르고 있어, 전 지구적 규모의 방대한 데이터를 다루면서도 활용성을 확보했다.<br /><br /><div>이 연구는 기존 데이터셋이 가진 커버리지의 한계와 3D 정보의 부재를 해결하기 위해 진행되었으며, 전 세계 약 27억 5천만 개의 건물을 포함하는 방대한 규모의 데이터를 구축하였다. 이는 기존의 가장 포괄적인 데이터베이스보다 10억 개 이상 많은 수치로, 그동안 데이터상에서 누락되었던 전 세계 건물의 약 40% 이상을 메우는 성과이다.</div><div><br /></div><div>연구팀은 이 데이터셋 구축을 위해 플래닛스코프(PlanetScope) 위성 이미지만을 사용하는 머신러닝 기반 파이프라인을 개발했다.&nbsp; 이 과정은 크게 건물 폴리곤 생성과 높이 추정의 두 단계로 나뉘며, 기존의 오픈소스 건물 데이터(OpenStreetMap, Google, Microsoft 등)와 자체 생성한 데이터를 '품질 기반 융합 전략'을 통해 결합하여 데이터의 완성도를 극대화했다. 이를 통해 완성된 'GBA-Height'는 3x3미터의 공간 해상도를 제공하는데, 이는 기존 글로벌 제품들이 제공하던 90미터 해상도보다 약 30배 더 정밀한 수준이며 이를 통해 지역 및 전 지구 규모에서 신뢰할 수 있는 건물 부피 분석이 가능해졌다.</div><div><br /></div><div>또한 연구팀은 건물 높이 정보를 포함한 'GBA-LoD1' 모델을 생성하여 약 26억 8천만 건의 건물 인스턴스를 구현했으며, 이는 전체의 97%에 달하는 높은 완성도를 보인다.&nbsp; 높이 추정의 정확도를 나타내는 RMSE(평균제곱근오차)는 대륙별로 1.5미터에서 8.9미터 사이로 나타났으며, 특히 오세아니아와 유럽에서 높은 정확도를 보였다. 데이터 분석 결과, 아시아가 건물 수와 총 부피 면에서 압도적인 비중을 차지하는 반면, 아프리카는 건물 수는 많으나 총 부피가 작아 소규모 또는 비공식 건물이 다수 분포함을 시사했다.&nbsp;</div><div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEgk1LKZ-pPsT2tVc3RUer0MgUyC4v52_JV7NgA2qDgNFM21u6i2nQa0psHSk-yM_Uup0FJQcRxG26T7p8m_0aYMCmJyk5Lp6yrXVKBRmS5MRjTPEWugd1iPoKKF5tu-DPD73HA4rnTl-foBmQMWnqo92xtlj7BIiY7IK_AcHoBhmcoCmLJy6mMsT8P0PPvR\" style=\"margin-left: 1em; margin-right: 1em;\"></a><div class=\"separator\" style=\"clear: both; text-align: center;\"><span style=\"margin-left: 1em; margin-right: 1em;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEgCfedMIuDuWPxMR7P48OjfbThuQtCEKd7K1Ulp85HeTruas_gm90od5Dwo5dITgj4kvLOD5cfetravIMDiJXDo3Q4lvfE9g7RwLwMIKPWMzpOe_vpbUM9GLMyc9goyUmQxyIr-HSdNdWQxvknoYDc4SfLJhTkXEakwsrpma6rFt42632ValQKI5DE0MjYy\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"1189\" data-original-width=\"1258\" height=\"219\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEgCfedMIuDuWPxMR7P48OjfbThuQtCEKd7K1Ulp85HeTruas_gm90od5Dwo5dITgj4kvLOD5cfetravIMDiJXDo3Q4lvfE9g7RwLwMIKPWMzpOe_vpbUM9GLMyc9goyUmQxyIr-HSdNdWQxvknoYDc4SfLJhTkXEakwsrpma6rFt42632ValQKI5DE0MjYy=w232-h219\" width=\"232\" /></a></span><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEih2uRYGE2ucx_F-h7IXbAm8dmqaKIpPY3c4Jj2c6GTLB_7RGzJgYNllZDBPkhU43TPUr1BS_bzHqNj9PxQx4nRN-SwpahvaIY2fLbfKOVeIU2T5YXjsFakyW417Q2eCPeeYcth2je_S3mYO1qwF2-W4DuJtQKm-TUwaa4yGT_QbXXKMs4yzSJo4z2BnPQd\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"1213\" data-original-width=\"1258\" height=\"219\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEih2uRYGE2ucx_F-h7IXbAm8dmqaKIpPY3c4Jj2c6GTLB_7RGzJgYNllZDBPkhU43TPUr1BS_bzHqNj9PxQx4nRN-SwpahvaIY2fLbfKOVeIU2T5YXjsFakyW417Q2eCPeeYcth2je_S3mYO1qwF2-W4DuJtQKm-TUwaa4yGT_QbXXKMs4yzSJo4z2BnPQd=w227-h219\" width=\"227\" /></a></div></div><div class=\"separator\" style=\"clear: both; text-align: center;\">공개된&nbsp;<a href=\"https://tubvsig-so2sat-vm1.srv.mwn.de/\"><span style=\"color: black;\">GlobalBuildingAtlas LoD1</span></a>&nbsp;웹 서비스(선릉역, 뉴욕 근처 생성된 3D건물모델)</div><br /></div><div><b>AI 모델 개발 접근법</b></div><div><div>인공지능 모델 개발 및 활용 관점에서 본 GlobalBuildingAtlas(GBA) 프로젝트는 3미터 해상도의 단일 시점(Monocular) 위성 영상인 PlanetScope 데이터를 입력으로 받아 전 지구적 규모의 3D 건물 모델을 생성하는 파이프라인을 구축했다는 점에서 기술적 의미가 있다. 전체 시스템은 크게 2D 건물 폴리곤 생성을 위한 의미론적 분할(Semantic Segmentation) 네트워크와 3D 높이 추정을 위한 단안 높이 추정(Monocular Height Estimation) 네트워크로 이원화되어 설계되었다.</div><div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEgEwnCpFsrz9NR4xbd72Kzomz-2mUAG8eyGAH6s0Yv7TNNnKc4KC-X2Wgvx_h2Lb2k9H5NAobFznXm6Lf7DMYFpyNUASCig4ojQDsQ31POeAMBBqV4qhDuv4DfnenyQ9I5BHvi4Po4MOzG94U7M_hct18M6plTRWzDi6fK3A_4iIvAUoAHIw1ju7aMt9mU_\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"877\" data-original-width=\"2482\" height=\"211\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEgEwnCpFsrz9NR4xbd72Kzomz-2mUAG8eyGAH6s0Yv7TNNnKc4KC-X2Wgvx_h2Lb2k9H5NAobFznXm6Lf7DMYFpyNUASCig4ojQDsQ31POeAMBBqV4qhDuv4DfnenyQ9I5BHvi4Po4MOzG94U7M_hct18M6plTRWzDi6fK3A_4iIvAUoAHIw1ju7aMt9mU_=w596-h211\" width=\"596\" /></a></div><br /></div><div>2D 건물 폴리곤 생성 모델의 경우, 연구팀은 UPerNet(Unified Perceptual Parsing Network) 아키텍처를 기반으로 하되 백본(Backbone)으로 ConvNeXt-Tiny를 사용했다.&nbsp; 모델의 성능을 높이기 위해 '추출(Extraction)'과 '정규화(Regularization)'라는 두 단계의 네트워크를 직렬로 구성한 점이 특징이다. 첫 번째 네트워크가 위성 영상에서 1차적인 이진 마스크를 생성하면, 동일한 아키텍처를 가진 두 번째 정규화 네트워크가 이를 입력받아 노이즈를 제거하고 건물 경계를 다듬는다. 특히 정규화 네트워크 학습 시에는 깨끗한 폴리곤 마스크에 인위적인 노이즈를 주입한 것을 입력 데이터로 사용하여, 모델이 거친 마스크를 정제된 형태로 복원하는 일종의 디노이징(Denoising) 기능을 수행하도록 훈련시켰다.</div><div><br /></div><div>3D 높이 추정 모델은 HTC-DC Net(Hybrid Transformer-CNN with Dynamic Classification)을 채택했다. 이는 CNN 계열인 EfficientNet-B5를 백본으로 사용하여 이미지의 특징을 추출하고, 비전 트랜스포머(ViT) 인코더를 결합하여 지역적 특징과 전역적 특징 간의 관계를 학습하는 하이브리드 구조이다. 높이 예측 방식으로는 단순한 회귀(Regression) 대신 '분류-회귀(Classification-Regression)' 패러다임을 적용했다. 이는 높이 범위를 먼저 구간별로 분류(Classification)한 뒤, 해당 구간 내에서 미세 값을 회귀로 조정하는 방식으로, 이를 통해 예측의 안정성을 높였다. 학습 데이터로는 전 세계 168개 도시의 항공 LiDAR 데이터에서 추출한 정규화된 디지털 표면 모델(nDSM)을 정답 레이블(Ground Truth)로 활용했다.</div><div><br /></div><div>추론(Inference) 및 배포 단계에서는 모델 예측의 불확실성(Uncertainty)을 정량화하기 위해 테스트 시간 증강(TTA, Test Time Augmentation) 기법을 도입했다. 대용량 위성 영상을 처리할 때 슬라이딩 윈도우 방식을 적용하여 겹치는 영역에 대해 픽셀당 최대 4번의 예측을 수행하고, 이 결과값들의 분산을 계산하여 데이터의 신뢰도 지표로 삼았다. 이러한 딥러닝 파이프라인은 기존 오픈소스 데이터가 커버하지 못하는 지역의 데이터를 생성하는 데 핵심적인 역할을 했으나, 아프리카 등 학습 데이터(LiDAR)가 전무한 지역에 대해서는 도메인 적응(Domain Adaptation)의 한계가 존재함을 명시하고 있다.</div></div><div><br /></div><div><b>기술 연구 및 개발 의미</b></div><div>이 연구는 단순한 데이터 구축을 넘어 유엔의 지속가능발전목표(SDG) 11번, 특히 토지 소비율과 인구 증가율의 비율을 모니터링하는 데 있어 단순 면적보다 '건물 부피' 기반 지표가 도시의 개발 상태와 인구 밀도를 더 정확하게 반영함을 입증했다. 1인당 건축 부피와 GDP의 상관관계를 분석한 결과, 부피 기반 지표가 경제 발전 수준을 더 잘 설명하는 것으로 나타났다.&nbsp;</div><div><br /></div><div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEhWUoZpW690P19-H54lkC2r0ZGgZoFBROyrFle6lLFp-q1JyfRlY2fLu4mTXhCD625nC0TDQ160TEWzCrEuE8Cn0Ij-MK4isxGJDtYGO0nl7ly6MLuK349uuB5yNih_Kdh4hcVigFtjOcFC-cHGeRdWY0yzLX0xSWPC-PJf-ZCs46QwSUj3vUNr8Nc5khOo\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"268\" data-original-width=\"500\" height=\"214\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEhWUoZpW690P19-H54lkC2r0ZGgZoFBROyrFle6lLFp-q1JyfRlY2fLu4mTXhCD625nC0TDQ160TEWzCrEuE8Cn0Ij-MK4isxGJDtYGO0nl7ly6MLuK349uuB5yNih_Kdh4hcVigFtjOcFC-cHGeRdWY0yzLX0xSWPC-PJf-ZCs46QwSUj3vUNr8Nc5khOo\" width=\"400\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\">상관관계 분석 결과</div><br /></div><div>이러한 고해상도 3D 데이터의 공개는 도시 계획, 재난 위험 관리, 기후 변화 대응 연구 분야에 즉각적인 활용이 가능하다. 구체적으로는 홍수나 지진 발생 시 피해 규모를 건물의 높이와 부피에 기반해 정확하게 시뮬레이션하거나, 도시의 건물 밀도와 부피를 분석하여 에너지 소비 효율을 계산하고 인구 과밀 지역의 주거 환경을 파악하는 기초 자료로 쓰일 수 있다. 해당 연구의 방법론과 데이터셋 구축 과정에 대한 상세한 내용은 과학 저널인 <a href=\"https://essd.copernicus.org/articles/17/6647/2025/\">Earth System Science Data</a>에 게재되어 학술적 검증을 마쳤으며, 연구팀은 이 데이터를 오픈 소스로 공개하여 전 세계 연구자와 정책 입안자들이 자유롭게 활용할 수 있도록 했다.</div><div style=\"text-align: center;\"><img alt=\"\" data-original-height=\"1186\" data-original-width=\"1280\" height=\"371\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEjkxph-sM3vjMj4mkyPkU2WaMWyW2rOMXq0I4xuduoDQ3PVASnPhET5d45bNMarvVYsVvhYThxP5d1Y4sx62po5-PbEJ6kG4DxhJngfUkbpZCxVzxXrb1jqi-NRV2db6a8GoF4fvhUt9m1Qh-KuqvcIYEz7YDJ9m8lcxfmbizJdsH7oyHcqimdUD95ldCUr=w400-h371\" style=\"color: #0000ee;\" width=\"400\" /></div><div><br /></div><div><b>마무리</b></div><div>논문의 주 저자들을 보면 알겠지만, 모두 중국인이다(요즘 놀랍지도 않은...). 논문은 매우 기술적이고, AI 사용 접근 방법은 똑똑하다. 글로벌 연구 분야에서 이런 상황들이 최근 몇 년 사이 크게 많아지고 있다. 이들이 접근한 방법들을 보고 있자면 여러가지 생각이 든다. 사실, 국내 연구 학계(산학연 포함)에서 이렇게 대규모의 데이터셋 수집, 구축, 기술 개발, 성능 분석, 연구 과정의 투명한? 오픈소스 공개, 여러 저자들 간의 협력적 연구를 통한 시너지 효과를 발생하는 경우는 매우 드물다. 좋은 연구 결과를 만든 것은 연구자들의 열정과 노력도 중요하겠지만 연구 핵심기술 개발에 대한 선택과 집중이 가능한 연구 환경이 전제 되어야 한다. 이런 환경의 연구기관 인프라는 참 부럽다는 생각이다.</div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEi19Uein0S_qR4PJ7Gs9GY3j0y2B6uOKUgBRXUXVtSLiPLAXfX-p0OUliiM7cWc6MfnQLq0HEmIM_ePk0hwnJ4syhUhWrbr2zixmTR1kVU045MN64p94aCJAm7JdA7sKzKfbta6qv9GVbsLpjIPMOr8uA84u8l2_Lz3U7BFX_0BtP2DTRo0mckoUD7huMQH\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"880\" data-original-width=\"1105\" height=\"240\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEi19Uein0S_qR4PJ7Gs9GY3j0y2B6uOKUgBRXUXVtSLiPLAXfX-p0OUliiM7cWc6MfnQLq0HEmIM_ePk0hwnJ4syhUhWrbr2zixmTR1kVU045MN64p94aCJAm7JdA7sKzKfbta6qv9GVbsLpjIPMOr8uA84u8l2_Lz3U7BFX_0BtP2DTRo0mckoUD7huMQH\" width=\"301\" /></a></div><br /><!----><div><b>레퍼런스</b></div><div><ul style=\"text-align: left;\"><li><a href=\"https://gizmodo.com/literally-a-map-showing-all-the-buildings-in-the-world-2000694696?fbclid=IwY2xjawOgcRRleHRuA2FlbQIxMQBzcnRjBmFwcF9pZBAyMjIwMzkxNzg4MjAwODkyAAEeLTTZi2UIbomLy1jhGXnSRsWsBQeH2PN-FUn78IJvH8hX0omf6Z4R1AFzMKg_aem_8suI2e-Y0eY-u6yDWIBaiQ\"><span style=\"color: black;\">Literally a Map Showing All the Buildings in the World</span></a></li><li><a href=\"https://github.com/zhu-xlab/GlobalBuildingAtlas\"><span style=\"color: black;\">zhu-xlab/GlobalBuildingAtlas</span></a></li><li><a href=\"https://essd.copernicus.org/articles/17/6647/2025/\"><span style=\"color: black;\">ESSD - GlobalBuildingAtlas: an open global and complete dataset of building polygons, heights and LoD1 3D models</span></a></li></ul></div></div>",
        "contentSnippet": "이 글은 독일 뮌헨 공과대학교(TUM) 연구팀이 개발하여 공개한 세계 최대 규모의 3D 건물 지도 데이터셋인 글로벌 빌딩 아틀라스(Global Building Atlas) 프로젝트에 대해 설명한다. 특히, 인공지능과 위성 영상 분석 기술을 결합하여 전 세계에 존재하는 건물을 3차원 모델로 구현한 방법을 기술적 관점에서 이야기나눈다.\n\n\n\nLiterally a Map Showing All the Buildings in the World\n이 결과는 오픈소스로 공개되었으며, 기존에 가장 방대하다고 알려진 데이터셋이 포함하던 약 17억 개의 건물 수치를 대폭 상회하는 규모로 개발되었다. 그동안 디지털 지도 데이터에서 소외되었던 아프리카, 남미, 아시아의 농촌 지역 건물들까지 정밀하게 포착해냈다는 점에서 기술적 진보를 보여준다.\n개발과정\n지도의 기반이 된 데이터는 주로 2019년에 촬영된 플래닛스코프(PlanetScope) 위성 이미지를 활용하였으며, 연구팀은 이를 통해 각 건물의 2D 바닥 면적뿐만 아니라 높이 정보까지 정밀하게 추출했다. 이 지도가 제공하는 높이 데이터의 해상도는 3x3미터 수준으로, 기존의 글로벌 건물 높이 데이터셋들이 주로 90미터 해상도에 그쳤던 것과 비교하면 약 30배 이상 정밀도가 향상된 수치이다. 제공되는 데이터는 건물의 대략적인 형태와 높이를 단순화하여 표현하는 LoD1(Level of Detail 1) 수준의 3D 모델 형식을 따르고 있어, 전 지구적 규모의 방대한 데이터를 다루면서도 활용성을 확보했다.\n\n이 연구는 기존 데이터셋이 가진 커버리지의 한계와 3D 정보의 부재를 해결하기 위해 진행되었으며, 전 세계 약 27억 5천만 개의 건물을 포함하는 방대한 규모의 데이터를 구축하였다. 이는 기존의 가장 포괄적인 데이터베이스보다 10억 개 이상 많은 수치로, 그동안 데이터상에서 누락되었던 전 세계 건물의 약 40% 이상을 메우는 성과이다.\n\n\n연구팀은 이 데이터셋 구축을 위해 플래닛스코프(PlanetScope) 위성 이미지만을 사용하는 머신러닝 기반 파이프라인을 개발했다.  이 과정은 크게 건물 폴리곤 생성과 높이 추정의 두 단계로 나뉘며, 기존의 오픈소스 건물 데이터(OpenStreetMap, Google, Microsoft 등)와 자체 생성한 데이터를 '품질 기반 융합 전략'을 통해 결합하여 데이터의 완성도를 극대화했다. 이를 통해 완성된 'GBA-Height'는 3x3미터의 공간 해상도를 제공하는데, 이는 기존 글로벌 제품들이 제공하던 90미터 해상도보다 약 30배 더 정밀한 수준이며 이를 통해 지역 및 전 지구 규모에서 신뢰할 수 있는 건물 부피 분석이 가능해졌다.\n\n\n또한 연구팀은 건물 높이 정보를 포함한 'GBA-LoD1' 모델을 생성하여 약 26억 8천만 건의 건물 인스턴스를 구현했으며, 이는 전체의 97%에 달하는 높은 완성도를 보인다.  높이 추정의 정확도를 나타내는 RMSE(평균제곱근오차)는 대륙별로 1.5미터에서 8.9미터 사이로 나타났으며, 특히 오세아니아와 유럽에서 높은 정확도를 보였다. 데이터 분석 결과, 아시아가 건물 수와 총 부피 면에서 압도적인 비중을 차지하는 반면, 아프리카는 건물 수는 많으나 총 부피가 작아 소규모 또는 비공식 건물이 다수 분포함을 시사했다. \n\n\n\n\n공개된 GlobalBuildingAtlas LoD1 웹 서비스(선릉역, 뉴욕 근처 생성된 3D건물모델)\n\nAI 모델 개발 접근법\n\n인공지능 모델 개발 및 활용 관점에서 본 GlobalBuildingAtlas(GBA) 프로젝트는 3미터 해상도의 단일 시점(Monocular) 위성 영상인 PlanetScope 데이터를 입력으로 받아 전 지구적 규모의 3D 건물 모델을 생성하는 파이프라인을 구축했다는 점에서 기술적 의미가 있다. 전체 시스템은 크게 2D 건물 폴리곤 생성을 위한 의미론적 분할(Semantic Segmentation) 네트워크와 3D 높이 추정을 위한 단안 높이 추정(Monocular Height Estimation) 네트워크로 이원화되어 설계되었다.\n\n\n\n2D 건물 폴리곤 생성 모델의 경우, 연구팀은 UPerNet(Unified Perceptual Parsing Network) 아키텍처를 기반으로 하되 백본(Backbone)으로 ConvNeXt-Tiny를 사용했다.  모델의 성능을 높이기 위해 '추출(Extraction)'과 '정규화(Regularization)'라는 두 단계의 네트워크를 직렬로 구성한 점이 특징이다. 첫 번째 네트워크가 위성 영상에서 1차적인 이진 마스크를 생성하면, 동일한 아키텍처를 가진 두 번째 정규화 네트워크가 이를 입력받아 노이즈를 제거하고 건물 경계를 다듬는다. 특히 정규화 네트워크 학습 시에는 깨끗한 폴리곤 마스크에 인위적인 노이즈를 주입한 것을 입력 데이터로 사용하여, 모델이 거친 마스크를 정제된 형태로 복원하는 일종의 디노이징(Denoising) 기능을 수행하도록 훈련시켰다.\n\n\n3D 높이 추정 모델은 HTC-DC Net(Hybrid Transformer-CNN with Dynamic Classification)을 채택했다. 이는 CNN 계열인 EfficientNet-B5를 백본으로 사용하여 이미지의 특징을 추출하고, 비전 트랜스포머(ViT) 인코더를 결합하여 지역적 특징과 전역적 특징 간의 관계를 학습하는 하이브리드 구조이다. 높이 예측 방식으로는 단순한 회귀(Regression) 대신 '분류-회귀(Classification-Regression)' 패러다임을 적용했다. 이는 높이 범위를 먼저 구간별로 분류(Classification)한 뒤, 해당 구간 내에서 미세 값을 회귀로 조정하는 방식으로, 이를 통해 예측의 안정성을 높였다. 학습 데이터로는 전 세계 168개 도시의 항공 LiDAR 데이터에서 추출한 정규화된 디지털 표면 모델(nDSM)을 정답 레이블(Ground Truth)로 활용했다.\n\n\n추론(Inference) 및 배포 단계에서는 모델 예측의 불확실성(Uncertainty)을 정량화하기 위해 테스트 시간 증강(TTA, Test Time Augmentation) 기법을 도입했다. 대용량 위성 영상을 처리할 때 슬라이딩 윈도우 방식을 적용하여 겹치는 영역에 대해 픽셀당 최대 4번의 예측을 수행하고, 이 결과값들의 분산을 계산하여 데이터의 신뢰도 지표로 삼았다. 이러한 딥러닝 파이프라인은 기존 오픈소스 데이터가 커버하지 못하는 지역의 데이터를 생성하는 데 핵심적인 역할을 했으나, 아프리카 등 학습 데이터(LiDAR)가 전무한 지역에 대해서는 도메인 적응(Domain Adaptation)의 한계가 존재함을 명시하고 있다.\n\n\n기술 연구 및 개발 의미\n이 연구는 단순한 데이터 구축을 넘어 유엔의 지속가능발전목표(SDG) 11번, 특히 토지 소비율과 인구 증가율의 비율을 모니터링하는 데 있어 단순 면적보다 '건물 부피' 기반 지표가 도시의 개발 상태와 인구 밀도를 더 정확하게 반영함을 입증했다. 1인당 건축 부피와 GDP의 상관관계를 분석한 결과, 부피 기반 지표가 경제 발전 수준을 더 잘 설명하는 것으로 나타났다. \n\n\n\n상관관계 분석 결과\n\n이러한 고해상도 3D 데이터의 공개는 도시 계획, 재난 위험 관리, 기후 변화 대응 연구 분야에 즉각적인 활용이 가능하다. 구체적으로는 홍수나 지진 발생 시 피해 규모를 건물의 높이와 부피에 기반해 정확하게 시뮬레이션하거나, 도시의 건물 밀도와 부피를 분석하여 에너지 소비 효율을 계산하고 인구 과밀 지역의 주거 환경을 파악하는 기초 자료로 쓰일 수 있다. 해당 연구의 방법론과 데이터셋 구축 과정에 대한 상세한 내용은 과학 저널인 Earth System Science Data에 게재되어 학술적 검증을 마쳤으며, 연구팀은 이 데이터를 오픈 소스로 공개하여 전 세계 연구자와 정책 입안자들이 자유롭게 활용할 수 있도록 했다.\n\n\n\n마무리\n논문의 주 저자들을 보면 알겠지만, 모두 중국인이다(요즘 놀랍지도 않은...). 논문은 매우 기술적이고, AI 사용 접근 방법은 똑똑하다. 글로벌 연구 분야에서 이런 상황들이 최근 몇 년 사이 크게 많아지고 있다. 이들이 접근한 방법들을 보고 있자면 여러가지 생각이 든다. 사실, 국내 연구 학계(산학연 포함)에서 이렇게 대규모의 데이터셋 수집, 구축, 기술 개발, 성능 분석, 연구 과정의 투명한? 오픈소스 공개, 여러 저자들 간의 협력적 연구를 통한 시너지 효과를 발생하는 경우는 매우 드물다. 좋은 연구 결과를 만든 것은 연구자들의 열정과 노력도 중요하겠지만 연구 핵심기술 개발에 대한 선택과 집중이 가능한 연구 환경이 전제 되어야 한다. 이런 환경의 연구기관 인프라는 참 부럽다는 생각이다.\n\n\n레퍼런스\n\nLiterally a Map Showing All the Buildings in the World\nzhu-xlab/GlobalBuildingAtlas\nESSD - GlobalBuildingAtlas: an open global and complete dataset of building polygons, heights and LoD1 3D models",
        "id": "tag:blogger.com,1999:blog-5201956450461596914.post-1347203566861704188",
        "isoDate": "2025-12-06T05:17:00.000Z"
      }
    ]
  },
  {
    "name": "권용진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김승호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for boyism Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성준의 린스타트업과 디자인씽킹",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권혁우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김준형",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강동혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고종범",
    "category": "개인",
    "posts": []
  },
  {
    "name": "cheese10yun",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구자철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "FSS",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권동준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김용일",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도균",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김동우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권윤학",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김만수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "엘키",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김슬기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김광현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강명훈",
    "category": "개인",
    "posts": [
      {
        "title": "Kibana Alert - 2nd",
        "link": "https://kangmyounghun.blogspot.com/2025/12/kibana-alert-2nd.html",
        "pubDate": "2025-12-06T05:45:00.018Z",
        "author": "강명훈",
        "content": "<div>로그스태시도 대안이 될 수 있다. <a href=\"https://www.elastic.co/docs/reference/logstash/plugins/plugins-inputs-elasticsearch\" target=\"_blank\">원하는 조건 입력</a> 후 <a href=\"https://www.elastic.co/docs/reference/logstash/plugins/plugins-outputs-email\" target=\"_blank\">이메일로 출력</a>하는 방식.</div>\n<div><pre><code class=\"java\"><div>input {</div><div>&nbsp; elasticsearch {</div><div>&nbsp; &nbsp; hosts =&gt; \"https://192.168.56.1:9200\"</div><div>&nbsp; &nbsp; index =&gt; \"winevent\"</div><div>&nbsp; &nbsp; user =&gt; \"elastic\"</div><div>&nbsp; &nbsp; password =&gt; \"******\"</div><div>&nbsp; &nbsp; ssl_certificate_authorities =&gt; \"D:/ELK/v9/elasticsearch-9.2.0/config/certs/http_ca.crt\"</div><div>&nbsp; &nbsp; schedule =&gt; \"* * * * *\"</div><div>&nbsp; &nbsp; query =&gt; '{</div><div><span><a name='more'></a></span> &nbsp; &nbsp; \"query\": {</div><div>&nbsp; &nbsp; &nbsp; &nbsp; \"bool\": {</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \"must\": [</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \"match\": {</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \"winlog.event_id\": \"4624\"</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }&nbsp; &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; },</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \"match\": {</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \"winlog.event_data.TargetUserName\": \"administrator\"</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; },</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \"range\": {</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \"@timestamp\": {</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \"gte\": \"now-1m\",</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \"lte\": \"now\"</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;&nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ]&nbsp; &nbsp;&nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; }</div><div>&nbsp; &nbsp; &nbsp; }&nbsp; &nbsp;&nbsp;</div><div>&nbsp; &nbsp; }'</div><div>&nbsp; }</div><div>}</div><div>&nbsp;</div><div>output {</div><div>&nbsp; email {</div><div>&nbsp; &nbsp; address =&gt; \"smtp.gmail.com\"</div><div>&nbsp; &nbsp; port =&gt; 587</div><div>&nbsp; &nbsp; username =&gt; \"mhkang589@gmail.com\"</div><div>&nbsp; &nbsp; password =&gt; \"app password\"</div><div>&nbsp; &nbsp; to =&gt; \"mhkang589@gmail.com\"</div><div>&nbsp; &nbsp; use_tls =&gt; true</div><div>&nbsp; &nbsp; subject =&gt; \"logstash alert\"</div><div>&nbsp; &nbsp; body =&gt; \"%{[winlog][event_data][TargetUserName]} login\"</div><div>&nbsp; }</div><div>}</div></code></pre></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjDm0ejPlU8d1Ruh4-qdFHP1hBomDa5GeS8-6HOhL4L4TE6kkQXL2dEw3lExRL1O30Khy8kM3qL5S2qlrBuxSFeNJx62tkCjZSeYO9Dmq7rkvIh4TVIvpguc167ykV0uydbMTA7EzH9vF1op6cj-F2Dtk-X4jnofn5_rozy_8SF6otjt_XpR1e6mMWIf399/s1280/logstash_alert.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"706\" data-original-width=\"1280\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjDm0ejPlU8d1Ruh4-qdFHP1hBomDa5GeS8-6HOhL4L4TE6kkQXL2dEw3lExRL1O30Khy8kM3qL5S2qlrBuxSFeNJx62tkCjZSeYO9Dmq7rkvIh4TVIvpguc167ykV0uydbMTA7EzH9vF1op6cj-F2Dtk-X4jnofn5_rozy_8SF6otjt_XpR1e6mMWIf399/s16000/logstash_alert.png\" /></a></div><br /><div>참고로 스플렁크는 서버 설정 &gt; 이메일 설정 후,</div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgfWm412nIfPtNyeOf4Ak8JDgoB1CEt0Ua5HgAgNEq2rut5qDdXvM4ZJrnQPGgO2cB_pzTBgAAjXCCsp4VKfGT219XRGTmsNvbOR5T751lLaGlU_q8G2yC8R_iJq6DGxRsMizkHjrCz7czWAnCfsPYAwaqZS3YnjrSwAMRTjw9MsC9kxOwFXNiy2vCSHKzg/s1164/splunk_alert.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"720\" data-original-width=\"1164\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgfWm412nIfPtNyeOf4Ak8JDgoB1CEt0Ua5HgAgNEq2rut5qDdXvM4ZJrnQPGgO2cB_pzTBgAAjXCCsp4VKfGT219XRGTmsNvbOR5T751lLaGlU_q8G2yC8R_iJq6DGxRsMizkHjrCz7czWAnCfsPYAwaqZS3YnjrSwAMRTjw9MsC9kxOwFXNiy2vCSHKzg/s16000/splunk_alert.png\" /></a></div><br /><div>원하는 조건 검색 기반 경보 생성.</div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgtztT-4N9R7gMNk_fwxmUVt4ZxpKCCJDc91hKkNIp0XV0jjoIWP49VBXOocFXNlD4VCf4W5q2_tCv1mA_FoVShxikO0dQquwJqvhqGTqDMP2ayY7vWnpcoUzxSTZoI-Y-lICjIrE83PE1ifWkflUlZl_JB8jAD5rUKyqyNGQuNExx-tgA30siFQig8qTtF/s1141/splunk_alert2.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"720\" data-original-width=\"1141\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgtztT-4N9R7gMNk_fwxmUVt4ZxpKCCJDc91hKkNIp0XV0jjoIWP49VBXOocFXNlD4VCf4W5q2_tCv1mA_FoVShxikO0dQquwJqvhqGTqDMP2ayY7vWnpcoUzxSTZoI-Y-lICjIrE83PE1ifWkflUlZl_JB8jAD5rUKyqyNGQuNExx-tgA30siFQig8qTtF/s16000/splunk_alert2.png\" /></a></div><div><br /></div><div>이메일 트리거 작업 등록.</div><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg-e7PiC10rz-geOSI9YeLaKa3C0mF7YZYihv0M8HYfwn9H04pJfWBQqLTxW9Niwqfa4VjKDYDuptTw6HuCjQGolnVzKuQ-mV0vtFvw-bxK3QthjPWL5s2vdc-IaGpPxtEpWGIB-soaSQE9fiXyvWbHKtqaG0sPouceidbDR7yTs5ThSO51MCggbhP2crSr/s1082/splunk_alert3.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"720\" data-original-width=\"1082\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg-e7PiC10rz-geOSI9YeLaKa3C0mF7YZYihv0M8HYfwn9H04pJfWBQqLTxW9Niwqfa4VjKDYDuptTw6HuCjQGolnVzKuQ-mV0vtFvw-bxK3QthjPWL5s2vdc-IaGpPxtEpWGIB-soaSQE9fiXyvWbHKtqaG0sPouceidbDR7yTs5ThSO51MCggbhP2crSr/s16000/splunk_alert3.png\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjwjIwO5gKDz2VrHkj2GPPvIVeEfestJQLW7jkh7cOwq7J3NXkZeGrtOYAfX6MxQ1MfF7yI2ae0YuQow7stS1aBS79m8avLUZ5awni-otlIaX_zN4bCQZY0Wxxjbz9iNPjKxBHeJTf4FhweLIkcNhDjCaJM_RmWgqMRBdV0BFnOMrCVuyLO1StgZ9zLEdfh/s1280/splunk_alert4.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"707\" data-original-width=\"1280\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjwjIwO5gKDz2VrHkj2GPPvIVeEfestJQLW7jkh7cOwq7J3NXkZeGrtOYAfX6MxQ1MfF7yI2ae0YuQow7stS1aBS79m8avLUZ5awni-otlIaX_zN4bCQZY0Wxxjbz9iNPjKxBHeJTf4FhweLIkcNhDjCaJM_RmWgqMRBdV0BFnOMrCVuyLO1StgZ9zLEdfh/s16000/splunk_alert4.png\" /></a></div><br /><div><b>관련 글</b></div><div><ul style=\"text-align: left;\"><li><a href=\"https://kangmyounghun.blogspot.com/2025/11/kibana-alert.html\">Kibana Alert</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2019/02/watcher.html\" target=\"\">Watcher 맛보기</a></li></ul></div>",
        "contentSnippet": "로그스태시도 대안이 될 수 있다. 원하는 조건 입력 후 이메일로 출력하는 방식.\n\ninput {\n  elasticsearch {\n    hosts => \"https://192.168.56.1:9200\"\n    index => \"winevent\"\n    user => \"elastic\"\n    password => \"******\"\n    ssl_certificate_authorities => \"D:/ELK/v9/elasticsearch-9.2.0/config/certs/http_ca.crt\"\n    schedule => \"* * * * *\"\n    query => '{\n     \"query\": {\n        \"bool\": {\n          \"must\": [\n            {\n              \"match\": {\n                \"winlog.event_id\": \"4624\"\n              }   \n            },\n            {\n              \"match\": {\n                \"winlog.event_data.TargetUserName\": \"administrator\"\n              }\n            },\n            {\n              \"range\": {\n                \"@timestamp\": {\n                  \"gte\": \"now-1m\",\n                  \"lte\": \"now\"\n                }\n              }  \n            }\n          ]    \n        }\n      }    \n    }'\n  }\n}\n \noutput {\n  email {\n    address => \"smtp.gmail.com\"\n    port => 587\n    username => \"mhkang589@gmail.com\"\n    password => \"app password\"\n    to => \"mhkang589@gmail.com\"\n    use_tls => true\n    subject => \"logstash alert\"\n    body => \"%{[winlog][event_data][TargetUserName]} login\"\n  }\n}\n\n\n\n\n참고로 스플렁크는 서버 설정 > 이메일 설정 후,\n\n\n\n\n원하는 조건 검색 기반 경보 생성.\n\n\n\n\n\n이메일 트리거 작업 등록.\n\n\n\n\n관련 글\n\nKibana Alert\nWatcher 맛보기",
        "id": "tag:blogger.com,1999:blog-2597780270996323853.post-6812630639812542206",
        "isoDate": "2025-12-06T05:45:00.018Z"
      }
    ]
  },
  {
    "name": "김민장",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성중",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구교준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고명환",
    "category": "개인",
    "posts": [
      {
        "creator": "고명환",
        "title": "스타트업 승진 / 직급체계 어떻게 만들까?",
        "link": "https://brunch.co.kr/@@LOc/317",
        "pubDate": "Mon, 08 Dec 2025 04:01:07 GMT",
        "author": "고명환",
        "content": "1. 배경 설명 : 왜 스타트업은 승진 체계를 다르게 가져가야 할까? 스타트업은 대기업과 달리 조직 규모가 작고 성장 속도가 빠르며 역할 변화가 잦은 환경입니다. 이 때문에 전통적인 &quot;사원 - 대리 - 과장 - 차장 - 부장&quot;구조를 그대로 사용하면 다음 문제가 발생합니다. 직급은 올랐는데 실제 업무 변화가 없음 직급 인플레이션으로 조직 전체 연봉 부담 증가<img src= \"https://img1.daumcdn.net/thumb/R1280x0.fjpg/?fname=http%3A%2F%2Ft1.daumcdn.net%2Fbrunch%2Fservice%2Fuser%2FLOc%2Fimage%2FlWFEfjxxivY819MTn-jcuFukR0A\" width=\"500\" />",
        "contentSnippet": "1. 배경 설명 : 왜 스타트업은 승진 체계를 다르게 가져가야 할까? 스타트업은 대기업과 달리 조직 규모가 작고 성장 속도가 빠르며 역할 변화가 잦은 환경입니다. 이 때문에 전통적인 \"사원 - 대리 - 과장 - 차장 - 부장\"구조를 그대로 사용하면 다음 문제가 발생합니다. 직급은 올랐는데 실제 업무 변화가 없음 직급 인플레이션으로 조직 전체 연봉 부담 증가",
        "guid": "https://brunch.co.kr/@@LOc/317",
        "isoDate": "2025-12-08T04:01:07.000Z"
      }
    ]
  },
  {
    "name": "강성희",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강병수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김봉현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강형석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수로",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강미경",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강진우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권민재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태관",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도곤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "칡토스의 게임 개발",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "프리웨어 이야기",
    "category": "개인",
    "posts": [
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "AI 스토리보드 앱으로 만드는 프로페셔널 15초 영상",
        "link": "https://muzbox.tistory.com/483688",
        "pubDate": "Mon, 8 Dec 2025 12:42:42 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "https://muzbox.tistory.com/483688#entry483688comment",
        "content": "<div style=\"font-family: 'Noto Sans KR', sans-serif; line-height: 1.6; max-width: 800px; margin: 0 auto; font-size: 16px; box-sizing: border-box; color: #333333;\">\n<div style=\"background-color: #e3f2fd; padding: 15px; border-radius: 8px; font-style: italic; margin-bottom: 25px; font-size: 15px;\">여러분, 15초짜리 짧은 영상을 만드는데 얼마나 걸리시나요? 예전에는 30분 넘게 걸리던 복잡한 작업이 이제는 AI 스토리보드 앱 덕분에 단 1분 만에 끝난다고 하면 믿으시겠어요? 현재 AI 기술은 영상 제작의 패러다임을 완전히 바꾸고 있습니다. Nano Banana Pro와 Sora 2.0/VEO 3.1의 환상적인 조합으로 탄생한 이 혁신적인 워크플로우를 지금 바로 만나보세요.</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #0f4c81, #002f6c); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  놀랍지 않나요? 30분 걸리던 영상 제작이 단 1분 만에!</b></h2>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"1200\"><span data-url=\"https://blog.kakaocdn.net/dn/Pkttw/dJMcagxe54q/RaE8wTPgwza2YjNB28p5A0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/Pkttw/dJMcagxe54q/RaE8wTPgwza2YjNB28p5A0/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/Pkttw/dJMcagxe54q/RaE8wTPgwza2YjNB28p5A0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FPkttw%2FdJMcagxe54q%2FRaE8wTPgwza2YjNB28p5A0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"AI 스토리보드 앱을 이용해 15초 영상을 빠르고 전문적으로 제작하는 과정을 보여주는 이미지. 화면에는 9개의 시네마틱 프레임으로 구성된 스토리보드가 보이며, 사용자가 영상을 생성하는 버튼을 누르려 하고 있다. 미래지향적이고 효율적인 영상 제작 환경을 시사한다.\" loading=\"lazy\" width=\"500\" height=\"500\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"1200\"/></span></figure>\n\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">솔직히 처음 이 이야기를 들었을 때 저도 깜짝 놀랐습니다. 불과 얼마 전까지만 해도 15초 분량의 영상을 만들기 위해선 프레임을 일일이 추출하고, 중간 프레임을 생성하며 사운드까지 수작업으로 입히는 등 꽤나 지난한 과정을 거쳐야 했거든요. 그런데 지금은 그 모든 과정이 단 몇 번의 클릭으로 끝난다는 겁니다. 특히 X에서 엄청난 화제를 모았던 Underwood의 혁신적인 AI 스토리보드 시스템은 이런 변화를 가능하게 했어요.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">핵심은 바로 <b>Nano Banana Pro와 Sora 2.0 (또는 VEO 3.1)의 조합</b>입니다. 고품질의 이미지를 만들어내는 Nano Banana Pro로 단 한 장의 이미지를 생성하고, 이를 Sora 2.0이나 VEO 3.1에 넣으면 놀랍도록 자연스러운 영상으로 확장되죠. 심지어 사운드 디자인까지 자동으로 처리해주니, 예전처럼 복잡한 편집 단계는 이제 정말 옛말이 되어버렸습니다.</p>\n<div style=\"background-color: #e3f2fd; border-left: 4px solid #0f4c81; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">  <b>AI 스토리보드 시스템의 마법:</b> 이미지 생성(Nano Banana Pro) &rarr; 영상 확장 및 사운드 자동 생성(Sora 2.0/VEO 3.1) = 초고속 영상 제작! ✨</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #0f4c81, #002f6c); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  Underwood의 '그' 복잡한 프롬프트, 완벽 분석!</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">Underwood가 X에 공개했던 원본 프롬프트는 사실 굉장히 전문적이고 복잡했습니다. 수백 줄에 달하는 영화 문법, 카메라 워킹, 조명 설정 등이 총망라되어 있었죠. 이 프롬프트의 구조를 자세히 들여다보면 그야말로 '영화 감독' 수준의 지식이 필요함을 알 수 있습니다.</p>\n<div style=\"background-color: #f0f4f8; padding: 20px; border-radius: 8px; border: 1px solid #b0bec5; margin-bottom: 20px;\"><b>Underwood 원본 프롬프트의 핵심 요소</b>\n<p style=\"margin-bottom: 10px;\" data-ke-size=\"size16\"><b>역할 정의:</b> 당신은 트레일러 감독이자 촬영 감독이자 스토리보드 아티스트다. 이미지 하나를 영화적 시퀀스로 확장하고, AI 비디오용 키프레임을 출력하라.</p>\n<ul style=\"list-style-type: disc; margin-left: 20px; margin-bottom: 15px; color: #333333;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 8px;\"><b>5가지 절대 규칙:</b>\n<ul style=\"list-style-type: circle; margin-left: 20px;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 5px;\">모든 피사체를 정확히 분석 (누가, 어디, 뭘 하는지).</li>\n<li style=\"margin-bottom: 5px;\">추측 금지, 보이는 것만 묘사.</li>\n<li style=\"margin-bottom: 5px;\">완벽한 일관성 (같은 의상, 환경, 조명. 액션과 표정만 변화).</li>\n<li style=\"margin-bottom: 5px;\">현실적 피사계 심도 (와이드는 깊게, 클로즈업은 얕게).</li>\n<li>새로운 요소 추가 금지 (긴장감은 화면 밖에서, 그림자, 소리, 시선으로 암시).</li>\n</ul>\n</li>\n<li style=\"margin-bottom: 8px;\"><b>4단계 프로세스:</b>\n<ul style=\"list-style-type: circle; margin-left: 20px;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 5px;\"><b>1단계, 장면 분석:</b> 피사체 분석 및 시각적 고정점 정의.</li>\n<li style=\"margin-bottom: 5px;\"><b>2단계, 테마와 스토리:</b> 테마 정의, 도입, 상승, 전환, 클라이맥스 감정 아크 설계.</li>\n<li style=\"margin-bottom: 5px;\"><b>3단계, 영화적 접근:</b> 샷 전략, 카메라 움직임, 렌즈, 조명 결정.</li>\n<li style=\"margin-bottom: 5px;\"><b>4단계, 키프레임 디자인:</b> 9~12개 프레임 디자인 (번호, 시간, 샷 타입, 구도, 액션, 카메라, 렌즈, 조명, 사운드 등 상세 정의). 와이드, 클로즈업, 익스트림 클로즈업, 파워 앵글 각 1개 필수.</li>\n<li><b>5단계, Contact Sheet 출력:</b> 모든 키프레임을 3x3 그리드로 만들어 각 패널에 번호, 샷 타입, 시간 라벨 부착.</li>\n</ul>\n</li>\n</ul>\n</div>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">어떠세요? 이 프롬프트를 원본 그대로 사용하기란 정말 쉽지 않겠죠? 전문 영상 제작자가 아니라면 엄두도 내기 어려울 정도의 복잡성과 전문성을 요구합니다. 하지만 걱정 마세요! 바로 이 복잡한 과정을 누구나 쉽게 사용할 수 있도록 앱으로 구현한 것이 바로 <b>'시네마틱 스토리보드 AI'</b>입니다.</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #0f4c81, #002f6c); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  이제는 버튼 몇 번으로 끝! '시네마틱 스토리보드 AI' 앱의 탄생</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이 고도화된 Underwood의 지침을 일반인도 쉽게 활용할 수 있도록 앱으로 만들었다는 사실이 정말 놀라웠습니다. 앱 개발 과정은 간단하게 요약하자면 이렇습니다.</p>\n<ol style=\"list-style-type: decimal; margin-left: 25px; margin-bottom: 20px; color: #333333;\" data-ke-list-type=\"decimal\">\n<li style=\"margin-bottom: 10px;\">X에 공유된 스토리보드 시스템의 핵심 지침을 복사하여 저장합니다.</li>\n<li style=\"margin-bottom: 10px;\">AI STUDIO BUILD에 해당 파일을 업로드한 후, '첨부 지침을 기반으로 사용자가 제공하는 이미지를 스토리보드로 만들고, 만들어진 스토리보드를 기반으로 영상 생성을 위한 JSON 파일까지 생성하는 한글 앱을 만들어'라고 요청합니다.</li>\n<li>결과물을 계속 테스트하고 피드백을 반영하며 앱을 완성시킵니다.</li>\n</ol>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이렇게 만들어진 '시네마틱 스토리보드 AI' 앱은 복잡한 AI 프롬프트 지식을 일반 사용자가 <b>버튼 몇 번으로 작동</b>할 수 있도록 직관적인 인터페이스를 제공합니다. 사용자의 역할은 단 세 가지로 압축됩니다. <b>이미지 업로드, 9컷 스토리보드 생성, 프롬프트 복사.</b> 정말 간단하죠? 이 앱의 소스 코드까지 궁금하신 유튜브 멤버십 회원분들을 위해 AI STUDIO BUILD 원본 앱 링크를 멤버십 게시판에 공유해 드렸으니, 여러분의 취향에 맞게 수정하여 활용해 보세요.</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #0f4c81, #002f6c); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>✨ '시네마틱 스토리보드 AI' 앱, 이렇게 사용해 보세요!</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">자, 그럼 이 혁신적인 앱을 어떻게 사용하는지 단계별로 자세히 알아볼까요? 어렵지 않으니 차근차근 따라오시면 됩니다.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1269\" data-origin-height=\"673\"><span data-url=\"https://blog.kakaocdn.net/dn/bgxcnl/dJMcajgnYkz/iplPuK4FlpXhFqmGfFHRK1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bgxcnl/dJMcajgnYkz/iplPuK4FlpXhFqmGfFHRK1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bgxcnl/dJMcajgnYkz/iplPuK4FlpXhFqmGfFHRK1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbgxcnl%2FdJMcajgnYkz%2FiplPuK4FlpXhFqmGfFHRK1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"시네마틱 스토리보드 AI 화면\" loading=\"lazy\" width=\"1269\" height=\"673\" data-origin-width=\"1269\" data-origin-height=\"673\"/></span></figure>\n\n<ol style=\"list-style-type: decimal; margin-left: 25px; margin-bottom: 20px; color: #333333;\" data-ke-list-type=\"decimal\">\n<li style=\"margin-bottom: 10px;\"><b>API 키 등록:</b> 앱 실행 후 제일 먼저 Nano Banana Pro를 사용하기 위한 API 키를 등록합니다. 지난 영상에서 등록 방법을 자세히 설명드렸으니 참고하시면 됩니다. 연결 테스트에 문제가 없다면 바로 저장이 완료됩니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>화면 구성 확인:</b>\n<ul style=\"list-style-type: circle; margin-left: 20px; margin-bottom: 10px;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 5px;\"><b>왼쪽 메뉴:</b> 언어 설정, 테마 설정, 이미지 생성 모델 설정을 할 수 있습니다. 그 아래엔 영상의 길이, 대사 언어 설정, 간단한 전문 용어 설명 및 도움말이 있습니다.</li>\n<li><b>오른쪽 화면:</b> 이미지만 등록하면 바로 스토리보드를 생성할 수 있는 직관적인 구성입니다.</li>\n</ul>\n</li>\n<li style=\"margin-bottom: 10px;\"><b>레퍼런스 이미지 등록 및 주제 입력:</b> 이제 직접 만들어 볼 시간입니다. 먼저 레퍼런스 이미지를 등록하세요. 이미지를 등록하면 이미지 아래에 '주제 입력창'이 나타나는데, 여러분이 직접 이미지와 관련된 스토리를 입력하거나 'AI 제안' 버튼을 클릭하여 AI가 이미지를 분석하고 자동으로 주제를 채워 넣을 수 있습니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>생성 옵션 설정:</b> 생성에 사용할 AI 모델을 선택하고, 영상의 길이를 지정합니다. 대사를 포함할지 여부와 대사 언어를 선택한 후, '생성하기' 버튼을 클릭합니다.</li>\n<li><b>9컷 스토리보드 생성 확인:</b> 잠시 후, 총 9개로 구성된 완벽한 스토리보드가 생성됩니다. 사용자가 업로드한 장면 분석 결과(A)와 주제를 기반으로 한 테마와 스토리(B)가 출력되고, 영상의 연출 접근 방식(C)을 분석하며, 9개의 키프레임(KF)별 상세 설정이 모두 반영된 것을 확인할 수 있습니다.</li>\n</ol>\n<div style=\"background-color: #e3f2fd; border-left: 4px solid #0f4c81; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">  <b>팁:</b> 스토리보드 마스터 이미지를 저장하거나, 9개의 각 프레임별 이미지를 개별적으로 분리하는 기능도 제공됩니다. 이는 특정 장면만으로 영상을 생성하거나 여러 장면을 조합하는 AI 도구들을 고려한 유용한 기능입니다.</div>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1446\" data-origin-height=\"676\"><span data-url=\"https://blog.kakaocdn.net/dn/cJznTK/dJMcajtVbQ6/aglfsgiDSV35kXaq1CXG00/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cJznTK/dJMcajtVbQ6/aglfsgiDSV35kXaq1CXG00/img.png\"><img src=\"https://blog.kakaocdn.net/dn/cJznTK/dJMcajtVbQ6/aglfsgiDSV35kXaq1CXG00/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcJznTK%2FdJMcajtVbQ6%2FaglfsgiDSV35kXaq1CXG00%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"시네마틱 스토리보드 AI\" loading=\"lazy\" width=\"1446\" height=\"676\" data-origin-width=\"1446\" data-origin-height=\"676\"/></span></figure>\n\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">마지막으로, <b>'비디오 프롬프트 생성'</b>을 클릭하면 영상 생성에 필요한 프롬프트가 제공됩니다. 마스터 프롬프트를 시작으로 키프레임별로 사용할 수 있는 장면별 상세 프롬프트, 그리고 가장 중요한 JSON 형식의 9개 씬 프롬프트가 일목요연하게 출력됩니다. 이제 이 JSON을 복사해서 원하는 AI 비디오 생성 툴에 붙여넣기만 하면 끝입니다!</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #0f4c81, #002f6c); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  Sora 2.0과 VEO 3.1, 그리고 AI 스토리보드 앱의 환상적인 시너지</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">'시네마틱 스토리보드 AI' 앱에서 생성된 JSON 프롬프트는 Sora 2.0뿐만 아니라 VEO 3.1과 같은 다양한 AI 비디오 생성 모델에서 활용 가능합니다. 이 조합이 얼마나 강력한지 실제 워크플로우를 통해 확인해볼까요?</p>\n<h3 style=\"font-size: 19px; color: #0f4c81; margin: 25px 0 10px; font-weight: 600;\" data-ke-size=\"size23\"><b>Sora 2.0을 활용한 15초 영상 제작</b></h3>\n<ul style=\"list-style-type: disc; margin-left: 25px; margin-bottom: 20px; color: #333333;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 10px;\"><b>스텝 1:</b> Sora 2.0에 접속합니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>스텝 2:</b> AI 스토리보드 앱에서 생성된 마스터 이미지를 등록합니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>스텝 3:</b> 앱에서 복사한 JSON 프롬프트를 붙여넣습니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>스텝 4:</b> 영상 길이를 15초로 설정하고 '생성' 버튼을 클릭합니다.</li>\n<li><b>결과:</b> 놀랍도록 자연스럽고 일관성 있는 15초 영상이 완성됩니다.</li>\n</ul>\n<h3 style=\"font-size: 19px; color: #0f4c81; margin: 25px 0 10px; font-weight: 600;\" data-ke-size=\"size23\"><b>VEO 3.1을 활용한 8초 영상 제작</b></h3>\n<ul style=\"list-style-type: disc; margin-left: 25px; margin-bottom: 20px; color: #333333;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 10px;\"><b>스텝 1:</b> AI 스토리보드 앱에서 레퍼런스 이미지를 등록하고 주제를 입력합니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>스텝 2:</b> 영상 길이를 8초로 지정하고 다른 옵션들을 선택 후 '생성하기' 버튼을 클릭하여 스토리보드를 만듭니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>스텝 3:</b> 생성된 스토리보드 이미지를 다운로드하고, '비디오 프롬프트 생성'을 클릭하여 JSON을 복사합니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>스텝 4:</b> Gemini (VEO 3.1)로 가서 다운로드한 마스터 이미지를 업로드하고 JSON도 붙여넣습니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>스텝 5:</b> 채팅창 옵션에 '동영상 만들기'를 선택하고 실행하면 바로 영상이 생성됩니다.</li>\n</ul>\n<div style=\"background-color: #ffebee; border-left: 4px solid #d32f2f; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">⚠️ <b>주의:</b> 영상을 만들 때 마스터 이미지가 아닌 원본 이미지를 JSON과 함께 업로드해도 무방합니다. 사용하시는 AI 모델의 특성과 선호도에 따라 유연하게 선택하세요!</div>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">정말이지, 이렇게 쉽고 빠르게 고품질의 영상을 만들 수 있다는 사실이 믿기지 않습니다. 이 앱을 활용하여 만든 영상들을 보면 그 퀄리티에 다시 한번 감탄하게 됩니다. 여러분도 직접 경험해보시면 제가 어떤 이야기를 하는지 바로 아실 거예요.</p>\n<div style=\"background-color: #f0f4f8; border: 1px solid #b0bec5; border-radius: 8px; padding: 25px; margin: 40px 0; box-shadow: 0 4px 12px rgba(0,0,0,0.1);\">\n<div style=\"font-size: 26px; color: #0f4c81; font-weight: bold; margin-bottom: 15px; padding-bottom: 10px; border-bottom: 2px solid #0f4c81;\">  핵심 요약</div>\n<ul style=\"list-style-type: none; padding: 0; margin: 0;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 15px; font-size: 17px;\">✅ <b>15초 영상 제작, 30분에서 1분으로 단축:</b> AI 스토리보드 앱이 혁신적인 시간 절약을 가능하게 합니다.</li>\n<li style=\"margin-bottom: 15px; font-size: 17px;\">✅ <b>Nano Banana Pro + Sora 2.0/VEO 3.1 조합:</b> 고품질 이미지 생성부터 영상 확장, 사운드 디자인까지 AI가 자동으로 처리합니다.</li>\n<li style=\"margin-bottom: 15px; font-size: 17px;\">✅ <b>복잡한 프롬프트 지식의 간소화:</b> Underwood의 전문적인 프롬프트를 앱 하나로 쉽게 구현할 수 있습니다.</li>\n<li style=\"margin-bottom: 0px; font-size: 17px;\">✅ <b>직관적인 워크플로우:</b> 이미지 업로드, 스토리보드 생성, JSON 프롬프트 복사만으로 영상 제작이 가능합니다.</li>\n</ul>\n<div style=\"font-size: 14px; color: #77aaff; margin-top: 25px; padding-top: 15px; border-top: 1px solid #e0e0e0;\">영상 제작의 미래, AI 스토리보드 앱과 함께라면 여러분도 전문가가 될 수 있습니다.</div>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #0f4c81, #002f6c); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>❓ 자주 묻는 질문 (FAQ)</b></h2>\n<div style=\"margin-bottom: 20px;\">\n<h3 style=\"font-size: 19px; color: #0f4c81; margin: 25px 0 10px; font-weight: 600;\" data-ke-size=\"size23\">Q1: '시네마틱 스토리보드 AI' 앱은 어떤 AI 모델을 지원하나요?</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이 앱은 기본적으로 Nano Banana Pro를 통해 고품질 이미지를 생성하며, 생성된 스토리보드와 JSON 프롬프트는 Sora 2.0과 VEO 3.1을 포함한 다양한 AI 비디오 생성 모델에서 활용할 수 있도록 설계되었습니다. 앱 내에서 사용하실 모델을 직접 선택할 수 있습니다.</p>\n</div>\n<div style=\"margin-bottom: 20px;\">\n<h3 style=\"font-size: 19px; color: #0f4c81; margin: 25px 0 10px; font-weight: 600;\" data-ke-size=\"size23\">Q2: 비전문가도 이 앱을 통해 프로페셔널한 영상을 만들 수 있나요?</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">네, 물론입니다! Underwood의 복잡한 영화적 프롬프트 지식을 앱이 자동으로 처리해주기 때문에, 사용자는 레퍼런스 이미지 하나만으로도 고품질의 9컷 스토리보드를 얻고, 이를 기반으로 전문가 수준의 영상을 손쉽게 제작할 수 있습니다. 별도의 영상 편집 기술이나 AI 프롬프트 지식이 없어도 가능합니다.</p>\n</div>\n<div style=\"margin-bottom: 20px;\">\n<h3 style=\"font-size: 19px; color: #0f4c81; margin: 25px 0 10px; font-weight: 600;\" data-ke-size=\"size23\">Q3: 앱을 사용하려면 API 키가 반드시 필요한가요?</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">네, Nano Banana Pro와 같은 이미지 생성 AI 모델을 사용하기 위해서는 해당 서비스의 API 키 등록이 필수입니다. 앱 실행 후 안내에 따라 API 키를 등록하고 연결 테스트를 완료해야 앱의 모든 기능을 원활하게 사용할 수 있습니다. 정확한 등록 방법은 관련 안내 영상을 참고해 주세요.</p>\n</div>\n<script type=\"application/ld+json\">\n  {\n    \"@context\": \"https://schema.org\",\n    \"@type\": \"FAQPage\",\n    \"mainEntity\": [\n      {\n        \"@type\": \"Question\",\n        \"name\": \"'시네마틱 스토리보드 AI' 앱은 어떤 AI 모델을 지원하나요?\",\n        \"acceptedAnswer\": {\n          \"@type\": \"Answer\",\n          \"text\": \"이 앱은 기본적으로 Nano Banana Pro를 통해 고품질 이미지를 생성하며, 생성된 스토리보드와 JSON 프롬프트는 Sora 2.0과 VEO 3.1을 포함한 다양한 AI 비디오 생성 모델에서 활용할 수 있도록 설계되었습니다. 앱 내에서 사용하실 모델을 직접 선택할 수 있습니다.\"\n        }\n      },\n      {\n        \"@type\": \"Question\",\n        \"name\": \"비전문가도 이 앱을 통해 프로페셔널한 영상을 만들 수 있나요?\",\n        \"acceptedAnswer\": {\n          \"@type\": \"Answer\",\n          \"text\": \"네, 물론입니다! Underwood의 복잡한 영화적 프롬프트 지식을 앱이 자동으로 처리해주기 때문에, 사용자는 레퍼런스 이미지 하나만으로도 고품질의 9컷 스토리보드를 얻고, 이를 기반으로 전문가 수준의 영상을 손쉽게 제작할 수 있습니다. 별도의 영상 편집 기술이나 AI 프롬프트 지식이 없어도 가능합니다.\"\n        }\n      },\n      {\n        \"@type\": \"Question\",\n        \"name\": \"앱을 사용하려면 API 키가 반드시 필요한가요?\",\n        \"acceptedAnswer\": {\n          \"@type\": \"Answer\",\n          \"text\": \"네, Nano Banana Pro와 같은 이미지 생성 AI 모델을 사용하기 위해서는 해당 서비스의 API 키 등록이 필수입니다. 앱 실행 후 안내에 따라 API 키를 등록하고 연결 테스트를 완료해야 앱의 모든 기능을 원활하게 사용할 수 있습니다. 정확한 등록 방법은 관련 안내 영상을 참고해 주세요.\"\n        }\n      }\n    ]\n  }\n  </script>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">여러분, 보셨죠? 이미지 하나만 업로드하면 아홉 컷 스토리보드부터 JSON 프롬프트까지 자동으로 생성되고, Sora 2.0이든 VEO 3.1이든 원하는 AI 모델에 붙여넣기만 하면 전문가 수준의 영상이 뚝딱 완성됩니다. X에 공유된 수백 줄짜리 프롬프트 지식을 이제는 버튼 클릭 한 번으로 활용하는 시대가 온 거죠. 30분 걸리던 작업이 1분으로 단축되는 이 놀라운 변화, 이게 바로 2025년 '바이브 코딩 시대'가 가져다준 혁신입니다.</p>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #0f4c81, #002f6c); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  시네마틱 스토리보드 AI&nbsp; 무료 사용하기</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">'시네마틱 스토리보드 AI'은 무료로 사용이 가능하나 나노바나나(프로) 사용에는 여러분의 API KEY 를 사용해야하며, 이때 과금이 발생하니 참고하세요.</p>\n<figure id=\"og_1765165928236\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"Cinematic Storyboard AI\" data-og-description=\"\" data-og-host=\"cinematic-storyboard-ai.vercel.app\" data-og-source-url=\"https://cinematic-storyboard-ai.vercel.app/\" data-og-url=\"https://cinematic-storyboard-ai.vercel.app/\" data-og-image=\"\"><a href=\"https://cinematic-storyboard-ai.vercel.app/\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://cinematic-storyboard-ai.vercel.app/\">\n<div class=\"og-image\" style=\"background-image: url();\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">Cinematic Storyboard AI</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">&nbsp;</p>\n<p class=\"og-host\" data-ke-size=\"size16\">cinematic-storyboard-ai.vercel.app</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=cGsxxVP8950\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/b7XQWi/hyZO4PS6ru/pfsk8oG33SCmD4DAPIWdr0/img.jpg?width=1280&amp;height=720&amp;face=760_286_1206_470,https://scrap.kakaocdn.net/dn/j52nA/hyZOUGxJs6/WVwTqhReHrgXYFKmuo6qp0/img.jpg?width=1280&amp;height=720&amp;face=760_286_1206_470\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"이미지 1장으로 15초 영상 완성? 1분컷 워크플로우 대공개 | 시네마틱 스토리보드 AI 무료앱 배포\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/cGsxxVP8950\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "여러분, 15초짜리 짧은 영상을 만드는데 얼마나 걸리시나요? 예전에는 30분 넘게 걸리던 복잡한 작업이 이제는 AI 스토리보드 앱 덕분에 단 1분 만에 끝난다고 하면 믿으시겠어요? 현재 AI 기술은 영상 제작의 패러다임을 완전히 바꾸고 있습니다. Nano Banana Pro와 Sora 2.0/VEO 3.1의 환상적인 조합으로 탄생한 이 혁신적인 워크플로우를 지금 바로 만나보세요.\n  놀랍지 않나요? 30분 걸리던 영상 제작이 단 1분 만에!\n\n\n솔직히 처음 이 이야기를 들었을 때 저도 깜짝 놀랐습니다. 불과 얼마 전까지만 해도 15초 분량의 영상을 만들기 위해선 프레임을 일일이 추출하고, 중간 프레임을 생성하며 사운드까지 수작업으로 입히는 등 꽤나 지난한 과정을 거쳐야 했거든요. 그런데 지금은 그 모든 과정이 단 몇 번의 클릭으로 끝난다는 겁니다. 특히 X에서 엄청난 화제를 모았던 Underwood의 혁신적인 AI 스토리보드 시스템은 이런 변화를 가능하게 했어요.\n핵심은 바로 Nano Banana Pro와 Sora 2.0 (또는 VEO 3.1)의 조합입니다. 고품질의 이미지를 만들어내는 Nano Banana Pro로 단 한 장의 이미지를 생성하고, 이를 Sora 2.0이나 VEO 3.1에 넣으면 놀랍도록 자연스러운 영상으로 확장되죠. 심지어 사운드 디자인까지 자동으로 처리해주니, 예전처럼 복잡한 편집 단계는 이제 정말 옛말이 되어버렸습니다.\n  AI 스토리보드 시스템의 마법: 이미지 생성(Nano Banana Pro) → 영상 확장 및 사운드 자동 생성(Sora 2.0/VEO 3.1) = 초고속 영상 제작! ✨\n  Underwood의 '그' 복잡한 프롬프트, 완벽 분석!\nUnderwood가 X에 공개했던 원본 프롬프트는 사실 굉장히 전문적이고 복잡했습니다. 수백 줄에 달하는 영화 문법, 카메라 워킹, 조명 설정 등이 총망라되어 있었죠. 이 프롬프트의 구조를 자세히 들여다보면 그야말로 '영화 감독' 수준의 지식이 필요함을 알 수 있습니다.\nUnderwood 원본 프롬프트의 핵심 요소\n역할 정의: 당신은 트레일러 감독이자 촬영 감독이자 스토리보드 아티스트다. 이미지 하나를 영화적 시퀀스로 확장하고, AI 비디오용 키프레임을 출력하라.\n5가지 절대 규칙:\n\n모든 피사체를 정확히 분석 (누가, 어디, 뭘 하는지).\n추측 금지, 보이는 것만 묘사.\n완벽한 일관성 (같은 의상, 환경, 조명. 액션과 표정만 변화).\n현실적 피사계 심도 (와이드는 깊게, 클로즈업은 얕게).\n새로운 요소 추가 금지 (긴장감은 화면 밖에서, 그림자, 소리, 시선으로 암시).\n4단계 프로세스:\n\n1단계, 장면 분석: 피사체 분석 및 시각적 고정점 정의.\n2단계, 테마와 스토리: 테마 정의, 도입, 상승, 전환, 클라이맥스 감정 아크 설계.\n3단계, 영화적 접근: 샷 전략, 카메라 움직임, 렌즈, 조명 결정.\n4단계, 키프레임 디자인: 9~12개 프레임 디자인 (번호, 시간, 샷 타입, 구도, 액션, 카메라, 렌즈, 조명, 사운드 등 상세 정의). 와이드, 클로즈업, 익스트림 클로즈업, 파워 앵글 각 1개 필수.\n5단계, Contact Sheet 출력: 모든 키프레임을 3x3 그리드로 만들어 각 패널에 번호, 샷 타입, 시간 라벨 부착.\n어떠세요? 이 프롬프트를 원본 그대로 사용하기란 정말 쉽지 않겠죠? 전문 영상 제작자가 아니라면 엄두도 내기 어려울 정도의 복잡성과 전문성을 요구합니다. 하지만 걱정 마세요! 바로 이 복잡한 과정을 누구나 쉽게 사용할 수 있도록 앱으로 구현한 것이 바로 '시네마틱 스토리보드 AI'입니다.\n  이제는 버튼 몇 번으로 끝! '시네마틱 스토리보드 AI' 앱의 탄생\n이 고도화된 Underwood의 지침을 일반인도 쉽게 활용할 수 있도록 앱으로 만들었다는 사실이 정말 놀라웠습니다. 앱 개발 과정은 간단하게 요약하자면 이렇습니다.\nX에 공유된 스토리보드 시스템의 핵심 지침을 복사하여 저장합니다.\nAI STUDIO BUILD에 해당 파일을 업로드한 후, '첨부 지침을 기반으로 사용자가 제공하는 이미지를 스토리보드로 만들고, 만들어진 스토리보드를 기반으로 영상 생성을 위한 JSON 파일까지 생성하는 한글 앱을 만들어'라고 요청합니다.\n결과물을 계속 테스트하고 피드백을 반영하며 앱을 완성시킵니다.\n이렇게 만들어진 '시네마틱 스토리보드 AI' 앱은 복잡한 AI 프롬프트 지식을 일반 사용자가 버튼 몇 번으로 작동할 수 있도록 직관적인 인터페이스를 제공합니다. 사용자의 역할은 단 세 가지로 압축됩니다. 이미지 업로드, 9컷 스토리보드 생성, 프롬프트 복사. 정말 간단하죠? 이 앱의 소스 코드까지 궁금하신 유튜브 멤버십 회원분들을 위해 AI STUDIO BUILD 원본 앱 링크를 멤버십 게시판에 공유해 드렸으니, 여러분의 취향에 맞게 수정하여 활용해 보세요.\n✨ '시네마틱 스토리보드 AI' 앱, 이렇게 사용해 보세요!\n자, 그럼 이 혁신적인 앱을 어떻게 사용하는지 단계별로 자세히 알아볼까요? 어렵지 않으니 차근차근 따라오시면 됩니다.\n\n\n\nAPI 키 등록: 앱 실행 후 제일 먼저 Nano Banana Pro를 사용하기 위한 API 키를 등록합니다. 지난 영상에서 등록 방법을 자세히 설명드렸으니 참고하시면 됩니다. 연결 테스트에 문제가 없다면 바로 저장이 완료됩니다.\n화면 구성 확인:\n\n왼쪽 메뉴: 언어 설정, 테마 설정, 이미지 생성 모델 설정을 할 수 있습니다. 그 아래엔 영상의 길이, 대사 언어 설정, 간단한 전문 용어 설명 및 도움말이 있습니다.\n오른쪽 화면: 이미지만 등록하면 바로 스토리보드를 생성할 수 있는 직관적인 구성입니다.\n레퍼런스 이미지 등록 및 주제 입력: 이제 직접 만들어 볼 시간입니다. 먼저 레퍼런스 이미지를 등록하세요. 이미지를 등록하면 이미지 아래에 '주제 입력창'이 나타나는데, 여러분이 직접 이미지와 관련된 스토리를 입력하거나 'AI 제안' 버튼을 클릭하여 AI가 이미지를 분석하고 자동으로 주제를 채워 넣을 수 있습니다.\n생성 옵션 설정: 생성에 사용할 AI 모델을 선택하고, 영상의 길이를 지정합니다. 대사를 포함할지 여부와 대사 언어를 선택한 후, '생성하기' 버튼을 클릭합니다.\n9컷 스토리보드 생성 확인: 잠시 후, 총 9개로 구성된 완벽한 스토리보드가 생성됩니다. 사용자가 업로드한 장면 분석 결과(A)와 주제를 기반으로 한 테마와 스토리(B)가 출력되고, 영상의 연출 접근 방식(C)을 분석하며, 9개의 키프레임(KF)별 상세 설정이 모두 반영된 것을 확인할 수 있습니다.\n  팁: 스토리보드 마스터 이미지를 저장하거나, 9개의 각 프레임별 이미지를 개별적으로 분리하는 기능도 제공됩니다. 이는 특정 장면만으로 영상을 생성하거나 여러 장면을 조합하는 AI 도구들을 고려한 유용한 기능입니다.\n\n\n마지막으로, '비디오 프롬프트 생성'을 클릭하면 영상 생성에 필요한 프롬프트가 제공됩니다. 마스터 프롬프트를 시작으로 키프레임별로 사용할 수 있는 장면별 상세 프롬프트, 그리고 가장 중요한 JSON 형식의 9개 씬 프롬프트가 일목요연하게 출력됩니다. 이제 이 JSON을 복사해서 원하는 AI 비디오 생성 툴에 붙여넣기만 하면 끝입니다!\n  Sora 2.0과 VEO 3.1, 그리고 AI 스토리보드 앱의 환상적인 시너지\n'시네마틱 스토리보드 AI' 앱에서 생성된 JSON 프롬프트는 Sora 2.0뿐만 아니라 VEO 3.1과 같은 다양한 AI 비디오 생성 모델에서 활용 가능합니다. 이 조합이 얼마나 강력한지 실제 워크플로우를 통해 확인해볼까요?\nSora 2.0을 활용한 15초 영상 제작\n스텝 1: Sora 2.0에 접속합니다.\n스텝 2: AI 스토리보드 앱에서 생성된 마스터 이미지를 등록합니다.\n스텝 3: 앱에서 복사한 JSON 프롬프트를 붙여넣습니다.\n스텝 4: 영상 길이를 15초로 설정하고 '생성' 버튼을 클릭합니다.\n결과: 놀랍도록 자연스럽고 일관성 있는 15초 영상이 완성됩니다.\nVEO 3.1을 활용한 8초 영상 제작\n스텝 1: AI 스토리보드 앱에서 레퍼런스 이미지를 등록하고 주제를 입력합니다.\n스텝 2: 영상 길이를 8초로 지정하고 다른 옵션들을 선택 후 '생성하기' 버튼을 클릭하여 스토리보드를 만듭니다.\n스텝 3: 생성된 스토리보드 이미지를 다운로드하고, '비디오 프롬프트 생성'을 클릭하여 JSON을 복사합니다.\n스텝 4: Gemini (VEO 3.1)로 가서 다운로드한 마스터 이미지를 업로드하고 JSON도 붙여넣습니다.\n스텝 5: 채팅창 옵션에 '동영상 만들기'를 선택하고 실행하면 바로 영상이 생성됩니다.\n⚠️ 주의: 영상을 만들 때 마스터 이미지가 아닌 원본 이미지를 JSON과 함께 업로드해도 무방합니다. 사용하시는 AI 모델의 특성과 선호도에 따라 유연하게 선택하세요!\n정말이지, 이렇게 쉽고 빠르게 고품질의 영상을 만들 수 있다는 사실이 믿기지 않습니다. 이 앱을 활용하여 만든 영상들을 보면 그 퀄리티에 다시 한번 감탄하게 됩니다. 여러분도 직접 경험해보시면 제가 어떤 이야기를 하는지 바로 아실 거예요.\n  핵심 요약\n✅ 15초 영상 제작, 30분에서 1분으로 단축: AI 스토리보드 앱이 혁신적인 시간 절약을 가능하게 합니다.\n✅ Nano Banana Pro + Sora 2.0/VEO 3.1 조합: 고품질 이미지 생성부터 영상 확장, 사운드 디자인까지 AI가 자동으로 처리합니다.\n✅ 복잡한 프롬프트 지식의 간소화: Underwood의 전문적인 프롬프트를 앱 하나로 쉽게 구현할 수 있습니다.\n✅ 직관적인 워크플로우: 이미지 업로드, 스토리보드 생성, JSON 프롬프트 복사만으로 영상 제작이 가능합니다.\n영상 제작의 미래, AI 스토리보드 앱과 함께라면 여러분도 전문가가 될 수 있습니다.\n❓ 자주 묻는 질문 (FAQ)\nQ1: '시네마틱 스토리보드 AI' 앱은 어떤 AI 모델을 지원하나요?\n이 앱은 기본적으로 Nano Banana Pro를 통해 고품질 이미지를 생성하며, 생성된 스토리보드와 JSON 프롬프트는 Sora 2.0과 VEO 3.1을 포함한 다양한 AI 비디오 생성 모델에서 활용할 수 있도록 설계되었습니다. 앱 내에서 사용하실 모델을 직접 선택할 수 있습니다.\nQ2: 비전문가도 이 앱을 통해 프로페셔널한 영상을 만들 수 있나요?\n네, 물론입니다! Underwood의 복잡한 영화적 프롬프트 지식을 앱이 자동으로 처리해주기 때문에, 사용자는 레퍼런스 이미지 하나만으로도 고품질의 9컷 스토리보드를 얻고, 이를 기반으로 전문가 수준의 영상을 손쉽게 제작할 수 있습니다. 별도의 영상 편집 기술이나 AI 프롬프트 지식이 없어도 가능합니다.\nQ3: 앱을 사용하려면 API 키가 반드시 필요한가요?\n네, Nano Banana Pro와 같은 이미지 생성 AI 모델을 사용하기 위해서는 해당 서비스의 API 키 등록이 필수입니다. 앱 실행 후 안내에 따라 API 키를 등록하고 연결 테스트를 완료해야 앱의 모든 기능을 원활하게 사용할 수 있습니다. 정확한 등록 방법은 관련 안내 영상을 참고해 주세요.\n여러분, 보셨죠? 이미지 하나만 업로드하면 아홉 컷 스토리보드부터 JSON 프롬프트까지 자동으로 생성되고, Sora 2.0이든 VEO 3.1이든 원하는 AI 모델에 붙여넣기만 하면 전문가 수준의 영상이 뚝딱 완성됩니다. X에 공유된 수백 줄짜리 프롬프트 지식을 이제는 버튼 클릭 한 번으로 활용하는 시대가 온 거죠. 30분 걸리던 작업이 1분으로 단축되는 이 놀라운 변화, 이게 바로 2025년 '바이브 코딩 시대'가 가져다준 혁신입니다.\n  시네마틱 스토리보드 AI  무료 사용하기\n'시네마틱 스토리보드 AI'은 무료로 사용이 가능하나 나노바나나(프로) 사용에는 여러분의 API KEY 를 사용해야하며, 이때 과금이 발생하니 참고하세요.\n\n \nCinematic Storyboard AI\n \ncinematic-storyboard-ai.vercel.app",
        "guid": "https://muzbox.tistory.com/483688",
        "categories": [
          "AI, 미래기술/AI 챗봇 및 지침 무료 배포",
          "15초 영상 제작",
          "AI 스토리보드 앱",
          "ai 영상 편집",
          "AI 크리에이티브 툴",
          "Nano Banana Pro",
          "Sora 2.0",
          "Underwood 프롬프트",
          "VEO 3.1",
          "바이브 코딩 시대",
          "영상 제작 시간 단축"
        ],
        "isoDate": "2025-12-08T03:42:42.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "왕초보를 위한 AI 필수 용어 완벽 가이드",
        "link": "https://muzbox.tistory.com/483687",
        "pubDate": "Sun, 7 Dec 2025 12:07:13 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "https://muzbox.tistory.com/483687#entry483687comment",
        "content": "<div style=\"font-family: 'Noto Sans KR', sans-serif; line-height: 1.6; max-width: 800px; margin: 0 auto; font-size: 16px; box-sizing: border-box; color: #3c4043;\">\n<div style=\"background-color: #e8f4fd; padding: 15px; border-radius: 8px; font-style: italic; margin-bottom: 25px; font-size: 15px; color: #3c4043;\">&nbsp;\"나만 AI 몰라?\"라는 생각에 불안하신가요? LLM, 할루시네이션, 프롬프트... 복잡한 용어들 때문에 AI 시작이 두렵다면 이 가이드를 주목하세요. 왕초보도 30분 만에 AI 핵심 용어를 완벽하게 이해하고 디지털 포모(FOMO)를 극복할 수 있도록, 지피티팍이 쉽고 친절하게 설명해드립니다. 지금 바로 AI 세상으로 함께 떠나보시죠!</div>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">\"나만 AI 몰라?\" 이런 불안감에 잠 못 이루는 분들이 많으실 거예요. 주변에서는 다들 챗GPT다, 제미나이다 하는데, 막상 시작하려니 LLM은 뭐고, 토큰은 또 뭔지... 용어의 벽에 부딪혀 막막함을 느끼실 수 있습니다. 솔직히 저도 처음엔 그랬어요. 특히 AI가 낯선 초보자분들, 그리고 컴퓨터 사용이 익숙지 않은 시니어분들이라면 더욱 어렵게 느껴질 수 있죠.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">하지만 괜찮습니다! 오늘 딱 30분만 투자하면 AI가 완전히 다르게 보일 거예요. 이 블로그 포스트는 바로 여러분을 위해 준비했어요. 나이나 컴퓨터 실력은 전혀 상관없습니다. 제가 여러분의 눈높이에 맞춰 가장 쉬운 말로만 설명해드릴 테니, 편안하게 따라오세요.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"1200\"><span data-url=\"https://blog.kakaocdn.net/dn/boj2S9/dJMcafkNzGp/uAATE1zBaQnBZAHw6ypPEK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/boj2S9/dJMcafkNzGp/uAATE1zBaQnBZAHw6ypPEK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/boj2S9/dJMcafkNzGp/uAATE1zBaQnBZAHw6ypPEK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fboj2S9%2FdJMcafkNzGp%2FuAATE1zBaQnBZAHw6ypPEK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"따뜻하고 미래적인 공간에서 다양한 연령대의 사람들이 친근한 AI 인터페이스를 통해 인공지능 용어를 배우고 이해하며 디지털 포모를 극복하는 모습.\" loading=\"lazy\" width=\"600\" height=\"600\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"1200\"/></span></figure>\n\n<div style=\"margin-top: 30px;\">&nbsp;</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  AI, 왜 시작이 어려울까요? 2025년 디지털 포모(FOMO)의 그림자</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">많은 분들이 AI를 시작하기 어려워하는 데는 몇 가지 이유가 있습니다. 특히 컴퓨터에 익숙하지 않은 분들은 더욱 크게 공감하실 텐데요.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">첫 번째 이유는 바로 <b>디지털 포모(Digital FOMO)</b> 때문입니다. FOMO는 'Fear Of Missing Out'의 약자로, \"나만 뒤처지는 것 같은 불안감\"을 의미해요. 2025년 현재, 뉴스나 유튜브, 심지어 회사에서도 AI 얘기가 끊이지 않죠. 주변에서 다들 챗GPT를 쓴다는데 나만 못하는 것 같아 조급하고 불안한 마음, 솔직히 저도 느껴봤습니다. 하지만 괜찮습니다. 지금 시작하는 것만으로도 충분히 빠르다고 생각해요. \"빨리 배워야 하는데...\" 하는 조급함이 오히려 제대로 배우는 것을 방해할 수 있으니, 차분하게 시작하는 것이 중요합니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">두 번째 이유는 바로 <b>어려운 용어의 장벽</b>입니다. AI, LLM, 프롬프트, 토큰, 멀티모달... 이런 단어들을 들으면 마치 외계어처럼 느껴져 머리가 지끈거릴 수 있습니다. 솔직히 말하면 저도 처음에는 'LLM? 엘엘엠? 래퍼 이름인가?' 하고 생각했던 기억이 나네요. 이 용어의 장벽만 넘어서면 AI는 훨씬 쉬워진답니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">세 번째는 <b>어디서부터 시작해야 할지 모른다는 막막함</b>입니다. 챗GPT, 클로드, 제미나이 등 종류가 너무 많아서 뭘 써야 할지 감이 안 잡히실 거예요. 마치 맛있는 치킨집이 너무 많아서 어디에 시켜야 할지 고민되는 것과 비슷하다고 할까요?</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">마지막 네 번째는 <b>질문을 어떻게 해야 할지 모른다는 점</b>입니다. AI에게 \"글 써줘\"라고만 하면 엉뚱한 답이 나오기 일쑤죠. 답답한 마음에 \"너 왜 이래?\" 하고 AI에게 화를 내봤자, AI는 감정이 없으니 계속 이상한 답만 내놓을 뿐입니다.</p>\n<div style=\"background-color: #e8f4fd; border-left: 4px solid #1a73e8; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0; color: #3c4043;\">  <b>이 포스트가 여러분의 불안감을 해소해 드립니다!</b> 오늘 'AI 필수 용어 완벽 가이드'를 통해 어려운 용어들을 일상 언어로 쉽게 풀어 설명해드릴게요. 용어만 알아도 AI 정복의 절반은 이뤄냈다고 볼 수 있습니다!</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  AI 왕초보를 위한 핵심 용어 16가지 완벽 정리!</b></h2>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px;\" data-ke-size=\"size23\"><b>1. AI (Artificial Intelligence): 인공지능</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">가장 먼저, <b>AI</b>는 쉽게 말해 <b>사람처럼 생각하고 대답할 수 있는 컴퓨터 프로그램</b>입니다. 마치 똑똑한 비서를 컴퓨터 안에 넣어둔 것과 같다고 생각하시면 돼요. 그것도 24시간 내내 일하고, 월급도 휴가도 필요 없는 완벽한 비서죠. 물론 가끔 엉뚱한 소리도 하긴 하지만 말입니다.</p>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px;\" data-ke-size=\"size23\"><b>2. LLM (Large Language Model): 대규모 언어 모델</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>LLM</b>은 한국어로 <b>대규모 언어 모델</b>이라고 부릅니다. 이건 쉽게 설명하자면, <b>엄청나게 많은 책과 인터넷 글을 읽고 학습한 AI</b>를 뜻해요. 'AI'가 '과일'이라는 큰 개념이라면, 'LLM'은 그 안의 '사과'처럼 언어에 특화된 특정 AI를 지칭합니다. 우리가 흔히 아는 챗GPT, 클로드, 제미나이가 바로 이 LLM에 속하죠. 마치 지구상의 모든 도서관 책을 다 읽어버린 초특급 독서광 AI라고 생각하시면 됩니다. 여기서 중요한 점은 LLM이 단순히 저장된 답변을 보여주는 게 아니라, 여러분의 질문을 이해하고 새로운 답변을 스스로 만들어낸다는 거예요. 네이버 지식인처럼 누가 써놓은 답을 복사 붙여넣기 하는 것이 아니라, 실시간으로 생각해서 답을 만들어내는 거죠!</p>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px;\" data-ke-size=\"size23\"><b>3. SLM (Small Language Model): 소형 언어 모델</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">LLM이 대형 트럭이라면, <b>SLM</b>은 <b>경차</b>에 비유할 수 있습니다. 작지만 가볍고 빠르다는 장점이 있죠. SLM은 LLM과 똑같은 방식으로 작동하지만, 크기를 확 줄인 모델이에요. 파라미터 수를 줄이거나 모델 압축 기술을 사용해서 효율성을 높입니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">가장 큰 차이는 <b>작동 위치</b>에 있습니다. 일반적인 LLM은 여러분이 질문하면 인터넷을 통해 멀리 떨어진 서버로 보내져 처리되고 답변이 돌아오죠. 마치 해외 본사에 전화해서 답변받는 것처럼 인터넷 연결이 필수예요. 하지만 SLM은 <b>여러분의 PC에 직접 설치되어 작동</b>합니다. 질문하면 컴퓨터의 CPU나 그래픽카드가 바로 처리해서 답변을 주기 때문에 인터넷 없이도 작동하고, 개인 정보가 외부로 나가지 않아 보안에도 강하죠. 물론 성능은 LLM보다 낮지만, 문서 요약, 간단한 번역, 메모 정리 같은 일상적인 작업에는 충분하고, 무엇보다 <b>무료로 사용할 수 있다</b>는 큰 장점이 있습니다.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/cMJu2M/dJMcafE6lpU/2kkldV8jnIIJGlAEKvhQOK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/cMJu2M/dJMcafE6lpU/2kkldV8jnIIJGlAEKvhQOK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/cMJu2M/dJMcafE6lpU/2kkldV8jnIIJGlAEKvhQOK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcMJu2M%2FdJMcafE6lpU%2F2kkldV8jnIIJGlAEKvhQOK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"LLM의 클라우드 기반 대규모 처리와 SLM의 개인 PC 기반 로컬 처리 방식을 시각적으로 비교하는 인포그래픽.\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px;\" data-ke-size=\"size23\"><b>4. 챗봇 &amp; GPTs/Gems &amp; Projects: AI 활용의 두 가지 방식</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>챗봇</b>은 채팅하듯이 대화할 수 있는 AI 프로그램입니다. 챗GPT의 '챗'이 바로 이 챗봇을 의미하죠. 그런데 여기서 <b>맞춤형 챗봇(GPTs/Gems)</b>과 <b>프로젝트 기능</b>이라는 두 가지 중요한 개념을 구분해야 해요. 둘 다 AI를 내 방식대로 쓰는 것이지만, 목적이 완전히 다릅니다. 쉽게 말해 \"너 누구야?\"라고 묻는 것과 \"이 일에 대해 어떻게 생각해?\"라고 묻는 것의 차이랄까요?</p>\n<h4 style=\"font-size: 17px; color: #004d99; margin: 15px 0 10px;\" data-ke-size=\"size20\"><b>✅ GPTs와 Gems: 나만의 전문 AI 비서 만들기 (누구냐?)</b></h4>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>GPTs</b>는 챗GPT에서 제공하는 맞춤형 챗봇 만들기 기능이에요. 'G'는 GPT의 G, 's'는 복수형을 의미합니다. 여러 개 만들 수 있다는 뜻이죠. 이건 특정 역할을 하는 전문 AI를 만드는 겁니다. 마치 전문 직업을 가진 직원을 여러 명 고용하는 것처럼요. 예를 들어, \"너는 세계 최고의 요리 전문가야\"라고 역할을 정의하고 상세 지침을 제공하면, 이후에 \"파스타 소스 비법 알려줘!\"라고 물을 때 요리 전문가답게 답변하는 식입니다. 한 번 만들어두면 매번 설명할 필요 없이 그 역할로 계속 작동하죠. 구글 제미나이에서 제공하는 <b>Gems</b>도 이름만 다를 뿐 완전히 동일한 개념이에요.</p>\n<div style=\"background-color: #e8f4fd; border-left: 4px solid #1a73e8; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0; color: #3c4043;\">  <b>예시:</b> 요리 전문가 GPT, 번역 전문가 GPT, 법률 상담 GPT 등 나만의 전문가 팀을 만들 수 있어요.</div>\n<h4 style=\"font-size: 17px; color: #004d99; margin: 15px 0 10px;\" data-ke-size=\"size20\"><b>✅ Projects: 작업 단위로 대화와 파일 관리하기 (무엇을 하느냐?)</b></h4>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>프로젝트</b>는 작업 단위로 대화와 파일을 묶어서 관리하는 기능입니다. 회사에서 A 프로젝트와 B 프로젝트를 동시에 진행한다고 할 때, A 프로젝트 관련 대화, 문서, 자료를 한곳에 모아두고, B 프로젝트 것들은 따로 모아두는 식이죠. 마치 프로젝트별로 폴더를 만드는 것과 같아요. 프로젝트의 핵심은 바로 <b>'맥락 유지'</b>입니다. \"마케팅 프로젝트\" 폴더 안에서 대화하면 AI가 그 프로젝트의 모든 이전 대화와 파일을 기억해요. 어제 업로드한 시장 분석 보고서 PDF를 기억해서, 오늘 같은 폴더에서 \"어제 올린 자료 기반으로 요약해줘\"라고만 해도 AI가 알아서 찾아 요약해줍니다. 챗GPT Projects와 클로드 Projects도 동일한 기능입니다.</p>\n<table style=\"width: 100%; border-collapse: collapse; margin: 25px 0; font-size: 15px;\" data-ke-align=\"alignLeft\">\n<thead>\n<tr>\n<th style=\"border: 1px solid #dadce0; padding: 12px; background-color: #e8eaed; text-align: center; color: #3c4043;\">구분</th>\n<th style=\"border: 1px solid #dadce0; padding: 12px; background-color: #e8eaed; text-align: center; color: #3c4043;\">GPTs / Gems</th>\n<th style=\"border: 1px solid #dadce0; padding: 12px; background-color: #e8eaed; text-align: center; color: #3c4043;\">Projects</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"border: 1px solid #dadce0; padding: 12px; background-color: #f8f9fa; color: #3c4043;\"><b>목적</b></td>\n<td style=\"border: 1px solid #dadce0; padding: 12px; background-color: #f8f9fa; color: #3c4043;\">특정 역할 수행 AI 제작</td>\n<td style=\"border: 1px solid #dadce0; padding: 12px; background-color: #f8f9fa; color: #3c4043;\">특정 작업의 대화/파일 통합 관리</td>\n</tr>\n<tr>\n<td style=\"border: 1px solid #dadce0; padding: 12px; background-color: #f1f3f4; color: #3c4043;\"><b>지속성</b></td>\n<td style=\"border: 1px solid #dadce0; padding: 12px; background-color: #f1f3f4; color: #3c4043;\">한 번 만든 역할이 모든 대화에서 유지</td>\n<td style=\"border: 1px solid #dadce0; padding: 12px; background-color: #f1f3f4; color: #3c4043;\">해당 프로젝트 내에서만 맥락 유지</td>\n</tr>\n<tr>\n<td style=\"border: 1px solid #dadce0; padding: 12px; background-color: #f8f9fa; color: #3c4043;\"><b>핵심</b></td>\n<td style=\"border: 1px solid #dadce0; padding: 12px; background-color: #f8f9fa; color: #3c4043;\">AI의 '정체성' 정의</td>\n<td style=\"border: 1px solid #dadce0; padding: 12px; background-color: #f8f9fa; color: #3c4043;\">작업의 '맥락' 보존</td>\n</tr>\n</tbody>\n</table>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px;\" data-ke-size=\"size23\"><b>5. 토큰 (Token): AI 언어 처리의 기본 단위</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>토큰</b>은 <b>AI가 글자를 처리할 때 사용하는 기본 단위</b>입니다. 레고 블록을 생각해보세요. 긴 문장을 작은 조각으로 쪼개서 이해하는데, 그 조각 하나가 바로 토큰인 거죠. 왜 중요하냐고요? AI 사용량이 이 토큰 단위로 제한되기 때문입니다. 무료 버전은 하루에 몇 천 토큰까지 쓸 수 있다, 이런 식이에요. 마치 핸드폰 데이터 요금처럼 말이죠. 그래서 너무 긴 질문이나 답변은 토큰을 많이 소모한다는 것만 기억하시면 됩니다. 보통 한국어 글자 한 자가 토큰 한 개 정도라고 보시면 편해요. 하지만 '안녕하세요'처럼 자주 쓰는 말은 AI가 통째로 기억해서 1~2개 토큰으로 아주 싸게 처리하니, 토큰 걱정 너무 하지 말고 편하게 쓰셔도 좋습니다.</p>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px;\" data-ke-size=\"size23\"><b>6. 컨텍스트 (Context): AI의 대화 기억력</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>컨텍스트</b>는 <b>AI가 대화의 흐름을 기억하는 능력</b>을 말합니다. 예를 들어, 여러분이 \"사과에 대해 알려줘\"라고 물어 AI가 과일 사과를 설명했어요. 그다음에 \"가격은?\"이라고만 물어봐도 AI는 \"아, 사과 가격을 묻는구나\" 하고 알아듣죠. 이게 바로 컨텍스트를 이해한다는 겁니다. 마치 친구와 대화할 때 앞뒤 맥락을 다 기억하고 있는 것처럼요. AI마다 기억할 수 있는 대화의 길이가 다른데, 클로드나 제미나이 같은 모델은 특히 긴 대화를 잘 기억하는 편입니다. 마치 토씨 하나 안 틀리는 꼼꼼한 비서 같달까요? 하지만 대화가 너무 길어져서 AI의 '기억 용량'이 꽉 차면 이전 기억을 지울 수도 있어요. 이럴 땐 처음부터 다시 설명해주는 것이 가장 정확합니다. AI도 가끔 건망증이 있답니다.</p>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px;\" data-ke-size=\"size23\"><b>7. 지식 단절 시점 (Knowledge Cutoff Date): AI의 시공간 제약</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이건 정말 중요해요! <b>지식 단절 시점</b>은 <b>AI가 특정 날짜까지의 정보만 알고 있다는 것</b>을 의미합니다. 그 이후의 정보는 모르는 거죠. 예를 들어, 챗GPT가 2024년 10월까지 학습했다면, 2024년 11월 이후의 일은 전혀 모릅니다. 마치 타임캡슐에 갇혀 2024년 10월에 잠들었다가 지금 깨어난 사람이라고 생각하시면 됩니다. 그래서 \"어제 뉴스\"나 \"지금 주식 시장 상황\"을 물어보면 AI는 모른다고 답할 수밖에 없어요. 이럴 때는 웹 검색 기능이 있는 AI를 사용하거나, \"웹 검색해서 알려줘\"라고 명확하게 요청해야 합니다. AI가 \"그 정보는 모릅니다\"라고 하면 화내지 마세요. 정말로 모르는 겁니다. 학습 데이터에 없으니까요!</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/dTC397/dJMcadAsLU6/jKjzGk9WM2m5mvGNsTfJhk/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/dTC397/dJMcadAsLU6/jKjzGk9WM2m5mvGNsTfJhk/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/dTC397/dJMcadAsLU6/jKjzGk9WM2m5mvGNsTfJhk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdTC397%2FdJMcadAsLU6%2FjKjzGk9WM2m5mvGNsTfJhk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"2024년 10월로 표시된 지식 단절 시점 이후의 정보는 알 수 없음을 표현한 시간표 이미지.\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px;\" data-ke-size=\"size23\"><b>8. 멀티모달 (Multimodal): 오감으로 소통하는 AI</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>멀티모달</b>은 <b>AI가 글자뿐만 아니라 사진, 음성, 영상 등 다양한 형식의 정보도 이해할 수 있다는 뜻</b>입니다. 예전 AI는 글로만 대화했지만, 이제는 사진을 올리면 설명해주고, 음성으로 질문하면 음성으로 답하며, 영상도 분석할 수 있어요. 마치 오감이 다 있는 사람처럼 보고, 듣고, 말할 수 있는 AI가 된 거죠. 이제는 \"이게 뭐야?\" 하면서 사진만 찍어 올려도 알아서 설명해줍니다. 저는 가끔 냉장고 사진 찍어서 \"오늘 저녁 뭐 해먹지?\" 하고 물어보는데 정말 편하답니다!</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">AI에 올릴 수 있는 파일들은 정말 다양해요. 파일 이름 끝에 붙는 몇 글자, 즉 <b>확장자</b>가 그 파일이 어떤 종류인지 알려주는 역할을 합니다. 마치 사람의 성씨처럼 파일을 구분하는 거죠.</p>\n<ul style=\"list-style-type: disc; margin-left: 20px; margin-bottom: 20px; color: #3c4043;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 8px;\"><b>문서 파일:</b> PDF (계약서, 보고서 요약), TXT (순수 텍스트), CSV (표 형태 데이터 분석), DOCX (워드 문서), MD (마크다운)</li>\n<li style=\"margin-bottom: 8px;\"><b>이미지 파일:</b> JPG/JPEG (사진), PNG (투명 배경), GIF (움직이는 이미지), WebP (고화질 경량 이미지)</li>\n<li style=\"margin-bottom: 8px;\"><b>오디오 파일:</b> MP3 (음악, 회의 녹음 텍스트 변환), WAV (고음질 오디오), M4A (애플 기기 오디오)</li>\n<li style=\"margin-bottom: 8px;\"><b>비디오 파일:</b> MP4 (가장 흔한 동영상), MOV (아이폰 동영상), AVI (옛날 동영상), WebM (웹 동영상)</li>\n<li style=\"margin-bottom: 8px;\"><b>프로그래밍 소스 파일:</b> PY (파이썬), JS (자바스크립트), HTML (웹페이지 코드)</li>\n</ul>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이런 파일들을 AI에게 올리고 \"이 코드가 무슨 일을 하는지 설명해줘\"라고 묻는 등, 프로그래밍을 모르는 분들도 AI의 도움을 받아 복잡한 코드를 쉽게 이해할 수 있습니다.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/dQwYft/dJMcaaX50kd/wJv1wJtLRBvZNjdJxQu0Nk/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/dQwYft/dJMcaaX50kd/wJv1wJtLRBvZNjdJxQu0Nk/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/dQwYft/dJMcaaX50kd/wJv1wJtLRBvZNjdJxQu0Nk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdQwYft%2FdJMcaaX50kd%2FwJv1wJtLRBvZNjdJxQu0Nk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"문서, 사진, 음성, 영상 등 다양한 형식의 데이터가 AI로 입력되는 모습을 시각화하여 멀티모달 AI의 이해를 돕는 이미지.\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px;\" data-ke-size=\"size23\"><b>9. API (Application Programming Interface): 프로그램들의 대화 통로</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>API</b>는 <b>프로그램들이 서로 대화하는 통로</b>를 말합니다. 쉽게 말해 AI를 다른 앱이나 웹사이트에 연결하는 방법이에요. 여러분이 사용하는 어떤 앱에서 \"AI로 답장 작성\" 버튼을 누르면, 그 앱이 챗GPT API를 사용해서 챗GPT와 연결되어 있는 겁니다. 마치 두 프로그램이 전화 통화하는 것처럼요. 과거에는 개발자가 아니라면 직접 사용할 일이 거의 없었지만, 바야흐로 '바이브 코딩' 시대에는 누구나 쉽게 AI를 활용하여 코딩하고 API를 사용할 수 있게 되었습니다.</p>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px;\" data-ke-size=\"size23\"><b>10. MCP (Model Context Protocol): AI와 도구 연결의 표준</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>MCP</b>는 <b>Model Context Protocol</b>의 약자로, AI가 여러 도구들을 사용할 수 있도록 연결해주는 <b>표준 규격</b>입니다. 마치 여러 기기를 연결하는 USB 단자처럼, MCP는 AI와 다양한 서비스를 연결하는 표준이라고 생각하시면 돼요. 예를 들어 MCP를 사용하면 클로드 같은 LLM이 구글 드라이브, 노션, 슬랙 같은 여러 서비스에 직접 접근해서 \"구글 드라이브에 있는 파일 찾아서 요약해줘\"처럼 한 번에 작업을 수행할 수 있죠. 아직 초보자가 직접 설정하기는 어렵지만, \"AI가 여러 서비스를 연결해서 쓸 수 있구나\" 정도만 알아두셔도 충분합니다. 앞으로 점점 더 많이 사용될 중요한 기술이랍니다.</p>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px;\" data-ke-size=\"size23\"><b>11. RAG (Retrieval-Augmented Generation): 똑똑한 오픈북 AI</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>RAG</b>는 <b>Retrieval-Augmented Generation</b>, 즉 <b>검색 증강 생성</b>이라는 뜻인데요. 어렵게 들리지만 쉽게 말하면, <b>AI가 답변할 때 자기가 아는 것만으로 대답하는 게 아니라, 필요한 정보를 먼저 찾아보고 그걸 바탕으로 답변하는 방식</b>입니다. 마치 오픈북 시험을 보는 것과 같아요. 모든 걸 외우지 않아도 책을 찾아보면서 답을 쓸 수 있잖아요? RAG가 바로 그런 원리입니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">여러분이 회사 문서를 AI에게 주고 \"우리 회사 휴가 정책이 뭐야?\"라고 물어본다고 가정해볼게요. RAG 방식의 AI는 먼저 여러분이 준 문서에서 휴가 관련 부분을 찾아보고, 그 내용을 바탕으로 답변을 만듭니다. 그냥 AI가 상상해서 답하는 게 아니라 실제 문서를 참고하기 때문에 훨씬 정확하고 신뢰할 수 있는 답변을 받을 수 있죠. 특히 회사 업무나 전문 분야에서 AI가 엉뚱한 답변을 지어내지 않고 실제 자료를 기반으로 답하게 하는 데 정말 유용합니다. Notebook LM 같은 서비스가 바로 이 RAG 방식을 사용하고 있어요.</p>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px;\" data-ke-size=\"size23\"><b>12. 마크다운(Markdown) &amp; JSON: AI와 효율적으로 대화하는 비법</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">자, 이제 정말 중요한 용어 두 가지를 알려드릴게요. <b>마크다운과 JSON</b>입니다. 이 두 가지를 알면 AI 활용 효율이 3배는 올라간다고 장담할 수 있어요!</p>\n<h4 style=\"font-size: 17px; color: #004d99; margin: 15px 0 10px;\" data-ke-size=\"size20\"><b>✅ 마크다운 (Markdown): 간단한 기호로 예쁜 문서 만들기</b></h4>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>마크다운</b>은 <b>간단한 기호로 문서를 예쁘게 꾸미는 방법</b>입니다. 샵(#) 기호를 쓰면 제목이 되고, 대시(-) 기호를 쓰면 목록이 되고, 별표 두 개(**)로 감싸면 굵은 글씨가 되죠. 노션, 깃허브 등에서 많이 사용하고 있으며, 워드처럼 마우스 클릭 없이 키보드만으로 뚝딱 깔끔한 문서를 만들 수 있어요.</p>\n<h4 style=\"font-size: 17px; color: #004d99; margin: 15px 0 10px;\" data-ke-size=\"size20\"><b>✅ JSON (JavaScript Object Notation): 데이터를 구조화하여 정리하기</b></h4>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>JSON</b>은 <b>데이터를 구조화해서 저장하는 형식</b>이에요. 중괄호({})와 대괄호([])를 사용해서 데이터를 항목과 값으로 명확하게 정리합니다. 프로그래밍에서 주로 쓰이지만, 일반인도 알면 정말 유용해요. 엑셀 데이터를 텍스트로 옮긴 것 같다고 생각하시면 됩니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>여기서 중요한 건, 이 형식들을 AI에게 질문할 때 활용하면 답변 품질이 확 올라간다는 거예요!</b> 그냥 일반 대화체로 질문하면 AI가 중간에 정보를 놓칠 수도 있습니다. 하지만 마크다운이나 JSON으로 구조화해서 질문하면 AI가 모든 조건을 명확하게 파악하고 정확히 처리하죠. 조건이 복잡할수록 효과는 더욱 커집니다.</p>\n<div style=\"background-color: #e8f4fd; border-left: 4px solid #1a73e8; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0; color: #3c4043;\">  <b>실전 꿀팁: 언제 어떤 형식을 쓸까요?</b><br />\n<ul style=\"list-style-type: none; padding-left: 0; margin-top: 10px;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 5px;\"><b>일상 대화체:</b> 간단한 질문, 빠르게 답변받고 싶을 때 (\"오늘 저녁 뭐 먹을까?\")</li>\n<li style=\"margin-bottom: 5px;\"><b>마크다운:</b> 문서, 보고서 작성할 때 (\"회의록을 마크다운으로 작성해줘\")</li>\n<li style=\"margin-bottom: 5px;\"><b>JSON:</b> 여러 항목 비교, 데이터 분석, 복잡한 조건 제시할 때 (\"상품 10개를 조건별로 비교 분석해줘\")</li>\n</ul>\n처음엔 일상 대화체로 물어보고, 답변이 마음에 들면 \"이거 마크다운으로 다시 정리해줘\" 또는 \"JSON으로 변환해줘\"라고 추가 요청하는 것도 아주 유용한 방법입니다!</div>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px;\" data-ke-size=\"size23\"><b>13. 프롬프트 (Prompt): AI에게 하는 질문과 명령</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>프롬프트</b>는 <b>AI에게 하는 질문이나 명령</b>을 말합니다. 쉽게 말해 여러분이 AI에게 타이핑하는 모든 문장이 프롬프트예요. \"오늘 날씨 어때?\"도 프롬프트고, \"이 코드 설명해줘\"도 프롬프트죠. 왜 이 용어가 중요하냐면, <b>AI 활용의 90%가 프롬프트를 잘 쓰느냐에 달려 있기 때문입니다.</b> 같은 AI를 써도 프롬프트를 어떻게 쓰느냐에 따라 결과가 천지 차이죠. 마치 검색엔진에서 검색어를 잘 쓰는 것이 중요한 것처럼 말입니다. \"글 써줘\"는 나쁜 프롬프트지만, \"블로그용 AI 활용 팁 글을 초보자 대상으로 1000자로 써줘\"는 구체적인 좋은 프롬프트예요. 프롬프트를 잘 쓰는 기술을 <b>'프롬프트 엔지니어링'</b>이라고 하는데, 이건 다음 시리즈에서 더 자세히 다룰 예정입니다.</p>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px;\" data-ke-size=\"size23\"><b>14. 온도 (Temperature): AI 답변의 창의성 조절</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>온도</b>는 실제 온도와는 상관없이 <b>AI 답변의 창의성을 조절하는 설정값</b>입니다. 온도가 낮으면 AI가 안전하고 예측 가능한, 교과서 같은 답변을 내놓아요. 반대로 온도가 높으면 AI가 더 창의적이고 다양한 답변을 생성하지만, 가끔 엉뚱한 소리도 할 수 있죠. 마치 자유로운 예술가처럼요. 보통 온도는 0에서 1 사이의 값으로 설정되는데, 0에 가까울수록 \"정확하게만 답해줘, 창의력은 필요 없어\", 1에 가까울수록 \"자유롭게 상상해서 답해줘\"라는 의미로 이해할 수 있습니다. 예를 들어, \"회의록 작성해줘\"라고 할 때는 온도를 낮게, \"광고 카피 아이디어 10개 줘\"라고 할 때는 온도를 높게 설정하는 것이 효과적입니다. 대부분의 AI 서비스에서는 직접 온도를 조절할 수는 없지만, 프롬프트에 \"창의적으로 답해줘\" 또는 \"정확하게만 답해줘\"라고 명시하면 비슷한 효과를 낼 수 있답니다.</p>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px;\" data-ke-size=\"size23\"><b>15. 할루시네이션 (Hallucination): AI의 그럴듯한 거짓말</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>할루시네이션</b>은 <b>AI가 거짓말을 하거나 사실이 아닌 정보를 그럴듯하게 지어내는 현상</b>을 말합니다. 환각이라고도 하죠. 중요한 건 AI가 일부러 거짓말하는 것이 아니라는 점이에요. AI는 '이것이 사실인지 아닌지'를 구분하지 못하고, 그저 학습된 데이터를 바탕으로 가장 그럴듯한 답변을 만들어낼 뿐입니다. 마치 시험 볼 때 모르는 문제를 대충 그럴듯하게 쓰는 것과 비슷하다고 할까요?</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">예를 들어, AI에게 \"2024년 노벨 물리학상 수상자는?\"이라고 물었을 때, AI가 존재하지 않는 '존 스미스 박사'를 자신 있게 말할 수도 있어요. 더 무서운 건, AI가 거짓말하는 것처럼 보이지 않는다는 겁니다. 엄청 자신 있고 구체적으로, 심지어 논문 제목까지 지어내면서 설명하기 때문에 초보자분들이 쉽게 속을 수 있습니다.</p>\n<div style=\"background-color: #fce8e6; border-left: 4px solid #d93025; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0; color: #3c4043;\">⚠️ <b>할루시네이션 방지법:</b><br />\n<ul style=\"list-style-type: none; padding-left: 0; margin-top: 10px;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 5px;\"><b>출처 요청:</b> \"출처와 함께 알려줘\"라고 명시하기</li>\n<li style=\"margin-bottom: 5px;\"><b>팩트체크:</b> 중요한 정보는 반드시 검색으로 확인하기</li>\n<li style=\"margin-bottom: 5px;\"><b>구체적 질문:</b> 모호한 질문보다 구체적으로 물어보기</li>\n<li style=\"margin-bottom: 5px;\"><b>최신 정보 주의:</b> 지식 단절 시점 이후 정보는 항상 의심하기</li>\n<li style=\"margin-bottom: 5px;\"><b>웹 검색 기능 사용:</b> AI에게 \"웹 검색해서 알려줘\"라고 요청하기</li>\n</ul>\n특히 의학, 법률, 금융과 같은 중요한 분야에서는 AI 답변을 100% 신뢰하지 마시고, 반드시 전문가나 공식 자료로 재확인해야 합니다.</div>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px;\" data-ke-size=\"size23\"><b>16. AGI (Artificial General Intelligence): 사람처럼 모든 것을 하는 AI</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">마지막 용어는 <b>AGI</b>, 즉 <b>범용 인공지능</b>입니다. 이건 <b>사람처럼 모든 것을 스스로 학습하고 판단할 수 있는 AI</b>를 말해요. 지금 우리가 사용하는 챗GPT나 클로드 같은 AI는 특정 작업만 잘하는 '전문가' AI입니다. 하지만 AGI는 '천재'에 가깝죠. 뭐든 배우고 응용할 수 있는 완전한 형태의 AI라고 할 수 있습니다. 현재 AGI는 아직 존재하지 않아요. 언제 나올지도 미지수이며, 전문가들 사이에서도 \"5년 안에 나온다\", \"50년 걸린다\", 심지어 \"영원히 불가능하다\" 등 다양한 의견이 분분합니다. AGI가 등장하면 세상이 완전히 뒤바뀔 것이기에, AI 뉴스에서 이 단어가 자주 언급되는 것이랍니다. \"아, 완전한 AI를 말하는 거구나\" 정도로만 이해해두시면 충분합니다.</p>\n<div style=\"background-color: #f8f9fa; border: 1px solid #dadce0; border-radius: 8px; box-shadow: 0 4px 12px rgba(0,0,0,0.1); padding: 25px; margin: 40px 0;\">\n<div style=\"font-size: 26px; color: #1a73e8; font-weight: bold; margin-bottom: 15px; padding-bottom: 10px; border-bottom: 2px solid #1a73e8;\">  <b>핵심 요약</b></div>\n<ul style=\"list-style-type: none; padding-left: 0; margin-bottom: 20px;\" data-ke-list-type=\"disc\">\n<li style=\"font-size: 17px; margin-bottom: 15px; line-height: 1.5; color: #3c4043;\"><b>AI의 기본 이해:</b> AI는 사람처럼 생각하고 대화하는 컴퓨터 프로그램이며, LLM은 언어에 특화된 대규모 AI, SLM은 작지만 빠르고 개인 PC에서 작동하는 AI입니다.</li>\n<li style=\"font-size: 17px; margin-bottom: 15px; line-height: 1.5; color: #3c4043;\"><b>AI 활용 방식의 이해:</b> GPTs/Gems는 AI의 '역할'을 정해 전문 비서를 만드는 것이고, Projects는 특정 '작업 맥락'을 유지하며 효율적으로 대화와 파일을 관리하는 기능입니다.</li>\n<li style=\"font-size: 17px; margin-bottom: 15px; line-height: 1.5; color: #3c4043;\"><b>AI 소통의 기술:</b> 토큰, 컨텍스트, 프롬프트의 개념을 이해하고 마크다운/JSON과 같은 구조화된 질문 방식을 활용하면 AI와 훨씬 효율적으로 소통할 수 있습니다.</li>\n<li style=\"font-size: 17px; margin-bottom: 0; line-height: 1.5; color: #3c4043;\"><b>AI 활용 시 주의점:</b> AI는 특정 시점까지의 정보만 알고(지식 단절 시점), 가끔 거짓 정보(할루시네이션)를 지어낼 수 있으므로 항상 팩트체크가 중요합니다.</li>\n</ul>\n<div style=\"font-size: 14px; color: #5f6368; border-top: 1px solid #dadce0; padding-top: 15px;\">이 핵심 내용들만 잘 숙지해도 AI 활용에 대한 자신감을 크게 높일 수 있습니다. 더 깊이 있는 내용은 본문에서 확인해보세요!</div>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>❓ 자주 묻는 질문 (FAQ)</b></h2>\n<div style=\"margin-bottom: 20px;\">\n<h3 style=\"font-size: 18px; color: #1a73e8; margin-bottom: 10px;\" data-ke-size=\"size23\">Q1. AI 초보자인데 무엇부터 시작해야 할까요?</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">가장 먼저, 오늘 배운 핵심 용어들을 이해하는 것이 중요합니다. 그 다음에는 챗GPT나 제미나이와 같은 LLM 서비스를 직접 사용해보면서 간단한 질문부터 시작해보세요. 처음에는 일상적인 대화나 정보 검색 위주로 사용하다가, 점차 필요한 기능을 익혀나가는 것이 좋습니다.</p>\n</div>\n<div style=\"margin-bottom: 20px;\">\n<h3 style=\"font-size: 18px; color: #1a73e8; margin-bottom: 10px;\" data-ke-size=\"size23\">Q2. AI가 거짓말하는 것을 어떻게 알 수 있나요?</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">AI가 사실이 아닌 정보를 지어내는 현상을 '할루시네이션'이라고 합니다. 이를 방지하기 위해서는 AI에게 답변의 출처를 요청하거나, 중요한 정보는 반드시 직접 검색을 통해 팩트체크하는 습관을 들이는 것이 중요해요. 특히 의학, 법률, 금융 등 민감한 분야의 정보는 전문가의 확인을 거쳐야 합니다.</p>\n</div>\n<div style=\"margin-bottom: 20px;\">\n<h3 style=\"font-size: 18px; color: #1a73e8; margin-bottom: 10px;\" data-ke-size=\"size23\">Q3. 무료로 AI를 써볼 수 있는 방법이 있나요?</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">네, 물론입니다. 챗GPT, 제미나이 등 대부분의 주요 AI 서비스는 무료 버전을 제공하고 있습니다. 또한, 웹 검색 기능이 포함된 AI를 활용하면 최신 정보도 얻을 수 있어 초보자들이 사용하기 좋습니다. 개인 PC에 직접 설치하여 사용할 수 있는 SLM(소형 언어 모델)도 무료로 활용 가능한 좋은 대안이 될 수 있습니다.</p>\n</div>\n<div style=\"margin-bottom: 20px;\">\n<h3 style=\"font-size: 18px; color: #1a73e8; margin-bottom: 10px;\" data-ke-size=\"size23\">Q4. AI 용어는 꼭 다 외워야 하나요?</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">모든 용어를 완벽하게 외울 필요는 없습니다. 오늘 배운 16가지 용어는 AI를 이해하고 활용하는 데 있어 기본 토대가 되는 개념들이에요. 처음에는 낯설겠지만, AI를 직접 사용하면서 궁금할 때마다 다시 찾아보고 이해하는 과정을 반복하다 보면 자연스럽게 익숙해질 겁니다.</p>\n</div>\n<script type=\"application/ld+json\">\n  {\n    \"@context\": \"https://schema.org\",\n    \"@type\": \"FAQPage\",\n    \"mainEntity\": [\n      {\n        \"@type\": \"Question\",\n        \"name\": \"AI 초보자인데 무엇부터 시작해야 할까요?\",\n        \"acceptedAnswer\": {\n          \"@type\": \"Answer\",\n          \"text\": \"가장 먼저, 오늘 배운 핵심 용어들을 이해하는 것이 중요합니다. 그 다음에는 챗GPT나 제미나이와 같은 LLM 서비스를 직접 사용해보면서 간단한 질문부터 시작해보세요. 처음에는 일상적인 대화나 정보 검색 위주로 사용하다가, 점차 필요한 기능을 익혀나가는 것이 좋습니다.\"\n        }\n      },\n      {\n        \"@type\": \"Question\",\n        \"name\": \"AI가 거짓말하는 것을 어떻게 알 수 있나요?\",\n        \"acceptedAnswer\": {\n          \"@type\": \"Answer\",\n          \"text\": \"AI가 사실이 아닌 정보를 지어내는 현상을 '할루시네이션'이라고 합니다. 이를 방지하기 위해서는 AI에게 답변의 출처를 요청하거나, 중요한 정보는 반드시 직접 검색을 통해 팩트체크하는 습관을 들이는 것이 중요해요. 특히 의학, 법률, 금융 등 민감한 분야의 정보는 전문가의 확인을 거쳐야 합니다.\"\n        }\n      },\n      {\n        \"@type\": \"Question\",\n        \"name\": \"무료로 AI를 써볼 수 있는 방법이 있나요?\",\n        \"acceptedAnswer\": {\n          \"@type\": \"Answer\",\n          \"text\": \"네, 물론입니다. 챗GPT, 제미나이 등 대부분의 주요 AI 서비스는 무료 버전을 제공하고 있습니다. 또한, 웹 검색 기능이 포함된 AI를 활용하면 최신 정보도 얻을 수 있어 초보자들이 사용하기 좋습니다. 개인 PC에 직접 설치하여 사용할 수 있는 SLM(소형 언어 모델)도 무료로 활용 가능한 좋은 대안이 될 수 있습니다.\"\n        }\n      },\n      {\n        \"@type\": \"Question\",\n        \"name\": \"AI 용어는 꼭 다 외워야 하나요?\",\n        \"acceptedAnswer\": {\n          \"@type\": \"Answer\",\n          \"text\": \"모든 용어를 완벽하게 외울 필요는 없습니다. 오늘 배운 16가지 용어는 AI를 이해하고 활용하는 데 있어 기본 토대가 되는 개념들이에요. 처음에는 낯설겠지만, AI를 직접 사용하면서 궁금할 때마다 다시 찾아보고 이해하는 과정을 반복하다 보면 자연스럽게 익숙해질 겁니다.\"\n        }\n      }\n    ]\n  }\n  </script>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">자, 여러분! 이것으로 'AI 바로 활용하시려면 이건 그냥 외우세요' 파트 1 강의를 마치도록 하겠습니다. 오늘 배운 <b>16가지 핵심 용어</b>, 완벽하게 외울 필요는 없습니다. AI를 사용하시면서 자연스럽게 익숙해지실 거예요.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">다음 파트 2에서는 여러분에게 맞는 AI를 고르는 방법을, 파트 3에서는 실전 프롬프트 기술을 배우게 됩니다. 이 3부작 시리즈를 차근차근 따라오시면 여러분도 AI를 자신 있게 활용하며 2025년 디지털 포모를 완전히 극복하실 수 있을 거예요.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">AI는 생각보다 어렵지 않습니다! 지금 바로 시작해서 변화를 경험해보세요. 다음 포스트에서 만나요!</p>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  AI 필수용어 PDF 다운로드</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">아래 구글드라이브 링크를 방문하세요.</p>\n<figure id=\"og_1765076808208\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"article\" data-og-title=\"AI초보,시니어를 위한 기초 용어.pdf\" data-og-description=\"\" data-og-host=\"drive.google.com\" data-og-source-url=\"https://drive.google.com/file/d/1D-lUcb2S5hq68xH2a3srsi6_AULxLZwu/view?usp=sharing\" data-og-url=\"https://drive.google.com/file/d/1D-lUcb2S5hq68xH2a3srsi6_AULxLZwu/view?usp=sharing&amp;usp=embed_facebook\" data-og-image=\"\"><a href=\"https://drive.google.com/file/d/1D-lUcb2S5hq68xH2a3srsi6_AULxLZwu/view?usp=sharing\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://drive.google.com/file/d/1D-lUcb2S5hq68xH2a3srsi6_AULxLZwu/view?usp=sharing\">\n<div class=\"og-image\" style=\"background-image: url();\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">AI초보,시니어를 위한 기초 용어.pdf</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">&nbsp;</p>\n<p class=\"og-host\" data-ke-size=\"size16\">drive.google.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=ep8QATZr_0M\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/e6y65/hyZO5nzSoz/Y7LvwLLdCVaWxEWcDOZtr1/img.jpg?width=1280&amp;height=720&amp;face=216_428_450_544,https://scrap.kakaocdn.net/dn/9ZzJA/hyZO1MdNYi/b4FNhfTxAKFNxFGlcSbV9K/img.jpg?width=1280&amp;height=720&amp;face=216_428_450_544\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"나이, 컴퓨터 실력 상관없습니다. 할머니도 이해하는 AI 기초 용어 12가지 | AI 바로 활용하시려면 \" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/ep8QATZr_0M\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "\"나만 AI 몰라?\"라는 생각에 불안하신가요? LLM, 할루시네이션, 프롬프트... 복잡한 용어들 때문에 AI 시작이 두렵다면 이 가이드를 주목하세요. 왕초보도 30분 만에 AI 핵심 용어를 완벽하게 이해하고 디지털 포모(FOMO)를 극복할 수 있도록, 지피티팍이 쉽고 친절하게 설명해드립니다. 지금 바로 AI 세상으로 함께 떠나보시죠!\n\"나만 AI 몰라?\" 이런 불안감에 잠 못 이루는 분들이 많으실 거예요. 주변에서는 다들 챗GPT다, 제미나이다 하는데, 막상 시작하려니 LLM은 뭐고, 토큰은 또 뭔지... 용어의 벽에 부딪혀 막막함을 느끼실 수 있습니다. 솔직히 저도 처음엔 그랬어요. 특히 AI가 낯선 초보자분들, 그리고 컴퓨터 사용이 익숙지 않은 시니어분들이라면 더욱 어렵게 느껴질 수 있죠.\n하지만 괜찮습니다! 오늘 딱 30분만 투자하면 AI가 완전히 다르게 보일 거예요. 이 블로그 포스트는 바로 여러분을 위해 준비했어요. 나이나 컴퓨터 실력은 전혀 상관없습니다. 제가 여러분의 눈높이에 맞춰 가장 쉬운 말로만 설명해드릴 테니, 편안하게 따라오세요.\n\n\n \n  AI, 왜 시작이 어려울까요? 2025년 디지털 포모(FOMO)의 그림자\n많은 분들이 AI를 시작하기 어려워하는 데는 몇 가지 이유가 있습니다. 특히 컴퓨터에 익숙하지 않은 분들은 더욱 크게 공감하실 텐데요.\n첫 번째 이유는 바로 디지털 포모(Digital FOMO) 때문입니다. FOMO는 'Fear Of Missing Out'의 약자로, \"나만 뒤처지는 것 같은 불안감\"을 의미해요. 2025년 현재, 뉴스나 유튜브, 심지어 회사에서도 AI 얘기가 끊이지 않죠. 주변에서 다들 챗GPT를 쓴다는데 나만 못하는 것 같아 조급하고 불안한 마음, 솔직히 저도 느껴봤습니다. 하지만 괜찮습니다. 지금 시작하는 것만으로도 충분히 빠르다고 생각해요. \"빨리 배워야 하는데...\" 하는 조급함이 오히려 제대로 배우는 것을 방해할 수 있으니, 차분하게 시작하는 것이 중요합니다.\n두 번째 이유는 바로 어려운 용어의 장벽입니다. AI, LLM, 프롬프트, 토큰, 멀티모달... 이런 단어들을 들으면 마치 외계어처럼 느껴져 머리가 지끈거릴 수 있습니다. 솔직히 말하면 저도 처음에는 'LLM? 엘엘엠? 래퍼 이름인가?' 하고 생각했던 기억이 나네요. 이 용어의 장벽만 넘어서면 AI는 훨씬 쉬워진답니다.\n세 번째는 어디서부터 시작해야 할지 모른다는 막막함입니다. 챗GPT, 클로드, 제미나이 등 종류가 너무 많아서 뭘 써야 할지 감이 안 잡히실 거예요. 마치 맛있는 치킨집이 너무 많아서 어디에 시켜야 할지 고민되는 것과 비슷하다고 할까요?\n마지막 네 번째는 질문을 어떻게 해야 할지 모른다는 점입니다. AI에게 \"글 써줘\"라고만 하면 엉뚱한 답이 나오기 일쑤죠. 답답한 마음에 \"너 왜 이래?\" 하고 AI에게 화를 내봤자, AI는 감정이 없으니 계속 이상한 답만 내놓을 뿐입니다.\n  이 포스트가 여러분의 불안감을 해소해 드립니다! 오늘 'AI 필수 용어 완벽 가이드'를 통해 어려운 용어들을 일상 언어로 쉽게 풀어 설명해드릴게요. 용어만 알아도 AI 정복의 절반은 이뤄냈다고 볼 수 있습니다!\n  AI 왕초보를 위한 핵심 용어 16가지 완벽 정리!\n1. AI (Artificial Intelligence): 인공지능\n가장 먼저, AI는 쉽게 말해 사람처럼 생각하고 대답할 수 있는 컴퓨터 프로그램입니다. 마치 똑똑한 비서를 컴퓨터 안에 넣어둔 것과 같다고 생각하시면 돼요. 그것도 24시간 내내 일하고, 월급도 휴가도 필요 없는 완벽한 비서죠. 물론 가끔 엉뚱한 소리도 하긴 하지만 말입니다.\n2. LLM (Large Language Model): 대규모 언어 모델\nLLM은 한국어로 대규모 언어 모델이라고 부릅니다. 이건 쉽게 설명하자면, 엄청나게 많은 책과 인터넷 글을 읽고 학습한 AI를 뜻해요. 'AI'가 '과일'이라는 큰 개념이라면, 'LLM'은 그 안의 '사과'처럼 언어에 특화된 특정 AI를 지칭합니다. 우리가 흔히 아는 챗GPT, 클로드, 제미나이가 바로 이 LLM에 속하죠. 마치 지구상의 모든 도서관 책을 다 읽어버린 초특급 독서광 AI라고 생각하시면 됩니다. 여기서 중요한 점은 LLM이 단순히 저장된 답변을 보여주는 게 아니라, 여러분의 질문을 이해하고 새로운 답변을 스스로 만들어낸다는 거예요. 네이버 지식인처럼 누가 써놓은 답을 복사 붙여넣기 하는 것이 아니라, 실시간으로 생각해서 답을 만들어내는 거죠!\n3. SLM (Small Language Model): 소형 언어 모델\nLLM이 대형 트럭이라면, SLM은 경차에 비유할 수 있습니다. 작지만 가볍고 빠르다는 장점이 있죠. SLM은 LLM과 똑같은 방식으로 작동하지만, 크기를 확 줄인 모델이에요. 파라미터 수를 줄이거나 모델 압축 기술을 사용해서 효율성을 높입니다.\n가장 큰 차이는 작동 위치에 있습니다. 일반적인 LLM은 여러분이 질문하면 인터넷을 통해 멀리 떨어진 서버로 보내져 처리되고 답변이 돌아오죠. 마치 해외 본사에 전화해서 답변받는 것처럼 인터넷 연결이 필수예요. 하지만 SLM은 여러분의 PC에 직접 설치되어 작동합니다. 질문하면 컴퓨터의 CPU나 그래픽카드가 바로 처리해서 답변을 주기 때문에 인터넷 없이도 작동하고, 개인 정보가 외부로 나가지 않아 보안에도 강하죠. 물론 성능은 LLM보다 낮지만, 문서 요약, 간단한 번역, 메모 정리 같은 일상적인 작업에는 충분하고, 무엇보다 무료로 사용할 수 있다는 큰 장점이 있습니다.\n\n\n4. 챗봇 & GPTs/Gems & Projects: AI 활용의 두 가지 방식\n챗봇은 채팅하듯이 대화할 수 있는 AI 프로그램입니다. 챗GPT의 '챗'이 바로 이 챗봇을 의미하죠. 그런데 여기서 맞춤형 챗봇(GPTs/Gems)과 프로젝트 기능이라는 두 가지 중요한 개념을 구분해야 해요. 둘 다 AI를 내 방식대로 쓰는 것이지만, 목적이 완전히 다릅니다. 쉽게 말해 \"너 누구야?\"라고 묻는 것과 \"이 일에 대해 어떻게 생각해?\"라고 묻는 것의 차이랄까요?\n✅ GPTs와 Gems: 나만의 전문 AI 비서 만들기 (누구냐?)\nGPTs는 챗GPT에서 제공하는 맞춤형 챗봇 만들기 기능이에요. 'G'는 GPT의 G, 's'는 복수형을 의미합니다. 여러 개 만들 수 있다는 뜻이죠. 이건 특정 역할을 하는 전문 AI를 만드는 겁니다. 마치 전문 직업을 가진 직원을 여러 명 고용하는 것처럼요. 예를 들어, \"너는 세계 최고의 요리 전문가야\"라고 역할을 정의하고 상세 지침을 제공하면, 이후에 \"파스타 소스 비법 알려줘!\"라고 물을 때 요리 전문가답게 답변하는 식입니다. 한 번 만들어두면 매번 설명할 필요 없이 그 역할로 계속 작동하죠. 구글 제미나이에서 제공하는 Gems도 이름만 다를 뿐 완전히 동일한 개념이에요.\n  예시: 요리 전문가 GPT, 번역 전문가 GPT, 법률 상담 GPT 등 나만의 전문가 팀을 만들 수 있어요.\n✅ Projects: 작업 단위로 대화와 파일 관리하기 (무엇을 하느냐?)\n프로젝트는 작업 단위로 대화와 파일을 묶어서 관리하는 기능입니다. 회사에서 A 프로젝트와 B 프로젝트를 동시에 진행한다고 할 때, A 프로젝트 관련 대화, 문서, 자료를 한곳에 모아두고, B 프로젝트 것들은 따로 모아두는 식이죠. 마치 프로젝트별로 폴더를 만드는 것과 같아요. 프로젝트의 핵심은 바로 '맥락 유지'입니다. \"마케팅 프로젝트\" 폴더 안에서 대화하면 AI가 그 프로젝트의 모든 이전 대화와 파일을 기억해요. 어제 업로드한 시장 분석 보고서 PDF를 기억해서, 오늘 같은 폴더에서 \"어제 올린 자료 기반으로 요약해줘\"라고만 해도 AI가 알아서 찾아 요약해줍니다. 챗GPT Projects와 클로드 Projects도 동일한 기능입니다.\n구분\nGPTs / Gems\nProjects\n\n\n\n\n목적\n특정 역할 수행 AI 제작\n특정 작업의 대화/파일 통합 관리\n\n\n지속성\n한 번 만든 역할이 모든 대화에서 유지\n해당 프로젝트 내에서만 맥락 유지\n\n\n핵심\nAI의 '정체성' 정의\n작업의 '맥락' 보존\n\n\n\n5. 토큰 (Token): AI 언어 처리의 기본 단위\n토큰은 AI가 글자를 처리할 때 사용하는 기본 단위입니다. 레고 블록을 생각해보세요. 긴 문장을 작은 조각으로 쪼개서 이해하는데, 그 조각 하나가 바로 토큰인 거죠. 왜 중요하냐고요? AI 사용량이 이 토큰 단위로 제한되기 때문입니다. 무료 버전은 하루에 몇 천 토큰까지 쓸 수 있다, 이런 식이에요. 마치 핸드폰 데이터 요금처럼 말이죠. 그래서 너무 긴 질문이나 답변은 토큰을 많이 소모한다는 것만 기억하시면 됩니다. 보통 한국어 글자 한 자가 토큰 한 개 정도라고 보시면 편해요. 하지만 '안녕하세요'처럼 자주 쓰는 말은 AI가 통째로 기억해서 1~2개 토큰으로 아주 싸게 처리하니, 토큰 걱정 너무 하지 말고 편하게 쓰셔도 좋습니다.\n6. 컨텍스트 (Context): AI의 대화 기억력\n컨텍스트는 AI가 대화의 흐름을 기억하는 능력을 말합니다. 예를 들어, 여러분이 \"사과에 대해 알려줘\"라고 물어 AI가 과일 사과를 설명했어요. 그다음에 \"가격은?\"이라고만 물어봐도 AI는 \"아, 사과 가격을 묻는구나\" 하고 알아듣죠. 이게 바로 컨텍스트를 이해한다는 겁니다. 마치 친구와 대화할 때 앞뒤 맥락을 다 기억하고 있는 것처럼요. AI마다 기억할 수 있는 대화의 길이가 다른데, 클로드나 제미나이 같은 모델은 특히 긴 대화를 잘 기억하는 편입니다. 마치 토씨 하나 안 틀리는 꼼꼼한 비서 같달까요? 하지만 대화가 너무 길어져서 AI의 '기억 용량'이 꽉 차면 이전 기억을 지울 수도 있어요. 이럴 땐 처음부터 다시 설명해주는 것이 가장 정확합니다. AI도 가끔 건망증이 있답니다.\n7. 지식 단절 시점 (Knowledge Cutoff Date): AI의 시공간 제약\n이건 정말 중요해요! 지식 단절 시점은 AI가 특정 날짜까지의 정보만 알고 있다는 것을 의미합니다. 그 이후의 정보는 모르는 거죠. 예를 들어, 챗GPT가 2024년 10월까지 학습했다면, 2024년 11월 이후의 일은 전혀 모릅니다. 마치 타임캡슐에 갇혀 2024년 10월에 잠들었다가 지금 깨어난 사람이라고 생각하시면 됩니다. 그래서 \"어제 뉴스\"나 \"지금 주식 시장 상황\"을 물어보면 AI는 모른다고 답할 수밖에 없어요. 이럴 때는 웹 검색 기능이 있는 AI를 사용하거나, \"웹 검색해서 알려줘\"라고 명확하게 요청해야 합니다. AI가 \"그 정보는 모릅니다\"라고 하면 화내지 마세요. 정말로 모르는 겁니다. 학습 데이터에 없으니까요!\n\n\n8. 멀티모달 (Multimodal): 오감으로 소통하는 AI\n멀티모달은 AI가 글자뿐만 아니라 사진, 음성, 영상 등 다양한 형식의 정보도 이해할 수 있다는 뜻입니다. 예전 AI는 글로만 대화했지만, 이제는 사진을 올리면 설명해주고, 음성으로 질문하면 음성으로 답하며, 영상도 분석할 수 있어요. 마치 오감이 다 있는 사람처럼 보고, 듣고, 말할 수 있는 AI가 된 거죠. 이제는 \"이게 뭐야?\" 하면서 사진만 찍어 올려도 알아서 설명해줍니다. 저는 가끔 냉장고 사진 찍어서 \"오늘 저녁 뭐 해먹지?\" 하고 물어보는데 정말 편하답니다!\nAI에 올릴 수 있는 파일들은 정말 다양해요. 파일 이름 끝에 붙는 몇 글자, 즉 확장자가 그 파일이 어떤 종류인지 알려주는 역할을 합니다. 마치 사람의 성씨처럼 파일을 구분하는 거죠.\n문서 파일: PDF (계약서, 보고서 요약), TXT (순수 텍스트), CSV (표 형태 데이터 분석), DOCX (워드 문서), MD (마크다운)\n이미지 파일: JPG/JPEG (사진), PNG (투명 배경), GIF (움직이는 이미지), WebP (고화질 경량 이미지)\n오디오 파일: MP3 (음악, 회의 녹음 텍스트 변환), WAV (고음질 오디오), M4A (애플 기기 오디오)\n비디오 파일: MP4 (가장 흔한 동영상), MOV (아이폰 동영상), AVI (옛날 동영상), WebM (웹 동영상)\n프로그래밍 소스 파일: PY (파이썬), JS (자바스크립트), HTML (웹페이지 코드)\n이런 파일들을 AI에게 올리고 \"이 코드가 무슨 일을 하는지 설명해줘\"라고 묻는 등, 프로그래밍을 모르는 분들도 AI의 도움을 받아 복잡한 코드를 쉽게 이해할 수 있습니다.\n\n\n9. API (Application Programming Interface): 프로그램들의 대화 통로\nAPI는 프로그램들이 서로 대화하는 통로를 말합니다. 쉽게 말해 AI를 다른 앱이나 웹사이트에 연결하는 방법이에요. 여러분이 사용하는 어떤 앱에서 \"AI로 답장 작성\" 버튼을 누르면, 그 앱이 챗GPT API를 사용해서 챗GPT와 연결되어 있는 겁니다. 마치 두 프로그램이 전화 통화하는 것처럼요. 과거에는 개발자가 아니라면 직접 사용할 일이 거의 없었지만, 바야흐로 '바이브 코딩' 시대에는 누구나 쉽게 AI를 활용하여 코딩하고 API를 사용할 수 있게 되었습니다.\n10. MCP (Model Context Protocol): AI와 도구 연결의 표준\nMCP는 Model Context Protocol의 약자로, AI가 여러 도구들을 사용할 수 있도록 연결해주는 표준 규격입니다. 마치 여러 기기를 연결하는 USB 단자처럼, MCP는 AI와 다양한 서비스를 연결하는 표준이라고 생각하시면 돼요. 예를 들어 MCP를 사용하면 클로드 같은 LLM이 구글 드라이브, 노션, 슬랙 같은 여러 서비스에 직접 접근해서 \"구글 드라이브에 있는 파일 찾아서 요약해줘\"처럼 한 번에 작업을 수행할 수 있죠. 아직 초보자가 직접 설정하기는 어렵지만, \"AI가 여러 서비스를 연결해서 쓸 수 있구나\" 정도만 알아두셔도 충분합니다. 앞으로 점점 더 많이 사용될 중요한 기술이랍니다.\n11. RAG (Retrieval-Augmented Generation): 똑똑한 오픈북 AI\nRAG는 Retrieval-Augmented Generation, 즉 검색 증강 생성이라는 뜻인데요. 어렵게 들리지만 쉽게 말하면, AI가 답변할 때 자기가 아는 것만으로 대답하는 게 아니라, 필요한 정보를 먼저 찾아보고 그걸 바탕으로 답변하는 방식입니다. 마치 오픈북 시험을 보는 것과 같아요. 모든 걸 외우지 않아도 책을 찾아보면서 답을 쓸 수 있잖아요? RAG가 바로 그런 원리입니다.\n여러분이 회사 문서를 AI에게 주고 \"우리 회사 휴가 정책이 뭐야?\"라고 물어본다고 가정해볼게요. RAG 방식의 AI는 먼저 여러분이 준 문서에서 휴가 관련 부분을 찾아보고, 그 내용을 바탕으로 답변을 만듭니다. 그냥 AI가 상상해서 답하는 게 아니라 실제 문서를 참고하기 때문에 훨씬 정확하고 신뢰할 수 있는 답변을 받을 수 있죠. 특히 회사 업무나 전문 분야에서 AI가 엉뚱한 답변을 지어내지 않고 실제 자료를 기반으로 답하게 하는 데 정말 유용합니다. Notebook LM 같은 서비스가 바로 이 RAG 방식을 사용하고 있어요.\n12. 마크다운(Markdown) & JSON: AI와 효율적으로 대화하는 비법\n자, 이제 정말 중요한 용어 두 가지를 알려드릴게요. 마크다운과 JSON입니다. 이 두 가지를 알면 AI 활용 효율이 3배는 올라간다고 장담할 수 있어요!\n✅ 마크다운 (Markdown): 간단한 기호로 예쁜 문서 만들기\n마크다운은 간단한 기호로 문서를 예쁘게 꾸미는 방법입니다. 샵(#) 기호를 쓰면 제목이 되고, 대시(-) 기호를 쓰면 목록이 되고, 별표 두 개(**)로 감싸면 굵은 글씨가 되죠. 노션, 깃허브 등에서 많이 사용하고 있으며, 워드처럼 마우스 클릭 없이 키보드만으로 뚝딱 깔끔한 문서를 만들 수 있어요.\n✅ JSON (JavaScript Object Notation): 데이터를 구조화하여 정리하기\nJSON은 데이터를 구조화해서 저장하는 형식이에요. 중괄호({})와 대괄호([])를 사용해서 데이터를 항목과 값으로 명확하게 정리합니다. 프로그래밍에서 주로 쓰이지만, 일반인도 알면 정말 유용해요. 엑셀 데이터를 텍스트로 옮긴 것 같다고 생각하시면 됩니다.\n여기서 중요한 건, 이 형식들을 AI에게 질문할 때 활용하면 답변 품질이 확 올라간다는 거예요! 그냥 일반 대화체로 질문하면 AI가 중간에 정보를 놓칠 수도 있습니다. 하지만 마크다운이나 JSON으로 구조화해서 질문하면 AI가 모든 조건을 명확하게 파악하고 정확히 처리하죠. 조건이 복잡할수록 효과는 더욱 커집니다.\n  실전 꿀팁: 언제 어떤 형식을 쓸까요?\n일상 대화체: 간단한 질문, 빠르게 답변받고 싶을 때 (\"오늘 저녁 뭐 먹을까?\")\n마크다운: 문서, 보고서 작성할 때 (\"회의록을 마크다운으로 작성해줘\")\nJSON: 여러 항목 비교, 데이터 분석, 복잡한 조건 제시할 때 (\"상품 10개를 조건별로 비교 분석해줘\")\n13. 프롬프트 (Prompt): AI에게 하는 질문과 명령\n프롬프트는 AI에게 하는 질문이나 명령을 말합니다. 쉽게 말해 여러분이 AI에게 타이핑하는 모든 문장이 프롬프트예요. \"오늘 날씨 어때?\"도 프롬프트고, \"이 코드 설명해줘\"도 프롬프트죠. 왜 이 용어가 중요하냐면, AI 활용의 90%가 프롬프트를 잘 쓰느냐에 달려 있기 때문입니다. 같은 AI를 써도 프롬프트를 어떻게 쓰느냐에 따라 결과가 천지 차이죠. 마치 검색엔진에서 검색어를 잘 쓰는 것이 중요한 것처럼 말입니다. \"글 써줘\"는 나쁜 프롬프트지만, \"블로그용 AI 활용 팁 글을 초보자 대상으로 1000자로 써줘\"는 구체적인 좋은 프롬프트예요. 프롬프트를 잘 쓰는 기술을 '프롬프트 엔지니어링'이라고 하는데, 이건 다음 시리즈에서 더 자세히 다룰 예정입니다.\n14. 온도 (Temperature): AI 답변의 창의성 조절\n온도는 실제 온도와는 상관없이 AI 답변의 창의성을 조절하는 설정값입니다. 온도가 낮으면 AI가 안전하고 예측 가능한, 교과서 같은 답변을 내놓아요. 반대로 온도가 높으면 AI가 더 창의적이고 다양한 답변을 생성하지만, 가끔 엉뚱한 소리도 할 수 있죠. 마치 자유로운 예술가처럼요. 보통 온도는 0에서 1 사이의 값으로 설정되는데, 0에 가까울수록 \"정확하게만 답해줘, 창의력은 필요 없어\", 1에 가까울수록 \"자유롭게 상상해서 답해줘\"라는 의미로 이해할 수 있습니다. 예를 들어, \"회의록 작성해줘\"라고 할 때는 온도를 낮게, \"광고 카피 아이디어 10개 줘\"라고 할 때는 온도를 높게 설정하는 것이 효과적입니다. 대부분의 AI 서비스에서는 직접 온도를 조절할 수는 없지만, 프롬프트에 \"창의적으로 답해줘\" 또는 \"정확하게만 답해줘\"라고 명시하면 비슷한 효과를 낼 수 있답니다.\n15. 할루시네이션 (Hallucination): AI의 그럴듯한 거짓말\n할루시네이션은 AI가 거짓말을 하거나 사실이 아닌 정보를 그럴듯하게 지어내는 현상을 말합니다. 환각이라고도 하죠. 중요한 건 AI가 일부러 거짓말하는 것이 아니라는 점이에요. AI는 '이것이 사실인지 아닌지'를 구분하지 못하고, 그저 학습된 데이터를 바탕으로 가장 그럴듯한 답변을 만들어낼 뿐입니다. 마치 시험 볼 때 모르는 문제를 대충 그럴듯하게 쓰는 것과 비슷하다고 할까요?\n예를 들어, AI에게 \"2024년 노벨 물리학상 수상자는?\"이라고 물었을 때, AI가 존재하지 않는 '존 스미스 박사'를 자신 있게 말할 수도 있어요. 더 무서운 건, AI가 거짓말하는 것처럼 보이지 않는다는 겁니다. 엄청 자신 있고 구체적으로, 심지어 논문 제목까지 지어내면서 설명하기 때문에 초보자분들이 쉽게 속을 수 있습니다.\n⚠️ 할루시네이션 방지법:\n출처 요청: \"출처와 함께 알려줘\"라고 명시하기\n팩트체크: 중요한 정보는 반드시 검색으로 확인하기\n구체적 질문: 모호한 질문보다 구체적으로 물어보기\n최신 정보 주의: 지식 단절 시점 이후 정보는 항상 의심하기\n웹 검색 기능 사용: AI에게 \"웹 검색해서 알려줘\"라고 요청하기\n16. AGI (Artificial General Intelligence): 사람처럼 모든 것을 하는 AI\n마지막 용어는 AGI, 즉 범용 인공지능입니다. 이건 사람처럼 모든 것을 스스로 학습하고 판단할 수 있는 AI를 말해요. 지금 우리가 사용하는 챗GPT나 클로드 같은 AI는 특정 작업만 잘하는 '전문가' AI입니다. 하지만 AGI는 '천재'에 가깝죠. 뭐든 배우고 응용할 수 있는 완전한 형태의 AI라고 할 수 있습니다. 현재 AGI는 아직 존재하지 않아요. 언제 나올지도 미지수이며, 전문가들 사이에서도 \"5년 안에 나온다\", \"50년 걸린다\", 심지어 \"영원히 불가능하다\" 등 다양한 의견이 분분합니다. AGI가 등장하면 세상이 완전히 뒤바뀔 것이기에, AI 뉴스에서 이 단어가 자주 언급되는 것이랍니다. \"아, 완전한 AI를 말하는 거구나\" 정도로만 이해해두시면 충분합니다.\n  핵심 요약\nAI의 기본 이해: AI는 사람처럼 생각하고 대화하는 컴퓨터 프로그램이며, LLM은 언어에 특화된 대규모 AI, SLM은 작지만 빠르고 개인 PC에서 작동하는 AI입니다.\nAI 활용 방식의 이해: GPTs/Gems는 AI의 '역할'을 정해 전문 비서를 만드는 것이고, Projects는 특정 '작업 맥락'을 유지하며 효율적으로 대화와 파일을 관리하는 기능입니다.\nAI 소통의 기술: 토큰, 컨텍스트, 프롬프트의 개념을 이해하고 마크다운/JSON과 같은 구조화된 질문 방식을 활용하면 AI와 훨씬 효율적으로 소통할 수 있습니다.\nAI 활용 시 주의점: AI는 특정 시점까지의 정보만 알고(지식 단절 시점), 가끔 거짓 정보(할루시네이션)를 지어낼 수 있으므로 항상 팩트체크가 중요합니다.\n이 핵심 내용들만 잘 숙지해도 AI 활용에 대한 자신감을 크게 높일 수 있습니다. 더 깊이 있는 내용은 본문에서 확인해보세요!\n❓ 자주 묻는 질문 (FAQ)\nQ1. AI 초보자인데 무엇부터 시작해야 할까요?\n가장 먼저, 오늘 배운 핵심 용어들을 이해하는 것이 중요합니다. 그 다음에는 챗GPT나 제미나이와 같은 LLM 서비스를 직접 사용해보면서 간단한 질문부터 시작해보세요. 처음에는 일상적인 대화나 정보 검색 위주로 사용하다가, 점차 필요한 기능을 익혀나가는 것이 좋습니다.\nQ2. AI가 거짓말하는 것을 어떻게 알 수 있나요?\nAI가 사실이 아닌 정보를 지어내는 현상을 '할루시네이션'이라고 합니다. 이를 방지하기 위해서는 AI에게 답변의 출처를 요청하거나, 중요한 정보는 반드시 직접 검색을 통해 팩트체크하는 습관을 들이는 것이 중요해요. 특히 의학, 법률, 금융 등 민감한 분야의 정보는 전문가의 확인을 거쳐야 합니다.\nQ3. 무료로 AI를 써볼 수 있는 방법이 있나요?\n네, 물론입니다. 챗GPT, 제미나이 등 대부분의 주요 AI 서비스는 무료 버전을 제공하고 있습니다. 또한, 웹 검색 기능이 포함된 AI를 활용하면 최신 정보도 얻을 수 있어 초보자들이 사용하기 좋습니다. 개인 PC에 직접 설치하여 사용할 수 있는 SLM(소형 언어 모델)도 무료로 활용 가능한 좋은 대안이 될 수 있습니다.\nQ4. AI 용어는 꼭 다 외워야 하나요?\n모든 용어를 완벽하게 외울 필요는 없습니다. 오늘 배운 16가지 용어는 AI를 이해하고 활용하는 데 있어 기본 토대가 되는 개념들이에요. 처음에는 낯설겠지만, AI를 직접 사용하면서 궁금할 때마다 다시 찾아보고 이해하는 과정을 반복하다 보면 자연스럽게 익숙해질 겁니다.\n자, 여러분! 이것으로 'AI 바로 활용하시려면 이건 그냥 외우세요' 파트 1 강의를 마치도록 하겠습니다. 오늘 배운 16가지 핵심 용어, 완벽하게 외울 필요는 없습니다. AI를 사용하시면서 자연스럽게 익숙해지실 거예요.\n다음 파트 2에서는 여러분에게 맞는 AI를 고르는 방법을, 파트 3에서는 실전 프롬프트 기술을 배우게 됩니다. 이 3부작 시리즈를 차근차근 따라오시면 여러분도 AI를 자신 있게 활용하며 2025년 디지털 포모를 완전히 극복하실 수 있을 거예요.\nAI는 생각보다 어렵지 않습니다! 지금 바로 시작해서 변화를 경험해보세요. 다음 포스트에서 만나요!\n  AI 필수용어 PDF 다운로드\n아래 구글드라이브 링크를 방문하세요.\n\n \nAI초보,시니어를 위한 기초 용어.pdf\n \ndrive.google.com",
        "guid": "https://muzbox.tistory.com/483687",
        "categories": [
          "AI, 미래기술/AI 인사이트",
          "2025 ai 트렌드",
          "ai 기초",
          "AI 왕초보 가이드",
          "AI 할루시네이션",
          "LLM 이해",
          "디지털 포모 극복",
          "멀티모달 ai",
          "인공지능 용어",
          "챗GPT 활용법",
          "프롬프트 엔지니어링"
        ],
        "isoDate": "2025-12-07T03:07:13.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "유튜브가 TV를 완전히 대체할 수 없는 이유",
        "link": "https://muzbox.tistory.com/483686",
        "pubDate": "Thu, 4 Dec 2025 10:57:03 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "https://muzbox.tistory.com/483686#entry483686comment",
        "content": "<div style=\"font-family: 'Noto Sans KR', sans-serif; line-height: 1.6; max-width: 800px; margin: 0 auto; font-size: 16px; box-sizing: border-box; color: #3c4043;\">\n<div style=\"background-color: #e8f4fd; padding: 15px; border-radius: 8px; font-style: italic; margin-bottom: 25px; font-size: 15px;\">\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">최근 거실 TV는 넷플릭스를 넘어 유튜브가 점령한 듯 보이죠. 뉴스, 예능, 드라마 할 것 없이 모두 유튜브로 소비되는 시, 우리는 정말 TV를 떠나왔을까요? 생성형 AI 시대, 콘텐츠의 홍수 속에서 우리가 놓치고 있는 '인간적인 이야기'의 가치와 유튜브가 TV를 완전히 대체할 수 없는 진짜 이유를 파헤쳐봅니다.</p>\n</div>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"1200\"><span data-url=\"https://blog.kakaocdn.net/dn/rkcZd/dJMcaacHxfJ/GiWRZ3bgtebDBCyEWS6J2k/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/rkcZd/dJMcaacHxfJ/GiWRZ3bgtebDBCyEWS6J2k/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/rkcZd/dJMcaacHxfJ/GiWRZ3bgtebDBCyEWS6J2k/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FrkcZd%2FdJMcaacHxfJ%2FGiWRZ3bgtebDBCyEWS6J2k%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"구형 TV가 가족 시청 경험과 공공 정보를 보여주고, 스마트폰은 개인화된 유튜브 콘텐츠를 보여주는 대조적인 이미지.\" loading=\"lazy\" width=\"500\" height=\"500\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"1200\"/></span></figure>\n\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  1. 유튜브의 '무한 자유'가 역설적으로 '결정 피로'를 부른다</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">유튜브의 가장 큰 매력 중 하나는 바로 <b>&lsquo;선택의 자유&rsquo;</b>라고 생각해요. 언제든 원하는 영상을 골라볼 수 있고, AI가 사용자의 취향을 분석해서 딱 맞는 콘텐츠를 추천해주죠. 마치 나만을 위한 비서가 있는 것 같은 기분마저 듭니다. 그런데 말이죠, 이 끝없이 펼쳐진 선택지들이 때로는 피로감으로 다가오기도 합니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">저만 그런가요? &ldquo;오늘은 뭘 볼까?&rdquo; 하며 수십 개의 썸네일을 넘기다가 결국은 아무것도 제대로 보지 못한 채 시간이 흘러버리는 경험, 여러분도 한두 번쯤 있으실 거예요. 이런 현상을 <b>&lsquo;결정 피로(Decision Fatigue)&rsquo;</b>라고 부르는데요. 무한한 자유가 역설적으로 더 큰 스트레스를 안겨주는 거죠. 보고 싶은 건 많고, 시간은 한정적인데, 내 선택이 과연 최선인지 계속 의심하게 됩니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">생각해보면, 예전 TV 시절에는 이런 고민이 훨씬 덜했어요. 방송사에서 정해준 편성표에 맞춰 모두가 같은 시간에 <b>&lsquo;함께&rsquo;</b> 드라마를 보고, 예능을 보며 웃었죠. 이런 단순함이 오히려 시청자들에게 <b>&lsquo;시청의 리듬&rsquo;</b>을 만들어주고, 콘텐츠에 온전히 몰입할 수 있도록 도와줬던 것 같습니다. 요즘처럼 복잡한 세상에선 이런 단순함이 주는 편안함이 가끔 그립기도 해요.</p>\n<div style=\"background-color: #e8f4fd; border-left: 4px solid #1a73e8; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">  <b>팁:</b> 결정 피로를 줄이려면, 시청할 콘텐츠의 장르나 시청 시간을 미리 정해두거나, 정주행할 시리즈를 한두 개만 집중해서 보는 것도 좋은 방법이에요!</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b> &zwj; &zwj; &zwj;  2. TV는 '공동체 경험'을, 유튜브는 '개인의 세계'를 확장한다</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">TV는 단순히 콘텐츠를 보여주는 매체 그 이상이었어요. 온 가족이 거실에 모여 같은 예능 프로그램을 보며 웃고 떠들거나, 다음 날 학교나 직장에서 친구, 동료들과 어젯밤 드라마 이야기에 꽃을 피웠던 경험, 다들 있으실 겁니다. 이건 단순한 콘텐츠 소비가 아니라, <b>&lsquo;공유된 문화 경험(Shared Cultural Experience)&rsquo;</b>이자 <b>&lsquo;공동체의 연결고리&rsquo;</b>였죠.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">하지만 유튜브는 그 방식이 완전히 다릅니다. 각자의 스마트폰이나 태블릿 앞에서 각자의 알고리즘이 추천하는 영상들을 보고 있어요. 어떤 사람은 인기 브이로그를, 다른 사람은 심층적인 정치 분석 영상을, 또 어떤 사람은 한창 빠져있는 게임 방송을 보고 있을 겁니다. 결국 유튜브는 공동체의 연결 대신, <b>개개인의 세계를 심도 있게 확장</b>시켜주는 역할을 합니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">물론 개인의 취향을 깊이 파고들 수 있다는 장점은 분명하지만, 문제는 이제 <b>&ldquo;같은 것을 본 사람&rdquo;을 찾기가 점점 어려워진다</b>는 점이에요. 과거에는 &ldquo;어제 그 드라마 봤어?&rdquo; 한마디로 대화가 시작되었지만, 이제는 각자의 알고리즘이 만든 세상 속에서 서로 다른 경험을 쌓아가고 있습니다. 이렇게 단절된 경험은 소통의 폭을 좁히고, 때로는 고립감을 느끼게 할 수도 있어요.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/sVDEd/dJMcai2PvDm/hD55NZ2fI9jepkxqGAKP41/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/sVDEd/dJMcai2PvDm/hD55NZ2fI9jepkxqGAKP41/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/sVDEd/dJMcai2PvDm/hD55NZ2fI9jepkxqGAKP41/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FsVDEd%2FdJMcai2PvDm%2FhD55NZ2fI9jepkxqGAKP41%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"스마트폰에서 끝없이 스크롤하며 영상 선택에 지쳐 보이는 사람, 결정 피로를 시각적으로 표현.\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  3. 생성형 AI 시대, 콘텐츠의 홍수 속에 '의미'가 사라진다</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">현재 2025년, <b>생성형 AI(Generative AI)</b>는 유튜브 콘텐츠 제작 방식을 급진적으로 변화시키고 있습니다. 이제 AI는 영상 편집, 자막 생성, 심지어 내레이션까지 자동으로 처리해주고, 더 나아가서는 AI가 직접 <b>영상을 기획하고 제작</b>하는 수준에 이르렀죠. 덕분에 콘텐츠의 <b>양(量)은 폭발적으로 증가</b>했지만, 그 이면에는 우려스러운 그림자가 드리워져 있습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">바로 콘텐츠가 가진 <b>&lsquo;질(質)&rsquo;과 &lsquo;진정성&rsquo;</b>이 점점 옅어지고 있다는 점입니다. AI가 만든 영상은 기술적으로는 완벽할지 모릅니다. 매끄러운 화면 전환, 완벽한 발음의 내레이션, 깔끔한 자막 등 흠잡을 데가 없어 보이죠. 하지만 그 속에는 <b>인간만이 전달할 수 있는 감정, 미묘한 맥락, 그리고 깊이 있는 서사적 여운</b>이 부족합니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">결국 AI는 &lsquo;기술적으로 완벽한 콘텐츠&rsquo;는 무한정 만들어낼 수 있지만, &lsquo;사람의 마음에 깊이 남는 이야기&rsquo;를 만드는 데는 한계가 있습니다. 진정한 의미에서 사람들을 울리고 웃기며, 생각하게 만드는 콘텐츠는 여전히 인간의 손길, 즉 <b>인간적인 시각과 경험</b>에서 비롯된다고 생각해요. 저는 이 차이가 바로 생성형 AI 시대에 우리가 주목해야 할 가장 중요한 지점이라고 봅니다.</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  4. 알고리즘의 편향 &mdash; 유튜브는 우리를 '확증 편향'에 가둔다</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">유튜브의 AI 추천 시스템은 정말이지 놀랍도록 정교합니다. 사용자가 어떤 영상을 좋아하는지 귀신같이 알아내고, 계속해서 취향에 맞는 영상을 제안해주죠. 하지만 이 친절함 뒤에는 <b>&lsquo;디지털 편향(Digital Bias)&rsquo;</b>이라는 숨겨진 위험이 도사리고 있습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">AI는 우리에게 &ldquo;당신이 좋아할 만한 걸 더 보여줄게&rdquo;라고 말하지만, 이건 동시에 <b>&ldquo;당신이 좋아하지 않을 만한 다른 세계는 보여주지 않을게&rdquo;</b>라는 의미가 될 수 있습니다. 즉, 우리가 이미 가지고 있는 생각이나 신념을 강화하는 콘텐츠만을 계속 보여줌으로써 <b>&lsquo;확증 편향(Confirmation Bias)&rsquo;</b>에 갇히게 만드는 것이죠. 결국 우리는 점점 더 비슷한 정보와 관점 속에 머물게 되고, 시야는 좁아질 수밖에 없습니다.</p>\n<div style=\"background-color: #fce8e6; border-left: 4px solid #d93025; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">⚠️ <b>경고:</b> 알고리즘 편향은 특정 정보에만 노출되게 하여, 잘못된 정보나 극단적인 관점에 쉽게 빠지게 만들 수 있습니다. 다양한 미디어를 통해 균형 잡힌 시각을 갖는 것이 중요합니다.</div>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">반면 TV는 어땠나요? 과거 지상파 방송들은 <b>의도적으로 다양한 장르와 시사 프로그램을 편성</b>하여 시청자들에게 균형 잡힌 시야를 제공하고자 노력했습니다. 내가 원하든 원치 않든, 뉴스, 다큐멘터리, 교양 프로그램 등을 접하며 자연스럽게 세상의 다양한 면을 알게 되었죠. AI는 아직 이런 <b>&lsquo;균형의 감각&rsquo;</b>을 완전히 대체하지 못하는 것 같습니다. 이 점이 TV가 가진 공익적 역할의 중요한 부분이라고 생각해요.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/bbWXgT/dJMcag435cE/kwwLJMB81YcUXkMOyKQKb1/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bbWXgT/dJMcag435cE/kwwLJMB81YcUXkMOyKQKb1/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/bbWXgT/dJMcag435cE/kwwLJMB81YcUXkMOyKQKb1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbbWXgT%2FdJMcag435cE%2FkwwLJMB81YcUXkMOyKQKb1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"TV를 함께 보는 가족과 각자 기기를 보는 개인들을 대비하여 공동체와 개인의 경험을 표현.\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b> ️ 5. TV는 여전히 '공공의 미디어'로서 그 역할을 다한다</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">유튜브가 주로 광고 수익을 기반으로 한 상업적 플랫폼이라면, TV는 여전히 <b>&lsquo;공공적 미디어&rsquo;</b>로서의 중요한 가치를 지닙니다. 비상 상황에서 재난 속보를 실시간으로 전달하고, 중요한 선거 개표 방송을 통해 민주주의 과정을 중계하며, 사회적 이슈에 대한 심층 보도를 통해 공론의 장을 형성하는 역할은 2025년 현재에도 TV가 가장 강력하게 수행하는 기능입니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">물론 유튜브를 통해서도 속보나 사회적 이슈를 접할 수 있지만, 파편화된 정보와 개인화된 추천 알고리즘 속에서는 <b>공신력 있는 정보를 신속하고 일관성 있게 전달하는 데 한계</b>가 있을 수밖에 없어요. 특히 국가적 재난이나 중대한 사회적 의제에 대해서는 모든 국민이 같은 정보를 동시에 접하고 함께 대응하는 것이 중요합니다. 이점에서 TV는 여전히 대체 불가능한 역할을 담당하고 있습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">그러므로 유튜브가 아무리 성장하고 개인화된 콘텐츠 소비를 주도하더라도, <b>&lsquo;공익적 미디어&rsquo;로서의 TV의 자리는 쉽게 사라지지 않을 겁니다.</b> 오히려 급변하는 미디어 환경 속에서 그 중요성은 더욱 부각될 수도 있다고 생각해요. 다양한 관점과 균형 잡힌 정보 전달이라는 기본적인 책무는 상업적 이윤 추구만으로는 완벽히 채워질 수 없으니까요.</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  6. 생성형 AI 시대, '인간적인 콘텐츠'가 진정한 경쟁력이 된다</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">미래에는 AI가 영상 콘텐츠의 90% 이상을 만들어낼지도 모른다는 예측도 나오고 있습니다. 정말 놀라운 기술의 발전이죠. 하지만 저는 사람들이 여전히 <b>&lsquo;사람이 직접 만든 콘텐츠&rsquo;를 더욱 신뢰하고 가치를 둔다</b>고 봅니다. 왜냐하면 우리는 기계의 완벽한 논리보다는, 인간의 진솔한 감정과 경험에 더 깊이 반응하기 때문이에요.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">앞으로의 미디어 경쟁은 단순히 &ldquo;누가 더 기술적으로 잘 만드는가?&rdquo;를 넘어, <b>&ldquo;누가 더 인간적으로, 진정성 있게 이야기하는가?&rdquo;</b>에 달려 있을 것이라고 확신합니다. AI는 완벽한 형식을 구현할 수 있지만, 그 속에 담긴 의미와 감동, 그리고 사람 사이의 공감대를 형성하는 능력은 여전히 인간의 고유한 영역으로 남아있을 겁니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">결국 AI는 효율성을 제공하고 콘텐츠의 양을 폭발적으로 늘리겠지만, <b>진정한 울림을 주는 '이야기꾼'은 여전히 인간</b>이라는 사실을 명심해야 합니다. 이 근본적인 차이가 바로 유튜브가 TV를 완전히 대체할 수 없는 가장 중요한 이유이며, 다가올 AI 시대의 콘텐츠 전략에서 우리가 반드시 놓치지 말아야 할 핵심 가치라고 생각해요.</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>✅ 결론: 유튜브는 TV의 '끝'이 아닌, 또 다른 '진화'다</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">유튜브가 TV를 완전히 대체했다는 말은, 어쩌면 성급한 판단일지도 모릅니다. 저는 유튜브가 TV의 기능을 완전히 소멸시킨 것이 아니라, <b>TV가 해오던 많은 역할을 새로운 디지털 환경에 맞춰 진화시킨 플랫폼</b>이라고 생각해요.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">유튜브는 개인화된 미디어로서 사용자의 취향을 깊이 파고들지만, TV는 여전히 공공적이고 공동체적인 미디어로서 사회적 역할을 다하고 있습니다. 그리고 2025년 현재, 생성형 AI의 등장으로 이 둘의 경계는 더욱 흐려지고 있죠.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">하지만 분명한 건 하나입니다. 다가올 AI 시대의 미디어 경쟁은 단순한 기술의 싸움이 아니라, <b>&lsquo;인간성의 복원력 싸움&rsquo;</b>이라는 점입니다. 기계는 아무리 정교하고 완벽한 영상을 만들어낼 수 있어도, 그 안에 담긴 이야기를 진심으로 &lsquo;전달&rsquo;하고 사람의 마음을 움직이는 것은 여전히 인간의 고유한 영역으로 남아있습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">결국, 유튜브와 TV는 서로 다른 방식으로 우리의 삶에 스며들어 있을 뿐, 각자의 가치와 역할을 가지고 공존하며 미디어의 미래를 만들어갈 것이라고 믿습니다.</p>\n<div style=\"background-color: #f8f9fa; border: 1px solid #dadce0; border-radius: 8px; box-shadow: 0 4px 12px rgba(0,0,0,0.1); padding: 25px; margin: 40px 0;\">\n<div style=\"font-size: 26px; color: #1a73e8; font-weight: bold; margin-bottom: 15px; padding-bottom: 10px; border-bottom: 2px solid #1a73e8;\">  핵심 요약</div>\n<div style=\"font-size: 17px; line-height: 1.8;\">\n<p style=\"margin-bottom: 10px;\" data-ke-size=\"size16\">✔️ <b>유튜브의 무한한 선택권은 '결정 피로'를 유발</b>하며, 단순했던 TV 시절의 시청 리듬을 그립게 만듭니다.</p>\n<p style=\"margin-bottom: 10px;\" data-ke-size=\"size16\">✔️ <b>생성형 AI는 콘텐츠 양을 늘리지만, '인간적 진정성'을 희석</b>시켜 기술적 완벽함과 감동 사이의 간극을 만듭니다.</p>\n<p style=\"margin-bottom: 10px;\" data-ke-size=\"size16\">✔️ <b>TV는 여전히 '공동체적 경험'과 '공공의 미디어'로서의 책임</b>을 다하며 대체 불가능한 역할을 수행합니다.</p>\n<p style=\"margin-bottom: 0;\" data-ke-size=\"size16\">✔️ <b>미래 미디어의 진정한 경쟁력은 '기술'이 아닌 '인간력'</b>, 즉 감동을 주는 인간적인 이야기에 달려 있습니다.</p>\n</div>\n<div style=\"font-size: 14px; color: #5f6368; margin-top: 25px; padding-top: 15px; border-top: 1px dashed #dadce0;\"><i>미디어 환경의 변화 속에서도, 결국 사람의 마음을 움직이는 것은 기술이 아닌 '사람의 이야기'라는 점을 잊지 말아야 합니다.</i></div>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>❓ 자주 묻는 질문 (FAQ)</b></h2>\n<h3 style=\"font-size: 18px; color: #1a73e8; margin-top: 25px; margin-bottom: 10px;\" data-ke-size=\"size23\">Q1. 유튜브가 TV를 완전히 대체하지 못하는 가장 큰 이유는 무엇인가요?</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">가장 큰 이유는 TV가 제공하는 <b>'공동체적 시청 경험'</b>과 <b>'공공 미디어로서의 역할'</b>을 유튜브가 완벽히 대체하기 어렵기 때문입니다. 유튜브는 개인화에 강하지만, 재난 속보나 사회적 이슈의 공론장 역할, 그리고 같은 시대를 공유하는 문화적 경험 제공에는 TV가 여전히 더 강력합니다.</p>\n<h3 style=\"font-size: 18px; color: #1a73e8; margin-top: 25px; margin-bottom: 10px;\" data-ke-size=\"size23\">Q2. 생성형 AI가 콘텐츠 제작에 미치는 긍정적 영향과 부정적 영향은 무엇인가요?</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">긍정적인 영향으로는 <b>콘텐츠 제작의 효율성 증대 및 양적 폭발적인 증가</b>를 들 수 있습니다. 하지만 부정적인 영향으로는 <b>'인간적인 진정성'과 '깊이 있는 서사'의 부재</b>로 인해 기술적으로 완벽하지만 감동 없는 콘텐츠가 양산될 수 있다는 점입니다.</p>\n<h3 style=\"font-size: 18px; color: #1a73e8; margin-top: 25px; margin-bottom: 10px;\" data-ke-size=\"size23\">Q3. '결정 피로'란 무엇이며, 유튜브 시청 시 어떻게 나타날 수 있나요?</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">'결정 피로'는 너무 많은 선택지 앞에서 결정을 내리는 데 지쳐 심리적으로 피로감을 느끼는 현상입니다. 유튜브에서는 수많은 영상 썸네일과 끊임없는 추천 목록 앞에서 무엇을 볼지 계속 고민하다가 결국 아무것도 보지 못하거나 만족도가 떨어지는 결과를 초래할 수 있습니다.</p>\n</div>\n<script type=\"application/ld+json\">\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"FAQPage\",\n  \"mainEntity\": [\n    {\n      \"@type\": \"Question\",\n      \"name\": \"유튜브가 TV를 완전히 대체하지 못하는 가장 큰 이유는 무엇인가요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"가장 큰 이유는 TV가 제공하는 '공동체적 시청 경험'과 '공공 미디어로서의 역할'을 유튜브가 완벽히 대체하기 어렵기 때문입니다. 유튜브는 개인화에 강하지만, 재난 속보나 사회적 이슈의 공론장 역할, 그리고 같은 시대를 공유하는 문화적 경험 제공에는 TV가 여전히 더 강력합니다.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"생성형 AI가 콘텐츠 제작에 미치는 긍정적 영향과 부정적 영향은 무엇인가요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"긍정적인 영향으로는 콘텐츠 제작의 효율성 증대 및 양적 폭발적인 증가를 들 수 있습니다. 하지만 부정적인 영향으로는 '인간적인 진정성'과 '깊이 있는 서사'의 부재로 인해 기술적으로 완벽하지만 감동 없는 콘텐츠가 양산될 수 있다는 점입니다.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"'결정 피로'란 무엇이며, 유튜브 시청 시 어떻게 나타날 수 있나요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"'결정 피로'는 너무 많은 선택지 앞에서 결정을 내리는 데 지쳐 심리적으로 피로감을 느끼는 현상입니다. 유튜브에서는 수많은 영상 썸네일과 끊임없는 추천 목록 앞에서 무엇을 볼지 계속 고민하다가 결국 아무것도 보지 못하거나 만족도가 떨어지는 결과를 초래할 수 있습니다.\"\n      }\n    }\n  ]\n}\n</script>",
        "contentSnippet": "최근 거실 TV는 넷플릭스를 넘어 유튜브가 점령한 듯 보이죠. 뉴스, 예능, 드라마 할 것 없이 모두 유튜브로 소비되는 시, 우리는 정말 TV를 떠나왔을까요? 생성형 AI 시대, 콘텐츠의 홍수 속에서 우리가 놓치고 있는 '인간적인 이야기'의 가치와 유튜브가 TV를 완전히 대체할 수 없는 진짜 이유를 파헤쳐봅니다.\n\n\n  1. 유튜브의 '무한 자유'가 역설적으로 '결정 피로'를 부른다\n유튜브의 가장 큰 매력 중 하나는 바로 ‘선택의 자유’라고 생각해요. 언제든 원하는 영상을 골라볼 수 있고, AI가 사용자의 취향을 분석해서 딱 맞는 콘텐츠를 추천해주죠. 마치 나만을 위한 비서가 있는 것 같은 기분마저 듭니다. 그런데 말이죠, 이 끝없이 펼쳐진 선택지들이 때로는 피로감으로 다가오기도 합니다.\n저만 그런가요? “오늘은 뭘 볼까?” 하며 수십 개의 썸네일을 넘기다가 결국은 아무것도 제대로 보지 못한 채 시간이 흘러버리는 경험, 여러분도 한두 번쯤 있으실 거예요. 이런 현상을 ‘결정 피로(Decision Fatigue)’라고 부르는데요. 무한한 자유가 역설적으로 더 큰 스트레스를 안겨주는 거죠. 보고 싶은 건 많고, 시간은 한정적인데, 내 선택이 과연 최선인지 계속 의심하게 됩니다.\n생각해보면, 예전 TV 시절에는 이런 고민이 훨씬 덜했어요. 방송사에서 정해준 편성표에 맞춰 모두가 같은 시간에 ‘함께’ 드라마를 보고, 예능을 보며 웃었죠. 이런 단순함이 오히려 시청자들에게 ‘시청의 리듬’을 만들어주고, 콘텐츠에 온전히 몰입할 수 있도록 도와줬던 것 같습니다. 요즘처럼 복잡한 세상에선 이런 단순함이 주는 편안함이 가끔 그립기도 해요.\n  팁: 결정 피로를 줄이려면, 시청할 콘텐츠의 장르나 시청 시간을 미리 정해두거나, 정주행할 시리즈를 한두 개만 집중해서 보는 것도 좋은 방법이에요!\n ‍ ‍ ‍  2. TV는 '공동체 경험'을, 유튜브는 '개인의 세계'를 확장한다\nTV는 단순히 콘텐츠를 보여주는 매체 그 이상이었어요. 온 가족이 거실에 모여 같은 예능 프로그램을 보며 웃고 떠들거나, 다음 날 학교나 직장에서 친구, 동료들과 어젯밤 드라마 이야기에 꽃을 피웠던 경험, 다들 있으실 겁니다. 이건 단순한 콘텐츠 소비가 아니라, ‘공유된 문화 경험(Shared Cultural Experience)’이자 ‘공동체의 연결고리’였죠.\n하지만 유튜브는 그 방식이 완전히 다릅니다. 각자의 스마트폰이나 태블릿 앞에서 각자의 알고리즘이 추천하는 영상들을 보고 있어요. 어떤 사람은 인기 브이로그를, 다른 사람은 심층적인 정치 분석 영상을, 또 어떤 사람은 한창 빠져있는 게임 방송을 보고 있을 겁니다. 결국 유튜브는 공동체의 연결 대신, 개개인의 세계를 심도 있게 확장시켜주는 역할을 합니다.\n물론 개인의 취향을 깊이 파고들 수 있다는 장점은 분명하지만, 문제는 이제 “같은 것을 본 사람”을 찾기가 점점 어려워진다는 점이에요. 과거에는 “어제 그 드라마 봤어?” 한마디로 대화가 시작되었지만, 이제는 각자의 알고리즘이 만든 세상 속에서 서로 다른 경험을 쌓아가고 있습니다. 이렇게 단절된 경험은 소통의 폭을 좁히고, 때로는 고립감을 느끼게 할 수도 있어요.\n\n\n  3. 생성형 AI 시대, 콘텐츠의 홍수 속에 '의미'가 사라진다\n현재 2025년, 생성형 AI(Generative AI)는 유튜브 콘텐츠 제작 방식을 급진적으로 변화시키고 있습니다. 이제 AI는 영상 편집, 자막 생성, 심지어 내레이션까지 자동으로 처리해주고, 더 나아가서는 AI가 직접 영상을 기획하고 제작하는 수준에 이르렀죠. 덕분에 콘텐츠의 양(量)은 폭발적으로 증가했지만, 그 이면에는 우려스러운 그림자가 드리워져 있습니다.\n바로 콘텐츠가 가진 ‘질(質)’과 ‘진정성’이 점점 옅어지고 있다는 점입니다. AI가 만든 영상은 기술적으로는 완벽할지 모릅니다. 매끄러운 화면 전환, 완벽한 발음의 내레이션, 깔끔한 자막 등 흠잡을 데가 없어 보이죠. 하지만 그 속에는 인간만이 전달할 수 있는 감정, 미묘한 맥락, 그리고 깊이 있는 서사적 여운이 부족합니다.\n결국 AI는 ‘기술적으로 완벽한 콘텐츠’는 무한정 만들어낼 수 있지만, ‘사람의 마음에 깊이 남는 이야기’를 만드는 데는 한계가 있습니다. 진정한 의미에서 사람들을 울리고 웃기며, 생각하게 만드는 콘텐츠는 여전히 인간의 손길, 즉 인간적인 시각과 경험에서 비롯된다고 생각해요. 저는 이 차이가 바로 생성형 AI 시대에 우리가 주목해야 할 가장 중요한 지점이라고 봅니다.\n  4. 알고리즘의 편향 — 유튜브는 우리를 '확증 편향'에 가둔다\n유튜브의 AI 추천 시스템은 정말이지 놀랍도록 정교합니다. 사용자가 어떤 영상을 좋아하는지 귀신같이 알아내고, 계속해서 취향에 맞는 영상을 제안해주죠. 하지만 이 친절함 뒤에는 ‘디지털 편향(Digital Bias)’이라는 숨겨진 위험이 도사리고 있습니다.\nAI는 우리에게 “당신이 좋아할 만한 걸 더 보여줄게”라고 말하지만, 이건 동시에 “당신이 좋아하지 않을 만한 다른 세계는 보여주지 않을게”라는 의미가 될 수 있습니다. 즉, 우리가 이미 가지고 있는 생각이나 신념을 강화하는 콘텐츠만을 계속 보여줌으로써 ‘확증 편향(Confirmation Bias)’에 갇히게 만드는 것이죠. 결국 우리는 점점 더 비슷한 정보와 관점 속에 머물게 되고, 시야는 좁아질 수밖에 없습니다.\n⚠️ 경고: 알고리즘 편향은 특정 정보에만 노출되게 하여, 잘못된 정보나 극단적인 관점에 쉽게 빠지게 만들 수 있습니다. 다양한 미디어를 통해 균형 잡힌 시각을 갖는 것이 중요합니다.\n반면 TV는 어땠나요? 과거 지상파 방송들은 의도적으로 다양한 장르와 시사 프로그램을 편성하여 시청자들에게 균형 잡힌 시야를 제공하고자 노력했습니다. 내가 원하든 원치 않든, 뉴스, 다큐멘터리, 교양 프로그램 등을 접하며 자연스럽게 세상의 다양한 면을 알게 되었죠. AI는 아직 이런 ‘균형의 감각’을 완전히 대체하지 못하는 것 같습니다. 이 점이 TV가 가진 공익적 역할의 중요한 부분이라고 생각해요.\n\n\n ️ 5. TV는 여전히 '공공의 미디어'로서 그 역할을 다한다\n유튜브가 주로 광고 수익을 기반으로 한 상업적 플랫폼이라면, TV는 여전히 ‘공공적 미디어’로서의 중요한 가치를 지닙니다. 비상 상황에서 재난 속보를 실시간으로 전달하고, 중요한 선거 개표 방송을 통해 민주주의 과정을 중계하며, 사회적 이슈에 대한 심층 보도를 통해 공론의 장을 형성하는 역할은 2025년 현재에도 TV가 가장 강력하게 수행하는 기능입니다.\n물론 유튜브를 통해서도 속보나 사회적 이슈를 접할 수 있지만, 파편화된 정보와 개인화된 추천 알고리즘 속에서는 공신력 있는 정보를 신속하고 일관성 있게 전달하는 데 한계가 있을 수밖에 없어요. 특히 국가적 재난이나 중대한 사회적 의제에 대해서는 모든 국민이 같은 정보를 동시에 접하고 함께 대응하는 것이 중요합니다. 이점에서 TV는 여전히 대체 불가능한 역할을 담당하고 있습니다.\n그러므로 유튜브가 아무리 성장하고 개인화된 콘텐츠 소비를 주도하더라도, ‘공익적 미디어’로서의 TV의 자리는 쉽게 사라지지 않을 겁니다. 오히려 급변하는 미디어 환경 속에서 그 중요성은 더욱 부각될 수도 있다고 생각해요. 다양한 관점과 균형 잡힌 정보 전달이라는 기본적인 책무는 상업적 이윤 추구만으로는 완벽히 채워질 수 없으니까요.\n  6. 생성형 AI 시대, '인간적인 콘텐츠'가 진정한 경쟁력이 된다\n미래에는 AI가 영상 콘텐츠의 90% 이상을 만들어낼지도 모른다는 예측도 나오고 있습니다. 정말 놀라운 기술의 발전이죠. 하지만 저는 사람들이 여전히 ‘사람이 직접 만든 콘텐츠’를 더욱 신뢰하고 가치를 둔다고 봅니다. 왜냐하면 우리는 기계의 완벽한 논리보다는, 인간의 진솔한 감정과 경험에 더 깊이 반응하기 때문이에요.\n앞으로의 미디어 경쟁은 단순히 “누가 더 기술적으로 잘 만드는가?”를 넘어, “누가 더 인간적으로, 진정성 있게 이야기하는가?”에 달려 있을 것이라고 확신합니다. AI는 완벽한 형식을 구현할 수 있지만, 그 속에 담긴 의미와 감동, 그리고 사람 사이의 공감대를 형성하는 능력은 여전히 인간의 고유한 영역으로 남아있을 겁니다.\n결국 AI는 효율성을 제공하고 콘텐츠의 양을 폭발적으로 늘리겠지만, 진정한 울림을 주는 '이야기꾼'은 여전히 인간이라는 사실을 명심해야 합니다. 이 근본적인 차이가 바로 유튜브가 TV를 완전히 대체할 수 없는 가장 중요한 이유이며, 다가올 AI 시대의 콘텐츠 전략에서 우리가 반드시 놓치지 말아야 할 핵심 가치라고 생각해요.\n✅ 결론: 유튜브는 TV의 '끝'이 아닌, 또 다른 '진화'다\n유튜브가 TV를 완전히 대체했다는 말은, 어쩌면 성급한 판단일지도 모릅니다. 저는 유튜브가 TV의 기능을 완전히 소멸시킨 것이 아니라, TV가 해오던 많은 역할을 새로운 디지털 환경에 맞춰 진화시킨 플랫폼이라고 생각해요.\n유튜브는 개인화된 미디어로서 사용자의 취향을 깊이 파고들지만, TV는 여전히 공공적이고 공동체적인 미디어로서 사회적 역할을 다하고 있습니다. 그리고 2025년 현재, 생성형 AI의 등장으로 이 둘의 경계는 더욱 흐려지고 있죠.\n하지만 분명한 건 하나입니다. 다가올 AI 시대의 미디어 경쟁은 단순한 기술의 싸움이 아니라, ‘인간성의 복원력 싸움’이라는 점입니다. 기계는 아무리 정교하고 완벽한 영상을 만들어낼 수 있어도, 그 안에 담긴 이야기를 진심으로 ‘전달’하고 사람의 마음을 움직이는 것은 여전히 인간의 고유한 영역으로 남아있습니다.\n결국, 유튜브와 TV는 서로 다른 방식으로 우리의 삶에 스며들어 있을 뿐, 각자의 가치와 역할을 가지고 공존하며 미디어의 미래를 만들어갈 것이라고 믿습니다.\n  핵심 요약\n✔️ 유튜브의 무한한 선택권은 '결정 피로'를 유발하며, 단순했던 TV 시절의 시청 리듬을 그립게 만듭니다.\n✔️ 생성형 AI는 콘텐츠 양을 늘리지만, '인간적 진정성'을 희석시켜 기술적 완벽함과 감동 사이의 간극을 만듭니다.\n✔️ TV는 여전히 '공동체적 경험'과 '공공의 미디어'로서의 책임을 다하며 대체 불가능한 역할을 수행합니다.\n✔️ 미래 미디어의 진정한 경쟁력은 '기술'이 아닌 '인간력', 즉 감동을 주는 인간적인 이야기에 달려 있습니다.\n미디어 환경의 변화 속에서도, 결국 사람의 마음을 움직이는 것은 기술이 아닌 '사람의 이야기'라는 점을 잊지 말아야 합니다.\n❓ 자주 묻는 질문 (FAQ)\nQ1. 유튜브가 TV를 완전히 대체하지 못하는 가장 큰 이유는 무엇인가요?\n가장 큰 이유는 TV가 제공하는 '공동체적 시청 경험'과 '공공 미디어로서의 역할'을 유튜브가 완벽히 대체하기 어렵기 때문입니다. 유튜브는 개인화에 강하지만, 재난 속보나 사회적 이슈의 공론장 역할, 그리고 같은 시대를 공유하는 문화적 경험 제공에는 TV가 여전히 더 강력합니다.\nQ2. 생성형 AI가 콘텐츠 제작에 미치는 긍정적 영향과 부정적 영향은 무엇인가요?\n긍정적인 영향으로는 콘텐츠 제작의 효율성 증대 및 양적 폭발적인 증가를 들 수 있습니다. 하지만 부정적인 영향으로는 '인간적인 진정성'과 '깊이 있는 서사'의 부재로 인해 기술적으로 완벽하지만 감동 없는 콘텐츠가 양산될 수 있다는 점입니다.\nQ3. '결정 피로'란 무엇이며, 유튜브 시청 시 어떻게 나타날 수 있나요?\n'결정 피로'는 너무 많은 선택지 앞에서 결정을 내리는 데 지쳐 심리적으로 피로감을 느끼는 현상입니다. 유튜브에서는 수많은 영상 썸네일과 끊임없는 추천 목록 앞에서 무엇을 볼지 계속 고민하다가 결국 아무것도 보지 못하거나 만족도가 떨어지는 결과를 초래할 수 있습니다.\n\n\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"FAQPage\",\n  \"mainEntity\": [\n    {\n      \"@type\": \"Question\",\n      \"name\": \"유튜브가 TV를 완전히 대체하지 못하는 가장 큰 이유는 무엇인가요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"가장 큰 이유는 TV가 제공하는 '공동체적 시청 경험'과 '공공 미디어로서의 역할'을 유튜브가 완벽히 대체하기 어렵기 때문입니다. 유튜브는 개인화에 강하지만, 재난 속보나 사회적 이슈의 공론장 역할, 그리고 같은 시대를 공유하는 문화적 경험 제공에는 TV가 여전히 더 강력합니다.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"생성형 AI가 콘텐츠 제작에 미치는 긍정적 영향과 부정적 영향은 무엇인가요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"긍정적인 영향으로는 콘텐츠 제작의 효율성 증대 및 양적 폭발적인 증가를 들 수 있습니다. 하지만 부정적인 영향으로는 '인간적인 진정성'과 '깊이 있는 서사'의 부재로 인해 기술적으로 완벽하지만 감동 없는 콘텐츠가 양산될 수 있다는 점입니다.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"'결정 피로'란 무엇이며, 유튜브 시청 시 어떻게 나타날 수 있나요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"'결정 피로'는 너무 많은 선택지 앞에서 결정을 내리는 데 지쳐 심리적으로 피로감을 느끼는 현상입니다. 유튜브에서는 수많은 영상 썸네일과 끊임없는 추천 목록 앞에서 무엇을 볼지 계속 고민하다가 결국 아무것도 보지 못하거나 만족도가 떨어지는 결과를 초래할 수 있습니다.\"\n      }\n    }\n  ]\n}",
        "guid": "https://muzbox.tistory.com/483686",
        "categories": [
          "AI, 미래기술/AI 인사이트",
          "AI 시대 미디어 트렌드",
          "결정 피로 콘텐츠",
          "공공 미디어 역할",
          "디지털 확증 편향",
          "미디어 공동체 경험",
          "생성형 AI 미디어",
          "알고리즘 편향",
          "유튜브 TV 대체",
          "인간적인 콘텐츠",
          "콘텐츠 진정성"
        ],
        "isoDate": "2025-12-04T01:57:03.000Z"
      }
    ]
  },
  {
    "name": "동우리의 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "하테나",
    "category": "개인",
    "posts": []
  },
  {
    "name": "늑돌이네 라지온",
    "category": "개인",
    "posts": []
  },
  {
    "name": "루리웹 - 루리웹 리뷰 게시판",
    "category": "게임",
    "posts": [
      {
        "creator": "｜RULIWEB｜",
        "title": "손과 손을 맞잡아 이어지는 태고의 봉인 전쟁, 젤다무쌍 봉인 전기",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2398",
        "pubDate": "Mon, 08 Dec 2025 15:21:42 +0900",
        "author": "｜RULIWEB｜",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i1.ruliweb.com/thumb/25/12/08/19afc9ae1d851ad6b.png\">",
        "contentSnippet": "",
        "categories": [
          "게임툰"
        ],
        "isoDate": "2025-12-08T06:21:42.000Z"
      },
      {
        "creator": "｜RULIWEB｜",
        "title": "악역영애 4컷 만화 - 29화, 밥을 더 맛있게 먹는 데스와~",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2397",
        "pubDate": "Wed, 03 Dec 2025 23:33:46 +0900",
        "author": "｜RULIWEB｜",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i3.ruliweb.com/thumb/25/12/03/19ae4a1b79d51ad6b.jpg\">",
        "contentSnippet": "",
        "categories": [
          "웹툰"
        ],
        "isoDate": "2025-12-03T14:33:46.000Z"
      },
      {
        "creator": "［RULIWEB］",
        "title": "[MULTI] 비슷하면서도 한층 풍부해진 시리즈의 1.5, 옥토패스 트래블러 0",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2396",
        "pubDate": "Wed, 03 Dec 2025 20:00:10 +0900",
        "author": "［RULIWEB］",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i3.ruliweb.com/thumb/25/12/03/19ae3dd2fee5104c1.jpg\">",
        "contentSnippet": "",
        "categories": [
          "리뷰"
        ],
        "isoDate": "2025-12-03T11:00:10.000Z"
      }
    ]
  },
  {
    "name": "Reasontobe",
    "category": "개인",
    "posts": []
  },
  {
    "name": "에스티마의 인터넷이야기 EstimaStory.com",
    "category": "개인",
    "posts": []
  },
  {
    "name": "나긋한 개발 - 데비안 리눅스와 프로그램 언어",
    "category": "개인",
    "posts": []
  },
  {
    "name": "일상을 여행처럼...",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Just hack'em",
    "category": "개인",
    "posts": []
  },
  {
    "name": "C++ Truths",
    "category": "개인",
    "posts": []
  },
  {
    "name": "jacking75",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Joel on Software",
    "category": "개인",
    "posts": []
  },
  {
    "name": "벤자민로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "악보쓰는 프로그래머",
    "category": "개인",
    "posts": []
  },
  {
    "name": "쭌안아빠",
    "category": "개인",
    "posts": []
  },
  {
    "name": "A Gangster World",
    "category": "개인",
    "posts": []
  },
  {
    "name": "요우의 내맘대로 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자스럽다",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Against All Odds.",
    "category": "개인",
    "posts": []
  },
  {
    "name": "움직이는 게임서버",
    "category": "개인",
    "posts": []
  },
  {
    "name": "이상욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "임철재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "어쩐지 오늘은",
    "category": "개인",
    "posts": [
      {
        "title": "Google Antigravity 사용법",
        "link": "https://zzsza.github.io/ai/2025/12/08/how-to-use-antigravity/",
        "pubDate": "Mon, 08 Dec 2025 00:00:00 +0000",
        "content": "<p>안녕하세요. 이번 글은 Google의 Antigravity 사용법에 대해 작성한 글입니다.</p>\n\n<ul>\n  <li>키워드 : Google Antigravity, Google Antigravity 사용법</li>\n</ul>\n\n<p><br />\n<br /></p>\n\n<hr />\n\n<h1 id=\"antigravity\">Antigravity</h1>\n<h2 id=\"이름의-유래\">이름의 유래</h2>\n<ul>\n  <li><a href=\"https://antigravity.google/blog/introducing-google-antigravity\">Antigravity 소개글</a>에 작성되어 있는 비전\n    <ul>\n      <li>Our vision is to ultimately enable anyone with an idea to experience liftoff and build that idea into reality.</li>\n      <li>Liftoff라는 용어는 항공기 전체가 지면에서 완전히 떨어지는 시점을 의미하는데, 구글은 자신의 아이디어 구현할 때 누구나 사용할 수 있는 도구를 만들고 싶었던 것 같음. 즉, 개발할 때 생기는 여러 이슈들을 중력이라 생각하고 그것을 대항할 수 있는 도구</li>\n    </ul>\n  </li>\n  <li>여담으로 Python에서 import antigravity를 하면 XKCD 만화(353번)를 웹 브라우저로 열어주는 이스터에그가 발생하는데, 관련은 없지만 익숙한 용어였음</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/lgbqgkff8nampxb1zbrzm/2025-12-03-3.59.03.png?rlkey=dr7nlj0eeo6ymg5hz0o461sq2&amp;raw=1\" /></p>\n\n<p><br /></p>\n\n<h2 id=\"핵심-원칙\">핵심 원칙</h2>\n<ul>\n  <li>Antigravity의 핵심 원칙은 Trust, Autonomy, Feedback, Self-improvement</li>\n</ul>\n\n<h3 id=\"trust\">Trust</h3>\n<ul>\n  <li>오늘날의 대부분의 제품은 두 케이스에 속함\n    <ul>\n      <li>(1) 에이전트가 수행한 모든 Action과 Tool 호출을 사용자에게 보여줌</li>\n      <li>(2) 작업의 컨텍스트나 검증할 방법 없이 최종 코드 변경 사항만 보여줌</li>\n      <li>이런 제품들은 에이전트가 왜 이 작업을 했는지, 어떻게 확인해야 하는지를 알기 어려움.</li>\n    </ul>\n  </li>\n  <li>Antigravity는 사용자가 에이전트가 수행할 작업에 대한 신뢰를 가질 수 있도록 Actifact와 Verfication result(검증 결과)를 제공해 컨텍스트를 제공함\n    <ul>\n      <li>단순히 개별 Tool 호출이 전부 보이는 것이 아닌, 호출들이 Task 단위로 묶어서 표시함</li>\n      <li>Task에 대한 추상화된 정리와 진행 상황을 확인할 수 있음</li>\n      <li>사용자가 검증하기 쉬운 형식의 Artifact를 생성함. 예를 들어 Task list(작업 목록), Implementation plan(구현 계획), Walkthrough(단계별 설명서), 스크린샷, 브라우저 녹화 영상</li>\n    </ul>\n  </li>\n  <li>사용하면서 인상 깊은 부분은 웹브라우저 작업을 할 때 녹화가 되는 기능으로 작업을 어떻게 진행했는지 확인할 수 있었음. Plan 버전으로 실행할 때 Implementation plan, Walkthrough를 제공하는 것도 좋았음</li>\n</ul>\n\n<h3 id=\"autonomy\">Autonomy</h3>\n<ul>\n  <li>요즘 가장 직관적인 제품의 형태는 여러 Surface(편집기, 브라우저, 터미널)에 내장된 에이전트와 동기적으로 동작하는 형태\n    <ul>\n      <li>에이전트가 자율적으로 프론트엔드 코드를 구현하고, 터미널에서 로컬호스트 실행하고, 브라우저를 작동시켜 새로운 기능이 작동하는지 테스트하는 형태</li>\n    </ul>\n  </li>\n  <li>이런 자율성을 최적으로 사용하기 위해 사용자가 에이전트와 비동기적으로 상호 작용할 수 있도록 Manager View를 만들었음</li>\n  <li>Agent Manager View는 여러 에이전트를 병렬로 생성하고 모니터링할 수 있는 관제탑 스타일의 화면</li>\n  <li>기존에 자주 사용하던 VSCode, Cursor 같은 스타일은 Editor View로 존재함(Editor View와 Manager View로 전환하는 단축키는 커맨드(컨트롤) + e)</li>\n</ul>\n\n<h3 id=\"feedback\">Feedback</h3>\n<ul>\n  <li>에이전트의 지능이 좋아지면서 여러 작업이 가능해졌지만, 아직 완벽하지 않음\n    <ul>\n      <li>이런 상황에서 피드백을 제공하면 도움이 됨</li>\n      <li>Antigravity는 모든 Surface나 Artifact에서 비동기 사용자 피드백을 허용함</li>\n      <li>Text Artifact에선 주석을 달 수 있고, 스크린샷에서 영역을 선택해서 주석을 달 수 있음</li>\n    </ul>\n  </li>\n</ul>\n\n<h3 id=\"self-improvement\">Self-improvement</h3>\n<ul>\n  <li>에이전트가 일하면서 배운 내용을 저장하고, 나중에 비슷한 일을 할 때 참조함\n    <ul>\n      <li>명시적 정보 : 유용한 코드 snippet, 아키텍처 정보</li>\n    </ul>\n  </li>\n</ul>\n\n<p><br />\n<br /></p>\n\n<h2 id=\"설치\">설치</h2>\n<ul>\n  <li><a href=\"https://antigravity.google/download\">웹페이지</a>에서 다운로드 가능</li>\n  <li>\n    <p>Mac 사용자라면 brew로도 설치 가능</p>\n\n    <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>  brew install --cask antigravity\n</code></pre></div>    </div>\n  </li>\n  <li>처음에 설치하면 기존에 사용하던 IDE(VS Code, Windsurf, Cursor 등)의 설정을 불러올 수 있고, Start fresh를 눌러서 시작할 수 있음</li>\n  <li>Agent 설정은 Agent-assisted development으로 설정했음</li>\n</ul>\n\n<h3 id=\"antigravity---크롬-확장-프로그램-설치\">Antigravity - 크롬 확장 프로그램 설치</h3>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/21thk8qlegjwzr0vcvmw1/2025-12-03-4.15.53.png?rlkey=vsbfntugs67jend3njbwvd0kn&amp;raw=1\" /></p>\n\n<ul>\n  <li>위와 같은 구성을 확인할 수 있고, VSCode와 다르게 우측 상단에 크롬 아이콘이 있어서 눌러봄</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/whyckpg9x0gcu7cx5ynti/2025-12-03-4.16.18.png?rlkey=bbfmw3i1zardgp4e3p7uqrt87&amp;raw=1\" /></p>\n\n<ul>\n  <li>설치가 필요한데, 이미 크롬이 설치되어 있어서 경로를 직접 수정함\n    <ul>\n      <li>Set custom Chrome binary path 클릭해서 경로 지정함</li>\n    </ul>\n  </li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/vfg4aznlbzr8mm3b0vby0/2025-12-03-4.17.21.png?rlkey=o8j4z8p3j4aogkt9t7urv8vcc&amp;raw=1\" /></p>\n\n<ul>\n  <li>설정에서 Browser로 이동해서 Chrome Binary Path를 지정할 수 있음</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/w9hsk0rmxxbcigck601tk/2025-12-03-4.17.41.png?rlkey=d22usq9uazadt8m30qpb0qq8u&amp;raw=1\" /></p>\n\n<ul>\n  <li>다시 크롬 버튼을 누르니 온보딩 페이지로 나오고, 확장 프로그램을 설치함. 이를 통해 Antigravity에서 크롬을 제어할 수 있음</li>\n</ul>\n\n<p><br />\n<br /></p>\n\n<h1 id=\"agent\">Agent</h1>\n<ul>\n  <li>Agent의 Core Compoent\n    <ul>\n      <li>Reasoning model</li>\n      <li>Tools</li>\n      <li>Artifacts</li>\n      <li>Knowledge</li>\n    </ul>\n  </li>\n  <li>Customization(커스텀 요소)\n    <ul>\n      <li>Agent Modes / Settings</li>\n      <li>MCP</li>\n      <li>Rules / Workflow</li>\n    </ul>\n  </li>\n</ul>\n\n<h2 id=\"models\">Models</h2>\n<ul>\n  <li><a href=\"https://cloud.google.com/model-garden?hl=ko\">Google Vertex Model Garden</a>을 통해 모델 제공\n    <ul>\n      <li>사용자가 원하는 모델을 선택할 수 있음</li>\n      <li>Gemini 3 Pro (high)</li>\n      <li>Gemini 3 Pro (low)</li>\n      <li>Claude Sonnet 4.5</li>\n      <li>Claude Sonnet 4.5 (thinking)</li>\n      <li>Claude Opus 4.5 (thinking)</li>\n      <li>GPT-OSS</li>\n    </ul>\n  </li>\n  <li>사용량 제한은 <a href=\"https://antigravity.google/docs/plans\">Plans</a> 문서에서 확인할 수 있음\n    <ul>\n      <li>현재(25년 12월 기준) Preview라서 무료로 사용 가능하며, Google AI Plan 구독 여부에 따라 제공량이 다름</li>\n      <li>기본 제공\n        <ul>\n          <li>위에 제공하는 Model에 대한 기본 사용</li>\n          <li>Tab completion 무제한 제공</li>\n          <li>Command requests 무제한 제공</li>\n          <li>Agent Manager, Borwser integration 사용 가능</li>\n        </ul>\n      </li>\n      <li>Google AI Ultra : 제일 많은 사용량, 5시간마다 쿼타 갱신</li>\n      <li>Google AI Pro : 많은 사용량, 5시간마다 쿼타 갱신</li>\n      <li>Google AI Plan에 가입하지 않은 경우 적당한 사용량을 제공하고 주마다 쿼타 갱신</li>\n      <li>아직 key를 사용하는 방식은 지원하지 않으나, 추후에 지원할 가능성이 높음</li>\n    </ul>\n  </li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/acmibxdkgq7txkdb8uvzi/2025-12-08-4.02.25.png?rlkey=l1mudboe51efjj339k263bhr4&amp;raw=1\" /></p>\n\n<h3 id=\"antigravity-내부에서-사용하는-모델\">Antigravity 내부에서 사용하는 모델</h3>\n<ul>\n  <li>Antigravity가 동작하는 과정에서 모델을 사용하고 있으며, 사용자가 설정할 수 없음</li>\n  <li>UI 목업 생성, 웹페이지나 앱에서 사용할 이미지 생성, 아키텍처 다이어그램 생성 : Nano Banana Pro</li>\n  <li>브라우저 서브 에이전트가 브라우저에서 클릭, 스크롤, 입력 등 브라우저를 제어할 때 : Gemini 2.5 Pro UI Checkpoint(내부적으로 커스텀한 모델로 추측)</li>\n  <li>체크포인팅, 컨텍스트 요약할 때 : Gemini 2.5 Flash</li>\n  <li>코드의 Semantic Search(의미 기반 검색) : Gemini 2.5 Flash Lite</li>\n</ul>\n\n<h2 id=\"toolsmcp\">Tools(MCP)</h2>\n<ul>\n  <li>MCP를 사용해 Antigravity가 데이터베이스에 직접 접근해서 정보를 가져올 수 있음</li>\n</ul>\n\n<h3 id=\"연결-방법\">연결 방법</h3>\n<ul>\n  <li>우측 상단에 있는 Agent의 우측에 …을 클릭 -&gt; MCP Servers 클릭</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/76sxjf9btplocg1dger2v/2025-12-08-4.14.19.png?rlkey=av0huxzewl1x2nfn0mpcgyg0t&amp;raw=1\" /></p>\n\n<ul>\n  <li>필요한 MCP 검색(저는 supabase)</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/xs6me8yu7to23687ufveq/2025-12-08-4.33.59.png?rlkey=4dps98mk4m43pwrpcn6rqd1as&amp;raw=1\" /></p>\n\n<ul>\n  <li>Install 클릭 후, 환경 설정</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/g493hhbxa4bh9jqxa3kud/2025-12-08-4.35.20.png?rlkey=okzmhg1lh6mf2ko8fycogk313&amp;raw=1\" /></p>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/qwmgrpp8gkjxq6bt6acd7/2025-12-08-4.35.43.png?rlkey=6lc9oe89lsvm2t4q5wbngus7x&amp;raw=1\" /></p>\n\n<ul>\n  <li>이제 MCP의 Tool을 사용할 수 있음</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/684nw0ljk067dayxs358d/2025-12-08-4.39.27.png?rlkey=i3a9v8mol8196kl1e5r8ythkn&amp;raw=1\" /></p>\n\n<h2 id=\"artifacts\">Artifacts</h2>\n<ul>\n  <li>Artifacts는 에이전트가 작업을 완료하거나 작업과 생각을 사용자에게 전달하기 위해 생성하는 모든 것</li>\n  <li>예시\n    <ul>\n      <li>Task list(할 일 목록)</li>\n      <li>Implementation plan(구현 계획)</li>\n      <li>Walkthrough(워크스루) : 변경 사항, 작업 과정 요약</li>\n      <li>Screenshots(화면 캡처)</li>\n      <li>Browser Recordings(브라우저 녹화)</li>\n      <li>Knowledge(지식)</li>\n    </ul>\n  </li>\n  <li>아래 실제로 실행하는 부분에서 확인 가능</li>\n</ul>\n\n<h2 id=\"agent-modes--settings\">Agent Modes / Settings</h2>\n<ul>\n  <li>에이전트의 모드나 설정에 대한 이해가 필요함</li>\n</ul>\n\n<h3 id=\"대화-모드\">대화 모드</h3>\n<ul>\n  <li>대화할 때 2가지 모드 중 선택할 수 있음\n    <ul>\n      <li>Planning, Fast</li>\n      <li>Planning : 작업 실행 전에 Plan을 세움. 복잡한 작업에서 활용하는 것이 좋으며, 작업에 따라 아티팩트 생성, 계획 등을 수행</li>\n      <li>Fast : 에이전트가 작업을 바로 실행함. 간단한 작업에 사용하며, 속도가 중요하고 품질 저하에 대한 걱정이 적을 때 사용</li>\n    </ul>\n  </li>\n  <li>대화할 때 바로 설정할 수 있음</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/hvz491aw707kyoyy0jan3/2025-12-08-4.49.38.png?rlkey=a2n7vpst5702st9hewt19gz78&amp;raw=1\" /></p>\n\n<h3 id=\"전반적인-설정\">전반적인 설정</h3>\n<ul>\n  <li>Antigravity Settings에서 설정할 수 있으며, Artifact Review Policy, Terminal Command Auto Execution Policy를 정의할 수 있음</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/z68sozb9d75ovnzf0p9p4/2025-12-08-4.56.34.png?rlkey=74ohrcqxa2cvi1ziubbre142p&amp;raw=1\" /></p>\n\n<ul>\n  <li>Artifact Review Policy(아티팩트 리뷰 정책)\n    <ul>\n      <li>에이전트가 아티팩트에 대해 리뷰를 어떻게, 언제 물어볼지 결정하는 정책</li>\n      <li>Always Proceed : 에이전트가 리뷰를 요청하지 않고 작업 진행</li>\n      <li>Agent Decides : 에이전트가 리뷰 요청 시점을 스스로 결정</li>\n      <li>Request Review : 에이전트가 항상 리뷰 요청</li>\n    </ul>\n  </li>\n  <li>Terminal Command Auto Execution Policy(터미널 커맨드 자동 실행 정책)\n    <ul>\n      <li>에이전트가 터미널 컴맨드를 자동으로 실행할지 결정하는 정책</li>\n      <li>Always Proceed : 에이전트가 터미널 명령을 실행하기 전에 확인하지 않고 실행</li>\n      <li>Agent Decides : 에이전트가 터미널 명령을 실행하기 전에 스스로 판단</li>\n      <li>Request Review : 에이전트가 터미널 명령을 실행하기 전에 항상 확인</li>\n    </ul>\n  </li>\n  <li>두가지 설정 모두 Agent Decides로 설정하고 사용 중</li>\n  <li>유사하게 Browser Javascript Execution Policy도 존재함(설정 - Browser)\n    <ul>\n      <li>Disabled : 에이전트가 브라우저에서 자바스크립트 코드를 실행하지 않음</li>\n      <li>Always Ask : 에이전트가 항상 자바스크립트 코드를 실행하기 전에 확인</li>\n      <li>Model Decides : 에이전트가 자바스크립트 코드를 실행하기 전에 스스로 판단</li>\n      <li>Turbo : 확인 없이 자바스크립트 코드를 실행함</li>\n    </ul>\n  </li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/vq5mp2ax6b7d65bzd7bmx/2025-12-08-5.12.29.png?rlkey=ts3iqtmlv52zgbw5odpbq3zaz&amp;raw=1\" /></p>\n\n<ul>\n  <li>그 외에 Agent Non-Workspace File Access 설정은 Agent가 지금 작업 폴더와 Antigravity 루트 폴더(`~/.antigravity/) 외의 폴더에 접근할 수 있게 설정할 수 있음</li>\n</ul>\n\n<p><br /></p>\n\n<h2 id=\"rules--workflows\">Rules / Workflows</h2>\n<ul>\n  <li>Rules : 지켜야 할 원칙</li>\n  <li>Workflows : AI가 행동해야 하는 순서 제공</li>\n  <li>Agent의 … 클릭 후 Customization을 누르면 설정할 수 있음</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/rlbedt1nas9yjnrihv0gs/2025-12-08-5.26.38.png?rlkey=o20yz76fbjt1p206vyb1s7ad3&amp;raw=1\" /></p>\n\n<h3 id=\"rules\">Rules</h3>\n<ul>\n  <li>Agent가 따라야 하는 작업 스타일, 가이드를 작성한 마크다운 파일</li>\n  <li>Claude Code나 Gemini CLI를 사용하면 CLAUDE.MD, GEMINI.MD를 만드는데, 이 개념과 같다고 보면 됨</li>\n  <li>Global Rules와 Workspace Rules로 나뉨\n    <ul>\n      <li>Global Rules : <code class=\"language-plaintext highlighter-rouge\">~/.gemini/GEMINI.md</code>에 저장</li>\n      <li>Workspace Rules : 워크스페이스의 <code class=\"language-plaintext highlighter-rouge\">.agent/rules</code>에 저장하고, 해당 워크스페이스에서만 적용</li>\n      <li>Rules 파일 제한 : 12,000자(character)</li>\n    </ul>\n  </li>\n  <li>Customizations에서 +workspace를 눌러서 Workspace Rules를 추가할 수 있음(현재 있는 Global 설정은 한국어 응답하라는 내용이 저장되어 있음)</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/1p9zekq7o0u6jwmpb3rkz/2025-12-08-5.31.09.png?rlkey=x1mj2mypnoxqylx3ver1rjr3n&amp;raw=1\" /></p>\n\n<ul>\n  <li>Workspace Rule도 어떤 상황에 활성화를 할 것인지 옵션이 존재함\n    <ul>\n      <li>Manual : 사용자가 에이전트 채팅창에서 @로 명시적으로 호출할 때 적용</li>\n      <li>Always On : 항상 모든 상황에 적용</li>\n      <li>Model Decision : Rule 파일을 읽고 현재 작업에 이 Rule이 필요한지 모델이 스스로 결정</li>\n      <li>Glob : 특정 파일 패턴과 일치하는 파일을 다룰 때 적용</li>\n    </ul>\n  </li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/2nmrv80un9c4n6c5l103k/2025-12-08-5.33.11.png?rlkey=kbcs8u1dble9cy6gzx6w3yy79&amp;raw=1\" /></p>\n\n<h3 id=\"workflows\">Workflows</h3>\n<ul>\n  <li>workflow는 반복되는 작업을 정리한 파일\n    <ul>\n      <li>작업들을 단계별로 정의하면 에이전트가 그 순서에 맞춰 일을 처리함</li>\n    </ul>\n  </li>\n  <li>실행할 때 채팅창에서 <code class=\"language-plaintext highlighter-rouge\">/워크플로우이름</code>을 입력하면 실행됨</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">.agent/workflows</code> 폴더에 저장됨</li>\n  <li>Customizatios - Workflows - +workspace를 누르면 만들 수 있고, 채팅으로 만들라고 할 수도 있음</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/0aescpxkq8bm6i88ft19w/2025-12-08-5.47.36.png?rlkey=n2ew7fa6bt2cqbn0w1h580j2b&amp;raw=1\" /></p>\n\n<ul>\n  <li>실행하니 정상적으로 동작함</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/5k02ictn45qu04oaenixj/2025-12-08-5.49.59.png?rlkey=j3rfpcz37gayuk2w4kj0xob8m&amp;raw=1\" /></p>\n\n<p><br />\n<br /></p>\n\n<h1 id=\"실제-사용기\">실제 사용기</h1>\n<h2 id=\"웹페이지-취약점-확인-후-동작-테스트\">웹페이지 취약점 확인 후 동작 테스트</h2>\n<ul>\n  <li>개인적으로 만들고 있던 웹페이지의 취약점을 확인하고, 그 후에 실제로 잘 동작하는지 확인해달라고 함</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/9shcp8r1iouy2ha4wl9nc/2025-12-04-5.08.55.png?rlkey=yp0w2dyg8xe01gmk6ue5eylhv&amp;raw=1\" /></p>\n\n<ul>\n  <li>하나씩 확인하는데, 영상을 찍어서 제시함. 이게 Screen Recording</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/0u51isx9o94pi1p2eh0g1/2025-12-04-5.12.11.png?rlkey=enfw10f8fxv76h85zclrt7n7a&amp;raw=1\" /></p>\n\n<ul>\n  <li>작업 완료한 후, 하단에서 여러 내용을 확인할 수 있음\n    <ul>\n      <li>수정된 파일, Artifact(Implementation Plan, Task, Walkthrough)</li>\n    </ul>\n  </li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/skevun8zx5c1173rq49q4/2025-12-04-5.02.55.gif?rlkey=rvom52b2x1b2k3l35hs9h67ir&amp;raw=1\" /></p>\n\n<ul>\n  <li>이번에는 직접 로그인을 한 후 다시 확인해보라고 하니, 로그인 상황에서 테스트를 진행함</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/vn2ylknl017qi9uby46fn/2025-12-04-5.15.11.png?rlkey=cuuxkhytfciv2s75lj99jkjo8&amp;raw=1\" /></p>\n\n<ul>\n  <li>관리자 계정이 아닌 계정으로 테스트하는게 좋을까?라고 물어보니 아래처럼 안내함(일단 false로 주석처리해서 테스트)</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/whujixj06y31xguwcrx9d/2025-12-04-5.17.04.png?rlkey=c8l9sf1dlbz2j5ipjqf89c81i&amp;raw=1\" /></p>\n\n<ul>\n  <li>그 후 테스트하고 성능 측정 후 내용을 공유함</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/z55rumit80cx1okowjt02/2025-12-04-5.26.35.gif?rlkey=de8tywtevt9u1sshj2fm0msz6&amp;raw=1\" /></p>\n\n<ul>\n  <li>Walkthrough 문서에 댓글을 남긴 후, 피드백을 제출함</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/hrm1fj1feem98f7prv2ph/2025-12-05-2.54.29.png?rlkey=x3a7o4ru556si2b36psb7eqjp&amp;raw=1\" /></p>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/2quzlzx4t2ha9om1quhaz/2025-12-05-2.54.41.png?rlkey=t5hvhd3uyemm9wzicuaxv5ji8&amp;raw=1\" /></p>\n\n<ul>\n  <li>제출한 후에 Agent Manager에서 내가 남긴 댓글에 대한 답변을 볼 수 있음</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/qs3vdi7shofopm6fvylw1/2025-12-05-2.56.44.png?rlkey=qj83obp4h8zk3mdulwcy6mwds&amp;raw=1\" /></p>\n\n<h3 id=\"screen-recording-기능\">Screen Recording 기능</h3>\n<ul>\n  <li>Screen Recording은 Antigravity가 <code class=\"language-plaintext highlighter-rouge\">browser_subagent</code>라는 도구를 사용해 브라우저를 제어할 때만 자동으로 수행됨\n    <ul>\n      <li>녹화 시점:  “브라우저를 열어서 확인해줘”라는 요청을 받거나, 스스로 웹페이지 테스트가 필요하다고 판단하여 브라우저 도구를 실행할 때그 세션의 화면이 녹화</li>\n      <li>녹화하는 것: 브라우저 창 내부에서 일어나는 일(클릭, 타이핑, 페이지 이동, 콘솔 로그 확인 등)만 녹화됨</li>\n    </ul>\n  </li>\n  <li>Artifact가 어디에 저장하는지 확인해보니 다음 경로에 저장됨(<code class=\"language-plaintext highlighter-rouge\">/Users/UserName/.gemini/antigravity/</code>)\n    <ul>\n      <li>동영상 용량은 작진 않아서 나중에 관리가 필요할 것으로 예상됨</li>\n    </ul>\n  </li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/eqw9neo8bvfxdpeup19k1/2025-12-04-5.27.35.png?rlkey=a849bwti5myqdzb14dwo80856&amp;raw=1\" /></p>\n\n<h3 id=\"대화-기록\">대화 기록</h3>\n<ul>\n  <li>만약 지난 대화를 찾고 싶다면 이 버튼을 통해서 찾을 수 있음</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/46p3flexpzq89gy9n14st/2025-12-04-6.11.33.png?rlkey=nssd8hk82ca9aoglvyh6oqrzy&amp;raw=1\" /></p>\n\n<p><br />\n<br /></p>\n\n<h2 id=\"아키텍처-이미지-생성-이미지-피드백\">아키텍처 이미지 생성, 이미지 피드백</h2>\n<ul>\n  <li>이번엔 아키텍처를 그려달라고 함\n    <ul>\n      <li>Created Task를 보면 Task가 생성되고, Task의 Progress Updates를 보여줌</li>\n    </ul>\n  </li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/6s2cuk19t4kodpvnriygf/2025-12-07-5.39.13.png?rlkey=4z9p6eujxgaxowdfch16pzwn2&amp;raw=1\" /></p>\n\n<ul>\n  <li>생성된 이미지에서 드래그를 하면 의견을 특정 부분에 줄 수 있음. 이 기능이 꽤 유용함</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/9vmn6n0iia78oyztndsk8/2025-12-07-5.43.58.png?rlkey=954e9vynplba6flzdunbln26z&amp;raw=1\" /></p>\n\n<ul>\n  <li>다른 의견도 주고 Submit을 클릭해서 피드백을 제시함</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/je6kj8nanox6goer4xeoq/2025-12-07-5.45.05.png?rlkey=oxh4n3f5chtu259w09m7ld8r5&amp;raw=1\" /></p>\n\n<ul>\n  <li>피드백을 반영해 이미지가 변경됨</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/qkgnx54wfh9s3vyay4icb/2025-12-07-5.46.28.png?rlkey=pw65x6z55sfhnramncoosop90&amp;raw=1\" /></p>\n\n<p><br />\n<br /></p>\n\n<h1 id=\"agent-manager-view\">Agent Manager View</h1>\n<ul>\n  <li>command + e 또는 ctrl + e를 누르면 에이전트 매니저로 전환됨</li>\n</ul>\n\n<h2 id=\"inbox\">Inbox</h2>\n<ul>\n  <li>아래 이미지는 Inbox에 진입한 상태</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/z5xo8lsdklhi74xtdt15a/2025-12-04-5.47.08.png?rlkey=vj61wscewcaa9qgwydiam5jcb&amp;raw=1\" /></p>\n\n<ul>\n  <li>Pending만 확인할 수도 있음. 지금은 모두 다 확인해서 나오지 않음</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/d71qeq04rluwd7tcquitk/2025-12-04-5.49.17.png?rlkey=2pww4xaikbaj5ax8c2j5g52rg&amp;raw=1\" /></p>\n\n<h2 id=\"workspace\">Workspace</h2>\n<ul>\n  <li>workspace에는 내가 대화한 내용들은 확인할 수 있음. 우측에 Review Changes를 누르면 변환된 부분만 확인할 수 있음</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/b82bnx6ezz6e7ovftgeps/2025-12-04-5.50.15.png?rlkey=zrttxmql5z30ugg31gh7e5izw&amp;raw=1\" /></p>\n\n<ul>\n  <li>workspace에 질문을 하니, 에디터쪽에도 동일한 workspace가 열려있어서 동기화됨</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/is7on7pwgqozn5oqbq31i/2025-12-04-5.53.06.png?rlkey=p5qj1z660lspaxvb1zuyaz3vc&amp;raw=1\" /></p>\n\n<ul>\n  <li>대화하다가 실수로 Conversation을 껐는데, option + command + b로 Toggle Agent를 다시 살렸음. 우측 최상단에 있는 이 버튼이였음</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/ok85yzp54wjjey1dprr3g/2025-12-04-6.02.00.png?rlkey=xu1s5ypl5ftn1fqty2kj29q0w&amp;raw=1\" /></p>\n\n<h2 id=\"playground\">Playground</h2>\n<ul>\n  <li>Playgrounds are independent workspaces perfect for quick prototypes or following your curiosity. Move to a dedicated workspace to continue exploring with multiple conversations라고 나와있는데, 간단히 요약하면 프로토타입을 만들 때 쓸 수 있는 공간</li>\n  <li>여기서 구현한 기능을 지금 프로젝트로 move 하는 기능도 제공함\n    <ul>\n      <li>다만 지금 에디터로 열었던 파일들을 참고하지 않는다. 제로베이스에서 시작하는 것</li>\n      <li><code class=\"language-plaintext highlighter-rouge\">~/.gemini/antigravity/playground/</code> : 경로를 확인해보니 해당 폴더에 저장됨</li>\n    </ul>\n  </li>\n</ul>\n\n<h2 id=\"knowledge\">Knowledge</h2>\n<ul>\n  <li>persistent memory라고 나와있는데, 아직 생성된 지식이 없어서 아무것도 나오지 않음</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/4gcdcokmo7fuh4w51mxhe/2025-12-04-6.10.17.png?rlkey=ieojrd6bd82cw8nktleinpqdo&amp;raw=1\" /></p>\n\n<p><br /></p>\n\n<h1 id=\"changelog\">Changelog</h1>\n<ul>\n  <li><a href=\"https://antigravity.google/changelog\">Changelog</a> 페이지를 보면 어떤 기능을 업데이트했는지 확인할 수 있음</li>\n  <li>25년 12월 4일 기준 Google AI Pro, Ultra 구독자에게 사용량을 늘려주고 Rate limit 주기를 더 빈번하게 수정함. 그 전에는 조금만 쓰면 쿼타가 찼다는 이야기가 나왔는데, Google AI 요금제랑 연동해서 점점 해결될 것으로 보임</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/0q99ui7yatz9wj0ycv1v3/2025-12-08-11.12.51.png?rlkey=b4i5irddd7et9g87zrsq4gnq6&amp;raw=1\" /></p>\n\n<p><br />\n<br /></p>\n\n<h1 id=\"전반적인-후기\">전반적인 후기</h1>\n<h2 id=\"antigravity-장점\">Antigravity 장점</h2>\n<ul>\n  <li>현재 Preview라 무료 사용 가능(Google AI 멤버십을 사용한다면 더 많은 사용량을 받음. Gemini 구독 중이라면 꼭 써보는 것을 추천)</li>\n  <li>Gemini 3, Claude Opus도 사용 가능</li>\n  <li>크롬 브라우저와 통합되어서 브라우저 제어가 수월함</li>\n  <li>브라우저 작업시 Screen Recording을 해서 확인할 수 있음</li>\n  <li>Agent Manager 구성으로 Agent가 어떻게 동작하는지 확인할 수 있음(다른 IDE와 차별점)</li>\n  <li>이미지에 드래그를 해서 피드백을 줄 수 있음(디테일한 피드백)</li>\n  <li>기존에 VSCode를 사용했는데, Antigravity를 메인으로 사용할 예정</li>\n</ul>\n\n<h2 id=\"개선하면-좋을-부분\">개선하면 좋을 부분</h2>\n<ul>\n  <li>나온지 얼마 되지 않아서 오류가 존재할 수 있음. 이는 Preview 단계라 그렇고 점점 개선될 것으로 예상</li>\n  <li>BigQuery MCP 설정할 때 오류가 발생했는데, 디버깅이 어려웠음</li>\n</ul>\n",
        "contentSnippet": "안녕하세요. 이번 글은 Google의 Antigravity 사용법에 대해 작성한 글입니다.\n키워드 : Google Antigravity, Google Antigravity 사용법\n\n\nAntigravity\n이름의 유래\nAntigravity 소개글에 작성되어 있는 비전\n    \nOur vision is to ultimately enable anyone with an idea to experience liftoff and build that idea into reality.\nLiftoff라는 용어는 항공기 전체가 지면에서 완전히 떨어지는 시점을 의미하는데, 구글은 자신의 아이디어 구현할 때 누구나 사용할 수 있는 도구를 만들고 싶었던 것 같음. 즉, 개발할 때 생기는 여러 이슈들을 중력이라 생각하고 그것을 대항할 수 있는 도구\n여담으로 Python에서 import antigravity를 하면 XKCD 만화(353번)를 웹 브라우저로 열어주는 이스터에그가 발생하는데, 관련은 없지만 익숙한 용어였음\n\n\n핵심 원칙\nAntigravity의 핵심 원칙은 Trust, Autonomy, Feedback, Self-improvement\nTrust\n오늘날의 대부분의 제품은 두 케이스에 속함\n    \n(1) 에이전트가 수행한 모든 Action과 Tool 호출을 사용자에게 보여줌\n(2) 작업의 컨텍스트나 검증할 방법 없이 최종 코드 변경 사항만 보여줌\n이런 제품들은 에이전트가 왜 이 작업을 했는지, 어떻게 확인해야 하는지를 알기 어려움.\nAntigravity는 사용자가 에이전트가 수행할 작업에 대한 신뢰를 가질 수 있도록 Actifact와 Verfication result(검증 결과)를 제공해 컨텍스트를 제공함\n    \n단순히 개별 Tool 호출이 전부 보이는 것이 아닌, 호출들이 Task 단위로 묶어서 표시함\nTask에 대한 추상화된 정리와 진행 상황을 확인할 수 있음\n사용자가 검증하기 쉬운 형식의 Artifact를 생성함. 예를 들어 Task list(작업 목록), Implementation plan(구현 계획), Walkthrough(단계별 설명서), 스크린샷, 브라우저 녹화 영상\n사용하면서 인상 깊은 부분은 웹브라우저 작업을 할 때 녹화가 되는 기능으로 작업을 어떻게 진행했는지 확인할 수 있었음. Plan 버전으로 실행할 때 Implementation plan, Walkthrough를 제공하는 것도 좋았음\nAutonomy\n요즘 가장 직관적인 제품의 형태는 여러 Surface(편집기, 브라우저, 터미널)에 내장된 에이전트와 동기적으로 동작하는 형태\n    \n에이전트가 자율적으로 프론트엔드 코드를 구현하고, 터미널에서 로컬호스트 실행하고, 브라우저를 작동시켜 새로운 기능이 작동하는지 테스트하는 형태\n이런 자율성을 최적으로 사용하기 위해 사용자가 에이전트와 비동기적으로 상호 작용할 수 있도록 Manager View를 만들었음\nAgent Manager View는 여러 에이전트를 병렬로 생성하고 모니터링할 수 있는 관제탑 스타일의 화면\n기존에 자주 사용하던 VSCode, Cursor 같은 스타일은 Editor View로 존재함(Editor View와 Manager View로 전환하는 단축키는 커맨드(컨트롤) + e)\nFeedback\n에이전트의 지능이 좋아지면서 여러 작업이 가능해졌지만, 아직 완벽하지 않음\n    \n이런 상황에서 피드백을 제공하면 도움이 됨\nAntigravity는 모든 Surface나 Artifact에서 비동기 사용자 피드백을 허용함\nText Artifact에선 주석을 달 수 있고, 스크린샷에서 영역을 선택해서 주석을 달 수 있음\nSelf-improvement\n에이전트가 일하면서 배운 내용을 저장하고, 나중에 비슷한 일을 할 때 참조함\n    \n명시적 정보 : 유용한 코드 snippet, 아키텍처 정보\n\n\n설치\n웹페이지에서 다운로드 가능\nMac 사용자라면 brew로도 설치 가능\n\n  brew install --cask antigravity\n\n    \n처음에 설치하면 기존에 사용하던 IDE(VS Code, Windsurf, Cursor 등)의 설정을 불러올 수 있고, Start fresh를 눌러서 시작할 수 있음\nAgent 설정은 Agent-assisted development으로 설정했음\nAntigravity - 크롬 확장 프로그램 설치\n\n위와 같은 구성을 확인할 수 있고, VSCode와 다르게 우측 상단에 크롬 아이콘이 있어서 눌러봄\n\n설치가 필요한데, 이미 크롬이 설치되어 있어서 경로를 직접 수정함\n    \nSet custom Chrome binary path 클릭해서 경로 지정함\n\n설정에서 Browser로 이동해서 Chrome Binary Path를 지정할 수 있음\n\n다시 크롬 버튼을 누르니 온보딩 페이지로 나오고, 확장 프로그램을 설치함. 이를 통해 Antigravity에서 크롬을 제어할 수 있음\n\n\nAgent\nAgent의 Core Compoent\n    \nReasoning model\nTools\nArtifacts\nKnowledge\nCustomization(커스텀 요소)\n    \nAgent Modes / Settings\nMCP\nRules / Workflow\nModels\nGoogle Vertex Model Garden을 통해 모델 제공\n    \n사용자가 원하는 모델을 선택할 수 있음\nGemini 3 Pro (high)\nGemini 3 Pro (low)\nClaude Sonnet 4.5\nClaude Sonnet 4.5 (thinking)\nClaude Opus 4.5 (thinking)\nGPT-OSS\n사용량 제한은 Plans 문서에서 확인할 수 있음\n    \n현재(25년 12월 기준) Preview라서 무료로 사용 가능하며, Google AI Plan 구독 여부에 따라 제공량이 다름\n기본 제공\n        \n위에 제공하는 Model에 대한 기본 사용\nTab completion 무제한 제공\nCommand requests 무제한 제공\nAgent Manager, Borwser integration 사용 가능\nGoogle AI Ultra : 제일 많은 사용량, 5시간마다 쿼타 갱신\nGoogle AI Pro : 많은 사용량, 5시간마다 쿼타 갱신\nGoogle AI Plan에 가입하지 않은 경우 적당한 사용량을 제공하고 주마다 쿼타 갱신\n아직 key를 사용하는 방식은 지원하지 않으나, 추후에 지원할 가능성이 높음\n\nAntigravity 내부에서 사용하는 모델\nAntigravity가 동작하는 과정에서 모델을 사용하고 있으며, 사용자가 설정할 수 없음\nUI 목업 생성, 웹페이지나 앱에서 사용할 이미지 생성, 아키텍처 다이어그램 생성 : Nano Banana Pro\n브라우저 서브 에이전트가 브라우저에서 클릭, 스크롤, 입력 등 브라우저를 제어할 때 : Gemini 2.5 Pro UI Checkpoint(내부적으로 커스텀한 모델로 추측)\n체크포인팅, 컨텍스트 요약할 때 : Gemini 2.5 Flash\n코드의 Semantic Search(의미 기반 검색) : Gemini 2.5 Flash Lite\nTools(MCP)\nMCP를 사용해 Antigravity가 데이터베이스에 직접 접근해서 정보를 가져올 수 있음\n연결 방법\n우측 상단에 있는 Agent의 우측에 …을 클릭 -> MCP Servers 클릭\n\n필요한 MCP 검색(저는 supabase)\n\nInstall 클릭 후, 환경 설정\n\n\n이제 MCP의 Tool을 사용할 수 있음\n\nArtifacts\nArtifacts는 에이전트가 작업을 완료하거나 작업과 생각을 사용자에게 전달하기 위해 생성하는 모든 것\n예시\n    \nTask list(할 일 목록)\nImplementation plan(구현 계획)\nWalkthrough(워크스루) : 변경 사항, 작업 과정 요약\nScreenshots(화면 캡처)\nBrowser Recordings(브라우저 녹화)\nKnowledge(지식)\n아래 실제로 실행하는 부분에서 확인 가능\nAgent Modes / Settings\n에이전트의 모드나 설정에 대한 이해가 필요함\n대화 모드\n대화할 때 2가지 모드 중 선택할 수 있음\n    \nPlanning, Fast\nPlanning : 작업 실행 전에 Plan을 세움. 복잡한 작업에서 활용하는 것이 좋으며, 작업에 따라 아티팩트 생성, 계획 등을 수행\nFast : 에이전트가 작업을 바로 실행함. 간단한 작업에 사용하며, 속도가 중요하고 품질 저하에 대한 걱정이 적을 때 사용\n대화할 때 바로 설정할 수 있음\n\n전반적인 설정\nAntigravity Settings에서 설정할 수 있으며, Artifact Review Policy, Terminal Command Auto Execution Policy를 정의할 수 있음\n\nArtifact Review Policy(아티팩트 리뷰 정책)\n    \n에이전트가 아티팩트에 대해 리뷰를 어떻게, 언제 물어볼지 결정하는 정책\nAlways Proceed : 에이전트가 리뷰를 요청하지 않고 작업 진행\nAgent Decides : 에이전트가 리뷰 요청 시점을 스스로 결정\nRequest Review : 에이전트가 항상 리뷰 요청\nTerminal Command Auto Execution Policy(터미널 커맨드 자동 실행 정책)\n    \n에이전트가 터미널 컴맨드를 자동으로 실행할지 결정하는 정책\nAlways Proceed : 에이전트가 터미널 명령을 실행하기 전에 확인하지 않고 실행\nAgent Decides : 에이전트가 터미널 명령을 실행하기 전에 스스로 판단\nRequest Review : 에이전트가 터미널 명령을 실행하기 전에 항상 확인\n두가지 설정 모두 Agent Decides로 설정하고 사용 중\n유사하게 Browser Javascript Execution Policy도 존재함(설정 - Browser)\n    \nDisabled : 에이전트가 브라우저에서 자바스크립트 코드를 실행하지 않음\nAlways Ask : 에이전트가 항상 자바스크립트 코드를 실행하기 전에 확인\nModel Decides : 에이전트가 자바스크립트 코드를 실행하기 전에 스스로 판단\nTurbo : 확인 없이 자바스크립트 코드를 실행함\n\n그 외에 Agent Non-Workspace File Access 설정은 Agent가 지금 작업 폴더와 Antigravity 루트 폴더(`~/.antigravity/) 외의 폴더에 접근할 수 있게 설정할 수 있음\n\nRules / Workflows\nRules : 지켜야 할 원칙\nWorkflows : AI가 행동해야 하는 순서 제공\nAgent의 … 클릭 후 Customization을 누르면 설정할 수 있음\n\nRules\nAgent가 따라야 하는 작업 스타일, 가이드를 작성한 마크다운 파일\nClaude Code나 Gemini CLI를 사용하면 CLAUDE.MD, GEMINI.MD를 만드는데, 이 개념과 같다고 보면 됨\nGlobal Rules와 Workspace Rules로 나뉨\n    \nGlobal Rules : ~/.gemini/GEMINI.md에 저장\nWorkspace Rules : 워크스페이스의 .agent/rules에 저장하고, 해당 워크스페이스에서만 적용\nRules 파일 제한 : 12,000자(character)\nCustomizations에서 +workspace를 눌러서 Workspace Rules를 추가할 수 있음(현재 있는 Global 설정은 한국어 응답하라는 내용이 저장되어 있음)\n\nWorkspace Rule도 어떤 상황에 활성화를 할 것인지 옵션이 존재함\n    \nManual : 사용자가 에이전트 채팅창에서 @로 명시적으로 호출할 때 적용\nAlways On : 항상 모든 상황에 적용\nModel Decision : Rule 파일을 읽고 현재 작업에 이 Rule이 필요한지 모델이 스스로 결정\nGlob : 특정 파일 패턴과 일치하는 파일을 다룰 때 적용\n\nWorkflows\nworkflow는 반복되는 작업을 정리한 파일\n    \n작업들을 단계별로 정의하면 에이전트가 그 순서에 맞춰 일을 처리함\n실행할 때 채팅창에서 /워크플로우이름을 입력하면 실행됨\n.agent/workflows 폴더에 저장됨\nCustomizatios - Workflows - +workspace를 누르면 만들 수 있고, 채팅으로 만들라고 할 수도 있음\n\n실행하니 정상적으로 동작함\n\n\n\n실제 사용기\n웹페이지 취약점 확인 후 동작 테스트\n개인적으로 만들고 있던 웹페이지의 취약점을 확인하고, 그 후에 실제로 잘 동작하는지 확인해달라고 함\n\n하나씩 확인하는데, 영상을 찍어서 제시함. 이게 Screen Recording\n\n작업 완료한 후, 하단에서 여러 내용을 확인할 수 있음\n    \n수정된 파일, Artifact(Implementation Plan, Task, Walkthrough)\n\n이번에는 직접 로그인을 한 후 다시 확인해보라고 하니, 로그인 상황에서 테스트를 진행함\n\n관리자 계정이 아닌 계정으로 테스트하는게 좋을까?라고 물어보니 아래처럼 안내함(일단 false로 주석처리해서 테스트)\n\n그 후 테스트하고 성능 측정 후 내용을 공유함\n\nWalkthrough 문서에 댓글을 남긴 후, 피드백을 제출함\n\n\n제출한 후에 Agent Manager에서 내가 남긴 댓글에 대한 답변을 볼 수 있음\n\nScreen Recording 기능\nScreen Recording은 Antigravity가 browser_subagent라는 도구를 사용해 브라우저를 제어할 때만 자동으로 수행됨\n    \n녹화 시점:  “브라우저를 열어서 확인해줘”라는 요청을 받거나, 스스로 웹페이지 테스트가 필요하다고 판단하여 브라우저 도구를 실행할 때그 세션의 화면이 녹화\n녹화하는 것: 브라우저 창 내부에서 일어나는 일(클릭, 타이핑, 페이지 이동, 콘솔 로그 확인 등)만 녹화됨\nArtifact가 어디에 저장하는지 확인해보니 다음 경로에 저장됨(/Users/UserName/.gemini/antigravity/)\n    \n동영상 용량은 작진 않아서 나중에 관리가 필요할 것으로 예상됨\n\n대화 기록\n만약 지난 대화를 찾고 싶다면 이 버튼을 통해서 찾을 수 있음\n\n\n\n아키텍처 이미지 생성, 이미지 피드백\n이번엔 아키텍처를 그려달라고 함\n    \nCreated Task를 보면 Task가 생성되고, Task의 Progress Updates를 보여줌\n\n생성된 이미지에서 드래그를 하면 의견을 특정 부분에 줄 수 있음. 이 기능이 꽤 유용함\n\n다른 의견도 주고 Submit을 클릭해서 피드백을 제시함\n\n피드백을 반영해 이미지가 변경됨\n\n\n\nAgent Manager View\ncommand + e 또는 ctrl + e를 누르면 에이전트 매니저로 전환됨\nInbox\n아래 이미지는 Inbox에 진입한 상태\n\nPending만 확인할 수도 있음. 지금은 모두 다 확인해서 나오지 않음\n\nWorkspace\nworkspace에는 내가 대화한 내용들은 확인할 수 있음. 우측에 Review Changes를 누르면 변환된 부분만 확인할 수 있음\n\nworkspace에 질문을 하니, 에디터쪽에도 동일한 workspace가 열려있어서 동기화됨\n\n대화하다가 실수로 Conversation을 껐는데, option + command + b로 Toggle Agent를 다시 살렸음. 우측 최상단에 있는 이 버튼이였음\n\nPlayground\nPlaygrounds are independent workspaces perfect for quick prototypes or following your curiosity. Move to a dedicated workspace to continue exploring with multiple conversations라고 나와있는데, 간단히 요약하면 프로토타입을 만들 때 쓸 수 있는 공간\n여기서 구현한 기능을 지금 프로젝트로 move 하는 기능도 제공함\n    \n다만 지금 에디터로 열었던 파일들을 참고하지 않는다. 제로베이스에서 시작하는 것\n~/.gemini/antigravity/playground/ : 경로를 확인해보니 해당 폴더에 저장됨\nKnowledge\npersistent memory라고 나와있는데, 아직 생성된 지식이 없어서 아무것도 나오지 않음\n\n\nChangelog\nChangelog 페이지를 보면 어떤 기능을 업데이트했는지 확인할 수 있음\n25년 12월 4일 기준 Google AI Pro, Ultra 구독자에게 사용량을 늘려주고 Rate limit 주기를 더 빈번하게 수정함. 그 전에는 조금만 쓰면 쿼타가 찼다는 이야기가 나왔는데, Google AI 요금제랑 연동해서 점점 해결될 것으로 보임\n\n\n\n전반적인 후기\nAntigravity 장점\n현재 Preview라 무료 사용 가능(Google AI 멤버십을 사용한다면 더 많은 사용량을 받음. Gemini 구독 중이라면 꼭 써보는 것을 추천)\nGemini 3, Claude Opus도 사용 가능\n크롬 브라우저와 통합되어서 브라우저 제어가 수월함\n브라우저 작업시 Screen Recording을 해서 확인할 수 있음\nAgent Manager 구성으로 Agent가 어떻게 동작하는지 확인할 수 있음(다른 IDE와 차별점)\n이미지에 드래그를 해서 피드백을 줄 수 있음(디테일한 피드백)\n기존에 VSCode를 사용했는데, Antigravity를 메인으로 사용할 예정\n개선하면 좋을 부분\n나온지 얼마 되지 않아서 오류가 존재할 수 있음. 이는 Preview 단계라 그렇고 점점 개선될 것으로 예상\nBigQuery MCP 설정할 때 오류가 발생했는데, 디버깅이 어려웠음",
        "guid": "https://zzsza.github.io/ai/2025/12/08/how-to-use-antigravity/",
        "categories": [
          "basic",
          "ai"
        ],
        "isoDate": "2025-12-08T00:00:00.000Z"
      }
    ]
  },
  {
    "name": "oddpoet’s étude",
    "category": "개인",
    "posts": []
  },
  {
    "name": "0x00 - NULL",
    "category": "개인",
    "posts": []
  },
  {
    "name": "퇴근 후 서버다운",
    "category": "개인",
    "posts": [
      {
        "creator": "SIDNFT",
        "title": "매지컬 할로윈 5 / 게임 소재 / 영상이 나오는 게임",
        "link": "https://serverdown.tistory.com/1536",
        "pubDate": "Wed, 10 Dec 2025 00:21:29 +0900",
        "author": "SIDNFT",
        "comments": "https://serverdown.tistory.com/1536#entry1536comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"420\" data-origin-height=\"315\"><span data-url=\"https://blog.kakaocdn.net/dn/b9m0Qh/dJMcafd25NZ/LcFChkN9o99JowyHTSSy3K/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/b9m0Qh/dJMcafd25NZ/LcFChkN9o99JowyHTSSy3K/img.png\"><img src=\"https://blog.kakaocdn.net/dn/b9m0Qh/dJMcafd25NZ/LcFChkN9o99JowyHTSSy3K/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb9m0Qh%2FdJMcafd25NZ%2FLcFChkN9o99JowyHTSSy3K%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"420\" height=\"315\" data-origin-width=\"420\" data-origin-height=\"315\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=gb01M392fbs\">【#665 マジカルハロウィン５(家)LIVE】設定6配信 悪い そろそろたのむ</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=gb01M392fbs\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/eIbp2g/hyZPmaVoIk/AeFsL8VEVOiIn8PuPPcg5K/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/FM7bt/hyZOKXrtUr/h4ezuUBCzHk5l7cx8cEWjk/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"【#665 マジカルハロウィン５(家)LIVE】設定6配信 悪い そろそろたのむ\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/gb01M392fbs\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">슬롯머신이 뭔가 해서 찾다보니 발견했습니다.</p>\n<p data-ke-size=\"size16\">가정용 게임이가 아니고 어마어마하게 큰 화면이 달린 게임기 입니다.</p>\n<p data-ke-size=\"size16\">거의 화면 두개를 붙여놓은 크기구요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">아래에 슬롯을 맞추다보면 위에 영상이 상황에 맞게 바뀝니다.</p>\n<p data-ke-size=\"size16\">AI 로 영상을 뽑아서 게임이랑 잘 섞으면 될꺼 같은 게임방식으로 보입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">슬롯 머신은 원래 이랬기 때문에 신기한건 아니지만</p>\n<p data-ke-size=\"size16\">모바일에서 AI 영상과 결합하면 재미난 게임이 나올 수 있을 것 같습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">찾아보니 모바일 버전도 있군요 코나미에서 만들었군요</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=IXYxbbsmiG0\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=IXYxbbsmiG0</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=IXYxbbsmiG0\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/nYE4G/hyZPce2I8I/jMHHksDpftIgyglV9PHDI1/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/cFFDNj/hyZPmhFXLf/1uOYFl5Y8GvPluZIXubCKk/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/zH99d/hyZO7dKt0R/W9tl9xw7aKG7S9LdFQTDLK/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"Magical Halloween 4 [iOS port]\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/IXYxbbsmiG0\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">소박한 화면 크기 입니다.</p>",
        "contentSnippet": "영상: 【#665 マジカルハロウィン５(家)LIVE】設定6配信 悪い そろそろたのむ\n\n\n\n \n슬롯머신이 뭔가 해서 찾다보니 발견했습니다.\n가정용 게임이가 아니고 어마어마하게 큰 화면이 달린 게임기 입니다.\n거의 화면 두개를 붙여놓은 크기구요\n \n아래에 슬롯을 맞추다보면 위에 영상이 상황에 맞게 바뀝니다.\nAI 로 영상을 뽑아서 게임이랑 잘 섞으면 될꺼 같은 게임방식으로 보입니다.\n \n슬롯 머신은 원래 이랬기 때문에 신기한건 아니지만\n모바일에서 AI 영상과 결합하면 재미난 게임이 나올 수 있을 것 같습니다.\n \n \n찾아보니 모바일 버전도 있군요 코나미에서 만들었군요\n영상: https://www.youtube.com/watch?v=IXYxbbsmiG0\n\n\n\n \n소박한 화면 크기 입니다.",
        "guid": "https://serverdown.tistory.com/1536",
        "categories": [
          "게임",
          "게임소재"
        ],
        "isoDate": "2025-12-09T15:21:29.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "크리피 비하인드 / 게임소재 / 게임 분석 / 미니게임 많이 모아둔 것",
        "link": "https://serverdown.tistory.com/1535",
        "pubDate": "Wed, 10 Dec 2025 00:11:51 +0900",
        "author": "SIDNFT",
        "comments": "https://serverdown.tistory.com/1535#entry1535comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"368\" data-origin-height=\"358\"><span data-url=\"https://blog.kakaocdn.net/dn/umY9T/dJMcaajvdqK/DfISrhkizak4VBLhF9pAk0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/umY9T/dJMcaajvdqK/DfISrhkizak4VBLhF9pAk0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/umY9T/dJMcaajvdqK/DfISrhkizak4VBLhF9pAk0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FumY9T%2FdJMcaajvdqK%2FDfISrhkizak4VBLhF9pAk0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"368\" height=\"358\" data-origin-width=\"368\" data-origin-height=\"358\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1002\" data-origin-height=\"247\"><span data-url=\"https://blog.kakaocdn.net/dn/U2Pav/dJMcaiu1ZL0/KJAJiJKsC2eIHKBq2dkjk1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/U2Pav/dJMcaiu1ZL0/KJAJiJKsC2eIHKBq2dkjk1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/U2Pav/dJMcaiu1ZL0/KJAJiJKsC2eIHKBq2dkjk1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FU2Pav%2FdJMcaiu1ZL0%2FKJAJiJKsC2eIHKBq2dkjk1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1002\" height=\"247\" data-origin-width=\"1002\" data-origin-height=\"247\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">게임 제목이 바꼈나봅니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"422\" data-origin-height=\"161\"><span data-url=\"https://blog.kakaocdn.net/dn/dQP7Cv/dJMcaaDNLT9/KKDCLwTmtWdv0mf0REsk9k/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/dQP7Cv/dJMcaaDNLT9/KKDCLwTmtWdv0mf0REsk9k/img.png\"><img src=\"https://blog.kakaocdn.net/dn/dQP7Cv/dJMcaaDNLT9/KKDCLwTmtWdv0mf0REsk9k/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdQP7Cv%2FdJMcaaDNLT9%2FKKDCLwTmtWdv0mf0REsk9k%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"422\" height=\"161\" data-origin-width=\"422\" data-origin-height=\"161\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=fq4jDVb-bwA\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=fq4jDVb-bwA</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=fq4jDVb-bwA\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/NbR5e/hyZO8jnnPk/K9zgLfYTvHP0gpOQQKP3GK/img.jpg?width=1280&amp;height=720&amp;face=150_168_1130_510,https://scrap.kakaocdn.net/dn/c9m8rj/hyZOMVgXlt/eY7kQSmN01WJbPDQnO0Aqk/img.jpg?width=1280&amp;height=720&amp;face=150_168_1130_510,https://scrap.kakaocdn.net/dn/NKcNG/hyZPdkIu0S/dMQ6rh8n5LrLLX8fAOLRck/img.jpg?width=1280&amp;height=720&amp;face=150_168_1130_510\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"광고 제거해 주세요 현기증 난단 말이에요 [크리피 비하인드]\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/fq4jDVb-bwA\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">AI 로 스토리 만들어서 게임에 넣자고 하길레 이게임이 생각나서 다시 찾아봤습니다.</p>\n<p data-ke-size=\"size16\">상황 시작 -&gt; 게임 -&gt; 실패 or 성공 연출</p>\n<p data-ke-size=\"size16\">여기서 AI 령상을</p>\n<p data-ke-size=\"size16\">상황시작 ( 이건 없어도 되겠고 )<br />게임중 ( 안절 부절한 영상 )<br />실패 ( 망한 영상 )<br />성공 ( 좋은 영상 )</p>\n<p data-ke-size=\"size16\">게임중 영상은 뒤에 배경으로 깔고<br />이것저것 하면 될꺼 같습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "게임 제목이 바꼈나봅니다.\n\n\n \n \n영상: https://www.youtube.com/watch?v=fq4jDVb-bwA\n\n\n\n \nAI 로 스토리 만들어서 게임에 넣자고 하길레 이게임이 생각나서 다시 찾아봤습니다.\n상황 시작 -> 게임 -> 실패 or 성공 연출\n여기서 AI 령상을\n상황시작 ( 이건 없어도 되겠고 )\n게임중 ( 안절 부절한 영상 )\n실패 ( 망한 영상 )\n성공 ( 좋은 영상 )\n게임중 영상은 뒤에 배경으로 깔고\n이것저것 하면 될꺼 같습니다.",
        "guid": "https://serverdown.tistory.com/1535",
        "categories": [
          "게임",
          "게임소재"
        ],
        "isoDate": "2025-12-09T15:11:51.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "엔비디아 DGX SPARK 리뷰 영상 / 램이 128 GB",
        "link": "https://serverdown.tistory.com/1534",
        "pubDate": "Tue, 9 Dec 2025 22:32:57 +0900",
        "author": "SIDNFT",
        "comments": "https://serverdown.tistory.com/1534#entry1534comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"434\" data-origin-height=\"322\"><span data-url=\"https://blog.kakaocdn.net/dn/bhSSf4/dJMcabJuCUY/1sSMvDvUaz9uhjkRh56dk0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bhSSf4/dJMcabJuCUY/1sSMvDvUaz9uhjkRh56dk0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bhSSf4/dJMcabJuCUY/1sSMvDvUaz9uhjkRh56dk0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbhSSf4%2FdJMcabJuCUY%2F1sSMvDvUaz9uhjkRh56dk0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"434\" height=\"322\" data-origin-width=\"434\" data-origin-height=\"322\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"284\" data-origin-height=\"476\"><span data-url=\"https://blog.kakaocdn.net/dn/cATHh0/dJMcacIoLIQ/HsVCB7P7j9eQkphG3HcVg0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cATHh0/dJMcacIoLIQ/HsVCB7P7j9eQkphG3HcVg0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/cATHh0/dJMcacIoLIQ/HsVCB7P7j9eQkphG3HcVg0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcATHh0%2FdJMcacIoLIQ%2FHsVCB7P7j9eQkphG3HcVg0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"284\" height=\"476\" data-origin-width=\"284\" data-origin-height=\"476\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">쿠팡에서도 팝니다.&nbsp;</p>\n<p data-ke-size=\"size16\">거의 500만원</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=p0Fjvz3YFAE\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=p0Fjvz3YFAE</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=p0Fjvz3YFAE\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/CYx2b/hyZO9JlRkN/ShA0JK75hQiWUhVPbCdaGk/img.jpg?width=1280&amp;height=720&amp;face=840_280_1060_520,https://scrap.kakaocdn.net/dn/cjf0Ls/hyZOD44fqU/BU9jinZO7rcDljKEvzLyF1/img.jpg?width=1280&amp;height=720&amp;face=840_280_1060_520\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"엔비디아 DGX SPARK 플랫폼 적용 '기가바이트 AI TOP ATOM' 간단하게 써보기\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/p0Fjvz3YFAE\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">AI 만 돌릴거면 램이 많아야하기때문에</p>\n<p data-ke-size=\"size16\">5090 같은걸로도 안됩니다.&nbsp;</p>\n<p data-ke-size=\"size16\">그래서 괴물급 램을 집어넣은 이 장비가 리뷰 되었네요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">하지만 최신 모델 크기가 점점 커지면서 150 GB 정도를 요구하고 있습니다.</p>\n<p data-ke-size=\"size16\">아직 램이 부족합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">돌아가는거 보니 램이 많은거지 빠른건 아닙니다. ㅠㅠ</p>\n<p data-ke-size=\"size16\">5090 사는거보다는 좋으니 개발자는 이거 사야는게 맞구요</p>\n<p data-ke-size=\"size16\">게임할 사람은 5090 가시고 ...</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">5090 은 32 GB 메모리고 가격은 450만원</p>\n<p data-ke-size=\"size16\">맥스튜디오는 512 GB 메모리를 달 수 있군요 가격은 1,400 만원</p>\n<p data-ke-size=\"size16\">DGX 는 128 GB 에 500 만원</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">기호에 맞게 잘 고르시기 바랍니다.</p>",
        "contentSnippet": "쿠팡에서도 팝니다. \n거의 500만원\n \n영상: https://www.youtube.com/watch?v=p0Fjvz3YFAE\n\n\n\n \nAI 만 돌릴거면 램이 많아야하기때문에\n5090 같은걸로도 안됩니다. \n그래서 괴물급 램을 집어넣은 이 장비가 리뷰 되었네요\n \n하지만 최신 모델 크기가 점점 커지면서 150 GB 정도를 요구하고 있습니다.\n아직 램이 부족합니다.\n \n돌아가는거 보니 램이 많은거지 빠른건 아닙니다. ㅠㅠ\n5090 사는거보다는 좋으니 개발자는 이거 사야는게 맞구요\n게임할 사람은 5090 가시고 ...\n \n5090 은 32 GB 메모리고 가격은 450만원\n맥스튜디오는 512 GB 메모리를 달 수 있군요 가격은 1,400 만원\nDGX 는 128 GB 에 500 만원\n \n기호에 맞게 잘 고르시기 바랍니다.",
        "guid": "https://serverdown.tistory.com/1534",
        "categories": [
          "유튜브",
          "엔비디아",
          "제품리뷰"
        ],
        "isoDate": "2025-12-09T13:32:57.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "NC 3D 생성 서비스 시작 - 바르코 3D",
        "link": "https://serverdown.tistory.com/1533",
        "pubDate": "Tue, 9 Dec 2025 14:33:51 +0900",
        "author": "SIDNFT",
        "comments": "https://serverdown.tistory.com/1533#entry1533comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"259\" data-origin-height=\"226\"><span data-url=\"https://blog.kakaocdn.net/dn/bnUWCC/dJMcahXe7o0/jimLQZyQGXVWVmdKa3C3i0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bnUWCC/dJMcahXe7o0/jimLQZyQGXVWVmdKa3C3i0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bnUWCC/dJMcahXe7o0/jimLQZyQGXVWVmdKa3C3i0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbnUWCC%2FdJMcahXe7o0%2FjimLQZyQGXVWVmdKa3C3i0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"259\" height=\"226\" data-origin-width=\"259\" data-origin-height=\"226\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">링크: <a href=\"https://3d.varco.ai/\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://3d.varco.ai/</a></p>\n<figure id=\"og_1765258349656\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"VARCO 3D &ndash; Meet Your First AI 3D Creator\" data-og-description=\"VARCO 3D is your first AI 3D tool. Instantly create and animate high-quality 3D models from text or images &mdash; fast, easy, and powerful for artists and teams.\" data-og-host=\"3d.varco.ai\" data-og-source-url=\"https://3d.varco.ai/\" data-og-url=\"https://3d.varco.ai\" data-og-image=\"https://scrap.kakaocdn.net/dn/VBSyB/hyZO93tD0t/WXKVhf5fCqiCLkuyk4mhLK/img.png?width=1200&amp;height=630&amp;face=0_0_1200_630,https://scrap.kakaocdn.net/dn/bFwfO3/hyZPie532T/enTnk9kMgwQWW6CuuM4rhK/img.png?width=1200&amp;height=630&amp;face=0_0_1200_630\"><a href=\"https://3d.varco.ai/\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://3d.varco.ai/\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/VBSyB/hyZO93tD0t/WXKVhf5fCqiCLkuyk4mhLK/img.png?width=1200&amp;height=630&amp;face=0_0_1200_630,https://scrap.kakaocdn.net/dn/bFwfO3/hyZPie532T/enTnk9kMgwQWW6CuuM4rhK/img.png?width=1200&amp;height=630&amp;face=0_0_1200_630');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">VARCO 3D &ndash; Meet Your First AI 3D Creator</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">VARCO 3D is your first AI 3D tool. Instantly create and animate high-quality 3D models from text or images &mdash; fast, easy, and powerful for artists and teams.</p>\n<p class=\"og-host\" data-ke-size=\"size16\">3d.varco.ai</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">마인크래프트 류 게임 만들려고 했는데</p>\n<p data-ke-size=\"size16\">쓰면 되겠군요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">열심히 써서 NC 드러가야지</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"592\" data-origin-height=\"270\"><span data-url=\"https://blog.kakaocdn.net/dn/bpeNE9/dJMcaiaLDAd/GadihX5okMQcXBBdVsabY1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bpeNE9/dJMcaiaLDAd/GadihX5okMQcXBBdVsabY1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bpeNE9/dJMcaiaLDAd/GadihX5okMQcXBBdVsabY1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbpeNE9%2FdJMcaiaLDAd%2FGadihX5okMQcXBBdVsabY1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"592\" height=\"270\" data-origin-width=\"592\" data-origin-height=\"270\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">다른데서 보던게 있네 ㅋ</p>",
        "contentSnippet": "링크: https://3d.varco.ai/\n\n \nVARCO 3D – Meet Your First AI 3D Creator\nVARCO 3D is your first AI 3D tool. Instantly create and animate high-quality 3D models from text or images — fast, easy, and powerful for artists and teams.\n3d.varco.ai\n\n \n마인크래프트 류 게임 만들려고 했는데\n쓰면 되겠군요\n \n열심히 써서 NC 드러가야지\n \n\n\n다른데서 보던게 있네 ㅋ",
        "guid": "https://serverdown.tistory.com/1533",
        "categories": [
          "프로그래밍/개발메모",
          "Ai"
        ],
        "isoDate": "2025-12-09T05:33:51.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "미안해서 죄가 점점 늘어나는 남자 / 악순환 수렁 / 역대급 거짓말",
        "link": "https://serverdown.tistory.com/1532",
        "pubDate": "Tue, 9 Dec 2025 10:48:55 +0900",
        "author": "SIDNFT",
        "comments": "https://serverdown.tistory.com/1532#entry1532comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"441\" data-origin-height=\"309\"><span data-url=\"https://blog.kakaocdn.net/dn/UdiwX/dJMcabpaBRZ/mikVd9YkJxvKd84KYCLc4K/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/UdiwX/dJMcabpaBRZ/mikVd9YkJxvKd84KYCLc4K/img.png\"><img src=\"https://blog.kakaocdn.net/dn/UdiwX/dJMcabpaBRZ/mikVd9YkJxvKd84KYCLc4K/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FUdiwX%2FdJMcabpaBRZ%2FmikVd9YkJxvKd84KYCLc4K%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"441\" height=\"309\" data-origin-width=\"441\" data-origin-height=\"309\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=y0hLqGgOqXk&amp;lc=UgyZ-cqVcgA4zt0pl894AaABAg\">\"흑흑..사장님\" 역대급 퇴사 빌런&hellip;직원들 모두 '충격' #뉴스다 / JTBC News</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=y0hLqGgOqXk&amp;lc=UgyZ-cqVcgA4zt0pl894AaABAg\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/Uq2c1/hyZPilLr4J/W7h8kiuH61xlB6QTGcz4nK/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/cuSzHV/hyZPcZ8goN/ukQzvFsRSHvJBKomckbd20/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"@gunilusalee4777님의 댓글\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/y0hLqGgOqXk\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이 사건은 역대급이 맞습니다.</p>\n<p data-ke-size=\"size16\">한 남자의 절규의 연기를 볼 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">잘못을 할때 마다 덮기 위해 거짓말을 만들어내다보니&nbsp;</p>\n<p data-ke-size=\"size16\">마지막에 마누라가 죽었다고 .... (구라침)</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이것인 진정한 수렁 아닌가 싶습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: \"흑흑..사장님\" 역대급 퇴사 빌런…직원들 모두 '충격' #뉴스다 / JTBC News\n\n\n\n \n이 사건은 역대급이 맞습니다.\n한 남자의 절규의 연기를 볼 수 있습니다.\n \n잘못을 할때 마다 덮기 위해 거짓말을 만들어내다보니 \n마지막에 마누라가 죽었다고 .... (구라침)\n \n이것인 진정한 수렁 아닌가 싶습니다.",
        "guid": "https://serverdown.tistory.com/1532",
        "categories": [
          "유튜브",
          "범죄",
          "인생"
        ],
        "isoDate": "2025-12-09T01:48:55.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "BLOTSPOT 협업 하기",
        "link": "https://serverdown.tistory.com/1531",
        "pubDate": "Tue, 9 Dec 2025 00:58:27 +0900",
        "author": "SIDNFT",
        "comments": "https://serverdown.tistory.com/1531#entry1531comment",
        "content": "<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"308\" data-origin-height=\"255\"><span data-url=\"https://blog.kakaocdn.net/dn/pOPrU/dJMcagRxU4y/z0eKy6XEuyKvjevpZSN8Ok/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/pOPrU/dJMcagRxU4y/z0eKy6XEuyKvjevpZSN8Ok/img.png\"><img src=\"https://blog.kakaocdn.net/dn/pOPrU/dJMcagRxU4y/z0eKy6XEuyKvjevpZSN8Ok/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FpOPrU%2FdJMcagRxU4y%2Fz0eKy6XEuyKvjevpZSN8Ok%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"308\" height=\"255\" data-origin-width=\"308\" data-origin-height=\"255\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">일단 블로그를 만들고</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"393\" data-origin-height=\"220\"><span data-url=\"https://blog.kakaocdn.net/dn/6tuMa/dJMcacn5g1s/H88MHnWtghbRVx4tKkBZyk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/6tuMa/dJMcacn5g1s/H88MHnWtghbRVx4tKkBZyk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/6tuMa/dJMcacn5g1s/H88MHnWtghbRVx4tKkBZyk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F6tuMa%2FdJMcacn5g1s%2FH88MHnWtghbRVx4tKkBZyk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"393\" height=\"220\" data-origin-width=\"393\" data-origin-height=\"220\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">설정 -&gt; 더 많은 작성자를 초대하세요 -&gt; 초대할 사람 이메일 쓰기</p>\n<p data-ke-size=\"size16\">이러면 끝이구요</p>\n<p data-ke-size=\"size16\">초대 받은 사람은</p>\n<p data-ke-size=\"size16\">1. 메일을 열고 (초대 메일 지우지마세요 아직 끝난게 아닙니다.)</p>\n<p data-ke-size=\"size16\">2. 수락하기 누르고</p>\n<p data-ke-size=\"size16\">3. 들어가면 됩니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">여기사 신규 유저 추가로 할일은</p>\n<p data-ke-size=\"size16\">본인 블로그가 하나도 없다면 하나 생성해야합니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"239\" data-origin-height=\"214\"><span data-url=\"https://blog.kakaocdn.net/dn/2Auyh/dJMcadN0q80/OXEfW7KiN2oEQW7kjuCzs1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/2Auyh/dJMcadN0q80/OXEfW7KiN2oEQW7kjuCzs1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/2Auyh/dJMcadN0q80/OXEfW7KiN2oEQW7kjuCzs1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F2Auyh%2FdJMcadN0q80%2FOXEfW7KiN2oEQW7kjuCzs1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"239\" height=\"214\" data-origin-width=\"239\" data-origin-height=\"214\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">추가로 설정 -&gt; 프로필 수정 (제일 아래에 있습니다.)</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"276\" data-origin-height=\"141\"><span data-url=\"https://blog.kakaocdn.net/dn/bEqKDh/dJMcaiu1D33/JPVM1YIDXbpXN45IYMEA61/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bEqKDh/dJMcaiu1D33/JPVM1YIDXbpXN45IYMEA61/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bEqKDh/dJMcaiu1D33/JPVM1YIDXbpXN45IYMEA61/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbEqKDh%2FdJMcaiu1D33%2FJPVM1YIDXbpXN45IYMEA61%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"276\" height=\"141\" data-origin-width=\"276\" data-origin-height=\"141\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">프로필에서 \"표시 이름\" 이란걸 작성해주세요</p>\n<p data-ke-size=\"size16\">이 이름이 다른 사람 플로그에서 쓰이게 되는거 같습니다.</p>\n<p data-ke-size=\"size16\">다시 초대 이메일로 가서 다시 수락을 합니다.</p>\n<p data-ke-size=\"size16\">이번엔 제대로 초대가 될 것입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"311\" data-origin-height=\"211\"><span data-url=\"https://blog.kakaocdn.net/dn/dNCMTy/dJMcaaDNoRg/pVK6KeueviBl4AOk7q6Qk1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/dNCMTy/dJMcaaDNoRg/pVK6KeueviBl4AOk7q6Qk1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/dNCMTy/dJMcaaDNoRg/pVK6KeueviBl4AOk7q6Qk1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdNCMTy%2FdJMcaaDNoRg%2FpVK6KeueviBl4AOk7q6Qk1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"311\" height=\"211\" data-origin-width=\"311\" data-origin-height=\"211\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">좌측 상단에 이부분을 누르면 내가 보유한 여러 블로그가 보입니다.</p>\n<p data-ke-size=\"size16\">여기서 블로그를 고르면 거기로 가서 글을 쓸 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "일단 블로그를 만들고\n \n\n\n설정 -> 더 많은 작성자를 초대하세요 -> 초대할 사람 이메일 쓰기\n이러면 끝이구요\n초대 받은 사람은\n1. 메일을 열고 (초대 메일 지우지마세요 아직 끝난게 아닙니다.)\n2. 수락하기 누르고\n3. 들어가면 됩니다.\n \n여기사 신규 유저 추가로 할일은\n본인 블로그가 하나도 없다면 하나 생성해야합니다.\n\n\n추가로 설정 -> 프로필 수정 (제일 아래에 있습니다.)\n \n\n\n프로필에서 \"표시 이름\" 이란걸 작성해주세요\n이 이름이 다른 사람 플로그에서 쓰이게 되는거 같습니다.\n다시 초대 이메일로 가서 다시 수락을 합니다.\n이번엔 제대로 초대가 될 것입니다.\n \n\n\n좌측 상단에 이부분을 누르면 내가 보유한 여러 블로그가 보입니다.\n여기서 블로그를 고르면 거기로 가서 글을 쓸 수 있습니다.",
        "guid": "https://serverdown.tistory.com/1531",
        "categories": [
          "프로그래밍/개발메모"
        ],
        "isoDate": "2025-12-08T15:58:27.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "BUN 앤트로픽에 (클로드코드) 에 인수되었습니다. / 성공담",
        "link": "https://serverdown.tistory.com/1530",
        "pubDate": "Mon, 8 Dec 2025 13:52:27 +0900",
        "author": "SIDNFT",
        "comments": "https://serverdown.tistory.com/1530#entry1530comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"279\" data-origin-height=\"255\"><span data-url=\"https://blog.kakaocdn.net/dn/bH4dxF/dJMcagRxKKr/KJVtMIYN3WumLAvYqlJTK0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bH4dxF/dJMcagRxKKr/KJVtMIYN3WumLAvYqlJTK0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bH4dxF/dJMcagRxKKr/KJVtMIYN3WumLAvYqlJTK0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbH4dxF%2FdJMcagRxKKr%2FKJVtMIYN3WumLAvYqlJTK0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"279\" height=\"255\" data-origin-width=\"279\" data-origin-height=\"255\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=RMwRhRyZ0Jo\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=RMwRhRyZ0Jo</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=RMwRhRyZ0Jo\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/SY4cL/hyZPlP3Wuy/gMIu2LoqYJuGftO1BwP5yk/img.jpg?width=1280&amp;height=720&amp;face=1048_482_1156_600,https://scrap.kakaocdn.net/dn/q9obf/hyZOOZCHmg/mLImoztvdtN0ENuhtZHog1/img.jpg?width=1280&amp;height=720&amp;face=1048_482_1156_600\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"6개월만에 1조 벌고 빵을 인수해버린 앤트로픽\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/RMwRhRyZ0Jo\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">BUN 은 빠른 typescript 처리기 입니다.</p>\n<p data-ke-size=\"size16\">앤트로픽은 클로트 코드 라는 AI 자동 코딩 툴 회사입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">처음 써보고 너무 빨라서 놀랐는데</p>\n<p data-ke-size=\"size16\">돈을 4년간 제대로 못벌고 있다가</p>\n<p data-ke-size=\"size16\">이번에 앤트로픽에서 인수해갔군요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">그 성공 스토리에 대한 이야기 구요</p>\n<p data-ke-size=\"size16\">두회사는 간접적으로 연관이 있었고 결국엔 성공했습니다.</p>\n<p data-ke-size=\"size16\">이번에도 레딧과 깃허브의 역활이 컷군요<br />이 두개에서 성공 사례가 많이 나오는거 같습니다.</p>\n<p data-ke-size=\"size16\">제품의 본질에 충실하면 좋은 제품이 되었을때<br /><span style=\"color: initial; letter-spacing: 0px;\">성공한다는 것을 배웠습니다.</span></p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=RMwRhRyZ0Jo\n\n\n\nBUN 은 빠른 typescript 처리기 입니다.\n앤트로픽은 클로트 코드 라는 AI 자동 코딩 툴 회사입니다.\n \n처음 써보고 너무 빨라서 놀랐는데\n돈을 4년간 제대로 못벌고 있다가\n이번에 앤트로픽에서 인수해갔군요\n \n그 성공 스토리에 대한 이야기 구요\n두회사는 간접적으로 연관이 있었고 결국엔 성공했습니다.\n이번에도 레딧과 깃허브의 역활이 컷군요\n이 두개에서 성공 사례가 많이 나오는거 같습니다.\n제품의 본질에 충실하면 좋은 제품이 되었을때\n성공한다는 것을 배웠습니다.",
        "guid": "https://serverdown.tistory.com/1530",
        "categories": [
          "유튜브",
          "Ai",
          "성공담"
        ],
        "isoDate": "2025-12-08T04:52:27.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "Next.js React 업그레이드 진행 / 당장하라는군요",
        "link": "https://serverdown.tistory.com/1529",
        "pubDate": "Sun, 7 Dec 2025 16:23:53 +0900",
        "author": "SIDNFT",
        "comments": "https://serverdown.tistory.com/1529#entry1529comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"398\" data-origin-height=\"261\"><span data-url=\"https://blog.kakaocdn.net/dn/vPuNd/dJMcagjHHU1/02BUSSuRdTzgNfQCQwxL9K/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/vPuNd/dJMcagjHHU1/02BUSSuRdTzgNfQCQwxL9K/img.png\"><img src=\"https://blog.kakaocdn.net/dn/vPuNd/dJMcagjHHU1/02BUSSuRdTzgNfQCQwxL9K/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FvPuNd%2FdJMcagjHHU1%2F02BUSSuRdTzgNfQCQwxL9K%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"398\" height=\"261\" data-origin-width=\"398\" data-origin-height=\"261\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">Next.js 해킹 이슈가 있었습니다.</h2>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=7YWRDRjz4jU\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=7YWRDRjz4jU</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=7YWRDRjz4jU\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/s5Ikt/hyZPfhQGIY/leW3n7iRrALBqtbSuQuKaK/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/cwIrex/hyZOEo3ywK/59DT9SZWUy1IYos5BkSCSk/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/b3z1r9/hyZOLIujBX/RIFI5KvfxvUbii50q4xaK1/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"리액트/넥스트JS에서 데이터 털리고 서버 뺏기는 최악의 취약점! 바이브코딩은 특히 조심! 해결 \" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/7YWRDRjz4jU\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">문제 내용</h2>\n<p data-ke-size=\"size16\">문제가 .env 파일 내용을 볼 수 있게 되었다고 합니다.</p>\n<p data-ke-size=\"size16\">빨리 패치하라는군</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">배포하려는데 막는군요</h2>\n<p data-ke-size=\"size16\">Error:&nbsp;Vulnerable&nbsp;version&nbsp;of&nbsp;Next.js&nbsp;detected,&nbsp;please&nbsp;update&nbsp;immediately.</p>\n<p data-ke-size=\"size16\">이런 에러입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">업그레이드 명령어는&nbsp;</h2>\n<div style=\"background-color: #000000; color: #ffffff;\">\n<div><span style=\"color: #ffffff;\">npm install next@latest react@latest react-dom@latest</span></div>\n</div>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">망했으니 빨리 막읍시다.</p>",
        "contentSnippet": "Next.js 해킹 이슈가 있었습니다.\n영상: https://www.youtube.com/watch?v=7YWRDRjz4jU\n\n\n\n \n문제 내용\n문제가 .env 파일 내용을 볼 수 있게 되었다고 합니다.\n빨리 패치하라는군\n \n \n배포하려는데 막는군요\nError: Vulnerable version of Next.js detected, please update immediately.\n이런 에러입니다.\n \n업그레이드 명령어는 \nnpm install next@latest react@latest react-dom@latest\n \n \n망했으니 빨리 막읍시다.",
        "guid": "https://serverdown.tistory.com/1529",
        "categories": [
          "프로그래밍/개발메모",
          "Next.js",
          "React",
          "보안이슈"
        ],
        "isoDate": "2025-12-07T07:23:53.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "로봇이 로봇을 생산하는 시점 부터 세상이 뒤집힌다. / 폰노이만 프로브",
        "link": "https://serverdown.tistory.com/1528",
        "pubDate": "Sun, 7 Dec 2025 14:45:19 +0900",
        "author": "SIDNFT",
        "comments": "https://serverdown.tistory.com/1528#entry1528comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"547\" data-origin-height=\"497\"><span data-url=\"https://blog.kakaocdn.net/dn/1ywTj/dJMcafZoQSp/vk6iosG1eSidLcNjiRWpF1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/1ywTj/dJMcafZoQSp/vk6iosG1eSidLcNjiRWpF1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/1ywTj/dJMcafZoQSp/vk6iosG1eSidLcNjiRWpF1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F1ywTj%2FdJMcafZoQSp%2Fvk6iosG1eSidLcNjiRWpF1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"547\" height=\"497\" data-origin-width=\"547\" data-origin-height=\"497\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">우주에서 로봇이 로봇을 생산할 수 있게 되며</p>\n<p data-ke-size=\"size16\">끝없이 우주로 뻣어나갈 수 있게 되는 현상이 시작된다는 것입니다.</p>\n<p data-ke-size=\"size16\">이 목표가 달성되면 시간의 문제이지 무한히 뻣어 나갈 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=k6FPnxxFpPw\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=k6FPnxxFpPw</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=k6FPnxxFpPw\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/15tDp/hyZO1ZMIaO/kRhKKKIPko8Y8zMFjvjK00/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/wAcHP/hyZOLV13oT/9Slk2ZtcCKnP5k6FVoZGj1/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"(테슬라) 옵티머스의 가치평가는?\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/k6FPnxxFpPw\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">18분 55초 에 나옵니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">로봇이 로봇을 생산하기 시작하면</p>\n<p data-ke-size=\"size16\">인건비가 0 에 수렵하는 현상이 발생하며</p>\n<p data-ke-size=\"size16\">사람들은 생산에서 벗어날 수 있게 됩니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이 시점이 오면 선진국은 인건비가 늘어서 생산량을 증가시키지 못하는 문제를 극복하게 됩니다.</p>\n<p data-ke-size=\"size16\">이후에는 로봇기술이 없는 국가는 이 차를 극복할 수 없게 됩니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">마치 칼로 싸우는 중에 총이 등장하는 현상이 나오게 되는 것입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">휴머노이드로봇 투자를 중단할 수 없는 이유이기도 합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "우주에서 로봇이 로봇을 생산할 수 있게 되며\n끝없이 우주로 뻣어나갈 수 있게 되는 현상이 시작된다는 것입니다.\n이 목표가 달성되면 시간의 문제이지 무한히 뻣어 나갈 수 있습니다.\n \n \n영상: https://www.youtube.com/watch?v=k6FPnxxFpPw\n\n\n\n18분 55초 에 나옵니다.\n \n로봇이 로봇을 생산하기 시작하면\n인건비가 0 에 수렵하는 현상이 발생하며\n사람들은 생산에서 벗어날 수 있게 됩니다.\n \n이 시점이 오면 선진국은 인건비가 늘어서 생산량을 증가시키지 못하는 문제를 극복하게 됩니다.\n이후에는 로봇기술이 없는 국가는 이 차를 극복할 수 없게 됩니다.\n \n마치 칼로 싸우는 중에 총이 등장하는 현상이 나오게 되는 것입니다.\n \n휴머노이드로봇 투자를 중단할 수 없는 이유이기도 합니다.",
        "guid": "https://serverdown.tistory.com/1528",
        "categories": [
          "투자"
        ],
        "isoDate": "2025-12-07T05:45:19.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "스머프 모자 짤막 지식 / 프리기아 모자 / 보다",
        "link": "https://serverdown.tistory.com/1527",
        "pubDate": "Sun, 7 Dec 2025 13:33:38 +0900",
        "author": "SIDNFT",
        "comments": "https://serverdown.tistory.com/1527#entry1527comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"238\" data-origin-height=\"192\"><span data-url=\"https://blog.kakaocdn.net/dn/ersbcb/dJMcac2DqcF/8C5WPuCWkXgn93R37S5VsK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/ersbcb/dJMcac2DqcF/8C5WPuCWkXgn93R37S5VsK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/ersbcb/dJMcac2DqcF/8C5WPuCWkXgn93R37S5VsK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fersbcb%2FdJMcac2DqcF%2F8C5WPuCWkXgn93R37S5VsK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"238\" height=\"192\" data-origin-width=\"238\" data-origin-height=\"192\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://youtu.be/Z2_Rx_L1hAI?t=632\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://youtu.be/Z2_Rx_L1hAI?t=632</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=Z2_Rx_L1hAI\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/bu2Pr5/hyZPfWqzrt/JliJDcMUbNoKpStNAFElEK/img.jpg?width=1280&amp;height=720&amp;face=142_108_1232_342,https://scrap.kakaocdn.net/dn/GJGwR/hyZOXiMgq6/900yLq8zTyqb4zIdkyKcB1/img.jpg?width=1280&amp;height=720&amp;face=142_108_1232_342\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"일본 사무라이들은 실제로 싸움을 잘했을까?(내려오는 비기..?)ㅣ역사를 보다 EP.115\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/Z2_Rx_L1hAI\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">10분 30초에 나옵니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">과학하고 앉아있네에서 하길 기다렸는데</p>\n<p data-ke-size=\"size16\">여기서 듣네요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">그리스 시대부터 여기저기 상징으로 쓰게 되었다고 합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">프리기아 모자</h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"246\" data-origin-height=\"224\"><span data-url=\"https://blog.kakaocdn.net/dn/Ac4nT/dJMcafd2a02/akjek1YTilUDuUaLWO55mK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/Ac4nT/dJMcafd2a02/akjek1YTilUDuUaLWO55mK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/Ac4nT/dJMcafd2a02/akjek1YTilUDuUaLWO55mK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FAc4nT%2FdJMcafd2a02%2Fakjek1YTilUDuUaLWO55mK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"246\" height=\"224\" data-origin-width=\"246\" data-origin-height=\"224\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">어쩌다 자유의 상징이 되었고</p>\n<p data-ke-size=\"size16\">귀엽습니다.(!?)</p>\n<p data-ke-size=\"size16\">귀여운건 상징이 될 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">저항의 상징이 된 크록스</h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1012\" data-origin-height=\"259\"><span data-url=\"https://blog.kakaocdn.net/dn/cRoygi/dJMcadHe1dE/NEAWl5qhTvxIoyTTc88pI1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cRoygi/dJMcadHe1dE/NEAWl5qhTvxIoyTTc88pI1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/cRoygi/dJMcadHe1dE/NEAWl5qhTvxIoyTTc88pI1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcRoygi%2FdJMcadHe1dE%2FNEAWl5qhTvxIoyTTc88pI1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1012\" height=\"259\" data-origin-width=\"1012\" data-origin-height=\"259\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">한때는 미국 청소년들이 크록시 신고 나와서 항의 시위도 했었</p>\n<p data-ke-size=\"size16\">싸고 주위에 널렸다면 상지잉 될 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">닌자 이야기</h2>\n<p data-ke-size=\"size16\">닌자도 인내하는 자라는 뜻으로 여러가지 수련을 하는데</p>\n<p data-ke-size=\"size16\">현대 시대에 보면 주식 투자자나 코인 투자자가 아닌가 싶다</p>\n<p data-ke-size=\"size16\">오직 인내만이 결과를 만들어낸다.</p>\n<p data-ke-size=\"size16\">인내하자</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://youtu.be/Z2_Rx_L1hAI?t=632\n\n\n\n10분 30초에 나옵니다.\n \n과학하고 앉아있네에서 하길 기다렸는데\n여기서 듣네요\n \n그리스 시대부터 여기저기 상징으로 쓰게 되었다고 합니다.\n \n프리기아 모자\n\n\n어쩌다 자유의 상징이 되었고\n귀엽습니다.(!?)\n귀여운건 상징이 될 수 있습니다.\n \n저항의 상징이 된 크록스\n\n\n한때는 미국 청소년들이 크록시 신고 나와서 항의 시위도 했었\n싸고 주위에 널렸다면 상지잉 될 수 있습니다.\n \n \n닌자 이야기\n닌자도 인내하는 자라는 뜻으로 여러가지 수련을 하는데\n현대 시대에 보면 주식 투자자나 코인 투자자가 아닌가 싶다\n오직 인내만이 결과를 만들어낸다.\n인내하자",
        "guid": "https://serverdown.tistory.com/1527",
        "categories": [
          "유튜브"
        ],
        "isoDate": "2025-12-07T04:33:38.000Z"
      }
    ]
  },
  {
    "name": "coolspeed",
    "category": "개인",
    "posts": []
  },
  {
    "name": "오늘도 끄적끄적",
    "category": "개인",
    "posts": []
  },
  {
    "name": "dx11 Vanica's Lifelog - 夢が夢で終わらないように",
    "category": "개인",
    "posts": []
  },
  {
    "name": "초코사랑",
    "category": "개인",
    "posts": []
  },
  {
    "name": "ZeroCho Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "imays게임엔진개발자",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for hurinmon Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "기억보단 기록을",
    "category": "개인",
    "posts": [
      {
        "creator": "향로 (기억보단 기록을)",
        "title": "즉시 실행하기",
        "link": "https://jojoldu.tistory.com/855",
        "pubDate": "Mon, 8 Dec 2025 08:59:32 +0900",
        "author": "향로 (기억보단 기록을)",
        "comments": "https://jojoldu.tistory.com/855#entry855comment",
        "content": "<p data-ke-size=\"size16\">지난 금요일 박소령 대표님과 &ldquo;실패를 통과하는 일&rdquo;의 라이브 방송을 진행했다.<br />라이브에서 얘기해주신 내용 중 부산의 유명 카페의 대표님 이야기가 생각난다.<br />B2B로 원두를 납품하는 것이 회사의 중요 사업 중 하나였지만,<br />그 카페의 대표님은 영어를 할 줄 모르셨다.<br />그래서 영어를 잘 하는 영업사원들에게 커피 원두를 아프리카에서 공수해오는 일을 위임했다.<br />근데 그 영업 사원들이 모두 이탈하는 경우가 생기니 회사의 큰 위기가 왔다.<br />이 카페의 가장 코어는 &lsquo;좋은 원두&rsquo; 인데, 그걸 대표가 직접 챙기지 않으니 이런 큰 위기가 올 수도 있다는 깨달음이 있으셨다.<br />그래서 그 길로 한국의 모든 사업은 팀원들에게 맡기고,<br />6개월간 어학연수를 바로 출발하셨다.<br />영어를 배워야만 회사의 코어인 &lsquo;커피 원두&rsquo; 를 대표가 직접 챙길 수 있으니깐.</p>\n<p data-ke-size=\"size16\">그리고 현재는 모든 커피 원두는 대표님이 직접 공수해오고 계신다.<br />직접 아프리카로 가시면서 직접 원두 하나하나를 다 테스팅 하시고 협상도 하신다.</p>\n<p data-ke-size=\"size16\">이 이야기에는 여러가지 고민할거리를 많이 줬다.<br />&lsquo;회사의 코어 인데 내가 직접 하지 않는 건은 무엇이 있을까?&rsquo;<br />&lsquo;지금 당장 실행에 옮기지 않고, 기다리고 있는것은 무엇일까?&rsquo;<br />&lsquo;그걸 실행하지 않는 이유는 무엇일까?&rsquo;<br />&hellip;</p>\n<p data-ke-size=\"size16\">12월은 항상 애매하게 붕 뜬다.<br />1년의 마무리를 하는 시점이다보니,<br />어영부영 정리하면서 내년 1월부터 무언갈 새롭게 시작하자로 정리가 된다.<br />그러다보니 12월에는 항상 무언갈 해낸 경험은 잘 없다.<br />1월을 위한 준비로만 사용하기 때문이다.<br />근데 12월도 한달이다.<br />12개월 중 1개인 1년의 8%를 차지하는 긴 일정이다.<br />이 한달을 정리만 하는것으로 마무리하기엔 너무 아쉽다.</p>\n<p data-ke-size=\"size16\">카페 대표님처럼,<br />생각난 즉시 실행에 옮기려면 1월까지 기다릴 필요 없이 12월에 바로 공부를 시작해야겠다.</p>\n<hr data-ke-style=\"style1\" />\n<p data-ke-size=\"size16\">그런 의미에서, 12월에도 저와 함께 공부하실 분들을 모집합니다 :)</p>\n<p data-ke-size=\"size16\"><a href=\"https://inf.run/kNSjJ\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://inf.run/kNSjJ</a></p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>신청 기간 : 12/4(목)~12/12(금)</li>\n<li>챌린지 기간 : 12월 14일(일)</li>\n</ul>\n<p data-ke-size=\"size16\">1월까지 기다리지말고,<br />12월에 바로 공부해보시죠.<br />12월에 조금이라도 공부한 경험, 완주한 경험은 1월의 새로운 시작을 성공 경험과 함께 더 알차게 시작할 수 있을거라고 믿습니다 :)</p>",
        "contentSnippet": "지난 금요일 박소령 대표님과 “실패를 통과하는 일”의 라이브 방송을 진행했다.\n라이브에서 얘기해주신 내용 중 부산의 유명 카페의 대표님 이야기가 생각난다.\nB2B로 원두를 납품하는 것이 회사의 중요 사업 중 하나였지만,\n그 카페의 대표님은 영어를 할 줄 모르셨다.\n그래서 영어를 잘 하는 영업사원들에게 커피 원두를 아프리카에서 공수해오는 일을 위임했다.\n근데 그 영업 사원들이 모두 이탈하는 경우가 생기니 회사의 큰 위기가 왔다.\n이 카페의 가장 코어는 ‘좋은 원두’ 인데, 그걸 대표가 직접 챙기지 않으니 이런 큰 위기가 올 수도 있다는 깨달음이 있으셨다.\n그래서 그 길로 한국의 모든 사업은 팀원들에게 맡기고,\n6개월간 어학연수를 바로 출발하셨다.\n영어를 배워야만 회사의 코어인 ‘커피 원두’ 를 대표가 직접 챙길 수 있으니깐.\n그리고 현재는 모든 커피 원두는 대표님이 직접 공수해오고 계신다.\n직접 아프리카로 가시면서 직접 원두 하나하나를 다 테스팅 하시고 협상도 하신다.\n이 이야기에는 여러가지 고민할거리를 많이 줬다.\n‘회사의 코어 인데 내가 직접 하지 않는 건은 무엇이 있을까?’\n‘지금 당장 실행에 옮기지 않고, 기다리고 있는것은 무엇일까?’\n‘그걸 실행하지 않는 이유는 무엇일까?’\n…\n12월은 항상 애매하게 붕 뜬다.\n1년의 마무리를 하는 시점이다보니,\n어영부영 정리하면서 내년 1월부터 무언갈 새롭게 시작하자로 정리가 된다.\n그러다보니 12월에는 항상 무언갈 해낸 경험은 잘 없다.\n1월을 위한 준비로만 사용하기 때문이다.\n근데 12월도 한달이다.\n12개월 중 1개인 1년의 8%를 차지하는 긴 일정이다.\n이 한달을 정리만 하는것으로 마무리하기엔 너무 아쉽다.\n카페 대표님처럼,\n생각난 즉시 실행에 옮기려면 1월까지 기다릴 필요 없이 12월에 바로 공부를 시작해야겠다.\n그런 의미에서, 12월에도 저와 함께 공부하실 분들을 모집합니다 :)\nhttps://inf.run/kNSjJ\n신청 기간 : 12/4(목)~12/12(금)\n챌린지 기간 : 12월 14일(일)\n1월까지 기다리지말고,\n12월에 바로 공부해보시죠.\n12월에 조금이라도 공부한 경험, 완주한 경험은 1월의 새로운 시작을 성공 경험과 함께 더 알차게 시작할 수 있을거라고 믿습니다 :)",
        "guid": "https://jojoldu.tistory.com/855",
        "categories": [
          "생각정리",
          "마라톤 챌린지",
          "박소령",
          "실패를 통과하는 일",
          "실패를 통과하는일",
          "향로 챌린지"
        ],
        "isoDate": "2025-12-07T23:59:32.000Z"
      }
    ]
  },
  {
    "name": "WestwoodForever's Dev Log",
    "category": "개인",
    "posts": []
  },
  {
    "name": "허니몬(Honeymon)의 자바guru",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Wolf Loves Fox :: 일상",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Game Programmer Life",
    "category": "개인",
    "posts": []
  },
  {
    "name": "yuchi's dev",
    "category": "개인",
    "posts": []
  },
  {
    "name": "만화로 나누는 자유/오픈소스 소프트웨어 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "신현석(Hyeonseok Shin)",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자 울이 노트",
    "category": "개인",
    "posts": []
  },
  {
    "name": "즐거운 개발자 :: 네이버  블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황제펭귄의 게임개발이야기 [여기는 한국]",
    "category": "개인",
    "posts": []
  },
  {
    "name": "LINE ENGINEERING",
    "category": "기업",
    "posts": [
      {
        "title": "동적 사용자 분할을 활용한 새로운 A/B 테스트 시스템을 소개합니다 ",
        "link": "https://techblog.lycorp.co.jp/ko/advanced-ab-test-system-with-dynamic-user-segmentation",
        "pubDate": "Fri, 05 Dec 2025 02:00:00 GMT",
        "content": "이 글은 Tech-Verse 2025에서 발표된 동적 유저 세분화를 활용한 새로운 A/B 테스트 시스템 세션을 글로 옮긴 것입니다.안녕하세요. LINE+ Contents Servi...",
        "contentSnippet": "이 글은 Tech-Verse 2025에서 발표된 동적 유저 세분화를 활용한 새로운 A/B 테스트 시스템 세션을 글로 옮긴 것입니다.안녕하세요. LINE+ Contents Servi...",
        "guid": "https://techblog.lycorp.co.jp/ko/advanced-ab-test-system-with-dynamic-user-segmentation",
        "isoDate": "2025-12-05T02:00:00.000Z"
      }
    ]
  },
  {
    "name": "뱅크샐러드 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "우아한형제들 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "TOAST Meetup",
    "category": "기업",
    "posts": []
  },
  {
    "name": "ZUM 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "SK Planet",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Spoqa tech blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "팀 왈도 번역팀",
    "category": "게임",
    "posts": []
  },
  {
    "name": "근원님",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황의윤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "호돌맨",
    "category": "개인",
    "posts": [
      {
        "creator": "호돌맨",
        "title": "제주도",
        "link": "https://hodolman.tistory.com/83",
        "pubDate": "Sun, 7 Dec 2025 23:53:05 +0900",
        "author": "호돌맨",
        "comments": "https://hodolman.tistory.com/83#entry83comment",
        "content": "<p data-ke-size=\"size16\">3박 4일 제주도 여행을 다녀와서.</p>\n<p data-ke-size=\"size16\">찍은 사진을 공유 해봅니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"DSC03615.webp\" data-origin-width=\"2000\" data-origin-height=\"3000\"><span data-url=\"https://blog.kakaocdn.net/dn/bZ4CMC/dJMcacVUuVG/6kSExLBeOBucjlJ3h7hGik/img.webp\" data-phocus=\"https://blog.kakaocdn.net/dn/bZ4CMC/dJMcacVUuVG/6kSExLBeOBucjlJ3h7hGik/img.webp\" data-alt=\"어승생악\"><img src=\"https://blog.kakaocdn.net/dn/bZ4CMC/dJMcacVUuVG/6kSExLBeOBucjlJ3h7hGik/img.webp\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbZ4CMC%2FdJMcacVUuVG%2F6kSExLBeOBucjlJ3h7hGik%2Fimg.webp\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"2000\" height=\"3000\" data-filename=\"DSC03615.webp\" data-origin-width=\"2000\" data-origin-height=\"3000\"/></span><figcaption>어승생악</figcaption>\n</figure>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"DSC03676.webp\" data-origin-width=\"3000\" data-origin-height=\"2000\"><span data-url=\"https://blog.kakaocdn.net/dn/bfqBgF/dJMcaiohJLJ/h7aJKXkR2rDe013a8vgkxk/img.webp\" data-phocus=\"https://blog.kakaocdn.net/dn/bfqBgF/dJMcaiohJLJ/h7aJKXkR2rDe013a8vgkxk/img.webp\" data-alt=\"어승생악 정상\"><img src=\"https://blog.kakaocdn.net/dn/bfqBgF/dJMcaiohJLJ/h7aJKXkR2rDe013a8vgkxk/img.webp\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbfqBgF%2FdJMcaiohJLJ%2Fh7aJKXkR2rDe013a8vgkxk%2Fimg.webp\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"3000\" height=\"2000\" data-filename=\"DSC03676.webp\" data-origin-width=\"3000\" data-origin-height=\"2000\"/></span><figcaption>어승생악 정상</figcaption>\n</figure>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"DSC03734.webp\" data-origin-width=\"3000\" data-origin-height=\"2000\"><span data-url=\"https://blog.kakaocdn.net/dn/bjPJOI/dJMcaiohJLK/OePs1DEAdUIogc5RQbdJ01/img.webp\" data-phocus=\"https://blog.kakaocdn.net/dn/bjPJOI/dJMcaiohJLK/OePs1DEAdUIogc5RQbdJ01/img.webp\" data-alt=\"새별오름\"><img src=\"https://blog.kakaocdn.net/dn/bjPJOI/dJMcaiohJLK/OePs1DEAdUIogc5RQbdJ01/img.webp\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbjPJOI%2FdJMcaiohJLK%2FOePs1DEAdUIogc5RQbdJ01%2Fimg.webp\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"3000\" height=\"2000\" data-filename=\"DSC03734.webp\" data-origin-width=\"3000\" data-origin-height=\"2000\"/></span><figcaption>새별오름</figcaption>\n</figure>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"DSC03793.webp\" data-origin-width=\"3000\" data-origin-height=\"2000\"><span data-url=\"https://blog.kakaocdn.net/dn/n2REd/dJMcahJHkaI/8rM2luru0EhRhFyaDXEjjK/img.webp\" data-phocus=\"https://blog.kakaocdn.net/dn/n2REd/dJMcahJHkaI/8rM2luru0EhRhFyaDXEjjK/img.webp\" data-alt=\"새별오름\"><img src=\"https://blog.kakaocdn.net/dn/n2REd/dJMcahJHkaI/8rM2luru0EhRhFyaDXEjjK/img.webp\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fn2REd%2FdJMcahJHkaI%2F8rM2luru0EhRhFyaDXEjjK%2Fimg.webp\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"3000\" height=\"2000\" data-filename=\"DSC03793.webp\" data-origin-width=\"3000\" data-origin-height=\"2000\"/></span><figcaption>새별오름</figcaption>\n</figure>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"DSC03828.webp\" data-origin-width=\"3000\" data-origin-height=\"2000\"><span data-url=\"https://blog.kakaocdn.net/dn/pf708/dJMcafd2lmZ/Tv5BrUwK5znV4wcDRYpbIK/img.webp\" data-phocus=\"https://blog.kakaocdn.net/dn/pf708/dJMcafd2lmZ/Tv5BrUwK5znV4wcDRYpbIK/img.webp\" data-alt=\"중앙식당\"><img src=\"https://blog.kakaocdn.net/dn/pf708/dJMcafd2lmZ/Tv5BrUwK5znV4wcDRYpbIK/img.webp\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fpf708%2FdJMcafd2lmZ%2FTv5BrUwK5znV4wcDRYpbIK%2Fimg.webp\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"3000\" height=\"2000\" data-filename=\"DSC03828.webp\" data-origin-width=\"3000\" data-origin-height=\"2000\"/></span><figcaption>중앙식당</figcaption>\n</figure>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"DSC03846.webp\" data-origin-width=\"2000\" data-origin-height=\"3000\"><span data-url=\"https://blog.kakaocdn.net/dn/cXJ3Py/dJMcaiohJLN/xTI0h6yPm4hcOErzlAJRd0/img.webp\" data-phocus=\"https://blog.kakaocdn.net/dn/cXJ3Py/dJMcaiohJLN/xTI0h6yPm4hcOErzlAJRd0/img.webp\"><img src=\"https://blog.kakaocdn.net/dn/cXJ3Py/dJMcaiohJLN/xTI0h6yPm4hcOErzlAJRd0/img.webp\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcXJ3Py%2FdJMcaiohJLN%2FxTI0h6yPm4hcOErzlAJRd0%2Fimg.webp\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"2000\" height=\"3000\" data-filename=\"DSC03846.webp\" data-origin-width=\"2000\" data-origin-height=\"3000\"/></span></figure>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"DSC03859.webp\" data-origin-width=\"2000\" data-origin-height=\"3000\"><span data-url=\"https://blog.kakaocdn.net/dn/bMxlbZ/dJMcafd2lm2/QSVgsYc3HUA4UghUAwUFmK/img.webp\" data-phocus=\"https://blog.kakaocdn.net/dn/bMxlbZ/dJMcafd2lm2/QSVgsYc3HUA4UghUAwUFmK/img.webp\" data-alt=\"화순 곶자왈\"><img src=\"https://blog.kakaocdn.net/dn/bMxlbZ/dJMcafd2lm2/QSVgsYc3HUA4UghUAwUFmK/img.webp\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbMxlbZ%2FdJMcafd2lm2%2FQSVgsYc3HUA4UghUAwUFmK%2Fimg.webp\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"2000\" height=\"3000\" data-filename=\"DSC03859.webp\" data-origin-width=\"2000\" data-origin-height=\"3000\"/></span><figcaption>화순 곶자왈</figcaption>\n</figure>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"DSC03934.webp\" data-origin-width=\"3000\" data-origin-height=\"2000\"><span data-url=\"https://blog.kakaocdn.net/dn/eB0JF9/dJMcahJHkaJ/0wKTTQ1oY6UZCBjeVDR961/img.webp\" data-phocus=\"https://blog.kakaocdn.net/dn/eB0JF9/dJMcahJHkaJ/0wKTTQ1oY6UZCBjeVDR961/img.webp\" data-alt=\"오또 도넛\"><img src=\"https://blog.kakaocdn.net/dn/eB0JF9/dJMcahJHkaJ/0wKTTQ1oY6UZCBjeVDR961/img.webp\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FeB0JF9%2FdJMcahJHkaJ%2F0wKTTQ1oY6UZCBjeVDR961%2Fimg.webp\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"3000\" height=\"2000\" data-filename=\"DSC03934.webp\" data-origin-width=\"3000\" data-origin-height=\"2000\"/></span><figcaption>오또 도넛</figcaption>\n</figure>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"DSC03937.webp\" data-origin-width=\"2400\" data-origin-height=\"3000\"><span data-url=\"https://blog.kakaocdn.net/dn/b4FBQa/dJMcacVUuVI/WJWfUxJ4UAlpfikNfk3kVK/img.webp\" data-phocus=\"https://blog.kakaocdn.net/dn/b4FBQa/dJMcacVUuVI/WJWfUxJ4UAlpfikNfk3kVK/img.webp\"><img src=\"https://blog.kakaocdn.net/dn/b4FBQa/dJMcacVUuVI/WJWfUxJ4UAlpfikNfk3kVK/img.webp\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb4FBQa%2FdJMcacVUuVI%2FWJWfUxJ4UAlpfikNfk3kVK%2Fimg.webp\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"2400\" height=\"3000\" data-filename=\"DSC03937.webp\" data-origin-width=\"2400\" data-origin-height=\"3000\"/></span></figure>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"DSC03952.webp\" data-origin-width=\"3000\" data-origin-height=\"2000\"><span data-url=\"https://blog.kakaocdn.net/dn/cZquO6/dJMcacVUuVJ/wvgy6KGdNKCdrAD7Fk8W9k/img.webp\" data-phocus=\"https://blog.kakaocdn.net/dn/cZquO6/dJMcacVUuVJ/wvgy6KGdNKCdrAD7Fk8W9k/img.webp\" data-alt=\"고근산\"><img src=\"https://blog.kakaocdn.net/dn/cZquO6/dJMcacVUuVJ/wvgy6KGdNKCdrAD7Fk8W9k/img.webp\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcZquO6%2FdJMcacVUuVJ%2Fwvgy6KGdNKCdrAD7Fk8W9k%2Fimg.webp\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"3000\" height=\"2000\" data-filename=\"DSC03952.webp\" data-origin-width=\"3000\" data-origin-height=\"2000\"/></span><figcaption>고근산</figcaption>\n</figure>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"DSC03983.webp\" data-origin-width=\"2400\" data-origin-height=\"3000\"><span data-url=\"https://blog.kakaocdn.net/dn/9DLos/dJMcafd2lm1/30c4K5D3r8MvoIBE1NIwxK/img.webp\" data-phocus=\"https://blog.kakaocdn.net/dn/9DLos/dJMcafd2lm1/30c4K5D3r8MvoIBE1NIwxK/img.webp\" data-alt=\"고근산\"><img src=\"https://blog.kakaocdn.net/dn/9DLos/dJMcafd2lm1/30c4K5D3r8MvoIBE1NIwxK/img.webp\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F9DLos%2FdJMcafd2lm1%2F30c4K5D3r8MvoIBE1NIwxK%2Fimg.webp\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"2400\" height=\"3000\" data-filename=\"DSC03983.webp\" data-origin-width=\"2400\" data-origin-height=\"3000\"/></span><figcaption>고근산</figcaption>\n</figure>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"DSC04017.webp\" data-origin-width=\"3000\" data-origin-height=\"2000\"><span data-url=\"https://blog.kakaocdn.net/dn/dQfq7b/dJMcacVUuVH/0gSaDXCHmHUv1XvBN8rs0k/img.webp\" data-phocus=\"https://blog.kakaocdn.net/dn/dQfq7b/dJMcacVUuVH/0gSaDXCHmHUv1XvBN8rs0k/img.webp\" data-alt=\"유채꽃 프라자\"><img src=\"https://blog.kakaocdn.net/dn/dQfq7b/dJMcacVUuVH/0gSaDXCHmHUv1XvBN8rs0k/img.webp\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdQfq7b%2FdJMcacVUuVH%2F0gSaDXCHmHUv1XvBN8rs0k%2Fimg.webp\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"3000\" height=\"2000\" data-filename=\"DSC04017.webp\" data-origin-width=\"3000\" data-origin-height=\"2000\"/></span><figcaption>유채꽃 프라자</figcaption>\n</figure>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"DSC04096-HDR.webp\" data-origin-width=\"2400\" data-origin-height=\"3000\"><span data-url=\"https://blog.kakaocdn.net/dn/bjplSm/dJMcaiohJLM/EnfKAtdji1mTxrLfpXCEXk/img.webp\" data-phocus=\"https://blog.kakaocdn.net/dn/bjplSm/dJMcaiohJLM/EnfKAtdji1mTxrLfpXCEXk/img.webp\" data-alt=\"지미봉\"><img src=\"https://blog.kakaocdn.net/dn/bjplSm/dJMcaiohJLM/EnfKAtdji1mTxrLfpXCEXk/img.webp\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbjplSm%2FdJMcaiohJLM%2FEnfKAtdji1mTxrLfpXCEXk%2Fimg.webp\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"2400\" height=\"3000\" data-filename=\"DSC04096-HDR.webp\" data-origin-width=\"2400\" data-origin-height=\"3000\"/></span><figcaption>지미봉</figcaption>\n</figure>\n</p>",
        "contentSnippet": "3박 4일 제주도 여행을 다녀와서.\n찍은 사진을 공유 해봅니다.\n어승생악\n\n어승생악 정상\n\n새별오름\n\n새별오름\n\n중앙식당\n\n\n화순 곶자왈\n\n오또 도넛\n\n\n고근산\n\n고근산\n\n유채꽃 프라자\n\n지미봉",
        "guid": "https://hodolman.tistory.com/83",
        "categories": [
          "여행",
          "제주도"
        ],
        "isoDate": "2025-12-07T14:53:05.000Z"
      }
    ]
  },
  {
    "name": "박우빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "문다영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "유수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "안건주",
    "category": "개인",
    "posts": [
      {
        "title": "데이터 시스템의 미래 - 옳은 일 하기",
        "link": "https://velog.io/@ahngj96/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%98-%EB%AF%B8%EB%9E%98-%EC%98%B3%EC%9D%80-%EC%9D%BC-%ED%95%98%EA%B8%B0",
        "pubDate": "Mon, 08 Dec 2025 13:38:39 GMT",
        "content": "<hr>\n<h2 id=\"doing-the-right-thing-데이터-시스템-설계에서-옳은-일을-한다\">Doing the Right Thing: 데이터 시스템 설계에서 “옳은 일”을 한다</h2>\n<p>앞선 장에서는 데이터 시스템의 아키텍처를 비교하고, 신뢰성·확장성·유지보수성을 높이는 기법을 논의하였다. 그러나 기술적 논의만으로는 충분하지 않다. 모든 시스템은 목적을 가지고 만들어지며, 모든 행동은 의도한 결과뿐 아니라 의도하지 않은 결과도 낳는다. 엔지니어는 시스템이 사회에 미치는 영향을 고려하고, 어떤 세계를 만들고 싶은지에 대해 의식적으로 선택할 책임을 가진다.</p>\n<p>데이터는 추상적 대상처럼 보이지만, 실제로는 사람들의 행동·관심·정체성에 관한 데이터가 많다. 따라서 사람에 관한 데이터를 다룰 때는 인간 존엄과 존중을 최우선 가치로 두어야 한다.</p>\n<hr>\n<h3 id=\"기술은-선악이-아니라-사용-방식이-문제이다\">기술은 선악이 아니라 사용 방식이 문제이다</h3>\n<p>기술 자체가 선하거나 악한 것이 아니라, 그것이 어떻게 사용되고 사람에게 어떤 영향을 미치는지가 중요하다. 검색 엔진과 같은 소프트웨어도, 총과 같은 무기도 “사용과 결과”가 본질을 결정한다. 엔지니어가 기술만 바라보고 결과를 외면하는 태도는 충분하지 않으며, 윤리적 책임은 엔지니어에게도 존재한다.</p>\n<hr>\n<h2 id=\"예측-분석predictive-analytics은-개인의-삶을-직접적으로-바꾼다\">예측 분석(Predictive Analytics)은 개인의 삶을 직접적으로 바꾼다</h2>\n<p>날씨나 질병 확산을 예측하는 분석과 달리, 다음과 같은 예측은 개인의 삶에 직접 영향을 준다.</p>\n<ul>\n<li>재범 가능성 판단</li>\n<li>대출 부도 가능성 판단</li>\n<li>보험금 청구 위험 판단</li>\n<li>채용에서의 “리스크” 판단</li>\n</ul>\n<p>조직은 위험 회피 관점에서 “의심스러우면 거절”을 선택하기 쉽다. 그러나 알고리즘이 개인을 “위험하다”고 라벨링하면, 그 사람은 반복적으로 거절당하며 사회 참여에서 배제될 수 있다. 이러한 체계적 배제는 개인의 자유를 크게 제한하며, “알고리즘 감옥(algorithmic prison)”이라고 불리기도 한다. 이는 죄가 증명되기 전까지 무죄를 전제로 하는 인권 원칙과 정면으로 충돌할 수 있다.</p>\n<hr>\n<h2 id=\"편향과-차별-알고리즘은-공정함을-자동으로-만들지-않는다\">편향과 차별: 알고리즘은 공정함을 자동으로 만들지 않는다</h2>\n<p>알고리즘 판단이 인간 판단보다 반드시 공정하거나 불공정한 것은 아니다. 인간도 편향을 가지고 있으며 차별이 제도화될 수 있다. 데이터 기반 판단이 오히려 더 공정할 수 있다는 기대도 존재한다.</p>\n<p>그러나 예측 분석에서 규칙 자체를 데이터로부터 학습시키면 다음 문제가 발생한다.</p>\n<ul>\n<li>학습된 패턴이 불투명(opaque)하여 “왜 그렇게 판단했는지” 알기 어렵다.</li>\n<li>입력 데이터가 편향되어 있으면, 모델은 그 편향을 학습하여 <strong>증폭</strong>할 가능성이 높다.</li>\n<li>보호 특성(인종/성별/나이/장애/종교 등)을 직접 사용하지 않더라도, 우편번호·IP 주소 등은 보호 특성과 강하게 상관될 수 있어 사실상 대리 변수(proxy)가 된다.</li>\n</ul>\n<p>따라서 편향된 과거 데이터로부터 “공정한 미래”가 자동으로 만들어진다고 믿는 태도는 위험하다. 예측 모델은 과거를 외삽할 뿐이며, 과거가 차별적이었다면 그 차별을 제도화한다. 더 나은 미래를 만들기 위해서는 인간의 도덕적 상상력과 의식적 개입이 필요하다. 데이터와 모델은 도구이지 주인이 아니다.</p>\n<hr>\n<h2 id=\"책임과-설명-가능성-누가-책임지는가\">책임과 설명 가능성: 누가 책임지는가</h2>\n<p>자동화된 의사결정이 확산되면 책임과 설명 가능성 문제가 발생한다.</p>\n<ul>\n<li>인간이 실수하면 책임을 물을 수 있고 항소 절차가 가능하다.</li>\n<li>알고리즘이 실수하면 누가 책임지는지 불분명해진다.</li>\n<li>자율주행차 사고, 신용평가 알고리즘의 차별 등에서 책임 주체가 모호해진다.</li>\n<li>사법적 검토가 들어오면, 모델이 왜 그런 결정을 했는지 설명할 수 있어야 한다.</li>\n</ul>\n<p>전통적 신용점수는 대체로 “개인의 과거 상환 기록” 같은 관련 사실에 기반하며, 오류 수정의 가능성이 존재한다(절차가 어렵더라도). 반면 머신러닝 기반 평가는 입력이 훨씬 넓고 불투명하여, 특정 개인이 왜 불이익을 받았는지 확인하기 어렵고 부당 대우 여부도 판단하기 어렵다.</p>\n<p>또한 예측 분석은 종종 “당신은 과거에 무엇을 했는가”가 아니라 “당신과 유사한 사람들이 과거에 무엇을 했는가”에 근거한다. 이는 고정관념과 범주화(stereotyping)를 내포하며, 잘못된 범주에 배치된 개인에게는 구제가 어렵다. 예측은 본질적으로 확률적이므로, 전체적으로는 맞더라도 개별 사례에서 틀릴 수 있다. 따라서 데이터 기반 결정의 절대적 우월성을 믿는 태도는 위험하다.</p>\n<p>필요한 과제는 다음과 같다.</p>\n<ul>\n<li>알고리즘의 책임성과 투명성 확보</li>\n<li>편향 증폭 방지</li>\n<li>오류가 발생했을 때 수정 및 구제(recours) 메커니즘 구축</li>\n<li>데이터가 사람을 해치는 데 쓰이지 않도록 방지</li>\n</ul>\n<hr>\n<h2 id=\"피드백-루프-예측이-현실을-고정시키는-악순환\">피드백 루프: 예측이 현실을 고정시키는 악순환</h2>\n<p>추천 시스템처럼 비교적 “가벼운” 예측에서도 사회적 문제는 발생한다.</p>\n<ul>\n<li>사용자가 이미 동의하는 콘텐츠만 노출되어 <strong>에코 챔버</strong>가 강화될 수 있다.</li>\n<li>고정관념, 허위정보, 양극화가 증폭될 수 있다.</li>\n</ul>\n<p>개인의 삶에 직접 영향을 주는 예측에서는 더 위험한 <strong>자기강화 피드백 루프</strong>가 생긴다. 예를 들어 채용에서 신용점수를 활용하면, 불운으로 점수가 떨어진 사람은 취업이 어려워지고, 실업은 빈곤을 심화하며, 점수는 더 악화되는 하향 나선이 발생한다. 수학적 엄밀성과 데이터가 이러한 가정을 가리는 위장막이 될 수 있다.</p>\n<p>이 문제는 컴퓨터만이 아니라 사람과 제도를 포함한 전체 시스템을 보는 <strong>시스템 사고(systems thinking)</strong> 가 필요하다. 시스템이 기존 격차를 증폭하는지, 불의를 완화하는지, 의도치 않은 결과는 무엇인지 점검해야 한다.</p>\n<hr>\n<h2 id=\"프라이버시와-트래킹-데이터-수집-자체의-윤리-문제\">프라이버시와 트래킹: 데이터 수집 자체의 윤리 문제</h2>\n<p>사용자가 명시적으로 입력한 데이터를 저장·처리하는 시스템은 사용자를 위한 서비스를 수행하며, 사용자와 서비스의 관계가 비교적 명확하다. 반면 사용자의 활동이 “부수 효과”로 추적·기록되는 경우 관계는 달라진다. 서비스는 사용자가 시킨 일만 수행하는 것이 아니라, 자체 이해관계를 갖게 되며, 이는 사용자의 이해관계와 충돌할 수 있다.</p>\n<p>트래킹은 검색 품질 향상, 추천, A/B 테스트, UI 개선 등 사용자에게 이득을 주는 측면도 있다. 그러나 광고 기반 비즈니스 모델에서는 사용자가 아니라 광고주가 실질적 고객이 되며, 추적은 더 정교해지고 보유 기간이 길어지며, 개인 프로파일링이 강화된다. 이 관계는 “감시(surveillance)”로 볼 수 있다.</p>\n<hr>\n<h2 id=\"감시surveillance라는-관점의-사고-실험\">감시(surveillance)라는 관점의 사고 실험</h2>\n<p>“data”라는 단어를 “surveillance(감시)”로 치환하면, 평소 미화되던 표현이 다른 의미로 들린다. 대규모 감시 인프라가 사실상 구축되고 있으며, IoT의 확산은 마이크·센서가 상시 연결되는 환경을 만들고 있다. 많은 기기는 보안 수준도 낮다.</p>\n<p>과거의 권위주의 국가도 상상하기 어려웠던 “항상 휴대되는 위치 추적 장치”와 “공간마다 존재하는 마이크”가 기업 주도의 방식으로 현실화되고 있다. 감시는 정부만이 아니라 기업에 의해 수행될 수 있으며, 그 결과가 개인의 보험·고용 등 삶의 핵심 영역을 좌우하면 더 이상 “무해한 개인화”로 보기 어렵다.</p>\n<hr>\n<h2 id=\"동의consent와-선택의-자유는-형식적으로만-존재할-수-있다\">동의(consent)와 선택의 자유는 형식적으로만 존재할 수 있다</h2>\n<p>이용약관과 프라이버시 정책에 동의했으므로 사용자가 자발적으로 선택했다고 주장할 수 있다. 그러나 다음 한계가 존재한다.</p>\n<ul>\n<li>사용자는 어떤 데이터가 수집되고 어떻게 결합·보존·처리되는지 충분히 알기 어렵다.</li>\n<li>프라이버시 정책은 이해를 돕기보다 은폐하는 방식으로 작성되는 경우가 많다.</li>\n<li>한 사람의 데이터는 다른 사람(서비스 비사용자)의 정보도 유추할 수 있어, 당사자의 동의만으로 충분하지 않다.</li>\n<li>데이터 제공과 서비스 제공의 교환은 상호 호혜적 협상 관계가 아니라, 서비스가 일방적으로 조건을 정한다.</li>\n<li>서비스가 사회 참여에 사실상 필수라면(네트워크 효과 포함), “사용하지 말라”는 선택지는 실질적 자유가 아니다.</li>\n<li>결국 감시에 동의하지 않는 사람에게 의미 있는 선택권이 없을 수 있으며, 감시는 특권층을 제외하면 회피하기 어려워진다.</li>\n</ul>\n<hr>\n<h2 id=\"프라이버시는-비밀이-아니라-결정권이다\">프라이버시는 비밀이 아니라 “결정권”이다</h2>\n<p>“프라이버시는 죽었다”는 주장은 프라이버시 개념을 오해한 것이다. 프라이버시는 모든 것을 숨긴다는 뜻이 아니라, <strong>무엇을 누구에게 공개할지 스스로 결정할 자유</strong>를 의미한다. 감시 인프라를 통해 데이터가 추출되면, 이 결정권은 개인에서 데이터 수집자로 이전된다.</p>\n<p>기업은 “올바르게 사용하겠다”고 요구하며, 사용자에게는 선택권이 제한된다. 또한 기업은 감시의 결과를 공개하지 않는 경향이 있으며, 광고 타기팅 같은 간접 형태로만 드러난다. 이는 개인이 자신의 민감 정보(질병 여부 등)의 공개에 대한 주도권을 잃는 결과를 낳는다.</p>\n<p>프라이버시 설정은 일부 통제권을 되돌리는 시작점이지만, 서비스 제공자는 여전히 데이터에 광범위한 접근권과 내부 분석권을 가진다. 개인의 프라이버시 권리가 대규모로 기업에 이전되는 현상은 역사적으로 전례가 드물다.</p>\n<hr>\n<h2 id=\"데이터는-자산이자-위험-자산toxic-asset이다\">데이터는 자산이자 위험 자산(toxic asset)이다</h2>\n<p>행동 데이터는 “데이터 배출물(data exhaust)”처럼 가치 없는 부산물로 묘사되기도 한다. 그러나 광고 기반 모델에서는 행동 데이터가 사실상 핵심 자산이며, 사용자 서비스는 데이터 수집을 위한 수단으로 전락할 수 있다.</p>\n<ul>\n<li>데이터 브로커 산업은 개인 데이터를 구매·결합·추론·재판매한다.</li>\n<li>정부도 비공식 협력, 강제력, 법적 요구, 또는 탈취를 통해 데이터를 획득하려 한다.</li>\n<li>기업 파산 시 개인 데이터는 매각될 수 있다.</li>\n<li>데이터 유출은 빈번하며, 데이터는 “유해 물질”에 비유되기도 한다.</li>\n</ul>\n<p>따라서 데이터 수집은 “오늘의 정치 환경”뿐 아니라 “미래의 모든 정권”까지 고려해야 한다. 언젠가 인권을 존중하지 않는 정권이 등장할 가능성을 배제할 수 없으므로, 장차 경찰 국가를 가능케 할 기술을 설치하는 것은 시민적 위생(civic hygiene) 관점에서 위험하다.</p>\n<p>데이터와 지식은 권력이며, 타인을 감시하면서 자신은 감시받지 않는 것은 강력한 권력이다. 기술 기업이 정치 권력을 노리지 않더라도, 축적된 데이터는 공적 감독 밖에서 사람들의 삶에 영향을 미치는 잠재적 권력이 된다.</p>\n<hr>\n<h2 id=\"산업혁명과-정보화-시대-데이터는-정보-시대의-오염이다\">산업혁명과 정보화 시대: 데이터는 “정보 시대의 오염”이다</h2>\n<p>정보화 시대는 산업혁명과 유사하게 장기적으로는 생활 수준을 높일 수 있으나, 단기적으로는 심각한 부작용이 발생할 수 있다. 산업혁명은 오염, 열악한 노동 환경, 아동 노동 등을 낳았고, 이후 규제와 안전장치가 구축되면서 사회 전체가 큰 이익을 얻었다.</p>\n<p>이와 유사하게, 정보화 시대에서 데이터 수집·사용·남용은 중대한 문제이며, 프라이버시 보호는 환경 보호에 비견될 수 있다. 데이터는 정보 시대의 “오염”이며, 이를 어떻게 관리·격리·폐기하는지가 정보 경제의 건강을 좌우한다.</p>\n<hr>\n<h2 id=\"법과-자율규제-균형과-문화-변화가-필요하다\">법과 자율규제: 균형과 문화 변화가 필요하다</h2>\n<p>데이터 보호 법제는 개인 권리를 보존하는 데 도움을 줄 수 있다(예: 목적 제한, 최소 수집, 과잉 수집 금지). 그러나 인터넷 환경에서 실효성은 논쟁적이며, “가능한 많이 모아 나중에 쓰자”는 빅데이터 철학과 충돌한다. 동시에 의료 데이터 분석처럼 사회적 효익이 큰 영역에서는 과규제가 혁신을 방해할 위험도 있어, 기회와 위험의 균형이 어렵다.</p>\n<p>근본적으로는 다음 문화 변화가 요구된다.</p>\n<ul>\n<li>사용자를 최적화할 “지표”로 보지 않고, 존엄·대리권(agency)을 가진 인간으로 대한다.</li>\n<li>데이터 수집과 처리 관행을 자율적으로 절제하여 신뢰를 구축한다.</li>\n<li>사용자에게 데이터 사용 방식에 대한 교육과 투명성을 제공한다.</li>\n<li>데이터는 필요 기간만 보관하고, 필요가 끝나면 폐기한다(“영원 보관”을 당연시하지 않는다).</li>\n<li>정책만이 아니라 암호학적 접근 제어 등 기술적 수단으로 권한을 강제하는 접근을 고려한다.</li>\n</ul>\n<hr>\n<h2 id=\"장-요약-데이터플로우·무결성·감사·윤리\">장 요약: 데이터플로우·무결성·감사·윤리</h2>\n<p>본 장의 논의는 다음 흐름으로 요약된다.</p>\n<ul>\n<li>단일 도구가 모든 요구를 만족시키지 못하므로, 애플리케이션은 여러 컴포넌트를 조합해야 한다.</li>\n<li>배치 처리와 이벤트 스트림을 통해 시스템 간 데이터 변경을 흐르게 하여 데이터 통합 문제를 해결할 수 있다.</li>\n<li>일부 시스템은 기록의 원천(system of record)이 되고, 다른 데이터는 변환을 통해 파생된다(인덱스, 물질화 뷰, ML 모델, 통계 요약 등).</li>\n<li>파생을 비동기·느슨 결합으로 구성하면, 한 영역의 문제가 다른 영역으로 전파되는 것을 줄여 견고성과 장애 내성을 높인다.</li>\n<li>변환 단계의 변경은 입력 전체에 대해 재실행하여 출력 재파생이 가능하며, 이는 애플리케이션 진화를 쉽게 한다.</li>\n<li>분산 트랜잭션 대신, end-to-end 요청 식별자에 기반한 멱등성 및 비동기 제약 검증을 통해 강한 무결성을 더 확장 가능하고 견고하게 달성할 수 있다.</li>\n<li>제약 위반은 즉시 차단하거나, 사후 보정(Compensation)으로 처리할 수 있으며, 이는 실제 비즈니스와 잘 맞는다.</li>\n<li>무결성 검증을 위해 감사(auditing)를 도입하여 데이터 손상과 오류를 조기에 탐지해야 한다.</li>\n<li>마지막으로, 데이터 집약 애플리케이션은 윤리적 책임을 수반하며, 예측 분석·차별·감시·프라이버시 침해·유출·의도치 않은 결과를 고려해야 한다.</li>\n<li>엔지니어는 인간 존엄과 존중을 기반으로, 자신이 만들고 싶은 세계를 의식적으로 선택해야 한다.</li>\n</ul>\n<h1 id=\"참고\">참고</h1>\n<p>데이터 중심 애플리케이션 설계 12장</p>\n",
        "contentSnippet": "Doing the Right Thing: 데이터 시스템 설계에서 “옳은 일”을 한다\n앞선 장에서는 데이터 시스템의 아키텍처를 비교하고, 신뢰성·확장성·유지보수성을 높이는 기법을 논의하였다. 그러나 기술적 논의만으로는 충분하지 않다. 모든 시스템은 목적을 가지고 만들어지며, 모든 행동은 의도한 결과뿐 아니라 의도하지 않은 결과도 낳는다. 엔지니어는 시스템이 사회에 미치는 영향을 고려하고, 어떤 세계를 만들고 싶은지에 대해 의식적으로 선택할 책임을 가진다.\n데이터는 추상적 대상처럼 보이지만, 실제로는 사람들의 행동·관심·정체성에 관한 데이터가 많다. 따라서 사람에 관한 데이터를 다룰 때는 인간 존엄과 존중을 최우선 가치로 두어야 한다.\n기술은 선악이 아니라 사용 방식이 문제이다\n기술 자체가 선하거나 악한 것이 아니라, 그것이 어떻게 사용되고 사람에게 어떤 영향을 미치는지가 중요하다. 검색 엔진과 같은 소프트웨어도, 총과 같은 무기도 “사용과 결과”가 본질을 결정한다. 엔지니어가 기술만 바라보고 결과를 외면하는 태도는 충분하지 않으며, 윤리적 책임은 엔지니어에게도 존재한다.\n예측 분석(Predictive Analytics)은 개인의 삶을 직접적으로 바꾼다\n날씨나 질병 확산을 예측하는 분석과 달리, 다음과 같은 예측은 개인의 삶에 직접 영향을 준다.\n재범 가능성 판단\n대출 부도 가능성 판단\n보험금 청구 위험 판단\n채용에서의 “리스크” 판단\n조직은 위험 회피 관점에서 “의심스러우면 거절”을 선택하기 쉽다. 그러나 알고리즘이 개인을 “위험하다”고 라벨링하면, 그 사람은 반복적으로 거절당하며 사회 참여에서 배제될 수 있다. 이러한 체계적 배제는 개인의 자유를 크게 제한하며, “알고리즘 감옥(algorithmic prison)”이라고 불리기도 한다. 이는 죄가 증명되기 전까지 무죄를 전제로 하는 인권 원칙과 정면으로 충돌할 수 있다.\n편향과 차별: 알고리즘은 공정함을 자동으로 만들지 않는다\n알고리즘 판단이 인간 판단보다 반드시 공정하거나 불공정한 것은 아니다. 인간도 편향을 가지고 있으며 차별이 제도화될 수 있다. 데이터 기반 판단이 오히려 더 공정할 수 있다는 기대도 존재한다.\n그러나 예측 분석에서 규칙 자체를 데이터로부터 학습시키면 다음 문제가 발생한다.\n학습된 패턴이 불투명(opaque)하여 “왜 그렇게 판단했는지” 알기 어렵다.\n입력 데이터가 편향되어 있으면, 모델은 그 편향을 학습하여 증폭할 가능성이 높다.\n보호 특성(인종/성별/나이/장애/종교 등)을 직접 사용하지 않더라도, 우편번호·IP 주소 등은 보호 특성과 강하게 상관될 수 있어 사실상 대리 변수(proxy)가 된다.\n따라서 편향된 과거 데이터로부터 “공정한 미래”가 자동으로 만들어진다고 믿는 태도는 위험하다. 예측 모델은 과거를 외삽할 뿐이며, 과거가 차별적이었다면 그 차별을 제도화한다. 더 나은 미래를 만들기 위해서는 인간의 도덕적 상상력과 의식적 개입이 필요하다. 데이터와 모델은 도구이지 주인이 아니다.\n책임과 설명 가능성: 누가 책임지는가\n자동화된 의사결정이 확산되면 책임과 설명 가능성 문제가 발생한다.\n인간이 실수하면 책임을 물을 수 있고 항소 절차가 가능하다.\n알고리즘이 실수하면 누가 책임지는지 불분명해진다.\n자율주행차 사고, 신용평가 알고리즘의 차별 등에서 책임 주체가 모호해진다.\n사법적 검토가 들어오면, 모델이 왜 그런 결정을 했는지 설명할 수 있어야 한다.\n전통적 신용점수는 대체로 “개인의 과거 상환 기록” 같은 관련 사실에 기반하며, 오류 수정의 가능성이 존재한다(절차가 어렵더라도). 반면 머신러닝 기반 평가는 입력이 훨씬 넓고 불투명하여, 특정 개인이 왜 불이익을 받았는지 확인하기 어렵고 부당 대우 여부도 판단하기 어렵다.\n또한 예측 분석은 종종 “당신은 과거에 무엇을 했는가”가 아니라 “당신과 유사한 사람들이 과거에 무엇을 했는가”에 근거한다. 이는 고정관념과 범주화(stereotyping)를 내포하며, 잘못된 범주에 배치된 개인에게는 구제가 어렵다. 예측은 본질적으로 확률적이므로, 전체적으로는 맞더라도 개별 사례에서 틀릴 수 있다. 따라서 데이터 기반 결정의 절대적 우월성을 믿는 태도는 위험하다.\n필요한 과제는 다음과 같다.\n알고리즘의 책임성과 투명성 확보\n편향 증폭 방지\n오류가 발생했을 때 수정 및 구제(recours) 메커니즘 구축\n데이터가 사람을 해치는 데 쓰이지 않도록 방지\n피드백 루프: 예측이 현실을 고정시키는 악순환\n추천 시스템처럼 비교적 “가벼운” 예측에서도 사회적 문제는 발생한다.\n사용자가 이미 동의하는 콘텐츠만 노출되어 에코 챔버가 강화될 수 있다.\n고정관념, 허위정보, 양극화가 증폭될 수 있다.\n개인의 삶에 직접 영향을 주는 예측에서는 더 위험한 자기강화 피드백 루프가 생긴다. 예를 들어 채용에서 신용점수를 활용하면, 불운으로 점수가 떨어진 사람은 취업이 어려워지고, 실업은 빈곤을 심화하며, 점수는 더 악화되는 하향 나선이 발생한다. 수학적 엄밀성과 데이터가 이러한 가정을 가리는 위장막이 될 수 있다.\n이 문제는 컴퓨터만이 아니라 사람과 제도를 포함한 전체 시스템을 보는 시스템 사고(systems thinking) 가 필요하다. 시스템이 기존 격차를 증폭하는지, 불의를 완화하는지, 의도치 않은 결과는 무엇인지 점검해야 한다.\n프라이버시와 트래킹: 데이터 수집 자체의 윤리 문제\n사용자가 명시적으로 입력한 데이터를 저장·처리하는 시스템은 사용자를 위한 서비스를 수행하며, 사용자와 서비스의 관계가 비교적 명확하다. 반면 사용자의 활동이 “부수 효과”로 추적·기록되는 경우 관계는 달라진다. 서비스는 사용자가 시킨 일만 수행하는 것이 아니라, 자체 이해관계를 갖게 되며, 이는 사용자의 이해관계와 충돌할 수 있다.\n트래킹은 검색 품질 향상, 추천, A/B 테스트, UI 개선 등 사용자에게 이득을 주는 측면도 있다. 그러나 광고 기반 비즈니스 모델에서는 사용자가 아니라 광고주가 실질적 고객이 되며, 추적은 더 정교해지고 보유 기간이 길어지며, 개인 프로파일링이 강화된다. 이 관계는 “감시(surveillance)”로 볼 수 있다.\n감시(surveillance)라는 관점의 사고 실험\n“data”라는 단어를 “surveillance(감시)”로 치환하면, 평소 미화되던 표현이 다른 의미로 들린다. 대규모 감시 인프라가 사실상 구축되고 있으며, IoT의 확산은 마이크·센서가 상시 연결되는 환경을 만들고 있다. 많은 기기는 보안 수준도 낮다.\n과거의 권위주의 국가도 상상하기 어려웠던 “항상 휴대되는 위치 추적 장치”와 “공간마다 존재하는 마이크”가 기업 주도의 방식으로 현실화되고 있다. 감시는 정부만이 아니라 기업에 의해 수행될 수 있으며, 그 결과가 개인의 보험·고용 등 삶의 핵심 영역을 좌우하면 더 이상 “무해한 개인화”로 보기 어렵다.\n동의(consent)와 선택의 자유는 형식적으로만 존재할 수 있다\n이용약관과 프라이버시 정책에 동의했으므로 사용자가 자발적으로 선택했다고 주장할 수 있다. 그러나 다음 한계가 존재한다.\n사용자는 어떤 데이터가 수집되고 어떻게 결합·보존·처리되는지 충분히 알기 어렵다.\n프라이버시 정책은 이해를 돕기보다 은폐하는 방식으로 작성되는 경우가 많다.\n한 사람의 데이터는 다른 사람(서비스 비사용자)의 정보도 유추할 수 있어, 당사자의 동의만으로 충분하지 않다.\n데이터 제공과 서비스 제공의 교환은 상호 호혜적 협상 관계가 아니라, 서비스가 일방적으로 조건을 정한다.\n서비스가 사회 참여에 사실상 필수라면(네트워크 효과 포함), “사용하지 말라”는 선택지는 실질적 자유가 아니다.\n결국 감시에 동의하지 않는 사람에게 의미 있는 선택권이 없을 수 있으며, 감시는 특권층을 제외하면 회피하기 어려워진다.\n프라이버시는 비밀이 아니라 “결정권”이다\n“프라이버시는 죽었다”는 주장은 프라이버시 개념을 오해한 것이다. 프라이버시는 모든 것을 숨긴다는 뜻이 아니라, 무엇을 누구에게 공개할지 스스로 결정할 자유를 의미한다. 감시 인프라를 통해 데이터가 추출되면, 이 결정권은 개인에서 데이터 수집자로 이전된다.\n기업은 “올바르게 사용하겠다”고 요구하며, 사용자에게는 선택권이 제한된다. 또한 기업은 감시의 결과를 공개하지 않는 경향이 있으며, 광고 타기팅 같은 간접 형태로만 드러난다. 이는 개인이 자신의 민감 정보(질병 여부 등)의 공개에 대한 주도권을 잃는 결과를 낳는다.\n프라이버시 설정은 일부 통제권을 되돌리는 시작점이지만, 서비스 제공자는 여전히 데이터에 광범위한 접근권과 내부 분석권을 가진다. 개인의 프라이버시 권리가 대규모로 기업에 이전되는 현상은 역사적으로 전례가 드물다.\n데이터는 자산이자 위험 자산(toxic asset)이다\n행동 데이터는 “데이터 배출물(data exhaust)”처럼 가치 없는 부산물로 묘사되기도 한다. 그러나 광고 기반 모델에서는 행동 데이터가 사실상 핵심 자산이며, 사용자 서비스는 데이터 수집을 위한 수단으로 전락할 수 있다.\n데이터 브로커 산업은 개인 데이터를 구매·결합·추론·재판매한다.\n정부도 비공식 협력, 강제력, 법적 요구, 또는 탈취를 통해 데이터를 획득하려 한다.\n기업 파산 시 개인 데이터는 매각될 수 있다.\n데이터 유출은 빈번하며, 데이터는 “유해 물질”에 비유되기도 한다.\n따라서 데이터 수집은 “오늘의 정치 환경”뿐 아니라 “미래의 모든 정권”까지 고려해야 한다. 언젠가 인권을 존중하지 않는 정권이 등장할 가능성을 배제할 수 없으므로, 장차 경찰 국가를 가능케 할 기술을 설치하는 것은 시민적 위생(civic hygiene) 관점에서 위험하다.\n데이터와 지식은 권력이며, 타인을 감시하면서 자신은 감시받지 않는 것은 강력한 권력이다. 기술 기업이 정치 권력을 노리지 않더라도, 축적된 데이터는 공적 감독 밖에서 사람들의 삶에 영향을 미치는 잠재적 권력이 된다.\n산업혁명과 정보화 시대: 데이터는 “정보 시대의 오염”이다\n정보화 시대는 산업혁명과 유사하게 장기적으로는 생활 수준을 높일 수 있으나, 단기적으로는 심각한 부작용이 발생할 수 있다. 산업혁명은 오염, 열악한 노동 환경, 아동 노동 등을 낳았고, 이후 규제와 안전장치가 구축되면서 사회 전체가 큰 이익을 얻었다.\n이와 유사하게, 정보화 시대에서 데이터 수집·사용·남용은 중대한 문제이며, 프라이버시 보호는 환경 보호에 비견될 수 있다. 데이터는 정보 시대의 “오염”이며, 이를 어떻게 관리·격리·폐기하는지가 정보 경제의 건강을 좌우한다.\n법과 자율규제: 균형과 문화 변화가 필요하다\n데이터 보호 법제는 개인 권리를 보존하는 데 도움을 줄 수 있다(예: 목적 제한, 최소 수집, 과잉 수집 금지). 그러나 인터넷 환경에서 실효성은 논쟁적이며, “가능한 많이 모아 나중에 쓰자”는 빅데이터 철학과 충돌한다. 동시에 의료 데이터 분석처럼 사회적 효익이 큰 영역에서는 과규제가 혁신을 방해할 위험도 있어, 기회와 위험의 균형이 어렵다.\n근본적으로는 다음 문화 변화가 요구된다.\n사용자를 최적화할 “지표”로 보지 않고, 존엄·대리권(agency)을 가진 인간으로 대한다.\n데이터 수집과 처리 관행을 자율적으로 절제하여 신뢰를 구축한다.\n사용자에게 데이터 사용 방식에 대한 교육과 투명성을 제공한다.\n데이터는 필요 기간만 보관하고, 필요가 끝나면 폐기한다(“영원 보관”을 당연시하지 않는다).\n정책만이 아니라 암호학적 접근 제어 등 기술적 수단으로 권한을 강제하는 접근을 고려한다.\n장 요약: 데이터플로우·무결성·감사·윤리\n본 장의 논의는 다음 흐름으로 요약된다.\n단일 도구가 모든 요구를 만족시키지 못하므로, 애플리케이션은 여러 컴포넌트를 조합해야 한다.\n배치 처리와 이벤트 스트림을 통해 시스템 간 데이터 변경을 흐르게 하여 데이터 통합 문제를 해결할 수 있다.\n일부 시스템은 기록의 원천(system of record)이 되고, 다른 데이터는 변환을 통해 파생된다(인덱스, 물질화 뷰, ML 모델, 통계 요약 등).\n파생을 비동기·느슨 결합으로 구성하면, 한 영역의 문제가 다른 영역으로 전파되는 것을 줄여 견고성과 장애 내성을 높인다.\n변환 단계의 변경은 입력 전체에 대해 재실행하여 출력 재파생이 가능하며, 이는 애플리케이션 진화를 쉽게 한다.\n분산 트랜잭션 대신, end-to-end 요청 식별자에 기반한 멱등성 및 비동기 제약 검증을 통해 강한 무결성을 더 확장 가능하고 견고하게 달성할 수 있다.\n제약 위반은 즉시 차단하거나, 사후 보정(Compensation)으로 처리할 수 있으며, 이는 실제 비즈니스와 잘 맞는다.\n무결성 검증을 위해 감사(auditing)를 도입하여 데이터 손상과 오류를 조기에 탐지해야 한다.\n마지막으로, 데이터 집약 애플리케이션은 윤리적 책임을 수반하며, 예측 분석·차별·감시·프라이버시 침해·유출·의도치 않은 결과를 고려해야 한다.\n엔지니어는 인간 존엄과 존중을 기반으로, 자신이 만들고 싶은 세계를 의식적으로 선택해야 한다.\n참고\n데이터 중심 애플리케이션 설계 12장",
        "guid": "https://velog.io/@ahngj96/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%98-%EB%AF%B8%EB%9E%98-%EC%98%B3%EC%9D%80-%EC%9D%BC-%ED%95%98%EA%B8%B0",
        "isoDate": "2025-12-08T13:38:39.000Z"
      },
      {
        "title": "데이터 시스템의 미래 - 정확성을 목표로",
        "link": "https://velog.io/@ahngj96/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%98-%EB%AF%B8%EB%9E%98-%EC%A0%95%ED%99%95%EC%84%B1%EC%9D%84-%EB%AA%A9%ED%91%9C%EB%A1%9C",
        "pubDate": "Sun, 07 Dec 2025 12:58:45 GMT",
        "content": "<p>마틴은 애플리케이션을 정확하게 만들고 결함에 견딜 수 있게 하는 최후의 방법이 전통적인 트랜잭션 접근법이라고 믿지 않는다. 데이터플로 아키텍처(마틴이 생각하는 미래)의 맥락에서 정확성에 관해 생각하는 몇 가지 방법을 제안한다.</p>\n<p>읽기 전용(stateless) 서비스는 장애가 발생하더라도 버그를 수정하고 재시작하면 정상 상태로 복귀하는 경우가 많다. 그러나 데이터베이스와 같은 상태 저장(stateful) 시스템은 “기억하는 시스템”이므로, 한 번 발생한 오류가 장기간 남아 데이터 손상으로 축적될 수 있다. 따라서 분산 시스템에서 <strong>정확성(correctness)</strong> 은 더 엄격한 설계와 검증을 요구한다.</p>\n<hr>\n<h2 id=\"1-트랜잭션acid은-정확성의-만능-해법이-아니다\">1. 트랜잭션(ACID)은 정확성의 만능 해법이 아니다</h2>\n<p>수십 년간 원자성(Atomicity), 격리성(Isolation), 지속성(Durability)은 애플리케이션 정확성을 위한 핵심 도구로 활용되어 왔다. 그러나 현실에서는 다음과 같은 한계가 존재한다.</p>\n<ul>\n<li>약한 격리 수준(weak isolation)은 의미가 불명확하거나 오해되기 쉬워, 특정 애플리케이션에 안전한지 판단하기 어렵다.</li>\n<li>성능과 확장성을 위해 leaderless replication 등 트랜잭션 중심 모델을 대체하는 접근이 사용되기도 하나, 의미론(semantics)이 복잡해지고 “일관성(consistency)”의 정의가 모호해지는 경향이 있다.</li>\n<li>네트워크 장애나 크래시와 같은 현실 조건에서는 제품이 주장하는 보장과 실제 동작이 불일치할 수 있으며, 이러한 간극은 여러 실험적 검증(예: Jepsen)에서 반복적으로 드러난다.</li>\n</ul>\n<p>결론적으로, 강한 트랜잭션을 제공하는 데이터 시스템을 사용하더라도 애플리케이션이 자동으로 정확해지지는 않는다.</p>\n<hr>\n<h2 id=\"2-정확히-한-번exactly-once-실행은-본질적으로-어렵다\">2. “정확히 한 번(Exactly-once)” 실행은 본질적으로 어렵다</h2>\n<p>분산 환경에서는 실패가 상시 발생한다. 메시지 처리 중 실패가 발생하면 일반적으로 다음 중 하나를 선택한다.</p>\n<ul>\n<li>처리를 포기하여 메시지를 드롭한다(데이터 손실 가능성이 발생한다).</li>\n<li>재시도를 수행한다(이미 성공했지만 성공 응답을 받지 못했을 가능성으로 인해 중복 처리 가능성이 발생한다).</li>\n</ul>\n<p>중복 처리는 결제 이중 청구, 카운터 과대 증가, 이체 중복 반영과 같은 형태로 나타나며, 이는 모두 데이터 오염의 한 형태이다. 따라서 “재시도”를 허용하는 시스템에서 정확성을 확보하려면 중복 억제 전략이 필요하다.</p>\n<hr>\n<h2 id=\"3-tcp와-db-트랜잭션만으로는-end-to-end-중복을-제거할-수-없다\">3. TCP와 DB 트랜잭션만으로는 end-to-end 중복을 제거할 수 없다</h2>\n<h3 id=\"31-tcp의-중복-제거는-단일-연결-범위에서만-유효하다\">3.1. TCP의 중복 제거는 단일 연결 범위에서만 유효하다</h3>\n<p>TCP는 시퀀스 번호를 이용하여 패킷 재전송 및 중복 제거를 수행한다. 그러나 이는 <strong>단일 TCP 연결 범위</strong>에서만 동작한다. 예를 들어, 클라이언트가 데이터베이스에 트랜잭션을 전송한 뒤 <code>COMMIT</code>을 전송했지만, 네트워크 단절로 인해 커밋 결과 응답을 받지 못한 경우를 생각할 수 있다. 클라이언트는 트랜잭션이 커밋되었는지 여부를 알 수 없으며, 재연결 후 동일 트랜잭션을 재시도할 가능성이 있다. 비멱등(non-idempotent) 연산이라면 결과가 중복 반영될 수 있다.</p>\n<h3 id=\"32-사용자브라우저서버db-경로-전체에서-중복이-발생한다\">3.2. 사용자(브라우저)–서버–DB 경로 전체에서 중복이 발생한다</h3>\n<p>DB-클라이언트 구간에서 중복을 일부 억제하더라도, 사용자 단말(예: 브라우저)과 애플리케이션 서버 사이에서 동일 요청이 반복 제출될 수 있다. HTTP POST가 타임아웃되면 사용자는 재시도를 수행할 수 있으며, 서버 관점에서는 별도 요청으로, DB 관점에서는 별도 트랜잭션으로 인식된다. 이 경우 일반적인 중복 억제 메커니즘(TCP 수준, DB 연결 수준)은 충분하지 않다.</p>\n<hr>\n<h2 id=\"4-핵심-해법-요청-id를-end-to-end로-전달하여-중복을-억제한다\">4. 핵심 해법: 요청 ID를 end-to-end로 전달하여 중복을 억제한다</h2>\n<p>중복 처리를 근본적으로 억제하려면 요청을 식별하는 <strong>Operation ID(요청 ID)</strong> 를 생성하고 이를 <strong>클라이언트에서 DB까지 end-to-end로 전달</strong>해야 한다.</p>\n<ul>\n<li>클라이언트는 요청마다 UUID 등 유일 식별자를 생성한다.</li>\n<li>요청 ID를 HTTP 요청 본문 또는 숨김 필드 등에 포함하여 서버로 전달한다.</li>\n<li>서버는 해당 요청 ID를 DB에 기록하고, DB는 <code>request_id UNIQUE</code> 제약 등을 통해 동일 요청이 2회 이상 반영되지 않도록 강제한다.</li>\n</ul>\n<p>이 방식은 요청 이벤트를 기록하는 테이블이 일종의 <strong>이벤트 로그(event log)</strong> 로 동작하도록 만들며, 이후의 상태(예: 잔액)는 이벤트로부터 파생될 수 있다.</p>\n<hr>\n<h2 id=\"5-종단-간-논증\">5. 종단 간 논증</h2>\n<p>저수준 신회성 기능이 그 자체로 종단 간 정확성을 보장하기에 충분하지 않다.</p>\n<p>Saltzer, Reed, Clark(1984)의 End-to-End Argument는 다음 원칙을 제시한다.</p>\n<ul>\n<li>특정 기능(중복 제거, 무결성 검증, 암호화 등)은 통신 계층이나 저장 계층만으로 완전하고 정확하게 구현될 수 없으며, 끝단 애플리케이션의 지식과 협력이 필요하다.</li>\n<li>저수준 기능은 문제 발생 확률을 낮추는 데 유용하지만, end-to-end 정확성을 보장하는 충분조건은 아니다.</li>\n</ul>\n<p>따라서 트랜잭션, TCP, 메시징 시스템이 제공하는 신뢰성 기능을 활용하되, 애플리케이션 수준에서 end-to-end 정확성 요구사항을 직접 설계해야 한다.</p>\n<hr>\n<h2 id=\"6-제약-조건-강제하기\">6. 제약 조건 강제하기</h2>\n<p>유저명 중복 금지, 좌석 중복 예약 금지, 요청 ID 유일성 보장과 같은 유니크 제약은 분산 환경에서 본질적으로 합의를 요구한다.</p>\n<ul>\n<li>동시성 상황에서 여러 요청이 동일 값을 주장하면, 시스템은 어느 요청을 승인할지 결정해야 한다.</li>\n<li>일반적으로 단일 리더(leader)가 결정을 수행하게 하면 단순하지만, 리더 장애나 지리적 분산, 확장성 요구가 커지면 다시 합의 문제가 중요해진다.</li>\n</ul>\n<p>유니크 값을 기준으로 파티셔닝하면(예: username 해시) 같은 키의 요청이 동일 파티션으로 라우팅되도록 하여 처리량을 확장할 수 있다.</p>\n<hr>\n<h2 id=\"7-로그-기반-메시징의-유일성\">7. 로그 기반 메시징의 유일성</h2>\n<p>파티션 로그(예: Kafka)는 동일 파티션 내 메시지에 대해 소비자가 같은 순서를 관찰하게 한다. 이는 총순서(total order) 보장으로서 합의와 동등한 성질(총순서 브로드캐스트)로 이해할 수 있다. 이를 이용하면 유니크 제약 처리가 단순해진다.</p>\n<h3 id=\"예시-username-선점-처리-흐름\">예시: username 선점 처리 흐름</h3>\n<ol>\n<li>username 요청을 메시지로 인코딩하여, username 해시 기반 파티션에 append한다.</li>\n<li>스트림 프로세서는 파티션을 단일 스레드로 순차 소비하며, 로컬 상태(예: 로컬 DB)에 점유 여부를 기록한다.</li>\n<li>사용 가능하면 성공 메시지를, 이미 점유된 경우 거절 메시지를 출력 스트림으로 발행한다.</li>\n<li>클라이언트는 출력 스트림에서 자신의 요청 결과를 관찰한다.</li>\n</ol>\n<p>핵심 원리는 충돌 가능성이 있는 쓰기들을 동일 파티션으로 모아 순차 처리함으로써 결정을 결정적이고 단순하게 만드는 것이다.</p>\n<hr>\n<h2 id=\"8-멀티-파티션-요청-처리\">8. 멀티 파티션 요청 처리</h2>\n<p>예를 들어, &quot;이체 요청&quot;은 다음 파티션들과 관련될 수 있다.</p>\n<ul>\n<li>요청 ID 파티션</li>\n<li>출금 계좌(A) 파티션</li>\n<li>입금 계좌(B) 파티션</li>\n</ul>\n<p>전통적 DB 접근은 멀티 파티션 원자 커밋(예: 2PC)을 필요로 하며, 이는 처리량 및 운영 복잡도 비용을 동반한다. 데이터플로우 접근은 다음과 같이 분해하여 동등한 무결성을 달성한다.</p>\n<ol>\n<li>계좌 A에서 계좌 B로 송금하는 요청은 클라이언트에게 고유 요청 ID를 발급받아 요청 ID 기준으로 특정 로그 파티션에 추가된다.</li>\n<li>스트림 처리자는 요청 로그를 읽는다. 각 요청 메시지마다 보내는 사람 계좌 A의 출금 지시 메시지(A로 파티셔닝됨)와 받는 사람 계좌 B의 입금 지시 메시지(B로 파티셔닝됨) 두 가지를 출력 스트림으로 방출한다. 방출한 메시지에는 원 요청 ID가 포함된다.</li>\n<li>후속 처리자는 출금과 입금 지시 스트림을 소비해 요청 ID로 중복을 제거한 다음 변경 내용을 계좌 잔고에 반영한다.</li>\n</ol>\n<p>스트림 프로세서가 재시작되어 동일 이벤트를 재처리하더라도, 파생이 결정적이라면 동일 명령이 재발행될 뿐이며, 최종 반영 단계에서 요청 ID로 중복을 제거하면 무결성이 유지된다.</p>\n<hr>\n<h2 id=\"9-적시성과-무결성\">9. 적시성과 무결성</h2>\n<p>일관성이라는 용어는 서로 다른 요구를 혼합하여 혼란을 유발한다. 이를 다음 두 축으로 분리하여 해석한다.</p>\n<h3 id=\"91-timeliness신선함최신성\">9.1. Timeliness(신선함/최신성)</h3>\n<ul>\n<li>사용자가 최신 상태를 즉시 관찰하는 정도를 의미한다.</li>\n<li>복제 지연 등으로 인해 일시적 불일치가 발생할 수 있으나, 시간이 지나면 자연히 해소되는 성격을 가진다.</li>\n</ul>\n<h3 id=\"92-integrity무결성\">9.2. Integrity(무결성)</h3>\n<ul>\n<li>데이터 손실, 중복 적용, 모순 데이터, 잘못된 파생 데이터와 같은 “오염”이 없는 상태를 의미한다.</li>\n<li>한 번 무결성이 깨지면 기다린다고 복구되지 않으며, 명시적 검증과 수리가 필요하다.</li>\n</ul>\n<p>대부분의 애플리케이션에서 Integrity는 Timeliness보다 더 중요하다. 최신 반영이 늦어지는 것은 허용 가능한 경우가 많지만, 돈이 사라지거나 합계가 맞지 않는 오류는 치명적이다.</p>\n<hr>\n<h2 id=\"10-데이터플로우-시스템의-정확성\">10. 데이터플로우 시스템의 정확성</h2>\n<p>스트리밍 기반 데이터플로우는 비동기 처리이므로 기본적으로 timeliness 보장이 약하다. 그러나 다음 조합을 통해 강한 무결성을 확보할 수 있다.</p>\n<ul>\n<li>쓰기를 단일 이벤트로 표현하여 원자적으로 기록한다.</li>\n<li>나머지 상태 업데이트는 이벤트로부터 결정적(Deterministic) 파생 함수로 계산한다.</li>\n<li>요청 ID를 end-to-end로 전달하여 중복 제거 및 멱등성을 확보한다.</li>\n<li>이벤트를 불변(Immutable)으로 유지하고 필요 시 재처리로 복구 가능하게 설계한다.</li>\n</ul>\n<p>이 조합은 분산 트랜잭션(2PC) 없이도 높은 무결성을 제공할 수 있는 유망한 방향이다.</p>\n<hr>\n<h2 id=\"11-느슨하게-해석되는-제약-조건\">11. 느슨하게 해석되는 제약 조건</h2>\n<p>엄격한 제약을 즉시 강제하려면 동기적 조정(합의/리더/선형화)이 필요하며 이는 성능 및 가용성 비용을 수반한다. 반면 많은 비즈니스는 다음과 같이 일시적 위반을 허용하고 사후 보정으로 해결할 수 있다.</p>\n<ul>\n<li>좌석 중복 예약: 한 명에게 사과하고 대체 좌석 또는 보상을 제공한다.</li>\n<li>재고 초과 판매: 입고 지연에 대해 사과하고 할인 등 보상을 제공한다.</li>\n<li>오버부킹: 환불, 업그레이드, 대체 제공 절차로 처리한다.</li>\n</ul>\n<p>즉, 제약 강제는 불일치로 인한 “사과”를 줄일 수 있으나, 시스템 성능 및 가용성을 낮춰 장애로 인한 “사과”를 늘릴 수 있다. 목표는 사과를 0으로 만드는 것이 아니라, 비즈니스에 적합한 균형점을 찾는 것이다.</p>\n<hr>\n<h2 id=\"12-믿어라-하지만-확인하라\">12. 믿어라, 하지만 확인하라</h2>\n<p>앞선 논의는 어떤 장애는 발생할 수 있고(프로세스 크래시, 전원 장애, 네트워크 지연/드롭 등), 어떤 장애는 발생하지 않는다고(예: fsync 이후 데이터 유실 없음, 메모리 비트 오류 없음, CPU 연산은 항상 정확함) 가정하는 <strong>시스템 모델(system model)</strong> 위에서 진행된다. 이러한 가정은 대부분의 상황에서 타당하지만, 현실에서는 “가능/불가능”의 이분법이라기보다 <strong>확률의 문제</strong>로 이해하는 편이 정확하다. 즉, 매우 드문 사건이라도 규모가 커지면 실제로 발생할 수 있으며, 가정 위반이 실무에서 충분히 관측될 정도인지가 핵심이다.</p>\n<h3 id=\"121-하드웨어는-완벽한-추상화가-아니다\">12.1. 하드웨어는 완벽한 추상화가 아니다</h3>\n<ul>\n<li>디스크는 가만히 두어도 데이터가 조용히(silent) 손상될 수 있다.</li>\n<li>네트워크의 데이터 손상은 TCP 체크섬을 우회하는 경우가 발생할 수 있다.</li>\n<li>메모리의 무작위 비트 플립(bit-flip)은 매우 드물지만, 대규모 디바이스 환경에서는 관측될 수 있다.</li>\n<li>결함이 없는 메모리에서도 특정 접근 패턴으로 비트가 뒤집히는 현상이 보고되었으며(예: <strong>Rowhammer</strong>), 이는 운영체제 보안 메커니즘을 무력화하는 공격에도 활용된다.</li>\n</ul>\n<p>하드웨어 오류는 빈도가 낮더라도 “불가능”하지 않으므로, 시스템은 이를 완전히 배제하는 모델에만 의존해서는 안 된다.</p>\n<h3 id=\"122-소프트웨어-버그가-발생해도-무결성integrity유지하기\">12.2. 소프트웨어 버그가 발생해도 무결성(integrity)유지하기</h3>\n<p>하드웨어뿐 아니라 <strong>소프트웨어 버그</strong>는 더 빈번한 위험 요인이다. 네트워크/메모리/파일시스템의 체크섬은 소프트웨어 버그로 인한 잘못된 데이터 기록을 잡아내지 못한다.</p>\n<ul>\n<li>성숙한 DBMS조차 버그가 존재하며, 유니크 제약을 잘못 유지하거나(사례 존재), 직렬화 격리 수준에서 예상치 못한 이상 현상이 보고된 적이 있다.</li>\n<li>애플리케이션 코드는 DBMS보다 테스트/리뷰 강도가 낮은 경우가 많아, 버그 가능성이 더 높다.</li>\n<li>외래키/유니크 제약 등 DB가 제공하는 무결성 도구를 애플리케이션이 올바르게 사용하지 않는 경우도 많다.</li>\n</ul>\n<p>ACID에서 말하는 “Consistency(일관성)”는 트랜잭션이 “일관된 상태에서 일관된 상태로” 시스템을 변환한다는 가정에 기반한다. 그러나 이는 트랜잭션(애플리케이션 로직)이 버그가 없다는 전제가 필요하며, 애플리케이션이 DB를 잘못 사용하면(예: 약한 격리 수준을 안전하지 않게 사용) 무결성은 보장되지 않는다.</p>\n<h3 id=\"123-약속을-맹목적으로-믿지-마라\">12.3. 약속을 맹목적으로 믿지 마라.</h3>\n<p>하드웨어와 소프트웨어가 이상적으로 동작하지 않을 수 있다면, 데이터 손상은 언젠가 발생할 수 있다고 보는 편이 현실적이다. 따라서 중요한 것은 “손상이 없다고 믿는 것”이 아니라, <strong>손상이 발생했는지 탐지하고 원인을 추적할 수 있는 메커니즘</strong>을 갖추는 것이다. 이러한 무결성 검증을 <strong>감사(auditing)</strong> 라고 한다.</p>\n<ul>\n<li>감사는 금융에만 필요한 개념이 아니며, 금융에서 특히 중요한 이유는 실수가 반드시 발생한다는 사실을 모두가 인정하기 때문이다.</li>\n<li>대규모 스토리지 시스템(HDFS, S3 등)은 디스크를 전적으로 신뢰하지 않고, 백그라운드에서 파일을 읽어 다른 복제본과 비교하거나 디스크 간 이동을 수행하여 <strong>조용한 손상(silent corruption)</strong> 위험을 완화한다.</li>\n<li>“데이터가 정말 존재하는지 확인하려면 읽어서 검사해야 한다”는 원칙이 성립한다.</li>\n<li>동일한 논리로 <strong>백업 복구 테스트</strong>를 주기적으로 수행해야 한다. 복구 테스트가 없다면, 백업이 깨졌다는 사실을 데이터 손실 이후에야 알 수 있다.</li>\n</ul>\n<h3 id=\"124-검증하는-문화\">12.4. 검증하는 문화</h3>\n<p>많은 시스템은 정확성 보장을 절대적인 것으로 가정하고, 드문 데이터 손상 가능성을 고려한 자가 검증 체계를 갖추지 않는다. 그러나 앞으로는 다음과 같은 방향이 필요하다.</p>\n<ul>\n<li>시스템이 스스로 자신의 무결성을 <strong>지속적으로 점검하는 self-validating/self-auditing</strong> 메커니즘의 확산</li>\n<li>ACID 문화가 만든 “트랜잭션을 믿으면 된다”는 습관에서 벗어나, 애플리케이션 설계 단계부터 <strong>감사 가능성(auditability)</strong> 을 투자 대상으로 포함</li>\n</ul>\n<p>NoSQL 확산과 약한 일관성, 그리고 성숙도가 낮은 저장 기술의 보편화는 “맹목적 신뢰” 전략을 더 위험하게 만들었다. 따라서 감사 가능성을 기반으로 한 설계가 중요해진다.</p>\n<h3 id=\"125-감사-기능-설계-이벤트-기반이-유리하다\">12.5. 감사 기능 설계: 이벤트 기반이 유리하다</h3>\n<p>여러 객체를 동시에 변경하는 트랜잭션은, 사후적으로 “왜 이런 변경이 일어났는지”를 해석하기 어렵다. CDC나 트랜잭션 로그를 확보하더라도, 여러 테이블의 INSERT/UPDATE/DELETE만으로는 <strong>의도(why)</strong> 와 맥락을 명확히 복원하기 어렵다. 또한 그 변경을 결정한 애플리케이션 로직 호출은 일회성(transient)이며 재현하기 어렵다.</p>\n<p>반면 <strong>이벤트 기반(event-based) 시스템</strong>은 감사 가능성 측면에서 장점이 있다.</p>\n<ul>\n<li>사용자 입력을 <strong>단일 불변 이벤트(immutable event)</strong> 로 기록한다.</li>\n<li>그 이벤트로부터 파생되는 상태 업데이트는 <strong>결정적(deterministic)</strong> 이고 반복 가능(repeatable)하도록 만든다.</li>\n<li>동일한 이벤트 로그와 동일한 버전의 파생 코드를 실행하면 동일한 결과가 재현된다.</li>\n</ul>\n<p>명시적인 데이터플로우는 데이터의 계보(provenance)를 선명하게 만들어 무결성 점검을 용이하게 한다.</p>\n<ul>\n<li>이벤트 로그는 <strong>해시(hash)</strong> 로 저장소 손상을 검증할 수 있다.</li>\n<li>파생 상태는 이벤트 로그로부터 <strong>재처리(reprocessing)</strong> 하여 동일 결과가 재현되는지 확인할 수 있다.</li>\n<li>필요하면 동일 파생을 <strong>중복 파이프라인으로 병렬 수행</strong>하여 결과를 상호 검증할 수도 있다.</li>\n<li>결정적 데이터플로우는 디버깅/트레이싱을 단순화하며, 문제 상황을 재현하는 <strong>시간 여행 디버깅(time-travel debugging)</strong> 성격의 진단 능력을 제공한다.</li>\n</ul>\n<h3 id=\"126-다시-종단-간-논증-무결성-검증도-end-to-end가-최선이다\">12.6. 다시 종단 간 논증: 무결성 검증도 end-to-end가 최선이다</h3>\n<p>개별 컴포넌트(디스크, 네트워크, 서비스, 알고리즘)가 완전히 무결하다고 신뢰할 수 없다면, 데이터 무결성은 주기적으로 점검해야 한다. 점검이 없다면 손상은 downstream에서 피해를 만든 뒤에야 드러나며, 그 시점에는 원인 추적 비용이 크게 증가한다.</p>\n<p>무결성 점검은 가능한 한 <strong>end-to-end</strong> 로 수행하는 것이 바람직하다.</p>\n<ul>\n<li>검증 범위에 더 많은 시스템을 포함할수록, 어떤 단계에서 손상이 “조용히” 지나갈 여지가 줄어든다.</li>\n<li>파생 데이터 파이프라인 전체를 end-to-end로 검증할 수 있다면, 경로 상의 디스크/네트워크/서비스/알고리즘이 암묵적으로 검증 범위에 포함된다.</li>\n</ul>\n<p>연속적인 end-to-end 무결성 검증은 신뢰도를 높이고, 이는 곧 변경에 대한 두려움을 줄여 시스템 진화를 빠르게 만든다. 이는 자동화 테스트가 변경 리스크를 낮추는 것과 같은 효과를 가진다.</p>\n<h3 id=\"127-감사-가능한-데이터-시스템용-도구-암호학적-검증의-가능성\">12.7. 감사 가능한 데이터 시스템용 도구: 암호학적 검증의 가능성</h3>\n<p>현재 많은 데이터 시스템은 감사 가능성을 1급 요구사항으로 두지 않는다. 애플리케이션이 별도 감사 테이블에 변경 로그를 남길 수는 있으나, 감사 로그와 실제 DB 상태의 무결성을 동시에 보장하기는 여전히 어렵다. 트랜잭션 로그를 HSM으로 서명해 위변조를 방지할 수 있으나, “처음부터 올바른 트랜잭션이 기록되었는지”까지 보장하기는 어렵다.</p>\n<p>이 영역에서 암호학적 도구가 흥미로운 가능성을 제공한다.</p>\n<ul>\n<li>블록체인/분산 원장 기술은 “서로 신뢰하지 않는 조직”이 운영하는 복제본들이 서로를 검증하며, 합의 프로토콜로 실행할 트랜잭션을 결정하는 분산 DB로 이해할 수 있다.</li>\n<li>비잔틴 장애 허용(Byzantine fault tolerance) 측면과 작업 증명(Proof of Work)의 비용 문제, 처리량 한계 등에 대한 비판적 논의가 존재하더라도, <strong>무결성 검증</strong> 아이디어는 주목할 가치가 있다.</li>\n<li>암호학적 감사는 종종 <strong>머클 트리(Merkle tree)</strong> 를 활용하며, 이는 특정 레코드가 데이터셋에 포함됨을 효율적으로 증명하는 데 사용된다.</li>\n<li>암호학적 감사 기법은 인증서 투명성(certificate transparency)처럼 이미 보안 영역에서 실전 적용 사례가 있으며, 향후 데이터 시스템 전반으로 확산될 가능성이 있다.</li>\n</ul>\n<p>암호학적 감사의 성능 오버헤드를 낮추고 대규모 시스템에서도 확장 가능하게 만드는 추가 연구가 필요하나, 장기적으로 주목할 만한 방향이다.</p>\n<hr>\n<h1 id=\"결론\">결론</h1>\n<ul>\n<li>데이터 시스템의 강한 보장은 end-to-end 정확성을 자동으로 제공하지 않는다.</li>\n<li>요청 ID 기반 end-to-end 중복 억제, 불변 이벤트, 결정적 파생, 중복 제거의 조합은 분산 트랜잭션 없이도 강한 무결성을 달성할 수 있다.</li>\n<li>엄격한 제약은 필요한 지점에 국소적으로 적용하고, 나머지는 느슨한 제약과 사후 보정 프로세스로 설계하는 전략이 실용적일 수 있다.</li>\n</ul>\n<h1 id=\"참고\">참고</h1>\n<p>데이터 중심 애플리케이션 설계 12장</p>\n",
        "contentSnippet": "마틴은 애플리케이션을 정확하게 만들고 결함에 견딜 수 있게 하는 최후의 방법이 전통적인 트랜잭션 접근법이라고 믿지 않는다. 데이터플로 아키텍처(마틴이 생각하는 미래)의 맥락에서 정확성에 관해 생각하는 몇 가지 방법을 제안한다.\n읽기 전용(stateless) 서비스는 장애가 발생하더라도 버그를 수정하고 재시작하면 정상 상태로 복귀하는 경우가 많다. 그러나 데이터베이스와 같은 상태 저장(stateful) 시스템은 “기억하는 시스템”이므로, 한 번 발생한 오류가 장기간 남아 데이터 손상으로 축적될 수 있다. 따라서 분산 시스템에서 정확성(correctness) 은 더 엄격한 설계와 검증을 요구한다.\n1. 트랜잭션(ACID)은 정확성의 만능 해법이 아니다\n수십 년간 원자성(Atomicity), 격리성(Isolation), 지속성(Durability)은 애플리케이션 정확성을 위한 핵심 도구로 활용되어 왔다. 그러나 현실에서는 다음과 같은 한계가 존재한다.\n약한 격리 수준(weak isolation)은 의미가 불명확하거나 오해되기 쉬워, 특정 애플리케이션에 안전한지 판단하기 어렵다.\n성능과 확장성을 위해 leaderless replication 등 트랜잭션 중심 모델을 대체하는 접근이 사용되기도 하나, 의미론(semantics)이 복잡해지고 “일관성(consistency)”의 정의가 모호해지는 경향이 있다.\n네트워크 장애나 크래시와 같은 현실 조건에서는 제품이 주장하는 보장과 실제 동작이 불일치할 수 있으며, 이러한 간극은 여러 실험적 검증(예: Jepsen)에서 반복적으로 드러난다.\n결론적으로, 강한 트랜잭션을 제공하는 데이터 시스템을 사용하더라도 애플리케이션이 자동으로 정확해지지는 않는다.\n2. “정확히 한 번(Exactly-once)” 실행은 본질적으로 어렵다\n분산 환경에서는 실패가 상시 발생한다. 메시지 처리 중 실패가 발생하면 일반적으로 다음 중 하나를 선택한다.\n처리를 포기하여 메시지를 드롭한다(데이터 손실 가능성이 발생한다).\n재시도를 수행한다(이미 성공했지만 성공 응답을 받지 못했을 가능성으로 인해 중복 처리 가능성이 발생한다).\n중복 처리는 결제 이중 청구, 카운터 과대 증가, 이체 중복 반영과 같은 형태로 나타나며, 이는 모두 데이터 오염의 한 형태이다. 따라서 “재시도”를 허용하는 시스템에서 정확성을 확보하려면 중복 억제 전략이 필요하다.\n3. TCP와 DB 트랜잭션만으로는 end-to-end 중복을 제거할 수 없다\n3.1. TCP의 중복 제거는 단일 연결 범위에서만 유효하다\nTCP는 시퀀스 번호를 이용하여 패킷 재전송 및 중복 제거를 수행한다. 그러나 이는 단일 TCP 연결 범위에서만 동작한다. 예를 들어, 클라이언트가 데이터베이스에 트랜잭션을 전송한 뒤 COMMIT을 전송했지만, 네트워크 단절로 인해 커밋 결과 응답을 받지 못한 경우를 생각할 수 있다. 클라이언트는 트랜잭션이 커밋되었는지 여부를 알 수 없으며, 재연결 후 동일 트랜잭션을 재시도할 가능성이 있다. 비멱등(non-idempotent) 연산이라면 결과가 중복 반영될 수 있다.\n3.2. 사용자(브라우저)–서버–DB 경로 전체에서 중복이 발생한다\nDB-클라이언트 구간에서 중복을 일부 억제하더라도, 사용자 단말(예: 브라우저)과 애플리케이션 서버 사이에서 동일 요청이 반복 제출될 수 있다. HTTP POST가 타임아웃되면 사용자는 재시도를 수행할 수 있으며, 서버 관점에서는 별도 요청으로, DB 관점에서는 별도 트랜잭션으로 인식된다. 이 경우 일반적인 중복 억제 메커니즘(TCP 수준, DB 연결 수준)은 충분하지 않다.\n4. 핵심 해법: 요청 ID를 end-to-end로 전달하여 중복을 억제한다\n중복 처리를 근본적으로 억제하려면 요청을 식별하는 Operation ID(요청 ID) 를 생성하고 이를 클라이언트에서 DB까지 end-to-end로 전달해야 한다.\n클라이언트는 요청마다 UUID 등 유일 식별자를 생성한다.\n요청 ID를 HTTP 요청 본문 또는 숨김 필드 등에 포함하여 서버로 전달한다.\n서버는 해당 요청 ID를 DB에 기록하고, DB는 request_id UNIQUE 제약 등을 통해 동일 요청이 2회 이상 반영되지 않도록 강제한다.\n이 방식은 요청 이벤트를 기록하는 테이블이 일종의 이벤트 로그(event log) 로 동작하도록 만들며, 이후의 상태(예: 잔액)는 이벤트로부터 파생될 수 있다.\n5. 종단 간 논증\n저수준 신회성 기능이 그 자체로 종단 간 정확성을 보장하기에 충분하지 않다.\nSaltzer, Reed, Clark(1984)의 End-to-End Argument는 다음 원칙을 제시한다.\n특정 기능(중복 제거, 무결성 검증, 암호화 등)은 통신 계층이나 저장 계층만으로 완전하고 정확하게 구현될 수 없으며, 끝단 애플리케이션의 지식과 협력이 필요하다.\n저수준 기능은 문제 발생 확률을 낮추는 데 유용하지만, end-to-end 정확성을 보장하는 충분조건은 아니다.\n따라서 트랜잭션, TCP, 메시징 시스템이 제공하는 신뢰성 기능을 활용하되, 애플리케이션 수준에서 end-to-end 정확성 요구사항을 직접 설계해야 한다.\n6. 제약 조건 강제하기\n유저명 중복 금지, 좌석 중복 예약 금지, 요청 ID 유일성 보장과 같은 유니크 제약은 분산 환경에서 본질적으로 합의를 요구한다.\n동시성 상황에서 여러 요청이 동일 값을 주장하면, 시스템은 어느 요청을 승인할지 결정해야 한다.\n일반적으로 단일 리더(leader)가 결정을 수행하게 하면 단순하지만, 리더 장애나 지리적 분산, 확장성 요구가 커지면 다시 합의 문제가 중요해진다.\n유니크 값을 기준으로 파티셔닝하면(예: username 해시) 같은 키의 요청이 동일 파티션으로 라우팅되도록 하여 처리량을 확장할 수 있다.\n7. 로그 기반 메시징의 유일성\n파티션 로그(예: Kafka)는 동일 파티션 내 메시지에 대해 소비자가 같은 순서를 관찰하게 한다. 이는 총순서(total order) 보장으로서 합의와 동등한 성질(총순서 브로드캐스트)로 이해할 수 있다. 이를 이용하면 유니크 제약 처리가 단순해진다.\n예시: username 선점 처리 흐름\nusername 요청을 메시지로 인코딩하여, username 해시 기반 파티션에 append한다.\n스트림 프로세서는 파티션을 단일 스레드로 순차 소비하며, 로컬 상태(예: 로컬 DB)에 점유 여부를 기록한다.\n사용 가능하면 성공 메시지를, 이미 점유된 경우 거절 메시지를 출력 스트림으로 발행한다.\n클라이언트는 출력 스트림에서 자신의 요청 결과를 관찰한다.\n핵심 원리는 충돌 가능성이 있는 쓰기들을 동일 파티션으로 모아 순차 처리함으로써 결정을 결정적이고 단순하게 만드는 것이다.\n8. 멀티 파티션 요청 처리\n예를 들어, \"이체 요청\"은 다음 파티션들과 관련될 수 있다.\n요청 ID 파티션\n출금 계좌(A) 파티션\n입금 계좌(B) 파티션\n전통적 DB 접근은 멀티 파티션 원자 커밋(예: 2PC)을 필요로 하며, 이는 처리량 및 운영 복잡도 비용을 동반한다. 데이터플로우 접근은 다음과 같이 분해하여 동등한 무결성을 달성한다.\n계좌 A에서 계좌 B로 송금하는 요청은 클라이언트에게 고유 요청 ID를 발급받아 요청 ID 기준으로 특정 로그 파티션에 추가된다.\n스트림 처리자는 요청 로그를 읽는다. 각 요청 메시지마다 보내는 사람 계좌 A의 출금 지시 메시지(A로 파티셔닝됨)와 받는 사람 계좌 B의 입금 지시 메시지(B로 파티셔닝됨) 두 가지를 출력 스트림으로 방출한다. 방출한 메시지에는 원 요청 ID가 포함된다.\n후속 처리자는 출금과 입금 지시 스트림을 소비해 요청 ID로 중복을 제거한 다음 변경 내용을 계좌 잔고에 반영한다.\n스트림 프로세서가 재시작되어 동일 이벤트를 재처리하더라도, 파생이 결정적이라면 동일 명령이 재발행될 뿐이며, 최종 반영 단계에서 요청 ID로 중복을 제거하면 무결성이 유지된다.\n9. 적시성과 무결성\n일관성이라는 용어는 서로 다른 요구를 혼합하여 혼란을 유발한다. 이를 다음 두 축으로 분리하여 해석한다.\n9.1. Timeliness(신선함/최신성)\n사용자가 최신 상태를 즉시 관찰하는 정도를 의미한다.\n복제 지연 등으로 인해 일시적 불일치가 발생할 수 있으나, 시간이 지나면 자연히 해소되는 성격을 가진다.\n9.2. Integrity(무결성)\n데이터 손실, 중복 적용, 모순 데이터, 잘못된 파생 데이터와 같은 “오염”이 없는 상태를 의미한다.\n한 번 무결성이 깨지면 기다린다고 복구되지 않으며, 명시적 검증과 수리가 필요하다.\n대부분의 애플리케이션에서 Integrity는 Timeliness보다 더 중요하다. 최신 반영이 늦어지는 것은 허용 가능한 경우가 많지만, 돈이 사라지거나 합계가 맞지 않는 오류는 치명적이다.\n10. 데이터플로우 시스템의 정확성\n스트리밍 기반 데이터플로우는 비동기 처리이므로 기본적으로 timeliness 보장이 약하다. 그러나 다음 조합을 통해 강한 무결성을 확보할 수 있다.\n쓰기를 단일 이벤트로 표현하여 원자적으로 기록한다.\n나머지 상태 업데이트는 이벤트로부터 결정적(Deterministic) 파생 함수로 계산한다.\n요청 ID를 end-to-end로 전달하여 중복 제거 및 멱등성을 확보한다.\n이벤트를 불변(Immutable)으로 유지하고 필요 시 재처리로 복구 가능하게 설계한다.\n이 조합은 분산 트랜잭션(2PC) 없이도 높은 무결성을 제공할 수 있는 유망한 방향이다.\n11. 느슨하게 해석되는 제약 조건\n엄격한 제약을 즉시 강제하려면 동기적 조정(합의/리더/선형화)이 필요하며 이는 성능 및 가용성 비용을 수반한다. 반면 많은 비즈니스는 다음과 같이 일시적 위반을 허용하고 사후 보정으로 해결할 수 있다.\n좌석 중복 예약: 한 명에게 사과하고 대체 좌석 또는 보상을 제공한다.\n재고 초과 판매: 입고 지연에 대해 사과하고 할인 등 보상을 제공한다.\n오버부킹: 환불, 업그레이드, 대체 제공 절차로 처리한다.\n즉, 제약 강제는 불일치로 인한 “사과”를 줄일 수 있으나, 시스템 성능 및 가용성을 낮춰 장애로 인한 “사과”를 늘릴 수 있다. 목표는 사과를 0으로 만드는 것이 아니라, 비즈니스에 적합한 균형점을 찾는 것이다.\n12. 믿어라, 하지만 확인하라\n앞선 논의는 어떤 장애는 발생할 수 있고(프로세스 크래시, 전원 장애, 네트워크 지연/드롭 등), 어떤 장애는 발생하지 않는다고(예: fsync 이후 데이터 유실 없음, 메모리 비트 오류 없음, CPU 연산은 항상 정확함) 가정하는 시스템 모델(system model) 위에서 진행된다. 이러한 가정은 대부분의 상황에서 타당하지만, 현실에서는 “가능/불가능”의 이분법이라기보다 확률의 문제로 이해하는 편이 정확하다. 즉, 매우 드문 사건이라도 규모가 커지면 실제로 발생할 수 있으며, 가정 위반이 실무에서 충분히 관측될 정도인지가 핵심이다.\n12.1. 하드웨어는 완벽한 추상화가 아니다\n디스크는 가만히 두어도 데이터가 조용히(silent) 손상될 수 있다.\n네트워크의 데이터 손상은 TCP 체크섬을 우회하는 경우가 발생할 수 있다.\n메모리의 무작위 비트 플립(bit-flip)은 매우 드물지만, 대규모 디바이스 환경에서는 관측될 수 있다.\n결함이 없는 메모리에서도 특정 접근 패턴으로 비트가 뒤집히는 현상이 보고되었으며(예: Rowhammer), 이는 운영체제 보안 메커니즘을 무력화하는 공격에도 활용된다.\n하드웨어 오류는 빈도가 낮더라도 “불가능”하지 않으므로, 시스템은 이를 완전히 배제하는 모델에만 의존해서는 안 된다.\n12.2. 소프트웨어 버그가 발생해도 무결성(integrity)유지하기\n하드웨어뿐 아니라 소프트웨어 버그는 더 빈번한 위험 요인이다. 네트워크/메모리/파일시스템의 체크섬은 소프트웨어 버그로 인한 잘못된 데이터 기록을 잡아내지 못한다.\n성숙한 DBMS조차 버그가 존재하며, 유니크 제약을 잘못 유지하거나(사례 존재), 직렬화 격리 수준에서 예상치 못한 이상 현상이 보고된 적이 있다.\n애플리케이션 코드는 DBMS보다 테스트/리뷰 강도가 낮은 경우가 많아, 버그 가능성이 더 높다.\n외래키/유니크 제약 등 DB가 제공하는 무결성 도구를 애플리케이션이 올바르게 사용하지 않는 경우도 많다.\nACID에서 말하는 “Consistency(일관성)”는 트랜잭션이 “일관된 상태에서 일관된 상태로” 시스템을 변환한다는 가정에 기반한다. 그러나 이는 트랜잭션(애플리케이션 로직)이 버그가 없다는 전제가 필요하며, 애플리케이션이 DB를 잘못 사용하면(예: 약한 격리 수준을 안전하지 않게 사용) 무결성은 보장되지 않는다.\n12.3. 약속을 맹목적으로 믿지 마라.\n하드웨어와 소프트웨어가 이상적으로 동작하지 않을 수 있다면, 데이터 손상은 언젠가 발생할 수 있다고 보는 편이 현실적이다. 따라서 중요한 것은 “손상이 없다고 믿는 것”이 아니라, 손상이 발생했는지 탐지하고 원인을 추적할 수 있는 메커니즘을 갖추는 것이다. 이러한 무결성 검증을 감사(auditing) 라고 한다.\n감사는 금융에만 필요한 개념이 아니며, 금융에서 특히 중요한 이유는 실수가 반드시 발생한다는 사실을 모두가 인정하기 때문이다.\n대규모 스토리지 시스템(HDFS, S3 등)은 디스크를 전적으로 신뢰하지 않고, 백그라운드에서 파일을 읽어 다른 복제본과 비교하거나 디스크 간 이동을 수행하여 조용한 손상(silent corruption) 위험을 완화한다.\n“데이터가 정말 존재하는지 확인하려면 읽어서 검사해야 한다”는 원칙이 성립한다.\n동일한 논리로 백업 복구 테스트를 주기적으로 수행해야 한다. 복구 테스트가 없다면, 백업이 깨졌다는 사실을 데이터 손실 이후에야 알 수 있다.\n12.4. 검증하는 문화\n많은 시스템은 정확성 보장을 절대적인 것으로 가정하고, 드문 데이터 손상 가능성을 고려한 자가 검증 체계를 갖추지 않는다. 그러나 앞으로는 다음과 같은 방향이 필요하다.\n시스템이 스스로 자신의 무결성을 지속적으로 점검하는 self-validating/self-auditing 메커니즘의 확산\nACID 문화가 만든 “트랜잭션을 믿으면 된다”는 습관에서 벗어나, 애플리케이션 설계 단계부터 감사 가능성(auditability) 을 투자 대상으로 포함\nNoSQL 확산과 약한 일관성, 그리고 성숙도가 낮은 저장 기술의 보편화는 “맹목적 신뢰” 전략을 더 위험하게 만들었다. 따라서 감사 가능성을 기반으로 한 설계가 중요해진다.\n12.5. 감사 기능 설계: 이벤트 기반이 유리하다\n여러 객체를 동시에 변경하는 트랜잭션은, 사후적으로 “왜 이런 변경이 일어났는지”를 해석하기 어렵다. CDC나 트랜잭션 로그를 확보하더라도, 여러 테이블의 INSERT/UPDATE/DELETE만으로는 의도(why) 와 맥락을 명확히 복원하기 어렵다. 또한 그 변경을 결정한 애플리케이션 로직 호출은 일회성(transient)이며 재현하기 어렵다.\n반면 이벤트 기반(event-based) 시스템은 감사 가능성 측면에서 장점이 있다.\n사용자 입력을 단일 불변 이벤트(immutable event) 로 기록한다.\n그 이벤트로부터 파생되는 상태 업데이트는 결정적(deterministic) 이고 반복 가능(repeatable)하도록 만든다.\n동일한 이벤트 로그와 동일한 버전의 파생 코드를 실행하면 동일한 결과가 재현된다.\n명시적인 데이터플로우는 데이터의 계보(provenance)를 선명하게 만들어 무결성 점검을 용이하게 한다.\n이벤트 로그는 해시(hash) 로 저장소 손상을 검증할 수 있다.\n파생 상태는 이벤트 로그로부터 재처리(reprocessing) 하여 동일 결과가 재현되는지 확인할 수 있다.\n필요하면 동일 파생을 중복 파이프라인으로 병렬 수행하여 결과를 상호 검증할 수도 있다.\n결정적 데이터플로우는 디버깅/트레이싱을 단순화하며, 문제 상황을 재현하는 시간 여행 디버깅(time-travel debugging) 성격의 진단 능력을 제공한다.\n12.6. 다시 종단 간 논증: 무결성 검증도 end-to-end가 최선이다\n개별 컴포넌트(디스크, 네트워크, 서비스, 알고리즘)가 완전히 무결하다고 신뢰할 수 없다면, 데이터 무결성은 주기적으로 점검해야 한다. 점검이 없다면 손상은 downstream에서 피해를 만든 뒤에야 드러나며, 그 시점에는 원인 추적 비용이 크게 증가한다.\n무결성 점검은 가능한 한 end-to-end 로 수행하는 것이 바람직하다.\n검증 범위에 더 많은 시스템을 포함할수록, 어떤 단계에서 손상이 “조용히” 지나갈 여지가 줄어든다.\n파생 데이터 파이프라인 전체를 end-to-end로 검증할 수 있다면, 경로 상의 디스크/네트워크/서비스/알고리즘이 암묵적으로 검증 범위에 포함된다.\n연속적인 end-to-end 무결성 검증은 신뢰도를 높이고, 이는 곧 변경에 대한 두려움을 줄여 시스템 진화를 빠르게 만든다. 이는 자동화 테스트가 변경 리스크를 낮추는 것과 같은 효과를 가진다.\n12.7. 감사 가능한 데이터 시스템용 도구: 암호학적 검증의 가능성\n현재 많은 데이터 시스템은 감사 가능성을 1급 요구사항으로 두지 않는다. 애플리케이션이 별도 감사 테이블에 변경 로그를 남길 수는 있으나, 감사 로그와 실제 DB 상태의 무결성을 동시에 보장하기는 여전히 어렵다. 트랜잭션 로그를 HSM으로 서명해 위변조를 방지할 수 있으나, “처음부터 올바른 트랜잭션이 기록되었는지”까지 보장하기는 어렵다.\n이 영역에서 암호학적 도구가 흥미로운 가능성을 제공한다.\n블록체인/분산 원장 기술은 “서로 신뢰하지 않는 조직”이 운영하는 복제본들이 서로를 검증하며, 합의 프로토콜로 실행할 트랜잭션을 결정하는 분산 DB로 이해할 수 있다.\n비잔틴 장애 허용(Byzantine fault tolerance) 측면과 작업 증명(Proof of Work)의 비용 문제, 처리량 한계 등에 대한 비판적 논의가 존재하더라도, 무결성 검증 아이디어는 주목할 가치가 있다.\n암호학적 감사는 종종 머클 트리(Merkle tree) 를 활용하며, 이는 특정 레코드가 데이터셋에 포함됨을 효율적으로 증명하는 데 사용된다.\n암호학적 감사 기법은 인증서 투명성(certificate transparency)처럼 이미 보안 영역에서 실전 적용 사례가 있으며, 향후 데이터 시스템 전반으로 확산될 가능성이 있다.\n암호학적 감사의 성능 오버헤드를 낮추고 대규모 시스템에서도 확장 가능하게 만드는 추가 연구가 필요하나, 장기적으로 주목할 만한 방향이다.\n결론\n데이터 시스템의 강한 보장은 end-to-end 정확성을 자동으로 제공하지 않는다.\n요청 ID 기반 end-to-end 중복 억제, 불변 이벤트, 결정적 파생, 중복 제거의 조합은 분산 트랜잭션 없이도 강한 무결성을 달성할 수 있다.\n엄격한 제약은 필요한 지점에 국소적으로 적용하고, 나머지는 느슨한 제약과 사후 보정 프로세스로 설계하는 전략이 실용적일 수 있다.\n참고\n데이터 중심 애플리케이션 설계 12장",
        "guid": "https://velog.io/@ahngj96/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%98-%EB%AF%B8%EB%9E%98-%EC%A0%95%ED%99%95%EC%84%B1%EC%9D%84-%EB%AA%A9%ED%91%9C%EB%A1%9C",
        "isoDate": "2025-12-07T12:58:45.000Z"
      },
      {
        "title": "데이터 시스템의 미래 - 데이터 통합",
        "link": "https://velog.io/@ahngj96/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%98-%EB%AF%B8%EB%9E%98",
        "pubDate": "Sun, 07 Dec 2025 06:56:06 GMT",
        "content": "<p>애플리케이션과 시스템을 신뢰할 수 있고 확장 가능하며 유지보수하기 쉽게 만드는 방법들을 모아 그것을 기반으로 미래를 고찰한다.</p>\n<h1 id=\"데이터-통합\">데이터 통합</h1>\n<p>데이터를 사용하는 모든 다른 상황에 적합한 소프트웨어가 있을 가능성은 낮다. 그래서 원하는 애플리케이션 기능을 제공하기 위해서는 반드시 여러 다른 소프트웨어를 함께 엮어 사용해야 한다.</p>\n<p>데이터 통합의 필요성은 나무가 아닌 숲을 보기 위해 줌아웃해서 조직 전체 데이터플로를 고려할 때야 비로소 명확해진다.</p>\n<h3 id=\"데이터플로에-대한-추론\">데이터플로에 대한 추론</h3>\n<p>다른 데이터 접근 양식을 만족하기 위해 같은 데이터의 사본을 여러 저장소 시스템에 유지해야할 때 입력과 출력을 분명히 할 필요가 있다. 어디서 데이터를 처음으로 기록하는지, 어떤 표현형이 어떤 원본에서 파생되는지, 데이터를 모두 올바른 장소로 올바른 형식으로 어떻게 넣는지 등에 대해 충분히 고려해야 한다.</p>\n<h3 id=\"파생-데이터-대-분산-트랜잭션\">파생 데이터 대 분산 트랜잭션</h3>\n<p>추상적인 수준에서 보면 파생 데이터와 분산 트랜잭션은 다른 방식으로 유사한 목표를 달성한다. 쓰기 순서를 결정한다는 목표는 모두 달성한다. 다만 트랜잭셔 ㄴ시스템은 일반적으로 선형성을 지원해서 자신이 쓴 내용 읽기 같은 유용한 기능을 보장해준다. 반면 파생 데이터 시스템은 대개 비동기로 갱신되기 때문에 기본적으로 동시간 갱신 보장을 하지 않는다.</p>\n<p>선형성은 유용하지만 최종적 일관성을 달성하는데 이종 데이터 시스템을 통합하는 가장 장래성 있는 접근법은 로그 기반 파생 데이터라고 마틴 크레프만은 생각한다.</p>\n<h3 id=\"일괄-처리와-스트림-처리\">일괄 처리와 스트림 처리</h3>\n<p>마틴은 데이터 통합의 목표는 데이터를 올바른 장소에 올바른 형태로 두는 것이라 생각한다. 그렇게 하기 위해서는 입력을 소비해 형태를 바꾸고 필터링하고 집계해 모델을 학습하고 평가한 뒤 마지가에는 적절한 출력으로 기록해야 한다. 일괄 처리와 스트림 처리는 이 목표를 달성하기 위한 도구다.</p>\n<h3 id=\"애플리케이션-발전을-위한-데이터-재처리\">애플리케이션 발전을 위한 데이터 재처리</h3>\n<p>기존 데이터를 재처리하는 것은 시스템을 유지보수하기 위한 좋은 메커니즘으로 새로운 기능 추가와 변경된 요구사항에 대응할 수 있다. 재처리 없이 스키마를 변경하는 작업은 레코드에 새 선택적 필드를 추가하거나 새로운 타입의 레코드를 추가하는 것과 같은 간단한 것으로 제한된다. 반면 재처리를 이용하면 새로운 요구사항을 더 잘 만족하기 위해 완전히 다른 모델로 데이터셋을 재구축할 수 있다.</p>\n<p>파생 뷰를 사용하면 점진적 발전이 가능하다. 이전 스키마와 새 스키마를 함께 유지해 같은 데이터를 기반으로 두 개의 독립적인 파생 뷰를 만들 수 있다. 점진적 이전의 장점은 처리의 모든 단계에서 뭔가 잘못됐을 때 쉽게 이전으로 되돌릴 수 있다는 점이다.</p>\n<h1 id=\"데이터베이스-언번들링\">데이터베이스 언번들링</h1>\n<p>추상화 수준에서 보면 데이터베이스, 하둡, 운영체제는 모두 같은 기능을 수행한다. 이 시스템은 모두 데이터를 저장하고 처리하며 질의도 한다.</p>\n<h3 id=\"os와-dbms의-공통점과-차이점-데이터-관리-관점\">OS와 DBMS의 공통점과 차이점 (데이터 관리 관점)</h3>\n<table>\n<thead>\n<tr>\n<th>관점</th>\n<th>공통점</th>\n<th>운영체제(OS)</th>\n<th>DBMS</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>데이터 관리(무엇을 “관리”하나)</strong></td>\n<td>“상태(state)”를 저장·유지하고, 일관성 있게 접근하게 함</td>\n<td><strong>자원/시스템 상태</strong>(프로세스, 스레드, 메모리, 파일, 디바이스, 네트워크 소켓 등) 관리</td>\n<td><strong>도메인 데이터/업무 상태</strong>(테이블/문서/인덱스, 메타데이터, 스키마, 통계 등) 관리</td>\n</tr>\n<tr>\n<td><strong>데이터 관리(저장 단위/구조)</strong></td>\n<td>디스크에 영속화하고, 계층 구조/참조 구조를 만든다</td>\n<td>파일/디렉터리, 페이지 캐시, inode 등 <strong>파일시스템 중심</strong> 구조</td>\n<td>레코드/페이지/세그먼트, 인덱스(B+tree 등), MVCC 버전 등 <strong>데이터 모델 중심</strong> 구조</td>\n</tr>\n<tr>\n<td><strong>데이터 관리(무결성/일관성)</strong></td>\n<td>손상 방지·복구·동시 접근 제어가 필요</td>\n<td>크래시 시 파일시스템 저널링/메타데이터 복구 등 <strong>시스템 레벨 일관성</strong></td>\n<td>제약조건(키/참조/체크), 트랜잭션(ACID), 로그(WAL/redo) 등 <strong>데이터 무결성</strong> 중심</td>\n</tr>\n<tr>\n<td><strong>데이터 관리(보안/권한)</strong></td>\n<td>접근 통제/감사를 제공</td>\n<td>사용자/그룹, 파일 권한, 캡/SELinux, 프로세스 권한 등 <strong>자원 접근 제어</strong></td>\n<td>사용자/롤, 스키마 권한, Row-level security, 감사 로그 등 <strong>데이터 접근 제어</strong></td>\n</tr>\n<tr>\n<td><strong>처리(실행 주체)</strong></td>\n<td>요청을 받아 실행하고 자원을 배분</td>\n<td>프로세스/스레드 스케줄링, 컨텍스트 스위칭 등 <strong>CPU·메모리·I/O 배분</strong></td>\n<td>쿼리 실행 엔진(연산자 파이프라인/벡터화), 버퍼 매니저 등 <strong>데이터 처리 연산</strong></td>\n</tr>\n<tr>\n<td><strong>처리(동시성/경합 처리)</strong></td>\n<td>여러 작업을 동시에 돌리며 경합을 해결</td>\n<td>락/세마포어/뮤텍스, 스케줄러, I/O 큐 등 <strong>커널 동기화·스케줄링</strong></td>\n<td>락/래치 + MVCC, 격리수준, 데드락 탐지 등 <strong>트랜잭션 동시성</strong></td>\n</tr>\n<tr>\n<td><strong>처리(성능 최적화 포인트)</strong></td>\n<td>캐시·배치·스케줄링으로 효율을 올림</td>\n<td>페이지 캐시, I/O 스케줄러, NUMA/메모리 정책 등 <strong>시스템 전반 효율</strong></td>\n<td>인덱스, 통계 기반 옵티마이저, 조인 전략, 실행 계획 캐시 등 <strong>질의 효율</strong></td>\n</tr>\n<tr>\n<td><strong>질의(요청 인터페이스)</strong></td>\n<td>“무언가를 해줘”라는 요청 언어/API가 있다</td>\n<td>시스템 콜, 파일 API, 프로세스/네트워크 API 등 <strong>명령형(How)</strong> 호출 중심</td>\n<td>SQL/Query API 등 <strong>선언형(What)</strong> 질의 중심</td>\n</tr>\n<tr>\n<td><strong>질의(해석/계획/실행)</strong></td>\n<td>요청을 해석해 내부 작업으로 분해</td>\n<td>커널이 시스템 콜을 처리해 드라이버/FS/스케줄러로 <strong>고정된 처리 경로</strong></td>\n<td>옵티마이저가 비용 기반으로 실행 계획 선택(인덱스/조인/스캔) <strong>가변적 계획</strong></td>\n</tr>\n<tr>\n<td><strong>질의 결과의 의미</strong></td>\n<td>결과를 반환(상태 조회 포함)</td>\n<td>파일 읽기/프로세스 상태/네트워크 송수신 등 <strong>자원 상태/바이트 스트림</strong> 반환</td>\n<td>행/집계/정렬/필터링된 <strong>논리적 결과 집합</strong> 반환</td>\n</tr>\n<tr>\n<td><strong>질의의 추상화 수준</strong></td>\n<td>내부 복잡성을 감추고 단순 인터페이스 제공</td>\n<td>“파일을 읽어라/소켓에 써라” 같은 <strong>저수준 자원 추상화</strong></td>\n<td>“이 조건의 데이터를 가져와라” 같은 <strong>고수준 데이터 의미(스키마/관계)</strong></td>\n</tr>\n<tr>\n<td><strong>실패/복구 관점</strong></td>\n<td>장애 시 복구 메커니즘이 핵심</td>\n<td>커널 패닉/전원 장애 후 FS 복구, 서비스 재기동 등 <strong>시스템 복원</strong></td>\n<td>크래시 리커버리(WAL redo/undo), 체크포인트, 복제/백업 등 <strong>데이터 복원</strong></td>\n</tr>\n</tbody></table>\n<p>마틴은 NoSQL을 유닉스의 저수준 추상화 접근법을 분산 OLTP 데이터 저장소 분야로 적용하려는 움직임으로 해석한다. NoSQL처럼 OS와 DBMS의 장점을 결합하기를 바란다.</p>\n<h3 id=\"모든-것의-메타데이터베이스\">모든 것의 메타데이터베이스</h3>\n<p>DBMS가 생성하는 인덱스는 사실 파생 데이터의 일종으로 추상화해서 생각할 수 있다. 이렇게 생각하면 지금까지 파생 데이터로 구성한 전체 조직의 데이터플로 자체가 하나의 DBMS처럼 추상화해서 볼 수 있다. 예를 들어, 일괄 처리와 스트림 처리는 DBMS의 트리거와 스토어드 프로시저로 매핑해서 생각하는 것이다.</p>\n<p>파생 데이터 시스템 아키텍처가 등장하면서 이런 도구를 하나로 통합된 데이터베이스 제품의 기능으로 구현하지 않고, 여러 장비에서 실행되고 여러 팀에서 관리하는 다양한 소프트웨어를 사용해 제공한다. 서로 다른 저장소와 처리 도구를 사용하지만 하나의 응집된 시스템으로 구성할 수 있는 두 가지 길이 존재한다.</p>\n<h4 id=\"연합-데이터베이스-읽기-통합\">연합 데이터베이스: 읽기 통합</h4>\n<p>엄청나게 많은 하단 저장소 엔진과 처리 메서드를 통합해 질의하는 인터페이스.</p>\n<h4 id=\"언번들링-데이터베이스-쓰기-통합\">언번들링 데이터베이스: 쓰기 통합</h4>\n<p>단일 데이터베이스 내에서 일관된 색인을 생성하는 것은 내장된 기능이다. 여러 시스템으로 구성됐을 때도 마찬가지로 변경된 모든 데이터가 올바른 장소에 반영되도록 보장해야 한다. 저장소 시스템들을 신뢰성 있게 결합하기 쉽게 만드는 것은 데이터베이스의 색인 유지 기능을 다른 기술에 걸친 쓰기를 동기화할 수 있는 방식으로 언번들링 하는 방식과 유사하다.\n언번들링 접근법은 하나만 잘하는 작은 도구를 사용하는 유닉스 전통을 따른다. 이 도구들은 통일된 저수준 API를 통해 통신한다.</p>\n<h3 id=\"언번들링이-동작하게-만들기\">언번들링이 동작하게 만들기</h3>\n<p>읽기 통합은 어렵지 않으니 쓰기 통합에 집중해보자. 쓰기를 동기화하는 전통적인 접근법은 이종 저장소 시스템 간 분산 트랜잭션이 필요하다. 마틴은 이 방법이 잘못된 해결책이라 생각한다. 단일 저장소나 스트림 처리 시스템에서 트랜잭션은 쓸 만하다. 하지만 데이터가 다른 기술 사이의 경계를 오간다면 멱등성을 기반으로 쓰기를 수행하는 비동기 이벤트 로그를 사용하는 편이 훨씬 더 강력하고 현실적인 접근법이라 본다.</p>\n<p>로그 기반 통합의 큰 장점은 다양한 구성 요소 간 느슨한 결합이다.</p>\n<blockquote>\n<ol>\n<li>시스템 수준에서 비동기 이벤트 스트림을 사용하면 전체 시스템이 개별 구성 요소의 장애나 성능 저하가 생겨도 잘 견디게 만들 수 있다.</li>\n<li>인적 수준에서 데이터 시스템을 언번들링하면 소프트웨어 구성 요소와 서비스를 다른 팀에서 각자 개발하고 개선하고 독립적으로 유지보수할 수 있다.</li>\n</ol>\n</blockquote>\n<h3 id=\"언번들링-vs-통합-시스템\">언번들링 vs 통합 시스템</h3>\n<p>언번들링이 실제로 미래에 사용될 방법이라고 가정해도 현재 형태의 데이터베이스를 대체하지는 못할 것이다. 데이터베이스는 여전히 스트림 처리자의 상태를 유지하기 위해 필요하고, 전문화된 질의 엔진은 특정 작업부하에 쓰는 용도로 여전히 중요하다.</p>\n<p>여러 다른 인프라에서 수행하는 복잡성도 문제다. 각 소프트웨어마다 학습 곡선과 설정 문제, 그리고 운영상에서만 나타나는 특성이 있다. 따라서 동적 부분을 가능하면 적게 배포해야 유리하다. 단일 통합 소프트웨어 제품은 설계된 용도에 맞춰 사용하면 애플리케이션 코드로 연결한 여러 도구로 구성된 시스템보다 뛰어나고 예측 가능한 성능을 낼 수 있다.</p>\n<p>필요하지도 않은 확장성을 고려해 시스템을 구축하는 노력은 전적으로 낭비일 뿐더러 유연하지 못한 설계에 갇힐 수 있다. 사실상 이것은 성급한 최적화의 한 형태다.</p>\n<p>필요한 모든 것을 만족하는 단일 기술이 있다면 저수준 구성 요소로부터 직접 재구현하려 하지말고 그냥 해당 제품을 사용하는 것이 좋다. 언번들링과 합성의 장점은 요구사항을 모두 만족하는 단일 소프트웨어가 없는 상황에서만 드러난다.</p>\n<blockquote>\n<p><strong>미분 데이터플로(differential dataflow)란</strong>\n입력이 계속 바뀌는 상황에서(스트리밍 업데이트) + 반복(iteration)이 있는 계산(그래프/ML 등)을 전체 재계산 없이 변화분만 전파해서 결과를 유지하는(incremental maintenance) 계산 모델/실행 기법</p>\n<p>직관적으로는 각 연산자 <code>f</code>에 대해 입력이 <code>A → A + a</code>, <code>B → B + b</code>로 바뀌었을 때, 출력 변화는 <code>δz = f(A+a, B+b) − f(A, B)</code> 꼴로 계산/전파(실제로는 키별 인덱스/상태를 유지해 변화가 <strong>영향 주는 부분</strong>만 빠르게 처리). 이 때문에 큰 데이터 전체를 다시 돌리는 대신, 보통 변경된 키/레코드 주변만 영향.</p>\n<p>실행 관점에서 보면 <strong>처리됨 vs 미처리 δ</strong> 두 덩어리를 굴리는 것으로, Naiad 기반 differential 모델(초기 문서/리포트들)에서는 각 엣지가 <code>이미 반영된 δ</code>와 <code>아직 반영 안 된 δ</code>를 나눠 들고 있다가, 연산자가 <code>미처리 δ</code>를 조금씩 가져와 처리하고, 그에 대응하는 <code>출력 δ</code>를 내보내는 식으로 전체가 수렴. 업데이트가 들어오면 다시 <code>미처리 δ</code>가 쌓이고, 그 부분만 연쇄적으로 갱신.</p>\n</blockquote>\n<h2 id=\"데이터플로-주변-애플리케이션-설계\">데이터플로 주변 애플리케이션 설계</h2>\n<p>현대 데이터 시스템은 내결함성과 확장성이 있어야 하고 지속성 있게 데이터를 저장해야 한다. 또 데이터 시스템은 시간이 흐름에 따라 다른 그룹의 사람들이 개발한 이종 기술과도 통합이 가능해야할 뿐 아니라 이미 존재하는 라이브러리와 서비스를 재사용 가능해야한다.\n이런 아이디어를 확장해 언번들링 데이터베이스와 데이터플로의 아이디어 주변에서 애플리케이션을 구축하는 몇 가지 방법을 탐구한다.</p>\n<h3 id=\"애플리케이션-코드와-상태의-분리\">애플리케이션 코드와 상태의 분리</h3>\n<p>마틴은 시스템의 일부는 지속성 있는 데이터 저장을 전문으로 하고 다른 일부는 애플리케이션 코드 실행을 전문으로 하는 게 합리적이라 생각한다. 두 부분이 독립적이라도 여전히 상호작용할 수 있다.</p>\n<p>오늘날 대부분의 웹 어플리케이션이 상태 비저장 서비스로 배포된다. 상태 비저장 서비스 내에서 사용자 요청은 어떤 애플리케이션 서버로도 라우트될 수 있다. 그리고 응답 결과를 보내고 난 요처에 대해서는 완전히 잊어버린다. 이런 배포 양식은 원할 때마다 서버를 추가하고 제거하기에 매우 편리하다. 요즘 추세는 상태 관리와 상태 비저장 애플리케이션 로직을 분리하는 것이다.</p>\n<h3 id=\"데이터플로-상태-변경과-애플리케이션-코드-간-상호작용\">데이터플로: 상태 변경과 애플리케이션 코드 간 상호작용</h3>\n<p>데이터플로 측면에서 애플리케이션을 생각한다는 것은 애플리케이션 코드와 상태 관리 간의 관계를 재조정한다는 의미다. 데이터베이스를 애플리케이션이 직접 조작하는 수동적 변수로 취급하는 대신 상태와 상태 변경, 그리고 상태를 처리하는 코드 간의 상호작용과 협동에 관해 좀 더 생각해 볼 수 있다.</p>\n<p>요약하자면 데이터베이스를 언번들링할 것이고 원본 데이터베이스 외부인 애플리케이션 레벨에서 파생 데이터를 다루겠다는 것이다.</p>\n<p>가장 명심해야 할 점은 파생 데이터를 유지하는 것이 전통적인 메시징 시스템의 설계 목적인 비동기 작업 실행과는 같지 않다는 것이다. 안정적인 메시지 순서화와 내결함성이 있는 메시지 처리를 해야한다. 이 요구 사항은 상당히 엄격하지만 분산 트랜잭션보다 훨씬 저렴하면서 탄탄한 운영을 가능하게 한다.</p>\n<p>이 애플리케이션 코드로 데이터베이스에 내장된 파생 함수가 지원하지 않는 임의 처리가 가능하다. 파이프로 연결한 유닉스 도구와 같이 스트림 처리자를 구성해서 데이터플로를 중심으로 대형 시스템을 구축할 수 있다. 각 연산자는 상태 변경 스트림을 입력으로 받아 다른 상태 변경 스트림을 출력으로 생산한다.</p>\n<h3 id=\"스트림-처리자와-서비스\">스트림 처리자와 서비스</h3>\n<p>스트림 연산자로 데이터플로 시스템을 구성하는 것은 마이크로서비스 접근법과 유사하다. 하지만 기반이 되는 통신 메커니즘은 매우 다르다. 마이크로서비스 접근법은 동기식 상호작용을 사용하지만 스트림 연산자로 구성한 시스템은 단방향 비동기식 메시지 스트림을 사용한다.</p>\n<p>예를 들면, 한 소비자가 특정 통화로 가격이 매겨진 상품을 구매했지만 지불은 다른 통화로 했다고 가정하자.</p>\n<ol>\n<li>마이크로서비스 접근법에서 구매 처리 코드는 특정 통화의 현재 환율을 얻기 위해 환율 서비스나 데이터베이스에 질의한다.</li>\n<li>데이터플로 접근법에서 구매 처리코드는 미리 환율 갱신 스트림을 구독하고 환율이 바뀔 때마다 로컬 데이터베이스에 환율을 기록한다. 구매 처리가 들어올 때 단지 로컬 데이터베이스에 질의하면 된다.</li>\n</ol>\n<h3 id=\"상태-변경을-클라이언트에-푸시하기\">상태 변경을 클라이언트에 푸시하기</h3>\n<p>웹 브라우저에 일반적인 웹 페이지 하나가 로드된 후 서버에서 데이터가 변경된다면 페이지가 새로 로드될 때까지 브라우저는 해당 변경 사항을 알 수 없다. 따라서 명시적으로 변경 사항을 폴링하지 않으면 장치의 상태는 갱신되지 않는 신선도가 떨어지는 캐시다.</p>\n<p>많은 최신 프로토콜이 HTTP의 기본적인 요청/응답 패턴을 벗어나고 있다. 웹브라우저가 서버와 TCP 접속을 유지하면서 연결이 유지되는 동안 서버가 주도적으로 메시지를 브라우저에 보내는 방식의 통신 채널을 제공한다. (예를 들면 서버 알림)</p>\n<p>장치가 얼마 동안 오프라인이라서 그 시간 동안 서버에서 상태 변경 알림을 받지 못할 수 있다. 그러나 이 문제는 &#39;소비자 오프셋&#39;을 통해 이미 해결할 수 있다. 각 장치는 작은 이벤트 스트림을 구독하는 작은 구독자다.</p>\n<p>그럼 왜 모든 애플리케이션을 이런 방식으로 구축하지 않을까? 문제는 상태 비저장 클라이언트와 요청/응답 방식의 상호작용이 데이터베이스, 라이브러리, 프레임워크, 프로토콜에 뿌리 깊게 배어 있기 때문이다. 쓰기 경로를 최종 사용자까지 확장하려면 근본적으로 시스템을 구축하는 방식을 재고할 필요가 있다. 즉 요청/응답 상호작용 방식에서 발행/구독 데이터플로 방식으로 변경해야한다는 의미다. 좀 더 반응성 있는 사용자 인터페이스를 지원하고 더 나은 오프라인 지원을 하기 위해 들이는 노력이 가치 있다고 생각한다. 데이터 시스템을 설계한다면 변경 사항을 구독하는 방식을 염두에 둬야 한다고 생각한다.</p>\n<h1 id=\"참고\">참고</h1>\n<p>데이터 중심 애플리케이션 설계 12장\n<a href=\"https://sunrise-min.tistory.com/entry/Tumbling-window%EC%99%80-Sliding-window\">텀블링 윈도우란</a>\n<a href=\"https://www.cidrdb.org/cidr2013/Papers/CIDR13_Paper111.pdf\">https://www.cidrdb.org/cidr2013/Papers/CIDR13_Paper111.pdf</a></p>\n<p>###</p>\n",
        "contentSnippet": "애플리케이션과 시스템을 신뢰할 수 있고 확장 가능하며 유지보수하기 쉽게 만드는 방법들을 모아 그것을 기반으로 미래를 고찰한다.\n데이터 통합\n데이터를 사용하는 모든 다른 상황에 적합한 소프트웨어가 있을 가능성은 낮다. 그래서 원하는 애플리케이션 기능을 제공하기 위해서는 반드시 여러 다른 소프트웨어를 함께 엮어 사용해야 한다.\n데이터 통합의 필요성은 나무가 아닌 숲을 보기 위해 줌아웃해서 조직 전체 데이터플로를 고려할 때야 비로소 명확해진다.\n데이터플로에 대한 추론\n다른 데이터 접근 양식을 만족하기 위해 같은 데이터의 사본을 여러 저장소 시스템에 유지해야할 때 입력과 출력을 분명히 할 필요가 있다. 어디서 데이터를 처음으로 기록하는지, 어떤 표현형이 어떤 원본에서 파생되는지, 데이터를 모두 올바른 장소로 올바른 형식으로 어떻게 넣는지 등에 대해 충분히 고려해야 한다.\n파생 데이터 대 분산 트랜잭션\n추상적인 수준에서 보면 파생 데이터와 분산 트랜잭션은 다른 방식으로 유사한 목표를 달성한다. 쓰기 순서를 결정한다는 목표는 모두 달성한다. 다만 트랜잭셔 ㄴ시스템은 일반적으로 선형성을 지원해서 자신이 쓴 내용 읽기 같은 유용한 기능을 보장해준다. 반면 파생 데이터 시스템은 대개 비동기로 갱신되기 때문에 기본적으로 동시간 갱신 보장을 하지 않는다.\n선형성은 유용하지만 최종적 일관성을 달성하는데 이종 데이터 시스템을 통합하는 가장 장래성 있는 접근법은 로그 기반 파생 데이터라고 마틴 크레프만은 생각한다.\n일괄 처리와 스트림 처리\n마틴은 데이터 통합의 목표는 데이터를 올바른 장소에 올바른 형태로 두는 것이라 생각한다. 그렇게 하기 위해서는 입력을 소비해 형태를 바꾸고 필터링하고 집계해 모델을 학습하고 평가한 뒤 마지가에는 적절한 출력으로 기록해야 한다. 일괄 처리와 스트림 처리는 이 목표를 달성하기 위한 도구다.\n애플리케이션 발전을 위한 데이터 재처리\n기존 데이터를 재처리하는 것은 시스템을 유지보수하기 위한 좋은 메커니즘으로 새로운 기능 추가와 변경된 요구사항에 대응할 수 있다. 재처리 없이 스키마를 변경하는 작업은 레코드에 새 선택적 필드를 추가하거나 새로운 타입의 레코드를 추가하는 것과 같은 간단한 것으로 제한된다. 반면 재처리를 이용하면 새로운 요구사항을 더 잘 만족하기 위해 완전히 다른 모델로 데이터셋을 재구축할 수 있다.\n파생 뷰를 사용하면 점진적 발전이 가능하다. 이전 스키마와 새 스키마를 함께 유지해 같은 데이터를 기반으로 두 개의 독립적인 파생 뷰를 만들 수 있다. 점진적 이전의 장점은 처리의 모든 단계에서 뭔가 잘못됐을 때 쉽게 이전으로 되돌릴 수 있다는 점이다.\n데이터베이스 언번들링\n추상화 수준에서 보면 데이터베이스, 하둡, 운영체제는 모두 같은 기능을 수행한다. 이 시스템은 모두 데이터를 저장하고 처리하며 질의도 한다.\nOS와 DBMS의 공통점과 차이점 (데이터 관리 관점)\n관점\n공통점\n운영체제(OS)\nDBMS\n\n\n\n데이터 관리(무엇을 “관리”하나)\n“상태(state)”를 저장·유지하고, 일관성 있게 접근하게 함\n자원/시스템 상태(프로세스, 스레드, 메모리, 파일, 디바이스, 네트워크 소켓 등) 관리\n도메인 데이터/업무 상태(테이블/문서/인덱스, 메타데이터, 스키마, 통계 등) 관리\n\n\n데이터 관리(저장 단위/구조)\n디스크에 영속화하고, 계층 구조/참조 구조를 만든다\n파일/디렉터리, 페이지 캐시, inode 등 파일시스템 중심 구조\n레코드/페이지/세그먼트, 인덱스(B+tree 등), MVCC 버전 등 데이터 모델 중심 구조\n\n\n데이터 관리(무결성/일관성)\n손상 방지·복구·동시 접근 제어가 필요\n크래시 시 파일시스템 저널링/메타데이터 복구 등 시스템 레벨 일관성\n제약조건(키/참조/체크), 트랜잭션(ACID), 로그(WAL/redo) 등 데이터 무결성 중심\n\n\n데이터 관리(보안/권한)\n접근 통제/감사를 제공\n사용자/그룹, 파일 권한, 캡/SELinux, 프로세스 권한 등 자원 접근 제어\n사용자/롤, 스키마 권한, Row-level security, 감사 로그 등 데이터 접근 제어\n\n\n처리(실행 주체)\n요청을 받아 실행하고 자원을 배분\n프로세스/스레드 스케줄링, 컨텍스트 스위칭 등 CPU·메모리·I/O 배분\n쿼리 실행 엔진(연산자 파이프라인/벡터화), 버퍼 매니저 등 데이터 처리 연산\n\n\n처리(동시성/경합 처리)\n여러 작업을 동시에 돌리며 경합을 해결\n락/세마포어/뮤텍스, 스케줄러, I/O 큐 등 커널 동기화·스케줄링\n락/래치 + MVCC, 격리수준, 데드락 탐지 등 트랜잭션 동시성\n\n\n처리(성능 최적화 포인트)\n캐시·배치·스케줄링으로 효율을 올림\n페이지 캐시, I/O 스케줄러, NUMA/메모리 정책 등 시스템 전반 효율\n인덱스, 통계 기반 옵티마이저, 조인 전략, 실행 계획 캐시 등 질의 효율\n\n\n질의(요청 인터페이스)\n“무언가를 해줘”라는 요청 언어/API가 있다\n시스템 콜, 파일 API, 프로세스/네트워크 API 등 명령형(How) 호출 중심\nSQL/Query API 등 선언형(What) 질의 중심\n\n\n질의(해석/계획/실행)\n요청을 해석해 내부 작업으로 분해\n커널이 시스템 콜을 처리해 드라이버/FS/스케줄러로 고정된 처리 경로\n옵티마이저가 비용 기반으로 실행 계획 선택(인덱스/조인/스캔) 가변적 계획\n\n\n질의 결과의 의미\n결과를 반환(상태 조회 포함)\n파일 읽기/프로세스 상태/네트워크 송수신 등 자원 상태/바이트 스트림 반환\n행/집계/정렬/필터링된 논리적 결과 집합 반환\n\n\n질의의 추상화 수준\n내부 복잡성을 감추고 단순 인터페이스 제공\n“파일을 읽어라/소켓에 써라” 같은 저수준 자원 추상화\n“이 조건의 데이터를 가져와라” 같은 고수준 데이터 의미(스키마/관계)\n\n\n실패/복구 관점\n장애 시 복구 메커니즘이 핵심\n커널 패닉/전원 장애 후 FS 복구, 서비스 재기동 등 시스템 복원\n크래시 리커버리(WAL redo/undo), 체크포인트, 복제/백업 등 데이터 복원\n\n\n마틴은 NoSQL을 유닉스의 저수준 추상화 접근법을 분산 OLTP 데이터 저장소 분야로 적용하려는 움직임으로 해석한다. NoSQL처럼 OS와 DBMS의 장점을 결합하기를 바란다.\n모든 것의 메타데이터베이스\nDBMS가 생성하는 인덱스는 사실 파생 데이터의 일종으로 추상화해서 생각할 수 있다. 이렇게 생각하면 지금까지 파생 데이터로 구성한 전체 조직의 데이터플로 자체가 하나의 DBMS처럼 추상화해서 볼 수 있다. 예를 들어, 일괄 처리와 스트림 처리는 DBMS의 트리거와 스토어드 프로시저로 매핑해서 생각하는 것이다.\n파생 데이터 시스템 아키텍처가 등장하면서 이런 도구를 하나로 통합된 데이터베이스 제품의 기능으로 구현하지 않고, 여러 장비에서 실행되고 여러 팀에서 관리하는 다양한 소프트웨어를 사용해 제공한다. 서로 다른 저장소와 처리 도구를 사용하지만 하나의 응집된 시스템으로 구성할 수 있는 두 가지 길이 존재한다.\n연합 데이터베이스: 읽기 통합\n엄청나게 많은 하단 저장소 엔진과 처리 메서드를 통합해 질의하는 인터페이스.\n언번들링 데이터베이스: 쓰기 통합\n단일 데이터베이스 내에서 일관된 색인을 생성하는 것은 내장된 기능이다. 여러 시스템으로 구성됐을 때도 마찬가지로 변경된 모든 데이터가 올바른 장소에 반영되도록 보장해야 한다. 저장소 시스템들을 신뢰성 있게 결합하기 쉽게 만드는 것은 데이터베이스의 색인 유지 기능을 다른 기술에 걸친 쓰기를 동기화할 수 있는 방식으로 언번들링 하는 방식과 유사하다.\n언번들링 접근법은 하나만 잘하는 작은 도구를 사용하는 유닉스 전통을 따른다. 이 도구들은 통일된 저수준 API를 통해 통신한다.\n언번들링이 동작하게 만들기\n읽기 통합은 어렵지 않으니 쓰기 통합에 집중해보자. 쓰기를 동기화하는 전통적인 접근법은 이종 저장소 시스템 간 분산 트랜잭션이 필요하다. 마틴은 이 방법이 잘못된 해결책이라 생각한다. 단일 저장소나 스트림 처리 시스템에서 트랜잭션은 쓸 만하다. 하지만 데이터가 다른 기술 사이의 경계를 오간다면 멱등성을 기반으로 쓰기를 수행하는 비동기 이벤트 로그를 사용하는 편이 훨씬 더 강력하고 현실적인 접근법이라 본다.\n로그 기반 통합의 큰 장점은 다양한 구성 요소 간 느슨한 결합이다.\n시스템 수준에서 비동기 이벤트 스트림을 사용하면 전체 시스템이 개별 구성 요소의 장애나 성능 저하가 생겨도 잘 견디게 만들 수 있다.\n인적 수준에서 데이터 시스템을 언번들링하면 소프트웨어 구성 요소와 서비스를 다른 팀에서 각자 개발하고 개선하고 독립적으로 유지보수할 수 있다.\n언번들링 vs 통합 시스템\n언번들링이 실제로 미래에 사용될 방법이라고 가정해도 현재 형태의 데이터베이스를 대체하지는 못할 것이다. 데이터베이스는 여전히 스트림 처리자의 상태를 유지하기 위해 필요하고, 전문화된 질의 엔진은 특정 작업부하에 쓰는 용도로 여전히 중요하다.\n여러 다른 인프라에서 수행하는 복잡성도 문제다. 각 소프트웨어마다 학습 곡선과 설정 문제, 그리고 운영상에서만 나타나는 특성이 있다. 따라서 동적 부분을 가능하면 적게 배포해야 유리하다. 단일 통합 소프트웨어 제품은 설계된 용도에 맞춰 사용하면 애플리케이션 코드로 연결한 여러 도구로 구성된 시스템보다 뛰어나고 예측 가능한 성능을 낼 수 있다.\n필요하지도 않은 확장성을 고려해 시스템을 구축하는 노력은 전적으로 낭비일 뿐더러 유연하지 못한 설계에 갇힐 수 있다. 사실상 이것은 성급한 최적화의 한 형태다.\n필요한 모든 것을 만족하는 단일 기술이 있다면 저수준 구성 요소로부터 직접 재구현하려 하지말고 그냥 해당 제품을 사용하는 것이 좋다. 언번들링과 합성의 장점은 요구사항을 모두 만족하는 단일 소프트웨어가 없는 상황에서만 드러난다.\n미분 데이터플로(differential dataflow)란\n입력이 계속 바뀌는 상황에서(스트리밍 업데이트) + 반복(iteration)이 있는 계산(그래프/ML 등)을 전체 재계산 없이 변화분만 전파해서 결과를 유지하는(incremental maintenance) 계산 모델/실행 기법\n직관적으로는 각 연산자 f에 대해 입력이 A → A + a, B → B + b로 바뀌었을 때, 출력 변화는 δz = f(A+a, B+b) − f(A, B) 꼴로 계산/전파(실제로는 키별 인덱스/상태를 유지해 변화가 영향 주는 부분만 빠르게 처리). 이 때문에 큰 데이터 전체를 다시 돌리는 대신, 보통 변경된 키/레코드 주변만 영향.\n실행 관점에서 보면 처리됨 vs 미처리 δ 두 덩어리를 굴리는 것으로, Naiad 기반 differential 모델(초기 문서/리포트들)에서는 각 엣지가 이미 반영된 δ와 아직 반영 안 된 δ를 나눠 들고 있다가, 연산자가 미처리 δ를 조금씩 가져와 처리하고, 그에 대응하는 출력 δ를 내보내는 식으로 전체가 수렴. 업데이트가 들어오면 다시 미처리 δ가 쌓이고, 그 부분만 연쇄적으로 갱신.\n데이터플로 주변 애플리케이션 설계\n현대 데이터 시스템은 내결함성과 확장성이 있어야 하고 지속성 있게 데이터를 저장해야 한다. 또 데이터 시스템은 시간이 흐름에 따라 다른 그룹의 사람들이 개발한 이종 기술과도 통합이 가능해야할 뿐 아니라 이미 존재하는 라이브러리와 서비스를 재사용 가능해야한다.\n이런 아이디어를 확장해 언번들링 데이터베이스와 데이터플로의 아이디어 주변에서 애플리케이션을 구축하는 몇 가지 방법을 탐구한다.\n애플리케이션 코드와 상태의 분리\n마틴은 시스템의 일부는 지속성 있는 데이터 저장을 전문으로 하고 다른 일부는 애플리케이션 코드 실행을 전문으로 하는 게 합리적이라 생각한다. 두 부분이 독립적이라도 여전히 상호작용할 수 있다.\n오늘날 대부분의 웹 어플리케이션이 상태 비저장 서비스로 배포된다. 상태 비저장 서비스 내에서 사용자 요청은 어떤 애플리케이션 서버로도 라우트될 수 있다. 그리고 응답 결과를 보내고 난 요처에 대해서는 완전히 잊어버린다. 이런 배포 양식은 원할 때마다 서버를 추가하고 제거하기에 매우 편리하다. 요즘 추세는 상태 관리와 상태 비저장 애플리케이션 로직을 분리하는 것이다.\n데이터플로: 상태 변경과 애플리케이션 코드 간 상호작용\n데이터플로 측면에서 애플리케이션을 생각한다는 것은 애플리케이션 코드와 상태 관리 간의 관계를 재조정한다는 의미다. 데이터베이스를 애플리케이션이 직접 조작하는 수동적 변수로 취급하는 대신 상태와 상태 변경, 그리고 상태를 처리하는 코드 간의 상호작용과 협동에 관해 좀 더 생각해 볼 수 있다.\n요약하자면 데이터베이스를 언번들링할 것이고 원본 데이터베이스 외부인 애플리케이션 레벨에서 파생 데이터를 다루겠다는 것이다.\n가장 명심해야 할 점은 파생 데이터를 유지하는 것이 전통적인 메시징 시스템의 설계 목적인 비동기 작업 실행과는 같지 않다는 것이다. 안정적인 메시지 순서화와 내결함성이 있는 메시지 처리를 해야한다. 이 요구 사항은 상당히 엄격하지만 분산 트랜잭션보다 훨씬 저렴하면서 탄탄한 운영을 가능하게 한다.\n이 애플리케이션 코드로 데이터베이스에 내장된 파생 함수가 지원하지 않는 임의 처리가 가능하다. 파이프로 연결한 유닉스 도구와 같이 스트림 처리자를 구성해서 데이터플로를 중심으로 대형 시스템을 구축할 수 있다. 각 연산자는 상태 변경 스트림을 입력으로 받아 다른 상태 변경 스트림을 출력으로 생산한다.\n스트림 처리자와 서비스\n스트림 연산자로 데이터플로 시스템을 구성하는 것은 마이크로서비스 접근법과 유사하다. 하지만 기반이 되는 통신 메커니즘은 매우 다르다. 마이크로서비스 접근법은 동기식 상호작용을 사용하지만 스트림 연산자로 구성한 시스템은 단방향 비동기식 메시지 스트림을 사용한다.\n예를 들면, 한 소비자가 특정 통화로 가격이 매겨진 상품을 구매했지만 지불은 다른 통화로 했다고 가정하자.\n마이크로서비스 접근법에서 구매 처리 코드는 특정 통화의 현재 환율을 얻기 위해 환율 서비스나 데이터베이스에 질의한다.\n데이터플로 접근법에서 구매 처리코드는 미리 환율 갱신 스트림을 구독하고 환율이 바뀔 때마다 로컬 데이터베이스에 환율을 기록한다. 구매 처리가 들어올 때 단지 로컬 데이터베이스에 질의하면 된다.\n상태 변경을 클라이언트에 푸시하기\n웹 브라우저에 일반적인 웹 페이지 하나가 로드된 후 서버에서 데이터가 변경된다면 페이지가 새로 로드될 때까지 브라우저는 해당 변경 사항을 알 수 없다. 따라서 명시적으로 변경 사항을 폴링하지 않으면 장치의 상태는 갱신되지 않는 신선도가 떨어지는 캐시다.\n많은 최신 프로토콜이 HTTP의 기본적인 요청/응답 패턴을 벗어나고 있다. 웹브라우저가 서버와 TCP 접속을 유지하면서 연결이 유지되는 동안 서버가 주도적으로 메시지를 브라우저에 보내는 방식의 통신 채널을 제공한다. (예를 들면 서버 알림)\n장치가 얼마 동안 오프라인이라서 그 시간 동안 서버에서 상태 변경 알림을 받지 못할 수 있다. 그러나 이 문제는 '소비자 오프셋'을 통해 이미 해결할 수 있다. 각 장치는 작은 이벤트 스트림을 구독하는 작은 구독자다.\n그럼 왜 모든 애플리케이션을 이런 방식으로 구축하지 않을까? 문제는 상태 비저장 클라이언트와 요청/응답 방식의 상호작용이 데이터베이스, 라이브러리, 프레임워크, 프로토콜에 뿌리 깊게 배어 있기 때문이다. 쓰기 경로를 최종 사용자까지 확장하려면 근본적으로 시스템을 구축하는 방식을 재고할 필요가 있다. 즉 요청/응답 상호작용 방식에서 발행/구독 데이터플로 방식으로 변경해야한다는 의미다. 좀 더 반응성 있는 사용자 인터페이스를 지원하고 더 나은 오프라인 지원을 하기 위해 들이는 노력이 가치 있다고 생각한다. 데이터 시스템을 설계한다면 변경 사항을 구독하는 방식을 염두에 둬야 한다고 생각한다.\n참고\n데이터 중심 애플리케이션 설계 12장\n텀블링 윈도우란\nhttps://www.cidrdb.org/cidr2013/Papers/CIDR13_Paper111.pdf\n###",
        "guid": "https://velog.io/@ahngj96/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%98-%EB%AF%B8%EB%9E%98",
        "isoDate": "2025-12-07T06:56:06.000Z"
      }
    ]
  },
  {
    "name": "손현호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "STARTUP BIBLE",
    "category": "개인",
    "posts": [
      {
        "creator": "Kihong Bae",
        "title": "종이, 펜, 그리고 손 필기",
        "link": "https://www.thestartupbible.com/2025/12/paper-pen-and-handwriting.html",
        "pubDate": "Sun, 07 Dec 2025 21:35:00 +0000",
        "content:encodedSnippet": "어느 날 사무실에서 새로운 창업가와 첫 미팅을 하는 도중, 미팅 룸을 둘러보면서 다른 팀 동료분들을 봤다. 모두 다 귀는 창업가의 발표를 들으면서, 눈은 대형 화면의 발표 자료, 창업가의 얼굴, 그리고 각자의 노트북 모니터를 왔다 갔다 하고 있었고, 손가락으로 열심히 미팅 노트를 적고 있었다. 어떤 분들은 AI 노트 테이킹 앱으로 대화 내용을 녹음하면서 요약하고 있었다.\n그런데 더 자세히 보면, 딴짓하는 분들도 내 눈에 띄었다. 각자의 노트북 화면을 내가 볼 순 없었지만, 분명히 다른 이메일 답장을 하거나, 슬랙을 하거나, 또는 그날 저녁 친구들과의 모임에서 어떤 음식을 먹을지에 대해서 단톡방에서 개인적인 대화하는 걸 느낄 수 있었다. 물론, 딴짓하는 걸 창업가에게 최대한 들키지 않게 열심히 연기를 하고 있었지만, 그 누가 봐도 미팅 도중에 그 미팅 내용과는 다른 일을 하고 있다는 걸 알 수 있었다. 내가 그걸 느낄 수 있다면, 우리의 건너편에서 우리를 보면서 열심히 사업 내용을 설명하는 창업가는 이걸 100% 알아차렸을 것이다.\n나는 미팅할 때, 아예 노트북을 지참하지 않는다. 종이와 볼펜만 미팅룸에 가져가고, 완전 옛날 방식으로 종이 위에 펜으로 내 손으로 직접 글씨를 쓴다. 내가 듣는 내용도 정리하고 요약해서 쓰고, 중간마다 그 창업가에 대해서 느낀 점들도 펜으로 다 적는다.\n내가 아직도 종이와 펜을 고집하는 데는 여러 가지 이유가 있는데, 가장 대표적인 이유 두 가지는 다음과 같다.\n일단 손으로 글씨를 쓰는 행위 자체는 그 내용을 확실하게 기억에 새기고, 또 마음에도 새기는데 가장 탁월한 암기 방법이다. 이걸 과학적으로 증명한 여러 가지 연구가 있고 논문도 있는데, 이렇게 뇌과학적으로 파고 들어가지 않아도 이 현상을 나는 손으로 글씨를 쓰면서 매일매일 몸으로 체감하고 있다. 상대방의 이야기를 귀로 듣고, 뇌로 처리하고, 손으로 쓰고, 쓰면서 다시 눈으로 보고 읽으면서 뇌로 한 번 더 정리하는 이 행위는 인간을 가장 인간답게 만드는 대단한 능력이자, AI가 아무리 발달해도 항상 지키고 개선하고 싶은 습관이다. 어쨌든 손으로 종이 위에 펜으로 필기하는 게 나에게는 가장 효과적인 미팅 노트테이킹 방법이다.\n두 번째 이유는 상대방에 대한 예의 때문이다. 나보다 내 앞의 사람이 말을 훨씬 더 많이 하는 우리가 주로 하는 창업가와의 미팅에서, 발표하는 사람의 건너편에 앉은 우리 앞에 있는, 인터넷에 연결된 노트북은 딴짓하는 걸 잘 감춰주는 최고의 도구이다.\n아마도 우리 모두 이런 경험이 있을 것이다. 내가 더 아쉽고 부탁할 게 많은 미팅인데, 미팅룸에서 다들 노트북이나 스마트폰을 들여다보는 사람들로부터 테이블의 건너편에 앉아서, 나는 정말 열과 성의를 다해 죽어라 이야기하는데, 내 건너편 사람들이 실제로 미팅 메모를 적는 건지, 아니면 쿠팡에서 쇼핑하는 건지 궁금해한 적이 있을 것이다. 펜, 종이, 그리고 필기는 나와 만나는 상대방이 제대로 주목받고 있고, 내 관심을 100% 받고 있다는 느낌을 완벽하게 줄 수 있다. 상대방이 말할 때, 나는 그들이 말하는 걸 내가 집중해서 듣고 있고, 그들이 말하는 걸 내가 요약하고 있다는 걸 확실하게 알려주고 싶고, 이걸 가장 잘 전달할 방법은 그들과 계속 아이컨택트를 하면서 펜으로 종이에 미팅 내용을 적는 것이다.\n11월 말에 나는 올해의 마지막 해외 출장을 다녀왔다. 처음 만나는 잠재 투자자와 미팅했는데, 미팅에 참석한 두 명 모두 본인들 노트북으로 딴짓하는 게 너무나 명확했던, 정말 짜증 나는 1시간이었다. 나는 열심히 준비한 내용을 거의 목이 쉴 정도로 열정적으로 샤우팅 하고 있는데, 내 앞에 있는 사람들은 내 말을 듣는 척 연기하면서, 마치 내 이야기를 노트북에 타이핑하는 척했지만, 모두 경험이 있겠지만, 이게 금방 티가 나고 들키게 된다. 솔직히, 성질 같아서는 그 노트북을 엎어버리고 딴짓하려면 꺼지라고 하고 싶었다. 물론, 아쉬운 게 나라서 그렇게 하진 않았지만. 하지만, 내가 저런 사람들에게 출자받고 앞으로 10년 동안 – 펀드의 만기가 10년이다 – 좋은 관계를 맺고 싶을지 잘 모르겠다. 그분들과 한 시간 미팅을 위해서 나는 6시간 동안 비행기를 타고 한국에서 왔고, 그걸 뻔히 알고 있는 사람들이 미팅 시간 내내 이메일 확인하고, 슬랙 보내고, 친구들과 금요일 저녁 어디서 만날까 왓츠앱 하는 걸 생각해 보면, 벌레 같은 인간들이라는 생각이 들기도 했다.\n스트롱 팀동료들도 창업가와 미팅할 때 노트북으로 노트테이킹을 하는데, 전에 내가 한 번 미팅 시간에 노트북으로 딴짓할 정도로 다른 중요한 일이 있으면, 미팅에 아예 들어오지 말라고 한 적이 있다. 이건 우리와 미팅하는 창업가들에 대해 우리가 보여줄 수 있는 최소한의 예의다. 다시 한번 반복하지만, 그냥 예의도 아니고, 최소한의 예의다. 어떤 분들은 미팅하면서 그 회사의 사업과 관련된 내용을 계속 검색하는데, 이건 그 누구에게도 도움이 안 되는 행동이고, 이런 건 미팅 전에 이미 조사해서 준비해 왔어야 하는 내용이다. 이런 식으로 미팅하게 되면, 상대방의 이야기는 전혀 머리에 안 들어오고, 서로 1시간을 낭비하게 되고, 그 창업가는 내가 위에서 느꼈던 것처럼 우리를 벌레 같은 VC라고 생각할 것이다. \n우리는 AI가 노트테이킹을 다 해주고, 다 요약해 주고, 그다음에 뭐를 할지까지 알려주는 좋은 세상에 살고 있지만, 그럴수록 내 생각을 손으로 종이에 직접 쓰는 걸 나는 강력하게 권장한다. 앞으로 이건 더욱더 중요해질 것이고, 어쩌면 펜으로 종이에 뭔가를 쓰면서 내 기억력을 글씨로 요약하는 행위는 나만의 엄청난 해자(垓字)가 될지도 모른다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2025/12/paper-pen-and-handwriting.html#respond",
        "content": "어느 날 사무실에서 새로운 창업가와 첫 미팅을 하는 도중, 미팅 룸을 둘러보면서 다른 팀 동료분들을 봤다. 모두 다 귀는 창업가의 발표를 들으면서, 눈은 대형 화면의 발표 자료, 창업가의 얼굴, 그리고 각자의 노트북 모니터를 왔다 갔다 하고 있었고, 손가락으로 열심히 미팅 노트를 적고 있었다. 어떤 분들은 AI 노트 테이킹 앱으로 대화 내용을 녹음하면서 요약하고 있었다. 그런데(...)",
        "contentSnippet": "어느 날 사무실에서 새로운 창업가와 첫 미팅을 하는 도중, 미팅 룸을 둘러보면서 다른 팀 동료분들을 봤다. 모두 다 귀는 창업가의 발표를 들으면서, 눈은 대형 화면의 발표 자료, 창업가의 얼굴, 그리고 각자의 노트북 모니터를 왔다 갔다 하고 있었고, 손가락으로 열심히 미팅 노트를 적고 있었다. 어떤 분들은 AI 노트 테이킹 앱으로 대화 내용을 녹음하면서 요약하고 있었다. 그런데(...)",
        "guid": "https://www.thestartupbible.com/?p=9637",
        "categories": [
          "Uncategorized",
          "ai",
          "FoundersAtWork",
          "general",
          "Strong",
          "technology"
        ],
        "isoDate": "2025-12-07T21:35:00.000Z"
      },
      {
        "creator": "Kihong Bae",
        "title": "사람, 영원히 안 변하는 자산",
        "link": "https://www.thestartupbible.com/2025/12/investing-in-people-is-the-most-derisked-investment.html",
        "pubDate": "Wed, 03 Dec 2025 21:29:00 +0000",
        "content:encodedSnippet": "내가 2012년에 스트롱의 첫 번째 펀드를 만들 때는 VC 사업에 대해서 정말 아무것도 몰랐다. 어떻게 돈을 모으고, 어떤 방식으로 펀드가 작동하는지, 그리고 남에게 받은 돈을 어떻게 운영해야 하는지 감이 전혀 없었다. 그냥 딱 한 가지 자신 있었던 건, 남들이 잘 못 알아보고, 잘 안 알아보는 똑똑한 창업가를 그 누구보다 먼저 알아보고 이들에게 투자할 수 있는 능력이었다. 하지만, 이렇게 똑똑한 사람을 알아보고 투자하기 위해서는 기본적으로 돈이 필요했는데, 그땐 나에게 없었던 게 바로 돈이었다.\n누구한테 돈을 달라고 해야 할지도 몰랐다. 일단 큰 기관 투자자들은 우리같이 처음 펀드를 만드는 초짜 VC에겐 돈을 안 주고, 돈이 많은 개인들이 확률이 좀 높긴 했는데, 솔직히 내 주변에 이런 사람들도 없었다. 그래도 그냥 여기저기 기웃거리면서 돈 좀 있는 분들을 한 명씩 소개 받았다. 한 명이 거절을 하면, 이분에게 또 한 명을 소개받고, 그 사람이 거절하면 그 분에게 또 한 명을 소개받고,,,이렇게 하면서 한 명씩 꾸역꾸역 지루한 미팅을 계속했다.\n2014년도에 강북구 수유리 쪽에서 주유소를 여러 개 운영하는 현금이 많은 나이 든 분을 만난 적이 있다. 본인 입으로 현금이 10억 원 있다고 자랑했으니, 당시로는 현금이 많은 분이었다.\n이 분과의 대화는 예상외로 잘 진행됐다. “스트롱벤처스는 뭘 보고 주로 투자하나요?”라는 질문이 나오기까진. 나는 우리는 절대적으로 사람을 보고 투자하고, 시장, 제품, 수치 모두 다 중요하지만 결국엔 사람을 보고 투자한다고 했는데, 갑자기 이분이 화를 엄청나게 내면서, 그렇게 안 봤는데 젊은 사람이 왜 이렇게 어리석냐, 세상에서 가장 믿으면 안 되는 게 사람인데 사람을 보고 투자하는 그런 멍청한 투자자가 어디 있냐면서 결국 내가 꽤 공을 들였던 그 미팅은 거기서 끝났다.\n그날 밤, 우리의 사람에 투자하는 전략이 혹시 잘못된 건지 살짝 고민도 해봤지만, 결국엔 이게 우리가 가야 하는 방향이었고, 우린 13년 동안 이 기본 원칙을 더욱더 확고히 다듬었다. 그리고 지금 생각해 보면, 당시 그 주유소 사장님은 본인 사업의 공식에서 사람을 제외했기 때문에 현금을 10억 원밖에 못 번 것 같다.\n우리가 사는 이 세상은 요새 눈 돌아가고 토 나올 정도로 빠르게 변하고 있다. 내가 일하고 있는 이 분야는 AI 때문에 온 세상이 파괴되고 있다. 이 외의 온갖 기술이 새로 나오고 발전하고 있고, 이에 따라 새로운 사업이 매일 만들어지고 있다. 환율은 미친 듯이 올라갔다가 내려가고, 주식 시장은 거품이 터질 듯 말 듯 하면서 계속 활활 불타고 있다. 법과 규제 또한 이런 변화에 발맞춰서 계속 변하고 있다. 즉, 우리가 예측할 수 있는 건 아무것도 없다. 아무리 많이 분석하고, 연구하고, 조사하고, 공부해도 절대로 시장을 예측할 수 없고, 투자한 회사도 어떻게 될지 예측할 수 없다. 누가 말했는지 기억은 안 나지만, 유일하게 변하지 않는 건 변화 그 자체이다.\n하지만, 변하지 않는 게 여기 또 하나 있는데, 그게 바로 사람이다. 나는 사람은 변하지 않는다고 믿는다. 사업을 하다 보면 수많은 변수가 있고, 모든 게 변하지만, 그 사업을 시작한 사람은 잘 안 변하기 때문에 어떻게 보면 사업에 있어서 가장 리스크가 적은 게 바로 창업가이다. 그래서 우리는 13년 전에도 그랬지만, 지금도 사람한테 투자하고 있다. 모든 게 정신없이 변하는 지금 이때, 이럴 때일수록 우리는 사람을 보고 투자해야 한다고 믿는다.\n이런 전략 때문에 우리는 사업에 실패했지만, 그 실패한 사업을 하는 동안 창업가와의 경험이 좋았다면, 같은 사람에게 또 투자할 수 있다. 사업의 성공과 실패는 운이 크게 작용하고, 창업가가 컨트롤할 수 없는 여러 가지 변수가 있지만, 그 사람은 안 바뀌기 때문이다. 하지만, 사업에는 성공했지만 그 사람과의 경험이 좋지 않았다면, 같은 창업가가 새로운 사업을 시작해도 절대로 다시 투자하지 않는다. 똑같은 이유인데, 사람의 기본적인 성향은 절대로 안 바뀌기 때문이다.\n어떻게 보면 우리 같은 VC는 ‘사람’이라는 아주 독특하고 어디로 튈지 모르는 자산에 투자하고 있는데, 너무 많은 VC가 위의 주유소 사장님과 같이 사람만 빼고 다른 모든 것에 투자하고 있다. 말은 모두 다 사람에 투자한다고 하지만, 내가 봤을 때 사람에 투자하는 VC가 점점 유니콘만큼 찾기가 힘들어지고 있는 게 현실이다.\n물론, 사람이 항상 좋은 건 아니다. 이상한 사람은 항상 이상하고, 개새끼는 항상 개새끼다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2025/12/investing-in-people-is-the-most-derisked-investment.html#comments",
        "content": "내가 2012년에 스트롱의 첫 번째 펀드를 만들 때는 VC 사업에 대해서 정말 아무것도 몰랐다. 어떻게 돈을 모으고, 어떤 방식으로 펀드가 작동하는지, 그리고 남에게 받은 돈을 어떻게 운영해야 하는지 감이 전혀 없었다. 그냥 딱 한 가지 자신 있었던 건, 남들이 잘 못 알아보고, 잘 안 알아보는 똑똑한 창업가를 그 누구보다 먼저 알아보고 이들에게 투자할 수 있는(...)",
        "contentSnippet": "내가 2012년에 스트롱의 첫 번째 펀드를 만들 때는 VC 사업에 대해서 정말 아무것도 몰랐다. 어떻게 돈을 모으고, 어떤 방식으로 펀드가 작동하는지, 그리고 남에게 받은 돈을 어떻게 운영해야 하는지 감이 전혀 없었다. 그냥 딱 한 가지 자신 있었던 건, 남들이 잘 못 알아보고, 잘 안 알아보는 똑똑한 창업가를 그 누구보다 먼저 알아보고 이들에게 투자할 수 있는(...)",
        "guid": "https://www.thestartupbible.com/?p=9633",
        "categories": [
          "Uncategorized",
          "cockroach",
          "fundraising",
          "hustle",
          "people",
          "Strong",
          "vc"
        ],
        "isoDate": "2025-12-03T21:29:00.000Z"
      }
    ]
  },
  {
    "name": "매거진 입맛",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "요즘 IT",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "쿠팡 엔지니어링",
    "category": "기업",
    "posts": []
  },
  {
    "name": "지마켓 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "리멤버 (드라마 앤 컴퍼니)",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Kimchi hill",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Hudi.blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "토스",
    "category": "기업",
    "posts": [
      {
        "title": "한가을 밤의 〈더 머니이슈〉 리딩파티",
        "link": "https://toss.im/tossfeed/article/readingparty",
        "pubDate": "Tue, 09 Dec 2025 05:47:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}‘돈 관리, 혼자 잘할 수 있을까요?’, ‘지금 하는 일을 언제까지 할 수 있을까요?’ 누군가에게 속 시원히 털어놓고 싶지만, 돈과 삶에 대한 이야기를 선뜻 꺼낼 기회는 드뭅니다. \n그래서 돈을 매개로 삶의 변화를 계획하게 하는 매거진 〈더 머니이슈〉를 만든 팀원들은 창간을 알리는 첫 이벤트로 돈에 대한 고민을 터놓고 삶의 가치관까지 솔직하게 이야기할 수 있는 ‘리딩파티’를 열었어요.\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}함께 책을 읽고\n대화를 나누는 자리\n‘리딩파티’에 대해 들어본 적 있나요? .css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}리딩파티는 뉴욕에서 시작된 문화로, 한자리에 모여 책을 읽고 생각을 나누는 독서 커뮤니티예요. 책을 미리 읽고 와서 대화를 나누는 기존의 독서모임보다는 가벼워진 형태로, 같은 시간 동안 함께 책을 읽고 이야기를 나눈다는 게 매력이죠. \n매거진 담당 팀원들은 〈더 머니이슈〉 창간호 주제가 ‘1인분의 삶’이었던 만큼 같은 책을 읽고 서로의 생각을 나눈다면 매거진에 담긴 이야기가 더 깊어질 것이라 생각했어요.\n리딩파티 장소로 선택한 곳은 프릳츠 장충. ‘맛있는 빵과 훌륭한 커피는 사람을 행복하게 만든다’는 프릳츠의 철학은 ‘돈에 관한 시선이 바뀌면 삶은 변한다’고 말하는 〈더 머니이슈〉의 관점과 맞닿아 있어요. 프릳츠 장충의 아름다운 공간은 낯선 사람들과 마음 편히 대화를 나누기에 더없이 좋은 분위기였죠.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n세상에 없던 돈에 관한 매거진\n〈더 머니이슈〉\n〈더 머니이슈〉는 요즘 사람들을 위한 경제 정보지이자, 돈을 대하는 태도와 관점의 전환을 제안하는 라이프스타일 경제 매거진이에요. 매거진에는 누구나 한 번쯤 품었을 질문들이 담겨 있어요. 질문마다 실제로 무엇을 고려해야 하는지, 어디서부터 시작하면 좋은지, 어떤 선택이 내 삶과 맞닿아 있는지를 차근차근 짚어줍니다.\n‘가진 돈이 한줌이어도 자산 관리는 필요할까?’, ‘연봉 1억 원을 찍으면 정말 행복해질까?’처럼 재테크 관점을 새롭게 제안하는 콘텐츠와 ‘인플루언서를 따라 산 새 옷은 내 취향일까?’, ‘좋아하는 일로 N잡을 시작해도 괜찮을까?’처럼 일상의 선택을 돌아보게 하는 콘텐츠가 가득해요.\n돈을 향한 실용적 해법과 새로운 시선을 따라 읽다 보면, ‘돈을 어떻게 바라보고, 어떻게 쓰며, 어떻게 살아갈 것인가’에 대한 기준이 선명해집니다.\n〈더 머니이슈〉를 읽으며\n1인분의 삶을 되돌아보는 시간\n11월 19일 오후 7시. 리딩파티에 초대된 50명의 참여자가 하나둘 입장했어요. 각자 마음에 드는 자리에 앉아 음악을 들으며 〈더 머니이슈〉를 읽고, ‘1인분의 삶’을 되돌아보는 시간을 가졌습니다. \n각자의 방식으로 삶을 단단하게 일구고 있는 6인의 리딩파티 호스트는 〈더 머니이슈〉에 대해 이렇게 얘기했어요.\n.css-2sk6rv{font-size:19px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);white-space:pre-wrap;margin:24px 0;padding-left:20px;position:relative;}.css-2sk6rv::before{content:'';display:block;position:absolute;top:4px;left:0;width:2px;height:calc(100% - 4px * 2);padding:4px 0;background-color:var(--adaptiveGrey800);}\n시골쥐 (유튜브 ‘시골쥐의 도시생활’ 운영).css-7mseny>*{margin-left:0;margin-right:0;}.css-7mseny>:last-child{margin-bottom:0;}blockquote>.css-7mseny:first-child>:first-child{margin-top:0;}.css-1k9y0sc{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}.css-1k9y0sc>*{margin-left:0;margin-right:0;}.css-1k9y0sc>:last-child{margin-bottom:0;}blockquote>.css-1k9y0sc:first-child>:first-child{margin-top:0;}\n요즘 청년들이 품고 있을 고민에 대한 해결책이 〈더 머니이슈〉에 담겨 있어 도움이 많이 될 것 같아요. 특히 다른 사람들은 어떻게 살아가는지 볼 수 있어서, 내가 걷고 있는 길에 대한 새로운 시야를 제안해줄 거라고 생각해요.\n\n김민경 (민음사 해외문학팀 출판편집자)\n재테크 관련 정보뿐만 아니라 재미있는 글들이 많았고, 천선란 작가님 소설도 있어서 반갑게 읽었습니다. 저처럼 경제나 재테크를 하고는 싶지만 아직 관심이 없는 2030에게 〈더 머니이슈〉를 추천하고 싶어요.\n\n홍상지 (중앙일보 IT산업부 기자)\n우리는 누구나 1인분의 삶을 살아가잖아요. 마침 이번 〈더 머니이슈〉의 주제가 ‘1인분의 삶’인데, 이에 대한 거의 모든 것을 다루고 있는 잡지라고 느꼈어요. 돈 뿐만 아니라 삶의 관점에 대해서도 다양한 각도로 다룬다는 점도 인상 깊었어요.\n\n전명희 (큐레이션 부동산 ‘별집’ 대표)\n돈이라는 주제를 단순히 투자나 저축같은 관점에서 접근하는 데서 끝나는 게 아니라 심리나 문화, 철학 등 다차원적으로 이야기하는 점이 신선했어요. 매달 돈을 벌면서 내 삶을 어떻게 성장시킬 수 있을까 고민하는 분에게 특히 추천하고 싶어요.\n\n고윤경 (여행 전문 서점 ‘책크인’ 대표)\n자기의 삶을 단단하게 만드는 법을 이야기하는 책 같아서 재미있게 읽었어요. 1인분의 삶을 단단하게 살아가고 싶은 분들이 읽으면 좋을 것 같아요.\n\n김짠부 (유튜브 ‘김짠부’ 운영)\n제 삶의 가장 중요한 키워드 중 하나는 ‘같이’예요. 유독 돈에 있어서 그 마음이 더 필요하더라고요. 그래서 누군가 나처럼 돈을 고민하고 있다는 사실만으로도 힘이 되는데, 〈더 머니이슈〉는 그런 사람들의 이야기가 한자리에 모여 있는 일종의 재테크 놀이동산 같아요. 만약 누군가에게 ‘재테크를 함께 이야기할 친구’가 필요하다면 이 책을 건네줄 거예요.\n\n.css-1lvcgm8{padding:22px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;border-radius:20px;}\n.css-13ko30i{width:375px;}〈더 머니이슈〉 살펴보기\n\n호스트와 함께\n생각을 나누는 시간\n김짠부의 ‘자산 관리 트렌드와 N잡’, 김민경의 ‘혼자를 기르는 법’, 홍상지의 ‘슬기로운 취향 소비 노하우’, 전명희의 ‘나에게 좋은 집 찾는 법’, 시골쥐의 ‘1억 원 모은 뒤 삶의 변화’, 고윤경의 ‘혼자 떠나는 여행’. 리딩파티 2부에서는 여섯 그룹으로 나뉘어 호스트와 함께 〈더 머니이슈〉에 나온 아티클을 중심으로 다양한 주제의 대화를 나눴어요.\n호스트와 참여자들은 혼자 안고 있던 돈 걱정을 털어놓고, 미래에 대한 불안을 나누고, 나만의 소비 취향을 자랑하며 서로의 이야기를 듣고 함께 고민했어요. 테이블마다 흥미로운 대화가 이어졌고, 어느덧 1시간이 훌쩍 지나 리딩파티는 막을 내렸습니다. 현장에서 느꼈던 다정한 분위기가 고스란히 담긴 참여자 분들의 생생한 후기를 소개할게요.\n.css-nv7vyi{margin:24px 0 8px;padding:16px 40px 32px;border-radius:16px;background-color:var(--adaptiveGrey100);}.css-123co55{font-size:19px;letter-spacing:0em;line-height:1.6;margin:24px 0 0;font-weight:400;color:var(--adaptiveGrey900);background-color:transparent;}\n“저와 비슷한 분들과 생산적인 이야기를 나눌 수 있어서 좋았어요. 돈에 관심 있는 분들과 모이기가 쉽지 않은데 기회를 가질 수 있었던 것도 너무 좋았어요”\n\n“‘돈’ 이야기만 할 줄 알았는데 의외로 말랑말랑한, 살아가는 ‘삶’에 대한 이야기들이 오갔다. 내향인에게 이런 자리는 참 소중하다. 다정한 시선을 가진 사람들과 다정한 장소에서 다정한 이야기를 나누는 소중한 시간이었다. 집으로 돌아가는 길 코끝은 시렸지만 마음만은 따뜻했다”\n\n“신개념 출간회, 토스의 리딩파티! 처음 만난 사람들과 돈 얘기를 이렇게 솔직하게 나눌 수 있다는 게 너무 재밌고 도파민 터져버림. 돈이 가진 다양한 모양들 그리고 감정들.. 이런 시간이 더더더 많았으면 좋겠다.”\n\n“분야가 정말 다양한 필진들이 돈에 대해 이야기하는 흥미로운 책. 책뿐만 아니라 각종 굿즈까지 가득 안겨받은 선물 같았다. 프릳츠 빵과 커피를 즐기면서 호젓한 리딩파티. 결이 맞는 다정한 사람들과의 흥미로운 대화. 에너지를 가득 얻은 수요일 밤이었다.”\n\n‘머니이슈’라는 이름은 돈에 관한 매거진을 뜻하는 동시에 ‘돈에 관한 문제는 언제나 삶의 문제’라는 뜻을 품고 있어요. 돈은 늘 삶의 한가운데 있지만, 돈과 나의 관계 설정은 미숙해서 돈은 불안의 시작점이 되기도, 자유의 수단이 되기도 하잖아요. 〈더 머니이슈〉는 그 경계에서 흔들리는 우리를 위해 시작됐어요.\n이번 리딩파티에는 함께 하지 못했지만, 돈과 삶에 대한 문제를 고민하며 더 잘 살아갈 방법을 찾고 있다면 〈더 머니이슈〉를 읽어보세요. ‘머니 앤 라이프 밸런스’를 단단하게 잡아주는 데 도움이 될 거예요.\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 윤동해 Photo 이욱영",
        "content": "함께 읽고 대화하며 찾는 돈과 삶의 밸런스",
        "contentSnippet": "함께 읽고 대화하며 찾는 돈과 삶의 밸런스",
        "guid": "https://toss.im/tossfeed/article/readingparty",
        "isoDate": "2025-12-09T05:47:00.000Z"
      },
      {
        "title": "조선시대에는 사교육비로 얼마를 썼을까?",
        "link": "https://toss.im/tossfeed/article/behindthemoney-14",
        "pubDate": "Mon, 08 Dec 2025 00:30:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}4살 아이들이 시험을 치르는 세상이다. 초등 영어학원 입학시험인 이른바 ‘7세 고시’를 넘어 영어유치원 입학 레벨테스트인 ‘4세 고시’까지 등장했다고 한다. 사교육 시장은 더 빠르고 더 크게 팽창하고 있다.\n2024년 기준 사교육비는 29조 원으로 해마다 5~7%씩 늘어나고 있다. 30조에 육박하는 돈이 움직이는 이 시장은, 교육부 2025년 전체 예산의 3분의 1에 달한다. 1인당 사교육비를 보면 더 적나라하다. 학생 수는 1년 사이 8만 명(1.5%) 줄었지만, 1인당 월평균 사교육비는 47만 4천 원으로 오히려 10% 가까이 증가했다.*\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}*'2024년 초중고 사교육비 조사’ 교육부, 통계청\n입시 이야기가 나오면 부모들은 걱정이 앞선다. 명문대 중심의 서열 구조, ‘고학력=고소득’이라는 오래된 공식, 줄지 않는 사교육비, 자주 바뀌는 교육 정책 등. 무엇이 문제인지 말하기 시작하면 끝이 없다. 경쟁은 다음 해에도, 그다음 해에도 끊임없이 반복된다. 하지만 이 ‘끝없는 경쟁’의 풍경은 사실 오늘의 이야기만이 아니다.\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}조선시대 14년 N수생,\n논밭까지 다 팔아버린 과거시험 생존기\n조선 후기, 무관 ‘노상추(盧尙樞, 1746～1829)’의 일기에는 이런 내용이 있다. “.css-1odxvuk{white-space:pre-wrap;font-style:italic;}내 5백여 냥은 모두 과거에 들어갔으니 앞으로 굶어 죽는 것을 면하기 어려운 것인가. 공명(功名)이라는 것이 참으로 가소롭다.” (1872.5.7) 과열된 입시 구조는 조선 시대에도 비슷했다. .css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}노상추는 무과에 급제하기까지 꼬박 10년이 걸렸고, 합격 후 관직에 올라 정식으로 녹봉을 받는 데까지 다시 4년을 더 기다려야 했다. 무려 14년을 꼬박 무관이 되기 위해 노력했고, 그 기간 동안 별다른 수입 없이 부모에게서 물려받는 재산을 써가며 생활해야 했다.\n노상추가 상속으로 받은 재산은 ‘논 한 섬 아홉 마지기와 밭 아흔여 마지기’였지만, 과채(科債), 즉 과거시험을 보고 나서 남은 것은 ‘대지(垈地) 다섯 마지기와 박답(薄畓) 여덟 마지기’였다. 어림 계산해보면 과거시험 비용으로 상속의 절반을 썼는데 남아있는 것이 대지, 즉 집터와 박답, 기름지지 못한 논이었다. 이를 현찰로 환산하면 5백여 냥. 무관이 되어 얻게 되는 명예로움이라는 것이 무엇이길래 굶어 죽을 것을 염려해야 한다는 말인가.\n노상추는 경상도 선산에서 태어나 그 인근에서 평생을 살았다. 전형적인 영남 유생이었고, 문신을 여럿 배출한 나름의 명문가였다. 그 역시 처음에는 문과를 꿈꿨지만 무과로 방향을 틀었는데, 여기에는 나름의 전략과 계획이 있었던 것으로 보인다. 문관이 무관보다 명예롭고 대우도 높았지만 그만큼 경쟁이 심했다. 조선 후기에는 무관의 사회적 지위도 나아졌고, 무엇보다 문과에 비해 훨씬 많은 인원을 뽑았기 때문에 합격 가능성이 문관보다 높았다.\n여기에 경제적 계산도 있었다. 경상도 선산에서 한양까지는 약 380km. 걸어서 부지런히 이동한다고 해도 약 보름이 걸리는 거리였다. 그만큼 만만치 않은 비용이 들 터였다. 과거시험에 최종 합격하려면 여러번 시험을 보아야 한다. 그렇다면 체류비와 여비도 고려해야 하는데 역시 문과보다는 무과가 상대적으로 ‘손해가 덜 나는’ 선택이었다. 노상추는 나름의 계산을 통해 시험에 도전했지만, 조선의 시험 운영은 그의 예측을 번번이 뒤엎었다.\n노상추는 23살부터 본격적으로 무과 시험을 준비했다. 26살에 처음으로 한양에 올라갔지만, 영조와 사도세자의 갈등이 극에 달하던 시기라 시험은 갑작스레 취소되었다. 31살에 다시 상경했지만, 정월에 치르기로 했던 시험은 두 달이나 미뤄졌고, 그마저도 영조가 승하하면서 또다시 취소되었다. 조선의 경우 3년에 한 번씩 ‘식년시’라는 이름으로 정기시험을 보았지만, ‘별시’라는 이름의 특별시험이 자주 있었고, 왕실의 사정에 따라 갑자기 시험이 취소되는 등 과거제도 운영에 미숙한 면이 있었다. 그렇기 때문에 먼 지방에 사는 유생들은 대단히 불리했고, 한양으로 올라오는 여비와 체류하는 비용 등 돈도 많이 들었다.\n그럼에도 노상추는 물러서지 않았다. 1777년, 1778년 두 번의 시험에서 고배를 마셨지만 포기하지 않은 노상추는 1779년 드디어 지역 시험을 통과해 1980년 35살의 나이로 비로소 무과 시험에 합격한다. 그는 마지막 시험을 위해 한 달 동안 한양에 머물러야 했는데, 이때 생활비를 마련하기 위해 친척에게 밭 열두 마지기를 팔았다.\n노상추가 과거에 합격하기 위해 쓴 돈은 몇 가지로 분류할 수 있다. 첫째, 과거 공부를 하기 위해 쓴 돈. 둘째, 과거 공부 기간 동안의 생활비. 셋째, 한양 체류비. 넷째, 이동 중에 들어간 품삯 및 노비 대동 비용 등이 그것이다. 공부를 하려면 책을 사야하고 서당부터 서원까지 스승님을 모셔야 한다. 요즘으로 따지면 교재비와 학원비에 해당하는 돈이다. 무엇보다 먹고 살아야 하지만 과거 시험은 오랜 기간 공부에만 집중해야 하기 때문에 모아놓은 재산으로 버티는 수밖에 없다. 집안이 대지주라면 별 문제가 없지만 어지간한 중소지주의 경우 땅을 팔아가면서 생활비를 마련해야 했다. \n한양에 머물기 위해서는 집을 빌려야 했고, 식사를 하기 위해 주막 등을 이용하는 등 모든 것이 돈! 돈! 돈이었다. 더구나 조선 후기에는 한양에 인구가 집중되면서 집값이 크게 올랐고 물가도 매우 높았으니 요즘 대학생들의 하숙비처럼 부담되었을 것이다. 노상추의 경우 무려 14년간 과거시험을 준비해야했고 이 기간 동안 노상추는 가족을 부양해야 했다.\n왜 우리는 시험에 매달리는가\n과거 시험에 모든 것을 쏟아붓던 조선 시대의 풍경은 지금 상상해도 놀랍다. 정약용은 《경세유표》에서 당시 향시(鄕試)의 실태를 이렇게 비판했다. “부잣집 자식은 입에 아직 비린내가 나고 정(丁)자도 모르면서 거벽(巨擘)의 글을 빌리고, 사수(寫手)의 글씨를 빌려 시권을 바친다. 향시(鄕試)가 이 모양이니 경시(京試)도 다르지 않을 것이다. 회시에서는 사람을 사서 대신 들여보내어 짓고 쓰며, 위조하고, 세력 있는 자와 통한다.”\n거벽은 문장에 능한 사람, 사수는 글씨에 능한 사람을 뜻한다. 향시는 고향에서 보는 1차 시험, 회시는 서울에서 보는 2차 시험, 경시는 서울에서 보는 시험이기 때문에 별시나 전시를 이야기한 듯 하다. 과거를 합격하려면 최소 3번을 합격해야 하는데, 그중 2번의 시험을 서울에서 치렀다.\n정약용의 글을 따라 상상해 보시라. 아무것도 모르는 귀한 집 자식이 앉아 있고, 그 옆에서 거벽이 문제를 분석해 “이렇게 쓰시오.” 하면, 한문을 잘 쓰는 사수가 좋은 필체로 내용을 적어주는 풍경을 말이다. 과거 시험장에도 당연히 감독관이 있었지만 명문가 도련님이 왔기 때문에 ‘불법을 막아야 하는 금란관은 머리를 감싸고 숨을 곳을 찾았다’라고 정약용은 고발하고 있다.\n조선 후기 입시 경쟁은 시간이 갈수록 격화되었다. 15세기 소과시험*합격자의 평균 연령은 25세. 하지만 19세기 후반이 되면 37세로 오른다. 문과 최종 합격자의 경우 조선시대 평균이 36세인데, 18세기 후반이 되면 40세에 이르렀다. 응시자 수 역시 폭발적으로 증가했다. 세종 때 1,000여 명이던 한성시** 응시자는 선조 때 2,000명, 인조 때 4,000명, 1707년 숙종 33년에는 무려 11,000명까지 늘었다. 세도정치기 때는 평균 5~6만 명, 고종 때는 무려 11만 명이 되었다. 물론 500년간의 이야기이고 인구성장, 합격 인원의 증가 등 변동 요소를 고려해야겠지만 그럼에도 불구하고 전반적으로 과거시험은 지나치게 비대해지고 있었다.\n*향시, 고향에서 보는 1차 시험\n**한성에서 치루던 문과·무과·생원진사시의 1차 시험\n상황이 이러니 기이한 기록도 등장한다. 영조 때 이요팔은 81세, 신수채는 84세에 과거에 합격했다. 개인과 가문에는 경사였을지 모르지만, 이들은 사실상 평생을 과거시험에 매달렸으며, 합격의 영예를 누리긴 했지만 실질적인 관직을 얻지는 못했다. 조선 후기가 되면 3대가 함께 과거시험 공부를 했다는 이야기도 거짓이 아니었다.\n경쟁이 심해지자 온갖 부정이 횡행했고, 황당한 사건도 벌어졌다. 조선 후기 학자 이옥은 《유광억전》을 남겼는데, 여기에는 ‘영남 제일의 인재’라 불리던 사람이 대필 시험으로 생계를 이어가다 결국 들켜 자결했다는 내용이 실려 있다. 부정행위가 발각되어, 흔히 곤장으로 알고 있는 장형을 받는 사례도 부지기수였다. 시험에 목숨을 걸고, 부정에 손을 대고, 들키면 또 목숨을 내놓아야 하는 시대였다.\n왜 조선 시대 사람들은 이렇게까지 과거시험에 매달렸을까. 양반 중심 사회에서 과거 합격만이 신분 상승의 거의 유일한 통로였기 때문이다. 14년간 무과 시험에 도전한 노상추 역시 마찬가지. 무관이 된다는 것은 양반 중심의 조선 사회에서 분명 명예로운 일이었다. 그러나 그 명예를 얻기 위해 노상추가 감내한 비용은 삶을 위협할 만큼 컸다. 시험 운영의 미숙함, 지방 유생의 불리함, 수차례의 취소와 연기 속에서 그는 오로지 ‘신분 상승’이라는 목표 하나만 의지해 버텼다. 그리고 그의 14년은 오늘날의 과열된 입시 구조를 자연스럽게 떠올리게 한다.\n경제가 성장하고 인구가 증가함에도 불구하고 그에 준하는 각종 사회 발전이 이루어지지 못한 것이 조선 후기였으니 오늘날에 비한다면 국민의 80%가 대학에 입학함에도 불구하고 여전히 대학 서열은 강고하고 하지만 대학을 졸업해도 딱히 성공을 보장받지 못하는 모습과 매우 유사하다.\n얼마 전 또 한 번의 수능이 끝났다. 결과가 어떻게 나오든, 그 사이에서 누군가는 자부심을, 또 누군가는 아쉬움을 느낄 것이다. 그러나 그 감정은 그 자체로 충분히 자연스럽고, 모두 각자의 자리에서 최선을 다했다는 증거다. 조선 시대 노상추의 일기장에 적힌 문구는 긴 세월이 흘렀음에도 우리가 같은 질문 앞에 서 있음을 보여주지만, 또다른 사실도 말해준다. 시험은 인생의 전부가 아니며, 공명은 시험이 아니라 살아가는 과정 속에서 만들어진다는 것이다. 힘을 내자. 그리고 아픔을 경험삼아 우리의 자녀들을 위하여 좀 더 나은 세상을 만들어 보자.\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 이지영 Graphic 이은호",
        "content": "조선시대 N수생, 논밭까지 다 팔아버린 과거시험 생존기",
        "contentSnippet": "조선시대 N수생, 논밭까지 다 팔아버린 과거시험 생존기",
        "guid": "https://toss.im/tossfeed/article/behindthemoney-14",
        "isoDate": "2025-12-08T00:30:00.000Z"
      }
    ]
  },
  {
    "name": "모나미",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김진홍",
    "category": "개인",
    "posts": []
  }
]