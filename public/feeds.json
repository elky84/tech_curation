[
  {
    "name": "ㅍㅍㅅㅅ",
    "category": "큐레이팅",
    "posts": []
  },
  {
    "name": "C++ Team Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Facebook Engineering",
    "category": "기업",
    "posts": [
      {
        "creator": "",
        "title": "Taming the tail utilization of ads inference at Meta scale",
        "link": "https://engineering.fb.com/2024/07/10/production-engineering/tail-utilization-ads-inference-meta/",
        "pubDate": "Wed, 10 Jul 2024 20:30:26 +0000",
        "content:encodedSnippet": "Tail utilization is a significant system issue and a major factor in overload-related failures and low compute utilization.\nThe tail utilization optimizations at Meta have had a profound impact on model serving capacity footprint and reliability. \nFailure rates, which are mostly timeout errors, were reduced by two-thirds; the compute footprint delivered 35% more work for the same amount of resources; and p99 latency was cut in half.\nThe inference platforms that serve the sophisticated machine learning models used by Meta’s ads delivery system require significant infrastructure capacity across CPUs, GPUs, storage, networking, and databases. Improving tail utilization – the utilization level of the top 5% of the servers when ranked by utilization– within our infrastructure is imperative to operate our fleet efficiently and sustainably.\nWith the growing complexity and computational intensity of these models, as well as the strict latency and throughput requirements to deliver ads, we’ve implemented system optimizations and best practices to address tail utilization. The solutions we’ve implemented for our ads inference service have positively impacted compute utilization in our ads fleet in several ways, including increasing work output by 35 percent without additional resources, decreasing timeout error rates by two-thirds, and reducing tail latency at p99 by half.\nHow Meta’s ads model inference service works \nWhen placing an ad, client requests are routed to the inference service to get predictions. A single request from a client typically results in multiple model inferences being requested, depending on experiment setup, page type, and ad attributes. This is shown below in figure 1 as a request from the ads core services to the model inference service. The actual request flow is more complex but for the purpose of this post, the below schematic model should serve well.\nThe inference service leverages Meta infrastructure capabilities such as ServiceRouter for service discovery, load balancing, and other reliability features. The service is set up as a sharded service where each model is a shard and multiple models are hosted in a single host of a job that spans multiple hosts.\nThis is supported by Meta’s sharding service, Shard Manager, a universal infrastructure solution that facilitates efficient development and operation of reliable sharded applications. Meta’s advertising team leverages Shard Manager’sload balancing and shard scaling capabilities to effectively handle shards across heterogeneous hardware.\nFigure 1: The ads inference architecture.\nChallenges of load balancing\nThere are two approaches to load balancing: \nRouting load balancing – load balancing across replicas of a single model. We use ServiceRouter to enable routing based load balancing. \nPlacement load balancing – balancing load on hosts by moving replicas of a model across hosts.\nFundamental concepts like replica estimation, snapshot transition and multi-service deployments are key aspects of model productionisation that make load balancing in this environment a complex problem.\nReplica estimation\nWhen a new version of the model enters the system, the number of replicas needed for the new model version is estimated based on historical data of the replica usage of the model.\nSnapshot transition\nAds models are continuously updated to improve their performance. The ads inference system then transitions traffic from the older model to the new version. Updated and refreshed models get a new snapshot ID. Snapshot transition is the mechanism by which the refreshed model replaces the current model serving production traffic.\nMulti-service deployment\nModels are deployed to multiple service tiers to take advantage of hardware heterogeneity and elastic capacity.\nWhy is tail utilization a problem?\nTail utilization is a problem because as the number of requests increases, servers that contribute to high tail utilization become overloaded and fail, ultimately affecting our service level agreements (SLAs). Consequently, the extra headroom or buffer needed to handle increased traffic is directly determined by the tail utilization. \nThis is challenging because it leads to overallocation of capacity for the service. If demand increases, capacity headroom is necessary in constrained servers to maintain service levels when accommodating new demand. Since capacity is uniformly added to all servers in a cluster, generating headroom in constrained servers involves adding significantly more capacity than required for headroom.\nIn addition, tail utilization for most constrained servers grows faster than lower percentile utilization due to the non linear relationship between traffic increase and utilization. This is the reason why more capacity is needed even while the system is under utilized on average.\nMaking the utilization distribution tighter across the fleet unlocks capacity within servers running at low utilization, i.e. the fleet can support more requests and model launches while maintaining SLAs.\nFigure 2: Divergence in the tail utilization distribution across percentile ranges.\nHow we optimized tail utilization \nThe implemented solution comprises a class of technical optimizations that attempt to balance the objectives of improving utilization and reducing error rate and latency.\nThe improvements made the utilization distribution tighter. This created the ability to move work from crunched servers to low utilization servers and absorb increased demand. As a result, the system has been able to absorb up to 35% load increase with no additional capacity.\nFigure 3: Convergence of tail utilization distribution across percentiles.\nThe reliability also improved, reducing the timeout error rate by two-thirds and cutting latency by half.\nFigure 4: System reliability over time.\nThe solution involved two approaches: \nTuning load balancing mechanisms\nMaking system level changes in model productionisation. \nThe first approach is well understood in the industry. The second one required significant trial, testing, and nuanced execution.\nTuning load balancing mechanisms\nThe power of two choices\nThe service mesh, ServiceRouter, provides detailed instrumentation that allows a better understanding of the load balancing characteristics. Specifically relevant to tail utilization is suboptimal load balancing because of load staleness. To address this we leveraged the power of two choices in a randomized load balancing mechanism. This algorithm requires load data from the servers. This telemetry is collected either by polling – query server load before request dispatch; or by load-header –  piggyback on response. \nPolling provides fresh load, while it adds an additional hop, but on the other side, load-header results in reading stale load. Load staleness is a significant issue for large services with substantial clients. Any error here due to staleness would result in random load balancing. For polling, given the inference request is computationally expensive, the overhead was found to be negligible. Using polling improved tail utilization noticeably because heavily loaded hosts were actively avoided. This approach worked very well specifically for inference requests greater than 10s of milliseconds.\nServiceRouter provides various tuning load-balancing capabilities. We tested many of these techniques, including the number of choices for server selection (i.e., power of k instead of 2), backup request configuration, and hardware-specific routing weights. \nThese changes offered marginal improvements. CPU utilization as load-counter was especially insightful. While it is intuitive to balance based on CPU utilization, it turned out to be not useful because: CPU utilization is aggregated over some period of time versus the need for instant load information in this case; and outstanding active tasks waiting on I/O were not taken into account correctly.\nPlacement load balancing\nPlacement load balancing helped a lot. Given the diversity in model resource demand characteristics and machine resource supply, there is significant variance in server utilization. There is an opportunity to make the utilization distribution tighter by tuning the Shard Manager load balancing configurations, such as load bands, thresholds, and balancing frequency. The basic tuning above helped and provided big gains. It also exposed a deeper problem like spiky tail utilization, which was hidden behind the high tail utilization and was fixed once identified .\nSystem level changes\nThere wasn’t a single significant cause for the utilization variance and several intriguing issues emerged among them that offered valuable insights into the system characteristics. \nMemory bandwidth\nCPU spikes were observed when new replicas, placed on hosts already hosting other models, began serving traffic. Ideally, this should not happen because Shard Manager should only place a replica when the resource requirements are met. Upon examining the spike pattern, the team discovered that the stall cycles were increasing significantly. Using dynolog perf instrumentations, we determined that memory latency was increasing as well, which aligned with memory latency benchmarks.\nMemory latency starts to increase exponentially at around 65-70% utilization. It appears to be an increase in CPU utilization, but the actual issue was that the CPU was stalling. The solution involved considering memory bandwidth as a resource during replica placement in Shard Manager. \nServiceRouter and Shard Manager expectation mismatch\nThere is a service control plane component called ReplicaEstimator that performs replica count estimation for a model. When ReplicaEstimator performs this estimation, the expectation is that each replica roughly receives the same amount of traffic. Shard Manager also works under this assumption that replicas of the same model will roughly be equal in their resource usage on a host. Shard Manager load balancing also assumes this property. There are also cases where Shard Manager uses load information from other replicas if load fetch fails. So ReplicaEstimator and Shard Manager share the same expectation that each replica will end up doing roughly the same amount of work.\nServiceRouter employs the default load counter, which encompasses both active and queued outstanding requests on a host. In general, this works fine when there is only one replica per host and they are expected to receive the same amount of load. However, this assumption is broken due to multi-tenancy, resulting in each host potentially having different models and outstanding requests on a host cannot be used to compare load as it can vary greatly. For example, two hosts serving the same model could have completely different load metrics leading to significant CPU imbalance issues.\nThe imbalance of replica load created because of the host level consolidated load counter violates Shard Manager and ReplicaEstimator expectations. A simple and elegant solution to this problem is a per-model load counter. If each model were to expose a load counter based on its own load on the server, ServiceRouter will end up balancing load across model replicas, and Shard Manger will end up more accurately balancing hosts. Replica estimation also ends up being more accurate. All expectations are aligned. \nSupport for this was added to the prediction client by explicitly setting the load counter per model client and exposing appropriate per model load metric on the server side. The model replica load distribution as expected became much tighter with a per-model load counter and helps with the problems discussed above.\nBut this also presented some challenges. Enabling per-model load counter changes the load distribution instantaneously, causing spikes until Shard Manager catches up and rebalances. The team built a mechanism to make the transition smooth by gradually rolling out the load counter change to the client. Then there are models with low load that end up having per-model load counter values of ‘0’, making it essentially random. In the default load counter configuration, such models end up using the host level load as a good proxy to decide which server to send the request to.\n“Outstanding examples CPU” was the most promising load counter among many that were tested. It is the estimated total CPU time spent on active requests, and better represents the cost of outstanding work. The counter is normalized by the number of cores to account for machine heterogeneity.\nFigure 5: Throughput as measured by requests per second across hosts in a tier.\nSnapshot transition\nSome ads models are retrained more frequently than others. Discounting real-time updated models, the majority of the models involve transitioning traffic from a previous model snapshot to the new model snapshot. Snapshot transition is a major disruption to a balanced system, especially when the transitioning models have a large number of replicas.\nDuring peak traffic, snapshot transition can have a significant impact on utilization. Figure 6 below illustrates the issue. The snapshot transition of large models during a crunched time causes utilization to be very unbalanced until Shard Manager is able to bring it back in balance. This takes a few load balancing runs because the placement of the new model during peak traffic ends up violating CPU soft thresholds. The problem of load counters, as discussed earlier, further complicates Shard Manager’s ability to resolve issues.\nFigure 6: A utilization spike due to the snapshot transition.\nTo mitigate this issue, the team added the snapshot transition budget capability. This allows for snapshot transitions to occur only when resource utilization is below a configured threshold. The trade-off here is between snapshot staleness and failure rate. Fast scale down of old snapshots helped minimize the overhead of snapshot staleness while maintaining lower failure rates.\nCross-service load balancing\nAfter optimizing load balancing within a single service, the next step was to extend this to multiple services. Each regional model inference service is made up of multiple sub-services depending on hardware type and capacity pools – guaranteed and elastic pools. We changed the calculation to the compute capacity of the hosts instead of the host number. This helped with a more balanced load across tiers. \nCertain hardware types are more loaded than others. Given that clients maintain separate connections to these tiers, ServiceRouter load balancing, which performs balancing within tiers, did not help. Given the production setup, it was non-trivial to put all these tiers behind a single parent tier. Therefore, the team added a small utilization balancing feedback controller to adjust traffic routing percentages and achieve balance between these tiers. Figure 7 shows  an example of this being rolled out.\nFigure 7: Request per service.\nReplica estimation and predictive scaling \nShard Manager employs a reactive approach to load by scaling up replicas in response to a load increase. This meant increased error rates during the time replicas were scaled up and became ready. This is exacerbated by the fact that replicas with higher utilization are more prone to utilization spikes given the non-linear relationship between queries per second (QPS) and utilization. To add to this, when auto-scaling kicks in, it responds to a much larger CPU requirement and results in over-replication. We designed a simple predictive replica estimation system for the models that predicts future resource usage based on current and past usage patterns up to two hours in advance. This approach yielded significant improvements in failure rate during peak periods. \nNext steps \nThe next step in our journey is to adopt our learnings around tail utilization to new system architectures and platforms. For example, we’re actively working to apply the utilizations discussed here to IPnext, Meta’s next-generation unified platform for managing the entire lifecycle of machine learning model deployments, from publishing to serving. IPnext’s modular design enables us to support various model architectures (e.g., for ranking or GenAI applications) through a single platform spanning multiple data center regions. Optimizing tail utilization within IPnext thereby delivering these benefits to a broader range of expanding machine learning inference use cases at Meta.\nThe post Taming the tail utilization of ads inference at Meta scale appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>Tail utilization is a significant system issue and a major factor in overload-related failures and low compute utilization. The tail utilization optimizations at Meta have had a profound impact on model serving capacity footprint and reliability.  Failure rates, which are mostly timeout errors, were reduced by two-thirds; the compute footprint delivered 35% more work for [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2024/07/10/production-engineering/tail-utilization-ads-inference-meta/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2024/07/10/production-engineering/tail-utilization-ads-inference-meta/\">Taming the tail utilization of ads inference at Meta scale</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "Tail utilization is a significant system issue and a major factor in overload-related failures and low compute utilization. The tail utilization optimizations at Meta have had a profound impact on model serving capacity footprint and reliability.  Failure rates, which are mostly timeout errors, were reduced by two-thirds; the compute footprint delivered 35% more work for [...]\nRead More...\nThe post Taming the tail utilization of ads inference at Meta scale appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=21421",
        "categories": [
          "ML Applications",
          "Networking & Traffic",
          "Production Engineering"
        ],
        "isoDate": "2024-07-10T20:30:26.000Z"
      },
      {
        "creator": "",
        "title": "Meta’s approach to machine learning prediction robustness",
        "link": "https://engineering.fb.com/2024/07/10/data-infrastructure/machine-learning-ml-prediction-robustness-meta/",
        "pubDate": "Wed, 10 Jul 2024 13:00:37 +0000",
        "content:encodedSnippet": "Meta’s advertising business leverages large-scale machine learning (ML) recommendation models that power millions of ads recommendations per second across Meta’s family of apps. Maintaining reliability of these ML systems helps ensure the highest level of service and uninterrupted benefit delivery to our users and advertisers. To minimize disruptions and ensure our ML systems are intrinsically resilient, we have built a comprehensive set of prediction robustness solutions that ensure stability without compromising performance or availability of our ML systems. \nWhy is machine learning robustness difficult?\nSolving for ML prediction stability has many unique characteristics, making it more complex than addressing stability challenges for traditional online services: \nML models are stochastic by nature. Prediction uncertainty is inherent, which makes it difficult to define, identify, diagnose, reproduce, and debug prediction quality issues. \n\nConstant and frequent refreshing of models and features. ML models and features are continuously updated to learn from and reflect people’s interests, which makes it challenging to locate prediction quality issues, contain their impact, and quickly resolve them\n\nBlurred line between reliability and performance. In traditional online services, reliability issues are easier to detect based on service metrics such as latency and availability. However, ML prediction stability implies a consistent prediction quality shift, which is harder to distinguish. For example, an “available” ML recommender system that reliably produces inaccurate predictions is actually “unreliable.”\n\nCumulative effect of small distribution shifts over time. Due to the stochastic nature of ML models, small regressions in prediction quality are hard to distinguish from the anticipated organic traffic-pattern changes. However, if undetected, such small prediction regressions could have a significant cumulative negative impact over time. \nLong chain of complex interactions. The final ML prediction result is derived from a complex chain of processing and propagation across multiple ML systems. Regression in prediction quality could be traced back to several hops upstream in the chain, making it hard to diagnose and locate stability improvements per specific ML system. \nSmall fluctuations can amplify to become big impacts. Even small changes in the input data (e.g., features, training data, and model hyperparameters) can have a significant and unpredictable impact on the final predictions. This poses a major challenge in containing prediction quality issues at particular ML artifacts (model, feature, label), and it requires end-to-end global protection. \nRising complexity with rapid modeling innovations. Meta’s ML technologies are evolving rapidly, with increasingly larger and more complex models and new system architectures. This requires prediction robustness solutions to evolve at the same fast pace. \nMeta’s approach and progress towards prediction robustness\nMeta has developed a systematic framework to build prediction robustness. This framework includes a set of prevention guardrails to build control from outside-in, fundamental understanding of the issues to gain ML insights, and a set of technical fortifications to establish intrinsic robustness. \nThese three approaches are exercised across models, features, training data, calibration, and interpretability to ensure all possible issues are covered throughout the ML ecosystem. With prediction robustness, Meta’s ML systems are robust by design, and any stability issues are actively monitored and resolved to ensure smooth ads delivery for our users and advertisers. \nFigure 1: A simplified view of Meta’s ads recommendation system shows the flow of complex interactions for producing the final predictions.\nOur prediction robustness solution systematically covers all areas of the recommender system – training data, features, models, calibration, and interpretability. \nModel robustness\nModel robustness challenges include model snapshot quality, model snapshot freshness, and inferencing availability. We use Snapshot Validator, an internal-only real-time, scalable, and low-latency model evaluation system, as the prevention guardrail on the quality of every single model snapshot, before it ever serves production traffic. \nSnapshot Validator runs evaluations with holdout datasets on newly-published model snapshots in real-time, and it determines whether the new snapshot can serve production traffic. Snapshot Validator has reduced model snapshot corruption by 74% in the past two years. It has protected >90% of Meta ads ranking models in production without prolonging Meta’s real-time model refresh. \nIn addition, Meta engineers built new ML techniques to improve the intrinsic robustness of models, such as pruning less-useful modules inside models, better model generalization against overfitting, more effective quantization algorithms, and ensuring model resilience in performance even with a small amount of input data anomalies. Together these techniques have improved the ads ML model stability, making the models resilient against overfitting, loss divergence, and more.  \nFeature robustness\nFeature robustness focuses on guaranteeing the quality of ML features across coverage, data distribution, freshness, and training-inference consistency. As prevention guardrails, robust feature monitoring systems were in production to continuously detect anomalies on ML features. As the ML-feature-value distributions can change widely with non-deterministics sways on model performance, the anomaly detection systems have turned to accommodate the particular traffic and ML prediction patterns for accuracy. \nUpon detection, automated preventive measures will kick in to ensure abnormal features are not used in production. Furthermore, a real-time feature importance evaluation system is built to provide fundamental understanding of the correlation between feature quality and model prediction quality. \nAll these solutions have effectively contained ML feature issues on coverage drop, data corruption, and inconsistency in Meta. \nTraining data robustness\nThe wide spectrum of Meta ads products requires distinct labeling logics for model training, which significantly increases the complexity of labeling. In addition, the data sources for label calculation could be unstable, due to the complicated logging infrastructure and the organic traffic drifts. Dedicated training-data-quality systems were built as the prevention guardrails to detect label drifts over time with high accuracy, and swiftly and automatically mitigate the abnormal data changes and prevent models from learning the affected training data. \nAdditionally, fundamental understanding of training data label consistency has resulted in optimizations in training data generation for better model learning. \nCalibration robustness\nCalibration robustness builds real-time monitoring and auto-mitigation toolsets to guarantee that the final prediction is well calibrated, which is vital for advertiser experiences. The calibration mechanism is technically unique because it is unjoined-data real-time model training, and it is more sensitive to traffic distribution shifts than the joined-data mechanism. \nTo improve the stability and accuracy of calibration Meta has built prevention guardrails that consist of high-precision alert systems to minimize problem-detection time, as well as high-rigor, automatically orchestrated mitigations to minimize problem-mitigation time.\nML interpretability\nML interpretability focuses on identifying the root causes of all ML instability issues. Hawkeye, our internal AI debugging toolkit, allows engineers at Meta to root-cause tricky ML prediction problems. Hawkeye is an end-to-end and streamlined diagnostic experience covering all ML artifacts at Meta, and it has covered >80% of ads ML artifacts. It is now one of the most widely used tools in the Meta ML engineering community. \nBeyond debugging, ML interpretability invests heavily in model internal state understanding – one of the most complex and technically challenging areas in the realm of ML stability. There are no standardized solutions to this challenge, but Meta uses model graph tracing, which uses model internal states on model activations and neuron importance, to accurately explain why models get corrupted. \nAltogether, advancements in ML Interpretability have reduced the time to root-cause ML prediction issues by 50%, and have significantly boosted the fundamental understanding of model behaviors. \nImproving ranking and productivity with prediction robustness\nGoing forward, we’ll be extending our prediction robustness solutions to improve ML ranking performance, and boost engineering productivity by accelerating ML developments.\nPrediction robustness techniques can boost ML performance by making models more robust intrinsically, with more stable training, less normalized entropy explosion or loss divergence, more resilience to data shift, and stronger generalizability. We’ve seen performance gains from applying robustness techniques like gradient clipping and more robust quantization algorithms. And we will continue to identify more systematic improvement opportunities with model understanding techniques.\nIn addition, model performance will be improved with less staleness and stronger consistency between serving and training environments across labels, features, inference platform, and more. We plan to continue upgrading Meta’s ads ML services with stronger guarantees of training-serving consistency and more aggressive staleness SLAs. \nRegarding ML development productivity, prediction robustness techniques can facilitate model development, and improve daily operations by reducing the time needed to address ML prediction stability issues. We’re currently building an intelligent ML diagnostic platform that will leverage the latest ML technologies, in the context of prediction robustness, to help even engineers with little ML knowledge locate the root cause of ML stability issues within minutes. \nThe platform will also evaluate reliability risk continuously across the development lifecycle, minimizing delays in ML development due to reliability regressions. It will embed reliability into every ML development stage, from idea exploration all the way to online experimentation and final launches. \nAcknowledgements\nWe would like to thank all the team members and the leadership that contributed to make the Prediction Robustness effort successful in Meta. Special thanks to Adwait Tumbde, Alex Gong, Animesh Dalakoti, Ashish Singh, Ashish Srivastava, Ben Dummitt, Booker Gong, David Serfass, David Thompson, Evan Poon, Girish Vaitheeswaran, Govind Kabra, Haibo Lin, Haoyan Yuan, Igor Lytvynenko, Jie Zheng, Jin Zhu, Jing Chen, Junye Wang, Kapil Gupta, Kestutis Patiejunas, Konark Gill, Lachlan Hillman, Lanlan Liu, Lu Zheng, Maggie Ma, Marios Kokkodis, Namit Gupta, Ngoc Lan Nguyen, Partha Kanuparthy, Pedro Perez de Tejada, Pratibha Udmalpet, Qiming Guo, Ram Vishnampet, Roopa Iyer, Rohit Iyer, Sam Elshamy, Sagar Chordia, Sheng Luo, Shuo Chang, Shupin Mao, Subash Sundaresan, Velavan Trichy, Weifeng Cui, Ximing Chen, Xin Zhao, Yalan Xing, Yiye Lin, Yongjun Xie, Yubin He, Yue Wang, Zewei Jiang, Santanu Kolay, Prabhakar Goyal, Neeraj Bhatia, Sandeep Pandey, Uladzimir Pashkevich, and Matt Steiner. \nThe post Meta’s approach to machine learning prediction robustness appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>Meta’s advertising business leverages large-scale machine learning (ML) recommendation models that power millions of ads recommendations per second across Meta’s family of apps. Maintaining reliability of these ML systems helps ensure the highest level of service and uninterrupted benefit delivery to our users and advertisers. To minimize disruptions and ensure our ML systems are intrinsically [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2024/07/10/data-infrastructure/machine-learning-ml-prediction-robustness-meta/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2024/07/10/data-infrastructure/machine-learning-ml-prediction-robustness-meta/\">Meta’s approach to machine learning prediction robustness</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "Meta’s advertising business leverages large-scale machine learning (ML) recommendation models that power millions of ads recommendations per second across Meta’s family of apps. Maintaining reliability of these ML systems helps ensure the highest level of service and uninterrupted benefit delivery to our users and advertisers. To minimize disruptions and ensure our ML systems are intrinsically [...]\nRead More...\nThe post Meta’s approach to machine learning prediction robustness appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=21437",
        "categories": [
          "Data Infrastructure",
          "ML Applications"
        ],
        "isoDate": "2024-07-10T13:00:37.000Z"
      }
    ]
  },
  {
    "name": "eBay Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Twitter Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Netflix TechBlog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "JetBrains: Developer Tools for Professionals and Teams – Company Blog | JetBrains",
    "category": "기업",
    "posts": [
      {
        "creator": "David Watson",
        "title": "WebStorm 2024.2 EAP Digest #3: Bun Debugger, Language Server Updates for Vue and Astro, and Prettier Integration by Default",
        "link": "https://blog.jetbrains.com/webstorm/2024/07/webstorm-2024-2-eap3/",
        "pubDate": "Mon, 15 Jul 2024 15:16:32 +0000",
        "content:encodedSnippet": "It’s time for our last EAP digest of this release that will walk you through the new features and improvements in WebStorm 2024.2! For more information, check out our previous blog posts.The Toolbox App is the easiest way to get the EAP builds and keep both your stable and EAP versions up to date. You can also manually download the EAP builds from our website.\n\nDOWNLOAD WEBSTORM 2024.2 EAP\nImportant! WebStorm EAP builds are not fully tested and might be unstable.Please try the latest EAP build and share your feedback with us. You can do so using our issue tracker or by leaving a comment on this blog post.\nKey highlights\nBun debugging support\nWebStorm 2024.2 now supports the Debug Adapter Protocol (DAP), introducing the debugging experience for developers using the Bun JavaScript runtime. This integration allows you to set breakpoints, step through code, inspect variables, and evaluate expressions directly within WebStorm:\n\n\n\n\nCurrently, we’re providing initial support and gathering your feedback. This functionality is available only for macOS and Linux users. Windows support is targeted for one of the upcoming minor releases; please track the following issue: WEB-67975.\nImproved file-system based routing support for major frameworks\nWebStorm 2024.2 introduces support for path resolving for frameworks that use file-system based routing. WebStorm can now resolve link paths based on your project’s file system, providing autocompletion, and navigation. Additionally, the improved path resolving supports dynamic and nested routes, ensuring that your development environment keeps up with the routing scenarios these frameworks employ. The following frameworks are covered:\nNext.js\nNuxt \nAstro\nSvelte\nCurrently, the navigation is supported for the built-in components like Link, NuxtLink, and native a elements.\n\n\n\n\n\n\nThe Astro Language Server is enabled by default\nIn the 2024.2 EAPs, we’ve enabled Astro Language Server Protocol (LSP) support, leading to improved code completion and a better overall developer experience. This enhancement ensures more accurate and efficient development when working with Astro projects, providing better integration and support within the IDE. Additionally, we’ve fixed several false-positive errors, further enhancing the Astro support.\n\n\n\n\nYou can toggle the language server in Settings | Languages & Frameworks | TypeScript | Astro.\nLanguage Services icons in status bar\nThe EAP 7 of WebStorm introduces a visual enhancement to the Language Services status bar widget. Now, instead of the Language Services static label, you can see icons representing the active language services like ESLint, Tailwind, and TypeScript, which are running on the current file:\n\n\n\n\nPrettier integration is enabled by default\nStarting from EAP 6, new projects with a direct prettier dependency in their root package.json and a Prettier configuration file at the same level will have the Automatic Prettier Configuration setting enabled by default. This feature simplifies the setup process, ensuring that Prettier integration is enabled out of the box.\nFor those working with monorepos, a separate issue (WEB-67396) is being addressed to support similar functionality across multiple packages within a single repository. \nNew project template with onboarding tips\nWebStorm EAP 8 enhances the New Project Wizard by adding a new option to create basic JavaScript and TypeScript projects. This feature is designed to simplify onboarding for new users, providing an easy way to set up a project with minimal configuration. Users can select JavaScript or TypeScript directly from the wizard.\n\n\n\n\nThe generated projects include essential files like package.json and either index.js or index.ts, with a welcoming console log message. For TypeScript projects, a tsconfig.json file is also included to set up compiler options. The Generate a playground project with onboarding tips option includes helpful TIP comments ensuring a smooth start with the IDE. Projects that are generated with this option are based on the Vite template and contains an example web application:\n\n\n\n\nExtract Vue component AI Action\nThe new feature, available with the AI Assistant plugin enabled, allows you to extract a Vue component from an existing template area. Open a Vue file, select a section of the template (excluding the template tag), and invoke the AI Actions | Extract Component intention. This opens two diff editors: one for the new component’s generated code and another for the changes in the existing component. After accepting the modifications, the new component is saved with a name suggested by the AI and integrated into the original component:\n\nLanguage-specific settings for sticky lines \nYou can now set sticky lines more precisely and choose the languages you want them to appear for. You can tailor the feature to your preferences either in Settings | Editor | General | Sticky Lines or by calling the context menu by right-clicking on a sticky line in the editor:\n\n\n\n\nTailwind preview in completion options\nPreviously, when using Tailwind CSS, developers could only see the preview of Tailwind classes in a secondary documentation popup. Now WebStorm displays Tailwind CSS class previews directly in the completion result list, eliminating the need to enable the documentation popup for completion:\n\n\n\n\nVue Language Tools 2.0\nThe 2024.2 EAPs introduce Vue Language Tools 2.0 support. This update enhances support for Vue 3, improving autocompletion, error checking, and type inference. Enjoy a smoother development experience powered by the most recent version of Vue language tools and built-in WebStorm support.\nOther highlights\nWe’ve introduced a highlighting category for ${ and } tokens in template literals for JavaScript and TypeScript files, including template literal types in TypeScript (WEB-35578).\n.cjs, .cts, .mjs, .mts file extensions were added to Run for files by default for ESLint Prettier (WEB-60181).\nWe’ve supported autocompletion for CSS classes inside object properties in React.js when using the classnames library (WEB-57054).\nThe IDE now suggests downloading the Node.js interpreter (if it’s not detected) via an in-editor notification for JavaScript, TypeScript, and web framework files (WEB-48436).\nWe’ve fixed a long-standing WEB-61405 issue (Vite package not found when using Yarn 3.5+ and PNP mode).\nThat’s it for today. For the full list of improvements available in the latest EAP build, check out the release notes.\nThe WebStorm team",
        "dc:creator": "David Watson",
        "content": "It’s time for our last EAP digest of this release that will walk you through the new features and improvements in WebStorm 2024.2! For more information, check out our previous blog posts.The Toolbox App is the easiest way to get the EAP builds and keep both your stable and EAP versions up to date. You [&#8230;]",
        "contentSnippet": "It’s time for our last EAP digest of this release that will walk you through the new features and improvements in WebStorm 2024.2! For more information, check out our previous blog posts.The Toolbox App is the easiest way to get the EAP builds and keep both your stable and EAP versions up to date. You […]",
        "guid": "https://blog.jetbrains.com/?post_type=webstorm&p=493634",
        "categories": [
          "eap",
          "webstorm-2024-2"
        ],
        "isoDate": "2024-07-15T15:16:32.000Z"
      },
      {
        "creator": "Anastassiya Sichkarenko",
        "title": "Help Shape the Future of Tech – Participate in the Developer Ecosystem Survey 2024",
        "link": "https://blog.jetbrains.com/team/2024/07/15/help-shape-the-future-of-tech-participate-in-the-developer-ecosystem-survey-2024/",
        "pubDate": "Mon, 15 Jul 2024 11:24:48 +0000",
        "content:encodedSnippet": "This year’s Developer Ecosystem Survey is out now! This is your chance to contribute to a comprehensive, unbiased analysis of the software development landscape. Your insights and feedback are invaluable, and we can’t wait to hear from you. Offering you an opportunity to share your experiences as a developer, the survey will take around 30 minutes to complete.\nTAKE THE DEVELOPER ECOSYSTEM SURVEY\nThe survey is available in 8 languages, including Chinese, German, French, Japanese, Korean, Portuguese, and Spanish.\n\n\n\n\n\nWhy participate?\nImpactful research: Your participation helps us and the broader community understand current trends, challenges, and opportunities in software development.\nExciting prizes: You could win amazing prizes like:\nA MacBook Pro 16″\nAn NVIDIA GeForce RTX 4090 graphics card\nAn iPhone 15 Pro, a Google Pixel 8 Pro\nA USD 300 Amazon Gift Card\n A JetBrains Merchandise Store voucher\nA one-year JetBrains All Products Pack subscription\n\n\n\n\nShare and win more\nThe survey’s success depends on widespread participation. Share the survey with your friends and colleagues to make the results truly representative of our community. By doing so, you’ll be entered into an additional prize raffle. The participant with the most referrals will win a special prize. Referral links are available on the last page of the survey.\nWhat to expect\nAs in previous years, we will publicly share the survey results and insights. You can look forward to detailed infographics showcasing the latest trends in tech and software development. Additionally, we will provide anonymized raw data for those interested in conducting their own research.\nReady to make a difference? Click the link below to get started!\nTAKE THE DEVELOPER ECOSYSTEM SURVEY\nThank you for helping us shape the future of software development!\nSincerely,\nThe JetBrains Tech Insights Lab",
        "dc:creator": "Anastassiya Sichkarenko",
        "content": "This year&#8217;s Developer Ecosystem Survey is out now! This is your chance to contribute to a comprehensive, unbiased analysis of the software development landscape. Your insights and feedback are invaluable, and we can&#8217;t wait to hear from you. Offering you an opportunity to share your experiences as a developer, the survey will take around 30 [&#8230;]",
        "contentSnippet": "This year’s Developer Ecosystem Survey is out now! This is your chance to contribute to a comprehensive, unbiased analysis of the software development landscape. Your insights and feedback are invaluable, and we can’t wait to hear from you. Offering you an opportunity to share your experiences as a developer, the survey will take around 30 […]",
        "guid": "https://blog.jetbrains.com/?post_type=team&p=487676",
        "categories": [
          "deveco",
          "news",
          "research",
          "devecosystem"
        ],
        "isoDate": "2024-07-15T11:24:48.000Z"
      },
      {
        "creator": "Anna Rovinskaia",
        "title": "New Livestream – Practical Debugging at Scale: Do You Really Know How to Debug Effectively?",
        "link": "https://blog.jetbrains.com/idea/2024/07/new-livestream-java-22-and-intellij-ideanew-livestream/",
        "pubDate": "Mon, 15 Jul 2024 09:31:32 +0000",
        "content:encodedSnippet": "Join us for a new IntelliJ IDEA Livestream episode with Shai Almog, where we will delve into the capabilities of the debugger.\nDate: July 25, 2024\nTime: 3:00 pm – 4:00 pm UTC\nREGISTER FOR THE LIVESTREAM\n\n\n\n\nSession abstract\nMost of us didn’t learn debugging in university and just “picked it up on the job”. That is shocking for such a crucial skill, even if testing debugging knowledge is known to be challenging. However, it’s never too late to learn how to use these underutilized debugger capabilities that many developers don’t know about:\n\nObject marking \nTracepoints \nMemory tracing \nJump to line \nRenderers \nAnd more \n \nAsking questions\nShai will try to answer all of your questions during the session. If we run out of time, we’ll publish the answers to any remaining questions in a follow-up blog post.\nYour speaker and host\nSpeaker\nShai Almog\n\nShai is an entrepreneur, author, blogger, and open-source hacker. He has written five books, including Practical Debugging at Scale: Cloud Native Debugging in Kubernetes and Production (Apress), and he blogs about debugging at debugagent.com.\n\nHost\nMala Gupta\n\nA Java Champion and JUG leader, Mala has authored multiple books with Manning, Packt, and O’Reilly Publications. She has more than two decades of experience in the software industry and is a regular speaker at industry conferences around the world. She is an active supporter of Java certification as a path to career advancement.\n\nHappy developing!",
        "dc:creator": "Anna Rovinskaia",
        "content": "Join us for a new IntelliJ IDEA Livestream episode with Shai Almog, where we will delve into the capabilities of the debugger. Date: July 25, 2024 Time: 3:00 pm – 4:00 pm UTC REGISTER FOR THE LIVESTREAM Session abstract Most of us didn&#8217;t learn debugging in university and just &#8220;picked it up on the job&#8221;. [&#8230;]",
        "contentSnippet": "Join us for a new IntelliJ IDEA Livestream episode with Shai Almog, where we will delve into the capabilities of the debugger. Date: July 25, 2024 Time: 3:00 pm – 4:00 pm UTC REGISTER FOR THE LIVESTREAM Session abstract Most of us didn’t learn debugging in university and just “picked it up on the job”. […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=493045",
        "categories": [
          "livestreams",
          "intellij-idea",
          "intellijidealivestream",
          "livestream",
          "webinars"
        ],
        "isoDate": "2024-07-15T09:31:32.000Z"
      },
      {
        "creator": "Maria Kosukhina",
        "title": "IntelliJ IDEA 2024.2 Beta Is Out! ",
        "link": "https://blog.jetbrains.com/idea/2024/07/intellij-idea-2024-2-beta/",
        "pubDate": "Thu, 11 Jul 2024 22:17:51 +0000",
        "content:encodedSnippet": "We’ve just released the Beta version of IntelliJ IDEA 2024.2. This milestone brings us closer to the big release date, and you still have time to try out the new features through the Early Access Program.\n\n\n\n\nThe Beta build includes all of the new functionality detailed in our IntelliJ IDEA 2024.2 EAP blog posts. Here’s a recap of what’s coming in the new version of the IDE:\nFaster time to code \nImproved Kotlin K2 mode \nEnhanced AI Assistant code сompletion\nBetter log management for Java and Kotlin \nSupport for math syntax in Markdown \nImproved experience with Gradle build scripts\nMultiple improvements for version control systems \nString variable visualizers for JSON, XML, and other formats in the debugger\nEnhanced Spring Data JPA support\nImproved cron expression support\nGraalJS as the execution engine for the HTTP Client\nAutocompletion for Micronaut and Quarkus beans\nAnd much more\n\n\n\n\nDownload IntelliJ IDEA 2024.2 Beta\nWhile the team is currently polishing these features, we still have a few updates that haven’t been covered yet. Let’s take a look!\nKotlin \nEnhanced Gradle build script support\nIn IntelliJ IDEA 2024.2, we’ve significantly improved Gradle.kts support. This includes enabling scripting support for K2 mode, introducing support for TOML files, adding project module navigation, and providing type-safe dependency project accessors.\n\n\n\n\n\n\n\n\nCode coverage \nTest coverage for changes in the current feature branch\nIntelliJ IDEA 2024.2 further improves the ability to quickly check and improve test coverage locally without invoking a slow CI/CD pipeline.\nBy default, the Coverage tool window now shows only the classes that were changed in your current feature branch. This allows you to check the test coverage for your recent changes without browsing the entire project status.\nIf you’re interested in the entire project’s test coverage, you can disable the Show Only Modified Classes option to view all classes.\n\n\n\n\nFrameworks and technologies \nKtor development mode support in run configurations\nIntelliJ IDEA 2024.2 provides an easy way to enable Ktor’s development mode in run configurations. This mode is now set by default when creating a new run configuration and can be managed in the updated Run/Debug Configurations dialog. In addition, we’ve reworked this dialog so that now it features a cleaner and more user-friendly UI for Ktor users.\n\n\n\n\nThat’s it for now! For the full list of changes implemented in this build, refer to the release notes.\nAs we put the finishing touches on the major release, you still have a couple of weeks to test out the new features and help us ensure the final version runs smoothly. For this, we’d love to know what you think about the latest additions, so please share your opinions in the comments section below or on X (formerly Twitter). If you encounter any bugs, submit a report to our issue tracker. \nHappy developing!",
        "dc:creator": "Maria Kosukhina",
        "content": "We’ve just released the Beta version of IntelliJ IDEA 2024.2. This milestone brings us closer to the big release date, and you still have time to try out the new features through the Early Access Program. The Beta build includes all of the new functionality detailed in our IntelliJ IDEA 2024.2 EAP blog posts. Here&#8217;s [&#8230;]",
        "contentSnippet": "We’ve just released the Beta version of IntelliJ IDEA 2024.2. This milestone brings us closer to the big release date, and you still have time to try out the new features through the Early Access Program. The Beta build includes all of the new functionality detailed in our IntelliJ IDEA 2024.2 EAP blog posts. Here’s […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=492460",
        "categories": [
          "eap",
          "2024-2-eap",
          "intellij-idea-2024-2",
          "intellij-idea-2024-2-eap"
        ],
        "isoDate": "2024-07-11T22:17:51.000Z"
      },
      {
        "creator": "Khalid Abuhakmeh",
        "title": "Snapshot Testing in .NET with Verify",
        "link": "https://blog.jetbrains.com/dotnet/2024/07/11/snapshot-testing-in-net-with-verify/",
        "pubDate": "Thu, 11 Jul 2024 14:06:26 +0000",
        "content:encodedSnippet": "When writing tests, the ultimate goal should always be to deliver “value”. This value is not just about the number of tests written but about the quality and relevance of the tests. We aim to write, execute, and maintain valuable tests that instill confidence in our application’s ability to withstand the rigors of user production use. Throughout the history of software testing, several techniques have contributed their unique value proposition to the testing mythos. \nFor example, Unit tests help us focus on writing small and faster tests around the logical aspects of our application. Integration tests take several units and dependencies and attempt to see the outcome of their interactions. Manual tests take the unpredictability of a human user and help us see if our applications can handle the unexpected. \nEach testing approach can have a distinct style. Today, we’ll delve into snapshot testing, a practical technique you can apply to code-driven tests. It combines a few previously mentioned approaches, offering a uniquely practical test. By the end of this post, you’ll have a comprehensive understanding of snapshot testing with Verify, how to integrate it into your test suites seamlessly, and why we believe it’s a valuable addition to your testing toolkit.\nDownload Verify plugin for Rider\n                                                    \nWhat is snapshot testing?\nLogically, you typically center tests around asserting the state before and after a particular action occurs. If you’re familiar with unit testing, you’ve likely heard the phrase: “Arrange, Act, and Assert”. In terms of code, let’s look at a simple example to illustrate this construct.\n[Test]\npublic void Assert_apple_is_not_null()\n{\n    // arrange\n    Apple apple;\n\n    // act\n    apple = new Apple(\"Honey Crisp\", \"Yellow & Red\");\n\n    // assert\n    Assert.That(apple, Is.Not.Null);\n}\n\n\n\n\nIf we look at this code, it sets out to accomplish the test’s intent: asserting that the target is not null. But as you look closer, you realize some data points are unused in this test, mainly the name and color of the apple.\nSnapshot testing is different from a traditional test as it focuses on the result of an action and expects you, the test author, to verify the accuracy of the result. In the case of our apple example, we would run our test and verify that the entire apple is “correctly” created.\nLet’s look at an example of a snapshot test and what steps you would take to get a passing.\nThe first step is to write a test similar to the one above.\n[Test]\npublic Task Verify_apple_is_granny_smith()\n{\n    // arrange\n    var service = new AppleService();\n\n    // act \n    var apple = service.GetApple();\n \n    // verify    \n    return Verify(apple);\n}\n\n\n\n\nNote that the call to Verify takes the entire instance and has no assertions. The method call will produce a binary snapshot of the instance and write it to non-volatile storage, such as the file system.\n{\n  Name: Granny Smith,\n  Color: Green\n}\nFrom here, the first test run of a newly created test will always fail. As the author, you will look at this serialized result and verify that it meets your success requirements. If it does, you accept the results, and the test now passes. We’ll get into how you verify results later, as this can vary depending on the serialization method of the snapshot. In future test runs, if our code produces a different result, then the test will fail and require reverifying the snapshot or investigating why the change occurred in the first place.\nSnapshot testing is straightforward in concept yet a powerful approach to building valuable test suites. In the next section, we’ll see how to start with Verify, a .NET library focused on producing and maintaining snapshots.\nGetting started with Verify\nBefore updating your test projects, we highly recommend installing the excellent Verify Plug-in, developed by .NET Developer Advocate Matthias Koch (check out the livestream below). The plug-in adds Verify support for both JetBrains Rider and ReSharper for Visual Studio. Great, let’s start adding Verify to your test project.\n\n\n\n\n\n\nVerify supports most major unit testing libraries, including NUnit, xUnit, MSTest, and Expecto. You’ll need to install the matching Verify package in a test project of your choice. In my case, I’ll be using NUnit and will install Verify.NUnit.\nFor the sake of this demo, I’ll be testing an AppleService class.\npublic class AppleService\n{\n    public Apple GetApple() \n        => new Apple(\"Granny Smith\", \"Green\");\n}\n\npublic record Apple(string Name, string Color);\nNext, I’ll create a static method to set up some global settings for Verify. This step is optional but allows you to define some of the library’s many features. In my case, I’m putting snapshot artifacts under a snapshots directory.\npublic class Tests\n{\n    private static readonly VerifySettings Settings;\n    \n    static Tests()\n    {\n        Settings = new VerifySettings();\n        Settings.UseDirectory(\"snapshots\");\n    }\n}\n\n\n\n\nNext, let’s add our tests.\nnamespace SnapshotTests;\n\npublic class Tests\n{\n    private static readonly VerifySettings Settings;\n    \n    static Tests()\n    {\n        Settings = new VerifySettings();\n        Settings.UseDirectory(\"snapshots\");\n    }\n    \n    private readonly AppleService sut = new();\n\n    [Test]\n    public void Assert_apple_is_granny_smith()\n    {\n        var apple = sut.GetApple();\n        Assert.That(apple.Name, Is.EquivalentTo(\"Granny Smith\"));\n    }\n\n    [Test]\n    public Task Verify_apple_is_granny_smith()\n    {\n        // arrange\n        var service = new AppleService();\n        // act \n        var apple = service.GetApple(); \n        // verify    \n        return Verify(apple, Settings);\n    }\n}\n\n\n\n\nNote that we have a mixture of traditional unit tests and snapshot tests. These two methodologies are compatible, and we encourage you to think critically about which approach suits your goals.\nRunning our test, you’ll see that it immediately fails with a VerifyException.\n\n\n\n\nThis result is as expected. Let’s use the Verify plug-in to see the received result compared with the verified result. In the test window, right-click the failed test and use the menu to find Compare Received/Verified.\n\n\n\n\nOnce you’ve chosen Compare Received/Verified, your IDE’s comparison tool will launch, allowing you to see the variations between the received and verified results.\n\n\n\n\nIf it looks good to you, remember you’re the verifier of the snapshot, then you can right-click the failed test and choose Accept Received.\n\n\n\n\nRerunning the tests will lead to a passing test.\n\n\n\n\nCongratulations. You’ve successfully written your first snapshot test. Now, let’s talk about some frequently asked questions and answer them.\nCommon questions about snapshot testing\nWhen adopting snapshot tests, there are a few questions many developers commonly ask. We’ve gathered some of them here and will try to answer them.\nIs this “really” better than other styles of testing?\nSnapshot testing provides a different approach and, as mentioned earlier, is compatible with all testing approaches. Snapshots can offer more value over fewer tests and catch unintended changes you may miss when writing assertion-based tests. Like all things in life, snapshot testing has advantages and disadvantages.\nDo I have to check in the snapshots to source control?\nYes. Snapshots are binary artifacts necessary to fulfill the verification test you’ve written. Without these files, your test has nothing to assert against and will fail.\nWon’t that make my source control huge?\nThese snapshot files should not change so frequently that they cause significant binary changes in your source control. Text-based serialization is typically the default for Verify, so these files are compressed and efficiently stored.\nCan I fine-tune the verification process?\nAs you’ve seen in the above example, a VerifySettings class allows you to configure how verification occurs. Settings changes could include where snapshot files are stored, what fields are part of verification, and how binary serialization occurs.\nCan I verify more than just JSON objects?\nYes! Serializing anything is another strength of snapshot testing. The comparison can be between any two binary files, including PDFs, images, videos, or whatever your code can produce. Simon Cropp created an entire library of extensions for that purpose.\nCan I set Verify settings globally?\nYes, but you’ll need to use the ModuleInitializer attribute, which allows you to execute code once the code runtime has loaded an assembly.\npublic class StaticSettings\n{\n    [Fact]\n    public Task Test() =>\n        Verify(\"String to verify\");\n}\n\npublic static class StaticSettingsUsage\n{\n    [ModuleInitializer]\n    public static void Initialize() =>\n        VerifierSettings.AddScrubber(_ => _.Replace(\"String to verify\", \"new value\"));\n}\n\n\n\n\nConclusion\nVerify by Simon Cropp is a fantastic library for folks looking to enhance the value of their test suites. Also, remember to install the plug-in written by Matthias Koch for both ReSharper and JetBrains Rider for an improved verification workflow. We also love that all major testing libraries are supported with a massive library of extensions to verify a variety of test artifacts. We highly recommend you take a look.\nWe hope you learned something about snapshot testing. Please let us know in the comments below if you try it in your solutions.\nimage credit: Alexander Wende",
        "dc:creator": "Khalid Abuhakmeh",
        "content": "When writing tests, the ultimate goal should always be to deliver “value”. This value is not just about the number of tests written but about the quality and relevance of the tests. We aim to write, execute, and maintain valuable tests that instill confidence in our application&#8217;s ability to withstand the rigors of user production [&#8230;]",
        "contentSnippet": "When writing tests, the ultimate goal should always be to deliver “value”. This value is not just about the number of tests written but about the quality and relevance of the tests. We aim to write, execute, and maintain valuable tests that instill confidence in our application’s ability to withstand the rigors of user production […]",
        "guid": "https://blog.jetbrains.com/?post_type=dotnet&p=477058",
        "categories": [
          "net-tools",
          "c",
          "integration-testing",
          "resharper",
          "rider",
          "unit-testing"
        ],
        "isoDate": "2024-07-11T14:06:26.000Z"
      },
      {
        "creator": "Alena Guzharina",
        "title": "5 Emerging Data Job Trends in 2024",
        "link": "https://blog.jetbrains.com/datalore/2024/07/11/5-emerging-data-job-trends-in-2024/",
        "pubDate": "Thu, 11 Jul 2024 09:54:11 +0000",
        "content:encodedSnippet": "This is a guest blog post by Thu Vu. \nThe long-term outlook for data jobs – like data scientists, statisticians, and market research analysts – predicts explosive growth, much faster than most other fields. But here’s the catch: Despite the promising stats, data professionals are struggling to find jobs. AI is also shaking things up with capable LLMs, coding assistants, and loads of smart tools for data analytics.\n\n\n\n\nData source  \nSo, what does this mean for you as a data professional? What exactly has changed in the past one to two years? To try and find out, I spent 24 hours researching the data job market. \nIn this article, I’m going to share five key trends I’ve noticed in the market right now and detail what I would do to adapt to these changes. To view all the graphs in one place, click the link below: \n      \n      Open Datalore report\n    \n\n\n\n\n1. Data job postings are getting competitive but remain stable\nFirst up, let’s talk about the job market. You might be thinking – with all the tech layoffs we’ve been hearing about, surely data jobs must be taking a hit, right? Well, you might be surprised.\nSince the end of 2022, the number of jobs for data scientists, data analysts, and data engineers has decreased by about 15% but has remained quite stable since the beginning of this year. \n\n\n\n\nData source\nThis is pretty interesting, especially when you consider that the tech industry has experienced two big waves of layoffs since the COVID-19 pandemic – one at the beginning of 2023 and another at the beginning of 2024.\n\n\n\n\nData source\nBut if we lay this trend next to the tech layoffs, we can see that the data job posts didn’t seem to be affected much by the tech layoff trends.\nThis trend can also be observed per job title.\n\n\n\n\nData source\nCompared to the last two years, the job market is certainly more competitive, with companies being more selective. The uncertain economic growth and high interest rates are making companies tighten their budgets and seek skills that focus on efficiency and cost reduction. This might explain why it feels harder to land a job today.\nDon’t let that discourage you, though! It just means we need to be smarter about how we position ourselves in the market. Which brings me to my next point…\n2. Technical skills\nIf you’re in the data field, you’ve probably noticed that certain programming languages are becoming more dominant. Technical skills are consolidating. And the data backs this up.\nA whopping 86% of data scientists said that Python is the main language they use for current projects. Another 10% said they use it as a secondary language.\n\n\n\n\nData source\nAnd Python is being used for everything from data analysis to machine learning and web development.\n\nData source\nA few years ago, if you asked me whether you should learn R or Python, I would’ve said it doesn’t matter which language you start with. But today, I’d definitely say Python.\nBut Python isn’t the only player in town. Looking at job postings data over the past two years, SQL consistently appears in up to 60% of all job posts, right alongside Python, month after month. This shows that Python and SQL are and will remain the dominant languages for the foreseeable future.\n\n\n\n\nData source\nSo, if you’re trying to become a data scientist from scratch and are wondering what programming language to learn, I’d say it’s smart to focus on mastering Python and SQL first.\nIn fact, you might be surprised to hear this, but Wes McKinney, the creator of the pandas package, was recently asked to give advice for data scientists. His shocking response? “Learn SQL.”\nHe said, “Learning SQL is actually a really good skill. It’s not just learning SQL, the language, but learning the concepts of relational algebra and how to think about data sets, designing schemas, and organizing data.”\nAs much as I love Python, I must agree on this. I once worked on a machine learning project at a large bank for anti-money laundering. We used PySpark SQL to query bank transaction data, think billions of rows. I remember at the beginning it’d take me up to 10 minutes to even run a command to check the number of rows in the dataset. Only afterward, I learned about concepts such as partitioning and load balancing to help me optimize my code.\nSo, if you’re looking to level up your skills, don’t overlook SQL. It’s more than just a query language – it’s a way of thinking about data that can make you a better data professional overall.\n      \n      Try SQL features in Datalore\n    \n\n\n\n\n3. Emergence of AI engineering\nNow, here’s where things get really exciting. While data scientists and data analyst roles are always in demand, there’s a new kid on the block: AI engineers.\nThese roles have emerged with the rapid development of large language models in the past two years. And here’s the interesting part – they don’t require a PhD. Rather, they require an in-depth knowledge of LLMs, prompt engineering, and AI agent workflow engineering.\nThis role is still very new, and there are different opinions about what the job exactly entails.\nBut in general, you can think of it this way: If we put data science research on one end of the spectrum and AI applications on the other, AI engineers lean towards the product and user end. They build applications that use pre-trained AI models, or foundation models, to solve a specialized business problem. You can perhaps think of AI engineers as software engineers specializing in AI products.\n\n\n\n\nData source\nFor example, let’s say a company wants to develop an AI application like a specialized customer chatbot using LLMs. AI Engineers will be the ones who put the AI model in place, do some prompt engineering, fine-tuning the model if necessary, tailoring the workflow to the use case, and also evaluating the application to make sure it works as it should.\nAndrej Karpathy, a big name in the AI world, predicts that:\n“In numbers, there’s probably going to be significantly more AI engineers than there are ML engineers/LLM engineers. One can be quite successful in this role without ever training anything.” – Andrej Karpathy\nAnd the job post data backs this up. In the past two years, AI engineer jobs have been growing much faster than ML engineer jobs, with the former actually surpassing the latter in May 2023, according to Hacker News Hiring trends.\n\n\n\n\nData source\nYou might be asking what’s the key difference between AI engineers and ML engineers: Well, it’s quite simple, creating LLM applications rely heavily on prompt engineering, which of course doesn’t exist in a traditional machine learning model. Evaluating LLM applications also requires a very different approach to using precision and recall metrics or mean squared error like in machine learning models.\nRecently, PwC, one of the big four companies, landed a deal with OpenAI to become its first resale partner. This partnership helps PwC scale AI capabilities across businesses to help drive accelerated impact for clients. What this basically means is more and more businesses will be able to build and incorporate AI into their solutions. And who will implement this? AI engineers, that’s who.\nSo, if you have a data science background, how do you become an AI engineer?\nI’m certainly not an expert in this field. But a popular post on Hacker News suggested focusing on these areas:\nMathematical foundations\nBasic statistics\nPython programming\nCourses such as:\n\nML specialization and deep learning specialization by Andrew Ng on Coursera\nfast.ai deep learning courses\nAnd then you can choose a specific area of AI to focus on, for example:\n\nNatural language processing (NLP)\nComputer vision (CV)\nReinforcement learning (RL)\nOther specializations\nThere are other emerging new roles being talked about, such as quality assurance business analyst (or QA analyst for short), who investigate LLM outputs, design A/B tests, and build dashboards to monitor the overall performance of AI products. This role is relatively business-focused.\nThis is yet to be seen in the data for the number of new vacancies being posted. But, this role does not require significant qualifications, and I think anyone with an analytical mind and data science skills can adapt themselves to this new role.\n4. Freelancing trends\nNow, let’s talk about another interesting trend: the rise of freelancing in the data world.\nIn 2024, there seems to have been a significant increase in the number of job posts looking for contractors and freelancers. This is exciting news for those of you who might be interested in a part-time or flexible job.\n\n\n\n\nData source\nBecoming a freelancer is a great way to learn new skills fast and build a diverse portfolio because you’ll get to work on real business problems with clients, sometimes in completely new domain areas, with different types of data and analytics tools.\nIn the US, most freelancers find their work through previous clients, friends and family, social media, and professional contacts.\n\n\n\n\nData source\nThe question is, if you don’t have a previous client already, how do you find your first client?\nHere’s my advice: Start small and utilize your own network. Post about your relevant projects on LinkedIn, showcase your skills, and mention that you’re looking for freelance work in this and that area. I used to be scared to post stuff on Linkedin, but a little bit of fear is a good sign that you’re getting out of your comfort zone.\nEven better, you can approach your neighbors, friends, and family members directly. Small business owners around the corner might need your help, and friends and relatives might have interesting work for you.\nOnce you have 2–3 projects like this (even for free or at very small commissions), you can start collecting reviews, building your process, and refining your services to offer them at a larger scale. You can even start going on online job boards like Upwork and Fiverr to find more jobs.\n5. Automation – The rise of low-code and no-code tools\nLast but definitely not least, let’s talk about a trend that’s changing the game: low-code and no-code tools. It’s not an exaggeration to say that, in the future, anyone could become a data analyst without specialized training. And I’m talking about doing much more than just creating pivot tables in Excel.\nLow-code and no-code development platforms, enabled by AI, are becoming increasingly popular. The low-code market is forecast to grow at an annual average rate of 22.9% from 2023 to 2030.\n\n\n\n\nData source\nThese tools are making data analytics more accessible to people who might not have traditional coding skills. They provide simplified interfaces that let anyone plug in their data and do tasks like data preparation, statistical analysis, visualization, and even build machine learning models without significant coding effort.\nNow, I know what some of you might be thinking. This sounds too good to be true, right? Well, you’re not entirely wrong: AI’s smart, but it still needs human expertise to guide it in complex tasks. And at the end of the day, someone needs to make sense of the results, evaluate them, and make a decision.\nSo, it’s all about finding that sweet spot where tech and expertise work together.\nAs low-code platforms improve to automate a lot of entry-level data analysis tasks, data jobs will likely become more specialized in the future. So instead of just looking for “data analyst” or “data scientist” job titles, you might consider a wider range of titles such as marketing analyst, sales analyst, risk analyst, psychometrician, quality assurance analyst, data governor, or perhaps even data cleaning ninja.\n      \n      Check out Datalore AI\n    \n\n\n\n\nConclusions\nNo matter what your next career move will be, the market will always be in constant flux. The key is to stay adaptable, keep learning, and make valuable connections with people. \nIf you want to dive deeper into the data behind this video, you can find the full report in a Datalore notebook on the JetBrains Datalore website.\n      \n      Open Datalore report",
        "dc:creator": "Alena Guzharina",
        "content": "This is a guest blog post by Thu Vu.&#160; The long-term outlook for data jobs – like data scientists, statisticians, and market research analysts – predicts explosive growth, much faster than most other fields. But here’s the catch: Despite the promising stats, data professionals are struggling to find jobs. AI is also shaking things up [&#8230;]",
        "contentSnippet": "This is a guest blog post by Thu Vu.  The long-term outlook for data jobs – like data scientists, statisticians, and market research analysts – predicts explosive growth, much faster than most other fields. But here’s the catch: Despite the promising stats, data professionals are struggling to find jobs. AI is also shaking things up […]",
        "guid": "https://blog.jetbrains.com/?post_type=datalore&p=492542",
        "isoDate": "2024-07-11T09:54:11.000Z"
      },
      {
        "creator": "Vaclav Pech",
        "title": "The MPS 2024.1 Release Candidate Is Out",
        "link": "https://blog.jetbrains.com/mps/2024/07/the-mps-2023-3-release-candidate-is-out-2/",
        "pubDate": "Thu, 11 Jul 2024 08:58:50 +0000",
        "content:encodedSnippet": "The Release Candidate for MPS 2024.1 is now available for download. Grab it and experience the new functionality before the final 2024.1 release.\nDOWNLOAD MPS 2024.1 RC\nYou can learn about the new features in more detail in this blog post.\nThe full list of fixed issues can be found here.\nYour JetBrains MPS team",
        "dc:creator": "Vaclav Pech",
        "content": "The Release Candidate for MPS 2024.1 is now available for download. Grab it and experience the new functionality before the final 2024.1 release. DOWNLOAD MPS 2024.1 RC You can learn about the new features in more detail in this blog post. The full list of fixed issues can be found here. Your JetBrains MPS team",
        "contentSnippet": "The Release Candidate for MPS 2024.1 is now available for download. Grab it and experience the new functionality before the final 2024.1 release. DOWNLOAD MPS 2024.1 RC You can learn about the new features in more detail in this blog post. The full list of fixed issues can be found here. Your JetBrains MPS team",
        "guid": "https://blog.jetbrains.com/?post_type=mps&p=487916",
        "categories": [
          "releases",
          "release"
        ],
        "isoDate": "2024-07-11T08:58:50.000Z"
      },
      {
        "creator": "Khalid Abuhakmeh",
        "title": "Try Full Line Code Completion in JetBrains Rider 2024.1.4",
        "link": "https://blog.jetbrains.com/dotnet/2024/07/10/full-line-code-completion-in-jetbrains-rider/",
        "pubDate": "Wed, 10 Jul 2024 13:49:11 +0000",
        "content:encodedSnippet": "We recently released the 2024.1 version of all our IDE products, including the dotUltimate family of products: ReSharper, Rider, dotMemory, dotTrace, dotCover, and dotPeek. Full Line Code Completion (FLCC), a local and fast AI model fine-tuned for product-specific programming languages, is one feature you may have heard of in this release. FLCC was released with support for many other languages, but we still feel there’s more work to be done regarding the .NET ecosystem, and that’s where your expertise and feedback are crucial. \nDownload\n                                \nJetBrains Rider 2024.1.4\nIn this post, we’d like to introduce you to FLCC, explain what it is and what it isn’t, and invite you to join our group of early adopters to try it out and provide feedback because you, as valued community members, complete us. Let’s get into it.\nWhat is Full Line Code Completion?\nFull Line Code Completion is an IntelliJ-platform plugin designed to predict the following line of code in the current scope. Predictions use a fine-tuned model for each language to suggest syntactically correct lines. Syntactic accuracy means there’s no chance that FLCC will suggest anything that will be a compilation error in the current scope of your code. Focusing on correctness means more valuable suggestions and less noise in the editor, keeping you in the coding flow.\nIn addition to correctness, FLCC is entirely local, which means all suggestions are processed and presented in the privacy of your development environment. Local also enables offline scenarios for those famous coding sessions on trains, planes, and automobiles. The locality of the models also means suggestions are “blink and you’ll miss it” fast. FLCC speed is another way we help you stay in the flow.\nFinally, the best part of FLCC is that it’s included at no additional cost to current JetBrains IDE subscription holders. Yes, that’s right; it’s part of the core JetBrains IDE experience. \nCheck out our YouTube announcement for a visual summary of FLCC. Developer advocate Paul Everitt explains FLCC in his usual charming way.\n\n\n\n\n\n\nI’d also recommend reading the IntelliJ Full Line Code Completion announcement, as it provides further details for those more curious about the plugin’s inner workings.\nThis sounds great, but what about the JetBrains Rider user community? When do we get access to FLCC? Well… right now!\nTrying out Full Line Code Completion\nWith the 2024.1.4 release of JetBrains Rider, the plugin can be found under the Staff Picks category of the Plugins section or by searching for “Full Line Completion” in the marketplace tab. Install the plugin as you would any other plugin from our JetBrains Marketplace.\n\n\n\n\nYou can verify that the plugin is available and enabled by navigating to “Settings | Editor” and finding the “Code Completion” section. \nIn this section, you’ll see a “Machine Learning-Assisted Completion” group, where you can pre-emptively download the models for each supported language in JetBrains Rider: C#, CSS-like, and JavaScript/TypeScript. Before F# folks ask, we are also researching F# support. C++ support for game developers is also coming soon.\n\n\n\n\nYou can choose which FLCC suggestions are available or disable the feature by checking the appropriate box. For folks on a strict bandwidth budget, you can also change the Download Models setting to ask before downloading any model. Downloading the models you use in your everyday workflow is a breeze. Considering they’re only 100 MB, you can download one or all. Remember, they’re fine-tuned, so they’re small and efficient. \nExamples of Full Line Code Completion\nFLCC works based on the current file and the position of your current cursor, attempting to predict the following line. You don’t have to do anything differently regarding your current workflow and developer habits other than look for suggestions and pick the ones that work best for you.\nAs a usability hint, the more code in the file, the more suggestions will meet your expectations. Here’s an example in a unit testing suite. Each new Assert is predicted by using similarly-scoped tests.\n\n\n\n\nFLCC can use existing patterns in your code to predict what you will do next. The context supercharges FLCC’s predictive powers, especially in opinionated codebases. A framework like ASP.NET Core MVC follows a predictable pattern and is an excellent place for predictive models to help you get to solutions faster.\n\n\n\n\nAs you may have noticed in the previous screenshot, the code completion key is fully customizable to your needs. Hover over the completion and select which key combination you want to use when picking a suggestion. Options include Tab, Right, Enter, Shift + Right, or a custom key combination of your choice.\n\n\n\n\nWhere You Can Help\nAs we mentioned at the beginning of this post, these models continue to undergo fine-tuning to serve our ultimate goal: providing JetBrains Rider users with the best experience possible. Your feedback is not just important; it’s crucial. While these models can feel like magic, they ultimately work on your feedback and insights. You can download newer iterations as these models improve, boosting your productivity.\nDownload\n                                \nJetBrains Rider 2024.1.4\nThe next step for the adventurous and curious is to download the latest version of JetBrains Rider along with the relevant models and try it for yourself. While doing so, tell us what you like and what we could do better. In the section below, let us know if you have any questions or comments.",
        "dc:creator": "Khalid Abuhakmeh",
        "content": "We recently released the 2024.1 version of all our IDE products, including the dotUltimate family of products: ReSharper, Rider, dotMemory, dotTrace, dotCover, and dotPeek. Full Line Code Completion (FLCC), a local and fast AI model fine-tuned for product-specific programming languages, is one feature you may have heard of in this release. FLCC was released with [&#8230;]",
        "contentSnippet": "We recently released the 2024.1 version of all our IDE products, including the dotUltimate family of products: ReSharper, Rider, dotMemory, dotTrace, dotCover, and dotPeek. Full Line Code Completion (FLCC), a local and fast AI model fine-tuned for product-specific programming languages, is one feature you may have heard of in this release. FLCC was released with […]",
        "guid": "https://blog.jetbrains.com/?post_type=dotnet&p=468903",
        "categories": [
          "net-tools",
          "ai",
          "c",
          "rider"
        ],
        "isoDate": "2024-07-10T13:49:11.000Z"
      },
      {
        "creator": "Elena Kerpeleva",
        "title": "Busy Plugin Developers Newsletter – Q2 2024",
        "link": "https://blog.jetbrains.com/platform/2024/07/busy-plugin-developers-newsletter-q2-2024/",
        "pubDate": "Tue, 09 Jul 2024 15:32:54 +0000",
        "content:encodedSnippet": "⭐️ Marketplace updates\nFlexible trial periods for paid plugins\nYou can now customize trial periods for your paid plugins. Instead of the default 30-day trial, you can set a shorter trial period or even none at all. Just select the preferred trial period while uploading your plugin to the Marketplace or, if your plugin is already on the Marketplace, go to the settings and edit the trial period length.\nNote: This feature is available in the IDE starting from the 2024.1.1 release. Anyone using an older version will see outdated trial period information.\nLearn more about this feature in our recent blog post.\nImportant update on plugin download statistics\nAs a plugin author, you might have noticed a recent decrease in your download numbers. This is due to a miscalculation identified by JetBrains Marketplace – no actual decrease occurred. \nIn March 2024, an error started causing inflated download numbers by mistakenly counting certain requests as downloads. We have now adjusted the algorithm to ensure data accuracy. We apologize for any inconvenience this may have caused. \nIf you have any questions or concerns, please reach out to our support team at marketplace@jetbrains.com.\nThe Writerside IDE is now on JetBrains Marketplace\nWriterside, a documentation authoring and building environment aimed at professional technical writers and software developers, is now available on JetBrains Marketplace. It lets you author, preview, build, test, and publish technical documentation for your plugins directly within your favorite IDE. \n\n\n\n\n⭐️ Plugin development tooling updates\nIntelliJ Platform Plugin Template 1.14.1\nThe IntelliJ Platform Plugin Template is a repository that streamlines the initial stages of plugin development for IntelliJ-based IDEs. Key changes in the recent update involve upgrading dependencies, as well as upgrading the platformVersion to 2023.2.7 and Gradle Wrapper to 8.8. Get more insights from the release notes.\nIntelliJ Plugin Verifier 1.367 \nPlugin Verifier Version 1.367 introduces a CLI switch to mute specific plugin problems, distinguishes errors in outputs, shows structure warnings with solution hints, fixes several issues when checking against Platform 2024.2, and adds a YouTrack App plugin structure parser.\nCheck out the changelog for more details.\nIntelliJ Platform Gradle Plugin 2.0 (Beta)\nThe IntelliJ Platform Gradle Plugin is a plugin for the Gradle build system to help configure your environment for building, testing, verifying, and publishing plugins for IntelliJ-based IDEs. The plugin is now 2.0.0-beta8 and available for general use. Users can report bugs or problems via GitHub issues.\nFind all of the details here.\n⭐️ Useful resources\nPlugin Internationalization\nTwo new articles cover plugin internationalization possibilities. The Internationalization page describes how to enable national language support (NLS) in IntelliJ-based IDEs and plugins, implement message bundles, and organize translations. \nThe Providing Translations article explains how to provide translations for IntelliJ Platform products and plugins through language packs and bundled translations, detailing the structure, implementation, and prioritization of translation files.\nCode Formatter\nA reworked Code Formatter page describes how to implement custom language formatters in the IntelliJ Platform, including the structure of formatting blocks, implementation steps, and specific formatting properties like indent, spacing, wrap, and alignment.\nIndexing and PSI Stubs: DumbAware API﻿\nA new addition to the Indexing and PSI Stubs article covers the implementation and testing of the DumbAware API, which enables certain extension points and actions to function during Dumb Mode in the IntelliJ Platform.\n⭐️ Community highlights\nTop plugin picks by JetBrains product teams\nRecently, we introduced an application process for plugin authors, providing a chance to be featured in JetBrains Marketplace’s Staff Picks.\nAll applications were carefully reviewed, and our product teams selected a handful of plugins based on their utility and impact. You can check out this blog post for some of the selected plugins or see the full list here.\nThe Staff Picks list is updated with each IDE release cycle. Releases take place in April, July, and November. Feel free to apply to have your own plugin featured.\nNew People Behind Plugins video\nWatch our latest interview with Yuna Morgenstern, author of the GitHub Workflow plugin. Yuna shares how she came up with the idea for the plugin and what inspires her to be an active member of the community. Learn about her journey, contributions to open-source, and how she manages her own pet projects and teaches kids to code.\nWould you like to nominate someone, or do you have a story to share? Email us at marketplace@jetbrains.com.",
        "dc:creator": "Elena Kerpeleva",
        "content": "⭐️ Marketplace updates Flexible trial periods for paid plugins You can now customize trial periods for your paid plugins. Instead of the default 30-day trial, you can set a shorter trial period or even none at all. Just select the preferred trial period while uploading your plugin to the Marketplace or, if your plugin is [&#8230;]",
        "contentSnippet": "⭐️ Marketplace updates Flexible trial periods for paid plugins You can now customize trial periods for your paid plugins. Instead of the default 30-day trial, you can set a shorter trial period or even none at all. Just select the preferred trial period while uploading your plugin to the Marketplace or, if your plugin is […]",
        "guid": "https://blog.jetbrains.com/?post_type=platform&p=491644",
        "categories": [
          "marketplace",
          "news",
          "busy-plugin-developers"
        ],
        "isoDate": "2024-07-09T15:32:54.000Z"
      },
      {
        "creator": "Garth Gilmour",
        "title": "Enhanced Column Selection DSL in Kotlin DataFrame",
        "link": "https://blog.jetbrains.com/kotlin/2024/07/enhanced-column-selection-dsl-in-kotlin-dataframe/",
        "pubDate": "Tue, 09 Jul 2024 15:26:52 +0000",
        "content:encodedSnippet": "Introduction\nThe Kotlin DataFrame library makes extracting values from structured data an easy task. As discussed in our documentation, there are four separate APIs that can be used for this purpose, with the optimal choice depending on your individual situation and requirements. \nTo demonstrate, let’s read in a JSON document containing information about users:\nval rawUserData = DataFrame.read(\"https://dummyjson.com/users\")\n   .getFrameColumn(\"users\")\n   .first()\n\nrawUserData.select { cols(0..2) }.head(3)\nThe final line selects the first three columns from the first three rows (for illustration purposes only):\n\n\n\n\nDon’t worry about how the final line works just yet – we’ll get to that later.\nHaving obtained our sample data, let’s now extract some values. In the example below, you:\nTake the last five users as strongly typed DataRow objects, using the tail operation.\nCapture each user’s name four times, using a different API each time.\nPrint the captured values, so you can be sure that they’re identical.\ndata class Person(val firstName: String)\n\nrawUserData.tail().forEach {\n   val name1 = firstName               // Extension Properties API\n   val name2 = \"firstName\"<String>()   // String API\n   val firstName by column<String>()   // Column Accessors API\n   val nameRef = Person::firstName     // KProperties API\n  \n   println(\"$name1 $name2 ${firstName()} ${this[nameRef]}\")\nThis should be the resultant output:\nEvelyn Evelyn Evelyn Evelyn\nDaniel Daniel Daniel Daniel\nLily Lily Lily Lily\nHenry Henry Henry Henry\nAddison Addison Addison Addison\nImpressive as this is, selecting individual values is not enough for real world scenarios. When using functions like select, remove, or update, you will typically need to select values from multiple columns. \nThese columns might all be at the top level, but when dealing with hierarchical data (like JSON), you’ll need to select columns from within nested column groups. This functionality is provided by the Columns Selection DSL.\nThe DataFrame library has always had a DSL for selecting multiple (potentially nested) columns, but in this release, we’ve added new functions and improved the overall syntax and readability. \nAn initial example of selection\nIn the example below, you:\nSelect the firstName column.\nUse the and operator to combine this column with further selections.\nAccess the nested data within the address column.\nUse the cols function to select multiple columns from the nested data.\nOnly keep the final five records via tail.\nrawUserData.select {\n   firstName and address.cols(\"city\", \"state\")\n}.tail()\nAs you can see from the results, you can use the and operator to select multiple columns individually, and the cols function to select multiple columns in one go.\n\n\n\n\nSelecting by index\nColumns can also be selected by index, with the first column having an index of zero. The code below would give you the same result:\nrawUserData.select {\n   firstName and address.cols(1, 2)\n}.tail()\nIf you were to include the column with index zero, then the results would include the street number and name. You could list the three indexes individually, but a range is more convenient:\nrawUserData.select {\n   firstName and address.cols(0..2)\n}.tail()\nThese would be the results:\n\n\n\n\nSelecting based on a predicate\nThe value passed to cols can also be a lambda. This allows you to select columns based on an arbitrary predicate – typically involving their name or content. Let’s look at two examples.\nThis first example selects all columns whose name ends with “Name”:\nrawUserData.select {\n   cols { it.name.contains(\".+Name\".toRegex()) }\n}.tail()\nAs you can see, this gives us three results:\n\n\n\n\nThe second example selects all columns whose values contain either the word “Lee” or the number 31.\nrawUserData.select {\n   cols { \"Lee\" in it.values() } and\n   cols { 31 in it.values() }\n}.tail()\nAs is visible below, this gives us two columns:\n\n\n\n\nHandling nested data\nWhat if you want to search within nested data? The function isValueColumn returns true if a column contains regular data. Otherwise the column is a column group or a frame column.\nThis test can be repeated recursively to descend the hierarchy. That sounds like a lot of work, but fortunately the library provides a colsAtAnyDepth function that handles the recursion for you. Let’s look at some examples.\nIn the code below, you select columns from anywhere in the column group hierarchy that contain regular data and have a name of length six:\nrawUserData.select {\n   colsAtAnyDepth {\n       it.name.length == 6 && it.isValueColumn()\n   }\n}.tail()\nThese are the results:\n\n\n\n\nUnfortunately, this code contains a bug. You cannot have multiple columns with the same name in the results. For example let’s say you search for columns of length four:\nrawUserData.select {\n   colsAtAnyDepth {\n       it.name.length == 4 && it.isValueColumn()\n   }\n}.tail()\nThe results will include two columns called “city” – one from the column group describing the user’s address, and the other from the column group describing the address of the company the user works for. This duplication will cause an exception to be raised:\nDuplicate column names: [city]\n\nAll column names: [type, city, iban, name, city, coin, role]\norg.jetbrains.kotlinx.dataframe.exceptions.DuplicateColumnNamesException: Duplicate column names: [city]\nThe solution is to create a new version of the data, where the column names encode the full path down the hierarchy:\nval renamedUserData = rawUserData.rename {\n   colsAtAnyDepth()\n}.into { it.path.joinToString(\".\") }\nYou can query this new data to see how the column names have changed:\nrenamedUserData.select {\n   colsAtAnyDepth()\n}.columnNames().forEach(::println)\nFor example, these are the columns relating to the address of the user:\naddress\naddress.address\naddress.city\naddress.state\naddress.stateCode\naddress.postalCode\naddress.coordinates\naddress.coordinates.lat\naddress.coordinates.lng\naddress.country\nIf you now select columns you will need to split up the column name:\nrenamedUserData.select {\n   colsAtAnyDepth {\n       val isLength6 = it.name.split(\".\").last().length == 6\n       isLength6 && it.isValueColumn()\n   }\n}.tail()\n\n\n\n\nThe benefit is that searching by length 4 no longer produces an exception:\nrenamedUserData.select {\n   colsAtAnyDepth {\n       val isLength4 = it.name.split(\".\").last().length == 4\n       isLength4 && it.isValueColumn()\n   }\n}.tail()\n\n\n\n\nNote that colsAtAnyDepth replaces the dfs and recursively functions, which have now been deprecated and removed.\nProcessing data by column order\nMost of the specificities of Column Selection DSL will be intuitive to folks who have experience with SQL. However, there is one area that might catch them off guard. Unlike in relational database theory (RDT), the order of the columns in a DataFrame is significant, and can be used in queries.\nWe already saw this with the example of indexing, but ordering can be used in many ways. Let’s try to find all of the top-level columns whose name begins with the letter “i”:\nrawUserData.select {\n   cols {\n       it.name.startsWith(\"i\")\n   }\n}.tail()\nYou can see that there are three such columns:\n\n\n\n\nUnlike in SQL, it’s meaningful to ask which column comes first:\nrawUserData.select {\n   first {\n       it.name.startsWith(\"i\")\n   }\n}.tail()\n\n\n\n\nBy that logic, it’s also meaningful to ask which column comes last:\nrawUserData.select {\n   last {\n       it.name.startsWith(\"i\")\n   }\n}.tail()\n\n\n\n\nYou can even traverse across the columns, selecting all columns until a specified one is reached or a condition is met. In the example below you select all columns until you encounter the first one whose name starts with “e”:\nrawUserData.select {\n   allUpTo {\n       first {\n           it.name.startsWith(\"e\")\n       }\n   }\n}.tail()\nIn our sample data, this is the column named “email”:\n\n\n\n\nAdditional helper functions\nThere are a number of helper functions you can explore, which simplify common scenarios. Let’s explore three examples.\nThe valueCols function \nThis function only selects value columns. That means we can take this earlier example:\nrawUserData.select {\n   cols {\n       it.name.length == 6 && it.isValueColumn()\n   }\n}.tail()\nAnd simplify it into:\nrawUserData.select {\n   valueCols {\n       it.name.length == 6\n   }\n}.tail()\nBoth will produce the following results:\n\n\n\n\nIf you did not exclude nested data, then the users cryptocurrency information will be included as well:\nrawUserData.select {\n   cols {\n       it.name.length == 6\n   }\n}.tail()\n\n\n\n\nThe colsOfKind function\nThis function lets you select any combination of group, frame, and value columns. If you only wanted to find the names of the group columns you could do this:\nrawUserData.select {\n   colsOfKind(ColumnKind.Group)\n}.first().run {\n   columnNames().forEach(::println)\n}\nIn which case, the results are:\nhair\naddress\nbank\ncompany\ncrypto\nAlternatively, you could select group and value columns like this:\nrawUserData.select {\n   colsOfKind(ColumnKind.Group, ColumnKind.Value)\n}.first().run {\n   columnNames().forEach(::println)\n}\nBecause the scope of the query is wider, more results will be selected:\naddress\nmacAddress\nuniversity\nbank\ncompany\nein\nssn\nuserAgent\ncrypto\nrole\nThe colsOf function\nIn the DataFrame library every column created infers its type based on the data inside. This being the case, you can select columns based on the type of data they contain:\nrawUserData.select {\n   colsOf<Int>()\n}.tail()\nIn this example, the top level data contains two columns holding integer values:\n\n\n\n\nThe colsOf function is polymorphic, meaning that it will select columns whose data type is a subtype of the type you specify. For example, if you specify Number as the type, then columns containing both integer and floating-point values will be selected. \nrawUserData.select {\n   colsOf<Number>()\n}.tail()\nIn this case, that gives us an additional two columns:\n\n\n\n\nIf you wanted, you could create a new version of the data, where all numeric values were doubles. This could be achieved as follows:\nval convertedUserData = rawUserData.convert {\n   colsAtAnyDepth().colsOf<Number>()\n}.toDouble()\nNow, selecting the integer columns would give us no results, whereas selecting all the doubles would give us four:\nconvertedUserData.select {\n   colsOf<Double>()\n}.tail()\n\n\n\n\nOperators and subtracting columns\nThe square brackets operator can be used as a shortcut for the cols function. Consider the following example:\nrawUserData.select {\n   bank.cols {\n       it.name.startsWith(\"card\")\n   }\n}.tail()\nThis selects the nested data within the “bank” column, specifically all those columns whose name starts with “card”:\n\n\n\n\nYou can achieve the same result using the operator as follows:\nrawUserData.select {\n   bank[{ it.name.startsWith(\"card\") }]\n}.tail()\nWhich syntax you prefer is a matter of personal preference, but consistency is recommended to avoid confusing your code’s maintainers.\nIt’s also possible to select columns by subtraction, rather than addition. To show this, let’s create a simpler data set:\nval employeeData = rawUserData.mapToFrame {\n   \"name\" from { \"$firstName $lastName\" }\n   university into \"education\"\n   \"employment\" from { \"${company.title} at ${company.name}\" }\n   +birthDate\n   +email\n}.tail()\nThis gives us the following values:\n\n\n\n\nYou already know how to specify which columns you want:\nemployeeData.select {\n   cols(name, employment, birthDate)\n}\nBut it’s also possible to obtain the same result by specifying which columns you wish to leave out:\nemployeeData.select {\n   allExcept(email, education)\n}.tail()\nBoth of these examples give the following result:\n\n\n\n\nSubtraction can be used when working with nested data. In the example below, you return to the original data set and select the user’s first name and all elements of their address with three exceptions:\nrawUserData.select {\n   firstName and\n   address.allColsExcept {\n       cols(coordinates, stateCode, postalCode)\n   }\n}.tail()\n\n\n\n\nInteractive grammars\nAs you can see, there’s a huge amount of functionality within the Column Selection DSL. When you first encounter the library, it’s easy to be confused by both the number of operations and the different ways in which they can be combined. \nTo assist with this, we now provide grammars for each function in the associated KDocs. You might have encountered these grammars on the website already, but in KDocs, they’re fully interactive!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConclusions\nHopefully this blog has given you some insight into the power and versatility of the Column Selection DSL. This latest (0.13.1) update brings a more organized and consistent way to select columns with detailed and interactive documentation. All examples from this article are available as a Kotlin Notebook on GitHub. \nAs always, we’re keen to receive feedback on our products, and what areas could be extended or improved. You can find more information about column selectors on this page of our Kotlin DataFrame documentation site. Each function is introduced with examples and explanations, which is a great way to get an overview of what’s possible. Happy coding!",
        "dc:creator": "Garth Gilmour",
        "content": "Introduction The Kotlin DataFrame library makes extracting values from structured data an easy task. As discussed in our documentation, there are four separate APIs that can be used for this purpose, with the optimal choice depending on your individual situation and requirements.&#160; To demonstrate, let’s read in a JSON document containing information about users: The [&#8230;]",
        "contentSnippet": "Introduction The Kotlin DataFrame library makes extracting values from structured data an easy task. As discussed in our documentation, there are four separate APIs that can be used for this purpose, with the optimal choice depending on your individual situation and requirements.  To demonstrate, let’s read in a JSON document containing information about users: The […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=487668",
        "categories": [
          "ecosystem",
          "data-analysis",
          "dataframe",
          "notebooks"
        ],
        "isoDate": "2024-07-09T15:26:52.000Z"
      },
      {
        "creator": "Dmitry Romanov",
        "title": "DataGrip User Experience Survey",
        "link": "https://blog.jetbrains.com/datagrip/2024/07/09/datagrip-user-experience-survey/",
        "pubDate": "Tue, 09 Jul 2024 13:58:48 +0000",
        "content:encodedSnippet": "Hello, DataGrip community!\nAt JetBrains, delivering an excellent user experience is always a top priority. Today, we’re launching a survey to gather your feedback and explore how we can make DataGrip even better. \nPlease take a few minutes to complete the DataGrip User Experience Survey. Your input will help us prioritize future improvements. \nAs a thank you for your time, you’ll have a chance to win one of five $100 Amazon Gift Cards or a one-year All Products Pack subscription. We’ll randomly pick the winners from among the questionnaires that are filled out completely with meaningful answers. Remember to enter your contact details to be eligible for the raffle.\nTake the DataGrip UX survey\nThank you for your time and effort!\nThe DataGrip team",
        "dc:creator": "Dmitry Romanov",
        "content": "Hello, DataGrip community! At JetBrains, delivering an excellent user experience is always a top priority. Today, we&#8217;re launching a survey to gather your feedback and explore how we can make DataGrip even better. Please take a few minutes to complete the DataGrip User Experience Survey. Your input will help us prioritize future improvements. As a [&#8230;]",
        "contentSnippet": "Hello, DataGrip community! At JetBrains, delivering an excellent user experience is always a top priority. Today, we’re launching a survey to gather your feedback and explore how we can make DataGrip even better. Please take a few minutes to complete the DataGrip User Experience Survey. Your input will help us prioritize future improvements. As a […]",
        "guid": "https://blog.jetbrains.com/?post_type=datagrip&p=491646",
        "categories": [
          "survey",
          "datagrip",
          "ux"
        ],
        "isoDate": "2024-07-09T13:58:48.000Z"
      },
      {
        "creator": "Regina Muradova",
        "title": "JetBrains Academy: New in July",
        "link": "https://blog.jetbrains.com/education/2024/07/09/jetbrains-academy-new-in-july/",
        "pubDate": "Tue, 09 Jul 2024 12:15:07 +0000",
        "content:encodedSnippet": "This July, we’ve made some improvements to our courses to better serve your learning needs, added certificates for two more courses, and introduced new learning topics. \nLet’s take a closer look at these updates.\nUpdated courses\nOur courses have been restructured to align with the latest job requirements. We’ve incorporated real interview questions and regularly revise our content to help you stay up to date with constantly evolving technologies.\nData Analyst\nData analysts play a crucial role in today’s data-driven world, helping companies make informed decisions and optimize performance. If you are eager to use large amounts of data to reveal meaningful insights, this career path might be right for you. \nIn this course you’ll gain data analysis skills, which are essential for solving complex problems in a data analyst role, with a focus on data handling and decision-making. \nThe Data Analyst course gives you a better understanding of how to work with data and strengthens your SQL skills so you can feel more confident in an interview.\nData Scientist\nIn this course, we’ll give you the foundational knowledge that every data scientist needs. We will show you the world of classic machine learning with models like linear and logistic regression, decision trees, model compositions, and much more, while also familiarizing you with more modern methods based on neural networks. Additionally, you will strengthen your data manipulation skills with advanced SQL queries.\nDevOps Engineer with AI\nThis course offers hands-on training to become a proficient DevOps engineer. You’ll learn critical DevOps principles, CI/CD processes, configuration management, and the integration of AI technologies. This training equips you to manage and automate the entire software lifecycle.\nNLP Engineer\nDeepen your understanding of natural language processing (NLP) with our advanced course. You’ll gain a solid understanding of fields like machine translation, chatbot systems, automatic question answering, and sentiment analysis. \nNew certificates available\nWe are excited to announce certificates for two courses: Introduction to Go and SQL for Data Analysis. Earn your certificate upon completing these courses and showcase your expertise to potential employers.\n\n\n\n\nNew learning topics\nData Science: Overview of Streamlit\nJavaScript: Testing frameworks introduction\nPython: Integer arithmetic: special operations\nGenerative AI: Combining prompting techniques, Self-evaluation and refine prompting\nWe hope that you find these updates valuable and that they enhance your learning experience. Your feedback and suggestions are welcome, so please don’t hesitate to get in touch with us at academy@jetbrains.com or share your thoughts with us on LinkedIn, X (formerly Twitter), or Facebook.\nHappy learning!\nYour JetBrains Academy team",
        "dc:creator": "Regina Muradova",
        "content": "This July, we&#8217;ve made some improvements to our courses to better serve your learning needs, added certificates for two more courses, and introduced new learning topics.  Let’s take a closer look at these updates. Updated courses Our courses have been restructured to align with the latest job requirements. We&#8217;ve incorporated real interview questions and regularly [&#8230;]",
        "contentSnippet": "This July, we’ve made some improvements to our courses to better serve your learning needs, added certificates for two more courses, and introduced new learning topics.  Let’s take a closer look at these updates. Updated courses Our courses have been restructured to align with the latest job requirements. We’ve incorporated real interview questions and regularly […]",
        "guid": "https://blog.jetbrains.com/?post_type=education&p=491699",
        "categories": [
          "jetbrains-academy",
          "learning-courses",
          "project-based-learning",
          "data-analysis",
          "data-science",
          "devops",
          "online-learning"
        ],
        "isoDate": "2024-07-09T12:15:07.000Z"
      }
    ]
  },
  {
    "name": "Airbnb Engineering & Data Science",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Instagram Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "PayPal Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "article New updates to Planner comment notifications and settings in Planner Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Visual Studio Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Jim Harrer",
        "title": "Get Hands-On with Visual Studio and Azure: Live at Microsoft HQ this August!",
        "link": "https://devblogs.microsoft.com/visualstudio/visual-studio-live-2024-microsoft-hq/",
        "pubDate": "Mon, 15 Jul 2024 14:45:58 +0000",
        "content:encodedSnippet": "Visual Studio LIVE! Microsoft HQ 2024\nAugust 5-9 | Microsoft Conference Center, Redmond, WA\nThere’s still time to register, join us, get your questions answered, and bring back a wealth of knowledge and excitement to your teams! We’re close to selling out for next month’s conference, which will be packed with valuable sessions and activities, hosted on campus at the Microsoft Conference Center in Redmond, WA.\nVisual Studio LIVE! 2024 is not just another conference; it’s a celebration of innovation, learning, and community. Here are some key highlights and reasons why you should attend:\nDiscover the Latest Innovations in Visual Studio, .NET, Azure, and GitHub\nJoin us to dive deep into the latest capabilities across Visual Studio, Azure, GitHub, and the marvels of GitHub Copilot. This event offers an immersive experience with 35 speakers, including 20 from Microsoft, and 71 sessions spread over 13 tracks. Whether you’re a seasoned developer or just starting, there’s something for everyone.\nKeynote Sessions at Visual Studio LIVE! 2024\nKeynote by Scott Hunter: Introducing .NET Aspire – Cloud Native Development for .NET\nOne of the most anticipated sessions is Scott Hunter’s keynote on “Introducing .NET Aspire – Cloud Native Development for .NET.” .NET Aspire, which shipped during the Microsoft Build conference, transforms .NET into a modern cloud-native framework with support for Observability, Resiliency, Scalability, and Manageability. This keynote will show how to transform an existing application, demonstrate the new telemetry dashboard, create local resources and resources in the cloud, and run and deploy multi-part apps from the command line, VS Code, and Visual Studio. Don’t miss this opportunity to learn about our most exciting release in years!\nKeynote by Asad Khan and Bob Ward: Building Applications with the Modern SQL Using AI and Microsoft Fabric\nAnother must-see session is the keynote by Asad Khan and Bob Ward on “Building Applications with the Modern SQL Using AI and Microsoft Fabric.” This session will cover the latest advancements in SQL products and services, showcasing how AI and Microsoft Fabric can enhance your applications and improve efficiency. Gain valuable insights from industry leaders on how to leverage these cutting-edge technologies to build powerful, modern applications.\nUnique Networking Opportunities\nVisual Studio LIVE! 2024 is designed to be intimate, with attendance capped at just 500. This setup provides you with unparalleled access to mingle directly with our speakers and product managers from Visual Studio, Azure, and GitHub. Engage in meaningful interactions and gain insights directly from the experts.\nMeet The Experts Welcome Reception: On Tuesday (8/6) from 4:15 pm to 5:45 pm, join us for a casual expo-style event with food, beverages, and raffles. Meet Product Managers from Visual Studio, .NET, Azure, GitHub, and GitHub Copilot.\nMeet The Visual Studio & .NET Team Reception: On Thursday (8/8) from 4:15 to 5:45 pm, connect with the actual tool makers of .NET Aspire & Blazor, GitHub Copilot Integration in Visual Studio, VS Extensibility, C# Dev Kit for VS Code, and more. Discuss specific features and get direct feedback from the developers who build these tools.\n\nExclusive Access and Benefits\nAttendees will enjoy VIP access to the Microsoft Commons—a bustling hub of retail, dining, and entertainment exclusive to Microsoft employees. Additionally, you’ll receive passes to the Microsoft Employee Store, where you can score exclusive deals on the latest Microsoft products.\nTwo Full Days of Hands-On Labs\nGo deeper into development topics with these excellent hands-on labs:\nApplication Building with .NET Aspire & ASP.NET Core 8 by Damian Edwards and David Fowler. Build distributed applications using the .NET Aspire stack and ASP.NET Core 8, covering new features in .NET 8 & C# 12.\nAsynchronous and Parallel Programming in C# by Jeremy Clark. Master asynchronous programming in C# using the .NET Task Parallel Library (TPL) and learn techniques for running code in parallel.\nElevate Your Career with Python and AI by Eric D. Boyd. A two-day workshop starting with Python basics and advancing to AI and machine learning applications.\nBuild Modern Applications with Azure SQL Database and SQL Server by Jerry Nixon and Brian Spendolini. Deep dive into new features of Azure SQL and SQL Server, including JSON, Data API builder, REST endpoints, and ChatGPT/OpenAI.\nMicrosoft Blazor Top to Bottom by Jason Bock, Allen Conway, and Rockford Lhotka. Learn to build Blazor apps, use the Razor component model, data and event binding, and explore Blazor server, WebAssembly, and MAUI hybrid apps.\nFor the full list of hands-on labs, visit Visual Studio LIVE! 2024 Hands-On Labs.\nSome of your favorite speakers from Visual Studio & .NET\nMads Kristensen: Visual Studio Tips & Tricks and Your Future is Bright with Visual Studio and AI\nJames Montemagno: What’s New & Next for .NET MAUI\nDaniel Roth: What’s Next for ASP.NET Core & Blazor\nHarshada Hole: Fast Focus: Visual Studio Debugging & Diagnostics: Tips & Tricks\nJessie Houghton: Fast Focus: Upgrade Your Git Game in Visual Studio 2022\nDalia Abo Sheasha: Lessons Learned Building AI-powered Features in Visual Studio\nRachel Kang: What’s New & Next for .NET MAUI\nClick here for our complete list of amazing speakers, 31 in all!\nLearn from the Best\nThe event will feature over 70 sessions, including hands-on labs and workshops, covering both introductory and advanced topics. This is your chance to accelerate your understanding of the latest technologies and bring back valuable knowledge to your team.\nHear from Past Attendees\nDon’t just take our word for it. Here’s what past attendees have to say about Visual Studio LIVE!:\n“The best thing about VS Live! was meeting Microsoft people.”\n“The conference events and the reception sponsored by Microsoft were outstanding!”\n“Learning about the direction of technology and Microsoft, and what others in the industry are doing, was invaluable.”\n“Access to Microsoft staff and demonstrations of AI techniques by Microsoft presenters was a major highlight.”\n“I appreciated the variety of courses and the expertise of the speakers and Microsoft reps.”\nRegister Now and Save\nVisual Studio Professional & Enterprise Subscribers can unlock exclusive discounts by exploring your discount benefit on My.VisualStudio.com. Not a subscriber? No problem—grab the EARLY BIRD Discount on the Visual Studio Live! Event Page. Only 500 spots are available for this exclusive event, and we expect it to sell out, so don’t delay!\nWe look forward to seeing you at Visual Studio LIVE! 2024. Secure your spot now for an unforgettable week of learning, networking, and technological innovation.\nLEARN MORE\n\nThe post Get Hands-On with Visual Studio and Azure: Live at Microsoft HQ this August! appeared first on Visual Studio Blog.",
        "dc:creator": "Jim Harrer",
        "content": "<p>Visual Studio LIVE! Microsoft HQ 2024<br />\nAugust 5-9 &#124; Microsoft Conference Center, Redmond, WA<br />\nThere’s still time to register, join us, get your questions answered, and bring back a wealth of knowledge and excitement to your teams! We’re close to selling out for next month’s conference,</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/visual-studio-live-2024-microsoft-hq/\">Get Hands-On with Visual Studio and Azure: Live at Microsoft HQ this August!</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "Visual Studio LIVE! Microsoft HQ 2024\nThe post Get Hands-On with Visual Studio and Azure: Live at Microsoft HQ this August! appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=249749",
        "categories": [
          "Events",
          "Visual Studio",
          ".NET"
        ],
        "isoDate": "2024-07-15T14:45:58.000Z"
      }
    ]
  },
  {
    "name": "Instagram Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Dropbox Tech Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "\r\n                            Binoy Dash,Bradley Crossen,Eric Cunningham,Royce Ausburn,Tejas Patel\r\n            \t\t\t",
        "title": "Bringing AI-powered answers and summaries to file previews on the web",
        "link": "https://dropbox.tech/machine-learning/bringing-ai-powered-answers-and-summaries-to-file-previews-on-the-web",
        "pubDate": "Thu, 11 Jul 2024 07:00:00 -0700",
        "content:encodedSnippet": "Dropbox offers a handful of features that use machine learning to understand content much like a human would. For example, Dropbox can generate summaries and answer questions about files when those files are previewed on the web. Instead of asking a coworker for the gist of last week’s all-hands meetings, Dropbox can provide a summary of the video and a user can ask questions about its contents—all from the file preview. We recently expanded AI-powered summarization and Q&A to handle multiple files simultaneously, too. \n(As part of our commitment to responsibly using AI, Dropbox abides by a set of AI principles; you can visit our Help Center to learn more. These features are still in early access, and not yet available to all users. These features are also optional, and can be turned on or off for you or your team.)\nBoth our summarization and Q&A features leverage large language models (LLMs) to find, compare, and consolidate the content of the file. An LLM works by ingesting content as text, transforming the ideas contained within it into a numerical representation, and comparing those numerical representations against both the input query and an internal corpus of knowledge to answer the question. This effectively enables a computer to consume and compare information semantically, rather than lexically.\nFor knowledge workers suffering from information overload, we can use machine learning to get them the answers they need—without them having to remember exactly how a piece of information was worded, or where it might be contained within a file. This is what we’ve done with file previews on the web.\n\r\n\r\n    \n Extracting text and embeddings with Riviera\n\r\n\r\n\n\nThe first part of this process is, of course, retrieving the text. Luckily, we already have a framework for transforming basically any file type to text.\nDropbox is capable of turning complex file types like CAD drawings into formats that are easily consumable by web browsers, such as PDF. Historically we have used this system for file previews, but we also use it to power features like transcription and Dropbox Replay. Internally, we call this system Riviera. \nAt a high level, Riviera consists of a frontend which routes requests through one or more plugins that convert a file from one type to another. Each plugin runs in a jail, which is a container designed to run third party code and tools safely and in an isolated manner. The framework maintains a graph of possible conversions, and is capable of chaining together multiple plugins into a multi-step pipeline to perform even more complex transformations. We currently support conversions between about 300 file types, and the system crunches through about 2.5 billion requests—totalling nearly an exabyte, or one billion gigabytes of data—per day.\nIn order to apply machine learning to file previews, the conversions we are interested are those that convert any file type to raw text. In the case of video, text extraction might looks something like:\n\r\n\r\n\r\n\r\n\r\n\n\r\n\r\n\r\n    \r\n        Copy\r\n    \r\n    \nVideo (.mp4) -> Audio (.aac) -> Transcript (.txt)\n\r\n\r\n\r\n\r\n\n\r\n\n\nSome of the conversions in Riviera can be quite expensive to compute on-the-fly, so it also includes a sophisticated caching layer that allows us to reuse conversions between plugins. Each state of the pipeline is cached, so intermediate states can be reused.\nIn the world of LLMs, the mathematical representation of the semantic meaning of text is called the embedding. Riviera treats embeddings like any other file conversion, so in the pipeline above, we can append:\n\r\n\r\n\r\n\r\n\r\n\n\r\n\r\n\r\n    \r\n        Copy\r\n    \r\n    \nVideo (.mp4) -> Audio (.aac) -> Transcript (.txt) -> AIEmbedding\n\r\n\r\n\r\n\r\n\n\r\n\n\nBy separating the embedding generation from the actual summary generation we can reuse the cache features built into Riviera. If a user wants to summarize a video, then ask some follow-up questions, we only have to generate the transcript and embeddings once.\n\r\n\r\n\r\n\r\n\r\n\n\r\n\r\n\r\n    \r\n        Copy\r\n    \r\n    \nVideo (.mp4) -> Audio (.aac) -> Transcript (.txt) -> AIEmbedding --> Summary\r\n                                                                 |\r\n                                                                 --> Q&A \n\r\n\r\n\r\n\r\n\n\r\n\n\nThe input for the embeddings plugin typically consists of text data extracted from various file types such as documents, videos, or audio files. In the case of video content, for example, the plugin may receive the transcript generated from the audio track of the video.\nThe process of converting text into embeddings involves using advanced language models that take the text input and produce a vector representing that text. In our implementation, we split the text into paragraph-sized chunks and calculate an embedding for each chunk. By doing this, we effectively increase the granularity of the information stored within a file. Instead of having just a single embedding for an entire file, we have multiple embeddings for different sections of the text. This higher granularity, or bit depth, allows us to capture more detailed and nuanced information. We apply the same chunking and embedding method for both summaries and Q&A, ensuring they share the same embedding cache within Riviera.\nWhile the actual LLM processing happens inside the summary and Q&A plugins, treating embeddings, summaries, and queries as file conversions inside Riviera allows us to operate these features at Dropbox scale.\n\r\n\r\n    \r\n        \r\n            \r\n    \r\n\r\n        \r\n\r\n        \r\n        \r\n        \r\n\r\n        \r\n        \r\n        \r\n\r\n        \r\n        \r\n\r\n        \r\n        <!-- <img data-sly-test.highRes=\"\"\r\n             srcset=\"/cms/content/dam/dropbox/tech-blog/en-us/2024/07/ai-file-previews/aifilepreviews-diagram-riviera_2x.png 2x, /cms/content/dam/dropbox/tech-blog/en-us/2024/07/ai-file-previews/aifilepreviews-diagram-riviera_2x.png.transform/half-res/img.png 1x\"\r\n             src=\"/cms/content/dam/dropbox/tech-blog/en-us/2024/07/ai-file-previews/aifilepreviews-diagram-riviera_2x.png\"\r\n             aria-hidden=\"\"\r\n             alt=\"\"\r\n             class=\"\"\r\n             data-sly-attribute.width=\"720\"\r\n             data-sly-attribute.height=\"673\"\r\n             data-aem-asset-id=\"46057bbc-1606-440d-85d8-9f203ed86c1d:aifilepreviews-diagram-riviera_2x.png\"\r\n             data-trackable=\"true\" />\r\n        <img data-sly-test.highRes=\"true\"\r\n             srcset=\"/cms/content/dam/dropbox/tech-blog/en-us/2024/07/ai-file-previews/aifilepreviews-diagram-riviera_2x.png 2x, /cms/content/dam/dropbox/tech-blog/en-us/2024/07/ai-file-previews/aifilepreviews-diagram-riviera_2x.png.transform/half-res/img.png 1x\"\r\n             src=\"/cms/content/dam/dropbox/tech-blog/en-us/2024/07/ai-file-previews/aifilepreviews-diagram-riviera_2x.png\"\r\n             aria-hidden=\"\"\r\n             alt=\"\"\r\n             class=\"\"\r\n             data-sly-attribute.width=\"720\"\r\n             data-sly-attribute.height=\"673\"\r\n             data-aem-asset-id=\"46057bbc-1606-440d-85d8-9f203ed86c1d:aifilepreviews-diagram-riviera_2x.png\"\r\n             data-trackable=\"true\" /> -->\r\n\r\n        \r\n         \r\n        \r\n    \r\n\r\n            \nThe high level architecture of our file previews surface, with new machine learning components highlighted\n\r\n        \r\n    \r\n\n\r\n\r\n    \n The summarization plugin\n\r\n\r\n\n\nA common use case for LLMs is to concisely summarize large amounts of text. When negotiating a contract, for example, a person might copy the text from a contract PDF, paste it into an LLM-powered chat prompt, and ask the LLM to summarize it in understandable terms. While adding this feature into Dropbox may have been useful as-is, we decided that we didn’t want to stop there. Dropbox users store long documents, videos, and other rich media files in Dropbox, and a summarization feature only gets more useful as the length of the file increases. We wanted to unlock this feature for all of our users' files, no matter the format or length.\nFirst, we needed to define the qualities of a good summary. A contract to purchase a home might include many different concepts. There might be a long description of payment terms, wire instructions, good-faith deposits, and escrow accounts. It also might have a long description of contingencies and when they can be triggered. A good summary might simply say “this document is an agreement to purchase a home for X amount, and it has finance and inspection contingencies.” In other words, we defined a good summary as one that can identify all the different ideas or concepts in a document and give the reader the gist of each.\nLanguage models enable this to be implemented algorithmically using embeddings, which allow passages to be compared semantically. King and Queen might be relatively close together (they are both regal), King and Dog might be somewhere in the middle (they are both living beings, perhaps), while King and Toaster have very little in common. Language model embeddings allow us to compare passages on thousands of dimensions that are all learned through a long training process. These embeddings in turn enable efficient summarization of large files of essentially unlimited length. \nOur summarization plugin takes the chunks and associated embeddings from the embeddings plugin and uses k-means clustering to group the text chunks from the file into clusters in this multi-dimensional embedding space. With this method, we can organize data into distinct groups, or clusters, based on their characteristics, so that chunks with similar content are placed in the same cluster. We then identify major clusters (the main ideas of the file) and concatenate a representative chunk from the corresponding text from each cluster into one blob—the context. Finally, we generate a summary of that context via an LLM.\nWe found k-means clustering was better than alternatives such as a summary-of-summaries approach in a couple of ways:\nHigher diversity of topics. Many individual summaries before reaching the final summary of summaries often repeat similar information. Combining these summaries results in a significant loss of overall file content. Using k-means clustering, we discovered that the summaries covered a broader range of topics—approximately 50% more than with map-reduce, since we search for chunks that are semantically dissimilar to one another.\nLower chance of hallucinations. When the LLM receives the entire file in one go, its likelihood of hallucinating decreases significantly. Conversely, each call made to the LLM presents a chance for hallucination, making the problem exponentially worse when summarizing summaries. The map-reduce approach lacks the context provided by other chunks, compounding the issue. Using the k-means technique, pinpointing errors in the final output—especially when comparing between LLMs or models—becomes much easier because there is just a single LLM call to evaluate.\n\r\n\r\n    \n The Q&A plugin\n\r\n\r\n\n\nOur Q&A plugin works in a similar manner to the summarization plugin, but in a somewhat opposite way. The Q&A plugin takes in the embeddings and text chunks from the embedding plugin and generates a new embedding for the user question. Then for each chunk of file text it computes the distance to the query text embedding. By calculating the closeness of each chunk to the query in vector space, the most relevant chunks are selected.\nIn the summarization plugin the text chunks were selected for dissimilarity, while in the Q&A plugin they were selected for similarity to the query text. These text chunks, along with the query, are sent to the language model for generating the answer. \nA language model uses the context to generate answers by analyzing the provided text chunks and the query to understand their meaning and relationships. When a query is received, the model first interprets the question and identifies key elements and intents. It then examines the text chunks, which serve as additional context, to extract relevant information. The model employs sophisticated algorithms to detect patterns, correlations, and nuances within the text, allowing it to discern how different pieces of information fit together. By integrating the context from the text chunks with the specifics of the query, the language model can produce a coherent and accurate response that is tailored to the query's requirements. This process involves leveraging large-scale language patterns learned during training, enabling the model to generate answers that are both contextually appropriate and informative.\nThe relevant chunk locations are then returned to the user as sources, allowing them to reference the specific parts of the file that contributed to the answer.\nAs an add on feature to both the summarization and Q&A plugins, we also request context-relevant follow-up questions from the LLM. In testing we found that follow-up questions allow the user to more naturally learn about a file and the topic they are interested in. To gather these follow-up questions, we utilize function calling and structured outputs to request follow-up questions from the LLM at the same time we request the summary or an answer to the initial question. \n\r\n\r\n    \n Expanding to multiple files\n\r\n\r\n\n\nThe first iteration of intelligent summaries and Q&A was limited to one file at a time—but we knew we could do better for our customers. We wanted to make LLM-powered understanding possible across collections of files, and not just individual documents.\nExpanding our understanding capabilities to multiple files within Dropbox involved a significant evolution of our capabilities, infrastructure, UI, and algorithms. Building on our existing file processing pipeline, we expanded Riviera’s capabilities to handle multiple files simultaneously inside of a single plugin. The embeddings plugin would still be separate for every file, but the final summarization or Q&A plugin call would need to take in multiple files. The question was: which subset of files selected by the user would we extract the relevant information from?\nWhen testing this feature, we found that some questions were quite direct (“What is Dropbox?”) while some were quite broad (“Can you explain this contract like I’m 5?”). For best results we found that we needed to tailor our response accordingly. Direct questions can often be answered in a single sentence, while the answers to broader questions are typically longer and potentially sourced from a wider context. The challenge was determining which type of answer was required. Put another way: How should we determine the number of relevant chunks or files to use when answering a request or query?\nWe eventually came to the conclusion that this was a trick question. You cannot determine if a question is direct or broad based just on the question itself. You also need the context the answer is pulled from. The question “What is Dropbox?” could both direct if asked about a list of tech companies, but also broad if asked about the Dropbox Wikipedia page.\nTo solve this question, we took advantage of power law dynamics to determine the number of relevant chunks to send to the LLM.\n\r\n\r\n    \r\n        \r\n            \r\n    \r\n\r\n        \r\n\r\n        \r\n        \r\n        \r\n\r\n        \r\n        \r\n        \r\n\r\n        \r\n        \r\n\r\n        \r\n        <!-- <img data-sly-test.highRes=\"\"\r\n             srcset=\"/cms/content/dam/dropbox/tech-blog/en-us/2024/07/ai-file-previews/aifilepreviews-diagram-ordering-by-relevance_2x.png 2x, /cms/content/dam/dropbox/tech-blog/en-us/2024/07/ai-file-previews/aifilepreviews-diagram-ordering-by-relevance_2x.png.transform/half-res/img.png 1x\"\r\n             src=\"/cms/content/dam/dropbox/tech-blog/en-us/2024/07/ai-file-previews/aifilepreviews-diagram-ordering-by-relevance_2x.png\"\r\n             aria-hidden=\"\"\r\n             alt=\"\"\r\n             class=\"\"\r\n             data-sly-attribute.width=\"720\"\r\n             data-sly-attribute.height=\"435\"\r\n             data-aem-asset-id=\"2790a713-cf18-4ba3-b2b5-8ca42d9642f9:aifilepreviews-diagram-ordering-by-relevance_2x.png\"\r\n             data-trackable=\"true\" />\r\n        <img data-sly-test.highRes=\"true\"\r\n             srcset=\"/cms/content/dam/dropbox/tech-blog/en-us/2024/07/ai-file-previews/aifilepreviews-diagram-ordering-by-relevance_2x.png 2x, /cms/content/dam/dropbox/tech-blog/en-us/2024/07/ai-file-previews/aifilepreviews-diagram-ordering-by-relevance_2x.png.transform/half-res/img.png 1x\"\r\n             src=\"/cms/content/dam/dropbox/tech-blog/en-us/2024/07/ai-file-previews/aifilepreviews-diagram-ordering-by-relevance_2x.png\"\r\n             aria-hidden=\"\"\r\n             alt=\"\"\r\n             class=\"\"\r\n             data-sly-attribute.width=\"720\"\r\n             data-sly-attribute.height=\"435\"\r\n             data-aem-asset-id=\"2790a713-cf18-4ba3-b2b5-8ca42d9642f9:aifilepreviews-diagram-ordering-by-relevance_2x.png\"\r\n             data-trackable=\"true\" /> -->\r\n\r\n        \r\n         \r\n        \r\n    \r\n\r\n            \nLine A is a direct question, while line B is a broad question\n\r\n        \r\n    \r\n\nOur solutions takes the max and min relevance scores from the top 50 text chunks related to the user query, as calculated through the embeddings, and cuts off the bottom 20% of that spread. This works well because, as shown in the diagram above, direct questions have a steeper power law curve than broad questions. \nFor Example A above, lets say that the most relevant chunk has a score of 0.9 and the least is 0.2. In this case, everything below a 0.34 score is discarded (the 20th percentile score). Since the slope is steep, over half of the chunks will be discarded, leaving about 15 left. For Example B—a more broad question—let’s say that the most relevant chunk has a score of 0.5, and the least is 0.2. In this case, everything below a 0.26 would be discarded, leaving about 40 left. Since the slope is flatter, more chunks are chosen to send to the LLM.\nAnother example could be a quarterly earnings report. For the question “what were the financial results?” a lot of the chunks would have medium relevance, resulting in something similar to the B curve above, since it is a broad question. For a question like “how much was spent on real estate?” there would be some very relevant chunks and a lot of non-relevant chunks—like the A curve above, since it is a more direct question. The first question would require more chunks to answer the question fully versus the second question.\nThis algorithm allowed us to strategically determine which files and chunks within those files were relevant, and thus, which context to send to the LLM. Direct questions get less but more relevant context, while broad questions are given more context to expand on the topic.\n\r\n\r\n    \n What we learned\n\r\n\r\n\n\nBuilding the machine learning capabilities for file understanding within Dropbox involved a series of strategic decisions, technical challenges, and optimizations to ensure efficient and accurate performance and a scalable cost model. These include: \nReal-time processing. We had to decide between calculating embeddings and AI responses ahead of time or in real time. Computing these transformations ahead of time allows for lower latency, but we settled on computing responses in real time because of one main factor: it allows the user to choose which files to share with the LLM—and only those files. Privacy and security is a top priority at Dropbox, so this was an easy choice to go with. As a side benefit, computing these requests in real-time would also save us the cost of pre-computing requests that a user might never make.\nSegmentation and clustering. We also found numerous benefits to the segmentation and clustering of requests, versus sending full file text to the LLM. By only sending the most relevant parts of a file to the LLM in a single request, we could return summaries and answers with lower latency and lower cost. Allowing the LLM to focus on the context that matters most to the user’s request also yielded better quality results; we quickly learned through testing that sending garbage into the LLM means garbage out from the LLM.\nChunk priority calculation. To optimize token usage and ensure the most relevant information is included in the summary or answer, we calculate a priority tier for each chunk. The first two chunks chronologically are given top priority, followed by k-means clustering to select semantically dissimilar chunks for summary, or semantically similar chunks to a question. This approach maximizes the breadth of topics covered in the summary and enhances the quality and relevancy of the answer.\nEmbracing embeddings. This was a crucial decision. Embeddings enabled us to compare passages efficiently in a multi-dimensional space, allowing for more accurate summarization and question answering. For multi-file actions, it also meant that we could pick and choose which files were most relevant for a query out of a list of multiple files. Even though there is a cost in latency and compute to gather these embeddings for each file, they enable a much higher quality response from the LLM.\nCached embeddings. In our initial version, embeddings were not cached, resulting in multiple calls to the LLM for the same document. In the subsequent version, embeddings are cached, reducing the number of API calls and improving performance. This optimization also allows summaries and Q&A to use the same chunks and embeddings, further enhancing efficiency.\nAll of this work has yielded significant improvements in terms of cost and latency since the start of the project. Cost-per-summary dropped by 93%, and cost-per-query dropped by 64%. The p75 latency of summaries decreased from 115 seconds to 4 seconds, and the p75 latency for queries decreased from 25 seconds to 5 seconds. These optimizations have not only made summarization and Q&A more affordable for Dropbox, but more responsive for our users.\nFile previews with AI-powered summaries and Q&A are available in early access on select Dropbox plans. Visit our Help Center to learn more.\n~ ~ ~\nIf building innovative products, experiences, and infrastructure excites you, come build the future with us! Visit dropbox.com/jobs to see our open roles, and follow @LifeInsideDropbox on Instagram and Facebook to see what it's like to create a more enlightened way of working.",
        "dc:creator": "\r\n                            Binoy Dash,Bradley Crossen,Eric Cunningham,Royce Ausburn,Tejas Patel\r\n            \t\t\t",
        "content": "null",
        "contentSnippet": "null",
        "guid": "https://dropbox.tech/machine-learning/bringing-ai-powered-answers-and-summaries-to-file-previews-on-the-web",
        "categories": [
          "Machine Learning",
          "AI",
          "summarization",
          "LLM",
          "file previews",
          "Q&A",
          "Riviera"
        ],
        "isoDate": "2024-07-11T14:00:00.000Z"
      }
    ]
  },
  {
    "name": "Joshua",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권재명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김석기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권진호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강대명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권정혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "줌구",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수보",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김시은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "곽민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김범진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민서",
    "category": "개인",
    "posts": []
  },
  {
    "name": "I am not Okay",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권창현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권기호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강태욱",
    "category": "개인",
    "posts": [
      {
        "title": "pandas AI 이용한 표 형식 데이터 생성AI로 처리해 보기",
        "link": "http://daddynkidsmakers.blogspot.com/2024/07/pandas-ai-ai.html",
        "pubDate": "2024-07-12T11:33:00.000Z",
        "author": "Daddy Maker",
        "content": "<div style=\"text-align: left;\">이 글은&nbsp;pandas AI 이용한 표 형식 데이터 생성AI로 처리해 보는 방법을 간략히 정리한다.<br /></div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEgVkwuvFaQen-42SQch-oPTBRAwnnvJfFjHCS11Woi-n1K_ZsrhYpkGHKsESYSNJzqAMXChHXcWOtHjxNJGAQntDIG8Hmw2Evxa07mpLLPQy-CwaT0o-JJDh4XeCRBCsUr8HiG2Qv3mDh5X5NT-JjX9CFkgZOFEVG4xi6Rl08K0cEDiVtfwyO7iWXAzAd1f\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"500\" data-original-width=\"800\" height=\"250\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEgVkwuvFaQen-42SQch-oPTBRAwnnvJfFjHCS11Woi-n1K_ZsrhYpkGHKsESYSNJzqAMXChHXcWOtHjxNJGAQntDIG8Hmw2Evxa07mpLLPQy-CwaT0o-JJDh4XeCRBCsUr8HiG2Qv3mDh5X5NT-JjX9CFkgZOFEVG4xi6Rl08K0cEDiVtfwyO7iWXAzAd1f=w400-h250\" width=\"400\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEhKvj69LoCWf3yRZmk_ciCj1oentwi__YYU8trQ81SiC0ZzgGjYbtcqD4Cu1SUc5CytZupZLl6EwWFiWuCi61IV4cE1QU8CDNnMeQcFKK9yrTQJUNLB2BLucyYgdlNHmLq0q1U1236GBThJaT9qnPsLyCiskUw2t5q2kbsFjkCbYE85hNL86aqZPud_OrzN\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"146\" data-original-width=\"500\" height=\"116\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEhKvj69LoCWf3yRZmk_ciCj1oentwi__YYU8trQ81SiC0ZzgGjYbtcqD4Cu1SUc5CytZupZLl6EwWFiWuCi61IV4cE1QU8CDNnMeQcFKK9yrTQJUNLB2BLucyYgdlNHmLq0q1U1236GBThJaT9qnPsLyCiskUw2t5q2kbsFjkCbYE85hNL86aqZPud_OrzN=w400-h116\" width=\"400\" /></a></div><br /></div></div><b>레퍼런스</b><br /><ul style=\"text-align: left;\"><li><a href=\"https://github.com/Sinaptik-AI/pandas-ai\">pandas-ai: Chat with your database (SQL, CSV, pandas, polars, mongodb, noSQL, etc). PandasAI makes data analysis conversational using LLMs (GPT 3.5 / 4, Anthropic, VertexAI) and RAG</a></li></ul></div>",
        "contentSnippet": "이 글은 pandas AI 이용한 표 형식 데이터 생성AI로 처리해 보는 방법을 간략히 정리한다.\n\n\n\n\n\n\n레퍼런스\n\npandas-ai: Chat with your database (SQL, CSV, pandas, polars, mongodb, noSQL, etc). PandasAI makes data analysis conversational using LLMs (GPT 3.5 / 4, Anthropic, VertexAI) and RAG",
        "id": "tag:blogger.com,1999:blog-5201956450461596914.post-8890276364037553078",
        "isoDate": "2024-07-12T11:33:00.000Z"
      }
    ]
  },
  {
    "name": "권용진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권영재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김승호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김병환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for boyism Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성준의 린스타트업과 디자인씽킹",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권혁우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김준형",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강동혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고종범",
    "category": "개인",
    "posts": []
  },
  {
    "name": "cheese10yun",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구자철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "FSS",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권동준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김용일",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도균",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김상훈",
    "category": "개인",
    "posts": [
      {
        "creator": "김상훈",
        "title": "비 대신, 가뭄을 주는 구름(cloud)",
        "link": "https://interpiler.com/2024/07/12/%eb%b9%84-%eb%8c%80%ec%8b%a0-%ea%b0%80%eb%ad%84%ec%9d%84-%ec%a3%bc%eb%8a%94-%ea%b5%ac%eb%a6%84cloud/",
        "pubDate": "Fri, 12 Jul 2024 08:58:45 +0000",
        "content:encodedSnippet": "하늘의 구름이 아니라, 클라우드 컴퓨팅의 그 구름(cloud) 얘기다.\n인공지능(AI) 열풍 때문에 데이터센터 건설 붐이 일었고, 데이터센터가 잡아먹는 전기가 어마어마해서 지역 정전까지 걱정할 상황이란 얘기가 계속 나온다. 갑자기 소형원자로 산업이 주목을 받질 않나, 소형원자로 조차도 도입을 결정해서 가동할 때까지 최소 5년 이상 걸리니 그 사이를 채우기 위해 태양광발전만이 대안이라질 않나, 전기 관련한 얘기는 끝이 없다.\n하지만 물은 전기 만큼의 관심을 받지 못한다.\n데이터센터의 전기는 반도체를 돌릴 때에도 필요하지만, 열심히 계산을 하느라 열을 잔뜩 뿜어낸 반도체를 식힐 때도 사용된다. 에어컨을 돌려 더워진 반도체를 식히는 방식이다. 비효율적이니 사람들은 더 효율적인 방법을 고민했다. 데이터센터를 추운 곳에 짓는다거나, 심지어 바다속에 짓겠다는 아이디어가 이래서 나왔다. 이 과정에서 찾아낸 현재의 가장 비용효율적인 냉각 방식이 냉각수를 사용하는 방식이다. 대개의 원리는 이렇다.\n에어컨을 수냉식으로 돌린다. 공기를 직접 냉매로 식히는 대신, 찬 물을 만들어 공기를 식히는 방식이다.\n우선 데이터센터 전역을 휘감는 냉각코일을 설치한 뒤 중앙냉각기에서 물을 냉각해, 차가워진 물을 코일로 보낸다. \n찬 물은 센터를 휘돌며 공기를 식히고, 열을 머금는다. 이렇게 더워진 물은 센터 외부의 냉각탑으로 보내진다.\n냉각탑은 외부 기온으로도 냉각수 온도를 낮추지만, 더 빨리 더 많이 온도를 낮추기 위해 일부 물을 증발시킨다. 기화열을 빼앗기도록 해 전기는 아끼지만, 당연히 이만큼의 물은 하늘로 증발된다.\n구글의 데이터센터는 (단 한 곳 기준으로도) 이런 냉각수로만 하루 210만리터의 물을 사용한다. 올림픽 경기를 여는 국제규격 수영장 하나를 가득 채우고도 남는 양이다.\n추운 지역은 건조한 날이 상대적으로 많게 마련이다. 가습에도 물이 사용된다. 건조한 환경은 정전기 발생 가능성을 높이고, 데이터센터의 민감한 부품들을 망가뜨린다. 냉각수보다는 적지만 상당한 물이 이렇게 습도를 높이는데 사용된다.\n물 사용을 줄이려면 물을 재활용하면 되지 않느냐 물을 수 있지만, 결론부터 말하자면 어렵다. 일부 증발도 거치고, 긴 코일 사이를 흐르기도 하면서 냉각수에는 조금씩 미네랄이 쌓여간다. 즉, 물의 농도가 점점 짙어진다. 어느 순간에는 미네랄이 코일을 막을 수도 있고, 전기가 너무 잘 통하게 된 물이 다른 문제를 일으킬 수도 있다. 한두번 재활용은 할 수 있어도 몇 번 돌리면 버려야 한다는 얘기다. 게다가 재활용까지 할 수준의 물은 깨끗한 물이어야하는데, 그게 어지간한 데이터센터가 식용수를 냉각수로 사용하는 이유다. 물은 그 자체로도 귀하지만, 마실 수 있는 물은 훨씬 더 귀하다.\n이런 식의 계산도 가능하다. 예를 들어 2030년까지 유럽인은 1인당 하루 평균 3리터의 물을 소비할 계획이다. 현실에서 마시는 물 얘기가 아니다. 유럽인이 사용하는 인터넷 사용량을 데이터센터 용량으로 역산해 냉각수에 사용되는 물의 양을 계산했을 때 나오는 수치다. 즉, 우리는 조만간 마시는 물보다 더 많은 물을 반도체를 식히는데 쓰게 될 예정이다.\n지금까지 우리가 혐오시설이라 생각했던 시설들은 화석연료를 태우는 엔진들이 연기를 뿜어내는 제조공장이나, 유독한 화학물질을 다루는 화학공장, 먼지가 휘날리는 광산 등이었다. 데이터센터는 다르다. 겉으로 보기엔 깨끗하다. 가끔 피어오르는 연기도 수증기에 불과하다. 하지만 그 수증기가 인근의 물을 빨아들이고, 지역에 가뭄을 불러온다.\n데이터센터의 평균 수명은 10-20년 정도. 기술 발전의 속도와 효율성의 경제논리 때문에 이 정도 시간이 지나면 데이터센터는 다시 리노베이션되거나 버려지게 된다. 즉, 10-20년 비트(bit)를 채굴하는 광산을 건설하고 자원을 뽑아쓸만큼 뽑아쓰면 버려버리는 셈이다. 데이터센터 건설에 열을 올리는 빅테크 기업들은 나무를 더 많이 심고, 숲을 조성하겠다고 한다. 그리고, 동시에 그 나무에 줘야 하는 물을 말려버리고 있다.",
        "dc:creator": "김상훈",
        "comments": "https://interpiler.com/2024/07/12/%eb%b9%84-%eb%8c%80%ec%8b%a0-%ea%b0%80%eb%ad%84%ec%9d%84-%ec%a3%bc%eb%8a%94-%ea%b5%ac%eb%a6%84cloud/#respond",
        "content": "하늘의 구름이 아니라, 클라우드 컴퓨팅의 그 구름(cloud) 얘기다. 인공지능(AI) 열풍 때문에 데이터센터 건설 붐이 일었고, 데이터센터가 잡아먹는 전기가 어마어마해서 지역 정전까지 걱정할 상황이란 얘기가 계속 나온다. 갑자기 소형원자로 산업이 주목을 받질 않나, 소형원자로 조차도 도입을 결정해서 가동할 때까지 최소 5년 이상 걸리니 그 사이를 채우기 위해 태양광발전만이 대안이라질 않나, 전기 관련한 얘기는 끝이 없다. 하지만 &#8230; <a href=\"https://interpiler.com/2024/07/12/%eb%b9%84-%eb%8c%80%ec%8b%a0-%ea%b0%80%eb%ad%84%ec%9d%84-%ec%a3%bc%eb%8a%94-%ea%b5%ac%eb%a6%84cloud/\" class=\"more-link\">계속 읽기 <span class=\"screen-reader-text\">비 대신, 가뭄을 주는&#160;구름(cloud)</span> <span class=\"meta-nav\">\t</span></a>",
        "contentSnippet": "하늘의 구름이 아니라, 클라우드 컴퓨팅의 그 구름(cloud) 얘기다. 인공지능(AI) 열풍 때문에 데이터센터 건설 붐이 일었고, 데이터센터가 잡아먹는 전기가 어마어마해서 지역 정전까지 걱정할 상황이란 얘기가 계속 나온다. 갑자기 소형원자로 산업이 주목을 받질 않나, 소형원자로 조차도 도입을 결정해서 가동할 때까지 최소 5년 이상 걸리니 그 사이를 채우기 위해 태양광발전만이 대안이라질 않나, 전기 관련한 얘기는 끝이 없다. 하지만 … 계속 읽기 비 대신, 가뭄을 주는 구름(cloud)",
        "guid": "http://interpiler.com/?p=1482",
        "categories": [
          "That's IT",
          "AI",
          "냉각수",
          "데이터센터",
          "클라우드",
          "인공지능"
        ],
        "isoDate": "2024-07-12T08:58:45.000Z"
      }
    ]
  },
  {
    "name": "김민석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김동우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권윤학",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김만수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "엘키",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김슬기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김광현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김영우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강명훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민장",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕홍",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성중",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구교준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고명환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성희",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강병수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김봉현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강형석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수로",
    "category": "개인",
    "posts": [
      {
        "creator": "김수로",
        "title": "[React, Next.js] Next.js? 꼭 써야하나? 어떤것을 써야 할까?",
        "link": "http://babysunmoon.tistory.com/entry/React-Nextjs-Nextjs-%EA%BC%AD-%EC%8D%A8%EC%95%BC%ED%95%98%EB%82%98-%EC%96%B4%EB%96%A4%EA%B2%83%EC%9D%84-%EC%8D%A8%EC%95%BC-%ED%95%A0%EA%B9%8C",
        "pubDate": "Tue, 16 Jul 2024 01:03:36 +0900",
        "author": "김수로",
        "comments": "http://babysunmoon.tistory.com/entry/React-Nextjs-Nextjs-%EA%BC%AD-%EC%8D%A8%EC%95%BC%ED%95%98%EB%82%98-%EC%96%B4%EB%96%A4%EA%B2%83%EC%9D%84-%EC%8D%A8%EC%95%BC-%ED%95%A0%EA%B9%8C#entry185comment",
        "content": "프론트엔드와 백엔드를 React를 사용해서 개발 할 예정 React로 만들려고 했는데..Next.js? 꼭 써야 할까?\n&nbsp;\n일단 정의부터 살펴보자.\n&nbsp;\nReact와 Next.js\n&nbsp;React.js\n정의: React.js는 Facebook에서 개발한 오픈 소스 JavaScript 라이브러리로, 사용자 인터페이스(UI)를 구축하기 위해 사용됩니다. React는 컴포넌트 기반 아키텍처를 통해 UI 컴포넌트를 쉽게 만들고 재사용할 수..",
        "contentSnippet": "프론트엔드와 백엔드를 React를 사용해서 개발 할 예정 React로 만들려고 했는데..Next.js? 꼭 써야 할까?\n \n일단 정의부터 살펴보자.\n \nReact와 Next.js\n React.js\n정의: React.js는 Facebook에서 개발한 오픈 소스 JavaScript 라이브러리로, 사용자 인터페이스(UI)를 구축하기 위해 사용됩니다. React는 컴포넌트 기반 아키텍처를 통해 UI 컴포넌트를 쉽게 만들고 재사용할 수..",
        "guid": "http://babysunmoon.tistory.com/185",
        "categories": [
          "React",
          "next.js",
          "next.js 꼭 써야 하나?",
          "next.js란?",
          "nextjs",
          "react",
          "React.js"
        ],
        "isoDate": "2024-07-15T16:03:36.000Z"
      }
    ]
  },
  {
    "name": "강미경",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강진우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권민재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태관",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도곤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "칡토스의 게임 개발",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김놀부",
    "category": "개인",
    "posts": []
  },
  {
    "name": "프리웨어 이야기",
    "category": "개인",
    "posts": [
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "안드로이드 추천 앱, 추천 어플 (24.7.15) 동영상 편집, AI이미지편집, 프로젝트관리, 문서뷰어, 문서스캔",
        "link": "http://muzbox.tistory.com/483450",
        "pubDate": "Mon, 15 Jul 2024 13:58:26 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483450#entry483450comment",
        "content": "<p style=\"text-align: left;\" data-ke-size=\"size16\">구글플레이 스토어에 등록된 유용한 앱 5개를&nbsp; 소개합니다. 새로운 기능, 사용자 경험 향상을 위한 앱들을 발견하고, 일상생활을 더욱 편리하게 만들어 줄 최고의 앱들을 찾아보세요.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"안드로이드 추천앱.png\" data-origin-width=\"500\" data-origin-height=\"500\"><span data-url=\"https://blog.kakaocdn.net/dn/czs8Qo/btsIAvh8MUE/wdtdMP1Q3euLAuhflXaDLK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/czs8Qo/btsIAvh8MUE/wdtdMP1Q3euLAuhflXaDLK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/czs8Qo/btsIAvh8MUE/wdtdMP1Q3euLAuhflXaDLK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fczs8Qo%2FbtsIAvh8MUE%2FwdtdMP1Q3euLAuhflXaDLK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"안드로이드 추천 앱\" data-filename=\"안드로이드 추천앱.png\" data-origin-width=\"500\" data-origin-height=\"500\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;안드로이드 앱스토어인 구글 플레이 스토어에는 하루에도 엄청난 수의 앱과 게임이 신규로 등록됩니다. 이 모든앱들을 사용자가 확인하고 양질의 앱을 선택하는 것이 사실상 불가능 하다는 얘기죠.&nbsp; <br /><br />또한, 최근들어 강화되었다 하지만 여전히 구글 플레이스토어에는 유해한 앱들이 사라지지 않고 이들 앱으로 피해를 보는 사용자도 많습니다. 본 블로그에서는 일주일에 한 번정도 운영자가 직접 유용하고 편리한 앱을 엄선하여 소개합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"text-align: left;\" data-ke-size=\"size16\"><b>'어떤오후의 프리웨어 이야기'에서 추천하는 </b><b><span style=\"color: #ee2323;\">2024년 7월 15일자 '안드로이드 추천 앱'</span>입니다.</b><b></b></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>1. VivaVideo&nbsp;-&nbsp;동영상&nbsp;편집&nbsp;&amp;&nbsp;브이로그&nbsp;편집&nbsp;앱</b></span></h2>\n<p data-ke-size=\"size16\">&nbsp; 무료&nbsp;동영상&nbsp;편집&nbsp;어플로,&nbsp;Vlog&nbsp;제작에&nbsp;유용한&nbsp;기능을&nbsp;제공합니다.&nbsp;이&nbsp;앱은&nbsp;음악,&nbsp;텍스트,&nbsp;스티커,&nbsp;효과&nbsp;등을&nbsp;추가할&nbsp;수&nbsp;있으며,&nbsp;필터,&nbsp;테마,&nbsp;텍스트,&nbsp;자막,&nbsp;스티커,&nbsp;한글&nbsp;폰트,&nbsp;배속,&nbsp;pip,&nbsp;음성&nbsp;변조,&nbsp;비율&nbsp;조절,&nbsp;배경음악,&nbsp;효과음,&nbsp;고화질&nbsp;저장,&nbsp;SNS&nbsp;공유&nbsp;등의&nbsp;기능을&nbsp;제공합니다. <br /><br />이&nbsp;앱은&nbsp;클립&nbsp;편집,&nbsp;영상&nbsp;자막&nbsp;및&nbsp;폰트,&nbsp;동영상&nbsp;비율,&nbsp;동영상&nbsp;필터,&nbsp;유튜브&nbsp;배경&nbsp;음악&nbsp;등의&nbsp;기능을&nbsp;포함한&nbsp;마스터&nbsp;영상&nbsp;편집기를&nbsp;제공합니다.&nbsp;또한&nbsp;동영상&nbsp;클립&nbsp;자르기&nbsp;및&nbsp;복사,&nbsp;붙이기,&nbsp;자막&nbsp;삽입,&nbsp;특수&nbsp;효과,&nbsp;스티커,&nbsp;음악,&nbsp;필터,&nbsp;변환&nbsp;및&nbsp;실시간&nbsp;더빙으로&nbsp;동영상을&nbsp;고급화하고&nbsp;HD&nbsp;화질로&nbsp;내보낼&nbsp;수&nbsp;있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"VivaVideo.jpg\" data-origin-width=\"1629\" data-origin-height=\"2889\"><span data-url=\"https://blog.kakaocdn.net/dn/cWD27V/btsIAyTtk4o/624gpGgwlKTv9LiKGDUVK0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/cWD27V/btsIAyTtk4o/624gpGgwlKTv9LiKGDUVK0/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/cWD27V/btsIAyTtk4o/624gpGgwlKTv9LiKGDUVK0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcWD27V%2FbtsIAyTtk4o%2F624gpGgwlKTv9LiKGDUVK0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"VivaVideo - 동영상 편집 &amp;amp; 브이로그 편집 앱\" width=\"760\" height=\"1348\" data-filename=\"VivaVideo.jpg\" data-origin-width=\"1629\" data-origin-height=\"2889\"/></span></figure>\n</p>\n<figure id=\"og_1721019242034\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"VivaVideo - 동영상 편집 &amp; 브이로그 편집 앱 - Google Play 앱\" data-og-description=\"Vlog 및 비디오 편집기: 비디오 또는 사진을 자르고 병합합니다. 전환, 효과, 필터, 음악 및 스티커로 마스터 비디오를 만드십시오!\" data-og-host=\"play.google.com\" data-og-source-url=\"https://play.google.com/store/apps/details?id=com.quvideo.xiaoying\" data-og-url=\"https://play.google.com/store/apps/details?id=com.quvideo.xiaoying&amp;hl=ko\" data-og-image=\"https://scrap.kakaocdn.net/dn/EpEYy/hyWzDHjbcv/SygIe6Tr6ZKV33MombSns1/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/btykmj/hyWzETMxkF/BykKMnFZTjTfEWyiM31Nxk/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/c5owkg/hyWzB3MMlm/MLa2bv7KzhqehSvNDxGMz0/img.png?width=240&amp;height=240&amp;face=0_0_240_240\"><a href=\"https://play.google.com/store/apps/details?id=com.quvideo.xiaoying\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://play.google.com/store/apps/details?id=com.quvideo.xiaoying\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/EpEYy/hyWzDHjbcv/SygIe6Tr6ZKV33MombSns1/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/btykmj/hyWzETMxkF/BykKMnFZTjTfEWyiM31Nxk/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/c5owkg/hyWzB3MMlm/MLa2bv7KzhqehSvNDxGMz0/img.png?width=240&amp;height=240&amp;face=0_0_240_240');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">VivaVideo - 동영상 편집 &amp; 브이로그 편집 앱 - Google Play 앱</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">Vlog 및 비디오 편집기: 비디오 또는 사진을 자르고 병합합니다. 전환, 효과, 필터, 음악 및 스티커로 마스터 비디오를 만드십시오!</p>\n<p class=\"og-host\" data-ke-size=\"size16\">play.google.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>2. Wrike&nbsp;-&nbsp;프로젝트&nbsp;관리</b></span></h2>\n<p data-ke-size=\"size16\">&nbsp;프로젝트 관리, 계획 수립, 팀 협업을 위한 클라우드 기반의 소프트웨어로, 15,000곳 이상의 기업이 사용 중입니다. <br /><br />작업&nbsp;자동화,&nbsp;위험&nbsp;예측,&nbsp;폴더&nbsp;및&nbsp;프로젝트&nbsp;액세스,&nbsp;작업&nbsp;배정&nbsp;및&nbsp;일정&nbsp;조정,&nbsp;알림&nbsp;확인,&nbsp;파일&nbsp;첨부,&nbsp;프로젝트&nbsp;보기&nbsp;조정&nbsp;등&nbsp;다양한&nbsp;기능을&nbsp;제공합니다. <br /><br />무료 앱으로 다운로드 가능하며, 비즈니스, 엔터프라이즈 등 다양한 플랜을 제공합니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Wrike.jpg\" data-origin-width=\"1089\" data-origin-height=\"1929\"><span data-url=\"https://blog.kakaocdn.net/dn/O1n3P/btsIyDWbTRD/vhwtSemBXgTbLkDvhaqhOK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/O1n3P/btsIyDWbTRD/vhwtSemBXgTbLkDvhaqhOK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/O1n3P/btsIyDWbTRD/vhwtSemBXgTbLkDvhaqhOK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FO1n3P%2FbtsIyDWbTRD%2FvhwtSemBXgTbLkDvhaqhOK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"Wrike - 프로젝트 관리\" width=\"760\" height=\"1346\" data-filename=\"Wrike.jpg\" data-origin-width=\"1089\" data-origin-height=\"1929\"/></span></figure>\n</p>\n<figure id=\"og_1721019264420\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"Wrike - 프로젝트 관리 - Google Play 앱\" data-og-description=\"프로젝트 최신 상태를 확인하고 이동하면서 다른 사람들과 아이디어를 공유하세요.\" data-og-host=\"play.google.com\" data-og-source-url=\"https://play.google.com/store/apps/details?id=com.wrike\" data-og-url=\"https://play.google.com/store/apps/details?id=com.wrike&amp;hl=ko\" data-og-image=\"https://scrap.kakaocdn.net/dn/SNR4P/hyWzp3lmTd/G768CNBtxqoURGUbl8YGlK/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/bBVUGG/hyWzAKyY7s/qei7rfkH3M44UPgG1WVLKk/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/c0uJrt/hyWzzx6kir/6Vp5ESR3fQokAvkGqlmNL1/img.jpg?width=480&amp;height=360&amp;face=0_0_480_360\"><a href=\"https://play.google.com/store/apps/details?id=com.wrike\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://play.google.com/store/apps/details?id=com.wrike\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/SNR4P/hyWzp3lmTd/G768CNBtxqoURGUbl8YGlK/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/bBVUGG/hyWzAKyY7s/qei7rfkH3M44UPgG1WVLKk/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/c0uJrt/hyWzzx6kir/6Vp5ESR3fQokAvkGqlmNL1/img.jpg?width=480&amp;height=360&amp;face=0_0_480_360');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">Wrike - 프로젝트 관리 - Google Play 앱</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">프로젝트 최신 상태를 확인하고 이동하면서 다른 사람들과 아이디어를 공유하세요.</p>\n<p class=\"og-host\" data-ke-size=\"size16\">play.google.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>3. VLLO&nbsp;블로,&nbsp;나의&nbsp;첫&nbsp;동영상&nbsp;편집기</b></span></h2>\n<p data-ke-size=\"size16\">&nbsp; 쉬운&nbsp;사용법으로&nbsp;유명한&nbsp;동영상&nbsp;편집&nbsp;앱입니다. <br /><br />직관적인&nbsp;UI를&nbsp;갖춰&nbsp;초보자도&nbsp;금세&nbsp;익숙해질&nbsp;수&nbsp;있으며,&nbsp;컷&nbsp;편집,&nbsp;자막,&nbsp;스티커,&nbsp;배경음악,&nbsp;효과음&nbsp;삽입과&nbsp;전환&nbsp;효과&nbsp;등&nbsp;기본적인&nbsp;기능부터&nbsp;전문가용&nbsp;기능인&nbsp;크로마키,&nbsp;PIP,&nbsp;모자이크,&nbsp;얼굴&nbsp;인식,&nbsp;키&nbsp;프레임까지&nbsp;폭&nbsp;넓게&nbsp;제공합니다. <br /><br />다양한 한국어 폰트와 트렌디한 스티커, 주기적인 업데이트로 사용자들의 만족도가 높습니다. 워터마크 없이 프로젝트를 저장할 수 있고, 결제를 강요하지 않는 것도 장점입니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"VLLO.jpg\" data-origin-width=\"1629\" data-origin-height=\"2889\"><span data-url=\"https://blog.kakaocdn.net/dn/FglHh/btsIz9M7l3l/zSkyCK1etNgcgKZ7PxZh9k/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/FglHh/btsIz9M7l3l/zSkyCK1etNgcgKZ7PxZh9k/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/FglHh/btsIz9M7l3l/zSkyCK1etNgcgKZ7PxZh9k/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FFglHh%2FbtsIz9M7l3l%2FzSkyCK1etNgcgKZ7PxZh9k%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"VLLO 블로, 나의 첫 동영상 편집기\" width=\"760\" height=\"1348\" data-filename=\"VLLO.jpg\" data-origin-width=\"1629\" data-origin-height=\"2889\"/></span></figure>\n</p>\n<figure id=\"og_1721019285709\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"VLLO 블로, 나의 첫 동영상 편집기 - Google Play 앱\" data-og-description=\"All-in-one 영상 편집앱, 블로! 저작권 걱정 없는 BGM&amp;효과음, 자막, 필터, 보정, 모자이크, 크로마키, 음성녹음, 블러, 특수효과\" data-og-host=\"play.google.com\" data-og-source-url=\"https://play.google.com/store/apps/details?id=com.darinsoft.vimo\" data-og-url=\"https://play.google.com/store/apps/details?id=com.darinsoft.vimo&amp;hl=ko\" data-og-image=\"https://scrap.kakaocdn.net/dn/1QmDh/hyWzviaGuV/sOFPJZkII1qr114beok4Q0/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/bF17Xv/hyWzr7V74t/UVKZw025DXDvlSrQ78pkNk/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/PW2Kb/hyWzvJftIt/eKkrF4VuhZKASzIS47UDk0/img.jpg?width=480&amp;height=360&amp;face=0_0_480_360\"><a href=\"https://play.google.com/store/apps/details?id=com.darinsoft.vimo\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://play.google.com/store/apps/details?id=com.darinsoft.vimo\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/1QmDh/hyWzviaGuV/sOFPJZkII1qr114beok4Q0/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/bF17Xv/hyWzr7V74t/UVKZw025DXDvlSrQ78pkNk/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/PW2Kb/hyWzvJftIt/eKkrF4VuhZKASzIS47UDk0/img.jpg?width=480&amp;height=360&amp;face=0_0_480_360');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">VLLO 블로, 나의 첫 동영상 편집기 - Google Play 앱</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">All-in-one 영상 편집앱, 블로! 저작권 걱정 없는 BGM&amp;효과음, 자막, 필터, 보정, 모자이크, 크로마키, 음성녹음, 블러, 특수효과</p>\n<p class=\"og-host\" data-ke-size=\"size16\">play.google.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><b><span style=\"color: #006dd7;\">4. Docx&nbsp;리더&nbsp;-&nbsp;HWP,&nbsp;PDF,&nbsp;Docx,&nbsp;XLSX</span><br /></b></h2>\n<p data-ke-size=\"size16\">&nbsp;PDF, XLSX, PPTX, Sly 등 다양한 문서 형식을 지원하는 올인원 문서 편집 앱입니다. 사무실, 수업, 여행지 등 어디서나 문서를 만들고, 보고, 편집하고 공유할 수 있습니다. 이미지를 PDF, Slide, XLSX로 변환하거나 디지털화하고, 저장하거나 Google Drive에 업로드할 수 있습니다. HWP 파일을 포함한 모든 문서와 호환되며, 사용자 정의 글꼴 추가 기능도 제공합니다. 앱 내에서 협업 기능을 사용하여 실시간으로 문서를 작성하고 공동 작업할 수도 있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Docx 리더.jpg\" data-origin-width=\"1089\" data-origin-height=\"1929\"><span data-url=\"https://blog.kakaocdn.net/dn/TX2jC/btsIyv5esZu/dLE1KUkkePDvzbLgLPS2A1/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/TX2jC/btsIyv5esZu/dLE1KUkkePDvzbLgLPS2A1/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/TX2jC/btsIyv5esZu/dLE1KUkkePDvzbLgLPS2A1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FTX2jC%2FbtsIyv5esZu%2FdLE1KUkkePDvzbLgLPS2A1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"Docx 리더 - HWP, PDF, Docx, XLSX\" width=\"760\" height=\"1346\" data-filename=\"Docx 리더.jpg\" data-origin-width=\"1089\" data-origin-height=\"1929\"/></span></figure>\n</p>\n<figure id=\"og_1721019303091\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"Docx 리더 - HWP, PDF, Docx, XLSX - Google Play 앱\" data-og-description=\"뷰어 및 편집기 Docx Reader - HWP, DOC, Reader, TXT, XLSX, PPT, PPTX 및 PDF.\" data-og-host=\"play.google.com\" data-og-source-url=\"https://play.google.com/store/apps/details?id=com.officedocument.word.docx.document.viewer\" data-og-url=\"https://play.google.com/store/apps/details?id=com.officedocument.word.docx.document.viewer&amp;hl=ko\" data-og-image=\"https://scrap.kakaocdn.net/dn/cUKHGB/hyWzAjuBEf/RdmKVU2rPYX3lRFnPA81Vk/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/bCwgDD/hyWzDUONrZ/zUXr0zjUmVFvuzGOU9WpW0/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/bEKBVY/hyWztSdzqk/BHc9y7eBXeeDKYyDmDcS3K/img.png?width=240&amp;height=240&amp;face=0_0_240_240\"><a href=\"https://play.google.com/store/apps/details?id=com.officedocument.word.docx.document.viewer\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://play.google.com/store/apps/details?id=com.officedocument.word.docx.document.viewer\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/cUKHGB/hyWzAjuBEf/RdmKVU2rPYX3lRFnPA81Vk/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/bCwgDD/hyWzDUONrZ/zUXr0zjUmVFvuzGOU9WpW0/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/bEKBVY/hyWztSdzqk/BHc9y7eBXeeDKYyDmDcS3K/img.png?width=240&amp;height=240&amp;face=0_0_240_240');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">Docx 리더 - HWP, PDF, Docx, XLSX - Google Play 앱</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">뷰어 및 편집기 Docx Reader - HWP, DOC, Reader, TXT, XLSX, PPT, PPTX 및 PDF.</p>\n<p class=\"og-host\" data-ke-size=\"size16\">play.google.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>5. Videoleap:&nbsp;영상편집&nbsp;전문,&nbsp;동영상&nbsp;편집&nbsp;템플릿</b></span></h2>\n<p data-ke-size=\"size16\">&nbsp;고품질 동영상을 몇 분 만에 제작할 수 있는 혁신적인 무료 동영상 편집 앱입니다. 아트 효과, 텍스트 추가, 레이어 변환, 이미지 믹싱 등 다양한 기능을 제공하며 안드로이드 구글 플레이에서 다운로드할 수 있습니다.다른 유저들이 만든 콘텐츠를 검색하여 내 취향에 맞는 템플릿을 찾을 수 있고 이를 수정하여 사용할 수 있습니다.전문가용 고급 효과와 초보자도 쉽게 사용할 수 있는 직관적인 편집 기능을 모두 갖추고 있습니다.완성된 동영상은 자동 저장되며 워터마크가 없습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Videoleap.jpg\" data-origin-width=\"1759\" data-origin-height=\"2889\"><span data-url=\"https://blog.kakaocdn.net/dn/MfSHm/btsIzzeuZPc/iRQnpQH8LgslN7dtj6XUG0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/MfSHm/btsIzzeuZPc/iRQnpQH8LgslN7dtj6XUG0/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/MfSHm/btsIzzeuZPc/iRQnpQH8LgslN7dtj6XUG0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FMfSHm%2FbtsIzzeuZPc%2FiRQnpQH8LgslN7dtj6XUG0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"Videoleap: 영상편집 전문, 동영상 편집 템플릿\" width=\"760\" height=\"1248\" data-filename=\"Videoleap.jpg\" data-origin-width=\"1759\" data-origin-height=\"2889\"/></span></figure>\n</p>\n<figure id=\"og_1721019325380\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"Videoleap: 영상편집 전문, 동영상 편집 템플릿 - Google Play 앱\" data-og-description=\"편리한 동영상 편집 앱을 찾고 계신가요? Videoleap 편집앱은 초보자도 놀라운 동영상을 쉽게 편집하도록 도와주는 강력한 영상편집어플입니다.\" data-og-host=\"play.google.com\" data-og-source-url=\"https://play.google.com/store/apps/details?id=com.lightricks.videoleap\" data-og-url=\"https://play.google.com/store/apps/details?id=com.lightricks.videoleap&amp;hl=ko\" data-og-image=\"https://scrap.kakaocdn.net/dn/kaj4v/hyWztYW6KA/xJOmxxGM28kWxooOL2Awkk/img.jpg?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/b1u67P/hyWztkk7hZ/feiz2P7fUkMkgRbf1bsRX0/img.jpg?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/PBTQ0/hyWzqHXQwG/IXkNN1hAH0DWTSikj56gf0/img.jpg?width=480&amp;height=360&amp;face=0_0_480_360\"><a href=\"https://play.google.com/store/apps/details?id=com.lightricks.videoleap\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://play.google.com/store/apps/details?id=com.lightricks.videoleap\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/kaj4v/hyWztYW6KA/xJOmxxGM28kWxooOL2Awkk/img.jpg?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/b1u67P/hyWztkk7hZ/feiz2P7fUkMkgRbf1bsRX0/img.jpg?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/PBTQ0/hyWzqHXQwG/IXkNN1hAH0DWTSikj56gf0/img.jpg?width=480&amp;height=360&amp;face=0_0_480_360');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">Videoleap: 영상편집 전문, 동영상 편집 템플릿 - Google Play 앱</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">편리한 동영상 편집 앱을 찾고 계신가요? Videoleap 편집앱은 초보자도 놀라운 동영상을 쉽게 편집하도록 도와주는 강력한 영상편집어플입니다.</p>\n<p class=\"og-host\" data-ke-size=\"size16\">play.google.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "구글플레이 스토어에 등록된 유용한 앱 5개를  소개합니다. 새로운 기능, 사용자 경험 향상을 위한 앱들을 발견하고, 일상생활을 더욱 편리하게 만들어 줄 최고의 앱들을 찾아보세요.\n\n\n \n 안드로이드 앱스토어인 구글 플레이 스토어에는 하루에도 엄청난 수의 앱과 게임이 신규로 등록됩니다. 이 모든앱들을 사용자가 확인하고 양질의 앱을 선택하는 것이 사실상 불가능 하다는 얘기죠.  \n또한, 최근들어 강화되었다 하지만 여전히 구글 플레이스토어에는 유해한 앱들이 사라지지 않고 이들 앱으로 피해를 보는 사용자도 많습니다. 본 블로그에서는 일주일에 한 번정도 운영자가 직접 유용하고 편리한 앱을 엄선하여 소개합니다.\n \n'어떤오후의 프리웨어 이야기'에서 추천하는 2024년 7월 15일자 '안드로이드 추천 앱'입니다.\n \n1. VivaVideo - 동영상 편집 & 브이로그 편집 앱\n  무료 동영상 편집 어플로, Vlog 제작에 유용한 기능을 제공합니다. 이 앱은 음악, 텍스트, 스티커, 효과 등을 추가할 수 있으며, 필터, 테마, 텍스트, 자막, 스티커, 한글 폰트, 배속, pip, 음성 변조, 비율 조절, 배경음악, 효과음, 고화질 저장, SNS 공유 등의 기능을 제공합니다. \n이 앱은 클립 편집, 영상 자막 및 폰트, 동영상 비율, 동영상 필터, 유튜브 배경 음악 등의 기능을 포함한 마스터 영상 편집기를 제공합니다. 또한 동영상 클립 자르기 및 복사, 붙이기, 자막 삽입, 특수 효과, 스티커, 음악, 필터, 변환 및 실시간 더빙으로 동영상을 고급화하고 HD 화질로 내보낼 수 있습니다.\n\n\n\n \nVivaVideo - 동영상 편집 & 브이로그 편집 앱 - Google Play 앱\nVlog 및 비디오 편집기: 비디오 또는 사진을 자르고 병합합니다. 전환, 효과, 필터, 음악 및 스티커로 마스터 비디오를 만드십시오!\nplay.google.com\n\n \n \n \n \n2. Wrike - 프로젝트 관리\n 프로젝트 관리, 계획 수립, 팀 협업을 위한 클라우드 기반의 소프트웨어로, 15,000곳 이상의 기업이 사용 중입니다. \n작업 자동화, 위험 예측, 폴더 및 프로젝트 액세스, 작업 배정 및 일정 조정, 알림 확인, 파일 첨부, 프로젝트 보기 조정 등 다양한 기능을 제공합니다. \n무료 앱으로 다운로드 가능하며, 비즈니스, 엔터프라이즈 등 다양한 플랜을 제공합니다.\n\n\n\n \nWrike - 프로젝트 관리 - Google Play 앱\n프로젝트 최신 상태를 확인하고 이동하면서 다른 사람들과 아이디어를 공유하세요.\nplay.google.com\n\n \n \n \n \n3. VLLO 블로, 나의 첫 동영상 편집기\n  쉬운 사용법으로 유명한 동영상 편집 앱입니다. \n직관적인 UI를 갖춰 초보자도 금세 익숙해질 수 있으며, 컷 편집, 자막, 스티커, 배경음악, 효과음 삽입과 전환 효과 등 기본적인 기능부터 전문가용 기능인 크로마키, PIP, 모자이크, 얼굴 인식, 키 프레임까지 폭 넓게 제공합니다. \n다양한 한국어 폰트와 트렌디한 스티커, 주기적인 업데이트로 사용자들의 만족도가 높습니다. 워터마크 없이 프로젝트를 저장할 수 있고, 결제를 강요하지 않는 것도 장점입니다.\n\n\n\n \nVLLO 블로, 나의 첫 동영상 편집기 - Google Play 앱\nAll-in-one 영상 편집앱, 블로! 저작권 걱정 없는 BGM&효과음, 자막, 필터, 보정, 모자이크, 크로마키, 음성녹음, 블러, 특수효과\nplay.google.com\n\n \n \n \n \n4. Docx 리더 - HWP, PDF, Docx, XLSX\n\n PDF, XLSX, PPTX, Sly 등 다양한 문서 형식을 지원하는 올인원 문서 편집 앱입니다. 사무실, 수업, 여행지 등 어디서나 문서를 만들고, 보고, 편집하고 공유할 수 있습니다. 이미지를 PDF, Slide, XLSX로 변환하거나 디지털화하고, 저장하거나 Google Drive에 업로드할 수 있습니다. HWP 파일을 포함한 모든 문서와 호환되며, 사용자 정의 글꼴 추가 기능도 제공합니다. 앱 내에서 협업 기능을 사용하여 실시간으로 문서를 작성하고 공동 작업할 수도 있습니다.\n\n\n\n \nDocx 리더 - HWP, PDF, Docx, XLSX - Google Play 앱\n뷰어 및 편집기 Docx Reader - HWP, DOC, Reader, TXT, XLSX, PPT, PPTX 및 PDF.\nplay.google.com\n\n \n \n \n \n5. Videoleap: 영상편집 전문, 동영상 편집 템플릿\n 고품질 동영상을 몇 분 만에 제작할 수 있는 혁신적인 무료 동영상 편집 앱입니다. 아트 효과, 텍스트 추가, 레이어 변환, 이미지 믹싱 등 다양한 기능을 제공하며 안드로이드 구글 플레이에서 다운로드할 수 있습니다.다른 유저들이 만든 콘텐츠를 검색하여 내 취향에 맞는 템플릿을 찾을 수 있고 이를 수정하여 사용할 수 있습니다.전문가용 고급 효과와 초보자도 쉽게 사용할 수 있는 직관적인 편집 기능을 모두 갖추고 있습니다.완성된 동영상은 자동 저장되며 워터마크가 없습니다.\n\n\n\n \nVideoleap: 영상편집 전문, 동영상 편집 템플릿 - Google Play 앱\n편리한 동영상 편집 앱을 찾고 계신가요? Videoleap 편집앱은 초보자도 놀라운 동영상을 쉽게 편집하도록 도와주는 강력한 영상편집어플입니다.\nplay.google.com",
        "guid": "http://muzbox.tistory.com/483450",
        "categories": [
          "ANDROID &amp; 모바일/추천 무료 앱",
          "ai이미지편집",
          "동영상 편집",
          "문서뷰어",
          "문서스캔",
          "안드로이드 추천 앱",
          "추천 어플",
          "프로젝트관리"
        ],
        "isoDate": "2024-07-15T04:58:26.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "스마트한 검색창 윈디로 편하게 사는법",
        "link": "http://muzbox.tistory.com/483449",
        "pubDate": "Fri, 12 Jul 2024 09:19:42 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483449#entry483449comment",
        "content": "<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\">&nbsp; 윈디는&nbsp;윈도우&nbsp;사용자들을&nbsp;위한&nbsp;스마트한&nbsp;검색&nbsp;프로그램입니다.&nbsp;빠른&nbsp;파일/폴더&nbsp;검색,&nbsp;웹&nbsp;검색,&nbsp;날씨&nbsp;검색&nbsp;등&nbsp;다양한&nbsp;기능을&nbsp;제공하여&nbsp;작업&nbsp;효율을&nbsp;극대화합니다.&nbsp; </p>\n<table style=\"border-collapse: collapse; width: 95.6979%; height: 248px;\" border=\"1\" data-ke-align=\"alignLeft\">\n<tbody>\n<tr style=\"height: 62px;\"><!-- 첫 번째 열에 배경색을 노란색으로 설정 -->\n<td style=\"width: 13.1835%; height: 62px; text-align: center; background-color: #555555;\"><span style=\"color: #ffffff;\"><b>분류</b></span></td>\n<td style=\"width: 22.4483%; height: 62px; text-align: center;\">유틸리티/파일관리</td>\n<td style=\"width: 64.3682%; height: 248px; text-align: center;\" rowspan=\"4\"><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"윈디1.png\" data-origin-width=\"551\" data-origin-height=\"367\"><span data-url=\"https://blog.kakaocdn.net/dn/48Wd4/btsIwdCIkx0/bqedPQoZqIKXNPhcKgbvX1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/48Wd4/btsIwdCIkx0/bqedPQoZqIKXNPhcKgbvX1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/48Wd4/btsIwdCIkx0/bqedPQoZqIKXNPhcKgbvX1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F48Wd4%2FbtsIwdCIkx0%2FbqedPQoZqIKXNPhcKgbvX1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"윈디1.png\" data-origin-width=\"551\" data-origin-height=\"367\"/></span></figure>\n</td>\n</tr>\n<tr style=\"height: 62px;\"><!-- 첫 번째 열에 배경색을 노란색으로 설정 -->\n<td style=\"width: 13.1835%; height: 62px; text-align: center; background-color: #555555;\"><span style=\"color: #ffffff;\"><b>사용범위</b></span></td>\n<td style=\"width: 22.4483%; height: 62px; text-align: center;\">무료(개인/기)</td>\n</tr>\n<tr style=\"height: 62px;\"><!-- 첫 번째 열에 배경색을 노란색으로 설정 -->\n<td style=\"width: 13.1835%; height: 62px; text-align: center; background-color: #555555;\"><span style=\"color: #ffffff;\"><b>사용환경</b></span></td>\n<td style=\"width: 22.4483%; height: 62px; text-align: center;\">Windows</td>\n</tr>\n<tr style=\"height: 62px;\"><!-- 첫 번째 열에 배경색을 노란색으로 설정 -->\n<td style=\"width: 13.1835%; height: 62px; text-align: center; background-color: #555555;\"><span style=\"color: #ffffff;\"><b>제작사</b></span></td>\n<td style=\"width: 22.4483%; height: 62px; text-align: center;\"><u><span style=\"color: #006dd7;\"><a style=\"color: #006dd7;\" href=\"https://sfsoftware.co.kr/\" target=\"_blank\" rel=\"noopener\">소셜프렌즈</a></span></u></td>\n</tr>\n</tbody>\n</table>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><b> 프로그램 소개</b></h2>\n<p data-ke-size=\"size18\">&nbsp; 윈디는&nbsp;윈도우&nbsp;사용자들에게&nbsp;클릭&nbsp;없이도&nbsp;파일/폴더&nbsp;검색,&nbsp;웹&nbsp;검색,&nbsp;날씨&nbsp;검색&nbsp;등을&nbsp;손쉽게&nbsp;할&nbsp;수&nbsp;있는&nbsp;스마트한&nbsp;검색&nbsp;프로그램입니다.&nbsp;간편한&nbsp;키보드&nbsp;조작만으로&nbsp;다양한&nbsp;검색과&nbsp;시스템&nbsp;명령을&nbsp;수행할&nbsp;수&nbsp;있어,&nbsp;사용자의&nbsp;작업&nbsp;효율을&nbsp;크게&nbsp;높여줍니다.&nbsp;</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\">이&nbsp;글에서는&nbsp;윈디의&nbsp;주요&nbsp;기능과&nbsp;장점,&nbsp;단점&nbsp;등을&nbsp;살펴보겠습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"스마트한 검색 창 윈디.png\" data-origin-width=\"500\" data-origin-height=\"500\"><span data-url=\"https://blog.kakaocdn.net/dn/5mExc/btsIvi5NQKa/S9ywJ3IkUdJN6Hi9X6TFKk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/5mExc/btsIvi5NQKa/S9ywJ3IkUdJN6Hi9X6TFKk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/5mExc/btsIvi5NQKa/S9ywJ3IkUdJN6Hi9X6TFKk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F5mExc%2FbtsIvi5NQKa%2FS9ywJ3IkUdJN6Hi9X6TFKk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"스마트한 검색창 윈디로 편하게 사는법\" data-filename=\"스마트한 검색 창 윈디.png\" data-origin-width=\"500\" data-origin-height=\"500\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><b> 주요 특징</b></h2>\n<p data-ke-size=\"size18\"><b>1. 빠른 파일/폴더 검색</b> <br />윈디는&nbsp;윈도우&nbsp;탐색기보다&nbsp;더&nbsp;빠르게&nbsp;파일,&nbsp;폴더,&nbsp;애플리케이션을&nbsp;검색할&nbsp;수&nbsp;있습니다.&nbsp;키보드&nbsp;방향키와&nbsp;엔터&nbsp;키만으로&nbsp;세부&nbsp;검색과&nbsp;실행을&nbsp;간편하게&nbsp;할&nbsp;수&nbsp;있어&nbsp;마우스를&nbsp;사용할&nbsp;필요가&nbsp;없습니다. <br /><br /><b>2. 기본 플러그인 바로 실행</b> <br />윈디는 기본 플러그인으로 계산기와 날씨 검색 기능을 제공합니다. 별도의 프로그램 실행 없이도 윈디 창에서 바로 계산과 날씨 검색을 할 수 있어 매우 편리합니다. 향후 추가될 플러그인 업데이트도 기대해 볼 만합니다.&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"윈디 플러그인.png\" data-origin-width=\"507\" data-origin-height=\"373\"><span data-url=\"https://blog.kakaocdn.net/dn/b5R2aB/btsIxKziD61/z2Jx4VyNyThUWWQxOtAwdK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/b5R2aB/btsIxKziD61/z2Jx4VyNyThUWWQxOtAwdK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/b5R2aB/btsIxKziD61/z2Jx4VyNyThUWWQxOtAwdK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb5R2aB%2FbtsIxKziD61%2Fz2Jx4VyNyThUWWQxOtAwdK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"윈디 플러그인.png\" data-origin-width=\"507\" data-origin-height=\"373\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\"><br /><br /><b>3. 웹사이트 검색</b> <br />웹&nbsp;브라우저를&nbsp;열지&nbsp;않고도&nbsp;구글,&nbsp;네이버,&nbsp;유튜브&nbsp;등에서&nbsp;검색을&nbsp;수행할&nbsp;수&nbsp;있는&nbsp;스마트한&nbsp;기능을&nbsp;제공합니다.&nbsp;액션키와&nbsp;검색어를&nbsp;입력하면&nbsp;검색&nbsp;결과를&nbsp;바로&nbsp;확인할&nbsp;수&nbsp;있어,&nbsp;검색&nbsp;단계를&nbsp;최소화할&nbsp;수&nbsp;있습니다. <br /><br /><b>4. 테마 설정</b> <br />윈디는&nbsp;사용자의&nbsp;취향에&nbsp;맞게&nbsp;다양한&nbsp;검색창&nbsp;테마를&nbsp;제공합니다.&nbsp;다크&nbsp;모드와&nbsp;라이트&nbsp;모드&nbsp;등&nbsp;여러&nbsp;테마를&nbsp;선택하여&nbsp;더욱&nbsp;트렌디하게&nbsp;사용할&nbsp;수&nbsp;있습니다. <br /><br /><b>5. 컴퓨터 시스템 명령</b> <br />화면&nbsp;잠금,&nbsp;시스템&nbsp;종료,&nbsp;제어판&nbsp;열기&nbsp;등&nbsp;자주&nbsp;사용하는&nbsp;시스템&nbsp;명령을&nbsp;윈디를&nbsp;통해&nbsp;빠르게&nbsp;실행할&nbsp;수&nbsp;있습니다.&nbsp;검색창에&nbsp;명령어를&nbsp;입력하면&nbsp;바로&nbsp;실행됩니다. </p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><b>  프로그램 장단점</b></h2>\n<h4 data-ke-size=\"size20\"><b> 장점</b></h4>\n<blockquote data-ke-style=\"style3\">1. 신속함: 윈디는 빠른 파일/폴더 검색 및 웹 검색에 최적화되어 있어 효율적인 작업이 가능합니다. <br />2. 간편함: 단축키(Alt+Space)를 사용해 마우스 없이도 키보드만으로 간편하게 조작할 수 있습니다. <br />3. 심플함: 직관적이고 심플한 UI로 다크, 라이트 등 다양한 테마 설정이 가능합니다. 사용자가 원하는 대로 인터페이스를 조정할 수 있습니다.</blockquote>\n<h4 data-ke-size=\"size20\"><b> 단점</b></h4>\n<blockquote data-ke-style=\"style3\">1. 플러그인 제한: 현재 제공되는 기본 플러그인이 제한적이어서 사용자 요구에 따라 추가 플러그인 업데이트가 필요합니다. <br />2. 학습 곡선: 새로운 인터페이스와 단축키 사용에 익숙해지기까지 다소 시간이 필요할 수 있습니다. <br />3. 시스템 자원 사용: 백그라운드에서 실행되는 프로그램이므로 시스템 자원을 다소 사용합니다.</blockquote>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><b>  간단 활용법</b></h2>\n<p data-ke-size=\"size18\"><b>윈디 설치 및 실행</b> <br />1.&nbsp;윈디&nbsp;다운로드&nbsp;및&nbsp;설치:&nbsp;윈디&nbsp;공식&nbsp;웹사이트에서&nbsp;프로그램을&nbsp;다운로드하고&nbsp;설치합니다. <br />2.&nbsp;프로그램&nbsp;실행:&nbsp;단축키&nbsp;`Alt+Enter`를&nbsp;눌러&nbsp;윈디를&nbsp;실행합니다. <br /><br /><b>기본 검색 기능 사용</b> <br />1. 파일/폴더 검색: 검색창에 찾고자 하는 파일이나 폴더 이름을 입력하고 `Enter` 키를 누릅니다. ▼</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"윈디1.png\" data-origin-width=\"551\" data-origin-height=\"367\"><span data-url=\"https://blog.kakaocdn.net/dn/Mvv0u/btsIwgGcRNt/Yu7pwbW2ifk8yYq6OUskTK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/Mvv0u/btsIwgGcRNt/Yu7pwbW2ifk8yYq6OUskTK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/Mvv0u/btsIwgGcRNt/Yu7pwbW2ifk8yYq6OUskTK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FMvv0u%2FbtsIwgGcRNt%2FYu7pwbW2ifk8yYq6OUskTK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"윈디1.png\" data-origin-width=\"551\" data-origin-height=\"367\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\"><br />2. 웹 검색: 액션키(`g` for 구글, `n` for 네이버 등)와 검색어를 함께 입력하고 `Enter`를 눌러 검색 결과를 확인합니다. ▼</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"윈디 웹검색.png\" data-origin-width=\"545\" data-origin-height=\"363\"><span data-url=\"https://blog.kakaocdn.net/dn/bfM9lC/btsIweIn22P/yrF2tFpzPUO1gqDlMPT2b0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bfM9lC/btsIweIn22P/yrF2tFpzPUO1gqDlMPT2b0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bfM9lC/btsIweIn22P/yrF2tFpzPUO1gqDlMPT2b0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbfM9lC%2FbtsIweIn22P%2FyrF2tFpzPUO1gqDlMPT2b0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"윈디 웹검색.png\" data-origin-width=\"545\" data-origin-height=\"363\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\"><br /><br /><b>추가 기능 활용</b> <br />1. 계산기: 검색창에 수식을 입력하면 자동으로 계산 결과를 제공합니다. ▼</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"윈디 계산기.png\" data-origin-width=\"545\" data-origin-height=\"361\"><span data-url=\"https://blog.kakaocdn.net/dn/tDXgk/btsIwZjpf5G/WDZh2j8CPKxUS4x1F0yHwK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/tDXgk/btsIwZjpf5G/WDZh2j8CPKxUS4x1F0yHwK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/tDXgk/btsIwZjpf5G/WDZh2j8CPKxUS4x1F0yHwK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FtDXgk%2FbtsIwZjpf5G%2FWDZh2j8CPKxUS4x1F0yHwK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"윈디 계산기.png\" data-origin-width=\"545\" data-origin-height=\"361\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\"><br />2.&nbsp;날씨&nbsp;검색:&nbsp;`날씨&nbsp;+&nbsp;지역`을&nbsp;입력하여&nbsp;해당&nbsp;지역의&nbsp;날씨&nbsp;정보를&nbsp;확인할&nbsp;수&nbsp;있습니다. ▼</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"윈디 날씨.png\" data-origin-width=\"545\" data-origin-height=\"363\"><span data-url=\"https://blog.kakaocdn.net/dn/lWemq/btsIwnrCM64/j5DbNZYrHTC10rdEcB6R11/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/lWemq/btsIwnrCM64/j5DbNZYrHTC10rdEcB6R11/img.png\"><img src=\"https://blog.kakaocdn.net/dn/lWemq/btsIwnrCM64/j5DbNZYrHTC10rdEcB6R11/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FlWemq%2FbtsIwnrCM64%2Fj5DbNZYrHTC10rdEcB6R11%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"윈디 날씨.png\" data-origin-width=\"545\" data-origin-height=\"363\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\"><br />3. 시스템 명령: `lock`, `shutdown`, `control panel` 등의 명령어를 입력하여 시스템 명령을 실행합니다. ▼</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"윈디 시스템.png\" data-origin-width=\"545\" data-origin-height=\"361\"><span data-url=\"https://blog.kakaocdn.net/dn/chW217/btsIwX0ceM9/cWaMqEjKC3D53wnWgrxD60/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/chW217/btsIwX0ceM9/cWaMqEjKC3D53wnWgrxD60/img.png\"><img src=\"https://blog.kakaocdn.net/dn/chW217/btsIwX0ceM9/cWaMqEjKC3D53wnWgrxD60/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FchW217%2FbtsIwX0ceM9%2FcWaMqEjKC3D53wnWgrxD60%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"윈디 시스템.png\" data-origin-width=\"545\" data-origin-height=\"361\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\"><br /><br /><b>테마 설정</b> <br />1. 테마 변경: 설정 메뉴에서 다크 모드, 라이트 모드 등 원하는 테마를 선택하여 검색창의 테마를 변경할 수 있습니다. ▼</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"윈디 테마.png\" data-origin-width=\"509\" data-origin-height=\"375\"><span data-url=\"https://blog.kakaocdn.net/dn/3ANze/btsIxK68dpV/elOMP8xYG2qrmNKaD0E2zK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/3ANze/btsIxK68dpV/elOMP8xYG2qrmNKaD0E2zK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/3ANze/btsIxK68dpV/elOMP8xYG2qrmNKaD0E2zK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F3ANze%2FbtsIxK68dpV%2FelOMP8xYG2qrmNKaD0E2zK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"윈디 테마.png\" data-origin-width=\"509\" data-origin-height=\"375\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<h2 style=\"color: #000000; text-align: start;\" data-ke-size=\"size26\"><b>  라이센스 정책</b></h2>\n<p data-ke-size=\"size18\">&nbsp;윈디는 개인 및 상업적 용도로 모두 무료로 제공되는 프리웨어입니다. 사용자는 소프트웨어를 자유롭게 다운로드하여 설치하고 사용할 수 있으며, 추가 비용 없이 모든 기능을 이용할 수 있습니다.&nbsp;</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><b>⬇️ 프로그램 다운로드</b></h2>\n\n<p data-ke-size=\"size16\">&nbsp;</p>\n<figure id=\"og_1720743289899\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"Social Freinds (소셜프렌즈) &ndash; 윈도우 메모장 프로그램 위메모, 윈도우 스팟라이트 윈디\" data-og-description=\"직관적이며 심플한 UI 다크, 라이트 등 테마 설정이 가능합니다\" data-og-host=\"sfsoftware.co.kr\" data-og-source-url=\"https://sfsoftware.co.kr/\" data-og-url=\"https://sfsoftware.co.kr/\" data-og-image=\"https://scrap.kakaocdn.net/dn/b4GlVk/hyWvKtGNpE/Y2tEJUAOxqHmQT0CgLoUaK/img.png?width=1024&amp;height=843&amp;face=0_0_1024_843,https://scrap.kakaocdn.net/dn/bMqkCt/hyWvUb0X9F/YCm8FJxBo2y7hVkm0yHeck/img.png?width=1024&amp;height=843&amp;face=0_0_1024_843,https://scrap.kakaocdn.net/dn/bJFdgU/hyWzEyzZnb/T8W0ZAAerv7KRdAvihJn40/img.png?width=1024&amp;height=796&amp;face=0_0_1024_796\"><a href=\"https://sfsoftware.co.kr/\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://sfsoftware.co.kr/\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/b4GlVk/hyWvKtGNpE/Y2tEJUAOxqHmQT0CgLoUaK/img.png?width=1024&amp;height=843&amp;face=0_0_1024_843,https://scrap.kakaocdn.net/dn/bMqkCt/hyWvUb0X9F/YCm8FJxBo2y7hVkm0yHeck/img.png?width=1024&amp;height=843&amp;face=0_0_1024_843,https://scrap.kakaocdn.net/dn/bJFdgU/hyWzEyzZnb/T8W0ZAAerv7KRdAvihJn40/img.png?width=1024&amp;height=796&amp;face=0_0_1024_796');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">Social Freinds (소셜프렌즈) &ndash; 윈도우 메모장 프로그램 위메모, 윈도우 스팟라이트 윈디</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">직관적이며 심플한 UI 다크, 라이트 등 테마 설정이 가능합니다</p>\n<p class=\"og-host\" data-ke-size=\"size16\">sfsoftware.co.kr</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "윈디는 윈도우 사용자들을 위한 스마트한 검색 프로그램입니다. 빠른 파일/폴더 검색, 웹 검색, 날씨 검색 등 다양한 기능을 제공하여 작업 효율을 극대화합니다.  \n\n분류\n유틸리티/파일관리\n\n\n\n\n사용범위\n무료(개인/기)\n\n\n사용환경\nWindows\n\n\n제작사\n소셜프렌즈\n\n\n\n \n 프로그램 소개\n  윈디는 윈도우 사용자들에게 클릭 없이도 파일/폴더 검색, 웹 검색, 날씨 검색 등을 손쉽게 할 수 있는 스마트한 검색 프로그램입니다. 간편한 키보드 조작만으로 다양한 검색과 시스템 명령을 수행할 수 있어, 사용자의 작업 효율을 크게 높여줍니다. \n \n이 글에서는 윈디의 주요 기능과 장점, 단점 등을 살펴보겠습니다.\n\n\n \n 주요 특징\n1. 빠른 파일/폴더 검색 \n윈디는 윈도우 탐색기보다 더 빠르게 파일, 폴더, 애플리케이션을 검색할 수 있습니다. 키보드 방향키와 엔터 키만으로 세부 검색과 실행을 간편하게 할 수 있어 마우스를 사용할 필요가 없습니다. \n2. 기본 플러그인 바로 실행 \n윈디는 기본 플러그인으로 계산기와 날씨 검색 기능을 제공합니다. 별도의 프로그램 실행 없이도 윈디 창에서 바로 계산과 날씨 검색을 할 수 있어 매우 편리합니다. 향후 추가될 플러그인 업데이트도 기대해 볼 만합니다. \n\n\n\n3. 웹사이트 검색 \n웹 브라우저를 열지 않고도 구글, 네이버, 유튜브 등에서 검색을 수행할 수 있는 스마트한 기능을 제공합니다. 액션키와 검색어를 입력하면 검색 결과를 바로 확인할 수 있어, 검색 단계를 최소화할 수 있습니다. \n4. 테마 설정 \n윈디는 사용자의 취향에 맞게 다양한 검색창 테마를 제공합니다. 다크 모드와 라이트 모드 등 여러 테마를 선택하여 더욱 트렌디하게 사용할 수 있습니다. \n5. 컴퓨터 시스템 명령 \n화면 잠금, 시스템 종료, 제어판 열기 등 자주 사용하는 시스템 명령을 윈디를 통해 빠르게 실행할 수 있습니다. 검색창에 명령어를 입력하면 바로 실행됩니다. \n \n \n  프로그램 장단점\n 장점\n1. 신속함: 윈디는 빠른 파일/폴더 검색 및 웹 검색에 최적화되어 있어 효율적인 작업이 가능합니다. \n2. 간편함: 단축키(Alt+Space)를 사용해 마우스 없이도 키보드만으로 간편하게 조작할 수 있습니다. \n3. 심플함: 직관적이고 심플한 UI로 다크, 라이트 등 다양한 테마 설정이 가능합니다. 사용자가 원하는 대로 인터페이스를 조정할 수 있습니다.\n 단점\n1. 플러그인 제한: 현재 제공되는 기본 플러그인이 제한적이어서 사용자 요구에 따라 추가 플러그인 업데이트가 필요합니다. \n2. 학습 곡선: 새로운 인터페이스와 단축키 사용에 익숙해지기까지 다소 시간이 필요할 수 있습니다. \n3. 시스템 자원 사용: 백그라운드에서 실행되는 프로그램이므로 시스템 자원을 다소 사용합니다.\n \n \n  간단 활용법\n윈디 설치 및 실행 \n1. 윈디 다운로드 및 설치: 윈디 공식 웹사이트에서 프로그램을 다운로드하고 설치합니다. \n2. 프로그램 실행: 단축키 `Alt+Enter`를 눌러 윈디를 실행합니다. \n기본 검색 기능 사용 \n1. 파일/폴더 검색: 검색창에 찾고자 하는 파일이나 폴더 이름을 입력하고 `Enter` 키를 누릅니다. ▼\n\n\n \n2. 웹 검색: 액션키(`g` for 구글, `n` for 네이버 등)와 검색어를 함께 입력하고 `Enter`를 눌러 검색 결과를 확인합니다. ▼\n\n\n\n추가 기능 활용 \n1. 계산기: 검색창에 수식을 입력하면 자동으로 계산 결과를 제공합니다. ▼\n\n\n \n2. 날씨 검색: `날씨 + 지역`을 입력하여 해당 지역의 날씨 정보를 확인할 수 있습니다. ▼\n\n\n \n3. 시스템 명령: `lock`, `shutdown`, `control panel` 등의 명령어를 입력하여 시스템 명령을 실행합니다. ▼\n\n\n\n테마 설정 \n1. 테마 변경: 설정 메뉴에서 다크 모드, 라이트 모드 등 원하는 테마를 선택하여 검색창의 테마를 변경할 수 있습니다. ▼\n\n\n \n  라이센스 정책\n 윈디는 개인 및 상업적 용도로 모두 무료로 제공되는 프리웨어입니다. 사용자는 소프트웨어를 자유롭게 다운로드하여 설치하고 사용할 수 있으며, 추가 비용 없이 모든 기능을 이용할 수 있습니다. \n \n⬇️ 프로그램 다운로드\n \n\n \nSocial Freinds (소셜프렌즈) – 윈도우 메모장 프로그램 위메모, 윈도우 스팟라이트 윈디\n직관적이며 심플한 UI 다크, 라이트 등 테마 설정이 가능합니다\nsfsoftware.co.kr",
        "guid": "http://muzbox.tistory.com/483449",
        "categories": [
          "추천 프리웨어/시스템관리,보안",
          "It",
          "공개자료실",
          "스마트 검색 프로그램",
          "웹 검색 플러그인",
          "윈도우 검색 도구",
          "윈도우 유틸리티",
          "윈디",
          "키보드 검색 도구",
          "파일 검색 프로그램",
          "프리웨어"
        ],
        "isoDate": "2024-07-12T00:19:42.000Z"
      }
    ]
  },
  {
    "name": "동우리의 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "하테나",
    "category": "개인",
    "posts": []
  },
  {
    "name": "늑돌이네 라지온",
    "category": "개인",
    "posts": [
      {
        "creator": "늑돌이",
        "title": "1등 10만달러! 글로벌 webOS 해커톤 여는 LG전자",
        "link": "http://lazion.com/2513714",
        "pubDate": "Wed, 10 Jul 2024 13:36:54 +0900",
        "author": "늑돌이",
        "comments": "http://lazion.com/2513714#entry2513714comment",
        "content": "<h3 data-ke-size=\"size23\">LG전자가 자사의 스마트TV 플랫폼인 <b>webOS</b>에 탑재할 게임과 라이프스타일, 인공지능(AI) 활용 콘텐츠를 모집하는 <b>글로벌 해커톤(Hackathon)을 개최</b>합니다.</h3>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"001 - 56870_web.jpg\" data-origin-width=\"856\" data-origin-height=\"542\"><span data-url=\"https://blog.kakaocdn.net/dn/cSgu6m/btsItHwW5V9/giFnMNdOkTKq6oWPYNTYz0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/cSgu6m/btsItHwW5V9/giFnMNdOkTKq6oWPYNTYz0/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/cSgu6m/btsItHwW5V9/giFnMNdOkTKq6oWPYNTYz0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcSgu6m%2FbtsItHwW5V9%2FgiFnMNdOkTKq6oWPYNTYz0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"001 - 56870_web.jpg\" data-origin-width=\"856\" data-origin-height=\"542\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\"><a href=\"https://weboshackathon.lge.com/\" target=\"_blank\" rel=\"noopener\">북미이노베이션센터(LG NOVA) 홈페이지를 통해 발표</a>된 이번 글로벌 해커톤 행사는 webOS 콘텐츠의 경쟁력을 향상시켜 webOS의 TV 플랫폼 사업을 확대하는 개방형 혁신 활동의 일환으로 진행됩니다.</p>\n<p data-ke-size=\"size16\">이미 LG전자는 TV 사업의 지향점을 미디어&amp;엔터테인먼트 플랫폼 기업으로 삼고 올해 webOS 플랫폼 사업을 조(兆) 단위 매출 규모로 키우겠다고 밝힌 바 있습니다.<br />&nbsp;</p>\n<p data-ke-size=\"size16\">현재 webOS에는 엔터테인먼트, 홈피트니스, 교육, 원격의료 등 약 3,500여개 앱 콘텐츠가 준비되어 있으며 글로벌 기준으로 webOS로 즐길 수 있는 게임은 500여개의 앱이 있습니다. 만약 지포스 나우(GeForce NOW), 아마존 루나(Amazon Luna) 등 클라우드 게이밍 서비스 내 게임을 합친다면 3,000여개까지 가능합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;<br />해커톤 참가를 원하는 글로벌 개발자들은 7월 26일까지 <span style=\"color: #0593d3;\"><a href=\"https://weboshackathon.lge.com/\" target=\"_blank\" rel=\"noopener\">공식 홈페이지(https://weboshackathon.lge.com/)</a></span>로 지원서를 제출해야 합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"002 - 56869_web.jpg\" data-origin-width=\"856\" data-origin-height=\"563\"><span data-url=\"https://blog.kakaocdn.net/dn/bEq2wq/btsIuSxwP5k/ETz6d4y89LqNRVs4uR3xgk/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bEq2wq/btsIuSxwP5k/ETz6d4y89LqNRVs4uR3xgk/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/bEq2wq/btsIuSxwP5k/ETz6d4y89LqNRVs4uR3xgk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbEq2wq%2FbtsIuSxwP5k%2FETz6d4y89LqNRVs4uR3xgk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"002 - 56869_web.jpg\" data-origin-width=\"856\" data-origin-height=\"563\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">선정된 수상자에게는 <b>1등은 10만달러(약 1억3천9백만원)</b>, 2등은 8만달러, 3등은 5만달러 등의 상금과 함께 개발한 콘텐츠를 webOS를 탑재한 2억대 넘는 스마트TV를 대상으로 사업화할 수 있는 하는 기회도 주어집니다. 참고로 콘텐츠 개발 과정에서 LG전자 전문가들로부터 기술 지원도 받을 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"text-align: right;\" data-ke-size=\"size16\">(출처 : <a href=\"https://www.lge.co.kr/\" target=\"_blank\" rel=\"noopener\">LG전자</a>)</p>",
        "contentSnippet": "LG전자가 자사의 스마트TV 플랫폼인 webOS에 탑재할 게임과 라이프스타일, 인공지능(AI) 활용 콘텐츠를 모집하는 글로벌 해커톤(Hackathon)을 개최합니다.\n\n\n북미이노베이션센터(LG NOVA) 홈페이지를 통해 발표된 이번 글로벌 해커톤 행사는 webOS 콘텐츠의 경쟁력을 향상시켜 webOS의 TV 플랫폼 사업을 확대하는 개방형 혁신 활동의 일환으로 진행됩니다.\n이미 LG전자는 TV 사업의 지향점을 미디어&엔터테인먼트 플랫폼 기업으로 삼고 올해 webOS 플랫폼 사업을 조(兆) 단위 매출 규모로 키우겠다고 밝힌 바 있습니다.\n \n현재 webOS에는 엔터테인먼트, 홈피트니스, 교육, 원격의료 등 약 3,500여개 앱 콘텐츠가 준비되어 있으며 글로벌 기준으로 webOS로 즐길 수 있는 게임은 500여개의 앱이 있습니다. 만약 지포스 나우(GeForce NOW), 아마존 루나(Amazon Luna) 등 클라우드 게이밍 서비스 내 게임을 합친다면 3,000여개까지 가능합니다.\n \n해커톤 참가를 원하는 글로벌 개발자들은 7월 26일까지 공식 홈페이지(https://weboshackathon.lge.com/)로 지원서를 제출해야 합니다.\n \n\n\n \n선정된 수상자에게는 1등은 10만달러(약 1억3천9백만원), 2등은 8만달러, 3등은 5만달러 등의 상금과 함께 개발한 콘텐츠를 webOS를 탑재한 2억대 넘는 스마트TV를 대상으로 사업화할 수 있는 하는 기회도 주어집니다. 참고로 콘텐츠 개발 과정에서 LG전자 전문가들로부터 기술 지원도 받을 수 있습니다.\n \n(출처 : LG전자)",
        "guid": "http://lazion.com/2513714",
        "categories": [
          "#소프트웨어#앱#서비스",
          "Hackathon",
          "LG",
          "LGE",
          "News",
          "SmartTV",
          "Software",
          "TV",
          "WEBOS"
        ],
        "isoDate": "2024-07-10T04:36:54.000Z"
      }
    ]
  },
  {
    "name": "루리웹 - 루리웹 리뷰 게시판",
    "category": "게임",
    "posts": [
      {
        "creator": "｜RULIWEB｜",
        "title": "[게임툰] 탐정이 사신쨩을 숨김, 초탐정사건부 레인코드",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2235",
        "pubDate": "Thu, 11 Jul 2024 16:41:54 +0900",
        "author": "｜RULIWEB｜",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i1.ruliweb.com/thumb/24/07/11/190a0953b8e51ad6b.png\">",
        "contentSnippet": "",
        "categories": [
          "게임툰"
        ],
        "isoDate": "2024-07-11T07:41:54.000Z"
      },
      {
        "creator": "［RULIWEB］",
        "title": "[MULTI] 두 개의 DNA가 만든 기초와 후반 집중 그라인딩, 퍼스트 디센던트",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2234",
        "pubDate": "Tue, 09 Jul 2024 13:48:10 +0900",
        "author": "［RULIWEB］",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i3.ruliweb.com/thumb/24/07/09/19095d14db05104c1.jpg\">",
        "contentSnippet": "",
        "categories": [
          "리뷰"
        ],
        "isoDate": "2024-07-09T04:48:10.000Z"
      }
    ]
  },
  {
    "name": "Reasontobe",
    "category": "개인",
    "posts": []
  },
  {
    "name": "자유로운 생활",
    "category": "개인",
    "posts": []
  },
  {
    "name": "에스티마의 인터넷이야기 EstimaStory.com",
    "category": "개인",
    "posts": []
  },
  {
    "name": "나긋한 개발 - 데비안 리눅스와 프로그램 언어",
    "category": "개인",
    "posts": []
  },
  {
    "name": "일상을 여행처럼...",
    "category": "개인",
    "posts": []
  },
  {
    "name": "khris'log",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Just hack'em",
    "category": "개인",
    "posts": []
  },
  {
    "name": "C++ Truths",
    "category": "개인",
    "posts": []
  },
  {
    "name": "jacking75",
    "category": "개인",
    "posts": [
      {
        "title": "Visual C++ - 리팩터링 도구",
        "link": "https://jacking75.github.io/VS_20240712/",
        "pubDate": "Fri, 12 Jul 2024 00:00:00 +0900",
        "content": "<iframe width=\"1024\" height=\"1024\" src=\"https://docs.google.com/document/d/e/2PACX-1vQ3mKCaWpwuh-q2xhHR49Wlz90iBQuHaVVU0W90Vs785x7kbgL7-t4-zYUU7XlgguXATi6_M73dXs8n/pub?embedded=true\"></iframe>\n\n",
        "contentSnippet": "",
        "guid": "https://jacking75.github.io/VS_20240712/",
        "isoDate": "2024-07-11T15:00:00.000Z"
      },
      {
        "title": "GitHub Copilot 명령어",
        "link": "https://jacking75.github.io/tech-ai_20240711/",
        "pubDate": "Thu, 11 Jul 2024 00:00:00 +0900",
        "content": "<iframe width=\"1024\" height=\"1024\" src=\"https://docs.google.com/document/d/e/2PACX-1vTmSSv2NBS-inJxrJkfNuAsRVCTnXAZkv8-ZEevtY-53JhJeaHuM2Xw8_ezOjH6inK7jmi5zTwZFcMz/pub?embedded=true\"></iframe>\n\n",
        "contentSnippet": "",
        "guid": "https://jacking75.github.io/tech-ai_20240711/",
        "isoDate": "2024-07-10T15:00:00.000Z"
      }
    ]
  },
  {
    "name": "Joel on Software",
    "category": "개인",
    "posts": []
  },
  {
    "name": "벤자민로그",
    "category": "개인",
    "posts": [
      {
        "title": "운영체제 넘나들기",
        "link": "https://jeho.page/essay/2024/07/15/crossing-operating-systems.html",
        "pubDate": "2024-07-14T23:06:00.000Z",
        "author": "김재호",
        "content": "<p><a href=\"https://kyoungwon.me/articles/2024/07/11/Living-with-Linux-and-Android-after-two-decades-of-Apple/\">DHH가 개발 환경을 애플에서 Linux 와 안드로이드로 바꾼 이야기</a>를 재밌게 읽었습니다.<br />\n처음엔 <a href=\"https://world.hey.com/dhh/i-could-have-been-happy-with-windows-bd4a7d01\">Windows로 바꾸려 했는데</a> 잘 안됐는지 결국 Linux에 정착하기로 한 모양입니다.<br />\n개발자를 위한 오마카세 셋업이라는 <a href=\"https://omakub.org/\">Omakub</a>도 공개를 했는데 저도 한 번 설치해 봐야겠습니다.</p>\n\n<p>한 가지 운영체제에 익숙해지면 사실 빠져나오기가 어렵습니다.<br />\n아이폰을 오랫동안 쓰다가 안드로이드로 넘어가거나, 안드로이드에서 아이폰으로 넘어갈 땐 용기가 필요합니다.<br />\n일상생활이 힘들어질 테니까.</p>\n\n<p>저는 오래전부터 이런 용기 하나는 잘 냈습니다.<br />\n2007년부터 리눅스 데스크톱을 사용해왔습니다.<br />\n핸드폰은 항상 안드로이드와 아이폰을 (그리고 한때는 윈도폰까지) 같이 들고 다녔습니다.</p>\n\n<p><img src=\"/assets/img/winphone8.png\" alt=\"카톡 윈도폰 개발 시절\" /><br />\n<em>2014년, Windows Phone 8 용 카카오톡을 만들던 시절.</em></p>\n\n<p>메인 폰을 변경하면 고통스러운 기간이 따르지만, 감수해야 한다고 생각하며 꽤 즐겁게 하는 편입니다.</p>\n\n<p>이렇게 플랫폼별로 익숙해지려는 노력을 하는 것은 두 가지 이유가 있는 것 같습니다.</p>\n\n<p>첫 번째는 서비스 개발자로서 운영체제와 그 생태계를 더 잘 알기 위해서.<br />\n그냥 핸드폰만 두 개 들고 다니는 것이 아니라 메인으로 쓰는 폰의 운영체제도 주기적으로 바꿉니다. (약 2년)<br />\n단순히 내 앱이 잘 동작하는지 테스트하는 것을 넘어서…  <br />\n내가 그 운영체제를 온전히 느낄 수 있도록 풍덩 빠져드는 것입니다.</p>\n\n<p>두 번째로는 그냥 재미로.<br />\n이런 일이 누군가에게는 고통스러운 일이겠지만…<br />\n이상하게도 저에게는 재밌는 일들입니다.<br />\n물론 제게도 답답함과 고통이 따르긴 하지만, 아무래도 재미가 더 큰 것 같습니다.<br />\n아직까지도 신기한 것을 보면 좋아하는 어린아이의 맘을 가지고 있는 것일까요? (그렇다면 좋겠네요)</p>\n\n<p>DHH의 글을 읽으며 가만 생각해 보니 메인 폰으로 아이폰을 사용한 지 만 4년이 됐습니다.<br />\n이렇게 오랫동안 한 운영체제만 쓰기는 처음입니다.<br />\n보통은 2년에 한 번씩은 반드시 메인 폰의 운영체제를 변경하거든요.</p>\n\n<p>어쩐지 너무 편안하다 했습니다.<br />\n맘에 드는 안드로이드폰이 없어서 조금 미적거렸는데…<br />\n구글 픽셀이 새로 나오면 다시 안드로이드로 전환해야겠다는 마음을 먹었습니다.\n<br />\n<br />\n<em>함께 읽으면 좋은 글:</em></p>\n<ul>\n  <li><a href=\"/essay/2021/08/25/무슨-운영체제를-가장-좋아하나요.html\">무슨 운영체제를 가장 좋아하나요?</a></li>\n  <li><a href=\"/essay/2022/02/12/ios-android.html\">아이폰과 안드로이드</a></li>\n</ul>",
        "contentSnippet": "DHH가 개발 환경을 애플에서 Linux 와 안드로이드로 바꾼 이야기를 재밌게 읽었습니다.\nWindows로 바꾸려 했는데 잘 안됐는지 결국 Linux에 정착하기로 한 모양입니다.\nOmakub도 공개를 했는데 저도 한 번 설치해 봐야겠습니다.\n한 가지 운영체제에 익숙해지면 사실 빠져나오기가 어렵습니다.\n저는 오래전부터 이런 용기 하나는 잘 냈습니다.\n\n2014년, Windows Phone 8 용 카카오톡을 만들던 시절.\n메인 폰을 변경하면 고통스러운 기간이 따르지만, 감수해야 한다고 생각하며 꽤 즐겁게 하는 편입니다.\n이렇게 플랫폼별로 익숙해지려는 노력을 하는 것은 두 가지 이유가 있는 것 같습니다.\n첫 번째는 서비스 개발자로서 운영체제와 그 생태계를 더 잘 알기 위해서.\n두 번째로는 그냥 재미로.\nDHH의 글을 읽으며 가만 생각해 보니 메인 폰으로 아이폰을 사용한 지 만 4년이 됐습니다.\n어쩐지 너무 편안하다 했습니다.\n함께 읽으면 좋은 글:\n무슨 운영체제를 가장 좋아하나요?\n아이폰과 안드로이드",
        "summary": "DHH가 개발 환경을 애플에서 Linux 와 안드로이드로 바꾼 이야기를 재밌게 읽었습니다. 처음엔 Windows로 바꾸려 했는데 잘 안됐는지 결국 Linux에 정착하기로 한 모양입니다. 개발자를 위한 오마카세 셋업이라는 Omakub도 공개를 했는데 저도 한 번 설치해 봐야겠습니다.",
        "id": "https://jeho.page/essay/2024/07/15/crossing-operating-systems",
        "isoDate": "2024-07-14T23:06:00.000Z"
      },
      {
        "title": "루비 온 레일즈 소식지",
        "link": "https://jeho.page/essay/2024/07/09/rails-news-letter.html",
        "pubDate": "2024-07-09T04:15:00.000Z",
        "author": "김재호",
        "content": "<p>루비 온 레일즈의 따끈따끈한 소식을 전달해 주는 한국어 소식지가 생겼습니다.</p>\n\n<p>소식지를 쓰는 사람은 이전 회사의 동료입니다.<br />\n10년 전에 카카오에서 레일즈로 서버 개발을 하던 당시에, 자리에 찾아와서 레일즈 배포 방법 같은 걸 귀찮게 물어보던 클라이언트 개발자가 있었습니다.<br />\n귀찮았지만(ㅋㅋ) 열심히 가르쳐 줬던 것 같습니다.<br />\n그러다가 시간이 흘러 카톡 서버팀으로 와서 함께 일하게 됐고… 큰 힘이 됐던 동료입니다.</p>\n\n<p><img src=\"/assets/img/rails_news.png\" alt=\"레일즈 소식지\" /><br />\n<em>레일즈를 좋아하는 사람들에게는 단비 같은 뉴스</em></p>\n\n<p>오늘 <a href=\"https://maily.so/rubyonrails/posts/3a2526c1\">두 번째 소식</a>을 받아봤는데 <a href=\"https://maily.so/rubyonrails/posts/8399b690\">첫 번째 소식지</a> 만큼이나 만족스럽습니다.<br />\n딱 이 정도 퀄리티로 꾸준하게 받아볼 수 있다면 제게 가장 기다려지는 소식지가 될 것 같습니다.</p>\n\n<p>레일즈에 관심 있는 사람들이 많이 구독하고 피드백하면서 계속 발전해나가면 좋겠습니다.\n<br />\n<br />\n<em>함께 읽으면 좋은 글:</em></p>\n<ul>\n  <li><a href=\"/essay/2021/12/17/ruby-on-rails-7.html\">루비 온 레일즈 7</a></li>\n  <li><a href=\"/essay/2023/01/04/dont-say-ruby-is-slow.html\">루비가 느리다고?</a></li>\n</ul>",
        "contentSnippet": "루비 온 레일즈의 따끈따끈한 소식을 전달해 주는 한국어 소식지가 생겼습니다.\n소식지를 쓰는 사람은 이전 회사의 동료입니다.\n\n레일즈를 좋아하는 사람들에게는 단비 같은 뉴스\n오늘 두 번째 소식을 받아봤는데 첫 번째 소식지 만큼이나 만족스럽습니다.\n레일즈에 관심 있는 사람들이 많이 구독하고 피드백하면서 계속 발전해나가면 좋겠습니다.\n\n\n함께 읽으면 좋은 글:\n루비 온 레일즈 7\n루비가 느리다고?",
        "summary": "루비 온 레일즈의 따끈따끈한 소식을 전달해 주는 한국어 소식지가 생겼습니다.",
        "id": "https://jeho.page/essay/2024/07/09/rails-news-letter",
        "isoDate": "2024-07-09T04:15:00.000Z"
      }
    ]
  },
  {
    "name": "악보쓰는 프로그래머",
    "category": "개인",
    "posts": []
  },
  {
    "name": "쭌안아빠",
    "category": "개인",
    "posts": []
  },
  {
    "name": "A Gangster World",
    "category": "개인",
    "posts": []
  },
  {
    "name": "요우의 내맘대로 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자스럽다",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Against All Odds.",
    "category": "개인",
    "posts": []
  },
  {
    "name": "움직이는 게임서버",
    "category": "개인",
    "posts": []
  },
  {
    "name": "이상욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "임철재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "어쩐지 오늘은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "oddpoet’s étude",
    "category": "개인",
    "posts": []
  },
  {
    "name": "0x00 - NULL",
    "category": "개인",
    "posts": []
  },
  {
    "name": "퇴근 후 서버다운",
    "category": "개인",
    "posts": [
      {
        "creator": "SIDNFT",
        "title": "디아2 / 핏빛 큰까마귀의 돌진 / 메이트리어컬 보우 / Blood Raven's Charge",
        "link": "http://serverdown.tistory.com/784",
        "pubDate": "Mon, 15 Jul 2024 20:46:52 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/784#entry784comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"427\" data-origin-height=\"607\"><span data-url=\"https://blog.kakaocdn.net/dn/bk33x1/btsIANQXCSd/5HS6tH4tE2gaOnnBt5IlkK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bk33x1/btsIANQXCSd/5HS6tH4tE2gaOnnBt5IlkK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bk33x1/btsIANQXCSd/5HS6tH4tE2gaOnnBt5IlkK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbk33x1%2FbtsIANQXCSd%2F5HS6tH4tE2gaOnnBt5IlkK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"427\" data-origin-height=\"607\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">이거 상점행이라고 글을 적혀있어서 상점행인줄알고 파시는 분이 많은데</p>\n<p data-ke-size=\"size16\">조화나 수리뿔 보단 좋습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">폴발하는 화살은 LV13 폭발화살이며</p>\n<p data-ke-size=\"size16\">데미지는 230%</p>\n<p data-ke-size=\"size16\">명중보너스 300%</p>\n<p data-ke-size=\"size16\">까지 붙을 수 있습니다.</p>\n<p data-ke-size=\"size16\">여기서 명중 보너스가 매우 중요한데 적힌 데미지보단 상당히 명중이 좋아서&nbsp;</p>\n<p data-ke-size=\"size16\">아주 잘 박힙니다.</p>\n<p data-ke-size=\"size16\">무시할만한 활이 압니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">설명이 있는 영상이 있어서 붙여둡니다.</p>\n<p data-ke-size=\"size16\"><a href=\"https://youtu.be/w240ycEkRy0?t=1015\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://youtu.be/w240ycEkRy0?t=1015</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=w240ycEkRy0\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/c8uE7H/hyWzEM5W75/zvS6o5SU2xpsmZ2L1Hndck/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"당신이 몰랐던 엄청난 성능의 유니크 활은? [활 총정리 1편: 유니크 활]\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/w240ycEkRy0\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영문 사이트: <a href=\"https://diablo.fandom.com/wiki/Blood_Raven%27s_Charge\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://diablo.fandom.com/wiki/Blood_Raven%27s_Charge</a></p>\n<figure id=\"og_1721043652713\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"article\" data-og-title=\"Blood Raven's Charge\" data-og-description=\"Blood Raven's Charge is a unique Matriarchal Bow exclusive to Amazons. With good strength and a fairly good boost to Bow and Crossbow Skills, Blood Raven's Charge is a safe choice for Amazons that specialize in bows, although Lycander's Aim may provide a s\" data-og-host=\"diablo.fandom.com\" data-og-source-url=\"https://diablo.fandom.com/wiki/Blood_Raven%27s_Charge\" data-og-url=\"https://diablo.fandom.com/wiki/Blood_Raven%27s_Charge\" data-og-image=\"https://scrap.kakaocdn.net/dn/uDd6A/hyWCCtjjuS/VpW3nSU1cgOUCMekExHjKk/img.png?width=600&amp;height=450&amp;face=0_0_600_450\"><a href=\"https://diablo.fandom.com/wiki/Blood_Raven%27s_Charge\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://diablo.fandom.com/wiki/Blood_Raven%27s_Charge\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/uDd6A/hyWCCtjjuS/VpW3nSU1cgOUCMekExHjKk/img.png?width=600&amp;height=450&amp;face=0_0_600_450');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">Blood Raven's Charge</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">Blood Raven's Charge is a unique Matriarchal Bow exclusive to Amazons. With good strength and a fairly good boost to Bow and Crossbow Skills, Blood Raven's Charge is a safe choice for Amazons that specialize in bows, although Lycander's Aim may provide a s</p>\n<p class=\"og-host\" data-ke-size=\"size16\">diablo.fandom.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "이거 상점행이라고 글을 적혀있어서 상점행인줄알고 파시는 분이 많은데\n조화나 수리뿔 보단 좋습니다.\n \n폴발하는 화살은 LV13 폭발화살이며\n데미지는 230%\n명중보너스 300%\n까지 붙을 수 있습니다.\n여기서 명중 보너스가 매우 중요한데 적힌 데미지보단 상당히 명중이 좋아서 \n아주 잘 박힙니다.\n무시할만한 활이 압니다.\n \n설명이 있는 영상이 있어서 붙여둡니다.\nhttps://youtu.be/w240ycEkRy0?t=1015\n\n\n\n \n \n \n영문 사이트: https://diablo.fandom.com/wiki/Blood_Raven%27s_Charge\n\n \nBlood Raven's Charge\nBlood Raven's Charge is a unique Matriarchal Bow exclusive to Amazons. With good strength and a fairly good boost to Bow and Crossbow Skills, Blood Raven's Charge is a safe choice for Amazons that specialize in bows, although Lycander's Aim may provide a s\ndiablo.fandom.com",
        "guid": "http://serverdown.tistory.com/784",
        "categories": [
          "유튜브",
          "디아2"
        ],
        "isoDate": "2024-07-15T11:46:52.000Z"
      }
    ]
  },
  {
    "name": "coolspeed",
    "category": "개인",
    "posts": []
  },
  {
    "name": "오늘도 끄적끄적",
    "category": "개인",
    "posts": []
  },
  {
    "name": "dx11 Vanica's Lifelog - 夢が夢で終わらないように",
    "category": "개인",
    "posts": []
  },
  {
    "name": "초코사랑",
    "category": "개인",
    "posts": []
  },
  {
    "name": "ZeroCho Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Hybrid's Notes",
    "category": "개인",
    "posts": []
  },
  {
    "name": "imays게임엔진개발자",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for hurinmon Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "기억보단 기록을",
    "category": "개인",
    "posts": []
  },
  {
    "name": "WestwoodForever's Dev Log",
    "category": "개인",
    "posts": []
  },
  {
    "name": "허니몬(Honeymon)의 자바guru",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Wolf Loves Fox :: 일상",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Game Programmer Life",
    "category": "개인",
    "posts": []
  },
  {
    "name": "IT 프리랜서 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "yuchi's dev",
    "category": "개인",
    "posts": []
  },
  {
    "name": "만화로 나누는 자유/오픈소스 소프트웨어 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "신현석(Hyeonseok Shin)",
    "category": "개인",
    "posts": []
  },
  {
    "name": "한상곤 - Sigmadream",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자 울이 노트",
    "category": "개인",
    "posts": []
  },
  {
    "name": "즐거운 개발자 :: 네이버  블로그",
    "category": "개인",
    "posts": [
      {
        "creator": "dlehddus84",
        "title": "쿼리도 팩맨, 보랏못 리라이트",
        "link": "http://blog.naver.com/dlehddus84/223511684142?fromRss=true&trackingCode=rss",
        "pubDate": "Sat, 13 Jul 2024 22:33:06 +0900",
        "author": "dlehddus84",
        "content": "쿼리도 팩맨을 구매해서 플레이해보았다. 기존 쿼리도 룰로 플레이를 할 수도 있고 팩맨 버전으로 플레이 할 수도 있다. 컴포 퀄리티도 뛰어나고 색감도 좋아서 기존에 쿼리도가 없는 사람은 꼭 이 쿼리도 팩맨으로 구입하는게 좋을것 같다. 이렇게 기존 쿼리도 룰로 게임을 할 수도있고 이런식으로 고스트 4마리와 파워 쿠키를 이용해 팩맨 룰로 할 수도 있다. 팩맨을 중앙에 각 고스트를 동서남북 중앙쪽에 놓고 팩맨은 한턴에 2칸 이동 고스트는 기본 1칸 이동 팩맨이 시야에 있으면 2칸 이동하여 팩맨은 파워쿠키를 먹는것이 목표, 고스트는 팩맨을 잡는것이 목표이다. 여기서 기존 팩맨 게임룰처럼 파워쿠키를 먹으면 즉시 3칸이동하는데 이.......",
        "contentSnippet": "쿼리도 팩맨을 구매해서 플레이해보았다. 기존 쿼리도 룰로 플레이를 할 수도 있고 팩맨 버전으로 플레이 할 수도 있다. 컴포 퀄리티도 뛰어나고 색감도 좋아서 기존에 쿼리도가 없는 사람은 꼭 이 쿼리도 팩맨으로 구입하는게 좋을것 같다. 이렇게 기존 쿼리도 룰로 게임을 할 수도있고 이런식으로 고스트 4마리와 파워 쿠키를 이용해 팩맨 룰로 할 수도 있다. 팩맨을 중앙에 각 고스트를 동서남북 중앙쪽에 놓고 팩맨은 한턴에 2칸 이동 고스트는 기본 1칸 이동 팩맨이 시야에 있으면 2칸 이동하여 팩맨은 파워쿠키를 먹는것이 목표, 고스트는 팩맨을 잡는것이 목표이다. 여기서 기존 팩맨 게임룰처럼 파워쿠키를 먹으면 즉시 3칸이동하는데 이.......",
        "guid": "http://blog.naver.com/dlehddus84/223511684142",
        "categories": [
          "플레이"
        ],
        "isoDate": "2024-07-13T13:33:06.000Z"
      },
      {
        "creator": "dlehddus84",
        "title": "2024 보드게임콘 방문",
        "link": "http://blog.naver.com/dlehddus84/223511673405?fromRss=true&trackingCode=rss",
        "pubDate": "Sat, 13 Jul 2024 22:20:15 +0900",
        "author": "dlehddus84",
        "content": "삼성역 코엑스에서 진행한 보드게임콘에 다녀왔다. 체험은 사람이 많아 해보진 못했고 딱히 뭘 사겠다 마음먹고 가진 않아서 신작보다 가격이 괜찮은 구작들 위주로 구입했다. 이번 콘에 직접간 이유는 피스크레프트의 미니와일드에 작가님 싸인을 받기 위해서였다. 미니와일드, 미니와일드 블루, 미니와일드 레드를 들고 피스크레프트를 찾아가 대표님께 싸인을 받아왔다. 실버건 작가님의 부스에 들러 인사를 드렸더니 부채를 주셔서 잘 가져왔다. 해달이랑 얼룩말이 귀엽더라.",
        "contentSnippet": "삼성역 코엑스에서 진행한 보드게임콘에 다녀왔다. 체험은 사람이 많아 해보진 못했고 딱히 뭘 사겠다 마음먹고 가진 않아서 신작보다 가격이 괜찮은 구작들 위주로 구입했다. 이번 콘에 직접간 이유는 피스크레프트의 미니와일드에 작가님 싸인을 받기 위해서였다. 미니와일드, 미니와일드 블루, 미니와일드 레드를 들고 피스크레프트를 찾아가 대표님께 싸인을 받아왔다. 실버건 작가님의 부스에 들러 인사를 드렸더니 부채를 주셔서 잘 가져왔다. 해달이랑 얼룩말이 귀엽더라.",
        "guid": "http://blog.naver.com/dlehddus84/223511673405",
        "categories": [
          "보드게임"
        ],
        "isoDate": "2024-07-13T13:20:15.000Z"
      }
    ]
  },
  {
    "name": "황제펭귄의 게임개발이야기 [여기는 한국]",
    "category": "개인",
    "posts": []
  },
  {
    "name": "LINE ENGINEERING",
    "category": "기업",
    "posts": []
  },
  {
    "name": "뱅크샐러드 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "우아한형제들 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "TOAST Meetup",
    "category": "기업",
    "posts": []
  },
  {
    "name": "ZUM 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "SK Planet",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Spoqa tech blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "팀 왈도 번역팀",
    "category": "게임",
    "posts": []
  },
  {
    "name": "이한",
    "category": "개인",
    "posts": []
  },
  {
    "name": "근원님",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황의윤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "호돌맨",
    "category": "개인",
    "posts": []
  },
  {
    "name": "박우빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "문다영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "유수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "안건주",
    "category": "개인",
    "posts": [
      {
        "title": "지식, 진실, 그리고 거짓말",
        "link": "https://velog.io/@ahngj96/%EC%A7%80%EC%8B%9D-%EC%A7%84%EC%8B%A4-%EA%B7%B8%EB%A6%AC%EA%B3%A0-%EA%B1%B0%EC%A7%93%EB%A7%90",
        "pubDate": "Thu, 11 Jul 2024 18:12:39 GMT",
        "content": "<p>분산 시스템에서 우리는 동작(시스템 모델)에 관해 정한 가정을 명시하고, 이런 가정을 만족시키는 방식으로 실제 시스템을 설계할 수 있다. 어떤 시스템 모델 내에서 알고리즘이 올바르게 동작하는지 증명할 수 있다. 기반 시스템 모델이 매우 적은 보장만 제공하더라도 신뢰성 있는 동작을 달성할 수 있다는 뜻이다.</p>\n<h1 id=\"진실은-다수결로-결정된다\">진실은 다수결로 결정된다</h1>\n<p>노드가 상황에 대한 자신의 판단은 반드시 믿을 수 있는 것이 아니다. 분산 시스템은 한 노드에만 의존할 수는 없다. 노드에 언제든 장애가 나서 잠재적으로 시스템이 멈추고 복구할 수 없게 될 수도 있기 때문이다. 대신 여러 분산 알고리즘은 정족수, 즉 노드들 사이의 투표에 의존한다. 특정한 노드 하나에 대한 의존을 줄이기 위해 결정을 하려면 여러 노드로부터 어떤 최소 개수의 투표를 받아야 한다.</p>\n<p>노드의 과반수 이상을 정족수로 삼는 게 가장 흔하다. 과반수 정족수를 사용하면 개별 노드들에 장애가 나더라도 시스템은 계속 동작할 수 있다(노드가 3대면 1대 장애 ok, 노드가 5대면 2대 장애 ok).</p>\n<h2 id=\"리더와-잠금\">리더와 잠금</h2>\n<p>시스템이 오직 하나의 뭔가가 필요할 때가 자주 있다.</p>\n<ul>\n<li>스플릿 브레인(리더가 하나뿐인 시스템에서 서로 자신이 리더인줄 알고 있는 상황) 방지</li>\n<li>객체에 쓰거나 수정할때 객체 잠금 획득</li>\n<li>유니크 사용자 명</li>\n</ul>\n<p>분산 시스템에서 이를 구현하려면 주의해야 한다. 어떤 노드가 스스로를 <code>선택된 자</code>라고 믿을지라도 노드의 정족수도 반드시 동의한다는 뜻은 아니다! 어떤 노드가 이전에 리더였더라도 시간이 흐른 사이에 다른 노드들이 그 노드가 죽었다고 선언하면 그 노드는 강등되고 다른 리더가 이미 선출됐을지도 모른다.</p>\n<p><img src=\"https://velog.velcdn.com/images/ahngj96/post/d4f4503e-8692-436b-858d-1fd64b4588d0/image.png\" alt=\"\">\n<a href=\"https://azderica.github.io/til/docs/data/designing-data-intensive-applications/ch8/\">이미지 출처</a></p>\n<p>위 그림과 같이 만료된 권한인지 모르고 권한 있는 상태(<code>선택된 자</code>)라 생각하고 데이터를 기록하게되면 저장소에 있는 데이터를 오염시키게 된다.</p>\n<h2 id=\"펜싱-토큰\">펜싱 토큰</h2>\n<p>자신이 <code>선택된 자</code>라고 잘못 믿고 있는 노드가 나머지 시스템을 방해할 수 없도록 보장해야 한다. 이 목적을 달성하는 상당히 단순한 기법을 펜싱(fencing)이 있다.</p>\n<p><img src=\"https://velog.velcdn.com/images/ahngj96/post/4bf9f1b5-d700-4d89-9456-6dc9298dbd7a/image.png\" alt=\"\">\n<a href=\"https://azderica.github.io/til/docs/data/designing-data-intensive-applications/ch8/\">이미지 출처</a></p>\n<p>잠금 서버가 잠금이나 임차권을 승인할 때마다 펜싱 토큰(fencing token)도 반환한다고 가정한다. 그리고 펜싱 토큰은 잠금이 승인될 때마다 증가하는 숫자라 가정한다. 그러면 클라이언트가 쓰기 요청을 저장소 서비스로 보낼 때마다 자신의 현재 펜싱 토큰을 포함하도록 요구할 수 있다. 그러면 위 그림과 같이 오래된 토큰의 요청은 거부할 수 있다.</p>\n<p>서버 측에서 토큰을 확인하는 것은 결점으로 보이지만 결점이 아니다. 뜻하지 않게 폭력적인 클라이언트로부터 보호하려는 서비스는 서버 측에서 토큰을 확인하는 게 좋다.</p>\n<h2 id=\"비잔틴-결함\">비잔틴 결함</h2>\n<p>펜싱 토큰은 아직 자신이 <code>선택된 자</code>라고 생각하는 오류에 빠진 노드를 감지하고 차단할 수 있다. 그러나 노드가 고의로 시스템의 보장을 무너뜨리려한다면 가짜 펜싱 토큰을 포함한 메시지를 보내기만 하면 된다.</p>\n<p>지금까지는 노드들이 신뢰성은 없지만 응답한다면 <code>진실</code>만 말한다고 가정했다. 그러나 분산 시스템 문제는 노드가 <code>거짓말</code>을 할지도 모른다는 위험이 있다면 훨씬 더 어려워진다. 이런 동작을 비잔틴 결함(Byzantine fault)이라고 하며 이렇게 신뢰할 수 없는 환경에서 합의에 도달하는 문제를 <a href=\"https://m.upbitcare.com/academy/education/blockchain/296\">비잔틴 장군 문제(Byzantine Generals Problem)</a>라고 한다.</p>\n<p>일부 노드가 오작동하고 프로토콜을 준수하지 않고나 악의적인 공격자가 네트워크를 방해하더라도 시스템이 계속 올바르게 동작한다면 이 시스템은 비잔틴 내결함성(Byzantine fault tolerant)을 지닌다. 이런 관심사는 특정 환경에서 유의미하다. (예를 들어, 방사선 노출이 큰 항공우주 산업이나 비트코인 같은 분야)</p>\n<p>그러나 우리가 살펴보는 시스템의 종류는 보통 비잔틴 결함이 없다고 가정할 수 있다. 그리고 대부분의 서버 측 데이터 시스템에서 비잔틴 내결함성 솔류션을 배치하는 것은 비용이 커서 실용적이지 않다. 대신 보통 중앙 권한을 가지고 최종 사용자의 입력을 확인(input validation)하고 살균(sanitization, 잠재적으로 위험할 수 있는 입력값을 유효한 값으로 치환)하고 출력 이스케이핑(output escaping) 등으로 SQL injection이나 크로스 사이트 스크립팅 등의 공격을 막는다.</p>\n<h2 id=\"약한-형태의-거짓말\">약한 형태의 거짓말</h2>\n<p>하드웨어 문제, 소프트웨어 버그, 잘못된 설정으로 인한 유효하지 않은 메시지 등 의도치 않은 약한 형태의 <code>거짓말</code>로부터 보호해주는 메커니즘을 추가하는 것은 가치가 있다.</p>\n<ul>\n<li>TCP 내장 체크섬만 믿지 말고 체크섬을 직접 애플리케이션에 넣기</li>\n<li>사용자 입력 살균하기</li>\n<li>NTP 여러 서버 주소 설정하기</li>\n</ul>\n<h1 id=\"시스템-모델과-현실\">시스템 모델과 현실</h1>\n<p>알고리즘은 그들이 실행되는 하드웨어와 소프트웨어 설정의 세부 사항에 너무 심하게 의존하지 않는 방식으로 작성해야 한다. 그러려면 시스템에서 발생할 것으로 예상되는 결함의 종류를 어떻게든 정형화해야 한다. 시스템 모델을 정의해서 정형화하는데, 시스템 모델은 알고리즘이 가정하는 것을 기술한 추상화다.</p>\n<blockquote>\n<p>타이밍 가정에 대한 흔히 사용하는 세 가지 시스템 모델</p>\n<ul>\n<li>동기식 모델: 네트워크 지연, 프로세스 중단 등 모두 제한이 있다고 가정</li>\n<li>부분 동기식 모델: 대부분의 시간에는 동기식 시스템처럼 동작하지만 때때로 네트워크 지연 등 한계치를 초과한다고 가정. 많은 시스템에서 현실적인 모델</li>\n<li>비동기식 모델: 이 모델에서 알고리즘은 타이밍에 대한 어떤 가정도 할 수 없다.</li>\n</ul>\n</blockquote>\n<blockquote>\n<p>노드 장애를 고려하는 세가지 시스템 모델</p>\n<ul>\n<li>죽으면 중단(crash-stop)하는 결함</li>\n<li>죽으면 복구하는(carsh-recovery) 결함</li>\n<li>비잔틴 결함</li>\n</ul>\n</blockquote>\n<p>현실 시스템을 모델링하는데는 죽으면 복구하는 결함을 지닌 부분 동기식 모델이 일반적으로 가장 유용한 모델이다.</p>\n<h2 id=\"알고리즘의-안정성과-활동성\">알고리즘의 안정성과 활동성</h2>\n<p>상황을 분명히 하기 위해 두 가지 다른 종류의 속성, 안정성(safety)과 활동성(liveness)을 구별할 필요가 있다.</p>\n<p>안정성은 흔히 비공식적으로 나쁜 일은 일어나지 않는다라고, 활동성은 좋은 일은 결국 일어난다라고 정의한다. 안전성 속성이 위반되면 그 속성이 깨진 특정 시점을 가리킬 수 있다. 안전성 속성이 위반된 후에는 그 위반을 취소할 수 없다. 활동성 속성은 어떤 시점을 정하지 못할 수 있지만, 항상 미래에 그 속성을 만족시킬 수 있다는 희망이 있다.</p>\n<p>분산 알고리즘은 시스템 모델의 모든 상황에서 안정성 속성이 항상 만족되기를 요구하는 게 일반적이다. 즉 모든 노드가 죽거나 네트워크 전체에 장애가 생기더라도 알고리즘은 잘못된 결과를 반환하지 않는다고 보장해야 한다.</p>\n<p>그러나 활동성 속성에 대해서는 경고를 하는 게 허용된다. 예를 들어 노드의 다수가 죽지 않고 네트워크가 중단으로부터 결국 복구됐을 때만 요청이 응답을 받아야 한다고 말할 수 있다.</p>\n<h2 id=\"시스템-모델을-현실-세계에-대응시키기\">시스템 모델을 현실 세계에 대응시키기</h2>\n<p>현업에서 알고리즘을 구현할 때 현실의 지저분한 사실들이 시스템 모델은 현실의 단순화된 추상화라는 게 명백해진다.</p>\n<p>알고리즘을 이론적으로 설명할 때는 그냥 어떤 일이 일어나지 않는다고 가정할 수 있다. 그러나 실제 구현에는 여전히 불가능하다고 가정했던 일이 발생하는 경우를 처리하는 코드를 포함시켜야 할 수도 있다.</p>\n<p>이론적인 추상 시스템 모델은 현실 시스템의 복잡함에서 우리가 추론할 수 있는 관리 가능한 결함의 집합을 뽑아내서, 문제를 이해하고 체계적으로 해결하려고 노력할 수 있게 하는 데 도움이 된다.</p>\n<p>알고리즘이 올바르다고 증명됐더라도 반드시 현실 시스템에서의 구현도 언제나 올바르게 동작한다는 뜻은 아니다. 그렇지만 알고리즘의 증명은 아주 좋은 첫걸음이다.</p>\n<h1 id=\"reference\">Reference</h1>\n<p>데이터 중심 애플리케이션 설계 8장</p>\n",
        "contentSnippet": "분산 시스템에서 우리는 동작(시스템 모델)에 관해 정한 가정을 명시하고, 이런 가정을 만족시키는 방식으로 실제 시스템을 설계할 수 있다. 어떤 시스템 모델 내에서 알고리즘이 올바르게 동작하는지 증명할 수 있다. 기반 시스템 모델이 매우 적은 보장만 제공하더라도 신뢰성 있는 동작을 달성할 수 있다는 뜻이다.\n진실은 다수결로 결정된다\n노드가 상황에 대한 자신의 판단은 반드시 믿을 수 있는 것이 아니다. 분산 시스템은 한 노드에만 의존할 수는 없다. 노드에 언제든 장애가 나서 잠재적으로 시스템이 멈추고 복구할 수 없게 될 수도 있기 때문이다. 대신 여러 분산 알고리즘은 정족수, 즉 노드들 사이의 투표에 의존한다. 특정한 노드 하나에 대한 의존을 줄이기 위해 결정을 하려면 여러 노드로부터 어떤 최소 개수의 투표를 받아야 한다.\n노드의 과반수 이상을 정족수로 삼는 게 가장 흔하다. 과반수 정족수를 사용하면 개별 노드들에 장애가 나더라도 시스템은 계속 동작할 수 있다(노드가 3대면 1대 장애 ok, 노드가 5대면 2대 장애 ok).\n리더와 잠금\n시스템이 오직 하나의 뭔가가 필요할 때가 자주 있다.\n스플릿 브레인(리더가 하나뿐인 시스템에서 서로 자신이 리더인줄 알고 있는 상황) 방지\n객체에 쓰거나 수정할때 객체 잠금 획득\n유니크 사용자 명\n분산 시스템에서 이를 구현하려면 주의해야 한다. 어떤 노드가 스스로를 선택된 자라고 믿을지라도 노드의 정족수도 반드시 동의한다는 뜻은 아니다! 어떤 노드가 이전에 리더였더라도 시간이 흐른 사이에 다른 노드들이 그 노드가 죽었다고 선언하면 그 노드는 강등되고 다른 리더가 이미 선출됐을지도 모른다.\n\n이미지 출처\n위 그림과 같이 만료된 권한인지 모르고 권한 있는 상태(선택된 자)라 생각하고 데이터를 기록하게되면 저장소에 있는 데이터를 오염시키게 된다.\n펜싱 토큰\n자신이 선택된 자라고 잘못 믿고 있는 노드가 나머지 시스템을 방해할 수 없도록 보장해야 한다. 이 목적을 달성하는 상당히 단순한 기법을 펜싱(fencing)이 있다.\n\n이미지 출처\n잠금 서버가 잠금이나 임차권을 승인할 때마다 펜싱 토큰(fencing token)도 반환한다고 가정한다. 그리고 펜싱 토큰은 잠금이 승인될 때마다 증가하는 숫자라 가정한다. 그러면 클라이언트가 쓰기 요청을 저장소 서비스로 보낼 때마다 자신의 현재 펜싱 토큰을 포함하도록 요구할 수 있다. 그러면 위 그림과 같이 오래된 토큰의 요청은 거부할 수 있다.\n서버 측에서 토큰을 확인하는 것은 결점으로 보이지만 결점이 아니다. 뜻하지 않게 폭력적인 클라이언트로부터 보호하려는 서비스는 서버 측에서 토큰을 확인하는 게 좋다.\n비잔틴 결함\n펜싱 토큰은 아직 자신이 선택된 자라고 생각하는 오류에 빠진 노드를 감지하고 차단할 수 있다. 그러나 노드가 고의로 시스템의 보장을 무너뜨리려한다면 가짜 펜싱 토큰을 포함한 메시지를 보내기만 하면 된다.\n지금까지는 노드들이 신뢰성은 없지만 응답한다면 진실만 말한다고 가정했다. 그러나 분산 시스템 문제는 노드가 거짓말을 할지도 모른다는 위험이 있다면 훨씬 더 어려워진다. 이런 동작을 비잔틴 결함(Byzantine fault)이라고 하며 이렇게 신뢰할 수 없는 환경에서 합의에 도달하는 문제를 비잔틴 장군 문제(Byzantine Generals Problem)라고 한다.\n일부 노드가 오작동하고 프로토콜을 준수하지 않고나 악의적인 공격자가 네트워크를 방해하더라도 시스템이 계속 올바르게 동작한다면 이 시스템은 비잔틴 내결함성(Byzantine fault tolerant)을 지닌다. 이런 관심사는 특정 환경에서 유의미하다. (예를 들어, 방사선 노출이 큰 항공우주 산업이나 비트코인 같은 분야)\n그러나 우리가 살펴보는 시스템의 종류는 보통 비잔틴 결함이 없다고 가정할 수 있다. 그리고 대부분의 서버 측 데이터 시스템에서 비잔틴 내결함성 솔류션을 배치하는 것은 비용이 커서 실용적이지 않다. 대신 보통 중앙 권한을 가지고 최종 사용자의 입력을 확인(input validation)하고 살균(sanitization, 잠재적으로 위험할 수 있는 입력값을 유효한 값으로 치환)하고 출력 이스케이핑(output escaping) 등으로 SQL injection이나 크로스 사이트 스크립팅 등의 공격을 막는다.\n약한 형태의 거짓말\n하드웨어 문제, 소프트웨어 버그, 잘못된 설정으로 인한 유효하지 않은 메시지 등 의도치 않은 약한 형태의 거짓말로부터 보호해주는 메커니즘을 추가하는 것은 가치가 있다.\nTCP 내장 체크섬만 믿지 말고 체크섬을 직접 애플리케이션에 넣기\n사용자 입력 살균하기\nNTP 여러 서버 주소 설정하기\n시스템 모델과 현실\n알고리즘은 그들이 실행되는 하드웨어와 소프트웨어 설정의 세부 사항에 너무 심하게 의존하지 않는 방식으로 작성해야 한다. 그러려면 시스템에서 발생할 것으로 예상되는 결함의 종류를 어떻게든 정형화해야 한다. 시스템 모델을 정의해서 정형화하는데, 시스템 모델은 알고리즘이 가정하는 것을 기술한 추상화다.\n타이밍 가정에 대한 흔히 사용하는 세 가지 시스템 모델\n동기식 모델: 네트워크 지연, 프로세스 중단 등 모두 제한이 있다고 가정\n부분 동기식 모델: 대부분의 시간에는 동기식 시스템처럼 동작하지만 때때로 네트워크 지연 등 한계치를 초과한다고 가정. 많은 시스템에서 현실적인 모델\n비동기식 모델: 이 모델에서 알고리즘은 타이밍에 대한 어떤 가정도 할 수 없다.\n노드 장애를 고려하는 세가지 시스템 모델\n죽으면 중단(crash-stop)하는 결함\n죽으면 복구하는(carsh-recovery) 결함\n비잔틴 결함\n현실 시스템을 모델링하는데는 죽으면 복구하는 결함을 지닌 부분 동기식 모델이 일반적으로 가장 유용한 모델이다.\n알고리즘의 안정성과 활동성\n상황을 분명히 하기 위해 두 가지 다른 종류의 속성, 안정성(safety)과 활동성(liveness)을 구별할 필요가 있다.\n안정성은 흔히 비공식적으로 나쁜 일은 일어나지 않는다라고, 활동성은 좋은 일은 결국 일어난다라고 정의한다. 안전성 속성이 위반되면 그 속성이 깨진 특정 시점을 가리킬 수 있다. 안전성 속성이 위반된 후에는 그 위반을 취소할 수 없다. 활동성 속성은 어떤 시점을 정하지 못할 수 있지만, 항상 미래에 그 속성을 만족시킬 수 있다는 희망이 있다.\n분산 알고리즘은 시스템 모델의 모든 상황에서 안정성 속성이 항상 만족되기를 요구하는 게 일반적이다. 즉 모든 노드가 죽거나 네트워크 전체에 장애가 생기더라도 알고리즘은 잘못된 결과를 반환하지 않는다고 보장해야 한다.\n그러나 활동성 속성에 대해서는 경고를 하는 게 허용된다. 예를 들어 노드의 다수가 죽지 않고 네트워크가 중단으로부터 결국 복구됐을 때만 요청이 응답을 받아야 한다고 말할 수 있다.\n시스템 모델을 현실 세계에 대응시키기\n현업에서 알고리즘을 구현할 때 현실의 지저분한 사실들이 시스템 모델은 현실의 단순화된 추상화라는 게 명백해진다.\n알고리즘을 이론적으로 설명할 때는 그냥 어떤 일이 일어나지 않는다고 가정할 수 있다. 그러나 실제 구현에는 여전히 불가능하다고 가정했던 일이 발생하는 경우를 처리하는 코드를 포함시켜야 할 수도 있다.\n이론적인 추상 시스템 모델은 현실 시스템의 복잡함에서 우리가 추론할 수 있는 관리 가능한 결함의 집합을 뽑아내서, 문제를 이해하고 체계적으로 해결하려고 노력할 수 있게 하는 데 도움이 된다.\n알고리즘이 올바르다고 증명됐더라도 반드시 현실 시스템에서의 구현도 언제나 올바르게 동작한다는 뜻은 아니다. 그렇지만 알고리즘의 증명은 아주 좋은 첫걸음이다.\nReference\n데이터 중심 애플리케이션 설계 8장",
        "guid": "https://velog.io/@ahngj96/%EC%A7%80%EC%8B%9D-%EC%A7%84%EC%8B%A4-%EA%B7%B8%EB%A6%AC%EA%B3%A0-%EA%B1%B0%EC%A7%93%EB%A7%90",
        "isoDate": "2024-07-11T18:12:39.000Z"
      },
      {
        "title": "신뢰성 없는 시계",
        "link": "https://velog.io/@ahngj96/%EC%8B%A0%EB%A2%B0%EC%84%B1-%EC%97%86%EB%8A%94-%EC%8B%9C%EA%B3%84-2",
        "pubDate": "Thu, 11 Jul 2024 15:44:45 GMT",
        "content": "<p>시계와 시간은 중요하다. 애플리케이션은 다양한 방식으로 시계에 의존하는데 대표적으로 <strong>지속 시간 측정</strong>과 <strong>특정 시점 기술</strong>에 의존한다. 분산 시스템에서는 통신이 즉각적이지 않으므로 시간은 다루기 까다롭다. 네트워크 지연의 변동성 때문에 어떤 일이 발생한 순서를 알아내기 어렵다. 게다가 네트워크에 있는 개별 장비는 자신의 시계(보통 수정 발진기, quartz crystal oscillator)를 가지고 있다. 각자 가지고 있는 시계는 완벽하지 않아서 다른 장비보다 약간 빠를 수도 느릴 수도 있다. 시간을 어느정도 동기화 할 수 있는데 NTP(Network Time Protocol)를 사용하는 것이다.</p>\n<h1 id=\"단조-시계-대-일-기준-시계\">단조 시계 대 일 기준 시계</h1>\n<p>각각 일 기준 시계와 단조 시계는 Java 의 <a href=\"https://www.baeldung.com/java-system-currenttimemillis-vs-system-nanotime\"><code>System.currentTimeMillis()</code>와 <code>System.nanoTime()</code></a>로 설명할 수 있다. 간단히 차이를 보자면 <strong>일 기준 시계는 시스템 시각이며 NTP와 동기화</strong>되어 만약 로컬 시계가 NTP 시계보다 빠르다면 동기화되면서 시간이 거꾸로 흐르는 것처럼 착각할 수 있다. <strong>단조 시계는 이름에서 알 수 있듯 항상 시간이 앞으로만 흐른다.</strong></p>\n<p>NTP는 컴퓨터의 로컬 시계가 NTP 서버보다 빠르거나 느리다는 것을 발견하면 <strong>단조 시계가 진행하는 진도수를 조정</strong>할 수도 있다(시계를 돌린다(slewing)고 한다). 기본적으로 NTP는 시계 속도를 0.05%까지 올리거나 내리는 것을 허용하지만 단조 시계가 앞이나 뒤로 뛰게 할 수는 없다.</p>\n<p>분산 시스템에서 경과 시간을 재는 데 단조 시계를 쓰는 것은 일반적으로 괜찮다. 다른 노드의 시계 사이에 동기화가 돼야 한다는 가정이 없고 측정이 약간 부정확해도 민감하지 않기 때문이다.</p>\n<h1 id=\"시계-동기화와-정확도\">시계 동기화와 정확도</h1>\n<p>단조 시계는 동기화가 필요 없지만 일 기준 시계는 NTP 서버나 다른 외부 시간 출처에 맞춰 설정돼야 유용하다. 유감스럽게도 시계가 정확한 시간을 알려주게 하는 방법은 기대만큼 신뢰성이 있거나 정확하지 않다. 하드웨어 시계와 NTP는 변덕스러운 짐승이 될 수 있다.</p>\n<ul>\n<li>컴퓨터의 수정 시계는 드리프트 현상(더 빠르거나 느리게 실행)으로 인하여 정확하지 않다. 시계 드리프트는 장비의 온도에 따라 변한다.</li>\n<li>컴퓨터 시계가 NTP 서버와 너무 많은 차이가 나면 동기화가 거부되거나 로컬 시계가 강제로 리셋될 수 있다. 리셋 전후로 시간을 관찰한 애플리케이션은 시간이 건너뛰어지는 상황을 보게 된다.</li>\n<li>방화벽으로 인하여 잘못된 설정이 알려지지 않을 수 있다.</li>\n<li>NTP 동기화도 네트워크 지연으로 인한 정확도에 한계가 있다.</li>\n<li>어떤 NTP 서버들은 잘못된 시간을 가지고 있기도 하는데, NTP 클라이언트는 여러 서버에 질의를 보내고 다른 것과 큰 차이가 나는 값을 무시하기에 상당히 견고하다. 그럼에도 다소 걱정스럽다.</li>\n<li>윤초가 발생하면 1분의 길이가 59초나 61초가 되어 윤초를 고려하지 않고 설계된 시스템에서는 시간에 관한 가정이 엉망이 돼 버린다. 윤초를 처리하는 최선의 방법은 윤초 조정을 하루에 걸쳐서 서서히 수행함으로써 NTP 서버가 거짓맣을 하게 하는 것일 수도 있다.(문지름(smearing)이라고 부른다)</li>\n<li>가상 장비에서 하드웨어 시계는 가상화돼서 정확한 시간 엄수가 필요한 애플리케이션에게 추가적인 어려움이 생긴다. CPU 코어가 가상 장비 사이에 공유될 때 각 VM은 다른 VM이 실행되는 동안 수십 밀리초 동안 멈춘다. 애플리케이션 관점에서 이 중단은 시계가 갑자기 앞으로 뛰는 문제로 나타난다.</li>\n<li>완전히 제어할 수 없는 장치에서 소프트웨어를 실행하면 그 장치의 하드웨어 시계를 전혀 믿을 수 없을 것이다.</li>\n</ul>\n<p>시계 정확도를 높이기 위해 많은 자원을 투입할 수 있다면 시계 정확도를 매우 높이는 것도 가능하다. GPS 수신기, 정밀 시간 프로토콜과 세심한 배포 및 모니터링으로 다성할 수 있다. 다만 상당한 노력과 전문 기술이 필요하다.</p>\n<h1 id=\"동기화된-시계에-의존하기\">동기화된 시계에 의존하기</h1>\n<p>시계는 간단하고 사용하기 쉬워 보이지만 함정이 있다는 것이 문제다. 하루는 정확히 86,400초가 아닐 수도 있고, 일 기준 시계의 시간이 거꾸로 갈 수도 있으며, 노드의 시간이 다른 노드의 시간과 차이가 많이 날 수도 있다. 대부분의 시간에 아주 잘 동작하지만 견고한 소프트웨어는 잘못된 시계에 대비할 필요가 있다.</p>\n<p>한 가지 문제는 시계가 잘못된다는 것을 눈치채지 못하기 쉽다는 것이다. 장비의 수정 시계에 결함이 있거나 NTP 클라이언트가 잘못 설정됐다면 시계는 드리프트가 생겨서 점점 실제 시간으로부터 멀어져 가지만 대부분이 잘 동작하는 것처럼 보인다. 따라서 동기화된 시계가 필요한 소프트웨어를 사용한다면 필수적으로 모든 장비 사이의 시계 차이를 조심스럽게 모니터링해야 한다. <strong>다른 노드와 시계가 너무 차이나는 노드는 죽은 것으로 선언되고 클러스터에서 제거</strong>돼야 한다. 이런 모니터링을 하면 너무 큰 피해를 입기 전에 고장 난 시계를 알아채도록 보장할 수 있다.</p>\n<h2 id=\"이벤트-순서화용-타임스탬프\">이벤트 순서화용 타임스탬프</h2>\n<p>시계에 의존하고 싶은 유혹이 들지만 위험한 특정 상황 하나를 고려해 보자. 여러 노드에 걸친 이벤트들의 순서를 정하는 문제다. 예를 들어 두 클라이언트가 분산 데이터베이스에 쓰면 누가 먼저 쓰게 될까? 누가 쓴 게 더 최근 것이 될까?</p>\n<p><img src=\"https://velog.velcdn.com/images/ahngj96/post/57d8e5ac-8d03-4db1-90d7-03dadf4d7faa/image.png\" alt=\"\">\n<a href=\"https://azderica.github.io/til/docs/data/designing-data-intensive-applications/ch8/\">이미지 출처</a></p>\n<p>다중 리더 복제 시스템에서 A가 실제로 더 먼저 작성하고 나중에 B가 작성했음에도 최종 쓰기 승리(last write wins, LWW)를 A가 가져가는 상황이 발생할 수 있다. LWW는 근본적으로 순차적인 쓰기가 빠른 시간 내에 연속으로 실행되는 것과 진짜 동시에 쓰기가 실행되는 것을 구별할 수 없다. 인과성 위반을 막으려면 <a href=\"https://en.wikipedia.org/wiki/Version_vector\">버전 벡터</a>와 같은 부가적인 인과성 추적 매커니즘이 필요하다.</p>\n<p>따라서 가장 최근 값을 유지하고 다른 것들을 버림으로써 충돌을 해소하고 싶은 유혹이 들더라도 <strong>최근의 정의는 로컬 일 기준 시계에 의존하며 그 시계는 틀릴 수도 있다</strong>는 것을 아는 게 중요하다.</p>\n<p>논리적 시계는 증가하는 카운터를 기반으로 하며 이벤트 순서화의 안전한 대안이다. 논리적 시계는 일 기준 시간이나 경과한 초 수를 측정하지 않고 이벤트의 상대적인 순서만 측정한다. 반대로 일 기준 시계와 단조 시계는 실제 경과 시간을 측정하며 물리적 시계라고도 한다.</p>\n<h2 id=\"시계-읽기는-신뢰-구간이-있다\">시계 읽기는 신뢰 구간이 있다</h2>\n<p>시계 읽기를 어떤 시점으로 생각하는 것은 옳지 않다. 어떤 신뢰 구간에 속하는 시간의 범위로 읽는 게 나을 것이다. 예를 들어, 스패너에 있는 구글 트루타임 API는 로컬 시계의 신뢰 구간을 명시적으로 보고한다. 이 API에 현재 시간을 요청하면 가능한 타임스탬프 범위 중 가장 이른 것과 가장 늦은 것을 가리키는 두 개의 값을 받는다. 시계는 불확실성 계산을 기반으로 실제 현재 시간이 그 구간 안의 어딘가에 있다는 것을 안다.</p>\n<h2 id=\"전역-스냅숏용-동기화된-시계\">전역 스냅숏용 동기화된 시계</h2>\n<p>DB에서 스냅숏 격리를 달성하기 위해서는 가장 흔한 방법은 단조 증가하는 트랜잭션 아이디이다. 그러나 분산 환경에서는 전역 단조 증가 트랜잭션 아이디를 생성하기 힘들다. 트랜잭션 아이디는 인과성을 반영해야 한다. 트랜잭션 A가 쓴 값을 트랜잭션 B가 읽는다면 B가 A보다 높은 높은 트랜잭션 아이디를 가져야 한다. 그렇지 않으면 스냅숏이 일관성을 지니지 못한다.</p>\n<p>동기화된 일 기준 시계의 타임스탬프를 트랜잭션 아이디로 쓸 수 있을까? 스패너의 경우 타임스탬프를 가지고 여러 데이터센터에 걸쳐서 스냅숏 격리를 구현한다. 스패너의 스냅숏 구현은 트루타입 API가 보고한 시계 신뢰 구간을 사용하여 다음과 같은 관찰을 기반으로 한다.</p>\n<blockquote>\n</blockquote>\n<ul>\n<li>A: [ early-A, last-A ]</li>\n<li>B: [ early-B, last-B ]</li>\n</ul>\n<p>위 와같은 두 개의 신뢰구간이 있을 때,</p>\n<blockquote>\n<p>early-A -&gt; last-A -&gt; early-B -&gt;  last-B</p>\n</blockquote>\n<p>이렇게 두 구간이 겹치지 않는다면 분명히 B가 A보다 나중에 실행됐다. 구간이 겹칠 때만 A와 B가 어떤 순서로 실행됐는지 확신할 수 없다.</p>\n<p>분산 트랜잭션 시맨틱용으로 시계 동기화를 쓰는 것은 흥미롭지만 구글 이외에는 주류 데이터베이스에서 구현한 사례가 없다.</p>\n<h1 id=\"프로세스-중단\">프로세스 중단</h1>\n<p>분산 시스템에서 시계를 위험하게 사용하는 경우가 두 가지있다.</p>\n<ol>\n<li>어떤 권한의 만료 체크를 동기화된 시계에 의존하는 것이다. 동기화된 시계의 동기화가 깨진다면 의도하지 않은 동작을 하게 될 수 있다.</li>\n<li>어떤 권한의 만료를 체크한 이후에 스레드가 오랜 시간 멈춘 것이다. 재시작됐을 때는 이미 만료된 권한이지만 만료된지 모르고 안전하지 않은 동작을 할 수 있다.</li>\n</ol>\n<p>스레드가 아주 오랫동안 멈추는 경우는 다음과 같다.</p>\n<ul>\n<li>JVM 등의 GC로 인한 stop-the-world</li>\n<li>가상 환경에서 가상 장비를 멈췄다 재실행</li>\n<li>노트북 덮개를 닫는 경우</li>\n<li>운영체제가 다른 스레드로 컨텍스트 스위치하거나 하이퍼바이저가 다른 가상 장비로 스위치되는 것. 가상 장비의 경우 다른 가상 장비에서 소비된 CPU 시간을 스틸 타임(steal time)이라고 한다.</li>\n<li>애플리케이션이 동기식으로 디스크에 접근하면 스레드가 느린 디스크 I/O 연산을 완료되기를 기다리느라 중단. 예를 들어 자바 클래스로더는 클래스 파일이 처음 사용될 때 지연로딩하는데, 이는 프로그램 실행 중 언제라도 일어날 수 있다.</li>\n<li>운영 체제의 디스크로 스왑(페이징) 설정. 극단적인 환경에서는 운영체제가 페이지를 메모리 안팎으로 스와핑하느라 대부분의 시간을 쓰고 실제 작업은 거의 못할 수도 있다. 이를 스래싱(thrashing)이라고 한다.</li>\n<li>유닉스에서 <code>SIGSTOP</code> 시그널. <code>ctrl + z</code>를 눌러 신호를 보낼 수 있다. 이 신호는 프로세스가 <code>SIGCONT</code> 신호로 재개되어 중단됐던 지점에서 다시 실행될 때까지 CPU 사이클을 더 이상 할당받지 못하게 한다.</li>\n</ul>\n<p>단일 장비에서 다중 스레드 코드를 작성할 때 그 코드를 thread-safe 하게 만들 수 있는 좋은 도구들이 있다. 뮤텍스, 세마포어, atomic, lock-free 자료구조, blocking queue 등이다. 불행하게도 이런 도구들은 분산 시스템용으로 바로 변형할 수 없다. 분산 시스템은 공유 메모리가 없고 단지 신뢰성 없는 네트워크를 통해 메시지를 보낼 수만 있기 때문이다.</p>\n<p>분산 시스템의 노드는 어느 시점에 실행이 상당한 시간 동안 멈출 수 있다고 가정해야 한다. 심지어 함수 중간에서 멈출 수도 있다. 그렇게 멈춰 있는 동안 외부 세계는 계속 움직이며 멈춘 노드가 응답하지 않아서 죽었다고 선언할 수도 있다. 결국 멈춘 노드는 다시 실행되겠지만 얼마 후 시계를 확인할 때까지 잠들었다는 것을 알아채지 못한다.</p>\n<h2 id=\"응답-시간-보장\">응답 시간 보장</h2>\n<p>많은 프로그래밍 언어와 운영체제에서 스레드와 프로세스는 기약 없는 시간동안 중단될 수 있다. 충분히 열심히 노력하면 중단의 원인을 제거할 수 있다.</p>\n<p>어떤 소프트웨어는 명시된 시간 안에 응답하는 데 실패하면 심각한 손상을 유발할 수 있는 환경에서 실행된다. 항공기, 로켓, 로봇, 자동차, 그리고 다른 물리적 물체를 제어하는 컴퓨터는 그들의 센서 입력에 빠르고 예측 가능하게 응답해야 한다. 이런 시스템에서는 소프트웨어가 응답해야 하는 데드라인이 명시된다. 데드라인을 만족시키지 못하면 전체 시스템의 장애를 유발할 수 있다. 이를 엄격한 실시간 시스템(hard real-time)이라고 한다.</p>\n<p>대부분의 서버측 데이터 처리 시스템에게 실시간 보장은 전혀 경제적이지도, 적절하지도 않다. 결과적으로 이런 시스템들은 비실시간 환경에서 운영될 때 발생하는 중단과 시계 불안적으로부터 고통받을 수밖에 없다.</p>\n<h2 id=\"가비지-컬렉션의-영향을-제한하기\">가비지 컬렉션의 영향을 제한하기</h2>\n<p>몇 가지 아이디어들이 있다.</p>\n<ul>\n<li>GC 중단을 노드가 잠시 동안 계획적으로 중단되는 것으로 간주하고 노드가 가비지 컬렉션을 하는 동안 클라이언트로부터의 요청을 다른 노드들이 처리하게 하는 것이다.</li>\n<li>수명이 짧은 객체만 GC를 사용하고 수명이 긴 객체의 전체 GC가 필요할 만큼 객체가 쌓이기 전에 주기적으로 프로세스를 재시작하는 것이다. 한 번에 노드 하나씩 재시작하도록 하고 순회식 업그레이드를 할 때 처럼 계획된 재시작을 하기 전에 트래픽을 다른 노드로 옮길 수 있다.</li>\n</ul>\n<p>이런 조치가 GC 중단을 완전히 막을 수는 없지만 애플리케이션에 미치는 영향은 유용하게 줄일 수 있다.</p>\n<h1 id=\"reference\">Reference</h1>\n<p>데이터 중심 애플리케이션 설계 8장</p>\n",
        "contentSnippet": "시계와 시간은 중요하다. 애플리케이션은 다양한 방식으로 시계에 의존하는데 대표적으로 지속 시간 측정과 특정 시점 기술에 의존한다. 분산 시스템에서는 통신이 즉각적이지 않으므로 시간은 다루기 까다롭다. 네트워크 지연의 변동성 때문에 어떤 일이 발생한 순서를 알아내기 어렵다. 게다가 네트워크에 있는 개별 장비는 자신의 시계(보통 수정 발진기, quartz crystal oscillator)를 가지고 있다. 각자 가지고 있는 시계는 완벽하지 않아서 다른 장비보다 약간 빠를 수도 느릴 수도 있다. 시간을 어느정도 동기화 할 수 있는데 NTP(Network Time Protocol)를 사용하는 것이다.\n단조 시계 대 일 기준 시계\n각각 일 기준 시계와 단조 시계는 Java 의 System.currentTimeMillis()와 System.nanoTime()로 설명할 수 있다. 간단히 차이를 보자면 일 기준 시계는 시스템 시각이며 NTP와 동기화되어 만약 로컬 시계가 NTP 시계보다 빠르다면 동기화되면서 시간이 거꾸로 흐르는 것처럼 착각할 수 있다. 단조 시계는 이름에서 알 수 있듯 항상 시간이 앞으로만 흐른다.\nNTP는 컴퓨터의 로컬 시계가 NTP 서버보다 빠르거나 느리다는 것을 발견하면 단조 시계가 진행하는 진도수를 조정할 수도 있다(시계를 돌린다(slewing)고 한다). 기본적으로 NTP는 시계 속도를 0.05%까지 올리거나 내리는 것을 허용하지만 단조 시계가 앞이나 뒤로 뛰게 할 수는 없다.\n분산 시스템에서 경과 시간을 재는 데 단조 시계를 쓰는 것은 일반적으로 괜찮다. 다른 노드의 시계 사이에 동기화가 돼야 한다는 가정이 없고 측정이 약간 부정확해도 민감하지 않기 때문이다.\n시계 동기화와 정확도\n단조 시계는 동기화가 필요 없지만 일 기준 시계는 NTP 서버나 다른 외부 시간 출처에 맞춰 설정돼야 유용하다. 유감스럽게도 시계가 정확한 시간을 알려주게 하는 방법은 기대만큼 신뢰성이 있거나 정확하지 않다. 하드웨어 시계와 NTP는 변덕스러운 짐승이 될 수 있다.\n컴퓨터의 수정 시계는 드리프트 현상(더 빠르거나 느리게 실행)으로 인하여 정확하지 않다. 시계 드리프트는 장비의 온도에 따라 변한다.\n컴퓨터 시계가 NTP 서버와 너무 많은 차이가 나면 동기화가 거부되거나 로컬 시계가 강제로 리셋될 수 있다. 리셋 전후로 시간을 관찰한 애플리케이션은 시간이 건너뛰어지는 상황을 보게 된다.\n방화벽으로 인하여 잘못된 설정이 알려지지 않을 수 있다.\nNTP 동기화도 네트워크 지연으로 인한 정확도에 한계가 있다.\n어떤 NTP 서버들은 잘못된 시간을 가지고 있기도 하는데, NTP 클라이언트는 여러 서버에 질의를 보내고 다른 것과 큰 차이가 나는 값을 무시하기에 상당히 견고하다. 그럼에도 다소 걱정스럽다.\n윤초가 발생하면 1분의 길이가 59초나 61초가 되어 윤초를 고려하지 않고 설계된 시스템에서는 시간에 관한 가정이 엉망이 돼 버린다. 윤초를 처리하는 최선의 방법은 윤초 조정을 하루에 걸쳐서 서서히 수행함으로써 NTP 서버가 거짓맣을 하게 하는 것일 수도 있다.(문지름(smearing)이라고 부른다)\n가상 장비에서 하드웨어 시계는 가상화돼서 정확한 시간 엄수가 필요한 애플리케이션에게 추가적인 어려움이 생긴다. CPU 코어가 가상 장비 사이에 공유될 때 각 VM은 다른 VM이 실행되는 동안 수십 밀리초 동안 멈춘다. 애플리케이션 관점에서 이 중단은 시계가 갑자기 앞으로 뛰는 문제로 나타난다.\n완전히 제어할 수 없는 장치에서 소프트웨어를 실행하면 그 장치의 하드웨어 시계를 전혀 믿을 수 없을 것이다.\n시계 정확도를 높이기 위해 많은 자원을 투입할 수 있다면 시계 정확도를 매우 높이는 것도 가능하다. GPS 수신기, 정밀 시간 프로토콜과 세심한 배포 및 모니터링으로 다성할 수 있다. 다만 상당한 노력과 전문 기술이 필요하다.\n동기화된 시계에 의존하기\n시계는 간단하고 사용하기 쉬워 보이지만 함정이 있다는 것이 문제다. 하루는 정확히 86,400초가 아닐 수도 있고, 일 기준 시계의 시간이 거꾸로 갈 수도 있으며, 노드의 시간이 다른 노드의 시간과 차이가 많이 날 수도 있다. 대부분의 시간에 아주 잘 동작하지만 견고한 소프트웨어는 잘못된 시계에 대비할 필요가 있다.\n한 가지 문제는 시계가 잘못된다는 것을 눈치채지 못하기 쉽다는 것이다. 장비의 수정 시계에 결함이 있거나 NTP 클라이언트가 잘못 설정됐다면 시계는 드리프트가 생겨서 점점 실제 시간으로부터 멀어져 가지만 대부분이 잘 동작하는 것처럼 보인다. 따라서 동기화된 시계가 필요한 소프트웨어를 사용한다면 필수적으로 모든 장비 사이의 시계 차이를 조심스럽게 모니터링해야 한다. 다른 노드와 시계가 너무 차이나는 노드는 죽은 것으로 선언되고 클러스터에서 제거돼야 한다. 이런 모니터링을 하면 너무 큰 피해를 입기 전에 고장 난 시계를 알아채도록 보장할 수 있다.\n이벤트 순서화용 타임스탬프\n시계에 의존하고 싶은 유혹이 들지만 위험한 특정 상황 하나를 고려해 보자. 여러 노드에 걸친 이벤트들의 순서를 정하는 문제다. 예를 들어 두 클라이언트가 분산 데이터베이스에 쓰면 누가 먼저 쓰게 될까? 누가 쓴 게 더 최근 것이 될까?\n\n이미지 출처\n다중 리더 복제 시스템에서 A가 실제로 더 먼저 작성하고 나중에 B가 작성했음에도 최종 쓰기 승리(last write wins, LWW)를 A가 가져가는 상황이 발생할 수 있다. LWW는 근본적으로 순차적인 쓰기가 빠른 시간 내에 연속으로 실행되는 것과 진짜 동시에 쓰기가 실행되는 것을 구별할 수 없다. 인과성 위반을 막으려면 버전 벡터와 같은 부가적인 인과성 추적 매커니즘이 필요하다.\n따라서 가장 최근 값을 유지하고 다른 것들을 버림으로써 충돌을 해소하고 싶은 유혹이 들더라도 최근의 정의는 로컬 일 기준 시계에 의존하며 그 시계는 틀릴 수도 있다는 것을 아는 게 중요하다.\n논리적 시계는 증가하는 카운터를 기반으로 하며 이벤트 순서화의 안전한 대안이다. 논리적 시계는 일 기준 시간이나 경과한 초 수를 측정하지 않고 이벤트의 상대적인 순서만 측정한다. 반대로 일 기준 시계와 단조 시계는 실제 경과 시간을 측정하며 물리적 시계라고도 한다.\n시계 읽기는 신뢰 구간이 있다\n시계 읽기를 어떤 시점으로 생각하는 것은 옳지 않다. 어떤 신뢰 구간에 속하는 시간의 범위로 읽는 게 나을 것이다. 예를 들어, 스패너에 있는 구글 트루타임 API는 로컬 시계의 신뢰 구간을 명시적으로 보고한다. 이 API에 현재 시간을 요청하면 가능한 타임스탬프 범위 중 가장 이른 것과 가장 늦은 것을 가리키는 두 개의 값을 받는다. 시계는 불확실성 계산을 기반으로 실제 현재 시간이 그 구간 안의 어딘가에 있다는 것을 안다.\n전역 스냅숏용 동기화된 시계\nDB에서 스냅숏 격리를 달성하기 위해서는 가장 흔한 방법은 단조 증가하는 트랜잭션 아이디이다. 그러나 분산 환경에서는 전역 단조 증가 트랜잭션 아이디를 생성하기 힘들다. 트랜잭션 아이디는 인과성을 반영해야 한다. 트랜잭션 A가 쓴 값을 트랜잭션 B가 읽는다면 B가 A보다 높은 높은 트랜잭션 아이디를 가져야 한다. 그렇지 않으면 스냅숏이 일관성을 지니지 못한다.\n동기화된 일 기준 시계의 타임스탬프를 트랜잭션 아이디로 쓸 수 있을까? 스패너의 경우 타임스탬프를 가지고 여러 데이터센터에 걸쳐서 스냅숏 격리를 구현한다. 스패너의 스냅숏 구현은 트루타입 API가 보고한 시계 신뢰 구간을 사용하여 다음과 같은 관찰을 기반으로 한다.\nA: [ early-A, last-A ]\nB: [ early-B, last-B ]\n위 와같은 두 개의 신뢰구간이 있을 때,\nearly-A -> last-A -> early-B ->  last-B\n이렇게 두 구간이 겹치지 않는다면 분명히 B가 A보다 나중에 실행됐다. 구간이 겹칠 때만 A와 B가 어떤 순서로 실행됐는지 확신할 수 없다.\n분산 트랜잭션 시맨틱용으로 시계 동기화를 쓰는 것은 흥미롭지만 구글 이외에는 주류 데이터베이스에서 구현한 사례가 없다.\n프로세스 중단\n분산 시스템에서 시계를 위험하게 사용하는 경우가 두 가지있다.\n어떤 권한의 만료 체크를 동기화된 시계에 의존하는 것이다. 동기화된 시계의 동기화가 깨진다면 의도하지 않은 동작을 하게 될 수 있다.\n어떤 권한의 만료를 체크한 이후에 스레드가 오랜 시간 멈춘 것이다. 재시작됐을 때는 이미 만료된 권한이지만 만료된지 모르고 안전하지 않은 동작을 할 수 있다.\n스레드가 아주 오랫동안 멈추는 경우는 다음과 같다.\nJVM 등의 GC로 인한 stop-the-world\n가상 환경에서 가상 장비를 멈췄다 재실행\n노트북 덮개를 닫는 경우\n운영체제가 다른 스레드로 컨텍스트 스위치하거나 하이퍼바이저가 다른 가상 장비로 스위치되는 것. 가상 장비의 경우 다른 가상 장비에서 소비된 CPU 시간을 스틸 타임(steal time)이라고 한다.\n애플리케이션이 동기식으로 디스크에 접근하면 스레드가 느린 디스크 I/O 연산을 완료되기를 기다리느라 중단. 예를 들어 자바 클래스로더는 클래스 파일이 처음 사용될 때 지연로딩하는데, 이는 프로그램 실행 중 언제라도 일어날 수 있다.\n운영 체제의 디스크로 스왑(페이징) 설정. 극단적인 환경에서는 운영체제가 페이지를 메모리 안팎으로 스와핑하느라 대부분의 시간을 쓰고 실제 작업은 거의 못할 수도 있다. 이를 스래싱(thrashing)이라고 한다.\n유닉스에서 SIGSTOP 시그널. ctrl + z를 눌러 신호를 보낼 수 있다. 이 신호는 프로세스가 SIGCONT 신호로 재개되어 중단됐던 지점에서 다시 실행될 때까지 CPU 사이클을 더 이상 할당받지 못하게 한다.\n단일 장비에서 다중 스레드 코드를 작성할 때 그 코드를 thread-safe 하게 만들 수 있는 좋은 도구들이 있다. 뮤텍스, 세마포어, atomic, lock-free 자료구조, blocking queue 등이다. 불행하게도 이런 도구들은 분산 시스템용으로 바로 변형할 수 없다. 분산 시스템은 공유 메모리가 없고 단지 신뢰성 없는 네트워크를 통해 메시지를 보낼 수만 있기 때문이다.\n분산 시스템의 노드는 어느 시점에 실행이 상당한 시간 동안 멈출 수 있다고 가정해야 한다. 심지어 함수 중간에서 멈출 수도 있다. 그렇게 멈춰 있는 동안 외부 세계는 계속 움직이며 멈춘 노드가 응답하지 않아서 죽었다고 선언할 수도 있다. 결국 멈춘 노드는 다시 실행되겠지만 얼마 후 시계를 확인할 때까지 잠들었다는 것을 알아채지 못한다.\n응답 시간 보장\n많은 프로그래밍 언어와 운영체제에서 스레드와 프로세스는 기약 없는 시간동안 중단될 수 있다. 충분히 열심히 노력하면 중단의 원인을 제거할 수 있다.\n어떤 소프트웨어는 명시된 시간 안에 응답하는 데 실패하면 심각한 손상을 유발할 수 있는 환경에서 실행된다. 항공기, 로켓, 로봇, 자동차, 그리고 다른 물리적 물체를 제어하는 컴퓨터는 그들의 센서 입력에 빠르고 예측 가능하게 응답해야 한다. 이런 시스템에서는 소프트웨어가 응답해야 하는 데드라인이 명시된다. 데드라인을 만족시키지 못하면 전체 시스템의 장애를 유발할 수 있다. 이를 엄격한 실시간 시스템(hard real-time)이라고 한다.\n대부분의 서버측 데이터 처리 시스템에게 실시간 보장은 전혀 경제적이지도, 적절하지도 않다. 결과적으로 이런 시스템들은 비실시간 환경에서 운영될 때 발생하는 중단과 시계 불안적으로부터 고통받을 수밖에 없다.\n가비지 컬렉션의 영향을 제한하기\n몇 가지 아이디어들이 있다.\nGC 중단을 노드가 잠시 동안 계획적으로 중단되는 것으로 간주하고 노드가 가비지 컬렉션을 하는 동안 클라이언트로부터의 요청을 다른 노드들이 처리하게 하는 것이다.\n수명이 짧은 객체만 GC를 사용하고 수명이 긴 객체의 전체 GC가 필요할 만큼 객체가 쌓이기 전에 주기적으로 프로세스를 재시작하는 것이다. 한 번에 노드 하나씩 재시작하도록 하고 순회식 업그레이드를 할 때 처럼 계획된 재시작을 하기 전에 트래픽을 다른 노드로 옮길 수 있다.\n이런 조치가 GC 중단을 완전히 막을 수는 없지만 애플리케이션에 미치는 영향은 유용하게 줄일 수 있다.\nReference\n데이터 중심 애플리케이션 설계 8장",
        "guid": "https://velog.io/@ahngj96/%EC%8B%A0%EB%A2%B0%EC%84%B1-%EC%97%86%EB%8A%94-%EC%8B%9C%EA%B3%84-2",
        "isoDate": "2024-07-11T15:44:45.000Z"
      }
    ]
  },
  {
    "name": "손현호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "STARTUP BIBLE",
    "category": "개인",
    "posts": [
      {
        "creator": "Kihong Bae",
        "title": "경쟁에 임하는 자세",
        "link": "https://www.thestartupbible.com/2024/07/on-the-mindset-of-facing-a-formidable-competitor.html",
        "pubDate": "Sun, 14 Jul 2024 20:24:40 +0000",
        "content:encodedSnippet": "여전히 난 아침에 운동하면서 음악과 팟캐스트를 번갈아 듣고 있다. 얼마 전에 비즈니스 관련 흥미로운 팟캐스트를 들으면서 몇 가지 메모를 했었는데, 내가 평소 경쟁에 대해서 생각했던 부분과 일맥상통하는 포인트가 있어서, 내 머릿속에서 스스로 정리하는 차원에서 여기서 몇 자 또 적어본다.\n미국의 한적한 휴양지 동네에 있는 작은 멕시칸 타코 식당을 운영하는 한 오너쉐프가 사업 하면서 지금 가장 어려운 점에 대해서 이미 이 분야에서 어느 정도 성공한 선배 창업가의 조언을 듣는 인터뷰인데, 이 자영업자/창업가가 요새 밤잠을 설치는 이유는 다음과 같다.\n나는 처음 들어봤지만, 쉐프들에게 주는 꽤 유명한 상을 받은 이 창업가는 자신만의 독특한 방식으로 동네에서는 상당히 유명한 타코 가게를 몇 년째 운영 중이다. 인상적인 내용은 살사(소스)를 직접 가게에서 만들고, 또르띠야랑 칩스도 외주 주문하는 게 아니라 가게에서 직접 하나씩 다 만드는, 말 그대로 수제 타코 가게인데, 이 말만 들어도 맛있을 것 같다는 느낌을 받았다. 그런데 얼마 전에 멕시칸 프랜차이즈의 헤비웨이트인 치포틀레가 이 동네로 진출한다는 발표를 했고, 공교롭게도 치포틀레 매장이 이 창업가의 가게에서 그렇게 멀지 않은 곳에서 오픈한다는 공포스러운 소식 또한 발표됐다.\n이 창업가의 질문은, 이런 다윗과 골리앗의 싸움이 예상될 때, 다윗이 취할 자세와 구사할 전략에 관해서였다. 이에 대해 좋은 피드백이 많이 제공됐는데 내가 평소 경쟁에 임하는 자세와 태도에 대해 생각했던 부분과 상당히 비슷했다. 이미 대형 경쟁사와 싸워 본 경험이 있는 선배 창업가들의 피드백과 평소 내 생각을 종합해 보면 다음과 같다.\n일단, 쉽지 않을 것이고, 아무리 치열하게 싸워도 질 수 있을 거라는 마음의 각오를 단단히 해야 한다. 다윗과 골리앗의 싸움이고, 성경에서는 운 좋게 다윗이 이겼지만, 현실에서는 골리앗이 대부분 이기기 때문이다. 그리고 너무 당연한 이야기지만, 우리가 할 수 없는 것들과 할 수 있는 것들을 구분해야 한다. 우리가 할 수 없는 건, 경쟁사의 우리 골목상권 진입을 막거나 방해하는 것이다. 이미 우리 구역으로 진출하기로 했고, 이와 관련해서 우리가 할 수 있는 건 그 어떤 것도 없다. 여기에 괜히 시간과 에너지는 쓰지 말자. 우리가 또 할 수 없는 건, 이들과 가격으로 경쟁하는 것이다. 치포틀레와 같은 대기업은 볼륨의 왕이기 때문에, 우리보다 원가는 항상 낮을 수밖에 없고, 이들이 원한다면 우리보다 항상 가격을 낮출 수 있다. 그리고 이들이 가격을 낮추든 안 낮추든, 일단 우리 마진의 30%는 무조건 날아갈 것이라는 걸 명확하게 인지해야 하고, 명확하게 인정해야 한다.\n하지만, 그렇다고 속수무책으로 당하기만 하지 않아도 된다. 작은 가게도 충분히 강점이 있고, 할 수 있는 게 있다. 대기업이 잘하는 게 많지만, 작은 가게가 잘하는 것도 많다. 이 타코 가게의 경우 모든 음식을 즉석에서 요리해 주는데, 이렇게 하면 맛은 월등할 수밖에 없다. 대형 프랜차이즈가 제공할 수 없는 탁월한 맛을 제공할 수 있다. 그리고 오랫동안 이 동네에서 장사를 해서 이 가게는 이미 동네 주민 커뮤니티의 일부가 됐고, 이런 소속감과 커뮤니티십을 잘 활용하면 단골 손님을 계속 유지할 수 있을 것이다. 한가지 나온 예시가, 지역에서 활동하는 음악인과 밴드를 매주 초대해서 라이브 음악을 들으면서 수제 타코를 먹을 수 있는 환경을 제공하는 것이었다. 그리고 대기업이 잘 못 하는 고객과의 접점을 더욱더 강화해서 서비스의 수준을 지속적으로 높이는 것이었다.\n종합하자면, 우리만의 차별점을 더 뾰족하게 만들어야 하고, 식당의 경우 이건 주로 맛과 서비스를 더욱더 갈고 닦는 것이라고 할 수 있다. 실은, 너무나 당연한 건데, 이렇게 당연한 게 대부분 잘 안 지켜진다.\n한국은 골목상권과 대기업 간의 싸움이 미국보다 더 언론화되고 큰 이슈 거리가 된다. 대기업이 골목상권에 진입하면, 우리나라의 정서상 대부분의 사람들은 골목상권과 자영업자의 편이 돼서 대기업을 맹공한다. 나도 대기업이 모든 걸 다 하면 안 된다는 생각이 강력하지만, 반대로 누구나 다 자유롭게 경쟁할 수 있다는 세상에 우리가 살고 있다는 것도 잘 알고 있다. 제일 아쉽고 짜증 나는 건, 위에서 말 한 타코 가게 창업가같이 이 어려운 전쟁에서 살아남기 위해서 어떻게 싸워야 하는지 치열하게 고민하는 자영업자들이 많이 없다는 점이다. 모두 다 대기업의 골목상권 진입을 무조건 막아야 한다는 주장만 하는데, 막상 이들의 골목 빵집, 분식집, 슈퍼, 밥집에 가보면 거지 같은 서비스에 형편없는 제품을 팔면서, 힘들어 죽겠다고 불평하는 자영업자들도 너무 많다.\n이 치열한 세상에서 뭐라도 제대로 하고 싶다면, 작은 경쟁이든, 큰 경쟁이든, 경쟁을 피할 순 없다. 이럴 때 우리가 경쟁에 어떤 자세와 태도로 임하는지가 매우 많은 걸 결정할 수 있다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2024/07/on-the-mindset-of-facing-a-formidable-competitor.html#respond",
        "content": "여전히 난 아침에 운동하면서 음악과 팟캐스트를 번갈아 듣고 있다. 얼마 전에 비즈니스 관련 흥미로운 팟캐스트를 들으면서 몇 가지 메모를 했었는데, 내가 평소 경쟁에 대해서 생각했던 부분과 일맥상통하는 포인트가 있어서, 내 머릿속에서 스스로 정리하는 차원에서 여기서 몇 자 또 적어본다. 미국의 한적한 휴양지 동네에 있는 작은 멕시칸 타코 식당을 운영하는 한 오너쉐프가 사업 하면서 지금 가장(...)",
        "contentSnippet": "여전히 난 아침에 운동하면서 음악과 팟캐스트를 번갈아 듣고 있다. 얼마 전에 비즈니스 관련 흥미로운 팟캐스트를 들으면서 몇 가지 메모를 했었는데, 내가 평소 경쟁에 대해서 생각했던 부분과 일맥상통하는 포인트가 있어서, 내 머릿속에서 스스로 정리하는 차원에서 여기서 몇 자 또 적어본다. 미국의 한적한 휴양지 동네에 있는 작은 멕시칸 타코 식당을 운영하는 한 오너쉐프가 사업 하면서 지금 가장(...)",
        "guid": "https://www.thestartupbible.com/?p=9155",
        "categories": [
          "Uncategorized",
          "competition",
          "FoundersAtWork",
          "general",
          "strategy",
          "스타트업 바이블 QA"
        ],
        "isoDate": "2024-07-14T20:24:40.000Z"
      },
      {
        "creator": "Kihong Bae",
        "title": "지속 가능한 사업",
        "link": "https://www.thestartupbible.com/2024/07/on-being-ready-to-be-a-sustainable-business.html",
        "pubDate": "Wed, 10 Jul 2024 21:34:00 +0000",
        "content:encodedSnippet": "한때는 테슬라보다 더 혁신적인 전기 자동차 회사로 추앙받던 Fisker가 얼마 전에 파산 신청을 했다. 실은, 10년 전에 이미 회사를 한 번 말아먹었고, 이번이 두 번째 파산이라고도 할 수 있는데, 관련 기사를 읽어보면 피스커의 파산 원인은 여러 가지 복합적이지만, 결국엔 지속 가능한 사업 자체를 만들 준비가 안 됐기 때문인 것 같다.\nTechCrunch의 기사 제목을 보면 피스커의 실패 원인이 “it wasn’t ready to be a car company” 라고 하는데, 내가 봤을 때 이 말의 뜻은 피스커가 멋진 컨셉의 전기자동차를 디자인하고 만드는 회사가 되긴 했지만, 이 자동차를 대량으로 생산하고, 판매하고, 결국엔 안정적으로 돈을 버는 비즈니스를 만들고 운영하는 데 실패했다는 것 같다. 피스커의 창업자는 Henrik Fisker라는 걸출한 자동차 디자이너인데, 이분은 멋진 자동차를 디자인하는 데는 천부적인 소질이 있었지만, 그 재능은 딱 거기까지인 것 같다. 비즈니스를 하는 사업가로 변신하는 데는 실패했고, 아마도 자신의 그런 한계를 잘 몰랐던 것 같다.\n우리가 투자했거나, 검토했던 꽤 많은 회사도 이런 비슷한 문제를 경험한다.\n창업가가 특정 문제를 해결하기 위해서 회사를 만들고, 열심히 제품을 만든다. 출시 일정을 정하고, 여기에 맞춰서 몇 개월, 또는 몇 년을 밤새워서 만들고, 운 좋으면 원래 계획했던 대로 제품이 완성돼서 시장에 출시된다. 실은, 대부분의 회사가 여기까지도 못 간다. 거창하게 세웠던 계획대로 되는 일은 하나도 없고, 모든 게 엉망진창으로 진행되면서 돈은 예상보다 빨리 쓰고, 제품은 나오지 않거나, 나오더라도 계획했던 게 아닌, 아주 허접한 제품이 출시되면서 그냥 소리 소문 없이 회사는 문을 닫거나, 다른 제품으로 피봇한다.\n하지만, 아주 운이 좋은 회사들은 시장에서 꽤 열광하는 좋은 제품을 만들어서 출시한다. 그리고, 초기 얼리 어댑터들 사이에서 입소문이 나고 어느 정도의 바이럴 요소가 감지된다.\n오랜 시간 동안 고생해서 초기 반응이 좋은 제품을 만들어서 출시한 건, 이것 자체가 대단하고 스스로 자랑스러워야 하는 큰 마일스톤 달성이지만, 많은 대표들은 이게 사업의 종착점이자 성공이라고 착각한다. 실은, 제품 출시한 후부터가 진정한 사업의 시작점이고, 여기서 어떻게 하는가에 따라서 이 사업이 정말로 지속 가능한 사업이 될 수 있을지 결정된다.\n어떤 분들은 만들어서 출시하면, 그냥 알아서 팔릴 것이고, 이렇게 팔리다 보면 곧 유니콘이 되는 걸로 착각하는데, 경험이 좀 있는 분들은 절대로 이렇게 안 된다는 걸 잘 알고 있을 것이다. 좋은 제품을 만들 때까진, 장인의 정신으로 정말로 쓸모 있는 제품을 만들어야 한다. 하지만, 이후부턴 이 제품을 어떻게 시장의 요구에 맞춰서 최적화하고, 어떻게 영업과 마케팅을 하고, 어떻게 더 좋은 사람을 채용하고, 어떻게 더 비용을 절감하면서 사업을 운영해서, 오랫동안 지속 가능한 회사다운 회사를 만들지에 대한, 사업가의 마인드와 실행력이 필요하다.\n어떤 분들은 이런 걸 0에서 1은 엄청나게 잘 하지만, 1에서 10까진 못 하는 딜레마라고도 한다. 결국엔 돈을 벌고 사업을 만드는 건 1에서 10 사이 어딘가에 존재하고, 단순히 만드는 회사가 아닌 사업하는 회사가 되기 위해선 1에서 10 사이 어딘가에 있어야 한다.\n결국엔 피스커도 멋지고 시장에서 WoW 하는 제품을 만들어서 출시했지만(0->1), 회사가 돈을 벌면서 이 멋진 자동차를 대량생산해서 판매할 방법에 대한 생각과 고민이 깊지 않았고, 결국 지속 가능한 사업(1->10)을 만드는 데 실패했다고 생각한다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2024/07/on-being-ready-to-be-a-sustainable-business.html#respond",
        "content": "한때는 테슬라보다 더 혁신적인 전기 자동차 회사로 추앙받던 Fisker가 얼마 전에 파산 신청을 했다. 실은, 10년 전에 이미 회사를 한 번 말아먹었고, 이번이 두 번째 파산이라고도 할 수 있는데, 관련 기사를 읽어보면 피스커의 파산 원인은 여러 가지 복합적이지만, 결국엔 지속 가능한 사업 자체를 만들 준비가 안 됐기 때문인 것 같다. TechCrunch의 기사 제목을 보면 피스커의(...)",
        "contentSnippet": "한때는 테슬라보다 더 혁신적인 전기 자동차 회사로 추앙받던 Fisker가 얼마 전에 파산 신청을 했다. 실은, 10년 전에 이미 회사를 한 번 말아먹었고, 이번이 두 번째 파산이라고도 할 수 있는데, 관련 기사를 읽어보면 피스커의 파산 원인은 여러 가지 복합적이지만, 결국엔 지속 가능한 사업 자체를 만들 준비가 안 됐기 때문인 것 같다. TechCrunch의 기사 제목을 보면 피스커의(...)",
        "guid": "https://www.thestartupbible.com/?p=9152",
        "categories": [
          "Uncategorized",
          "failure",
          "FoundersAtWork",
          "hardware",
          "mobility",
          "strategy",
          "Strong",
          "스타트업 바이블 QA"
        ],
        "isoDate": "2024-07-10T21:34:00.000Z"
      }
    ]
  },
  {
    "name": "Build a Great Product",
    "category": "개인",
    "posts": []
  },
  {
    "name": "지금 써보러 갑니다",
    "category": "개인",
    "posts": []
  },
  {
    "name": "매거진 입맛",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "요즘 IT",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "쿠팡 엔지니어링",
    "category": "기업",
    "posts": []
  },
  {
    "name": "지마켓 기술 블로그",
    "category": "기업",
    "posts": [
      {
        "creator": "지마켓 기술블로그",
        "title": "Redis Stream 적용기",
        "link": "https://dev.gmarket.com/113",
        "pubDate": "Thu, 11 Jul 2024 15:55:03 +0900",
        "author": "지마켓 기술블로그",
        "comments": "https://dev.gmarket.com/113#entry113comment",
        "content": "<div id=\"SE-2c9b3139-ac56-4d2d-850c-9c900a9815a4\" data-compid=\"SE-2c9b3139-ac56-4d2d-850c-9c900a9815a4\" data-a11y-title=\"본문\">\n<div data-unitid=\"\" data-compid=\"SE-2c9b3139-ac56-4d2d-850c-9c900a9815a4\" data-direction=\"top\">\n<div id=\"SE-741470b1-f120-49c5-87ee-5590a6ea400a\">\n<p id=\"SE-357ed5d0-792c-4e3b-8e49-ae1c6930c179\" style=\"text-align: justify;\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">안녕하세요 Data Product 팀 박상우입니다.</span></p>\n<p id=\"SE-21a56774-3805-4eb6-a441-8b03225e0767\" style=\"text-align: justify;\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-ca8cdf9c-9bec-49fe-8444-8b20e8ef3c1f\" style=\"text-align: justify;\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">이번에 제가 소개해드릴 내용은 팀 내 session Info data 적재 및 API 서비스 구축에 적용한 Redis Stream에 대한 이야기입니다.</span></p>\n<p id=\"SE-2edf5846-d99e-4b1d-942a-824a88ef7faa\" style=\"text-align: justify;\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-6d909383-ff9b-4d35-aae4-be5d72b77c65\" style=\"text-align: justify;\" data-ke-size=\"size16\">저희 팀에서는 User의 행동 정보를 수집하는 프레임워크 중 하나인 montelena receiver를 통해 수집한 데이터 (view, event, impression 등)를 post Processor라는 데이터 파이프라인 application을 통해 적재, 가공해서 각종 지표 트래킹 및 분석에 활용할 수 있도록 제공하고 있습니다.</p>\n<p id=\"SE-02e93e82-be43-4a45-a3f1-db95b554df20\" style=\"text-align: justify;\" data-ke-size=\"size16\">&nbsp;</p>\n</div>\n</div>\n</div>\n<div id=\"SE-468d39bb-314c-46ca-83cd-0af12095f990\" data-compid=\"SE-468d39bb-314c-46ca-83cd-0af12095f990\" data-a11y-title=\"사진\">\n<div data-unitid=\"\" data-compid=\"SE-468d39bb-314c-46ca-83cd-0af12095f990\" data-direction=\"top\">\n<div id=\"SE-468d39bb-314c-46ca-83cd-0af12095f990\">\n<div data-unitid=\"SE-468d39bb-314c-46ca-83cd-0af12095f990\" data-compid=\"\" data-direction=\"top\"><figure class=\"imageblock alignLeft\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"936\" data-origin-height=\"353\"><span data-url=\"https://blog.kakaocdn.net/dn/SBPOd/btsIwoKfyaN/2JJfk81k3oxKCKPy1Dezy1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/SBPOd/btsIwoKfyaN/2JJfk81k3oxKCKPy1Dezy1/img.png\" data-alt=\"Post Processor Data Pipeline\"><img src=\"https://blog.kakaocdn.net/dn/SBPOd/btsIwoKfyaN/2JJfk81k3oxKCKPy1Dezy1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FSBPOd%2FbtsIwoKfyaN%2F2JJfk81k3oxKCKPy1Dezy1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"936\" data-origin-height=\"353\"/></span><figcaption>Post Processor Data Pipeline</figcaption>\n</figure>\n</div>\n</div>\n<div id=\"SE-5a4bd3d0-0d12-4aad-bf3a-3c3dcce13a6f\">\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-e075356b-38e3-41eb-a3a2-b7858c9beba2\" data-ke-size=\"size16\"><span style=\"color: #000000; letter-spacing: 0px; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">그중 유니크한 active user를 식별하기 위해 session_id를 발급하고, 그 히스토리를 남겨 광고에 활용하고 있는데,</span></p>\n</div>\n</div>\n</div>\n<div id=\"SE-0b48a89c-f2df-44d8-8d78-7edc34e87c1d\" data-compid=\"SE-0b48a89c-f2df-44d8-8d78-7edc34e87c1d\" data-a11y-title=\"본문\">\n<div data-unitid=\"\" data-compid=\"SE-0b48a89c-f2df-44d8-8d78-7edc34e87c1d\" data-direction=\"top\">\n<div id=\"SE-0493ecca-7da0-42b9-87b5-31418a7ef390\">\n<p id=\"SE-c7fb2763-0ab4-4ee5-b9aa-fa5fdbc41797\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">'Big Smile Day' (지마켓 최고의 연례행사인 빅스마일데이, 이하 BDS)</span></p>\n<p id=\"SE-55b4456d-f930-4b5a-b8cb-4254427f8342\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">'User Targeting Content' (이하 UTC) Push 발송 등 유저의 유입이 급증해서 트래픽이 대폭 증가할 경우 데이터 처리가 지연되는 현상이 발생하게 되었습니다.</span></p>\n<p id=\"SE-a3dd4089-12f6-48d5-a70f-211da8bc84dc\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-6168f497-1f4a-40e0-adb6-8600e573040e\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">이 문제를 해결하기 위해서는 부하를 발생시키는 로직을 분리해서 별도로 처리하도록 하는<span>&nbsp;</span><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif; color: #000000; text-align: start;\">application</span>의 개발이 요구되는 상황이었고,</span></p>\n<p id=\"SE-411d4691-6532-4300-9a58-0e1b4db2dbcd\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">이에 Redis stream을 사용해서 session_id 히스토리 적재 로직을 수행하는 신규 consumer를 개발했던 과정을 간단하게나마 공유해보고자 합니다.</span></p>\n<p id=\"SE-9aebcf12-3a31-4257-aa78-23b2b573f787\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-412c07c7-1fbf-45e3-bc6e-655cf98e9f72\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-b2f0ee19-e189-4a18-bcb3-58df216da2f7\" data-ke-size=\"size16\">&nbsp;</p>\n</div>\n</div>\n</div>\n<div id=\"SE-8c1cf4fc-bedd-4308-ba8a-d7746f88e176\" data-compid=\"SE-8c1cf4fc-bedd-4308-ba8a-d7746f88e176\" data-a11y-title=\"소제목\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-8c1cf4fc-bedd-4308-ba8a-d7746f88e176\" data-direction=\"top\">\n<div>\n<div id=\"SE-0b356118-4562-40a6-970c-366cf868c876\">\n<h2 id=\"SE-5b922977-36c3-495c-87b4-f690741f3b32\" style=\"color: #000000;\" data-ke-size=\"size26\"><b><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">Redis Stream의 특징과 장점</span></b></h2>\n</div>\n</div>\n</div>\n</div>\n</div>\n<p style=\"text-align: justify;\" data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"text-align: justify;\" data-ke-size=\"size16\"><span style=\"color: #000000; letter-spacing: 0px; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">2018년 10월 17일, Redis 5.0 버전이 출시되었습니다.</span></p>\n<div id=\"SE-19dc2e32-9404-454a-b69c-0eaa465d7b9a\" data-compid=\"SE-19dc2e32-9404-454a-b69c-0eaa465d7b9a\" data-a11y-title=\"사진\">\n<div data-unitid=\"\" data-compid=\"SE-19dc2e32-9404-454a-b69c-0eaa465d7b9a\" data-direction=\"top\">\n<div id=\"SE-9291e0a4-c0af-46d2-b6b9-77ebb077ab5f\">\n<p data-ke-size=\"size16\">&nbsp;</p>\n<div id=\"SE-19dc2e32-9404-454a-b69c-0eaa465d7b9a\" data-compid=\"SE-19dc2e32-9404-454a-b69c-0eaa465d7b9a\" data-a11y-title=\"사진\">\n<div data-unitid=\"\" data-compid=\"SE-19dc2e32-9404-454a-b69c-0eaa465d7b9a\" data-direction=\"top\">\n<div id=\"SE-19dc2e32-9404-454a-b69c-0eaa465d7b9a\">\n<div>&nbsp;</div>\n<div data-unitid=\"SE-19dc2e32-9404-454a-b69c-0eaa465d7b9a\" data-compid=\"\" data-direction=\"top\"><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"727\" data-origin-height=\"471\"><span data-url=\"https://blog.kakaocdn.net/dn/bJtN2h/btsIv8Vbi5J/y3xzOpcLp6Yw69kOCkbDU0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bJtN2h/btsIv8Vbi5J/y3xzOpcLp6Yw69kOCkbDU0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bJtN2h/btsIv8Vbi5J/y3xzOpcLp6Yw69kOCkbDU0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbJtN2h%2FbtsIv8Vbi5J%2Fy3xzOpcLp6Yw69kOCkbDU0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"500\" data-origin-width=\"727\" data-origin-height=\"471\"/></span></figure>\n</div>\n<span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\"></span></div>\n<div>&nbsp;</div>\n<div>&nbsp;</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<p style=\"text-align: justify;\" data-ke-size=\"size16\">이전&nbsp;버전에서&nbsp;많은&nbsp;부분이&nbsp;개선되었지만&nbsp;그중&nbsp;가장&nbsp;중요한&nbsp;기능&nbsp;추가&nbsp;중&nbsp;하나가&nbsp;바로&nbsp;Redis&nbsp;stream&nbsp;이였는데요.<br />고가용성&nbsp;데이터&nbsp;스트리밍&nbsp;처리가&nbsp;도입되면서,&nbsp;데이터의&nbsp;일관성과&nbsp;안정성을&nbsp;보장하면서&nbsp;대용량&nbsp;데이터&nbsp;스트림을&nbsp;실시간으로&nbsp;처리할 수&nbsp;있게&nbsp;되었습니다.<br />동시에 inmemory 기반으로 동작하는 key value 기반의 캐시를 사용하기 때문에 속도가 빠르다는 장점으로 사내에서도 저장소로&nbsp;널리&nbsp;사용되고 있죠.</p>\n<p style=\"text-align: justify;\" data-ke-size=\"size16\">&nbsp;</p>\n<div id=\"SE-401d2a2f-1385-43dc-95ac-240605a5cff7\" data-compid=\"SE-401d2a2f-1385-43dc-95ac-240605a5cff7\" data-a11y-title=\"본문\">\n<div data-unitid=\"\" data-compid=\"SE-401d2a2f-1385-43dc-95ac-240605a5cff7\" data-direction=\"top\">\n<div id=\"SE-27f964f0-3e80-4fbe-b415-5335fd52026c\">\n<p id=\"SE-476d05cb-8a69-4e82-980c-9d7baca9f1d0\" data-ke-size=\"size16\">&nbsp;</p>\n<h2 id=\"SE-d9e7b0e4-6c6a-4932-be60-96638bca8718\" style=\"color: #000000;\" data-ke-size=\"size26\"><b><span style=\"color: #000000; letter-spacing: 0px; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">왜 Redis Stream을 선택했는가?</span></b></h2>\n</div>\n</div>\n</div>\n<div id=\"SE-662bd44e-9cac-4554-b87a-9572250e9bc2\" data-compid=\"SE-662bd44e-9cac-4554-b87a-9572250e9bc2\" data-a11y-title=\"본문\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-662bd44e-9cac-4554-b87a-9572250e9bc2\" data-direction=\"top\">\n<div>\n<div id=\"SE-1132e013-65d2-4ece-808b-f2633ffe9d50\">\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-270a3284-7ae1-4297-8f36-ab7624d57043\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">처음에는 메시지 큐로 kafka나 MQ를 생각했었는데, 새로운 플랫폼을 적용해야 하다 보니 개발 공수도 늘어나고 리소스도 많이 소모될 거라는 결론을 내렸습니다.</span></p>\n<p id=\"SE-a2903419-78c8-42eb-9aed-0d5f54ca6b90\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">거기다 BSD가 얼마 남지 않은 시점이라 그전에 개발을 완료해야 된다는 시간적인 제한도 허들이었습니다.</span></p>\n<p id=\"SE-d4b227e2-63f1-4f92-b04d-9d26a05c9b5a\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">이미 session_id 저장소로 redis를 사용하고 있었고, 최대한 기존 로직을 건드리지 않으면서, 빠르게 히스토리를 적재할 수 있는 방법을 찾던 중,</span></p>\n<p id=\"SE-ce036b84-2517-4774-84e0-23908edcd43f\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">kafka와 유사한 기능들을 제공하면서 사내 openshift 환경의 여러 개 pod에서 구동해도 데이터 중복이나 유실 없이 처리가 가능한 Redis stream을 선택하게 되었습니다.</span></p>\n<p id=\"SE-9c0b7bfc-2769-4411-a8bd-8a73884e7abc\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-8d5fb2d8-06ac-47a2-9fb9-449b0eff6d50\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-6ae2d4c0-877b-4b62-8629-b4015e0ec3f0\" data-ke-size=\"size16\">&nbsp;</p>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-b28477fc-4501-4d0b-919a-48011b3b7d95\" data-compid=\"SE-b28477fc-4501-4d0b-919a-48011b3b7d95\" data-a11y-title=\"소제목\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-b28477fc-4501-4d0b-919a-48011b3b7d95\" data-direction=\"top\">\n<div>\n<div id=\"SE-edc77a9b-6756-4678-91c4-e7f6fa5a5040\">\n<h2 id=\"SE-1eedcb1a-3744-4dc2-b8f0-66f9dc8cb113\" style=\"color: #000000;\" data-ke-size=\"size26\"><b><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">Redis Pub/Sub과 Redis Stream?</span></b></h2>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-b2bfe4c8-3516-4379-8f5a-0d3343890166\" data-compid=\"SE-b2bfe4c8-3516-4379-8f5a-0d3343890166\" data-a11y-title=\"본문\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-b2bfe4c8-3516-4379-8f5a-0d3343890166\" data-direction=\"top\">\n<div>\n<div id=\"SE-2b73999d-9408-4f92-adfd-337b6364c533\">\n<p id=\"SE-e11ef9e3-5704-4fe1-a45d-aa93b4dc4061\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-3e062e88-28c2-41be-a19b-d0f1ca15cf58\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">일반적으로 Redis를 이용해 메시지를 Broadcasting 할 때는 pub/sub을 많이 사용합니다.</span></p>\n<p id=\"SE-afd4ed17-640d-417e-ac6e-a48c5896ea5d\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">하지만 이 방식은 publisher가 메시지를 발행했을 때 subscriber가 존재하지 않거나 애플리케이션에 이슈가 발생하면 수신 여부에 관계없이 메시지가 휘발되는 단점이 있습니다.</span></p>\n<p id=\"SE-9ae4edb6-538a-47e2-9e74-226c6df845d1\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">또한, 여러 개의 subscriber를 구동하면 모두에게 동일한 메시지를 발행해 데이터가 중복되는 이슈가 발생합니다.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-8deef978-4efa-41b3-83e6-09075a0ff7d8\" data-compid=\"SE-8deef978-4efa-41b3-83e6-09075a0ff7d8\" data-a11y-title=\"사진\">\n<div data-unitid=\"\" data-compid=\"SE-8deef978-4efa-41b3-83e6-09075a0ff7d8\" data-direction=\"top\">\n<div id=\"SE-8deef978-4efa-41b3-83e6-09075a0ff7d8\">\n<div id=\"SE-8deef978-4efa-41b3-83e6-09075a0ff7d8\" data-compid=\"SE-8deef978-4efa-41b3-83e6-09075a0ff7d8\" data-a11y-title=\"사진\">\n<div data-unitid=\"\" data-compid=\"SE-8deef978-4efa-41b3-83e6-09075a0ff7d8\" data-direction=\"top\">\n<div id=\"SE-8deef978-4efa-41b3-83e6-09075a0ff7d8\">\n<div data-unitid=\"SE-8deef978-4efa-41b3-83e6-09075a0ff7d8\" data-compid=\"\" data-direction=\"top\"><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"764\" data-origin-height=\"271\"><span data-url=\"https://blog.kakaocdn.net/dn/djuNL5/btsIvc44dSR/nwOBrr8w29oi21zVE3rBw1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/djuNL5/btsIvc44dSR/nwOBrr8w29oi21zVE3rBw1/img.png\" data-alt=\"Redis Pub / Sub\"><img src=\"https://blog.kakaocdn.net/dn/djuNL5/btsIvc44dSR/nwOBrr8w29oi21zVE3rBw1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdjuNL5%2FbtsIvc44dSR%2FnwOBrr8w29oi21zVE3rBw1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"500\" data-origin-width=\"764\" data-origin-height=\"271\"/></span><figcaption>Redis Pub / Sub</figcaption>\n</figure>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-d8914789-fae5-40df-b819-d93e5536cc54\" data-compid=\"SE-d8914789-fae5-40df-b819-d93e5536cc54\" data-a11y-title=\"본문\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-d8914789-fae5-40df-b819-d93e5536cc54\" data-direction=\"top\">\n<div>\n<div id=\"SE-b1a053cd-7310-4f7d-ba53-b9259578498e\">\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-afc6e0ac-5e90-4898-900a-5375c334b416\" data-ke-size=\"size16\"><span style=\"background-color: #ffffff; color: #202124; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">반면, Redis Stream은 휘발성이 아니라 Kafka의 offset 개념처럼 마지막으로 수신한 record id를 저장하고 XADD, XREADGROUP, XACK, XPENDING, XCLAIM으로 이어지는 처리 프로세스를 통해 메시지를 컨트롤할 수 있는 다양한 방법을 제공합니다.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-9e58f812-3103-4700-8642-45867dc03830\" data-compid=\"SE-9e58f812-3103-4700-8642-45867dc03830\" data-a11y-title=\"사진\">\n<div data-unitid=\"\" data-compid=\"SE-9e58f812-3103-4700-8642-45867dc03830\" data-direction=\"top\">\n<div id=\"SE-38ffbcef-62f9-4b87-a300-74b1c2961990\">\n<div id=\"SE-9e58f812-3103-4700-8642-45867dc03830\" data-compid=\"SE-9e58f812-3103-4700-8642-45867dc03830\" data-a11y-title=\"사진\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-9e58f812-3103-4700-8642-45867dc03830\" data-direction=\"top\">\n<div>\n<div id=\"SE-9e58f812-3103-4700-8642-45867dc03830\">\n<div data-unitid=\"SE-9e58f812-3103-4700-8642-45867dc03830\" data-compid=\"\" data-direction=\"top\"><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"936\" data-origin-height=\"454\"><span data-url=\"https://blog.kakaocdn.net/dn/5VRLC/btsIuJbk6De/jgDkLxka0URSNnkpQGfjKK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/5VRLC/btsIuJbk6De/jgDkLxka0URSNnkpQGfjKK/img.png\" data-alt=\"Redis Stream\"><img src=\"https://blog.kakaocdn.net/dn/5VRLC/btsIuJbk6De/jgDkLxka0URSNnkpQGfjKK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F5VRLC%2FbtsIuJbk6De%2FjgDkLxka0URSNnkpQGfjKK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"700\" height=\"340\" data-origin-width=\"936\" data-origin-height=\"454\"/></span><figcaption>Redis Stream</figcaption>\n</figure>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-1685d92e-3fd6-4e11-ae8e-7f7010b4f3d0\" data-compid=\"SE-1685d92e-3fd6-4e11-ae8e-7f7010b4f3d0\" data-a11y-title=\"본문\">\n<div data-unitid=\"\" data-compid=\"SE-1685d92e-3fd6-4e11-ae8e-7f7010b4f3d0\" data-direction=\"top\">\n<div id=\"SE-6c282846-05f4-450b-b3f8-299d639bd94c\">\n<p id=\"SE-a1ce989c-92e9-434c-a046-4009660c5ae8\" style=\"text-align: center;\" data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\"><span style=\"color: #000000;\">출처 :<span>&nbsp;</span></span><span style=\"color: #000000;\" data-href=\"https://jybaek.tistory.com/935\"><a href=\"https://jybaek.tistory.com/935\">https://jybaek.tistory.com/935</a></span></span></p>\n<p id=\"SE-ab0cbd7c-2853-41b6-9179-101ca31033ec\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-d054cfc8-c06c-429e-960a-fad4ad846a75\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-b4aeaa0a-5405-4c79-9c69-9afaa5447348\" data-ke-size=\"size16\"><span style=\"background-color: #ffffff; color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">또한, Redis Stream은 consumer group을 지원하기 때문에 producer가 발행한 메시지를 여러 개의 consumer가 하나의 그룹을 형성해서 중복 없이 순차적으로 병렬 처리할 수 있습니다.</span></p>\n<p id=\"SE-c899530e-7b99-4159-b0dc-d2c6ddba796e\" data-ke-size=\"size16\"><span style=\"background-color: #ffffff; color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">그리고 XACK 명령어를 사용해 메시지 처리 여부를 확인할 수 있으며, 일정 시간 동안 처리되지 못한 메시지들도 Pending Entries List를 이용해서 재처리할 수 있는 방법을 제공합니다.</span></p>\n<p data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">&nbsp;</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<div id=\"SE-e16ffa64-c312-4d25-9143-50cf67592c37\" data-compid=\"SE-e16ffa64-c312-4d25-9143-50cf67592c37\" data-a11y-title=\"사진\">\n<div data-unitid=\"\" data-compid=\"SE-e16ffa64-c312-4d25-9143-50cf67592c37\" data-direction=\"top\">\n<div id=\"SE-e16ffa64-c312-4d25-9143-50cf67592c37\">\n<div>&nbsp;</div>\n<div data-unitid=\"SE-e16ffa64-c312-4d25-9143-50cf67592c37\" data-compid=\"\" data-direction=\"top\"><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"936\" data-origin-height=\"384\"><span data-url=\"https://blog.kakaocdn.net/dn/dcWlQp/btsIvuj7Zcb/EubKOQ3WOv7XN1Bnj0H2gK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/dcWlQp/btsIvuj7Zcb/EubKOQ3WOv7XN1Bnj0H2gK/img.png\" data-alt=\"Redis Stream\"><img src=\"https://blog.kakaocdn.net/dn/dcWlQp/btsIvuj7Zcb/EubKOQ3WOv7XN1Bnj0H2gK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdcWlQp%2FbtsIvuj7Zcb%2FEubKOQ3WOv7XN1Bnj0H2gK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"500\" data-origin-width=\"936\" data-origin-height=\"384\"/></span><figcaption>Redis Stream</figcaption>\n</figure>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-288e280d-6a52-41e8-8499-823d02f251b6\" data-compid=\"SE-288e280d-6a52-41e8-8499-823d02f251b6\" data-a11y-title=\"본문\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-288e280d-6a52-41e8-8499-823d02f251b6\" data-direction=\"top\">\n<div>\n<div id=\"SE-fb3932b5-b95d-4b11-8b07-5ceaf287aefb\">\n<p id=\"SE-9e6367df-0387-4fba-a980-1fc1075b9da8\" style=\"text-align: center;\" data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\"><span style=\"color: #000000;\">출처 :<span>&nbsp;</span></span><span style=\"color: #000000;\" data-href=\"https://jybaek.tistory.com/935\"><a href=\"https://jybaek.tistory.com/935\">https://jybaek.tistory.com/935</a></span></span></p>\n<p id=\"SE-a1d3405d-9bf0-44fc-8335-d72f94d05895\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-f7885cbb-4667-4e34-a91e-a6b61bc7ba9d\" data-ke-size=\"size16\">&nbsp;</p>\n<h2 id=\"SE-c2091a53-27c5-4981-819b-8363f55aedce\" style=\"color: #000000;\" data-ke-size=\"size26\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\"><b>Redis stream Development</b></span></h2>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-707de02d-f65b-48a9-b6f0-3b9a443cc77b\" data-compid=\"SE-707de02d-f65b-48a9-b6f0-3b9a443cc77b\" data-a11y-title=\"본문\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-707de02d-f65b-48a9-b6f0-3b9a443cc77b\" data-direction=\"top\">\n<div>\n<div id=\"SE-b9beb496-17c7-4639-8501-98cfa7c601c5\">\n<p id=\"SE-848be57f-56e6-4915-9825-93836706a052\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-eb31c105-8a1b-48fe-bce2-91a3d4629279\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">이제 실제로 코드를 보며 Redis stream으로 어떻게 개발을 진행했는지 간단히 알아보도록 하겠습니다.</span></p>\n<p id=\"SE-4c006b2e-08de-451c-a726-2c5558f7b92a\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">프로세스는 심플한 구조로 아래 flow chart를 참고해 주시면 되겠습니다.</span></p>\n</div>\n</div>\n</div>\n</div>\n</div>\n<p style=\"text-align: justify;\" data-ke-size=\"size16\">&nbsp;</p>\n<div id=\"SE-4bb6012c-751a-4442-8b38-e7bfa5169dfc\" data-compid=\"SE-4bb6012c-751a-4442-8b38-e7bfa5169dfc\" data-a11y-title=\"사진\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-4bb6012c-751a-4442-8b38-e7bfa5169dfc\" data-direction=\"top\">\n<div>&nbsp;</div>\n</div>\n</div>\n</div>\n<div id=\"SE-b8fbb9b6-067f-4fd3-82b2-513c47cfb988\" data-compid=\"SE-b8fbb9b6-067f-4fd3-82b2-513c47cfb988\" data-a11y-title=\"소제목\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-b8fbb9b6-067f-4fd3-82b2-513c47cfb988\" data-direction=\"top\">\n<div>\n<div id=\"SE-7bf1eb01-c5e9-4567-affa-b6a9ad6384de\">\n<p data-ke-size=\"size16\">&nbsp;</p>\n<div id=\"SE-4bb6012c-751a-4442-8b38-e7bfa5169dfc\" data-compid=\"SE-4bb6012c-751a-4442-8b38-e7bfa5169dfc\" data-a11y-title=\"사진\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-4bb6012c-751a-4442-8b38-e7bfa5169dfc\" data-direction=\"top\">\n<div>\n<div id=\"SE-4bb6012c-751a-4442-8b38-e7bfa5169dfc\">\n<div>&nbsp;</div>\n<div data-unitid=\"SE-4bb6012c-751a-4442-8b38-e7bfa5169dfc\" data-compid=\"\" data-direction=\"top\"><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"808\" data-origin-height=\"327\"><span data-url=\"https://blog.kakaocdn.net/dn/cADQ90/btsIv7IKSSA/ZAki0Xm51oKpkSICbkZZ6k/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cADQ90/btsIv7IKSSA/ZAki0Xm51oKpkSICbkZZ6k/img.png\" data-alt=\"Redis Stream flow\"><img src=\"https://blog.kakaocdn.net/dn/cADQ90/btsIv7IKSSA/ZAki0Xm51oKpkSICbkZZ6k/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcADQ90%2FbtsIv7IKSSA%2FZAki0Xm51oKpkSICbkZZ6k%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"808\" height=\"327\" data-origin-width=\"808\" data-origin-height=\"327\"/></span><figcaption>Redis Stream flow</figcaption>\n</figure>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-32a10410-a65a-4dbd-9633-7a1305807528\" data-compid=\"SE-32a10410-a65a-4dbd-9633-7a1305807528\" data-a11y-title=\"소제목\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-32a10410-a65a-4dbd-9633-7a1305807528\" data-direction=\"top\">\n<div>\n<div id=\"SE-32848fa8-69dd-4c86-b11f-7450c4f671c7\">\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-84113c7f-be28-4bb0-a7c5-40373116ca6b\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\"><b>&lt;Publisher&gt;</b></span></p>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-edac2506-b47b-4324-ad33-123a418238b6\" data-compid=\"SE-edac2506-b47b-4324-ad33-123a418238b6\" data-a11y-title=\"본문\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-edac2506-b47b-4324-ad33-123a418238b6\" data-direction=\"top\">\n<div>\n<div id=\"SE-b23e679d-2030-4156-af61-4fa1da515d1f\">\n<p id=\"SE-61ccbf26-4173-4f6e-a7c1-c285af9f72d2\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">먼저 Post Processor에서 트래픽 데이터를 가공/처리한 후, app에서 정의한 streamKey를 통해서 생성한 session 객체를 캡슐화해서 Redis Stream 메시지로 발행합니다.</span></p>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-77887dee-5a6a-4f32-86cb-ac6c538be831\" data-compid=\"SE-77887dee-5a6a-4f32-86cb-ac6c538be831\" data-a11y-title=\"코드\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-77887dee-5a6a-4f32-86cb-ac6c538be831\" data-direction=\"top\">\n<div>\n<div>\n<div>\n<pre class=\"reasonml\" style=\"background-color: #f8f8f8; color: #383a42;\" data-ke-language=\"java\"><code>ObjectRecord&lt;String, String&gt; record = StreamRecords.newRecord()\n\t\t\t\t.ofObject(GsonUtil.gson().toJson(session))\n\t\t\t\t.withStreamKey(streamKey);\n\nRecordId recordId = gmktRedisTemplate.opsForStream().add(record);\nif (Objects.isNull(recordId)) {\n    // Redis Stream record 처리에 실패했을 경우 로직 추가\n}</code></pre>\n</div>\n<div>&nbsp;</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-cfc7fcb3-d839-45cd-b87e-f298b5026795\" data-compid=\"SE-cfc7fcb3-d839-45cd-b87e-f298b5026795\" data-a11y-title=\"본문\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-cfc7fcb3-d839-45cd-b87e-f298b5026795\" data-direction=\"top\">\n<div>\n<div id=\"SE-2e782fc2-0ab5-4abf-914b-08864a729e76\">\n<p id=\"SE-ee92c833-7004-4aff-88a3-56d74510ede1\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">opsForStream().add() 메서드를 통해서 메시지를 발행하면 recordId를 리턴하는데, 이 값은 각각의 메시지가 스트림에 추가될 때 Redis가 생성해 주는 고유의 id 값으로 보시면 됩니다.</span></p>\n<p id=\"SE-1c7c2ef7-8c54-49ad-a8c7-2f2b3c4ae6a9\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">저는 stream key / value 형태의 ObjectRecord 객체를 사용해서 개발했지만,</span></p>\n<p id=\"SE-c5453b6a-83fb-4f14-bffb-455d21798805\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">이외에도 value 값으로 Map&lt;K, V&gt; 형태로 데이터를 저장하고 읽을 수 있는 MapRecord라는 메서드도 지원하고 있습니다.</span></p>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-9fc73dac-0da6-4c26-8cb9-86d12ca9d6f1\" data-compid=\"SE-9fc73dac-0da6-4c26-8cb9-86d12ca9d6f1\" data-a11y-title=\"코드\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-9fc73dac-0da6-4c26-8cb9-86d12ca9d6f1\" data-direction=\"top\">\n<div>\n<div>\n<div>\n<pre class=\"reasonml\" style=\"background-color: #f8f8f8; color: #383a42;\"><code>public interface MapRecord&lt;S, K, V&gt; extends Record&lt;S, Map&lt;K, V&gt;&gt;, Iterable&lt;Map.Entry&lt;K, V&gt;&gt; {\n\n\tstatic &lt;S, K, V&gt; MapRecord&lt;S, K, V&gt; create(S stream, Map&lt;K, V&gt; map) {\n\n\t\tAssert.notNull(stream, \"Stream must not be null\");\n\t\tAssert.notNull(map, \"Map must not be null\");\n\n\t\treturn new MapBackedRecord&lt;&gt;(stream, RecordId.autoGenerate(), map);\n\t}\n}</code></pre>\n</div>\n<div>&nbsp;</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-98145847-a32a-42c0-8da6-7a148159ce2b\" data-compid=\"SE-98145847-a32a-42c0-8da6-7a148159ce2b\" data-a11y-title=\"본문\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-98145847-a32a-42c0-8da6-7a148159ce2b\" data-direction=\"top\">\n<div>\n<div id=\"SE-5360de94-3060-40bc-bd73-ed580458aa65\">\n<p id=\"SE-185d8051-2d3f-4daf-9a0f-55cf30e9408c\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-1a9ed55e-cb22-4642-95bb-0d9530ccefa9\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\"><b>&lt;Consumer&gt;</b></span></p>\n<p id=\"SE-454f8cb7-0b4f-4483-acfb-02371449862b\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">다음은 발행된 메시지를 컨슈밍 하고 처리하는 코드를 보여드리겠습니다.</span></p>\n<p id=\"SE-d1e0074a-b694-45b6-9d8b-bc0d867cb4b3\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">먼저 Spring boot 프로젝트에서 'spring-boot-starter-data-redis' 의존성을 추가하고 Redis 서버 설정을 완료합니다.</span></p>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-45b12fc3-7f7a-4a11-80aa-18f4bb1a4dd7\" data-compid=\"SE-45b12fc3-7f7a-4a11-80aa-18f4bb1a4dd7\" data-a11y-title=\"코드\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-45b12fc3-7f7a-4a11-80aa-18f4bb1a4dd7\" data-direction=\"top\">\n<div>\n<div>\n<div>\n<pre class=\"xml\" style=\"background-color: #f8f8f8; color: #383a42;\"><code>&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;\n&lt;/dependency&gt;</code></pre>\n</div>\n<div>&nbsp;</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-2be1ad25-43fa-4716-992e-de27eeb244f1\" data-compid=\"SE-2be1ad25-43fa-4716-992e-de27eeb244f1\" data-a11y-title=\"본문\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-2be1ad25-43fa-4716-992e-de27eeb244f1\" data-direction=\"top\">\n<div>\n<div id=\"SE-1fa8afaa-6160-4826-b530-b3a37368dd9b\">\n<p id=\"SE-2a544bfe-68be-43bc-a2d1-b56886883422\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">그다음 'StreamListener' 인터페이스를 구현하고, afterPropertiesSet() 메서드를 @Orverride 해서 Redis Stream 메시지를 소비하는 consumer Group과 Listener Container를 설정하고 초기화합니다.</span></p>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-ef18516e-30ed-4bb5-a556-a87a00b1826f\" data-compid=\"SE-ef18516e-30ed-4bb5-a556-a87a00b1826f\" data-a11y-title=\"코드\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-ef18516e-30ed-4bb5-a556-a87a00b1826f\" data-direction=\"top\">\n<div>\n<div>\n<div>\n<pre class=\"reasonml\" style=\"background-color: #f8f8f8; color: #383a42;\"><code>@Override\npublic void afterPropertiesSet() throws Exception {\n    // Consumer Group 설정\n    createStreamConsumerGroup(streamKey, consumerGroupName);\n\n    // StreamMessageListenerContainer 설정\n    this.listenerContainer = StreamMessageListenerContainer.create(\n\t\t\t\tredisTemplate.getConnectionFactory(),\n\t\t\t\tStreamMessageListenerContainer.StreamMessageListenerContainerOptions.builder()\n\t\t\t\t.targetType(String.class)\n\t\t\t\t.pollTimeout(Duration.ofSeconds(2))\n\t\t\t\t.build()\n\t\t);\n\n    // Subscription 설정\n    this.subscription = this.listenerContainer.receive(\n            Consumer.from(this.consumerGroupName, consumerName),\n            StreamOffset.create(streamKey, ReadOffset.lastConsumed()),\n            this\n    );\n\n    // Redis listen 시작\n    this.listenerContainer.start();\n}\n\npublic void createStreamConsumerGroup(String streamKey, String consumerGroupName){\n\tif (!redisTemplate.hasKey(streamKey)){\n\t\tRedisClusterAsyncCommands commands = (RedisClusterAsyncCommands) this.redisTemplate\n\t\t\t\t.getConnectionFactory()\n\t\t\t\t.getClusterConnection()\n\t\t\t\t.getNativeConnection();\n\t\t\n        CommandArgs&lt;String, String&gt; args = new CommandArgs&lt;&gt;(StringCodec.UTF8)\n\t\t\t\t.add(CommandKeyword.CREATE)\n\t\t\t\t.add(streamKey)\n\t\t\t\t.add(consumerGroupName)\n\t\t\t\t.add(\"0\")\n\t\t\t\t.add(\"MKSTREAM\");\n\n\t\tcommands.dispatch(CommandType.XGROUP, new StatusOutput(StringCodec.UTF8), args);\n\t}\n\telse{\n\t\tif(!isStreamConsumerGroupExist(streamKey, consumerGroupName)){\n\t\t\tthis.redisTemplate.opsForStream().createGroup(streamKey, ReadOffset.from(\"0\"), consumerGroupName);\n\t\t}\n\t}\n}</code></pre>\n</div>\n<div>&nbsp;</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-c5eab8de-6a72-4a4f-8e32-4af6a44dacff\" data-compid=\"SE-c5eab8de-6a72-4a4f-8e32-4af6a44dacff\" data-a11y-title=\"본문\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-c5eab8de-6a72-4a4f-8e32-4af6a44dacff\" data-direction=\"top\">\n<div>\n<div id=\"SE-6d43d598-d620-4aca-bba0-c3cb7590ae47\">\n<p id=\"SE-2e564dd0-5c7c-4245-95d3-6c566ea24e15\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">Publisher에서 설정한 StreamKey와 Consumer Name을 세팅해서 Consumer Group을 생성합니다.</span></p>\n<p id=\"SE-f1cfaf02-4aa6-4f2a-9580-6b70e6f42e99\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">그리고 Consumer 객체를 생성, Offset 설정, Subscriber 옵션 등 세부적인 설정을 완료한 뒤, Listener Container를 시작하면 Redis Stream 메시지를 비동기적으로 Listner에게 전달하게 됩니다.</span></p>\n<p id=\"SE-c7bafcff-d90c-412c-a794-02cf3171546a\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">이 과정을 통해서 여러 개의 Consumer Group을 사용해서 하나의 Redis Stream을 병렬로 처리할 수 있습니다.</span></p>\n<p id=\"SE-ecc68fbd-e19e-432f-b6a1-d69aa5666fdb\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-094e67ba-5494-4454-af2b-94dc1d8a9cc4\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">이렇게 전달되는 메시지들은 마찬가지로 'StreamListener' 인터페이스가 제공하는 onMessage 메서드를 구현해서 처리하게 됩니다.</span></p>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-3a982061-e5b4-4038-ae19-04ba484914aa\" data-compid=\"SE-3a982061-e5b4-4038-ae19-04ba484914aa\" data-a11y-title=\"코드\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-3a982061-e5b4-4038-ae19-04ba484914aa\" data-direction=\"top\">\n<div>\n<div>\n<div>\n<pre class=\"reasonml\" style=\"background-color: #f8f8f8; color: #383a42;\"><code>@Override\npublic void onMessage(ObjectRecord&lt;String, String&gt; message) {\n    \n    String stream = message.getStream();\n    String recordId = message.getId().getValue();\n    \n    try {\n        // 처리할 로직 구현\n        if (StringUtils.isNotEmpty(message.getValue())) {\n            // To-Do\n        }\n        // 이후, ack stream\n        this.redisTemplate.opsForStream().acknowledge(streamKey, consumerGroupName, recordId);\n        \n    } catch (Exception e) {\n        // TODO: handle exception\n        e.printStackTrace();\n        this.redisOperator.delete(stream, recordId);\n    }\n}</code></pre>\n</div>\n<div>&nbsp;</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-a27a1193-0356-49c7-b518-59125a518ed4\" data-compid=\"SE-a27a1193-0356-49c7-b518-59125a518ed4\" data-a11y-title=\"본문\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-a27a1193-0356-49c7-b518-59125a518ed4\" data-direction=\"top\">\n<div>\n<div id=\"SE-77401bbc-f306-4983-8687-2811adf476f6\">\n<p id=\"SE-b9079962-3214-42fa-b68b-dbab64b1f572\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">메시지를 처리하고 나면 'ackStream' 메소드를 호출해서 Redis Stream 메시지가 성공적으로 처리되었음을 알리고, 해당 메시지를 대기열에서 제거합니다.</span></p>\n<p id=\"SE-86d29336-8939-4552-b232-12fbb8d88559\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">Exception 이 발생할 경우 recordId를 통해 메시지를 삭제 처리할 수도 있고, 다양한 시나리오로 처리가 가능하니 용도에 맞게 사용하시면 되겠습니다.</span></p>\n<p id=\"SE-b526e745-0b93-41e8-aca0-da6e37a27e6f\" data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-54f0a52c-4c94-4a55-b41e-e5d4511a6e19\" data-ke-size=\"size16\">&nbsp;</p>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-e30ea8ea-4591-4bea-aa95-20d8826a6409\" data-compid=\"SE-e30ea8ea-4591-4bea-aa95-20d8826a6409\" data-a11y-title=\"소제목\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-e30ea8ea-4591-4bea-aa95-20d8826a6409\" data-direction=\"top\">\n<div>\n<div id=\"SE-03626274-fc83-43bf-9233-551862ac372c\">\n<h2 id=\"SE-a27eef85-6824-4d86-b7d4-b2b29d03ebeb\" style=\"color: #000000;\" data-ke-size=\"size26\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\"><b>Redis stream 적용 시 고려할 점들</b></span></h2>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-87337d3c-5368-4f1e-9f65-b37a21afde18\" data-compid=\"SE-87337d3c-5368-4f1e-9f65-b37a21afde18\" data-a11y-title=\"본문\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-87337d3c-5368-4f1e-9f65-b37a21afde18\" data-direction=\"top\">\n<div>\n<div id=\"SE-a4e50485-301a-4a9e-9d0b-6663d0d4c93c\">\n<p id=\"SE-64809c52-18b2-4908-b60a-2a8c36fed53a\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-70df0afc-f520-4bb5-b4b7-3d8a0de56a52\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">Redis Stream은 파티션 개념이 없기 때문에 하나의 stream을 여러 개의 consumer가 병렬 처리하는 구조로 동작합니다.</span></p>\n<p id=\"SE-862d46d6-c66f-472d-a7cd-05838df12568\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">그래서 Redis cluster 구조에서 sharding 되어 있는 node에 메시지를 고르게 보내려면 추가적으로 N개의 stream을 각각의 node에 할당하도록 추가 개발이 필요합니다.</span></p>\n<p id=\"SE-70c5363c-6600-405c-9acd-098e8440ce5f\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">이러한 특징 때문에 produce 된 순서대로 메시지를 처리한다는 보장이 없어지는데, 이는 실서비스에 적용할 때 반드시 고려해야 할 점입니다.</span></p>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-e29805df-493d-4a32-8789-5a611b6e7ad0\" data-compid=\"SE-e29805df-493d-4a32-8789-5a611b6e7ad0\" data-a11y-title=\"사진\">\n<div data-unitid=\"\" data-compid=\"SE-e29805df-493d-4a32-8789-5a611b6e7ad0\" data-direction=\"top\">\n<div id=\"SE-e29805df-493d-4a32-8789-5a611b6e7ad0\">\n<div id=\"SE-e29805df-493d-4a32-8789-5a611b6e7ad0\" data-compid=\"SE-e29805df-493d-4a32-8789-5a611b6e7ad0\" data-a11y-title=\"사진\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-e29805df-493d-4a32-8789-5a611b6e7ad0\" data-direction=\"top\">\n<div>\n<div id=\"SE-e29805df-493d-4a32-8789-5a611b6e7ad0\">\n<div data-unitid=\"SE-e29805df-493d-4a32-8789-5a611b6e7ad0\" data-compid=\"\" data-direction=\"top\"><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"519\" data-origin-height=\"215\"><span data-url=\"https://blog.kakaocdn.net/dn/bSL4Sg/btsIvO3JfJn/csBbQKFXKKAG9EE5OCjOKK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bSL4Sg/btsIvO3JfJn/csBbQKFXKKAG9EE5OCjOKK/img.jpg\" data-alt=\"Partition을 지원하는 Kafka cousumer group의 구조\"><img src=\"https://blog.kakaocdn.net/dn/bSL4Sg/btsIvO3JfJn/csBbQKFXKKAG9EE5OCjOKK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbSL4Sg%2FbtsIvO3JfJn%2FcsBbQKFXKKAG9EE5OCjOKK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"600\" height=\"249\" data-origin-width=\"519\" data-origin-height=\"215\"/></span><figcaption>Partition을 지원하는 Kafka cousumer group의 구조</figcaption>\n</figure>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-608c567f-3e1e-4174-ad08-3ccd114e6363\" data-compid=\"SE-608c567f-3e1e-4174-ad08-3ccd114e6363\" data-a11y-title=\"사진\">\n<div data-unitid=\"\" data-compid=\"SE-608c567f-3e1e-4174-ad08-3ccd114e6363\" data-direction=\"top\">\n<div id=\"SE-608c567f-3e1e-4174-ad08-3ccd114e6363\">\n<div id=\"SE-608c567f-3e1e-4174-ad08-3ccd114e6363\" data-compid=\"SE-608c567f-3e1e-4174-ad08-3ccd114e6363\" data-a11y-title=\"사진\">\n<div data-unitid=\"\" data-compid=\"SE-608c567f-3e1e-4174-ad08-3ccd114e6363\" data-direction=\"top\">\n<div id=\"SE-608c567f-3e1e-4174-ad08-3ccd114e6363\">\n<div data-unitid=\"SE-608c567f-3e1e-4174-ad08-3ccd114e6363\" data-compid=\"\" data-direction=\"top\"><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"621\" data-origin-height=\"197\"><span data-url=\"https://blog.kakaocdn.net/dn/npYh8/btsIu22KWqw/RkzpHbeirIf34M98HJ1QPk/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/npYh8/btsIu22KWqw/RkzpHbeirIf34M98HJ1QPk/img.jpg\" data-alt=\"단일 Stream Redis stream cousumer group의 구조\"><img src=\"https://blog.kakaocdn.net/dn/npYh8/btsIu22KWqw/RkzpHbeirIf34M98HJ1QPk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FnpYh8%2FbtsIu22KWqw%2FRkzpHbeirIf34M98HJ1QPk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"600\" height=\"190\" data-origin-width=\"621\" data-origin-height=\"197\"/></span><figcaption>단일 Stream Redis stream cousumer group의 구조</figcaption>\n</figure>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-e9465d19-1241-4b4f-95c5-50a2277c372b\" data-compid=\"SE-e9465d19-1241-4b4f-95c5-50a2277c372b\" data-a11y-title=\"본문\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-e9465d19-1241-4b4f-95c5-50a2277c372b\" data-direction=\"top\">\n<div>\n<div id=\"SE-65d6d43d-9c7f-4a33-add0-3e989e0afe0a\">\n<p id=\"SE-2c787147-9cc6-4a3e-b992-addc26e3ae16\" style=\"text-align: center;\" data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\"><span style=\"color: #000000;\">출처 :<span>&nbsp;</span></span><span style=\"color: #000000;\" data-href=\"https://mattwestcott.org/blog/redis-streams-vs-kafka\"><a href=\"https://mattwestcott.org/blog/redis-streams-vs-kafka\">https://mattwestcott.org/blog/redis-streams-vs-kafka</a></span></span></p>\n<p id=\"SE-bbe73690-fbfd-49d0-b88d-a389de44d439\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-d7e416de-66bf-4f23-becc-cfc8c0e1abb0\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-a4680370-73c5-4265-aeb4-8c3c8cca5851\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">그리고 또 한 가지.</span></p>\n<p id=\"SE-24b0340e-ccac-4dfa-a27a-6f2b4b3c5c75\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">in-memory 기반의 저장소이기 때문에 memory 관리에 신경을 많이 써야 합니다.</span></p>\n<p id=\"SE-b3a1c6b3-6467-41ec-ac68-ee4aba251ae9\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">예를 들어, XACK를 받지 못한 pending 메시지를 다시 처리하지 않으면, 그 메시지들은 점점 쌓여가면서 Redis cluster의 memory를 위태롭게 만들 것입니다.</span></p>\n<p id=\"SE-bdf5cc9a-642c-4ce3-b23b-140131123daa\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">그래서 저도 1분마다 스케줄을 돌며 pending 메시지를 처리하는 로직을 추가해 memory full 이슈를 방지하고 있습니다.</span></p>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-c0fd154c-f351-44b0-842a-3321011e41e6\" data-compid=\"SE-c0fd154c-f351-44b0-842a-3321011e41e6\" data-a11y-title=\"코드\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-c0fd154c-f351-44b0-842a-3321011e41e6\" data-direction=\"top\">\n<div>\n<div>\n<div>\n<pre class=\"kotlin\" style=\"background-color: #f8f8f8; color: #383a42;\"><code>@Scheduled(fixedRate = 60000)\npublic void PendingMessagesSummaryScheduler() {\n    PendingMessagesSummary pendingSummary = this.redisOperator.pendingSummary(streamKey, consumerGroupName);\n\n    // 로그 출력\n    pendingSummary.getPendingMessagesPerConsumer().forEach((consumer, count) -&gt; {\n        log.info(\"Consumer: \" + consumer + \", Pending Messages: \" + count);\n    });\n\n    // pendingSummary와 TotalPendingMessages 체크 및 메시지 처리\n    if (pendingSummary != null &amp;&amp; pendingSummary.getTotalPendingMessages() &gt; 0) {\n        PendingMessages pendingMessages = this.redisOperator.pending(streamKey, consumerGroupName);\n        pendingMessages.toList().stream()\n            .filter(pendingMessage -&gt; !ObjectUtils.isEmpty(pendingMessage))\n            .forEach(pendingMessage -&gt; {\n                List&lt;ObjectRecord&lt;String, String&gt;&gt; messages = this.redisOperator.read(streamKey, consumerGroupName, consumerName, pendingMessage.getIdAsString());\n                messages.stream()\n                    .filter(recordMessage -&gt; !ObjectUtils.isEmpty(recordMessage))\n                    .forEach(recordMessage -&gt; {\n                        // 메시지 처리 로직\n\n                    });\n                // 메시지 ACK\n                this.redisTemplate.opsForStream().acknowledge(streamKey, consumerGroupName, pendingMessage.getIdAsString());\n            });\n    }\n}</code></pre>\n</div>\n<div>&nbsp;</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-42274b60-2da6-44b5-ad35-b53dacb09eb2\" data-compid=\"SE-42274b60-2da6-44b5-ad35-b53dacb09eb2\" data-a11y-title=\"본문\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-42274b60-2da6-44b5-ad35-b53dacb09eb2\" data-direction=\"top\">\n<div>\n<div id=\"SE-c7cb55f7-fe1f-4819-bfc7-802c1132f4ae\">\n<p id=\"SE-693159ae-8306-4082-a9ec-3c18d5f8f95d\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-47cb3487-82b5-4ae5-9341-c0c88e5a4946\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-b83569b2-1c27-42da-8743-44d9dc71ad3f\" data-ke-size=\"size16\">&nbsp;</p>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-10c8da58-aef9-4e4e-96a5-5ff41f728b27\" data-compid=\"SE-10c8da58-aef9-4e4e-96a5-5ff41f728b27\" data-a11y-title=\"소제목\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-10c8da58-aef9-4e4e-96a5-5ff41f728b27\" data-direction=\"top\">\n<div>\n<div id=\"SE-b594a902-f03d-4223-b683-2e9c5487e358\">\n<h2 id=\"SE-71dc92dd-b306-42bd-bbdd-9dc5b4d5ddeb\" style=\"color: #000000;\" data-ke-size=\"size26\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\"><b>마치며</b></span></h2>\n</div>\n</div>\n</div>\n</div>\n</div>\n<p style=\"text-align: justify;\" data-ke-size=\"size16\">&nbsp;</p>\n<div id=\"SE-f2b009b7-1f8d-4ff8-a0e7-505550c6290a\" data-compid=\"SE-f2b009b7-1f8d-4ff8-a0e7-505550c6290a\" data-a11y-title=\"사진\">\n<div data-unitid=\"\" data-compid=\"SE-f2b009b7-1f8d-4ff8-a0e7-505550c6290a\" data-direction=\"top\">\n<div id=\"SE-ca80826c-94e0-4ff5-9146-d700c00e5dbb\">\n<div id=\"SE-f2b009b7-1f8d-4ff8-a0e7-505550c6290a\" data-compid=\"SE-f2b009b7-1f8d-4ff8-a0e7-505550c6290a\" data-a11y-title=\"사진\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-f2b009b7-1f8d-4ff8-a0e7-505550c6290a\" data-direction=\"top\">\n<div>\n<div id=\"SE-f2b009b7-1f8d-4ff8-a0e7-505550c6290a\">\n<div data-unitid=\"SE-f2b009b7-1f8d-4ff8-a0e7-505550c6290a\" data-compid=\"\" data-direction=\"top\"><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"768\" data-origin-height=\"267\"><span data-url=\"https://blog.kakaocdn.net/dn/blcKht/btsIv8t7Obt/B9tykHX6n0BhZ1UzhNlbSK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/blcKht/btsIv8t7Obt/B9tykHX6n0BhZ1UzhNlbSK/img.png\" data-alt=\"Redis Stream 적용 전\"><img src=\"https://blog.kakaocdn.net/dn/blcKht/btsIv8t7Obt/B9tykHX6n0BhZ1UzhNlbSK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FblcKht%2FbtsIv8t7Obt%2FB9tykHX6n0BhZ1UzhNlbSK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"768\" height=\"267\" data-origin-width=\"768\" data-origin-height=\"267\"/></span><figcaption>Redis Stream 적용 전</figcaption>\n</figure>\n</div>\n<div id=\"SE-5a48b168-41af-4e85-a534-1895384ac2c7\" data-compid=\"SE-5a48b168-41af-4e85-a534-1895384ac2c7\" data-a11y-title=\"사진\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-5a48b168-41af-4e85-a534-1895384ac2c7\" data-direction=\"top\">\n<div>\n<div id=\"SE-5a48b168-41af-4e85-a534-1895384ac2c7\">\n<div>&nbsp;</div>\n<div data-unitid=\"SE-5a48b168-41af-4e85-a534-1895384ac2c7\" data-compid=\"\" data-direction=\"top\"><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"765\" data-origin-height=\"268\"><span data-url=\"https://blog.kakaocdn.net/dn/UKiVE/btsIwTCYMz8/zxfAyKBSfE97ad8RswKHSk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/UKiVE/btsIwTCYMz8/zxfAyKBSfE97ad8RswKHSk/img.png\" data-alt=\"Redis Stream 적용 후\"><img src=\"https://blog.kakaocdn.net/dn/UKiVE/btsIwTCYMz8/zxfAyKBSfE97ad8RswKHSk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FUKiVE%2FbtsIwTCYMz8%2FzxfAyKBSfE97ad8RswKHSk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"765\" height=\"268\" data-origin-width=\"765\" data-origin-height=\"268\"/></span><figcaption>Redis Stream 적용 후</figcaption>\n</figure>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-7ee1f2b0-a714-4669-9e65-8b30e4d5826f\" data-compid=\"SE-7ee1f2b0-a714-4669-9e65-8b30e4d5826f\" data-a11y-title=\"본문\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-7ee1f2b0-a714-4669-9e65-8b30e4d5826f\" data-direction=\"top\">\n<div>\n<div id=\"SE-02edf51b-92e7-4e2f-bcb8-c6a57e6e9e2d\">\n<p id=\"SE-bf6bfcd0-4542-4cca-970d-19af03efff87\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">데이터 파이프라인 applicaion에 Redis Stream을 적용 후,</span></p>\n<p id=\"SE-2db906b3-8936-4cbe-a53e-8800aa493289\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">UTS Push 발송 시 지연되던 트래픽 처리가 완전하게 해소되어, BDS 행사기간에도 원활하게 서비스가 가능하게 되었습니다.</span></p>\n<p id=\"SE-6cd6cb97-2cab-4575-8841-e6b0855fee35\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">Redis stream은 분산 처리 환경에서 쉽고 빠르게 실시간 데이터 처리를 가능하게 만들어주는 아주 효율적인 도구입니다.</span></p>\n<p id=\"SE-38a26d28-e877-4047-813d-9546cac74fc1\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">이 포스팅을 통해서 Redis Stream의 개념과 동작 방식에 대해서 간단하게나마 파악하고, 추후 Redis Stream을 이용한 애플리케이션을 구축하는데 작은 도움이 되었으면 하는 바람입니다.</span></p>\n<p id=\"SE-86da73f1-502d-4546-a181-08e1b1fcbe7e\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-a64c4b1e-fe02-424f-a7ee-df4d8150007e\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-c3dc5a9e-a343-44ac-9683-70e65485d380\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-d007608b-6eaf-49e9-993b-dd36f1741769\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-3d107c9b-9460-42e7-8b3e-b431203876e4\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-1d5667f3-9023-4457-aa24-aecad03020d0\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-589e507f-4171-4d24-b177-f44a9b0c8033\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">&lt;참고문서&gt;</span></p>\n<p id=\"SE-e467964e-8d0c-4f7d-ad03-deea9d4649f1\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\" data-href=\"https://nimasrn.medium.com/introduction-to-redis-streams-1d6a95ab141\"><a href=\"https://nimasrn.medium.com/introduction-to-redis-streams-1d6a95ab141\">https://nimasrn.medium.com/introduction-to-redis-streams-1d6a95ab141</a></span></p>\n<p id=\"SE-8c5f199d-1b03-40e3-b2fd-a17fc3134293\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\" data-href=\"https://redis.io/docs/latest/develop/data-types/streams/\"><a href=\"https://redis.io/docs/latest/develop/data-types/streams/\">https://redis.io/docs/latest/develop/data-types/streams/</a></span></p>\n<p id=\"SE-e042d8ec-bd31-4584-9faa-9ccdc721abbb\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\" data-href=\"https://jybaek.tistory.com/935\"><a href=\"https://jybaek.tistory.com/935\">https://jybaek.tistory.com/935</a></span></p>\n</div>\n</div>\n</div>\n</div>\n</div>\n<p style=\"text-align: justify;\" data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "안녕하세요 Data Product 팀 박상우입니다.\n \n이번에 제가 소개해드릴 내용은 팀 내 session Info data 적재 및 API 서비스 구축에 적용한 Redis Stream에 대한 이야기입니다.\n \n저희 팀에서는 User의 행동 정보를 수집하는 프레임워크 중 하나인 montelena receiver를 통해 수집한 데이터 (view, event, impression 등)를 post Processor라는 데이터 파이프라인 application을 통해 적재, 가공해서 각종 지표 트래킹 및 분석에 활용할 수 있도록 제공하고 있습니다.\n \nPost Processor Data Pipeline\n\n\n\n\n \n그중 유니크한 active user를 식별하기 위해 session_id를 발급하고, 그 히스토리를 남겨 광고에 활용하고 있는데,\n'Big Smile Day' (지마켓 최고의 연례행사인 빅스마일데이, 이하 BDS)\n'User Targeting Content' (이하 UTC) Push 발송 등 유저의 유입이 급증해서 트래픽이 대폭 증가할 경우 데이터 처리가 지연되는 현상이 발생하게 되었습니다.\n \n이 문제를 해결하기 위해서는 부하를 발생시키는 로직을 분리해서 별도로 처리하도록 하는 application의 개발이 요구되는 상황이었고,\n이에 Redis stream을 사용해서 session_id 히스토리 적재 로직을 수행하는 신규 consumer를 개발했던 과정을 간단하게나마 공유해보고자 합니다.\n \n \n \nRedis Stream의 특징과 장점\n \n2018년 10월 17일, Redis 5.0 버전이 출시되었습니다.\n \n \n\n\n\n \n \n이전 버전에서 많은 부분이 개선되었지만 그중 가장 중요한 기능 추가 중 하나가 바로 Redis stream 이였는데요.\n고가용성 데이터 스트리밍 처리가 도입되면서, 데이터의 일관성과 안정성을 보장하면서 대용량 데이터 스트림을 실시간으로 처리할 수 있게 되었습니다.\n동시에 inmemory 기반으로 동작하는 key value 기반의 캐시를 사용하기 때문에 속도가 빠르다는 장점으로 사내에서도 저장소로 널리 사용되고 있죠.\n \n \n왜 Redis Stream을 선택했는가?\n \n처음에는 메시지 큐로 kafka나 MQ를 생각했었는데, 새로운 플랫폼을 적용해야 하다 보니 개발 공수도 늘어나고 리소스도 많이 소모될 거라는 결론을 내렸습니다.\n거기다 BSD가 얼마 남지 않은 시점이라 그전에 개발을 완료해야 된다는 시간적인 제한도 허들이었습니다.\n이미 session_id 저장소로 redis를 사용하고 있었고, 최대한 기존 로직을 건드리지 않으면서, 빠르게 히스토리를 적재할 수 있는 방법을 찾던 중,\nkafka와 유사한 기능들을 제공하면서 사내 openshift 환경의 여러 개 pod에서 구동해도 데이터 중복이나 유실 없이 처리가 가능한 Redis stream을 선택하게 되었습니다.\n \n \n \nRedis Pub/Sub과 Redis Stream?\n \n일반적으로 Redis를 이용해 메시지를 Broadcasting 할 때는 pub/sub을 많이 사용합니다.\n하지만 이 방식은 publisher가 메시지를 발행했을 때 subscriber가 존재하지 않거나 애플리케이션에 이슈가 발생하면 수신 여부에 관계없이 메시지가 휘발되는 단점이 있습니다.\n또한, 여러 개의 subscriber를 구동하면 모두에게 동일한 메시지를 발행해 데이터가 중복되는 이슈가 발생합니다.\n \nRedis Pub / Sub\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n반면, Redis Stream은 휘발성이 아니라 Kafka의 offset 개념처럼 마지막으로 수신한 record id를 저장하고 XADD, XREADGROUP, XACK, XPENDING, XCLAIM으로 이어지는 처리 프로세스를 통해 메시지를 컨트롤할 수 있는 다양한 방법을 제공합니다.\n \nRedis Stream\n\n\n\n\n\n\n\n\n\n\n\n\n\n출처 : https://jybaek.tistory.com/935\n \n \n또한, Redis Stream은 consumer group을 지원하기 때문에 producer가 발행한 메시지를 여러 개의 consumer가 하나의 그룹을 형성해서 중복 없이 순차적으로 병렬 처리할 수 있습니다.\n그리고 XACK 명령어를 사용해 메시지 처리 여부를 확인할 수 있으며, 일정 시간 동안 처리되지 못한 메시지들도 Pending Entries List를 이용해서 재처리할 수 있는 방법을 제공합니다.\n \n \n \nRedis Stream\n\n\n\n\n\n\n\n\n\n\n\n\n\n출처 : https://jybaek.tistory.com/935\n \n \nRedis stream Development\n \n이제 실제로 코드를 보며 Redis stream으로 어떻게 개발을 진행했는지 간단히 알아보도록 하겠습니다.\n프로세스는 심플한 구조로 아래 flow chart를 참고해 주시면 되겠습니다.\n \n \n \n \nRedis Stream flow\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n<Publisher>\n먼저 Post Processor에서 트래픽 데이터를 가공/처리한 후, app에서 정의한 streamKey를 통해서 생성한 session 객체를 캡슐화해서 Redis Stream 메시지로 발행합니다.\nObjectRecord<String, String> record = StreamRecords.newRecord()\n\t\t\t\t.ofObject(GsonUtil.gson().toJson(session))\n\t\t\t\t.withStreamKey(streamKey);\n\nRecordId recordId = gmktRedisTemplate.opsForStream().add(record);\nif (Objects.isNull(recordId)) {\n    // Redis Stream record 처리에 실패했을 경우 로직 추가\n}\n \nopsForStream().add() 메서드를 통해서 메시지를 발행하면 recordId를 리턴하는데, 이 값은 각각의 메시지가 스트림에 추가될 때 Redis가 생성해 주는 고유의 id 값으로 보시면 됩니다.\n저는 stream key / value 형태의 ObjectRecord 객체를 사용해서 개발했지만,\n이외에도 value 값으로 Map<K, V> 형태로 데이터를 저장하고 읽을 수 있는 MapRecord라는 메서드도 지원하고 있습니다.\npublic interface MapRecord<S, K, V> extends Record<S, Map<K, V>>, Iterable<Map.Entry<K, V>> {\n\n\tstatic <S, K, V> MapRecord<S, K, V> create(S stream, Map<K, V> map) {\n\n\t\tAssert.notNull(stream, \"Stream must not be null\");\n\t\tAssert.notNull(map, \"Map must not be null\");\n\n\t\treturn new MapBackedRecord<>(stream, RecordId.autoGenerate(), map);\n\t}\n}\n \n \n<Consumer>\n다음은 발행된 메시지를 컨슈밍 하고 처리하는 코드를 보여드리겠습니다.\n먼저 Spring boot 프로젝트에서 'spring-boot-starter-data-redis' 의존성을 추가하고 Redis 서버 설정을 완료합니다.\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-data-redis</artifactId>\n</dependency>\n \n그다음 'StreamListener' 인터페이스를 구현하고, afterPropertiesSet() 메서드를 @Orverride 해서 Redis Stream 메시지를 소비하는 consumer Group과 Listener Container를 설정하고 초기화합니다.\n@Override\npublic void afterPropertiesSet() throws Exception {\n    // Consumer Group 설정\n    createStreamConsumerGroup(streamKey, consumerGroupName);\n\n    // StreamMessageListenerContainer 설정\n    this.listenerContainer = StreamMessageListenerContainer.create(\n\t\t\t\tredisTemplate.getConnectionFactory(),\n\t\t\t\tStreamMessageListenerContainer.StreamMessageListenerContainerOptions.builder()\n\t\t\t\t.targetType(String.class)\n\t\t\t\t.pollTimeout(Duration.ofSeconds(2))\n\t\t\t\t.build()\n\t\t);\n\n    // Subscription 설정\n    this.subscription = this.listenerContainer.receive(\n            Consumer.from(this.consumerGroupName, consumerName),\n            StreamOffset.create(streamKey, ReadOffset.lastConsumed()),\n            this\n    );\n\n    // Redis listen 시작\n    this.listenerContainer.start();\n}\n\npublic void createStreamConsumerGroup(String streamKey, String consumerGroupName){\n\tif (!redisTemplate.hasKey(streamKey)){\n\t\tRedisClusterAsyncCommands commands = (RedisClusterAsyncCommands) this.redisTemplate\n\t\t\t\t.getConnectionFactory()\n\t\t\t\t.getClusterConnection()\n\t\t\t\t.getNativeConnection();\n\t\t\n        CommandArgs<String, String> args = new CommandArgs<>(StringCodec.UTF8)\n\t\t\t\t.add(CommandKeyword.CREATE)\n\t\t\t\t.add(streamKey)\n\t\t\t\t.add(consumerGroupName)\n\t\t\t\t.add(\"0\")\n\t\t\t\t.add(\"MKSTREAM\");\n\n\t\tcommands.dispatch(CommandType.XGROUP, new StatusOutput(StringCodec.UTF8), args);\n\t}\n\telse{\n\t\tif(!isStreamConsumerGroupExist(streamKey, consumerGroupName)){\n\t\t\tthis.redisTemplate.opsForStream().createGroup(streamKey, ReadOffset.from(\"0\"), consumerGroupName);\n\t\t}\n\t}\n}\n \nPublisher에서 설정한 StreamKey와 Consumer Name을 세팅해서 Consumer Group을 생성합니다.\n그리고 Consumer 객체를 생성, Offset 설정, Subscriber 옵션 등 세부적인 설정을 완료한 뒤, Listener Container를 시작하면 Redis Stream 메시지를 비동기적으로 Listner에게 전달하게 됩니다.\n이 과정을 통해서 여러 개의 Consumer Group을 사용해서 하나의 Redis Stream을 병렬로 처리할 수 있습니다.\n \n이렇게 전달되는 메시지들은 마찬가지로 'StreamListener' 인터페이스가 제공하는 onMessage 메서드를 구현해서 처리하게 됩니다.\n@Override\npublic void onMessage(ObjectRecord<String, String> message) {\n    \n    String stream = message.getStream();\n    String recordId = message.getId().getValue();\n    \n    try {\n        // 처리할 로직 구현\n        if (StringUtils.isNotEmpty(message.getValue())) {\n            // To-Do\n        }\n        // 이후, ack stream\n        this.redisTemplate.opsForStream().acknowledge(streamKey, consumerGroupName, recordId);\n        \n    } catch (Exception e) {\n        // TODO: handle exception\n        e.printStackTrace();\n        this.redisOperator.delete(stream, recordId);\n    }\n}\n \n메시지를 처리하고 나면 'ackStream' 메소드를 호출해서 Redis Stream 메시지가 성공적으로 처리되었음을 알리고, 해당 메시지를 대기열에서 제거합니다.\nException 이 발생할 경우 recordId를 통해 메시지를 삭제 처리할 수도 있고, 다양한 시나리오로 처리가 가능하니 용도에 맞게 사용하시면 되겠습니다.\n \n \n \nRedis stream 적용 시 고려할 점들\n \nRedis Stream은 파티션 개념이 없기 때문에 하나의 stream을 여러 개의 consumer가 병렬 처리하는 구조로 동작합니다.\n그래서 Redis cluster 구조에서 sharding 되어 있는 node에 메시지를 고르게 보내려면 추가적으로 N개의 stream을 각각의 node에 할당하도록 추가 개발이 필요합니다.\n이러한 특징 때문에 produce 된 순서대로 메시지를 처리한다는 보장이 없어지는데, 이는 실서비스에 적용할 때 반드시 고려해야 할 점입니다.\nPartition을 지원하는 Kafka cousumer group의 구조\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n단일 Stream Redis stream cousumer group의 구조\n\n\n\n\n\n\n\n\n\n\n\n\n\n출처 : https://mattwestcott.org/blog/redis-streams-vs-kafka\n \n \n그리고 또 한 가지.\nin-memory 기반의 저장소이기 때문에 memory 관리에 신경을 많이 써야 합니다.\n예를 들어, XACK를 받지 못한 pending 메시지를 다시 처리하지 않으면, 그 메시지들은 점점 쌓여가면서 Redis cluster의 memory를 위태롭게 만들 것입니다.\n그래서 저도 1분마다 스케줄을 돌며 pending 메시지를 처리하는 로직을 추가해 memory full 이슈를 방지하고 있습니다.\n@Scheduled(fixedRate = 60000)\npublic void PendingMessagesSummaryScheduler() {\n    PendingMessagesSummary pendingSummary = this.redisOperator.pendingSummary(streamKey, consumerGroupName);\n\n    // 로그 출력\n    pendingSummary.getPendingMessagesPerConsumer().forEach((consumer, count) -> {\n        log.info(\"Consumer: \" + consumer + \", Pending Messages: \" + count);\n    });\n\n    // pendingSummary와 TotalPendingMessages 체크 및 메시지 처리\n    if (pendingSummary != null && pendingSummary.getTotalPendingMessages() > 0) {\n        PendingMessages pendingMessages = this.redisOperator.pending(streamKey, consumerGroupName);\n        pendingMessages.toList().stream()\n            .filter(pendingMessage -> !ObjectUtils.isEmpty(pendingMessage))\n            .forEach(pendingMessage -> {\n                List<ObjectRecord<String, String>> messages = this.redisOperator.read(streamKey, consumerGroupName, consumerName, pendingMessage.getIdAsString());\n                messages.stream()\n                    .filter(recordMessage -> !ObjectUtils.isEmpty(recordMessage))\n                    .forEach(recordMessage -> {\n                        // 메시지 처리 로직\n\n                    });\n                // 메시지 ACK\n                this.redisTemplate.opsForStream().acknowledge(streamKey, consumerGroupName, pendingMessage.getIdAsString());\n            });\n    }\n}\n \n \n \n \n마치며\n \nRedis Stream 적용 전\n\n\n\n\n\n\n\n \nRedis Stream 적용 후\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n데이터 파이프라인 applicaion에 Redis Stream을 적용 후,\nUTS Push 발송 시 지연되던 트래픽 처리가 완전하게 해소되어, BDS 행사기간에도 원활하게 서비스가 가능하게 되었습니다.\nRedis stream은 분산 처리 환경에서 쉽고 빠르게 실시간 데이터 처리를 가능하게 만들어주는 아주 효율적인 도구입니다.\n이 포스팅을 통해서 Redis Stream의 개념과 동작 방식에 대해서 간단하게나마 파악하고, 추후 Redis Stream을 이용한 애플리케이션을 구축하는데 작은 도움이 되었으면 하는 바람입니다.\n \n \n \n \n \n \n<참고문서>\nhttps://nimasrn.medium.com/introduction-to-redis-streams-1d6a95ab141\nhttps://redis.io/docs/latest/develop/data-types/streams/\nhttps://jybaek.tistory.com/935",
        "guid": "https://dev.gmarket.com/113",
        "categories": [
          "Infra"
        ],
        "isoDate": "2024-07-11T06:55:03.000Z"
      }
    ]
  },
  {
    "name": "리멤버 (드라마 앤 컴퍼니)",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Kimchi hill",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Hudi.blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "토스",
    "category": "기업",
    "posts": [
      {
        "title": "2024 하반기 달라지는 정책: 금융·경제·복지 제도 13가지",
        "link": "https://blog.toss.im/article/money-policies-17",
        "pubDate": "Fri, 12 Jul 2024 02:50:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}2024 하반기를 맞아 새롭게 시행되는 금융, 경제, 복지 분야의 다양한 정책들을 정리했습니다. 부모와 청년을 위한 혜택부터 더 안전하고 간편한 금융생활을 위한 정책까지 많은 변화가 기다리고 있어요.\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}부모를 위한 혜택\n1.모든 초등학교에서 늘봄학교를 운영해요\n.css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}2024년 2학기부터 전국 모든 초등학교 약 6,100개에서 1학년을 대상으로 늘봄학교를 확대 운영합니다. 늘봄학교를 이용하는 아이들은 다양한 맞춤형 프로그램을 연간 매일 2시간씩 무료로 제공받게 됩니다.\n2.육아로 근로시간 단축 시, 소득을 더 보전받아요\n육아를 이유로 근로시간을 단축할 경우, 통상임금 100%를 지급하는 기간이 늘어납니다. 7월 1일부터 통상임금 100%(월 상한액 200만 원) 지원범위를 주 최초 5시간에서 주 최초 10시간까지 확대합니다.\n육아기 근로시간 단축을 30일 이상 허용(주당 10시간 이상)하고, 업무분담 근로자를 지정하여 금전적 지원을 한 경우, 정부가 사업주에게 월 최대 20만 원을 지원합니다.\n3.출산과 양육에 어려움을 겪는 임산부를 지원해요\n7월 19일부터 위기임산부는 상담전화(1308)을 통해 경제적 지원, 법률적 지원, 출산 전후 주거·돌봄 및 산후조리 지원 등을 연계 받을 수 있습니다. 또한 신원을 밝히기 어려운 임산부는 의료기관에서 가명으로 진료·출산할 수 있고,  태어난 아동은 출생등록 및 보호조치를 받을 수 있어요.\n청년을 위한 혜택\n4.취업 후 상환 학자금 대출 지원 대상 및 이자 면제 확대\n7월 1일부터 학자금 지원 1~5구간인 기준 중위소득 이하 가구의 대학생*이라면 대출 시점부터 졸업 후 2년 범위 안에서 의무상환 개시 전까지 이자를 면제받을 수 있습니다.\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}*기준 중위소득 100%이하(4인가구 기준 월 572만 9913원)\n상환유예 사유에 재난 피해(재난사태 선포 또는 특별재난지역 거주)를 추가하고, 유예기간 동안 발생한 이자도 면제합니다. 취업 후 상환 등록금대출을 받을 수 있는 대학생 또한 기존 학자금지원 8구간에서 9구간까지 확대되었습니다.\n5.청년 제대군인을 위한 혜택이 늘어요\n만 34세 이하의 제대군인 또는 전역 후 3년 이내의 제대군인이라면 ‘히어로즈 카드'를 이용해 보세요. 학원·도서 구입·어학시험 등 자기 계발비나 교통·통신 등 생활편의에 5~20%의 할인 혜택을 받을 수 있어요. IBK기업은행, KB국민카드, NH농협카드 등 3개 금융사를 통해 7월 16일부터 발급할 수 있습니다.\n여가생활을 위한 혜택\n6. 여권 발급 비용이 저렴해져요\n7월 1일 부터 여권발급비용이 3,000원 저렴해집니다. 유효기간이 10년인 58면짜리 여권은 기존 5만 3,000원에서 5만 원으로, 페이지 수가 적은 26면짜리 여권은 기존 5만 원에서 4만 7,000원으로 발급비용이 줄었어요.\n또한 여권을 재발급 할 때에는 민간 앱을 이용할 수 있어요. 전자여권을 한 번이라도 발급받은 적이 있는 18세 이상 국민은 KB스타뱅킹을 통해 재발급 신청을 하면 돼요.\n7. 해외여행 갈 때 내던 세금이 줄어요\n해외여행 갈 때 내던 출국납부금이 1만 원에서 7,000원으로 인하됐습니다. 출국납부금 면제 기준 연령도 12세 미만 어린이로 확대됩니다.\n더 안전하고 편리한 금융생활을 위해\n8. 보이스피싱 피해, 더 빠르게 구제받을 수 있어요\n8월 말 부터 .css-iynyr0{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);-webkit-text-decoration:underline!important;text-decoration:underline!important;}통장협박 피해자도 피해금 편취 의도가 없음을 소명하는 협박문자와 같은 객관적인 자료를 가지고 금융회사에 이의제기를 신청하면 피해금과 관련이 없는 부분에 대한 신속한 지급정지 해제가 가능하게 됩니다.\n계좌 추적이 어려운 보이스피싱에 대해, 금융회사와 전자금융업자 간 계좌정보 공유를 의무화해 신속한 지급정지 및 피해금 환급이 가능하게 됩니다.\n9. 불법추심 피해 입은 가족·지인도 무료 법률 상담받을 수 있어요\n채무당사자뿐만 아니라 ① 채무자와 동거하거나 생계를 같이 하는 자 ②채무자의 친족 ③채무자가 근무하는 장소에 함께 근무하는 직장동료도 무료로 법률지원을 받을 수 있습니다.\n금융감독원 누리집 불법금융 신고센터 내 ‘채무자대리인 및 소송변호사 무료지원 신청’에서 온라인 신청하거나, 금융감독원 불법사금융신고센터(1332)를 통해 신청할 수 있어요.\n10.주택임대차 신고, 모바일로도 할 수 있어요\n8월부터 계약을 체결한 자리에서 집주인과 세입자가 모바일로 .css-1ly3pih{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey800);background-color:#3fd59936;-webkit-text-decoration:underline!important;text-decoration:underline!important;}주택임대차 신고를 할 수 있습니다. 주민센터에 직접 방문 또는 PC를 통해서만 신고가 가능했지만, 8월부터는 모바일로도 신고가 가능합니다.\n11.오피스텔·빌라도 주택담보대출 갈아탈 수 있어요\n9월부터는 주거용 오피스텔·빌라 담보대출도 주택담보대출 갈아타기 서비스 이용대상에 포함됩니다. 현재는 신용대출, 아파트 주택담보대출, 전세대출만 온라인 대환대출 인프라를 통해 갈아탈 수 있는데요. 9월부터 KB시세 등 실시간 시세 조회가 가능한 빌라(연립·다세대) 및 주거용 오피스텔 담보대출도 갈아탈 수 있게 됩니다.\n12.주민등록증, 휴대폰에 넣고 다녀요\n12월 27일부터 17세 이상 국민 누구나 모바일 주민등록증을 발급받을 수 있습니다. 실물 주민등록증을 들고 다닐 필요 없이 휴대폰에 주민등록증을 저장해 편리하게 사용할 수 있어요. 모바일 주민등록증은 읍·면·동 주민센터를 방문해 본인 확인을 거친 뒤 무료로 발급받을 수 있습니다.\n13.인감증명서, 정부24에서 편하게 발급해요\n그동안 주민센터를 방문해야만 발급받을 수 있던 인감증명서를 9월 30일(예정)부터 정부24에서 무료로 발급받을 수 있습니다.\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 이지영 Graphic 조수희",
        "content": "내 삶에 도움이 되는 혜택을 찾아보세요.",
        "contentSnippet": "내 삶에 도움이 되는 혜택을 찾아보세요.",
        "guid": "https://blog.toss.im/article/money-policies-17",
        "isoDate": "2024-07-12T02:50:00.000Z"
      },
      {
        "title": "자꾸 디폴트옵션 설정하라고 알림이 와요",
        "link": "https://blog.toss.im/article/retirement-plans-04",
        "pubDate": "Fri, 12 Jul 2024 00:14:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-nv7vyi{margin:24px 0 8px;padding:16px 40px 32px;border-radius:16px;background-color:var(--adaptiveGrey100);}.css-123co55{font-size:19px;letter-spacing:0em;line-height:1.6;margin:24px 0 0;font-weight:400;color:var(--adaptiveGrey900);background-color:transparent;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}이 글에서 알 수 있는 것들\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1kxrhf3{white-space:pre-wrap;}DC형 퇴직연금과 IRP 가입자에게 필수 사항인 디폴트옵션의 개념 \n디폴트옵션의 종류와 성향에 따라 잘 고르는 방법\n\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n무심코 선택한 디폴트옵션에서 다섯 배 이상 수익률 차이가 난다고요?!\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n고용노동부가 발표한 2024년도 1분기 퇴직연금 디폴트옵션 주요 현황 공시에 따르면 한국투자증권의 '디폴트옵션고위험BF1'은 1년 수익률이 22.87%로 전 사업자의 전체 상품 수익률 중 1위를 기록했다. 1년에 22%가 넘는 수익률이라니, 디폴트옵션의 취지가 ‘너무 낮은 퇴직연금 수익률 개선하기’였던 점을 생각하면 이런 성과는 그저 놀라울 뿐이다.\n디폴트옵션은 DC형 퇴직연금이나 IRP 계좌를 만들고 나서 첫 번째로 만나는 단계이다. 2023년 7월 이후 둘 중 하나의 계좌라도 가지고 있었다면 디폴트옵션에 대해 들어봤거나 직접 선택한 경험이 있을 것이다. 만약 당신이 이제 막 취업에 성공한 사회초년생이라면 가입 과정에서 디폴트옵션에 가입해야 한다는 설명을 들었을 수도 있다.\n그럼에도 많은 사람들은 이렇게 생각한다. .css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}‘대체 디폴트옵션이 뭐야? 퇴직연금도 아직 잘 이해하지 못했는데 왜 자꾸 디폴트옵션을 선택하라고 하는 거지?’ 그러고는 설명을 읽어봐도 뭐가 뭔지 잘 모르겠어서 대충 원리금이 보장된다는 저위험 상품을 골라두기도 한다. 하지만 디폴트옵션을 어떻게 선택하느냐에 따라 원리금 보장형이 예금을 통해 연 3~4% 수익률을 내는 동안 22%가 넘는 수익률을 올리는 상품도 있다. 무조건 고위험을 고르자는 뜻은 아니다. 이제부터 잘 이해하고 골라야겠다는 마음, 그 마음의 준비가 필요하다.\n1. 이게 다 우리를 위해 만들어졌다니까요? 디폴트옵션의 탄생\n‘디폴트옵션(default option, 사전지정운용제도)’은 쉽게 말하면 퇴직연금 계좌에 들어있는 돈을 가입자가 사전에 정한 방법으로 돈을 운용하는 제도이다. 퇴직연금에 넣은 돈은 활발히 투자해 노후 연금 형태로 쓸 수 있도록 불려야 하는데, 가입자가 주기적으로 돈을 어떻게 운용할지 지시하지 않는 경우가 많다. 그러면 결국 가입자의 손해로 이어지므로, 퇴직연금이 투자한 상품이 만기가 됐는데도 일정 기간 가입자가 별도의 운용 지시를 하지 않으면 사전에 지정해둔 방법으로 운용해주는 것이다.\n퇴직연금 운용에 대한 경험이 풍부한 미국, 영국, 호주 등 연금 선진국에서는 가입자가 적절한 시기에 적절한 선택을 하도록 유도하여 노후 소득 보장을 강화하도록 돕는 것이 정부의 사회적 책무라는 인식이 퍼져 있다. 그래서 이미 오래전부터 이 디폴트옵션을 도입하고 운영해 왔으며, 연평균 6%에서 8%대의 안정적인 수익률 성과를 내고 있다.\n국내에서 디폴트옵션은 2022년 7월 도입되었고, 1년간의 사전 준비 등 유예기간을 거쳐 2023년 7월 12일부터 본격적으로 시행되었다. 시행 목적은 물론 매우 저조한 수익률을 거두고 있는 퇴직연금 적립금을 활용해 운용 성과를 높이기 위한 것이다. 2021년 기준 5년간 퇴직연금 수익률은 2.4%에 불과했고 직전 해까지 기준으로는 1%대였다. 적극적으로 투자하지 않고 원리금 보장형으로 운용되거나 아예 현금 그대로 방치하는 경우도 많았기 때문이다. 연 1~2%의 수익률은 물가상승률도 따라가지 못하는 숫자인데, 그렇다는 건 돈을 그대로 방치하는 바람에 실질적으로는 마이너스 수익률을 거두는 것이다. 이렇게 노후를 위해 마련하는 퇴직연금을 몇십 년 방치하면 어떤 일이 벌어질까? 안타깝게도 빈곤한 연금 잔액이 기다리게 된다. 그래서 잠자고 있는 퇴직연금을 투자하게 만드는 데에 국가가 발벗고 나선 것이다.\n2. 누가 디폴트옵션을 지정해야 할까?\n개인이 운용 책임을 지는  DC형 퇴직연금과 IRP 계좌를 가진 사람들에게는 모두 해당한다. 만약 디폴트옵션을 끝내 지정하지 않으면 퇴직연금 운용 수익이 발생하지 않을 수 있다는 점을 꼭 기억하자.\nDB형 퇴직연금은 회사가 운용 책임을 가지기 때문에 DB형 가입자들은 디폴트옵션을 직접 선택하지 않는다.\n3. 지정해두면 언제 디폴트옵션으로 운용될까?\n디폴트옵션은 가입자가 퇴직연금 계좌에 있는 적립금을 일정기간 동안 어떻게 운용할지 지시하지 않을 때 작동한다. 이 시기에는 2가지 경우가 해당한다. 첫째, DC형 퇴직연금이나 IRP에 가입 후 적립금이 이체되고 나서 2주 동안 운용 지시를 내리지 않으면 디폴트옵션이 작동한다.\n둘째, 적립금이 들어가 있던 금융상품이 만기 되고 4주가 지났는데도 운용 지시를 별도로 하지 않으면 퇴직연금사업자로부터 2주 안에 운용 지시를 해야 한다는 안내를 받게 된다. 이때도 운용 지시를 하지 않아 총 6주 동안 방치하면 디폴트옵션으로 운용된다. 디폴트옵션 미지정 시 기존 상품의 만기가 도래했는데 가입자가 별도로 운용 지시를 하지 않으면 현금성 자산으로 남아 낮은 금리로 운용된다.\n4. 디폴트옵션에는 어떤 상품이 있을까?\n디폴트옵션을 설정하러 들어가면 보통 네 가지 중에 고르라는 문항을 만나게 된다. 바로 초저위험, 저위험, 중위험, 고위험이다. 초저위험은 말 그대로 위험이 매우 낮아 원리금을 잃을 가능성이 없는 원리금 보장형 상품으로 구성된다. 따라서 은행의 예금, 보험사의 GIC(이율보증형 보험계약)* 등이 주를 이룬다. 최근 1~2년 동안 금리 상승 효과로 초저위험 디폴트옵션의 수익률이 3% 이상으로 올라가면서 주목을 받기도 했다.\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}*은행의 정기예금과 유사한 금융상품으로 보험사가 판매하는 원리금보장 보험계약(특별계정, 예금자보호 대상)이다.\n저위험부터는 원리금 보장형인 정기예금부터 투자 성향이 들어가는 TDF, BF펀드까지 상품군이 다양해진다. 물론 저위험의 성향에 맞게 원리금 보장형의 배분이 더 높고 투자형 상품의 배분은 더 낮은 편이다. 중위험으로 갈수록 투자형 상품의 배분이 더 높아진다. 그렇다면 디폴트옵션에 많이 포함되어 있는 TDF나 BF펀드는 무엇일까?\n먼저 TDF는 타깃 데이트 펀드(Target Date Fund)의 줄임말로 은퇴 시점을 기준으로 운용되는 은퇴 상품이다. TDF는 투자자의 은퇴 시점에 맞춰 은퇴까지 많은 시간이 남아 있을 때는 주식 비중이 높고 은퇴에 가까워질수록 안전자산인 채권의 비중이 높아지도록 배분을 조정한다. 즉 은퇴 시점에 맞춰 펀드 안에 있는 자산의 편입 비중을 자동으로 조정해준다는 특징이 있다.\n만약 디폴트옵션에서 TDF를 선택하고 싶다면 목표 시점을 확인해야 한다. TDF 상품 이름에 들어간 네 자리 숫자가 목표 시점을 나타낸다. 2030, 2040 등이 붙은 상품 이름은 해당 시점 무렵에 은퇴할 예정인 투자자를 위한 상품이다. 네 자리 숫자를 빈티지(vintage)라고 부른다.\n디폴트옵션 안에는 BF펀드(Balance Fund, 밸런스펀드)도 들어 있다. 이는 투자위험이 다른 다양한 자산에 분산투자하고, 금융시장 상황과 가치 변동 등에 맞춰 주기적으로 자산 비중을 조절하는 펀드다. TDF와 BF펀드는 모두 주식과 채권 등 다양한 자산에 분산 투자하는 자산배분펀드라는 점에서는 같지만, BF펀드는 자산배분 비중이 일정하게 유지된다. 시간의 흐름에 따라 주식과 채권의 비중이 달라지는 TDF와 가장 큰 차이점이라고 할 수 있다. 따라서 현재 주식과 같은 위험자산에 최대 얼마나 투자할지 등을 체크해야 한다. 만약 위험비중을 조정하고 싶다면 투자자가 직접 상품을 변경하는 등의 개입이 있어야 한다.\n5. 그럼 나는 어디에 투자하는 게 좋을까?\n실제로 승인받은 퇴직연금사업자가 지금까지 300개가 넘는 디폴트옵션 상품을 내놓았다. 그렇다면 어떤 기준을 가지고 선택해야 할까? 이 역시 투자자의 위험 감수 성향과 은퇴까지 남은 시간 등을 고려해야 한다. 우선 네 가지 분류에 대해서는 아래의 질문을 따라가면서 나에게 맞는 카테고리를 골라보자.\n우선 가장 첫 번째 기준은 내가 받고 싶은 수익률이다. 만약 정기예금 금리 수준의 수익에 만족하며 원금 손실을 원하지 않는다면 초저위험을 선택하면 된다. 정기예금 금리보다는 높은 수준을 원한다면 다음 질문을 살펴보자. 원금 손실을 최소화하고 싶다면 저위험으로, 정기예금보다 높은 수익을 추구하며 그에 따르는 위험성을 충분히 알고 있다면 다음 단계로 넘어갈 수 있다. 마지막 질문은 어느 정도의 위험을 감당할 수 있는가에 달려 있다. 너무 높은 위험을 피하고 싶다면 중위험으로, 위험을 감수하더라도 높은 수익을 추구한다면 고위험으로 선택할 수 있다.\n\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n\n그런데 2024년 2월에 금융감독원이 발표한 자료에 따르면 디폴트옵션 전체 적립금 가운데 84%가 은행권에 몰려 있다. 적립금 상위 10개 기관을 살펴보면 상위 5위까지를 모두 은행이 차지하고 있다는 것을 알 수 있다. 근로복지공단과 미래에셋증권을 제외하면 8개가 모두 은행권이다.\n\n\n\n또한 최근 5월에 발표된 금융감독원 자료를 살펴보면 얼마나 많은 비중이 원리금 보장형으로 몰려 있는지도 알 수 있다. 은행의 적립금 비중을 살펴보면 원리금 보장형 90.1%, 실적배당형 9.9%이다. 90%가 원리금 보장형으로 운용되고 있음을 알 수 있다.\n\n\n\n운용 성과를 높이기 위해 도입한 디폴트옵션의 취지에 무색하게 대다수가 원리금 보장형을 선택하는 상황이다. 1년 22%의 수익률을 기록한 디폴트옵션 상품도 있으나 실제로 80%가 넘는 적립금이 초저위험으로 몰려 있는 것을 보면 가입자들의 이해도나 기대치와 디폴트옵션의 취지 사이에는 갭이 있다는 것을 알 수 있다. 아직도 퇴직연금이 가야 할 길은 멀다.\n6. 분기별로 수익률을 체크하자\n300개가 넘는 디폴트옵션 상품은 그 숫자만큼 다양한 수익률을 보여준다. 따라서 정확하게 수익률을 확인하는 일도 중요하다. 금융감독원이 2023년 7월에 발표한 보도자료를 보면 실적배당형의 수익률은 13.25%이고, 원리금 보장형은 4.08%으로 세 배 이상의 수익률 차이를 보인다. 그렇기 때문에 직접 내 적립금이 들어가 있는 상품의 수익률과 다른 선택지들의 수익률을 비교해보거나, 글라이드 등 수많은 상품별 수익률 정보를 리포트해주는 곳을 활용해 주기적으로 수익률을 체크하고 다시 지정할 필요가 있다.\n7. 상품 만기가 끝났다면 언제든 운용 지시도 가능! 옵트인과 옵트아웃을 적극적으로 활용하자\n가입자가 디폴트옵션이 발동하기 전에 적극적으로 디폴트옵션 상품으로 적립금을 운용하고 싶다면 대기 기간 없이 상품을 선택할 수 있다. 이를 옵트인(opt-in, 직접 운용)이라고 한다. 퇴직연금사업자가 제공하는 디폴트옵션 상품으로 퇴직연금 계좌의 돈을 직접 운용할 수 있다는 뜻이다. 동일한 유형의 일반 퇴직연금 상품과 비교했을 때 디폴트옵션 상품은 금리가 조금 더 높거나 수수료가 조금 더 싼 편이다. 따라서 이를 적극적으로 이용한다면 수익률에 도움을 받을 수 있다. 다만 옵트인으로는 디폴트옵션 상품 하나만 가입이 가능하다는 점을 잊지 말아야 한다.\n또 반대로 디폴트옵션이 적용된 뒤에도 가입자가 희망하면 언제든지 다른 금융 상품으로 갈아탈 수 있다. 이것을 옵트아웃(opt-out)이라고 부른다.\n지금까지 글을 따라오면서 자신이 어떤 디폴트옵션을 선택했는지 기억났는가? 만약 제대로 따져보고 고르지 않았다면, 어떤 상품을 골랐는지조차 잘 기억나지 않을 수 있다. 그렇다면 지금까지 정리한 정보를 통해서 다시 한 번 골라보면 어떨까?\n가입자는 퇴직연금사업자(은행, 보험, 증권사)가 제시하는 디폴트옵션 상품 가운데 하나만을 선택할 수 있다. 만약 이미 퇴직연금 적립금을 디폴트옵션 상품에 투자하고 있다면 다른 디폴트옵션 상품에 적립금을 투자할 수는 없다. 하지만 다른 상품으로 갈아타기를 희망해 다시 지정하면 기존에 운용하고 있는 디폴트옵션 상품은 그대로 유지되고, 이후에 새롭게 납부된 금액부터 새롭게 지정한 디폴트옵션 상품으로 운용된다.\n만약 이 개념이 헷갈린다면 직접 고르고 변경해보면서 알아가도 좋다. 중요한 점은 한번 골랐다고 그대로 방치하지 말아야 한다는 사실이다. 분기별 수익률도 점검해보고, 위험을 감수하더라도 조금 더 나은 수익률을 얻고 싶다면 다시 한번 비교하고 고르는 수고로움도 반드시 감수해야 한다. 이번 글을 읽은 투자자들은 반드시 자신이 가입한 디폴트옵션 상품이 무엇인지, 수익률을 얼마나 되는지 꼭 점검하길 바란다.\n다음 편에서는 사람들이 가장 쉽게 접근할 수 있는 은퇴상품 TDF를 어떻게 고르고 포트폴리오를 구성해야 하는지 실제 투자 노하우를 알아보자.\n*디폴트옵션 상품 구성에 대한 더 자세한 정보는 .css-iynyr0{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);-webkit-text-decoration:underline!important;text-decoration:underline!important;}글라이드의 포스트 혹은 카카오톡 채널을 통해 확인하실 수 있습니다.\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 주소은, 김현미(아이랩)\nGraphic 조수희, 이서영",
        "content": "디폴트옵션(사전지정운용제도)의 모든 것",
        "contentSnippet": "디폴트옵션(사전지정운용제도)의 모든 것",
        "guid": "https://blog.toss.im/article/retirement-plans-04",
        "isoDate": "2024-07-12T00:14:00.000Z"
      },
      {
        "title": "킹달러 현상 지속, 지금은 여러가지 이유가 복잡하게 얽혀있어요",
        "link": "https://blog.toss.im/article/economic-terms-21-kingdollar",
        "pubDate": "Thu, 11 Jul 2024 02:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-8atqhb{width:100%;}.css-1c1qox8{font-size:30px;letter-spacing:0em;line-height:1.55;font-weight:bold;color:var(--adaptiveGrey900);margin:40px 0 4px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-p4abj2{display:contents;line-height:1.55;}.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}🔖 이번 주 경제 용어\n킹달러\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}이번 주 경제 용어는 글로벌 경제를 파악하기 위해 필요한 정보예요.\n\n.css-1pgssrp{max-width:100%;border-radius:16px;}\n달러가 강세인 상황으로, 달러의 힘이 세지는 것을 말해요.\n\n\n올해 들어 달러화 가치가 상승하면서 원·달러 환율이 고공행진 중입니다. 지난 4월 원·달러 환율이 1,400원에 육박할 정도로 가파르게 상승한 뒤, 외환 당국의 시장 개입으로 1,300원대 중후반대로 내려오면서 안정을 찾는 듯 싶었는데요. 최근 달러 값이 다시 상승하면서 현재(2024.7.11.기준)는 1달러를 구매하기 위해 약 1,390원이 필요한 상황입니다.\n.css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}원·달러 환율이 1,350원을 넘는 것은 경제적으로 위험한 수준으로 여겨집니다. 1997년 아시아 금융 위기, 2008년 글로벌 금융 위기 때 원화가 크게 평가절하되면서 원·달러 환율이 급등한 적이 있기 때문인데요. 당시 환율 수준이 1,300원~1,400원 사이였고 특히 2008년 금융 위기 때엔 1,400원 대까지 폭등했습니다. 이 때의 경험으로 1,350원이 넘으면 경제적으로 위험한 수준이라 인지하게 되는 것이죠.\n원·달러 환율이 1,400원에 육박하다 조금 잠잠해지나 싶었는데, 다시 두 달 만에 1,400원을 위협하는 수준까지 상승했습니다. 이는 수출입 뿐만 아니라, 소비·투자·여행 등 다방면에 상당히 큰 영향을 미칠 수 있는 상황이에요.\n대체 왜 달러가 오르는 걸까요?\n4월에 달러가 강세였던 이유는 미국 연방준비제도(연준, Fed)의 기준금리 인하 시점이 늦어질 수도 있다는 전망 때문이었습니다. 생각보다 미국의 물가가 끈적거리며 3% 대에 달라붙어 내려오지 않았고, 고용 시장도 활발해지고 뜨거워졌기 때문에 연준의 금리 인하 시점은 9월 이후로 늦춰질 가능성이 높아졌습니다.\n심지어 일부 분석에서는 연준이 올해 추가 인상 없이 금리를 유지할 수 있다는 전망도 제시되고 있습니다. 기준금리가 내려가야 시중에 통화가 풀리면서 통화 가치가 하락할 수 있는데요. 이 기대감이 하락하며 당시 달러 가치가 상승했습니다.\n그런데, 지금 원·달러 환율이 오르는 이유는 4월보다 좀 더 복잡합니다. 여러 나라가 각자의 이유로 금리를 관리하고 있는데 달러 가치가 오를 수 밖에 없는 상황으로 가고 있어요.\n1. 주요국 중앙은행의 기준금리 인하\n최근 캐나다·유럽연합(EU)·스위스·스웨덴 중앙은행이 미국보다 먼저 기준금리를 인하했습니다. 이는 자국 경기가 침체될 우려에 대응하기 위한 조치였는데요.\n통화 가치 하락은 각오해야 했습니다. 주요 6개 통화(유로, 일본 엔, 영국 파운드, 캐나다 달러, 스웨덴 크로나, 스위스 프랑)에 대한 달러화 가치를 반영하는 달러 인덱스 값은 상승해서 105*를 넘겼어요.\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}* 통상적으로 달러 인덱스 값이 100을 초과하면 강달러, 100보다 낮으면 약달러라고 부릅니다.\n2. 일본 엔화 약세 가속\n일본은 지난 3월, 17년 만에 첫 금리 인상을 단행했습니다. 하지만 .css-iynyr0{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);-webkit-text-decoration:underline!important;text-decoration:underline!important;}엔화 약세는 지속되고 있는데요. 일본 은행이 미국 연준(Fed)의 기준금리 인하 소식만 기다리며, 적극적으로 금리 추가 인상을 하지 않고 있기 때문입니다.\n국가 부채가 많은 일본의 경우 금리가 오르면 이자가 늘어나기 때문에 부담이 커요. 금리를 올리는 데에 한계가 있습니다. 그렇다고 일본이 보유하고 있는 미국 국채를 팔면? 다시 채권 금리가 올라 달러 강세가 심화될 수 있다는 우려가 있어요. 이러지도 저러지도 못하고 있는 실정이죠. 이에 따라 당분간 엔저 현상이 쉽게 해소되지 않을 것이라는 전망이 높습니다.\n3. 동아시아 지정학적 불안\n달러·위안화 환율은 지난 해부터 중국 당국이 심리적 마지노선으로 여기는 '달러당 7위안'을 넘긴 상태입니다. 중국의 위안화 환율이 달러당 7위안 이상으로 오르는 것을 포치(破七) 상태라 하는데요. 한동안 포치 상태로 머무를 가능성이 높아보입니다. 중국 경기가 살아나지 못한다면 위안화 가치 회복이 어려울 것으로 예상되기 때문이에요.\n그리고 러시아는 아직 우크라이나와 전쟁 중이고, 러시아 푸틴 대통령은 북한을 방문하기도 했기에 국제 정세에 긴장감이 더해지고 있습니다.\n\n\n.css-2yhypk{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);font-style:italic;-webkit-text-decoration:underline!important;text-decoration:underline!important;}7월도 킹달러 여진 지속…고환율 수혜주 담아라\n(이데일리 2024.7.2)\n화장품과 반도체 관련주가 강세를 보인 것은 고환율 기조 전망 속 수출 확대에 따른 수혜가 예상되기 때문으로 풀이된다. 고환율 국면에서 수출 비중이 높은 업체의 경우 달러 강세에 따른 매출 증가와 환차익을 누릴 수 있는데, 최근 환율이 상승 기조를 보이면서 수출주에 대한 매수세가 확대했다는 판단이다.\n서울외국환중개에 따르면 이날 오후 3시30분 기준 원·달러 환율은 전 거래일 대비 2.6원 오른 1379.3원을 기록했다. 이는 지난달 중순 1370원 초반대 수준을 기록한 것과 비교하면 점진적으로 상승하는 흐름이다.\n증권가에선 고환율 기조가 이달에도 지속할 가능성이 크다고 점친다. 엔화와 유로화 약세가 당분간 이어지며 달러 강세를 지속 부추길 것이란 이유에서다. 엔화 약세는 일본은행(BOJ)의 추가 긴축 조치가 지연되고 있는 데다, 기시다 후미오 총리의 퇴진 위기가 가시화한 게 주요한 영향을 미치고 있다는 분석이다.\n유럽에선 기대를 밑도는 경기 회복 흐름과 조기 초선을 치르는 프랑스와 영국에서 극우 세력 돌풍에 따른 정치 불안 우려가 유로화 약세의 동인이 되고 있다. 박상현 하이투자증권 연구원은 “엔화와 유로화의 추가 약세 시 원·달러 환율의 1400원대 진입을 배제할 수 없으며, 일시적으로 금융시장 변동성이 확대될 것”이라고 전망했다. (중략)\n\n\n달러와 원화의 관계를 간략히 정리하면 아래와 같습니다.\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n달러 강세 = 원화 약세 = 원·달러 환율 상승\n달러 약세 = 원화 강세 = 원·달러 환율 하락\n\n원·달러 환율이 1,250원에서 1,400원으로 상승했다는 것은 1달러를 구매하는 데 더 많은 한국 원화가 필요하게 되었음을 의미합니다. 이전에는 1달러를 1,250원에 구매할 수 있었지만 지금은 1,400원을 지불해야 하는 거죠. 반대로 미국에서 1달러를 벌어와서 국내에서 환전했을 때, 예전에는 1,250원만 받았지만 지금은 1,400원을 받게 됩니다.\n즉, 환율 상승은 수출 기업에는 유리할 수 있지만 수입 기업에는 불리하며 물가 상승을 불러올 수 있어요.\n환율 상승은 외국인 투자자들의 국내 투자 감소로 이어질 가능성이 높습니다. 외국인 투자자들은 국내 투자로 얻는 수익이 원화로 지급되는데, 환율이 상승하면 외화로 환전했을 때 받는 금액이 줄어들기 때문에 투자를 회수할 우려가 높아요.\n그나마 수출 중심 기업은 달러를 벌어와서 높은 가격으로 환전할 수 있으니까 실적이 좋아질 수 있는데요. 이런 주식에는 외국인 투자자도 투자를 할 수 있습니다.\n기사 내용처럼 최근 화장품과 반도체 관련 주식이 강세를 보이는 이유는 고환율 기조 전망 속에서 수출이 늘어나면 그에 따른 수혜가 예상되기 때문이에요. 고환율은 수출 중심 기업의 경쟁력을 높여주고, 환차익도 얻을 수 있으니까요.\n그러니까 당분간 달러가 대세 상승기에 접어든다면 화장품, K-식품, 반도체, 자동차 같은 수출 중심 기업의 주식에 관심을 가지는 것도 좋겠습니다.\n\n\n환율 방어: 외환시장에서 급격한 변동으로 인해 자국 통화 가치가 하락하는 것을 막기 위해 중앙은행이나 정부가 시장에 개입하여 인위적으로 환율을 안정시키는 것. 구두 개입은 말로 외환 시장 불안이 지속되면 조치를 취하겠다고 경고를 주는 것이고, 직접 개입은 외환당국이 외환 시장에서 달러를 팔거나 사들이는 것이에요. 사실 외환시장에 직접 개입하는 건 환율조작국으로 지정될 수 있기 때문에 공식적으로 발표하지 않습니다.\n통화 스와프(Swap): 두 국가가 서로 다른 통화를 교환하고, 일정 기간 후에 다시 원래의 통화로 교환하는 거래. 외환시장의 안정성을 유지하고, 국제무역의 원활한 거래를 지원하는 것이 목적이에요.\n외환당국: 외환시장의 안정을 유지하기 위한 역할을 하는 기관. 우리나라에선 기획재정부와 한국은행이 그 역할을 해요.\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 금혜원 Graphic 조수희 이동건",
        "content": "올해 들어 원·달러 환율이 고공행진 중입니다. 킹달러 현상이 지속되는 이유, 자세히 알아볼게요.",
        "contentSnippet": "올해 들어 원·달러 환율이 고공행진 중입니다. 킹달러 현상이 지속되는 이유, 자세히 알아볼게요.",
        "guid": "https://blog.toss.im/article/economic-terms-21-kingdollar",
        "isoDate": "2024-07-11T02:00:00.000Z"
      },
      {
        "title": "토스, CU멤버십 연동 고객 110만 명 돌파",
        "link": "https://blog.toss.im/article/toss-cu-membership",
        "pubDate": "Wed, 10 Jul 2024 04:52:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}‘내 멤버십 모아보기’에서 CU멤버십 포인트 적립 내역 확인 가능\n사후 적립 기능도 구현... 론칭 한 달 만에 80만 건 적립\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n토스 앱 내 ‘내 멤버십 모아보기’ 서비스에 ‘CU멤버십’을 연동한 고객이 110만 명을 돌파했다.\n내 멤버십 모아보기는 토스 앱으로 다양한 멤버십 포인트를 확인할 수 있는 서비스다. 현재 CU멤버십을 포함, 총 7개의 멤버십 포인트 조회가 가능하다. 멤버십별로 결제일과 결제처, 그에 따른 포인트 적립 내역을 확인할 수 있는 것이 특징이다.\n토스는 CU멤버십에 한하여 사후 적립 기능도 추가로 구현했다. 해당 기능을 통해 CU 편의점에서 결제 시 포인트를 적립하지 않았더라도, 나중에 토스 앱을 통해 적립이 가능해졌다. 현재 토스에 CU멤버십을 연동한 고객 수는 110만 명을 돌파했다.\n사후 적립 기능을 사용하기 위해서는 내 멤버십 모아보기 메뉴에 CU멤버십 연결이 필요하다. 결제 시 CU멤버십 회원이 아니었더라도 이후 CU멤버십 가입 후 연동을 진행하면 포인트 적립이 가능하다. 적립 대상 내역은 토스 앱 내 '내 소비' 내역(계좌 및 유스카드 결제 제외)을 기준으로 한다. 총 14일 전부터 1일 전까지의 결제 내역에 대해 적립 가능한 CU포인트가 있는 경우, [내 멤버십 모아보기 - CU - 받을 포인트]에서 확인할 수 있다.\n토스 관계자는 “CU포인트 사후 적립 기능은 빠르고 간편한 결제 경험을 위해 결제 시 멤버십 적립 과정을 생략할 수 있도록 설계한 것”이라며 “해당 기능 론칭 한 달여 만에 사후 적립 건수는 80만 건을 돌파할 정도로 긍정적인 반응이 이어지고 있다”라고 전했다.",
        "content": "사후 적립 기능 구현 한 달 만에 적립 건수는 80만 건을 넘었어요.",
        "contentSnippet": "사후 적립 기능 구현 한 달 만에 적립 건수는 80만 건을 넘었어요.",
        "guid": "https://blog.toss.im/article/toss-cu-membership",
        "isoDate": "2024-07-10T04:52:00.000Z"
      }
    ]
  },
  {
    "name": "모나미",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김진홍",
    "category": "개인",
    "posts": []
  }
]