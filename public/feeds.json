[
  {
    "name": "ㅍㅍㅅㅅ",
    "category": "큐레이팅",
    "posts": []
  },
  {
    "name": "C++ Team Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Augustin Popa",
        "title": "Siemens Healthineers manages C++ libraries with vcpkg in an offline build environment",
        "link": "https://devblogs.microsoft.com/cppblog/siemens-healthineers-manages-c-libraries-with-vcpkg-in-an-offline-build-environment/",
        "pubDate": "Tue, 12 Nov 2024 23:10:37 +0000",
        "content:encodedSnippet": "vcpkg is a free and open-source C/C++ package manager maintained by Microsoft and the C++ community that runs on Windows, macOS, and Linux. Over the years we have heard from companies using vcpkg to manage dependencies at enterprise-scale. For this blog post, I spoke to Shrey Chauhan, a Senior DevOps Engineer with Siemens Healthineers.\nSiemens Healthineers adopted vcpkg in late 2023 after a successful proof of concept. Their main motivation was to improve their versioning and overall dependency management for C++ libraries in their offline, air-gapped build environment. They also like vcpkg’s integration with the Visual Studio IDE, extensive and evolving library support, and automatic dependency resolution.\nAbout Siemens Healthineers and development team\nShrey: The Ultrasound business area is an integral part of Siemens Healthineers. This advanced medical device features a comprehensive hardware layer and a full-stack windows-based software layer. Ultrasound Software teams handle the development of the entire software stack, while the DevOps team manages CI/CD processes, including building, packaging, deployment, and related tools.\nC++ development environment\nSiemens Healthineers develops on Windows and targets Windows x64. They use Visual Studio 2022 with MSBuild projects, and their project is a combination of C#, C++/CLI, and C++. They have around 300 developers maintaining over 6 million lines of code. In addition, they use Azure DevOps as their continuous integration system.\nHow they were managing C++ dependencies before vcpkg\nTheir team mostly consumes open-source dependencies. They were previously packaging the C++ dependencies in individual .zip packages, which were being downloaded from a JFrog Artifactory repository. This is a tedious process because the path to each .dll or .lib needs to be correct and could vary based on the package.\nQ: When did your team move to vcpkg and why did you ultimately choose to move to vcpkg?\nShrey: We moved to vcpkg around September or October 2023 with the main reasoning being improved versioning and dependency management of C++ libraries. We did a proof of concept to determine if it suited our needs with respect to our air-gapped build environment, which was successful after a little help from vcpkg team. Additional features we benefitted from:\nvcpkg is well integrated with Visual Studio IDE\nHas extensive library support, which is still evolving\nAutomatic dependency resolution\nIn Siemens Ultrasound, our builds/CI are on a protected network with restricted access to the Internet. By default, vcpkg downloads packages from source repositories (Internet) which did not work for us because of access restrictions. We were able to work with the vcpkg team to integrate custom Asset Caching (which was later documented under: How to create a x-script Asset Caching source for NuGet | Microsoft Learn) to use our own Azure DevOps NuGet feed as a source to upload & restore packages. This addressed our issue with the air-gapped environment and allowed us to reuse existing cached packages, making the process more efficient.\nQ: What is your overall impression of vcpkg?\nShrey: Overall, the feedback has been good so far. vcpkg does a great job of caching the built libraries, making the developers’ workflow efficient. It has also been easily accepted by developers because of its ease of use (i.e. no extra steps or setup was required).\nLearn More About vcpkg\nIf you want to learn more about vcpkg, check out our website at vcpkg.io and read the vcpkg overview in our documentation.\nIf you have a story you would like to share with us about your experiences with vcpkg, feel free to contact us at vcpkg@microsoft.com. You can submit bug reports in our GitHub issue tracker or make feature requests in our discussion forum.\nThe post Siemens Healthineers manages C++ libraries with vcpkg in an offline build environment appeared first on C++ Team Blog.",
        "dc:creator": "Augustin Popa",
        "comments": "https://devblogs.microsoft.com/cppblog/siemens-healthineers-manages-c-libraries-with-vcpkg-in-an-offline-build-environment/#respond",
        "content": "<p>vcpkg is a free and open-source C/C++ package manager maintained by Microsoft and the C++ community that runs on Windows, macOS, and Linux. Over the years we have heard from companies using vcpkg to manage dependencies at enterprise-scale. For this blog post, I spoke to Shrey Chauhan, a Senior DevOps Engineer with Siemens Healthineers. Siemens [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/cppblog/siemens-healthineers-manages-c-libraries-with-vcpkg-in-an-offline-build-environment/\">Siemens Healthineers manages C++ libraries with vcpkg in an offline build environment</a> appeared first on <a href=\"https://devblogs.microsoft.com/cppblog\">C++ Team Blog</a>.</p>\n",
        "contentSnippet": "vcpkg is a free and open-source C/C++ package manager maintained by Microsoft and the C++ community that runs on Windows, macOS, and Linux. Over the years we have heard from companies using vcpkg to manage dependencies at enterprise-scale. For this blog post, I spoke to Shrey Chauhan, a Senior DevOps Engineer with Siemens Healthineers. Siemens […]\nThe post Siemens Healthineers manages C++ libraries with vcpkg in an offline build environment appeared first on C++ Team Blog.",
        "guid": "https://devblogs.microsoft.com/cppblog/?p=34928",
        "categories": [
          "C++",
          "Vcpkg",
          "CPP",
          "vcpkg"
        ],
        "isoDate": "2024-11-12T23:10:37.000Z"
      },
      {
        "creator": "Sy Brand",
        "title": "What’s New for C++ Developers in Visual Studio 2022 17.12",
        "link": "https://devblogs.microsoft.com/cppblog/whats-new-for-c-developers-in-visual-studio-2022-17-12/",
        "pubDate": "Tue, 12 Nov 2024 20:58:48 +0000",
        "content:encodedSnippet": "We are happy to announce that Visual Studio 2022 version 17.12 is now generally available! This post summarizes the new features you can find in this release for C++. You can download Visual Studio 2022 from the Visual Studio downloads page or upgrade your existing installation by following the Update Visual Studio Learn page.\nStandard Library and MSVC Compiler\nAs always, you can find all the details about our STL work in the changelog on GitHub. Thanks to everyone who contributed changes for this release!\nOn the conformance side, we have finished the implementation of C++23’s P2286R8 Formatting Ranges by implementing:\nFormatters for the container adaptors stack, queue, and priority_queue. #4825\nrange-default-formatter. #4716\n\n\nWe implemented multidimensional subscript operators in the compiler, which supports our existing <mdspan> implementation. For example, you can use the my_mdspan[i,j] syntax to index multidimensional spans. Here’s a full example:\n#include <mdspan>\r\n#include <print>\r\n\r\nusing namespace std;\r\nint main() {\r\n    const char* const str{\"CatDogElkFox\"};\r\n    //Defines a multidimensional view of str\r\n    mdspan<const char, extents<int, 4, 3>> m{str, 4, 3};\r\n\r\n    for (int i = 0; i < m.extents().extent(0); ++i) {\r\n        for (int j = 0; j < m.extents().extent(1); ++j) {\r\n            //Note the m[i, j] syntax\r\n            print(\"m[{}, {}]: '{}'; \", i, j, m[i, j]);\r\n        }\r\n        println();\r\n    }\r\n}\nThis release also comes with some new C++26 features:\nP2997R1 Removing The Common Reference Requirement From The Indirectly Invocable Concepts\nP0952R2 A New Specification For generate_canonical()\nP2968R2 Make std::ignore A First-Class Object\nYou’ll find improvements to several debug visualizers, including those for mutex/recursive_mutex and move_iterator.\nWe added lifetimebound attributes to min, max, clamp, ranges::min, ranges::max, and ranges::clamp, allowing MSVC code analysis and Clang -Wdangling to detect dangling references in improper usage. See the documentation for warnings C26815 and C26816 for more information about lifetimebound annotations.\nFinally, we improved the performance of several types and algorithms. The popcount() function now uses a compiler intrinsic on ARM64. We further improved the vectorized implementations of the minmax_element() and minmax() algorithm families, and optimized the search() and find_end() algorithms. We also overhauled the implementations of condition_variable and condition_variable_any, which has knock-on effects on the timed_mutex and recursive_timed_mutex types.\nC++ Productivity\nSet Command Line Arguments\nFor Unreal Engine projects, you can now set the command line arguments to pass to your application directly from the toolbar. This toolbar component will show up by default if you have the Game development with C++ workload installed. If you don’t see it, you can add it by right-clicking on the toolbar and selecting Set Arguments.\n\nWe’ll be adding support for this feature to non-UE projects in the future. See Pass command-line arguments while debugging on Microsoft Learn for documentation.\nOpen Folder for Unreal Engine uproject\nWe have added an additional entry point to open your Unreal Engine uproject with Visual Studio’s uproject support. You can now open your uproject directly from the File menu by selecting Open > Folder…. This will open your Unreal Engine project in Visual Studio.\nFor more information on how to use this feature, see the documentation on Microsoft Learn and our announcement blog post.\n\nChange Signature Improvements\nWe have updated the Change Signature interface, allowing you to add, remove, and rearrange parameters in the parameter configuration section. Additionally, you can change their order by selecting and dragging them to a new position.\nThe access methods remain the same: press Ctrl+. to trigger the Quick Actions and Refactorings menu and select Change Signature.\n\nBuild Insights\nRun Build Insights on Selected Files\nYou can select a few files, run Build Insights on them, and see exactly how these files impact build performance.\n\nFilter Projects\nYou can now filter results based on projects. Simply click the filter button on the filter column header and select the projects you want to filter.\n\nGlob Patterns to Filter Files\nThe File Path Filter is incredibly useful for narrowing down your analysis to specific directories or excluding paths that aren’t relevant to your task.\n\nEnhanced Save Experience\nNow you can designate a folder to automatically store the reports so you can easily access them during your investigation.\n\nView Explanations\nYou can now see a short description on how each tab of Build Insights can be used, along with a link to the documentation for a detailed explanation.\n\nPath Adjustments\nWe have hidden full and relative paths to reduce clutter. To see full paths, simply hover over the file. You will also see a new File Name column for both files and translation units, displayed by default to help you quickly identify files without parsing lengthy paths.\n\nGeneral Productivity\nCopy from the Error List\nWhen you copy an error from the Error List using Ctrl+C, now only the description is copied to the clipboard. This makes it easier to search for the error online or share it with others.\nYou can still copy the entire row by right-clicking the error and selecting Copy Row from the context menu or hitting Ctrl+Shift+C.\nIf what you wanted to do with the error description was to do a web search, then just hit Ctrl+F1 to search for information about the error online.\n\nDock the Code Search window\nIf you need Code or Feature Search to stay out of your way, you now have more control over the behavior of the search window.\nYou can now dock the search window and perform tool window actions with it, like Solution Explorer and others.\n\nAfter opening Code Search or Feature Search, click on the box icon at the top right to convert it into a tool window. You may choose to dock it elsewhere, pop it out, auto-hide, etc. You can revert to the dismissible window by closing the tool window and reopening search.\n\nWe’ve also simplified and cleaned up the previewing experience in search. There is now one button, indicated with an eye icon, to toggle the preview on and off.\n\nRefresh your Find results\nWe heard from a lot of users that it’s frustrating having to reopen the Find window and go through the motions of redoing a search to get updated results. Maybe you just refactored some code and want to confirm everything has been changed as expected, or you pulled some recent changes and need your recent Find operation to reflect those updates.\nAfter completing Find in Files, you will now have the option to refresh the results in the window. You’ll get your updated results without having to redo the search.\n\nNon-blocking Code Cleanup on save\nPreviously when a Code Cleanup action was run on save, you couldn’t perform any actions in the IDE. We’ve now enhanced this to operate in a non-blocking manner. The cleanup process will run in the background and can be automatically cancelled if you resume typing.\nGit\nManage file renaming\nWhen you rename files from the Solution Explorer, you’ll now be reminded to stage your changes to see the renames in Git.\n\nCopy Git link\nYou can now get a GitHub or Azure DevOps link to a specific line of code to make it easy to share with your colleagues. Access this option by right-clicking on some code and selecting Git > Copy GitHub/Azure DevOps Permalink.\n\nDebugging\nInline Return Values\nThe debugger now displays return values inline, making it much easier to see the return value of functions that have complex return statements.\n\nGitHub Copilot\nSmart Variable Inspection\nYou can now click on Ask Copilot next to the value of a variable to get AI-driven insights into what led to your current program state. For example, the following program has an off-by-one error in its loop condition, resulting in undefined behavior:\n\nIf you click Ask Copilot, it tells you what went wrong:\n\nFix my Code\nFor errors in the Visual Studio Error List, you can click Ask Copilot for an explanation and a fix to get suggestions on how to rectify your errors. For example, if we try to fix the code from the previous section by introducing a range based for loop, we might get the following error:\n\nCopilot suggests the following:\n\nDebug Failed Tests\nWe might fix the above issue and write a test case to ensure the function works, but then have a cat sit on our keyboard and accidentally initialize n_cats to 1 instead of 0. Fortunately, GitHub Copilot now comes with options to help debug the test failure:\n\nSelecting this option may give something like the following:\n\nSend us your feedback\nWe are very much interested in your feedback to continue to improve this experience. The comments below are open. Feedback can also be shared through Visual Studio Developer Community. You can also reach us on Twitter (@VisualC), or via email at visualcpp@microsoft.com.\nThe post What’s New for C++ Developers in Visual Studio 2022 17.12 appeared first on C++ Team Blog.",
        "dc:creator": "Sy Brand",
        "comments": "https://devblogs.microsoft.com/cppblog/whats-new-for-c-developers-in-visual-studio-2022-17-12/#comments",
        "content": "<p>We are happy to announce that Visual Studio 2022 version 17.12 is now generally available! This post summarizes the new features you can find in this release for C++. You can download Visual Studio 2022 from the Visual Studio downloads page or upgrade your existing installation by following the Update Visual Studio Learn page. Standard Library and MSVC [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/cppblog/whats-new-for-c-developers-in-visual-studio-2022-17-12/\">What’s New for C++ Developers in Visual Studio 2022 17.12</a> appeared first on <a href=\"https://devblogs.microsoft.com/cppblog\">C++ Team Blog</a>.</p>\n",
        "contentSnippet": "We are happy to announce that Visual Studio 2022 version 17.12 is now generally available! This post summarizes the new features you can find in this release for C++. You can download Visual Studio 2022 from the Visual Studio downloads page or upgrade your existing installation by following the Update Visual Studio Learn page. Standard Library and MSVC […]\nThe post What’s New for C++ Developers in Visual Studio 2022 17.12 appeared first on C++ Team Blog.",
        "guid": "https://devblogs.microsoft.com/cppblog/?p=34893",
        "categories": [
          "C++"
        ],
        "isoDate": "2024-11-12T20:58:48.000Z"
      }
    ]
  },
  {
    "name": "Facebook Engineering",
    "category": "기업",
    "posts": [
      {
        "creator": "",
        "title": "How Meta built large-scale cryptographic monitoring",
        "link": "https://engineering.fb.com/2024/11/12/security/how-meta-built-large-scale-cryptographic-monitoring/",
        "pubDate": "Tue, 12 Nov 2024 17:00:10 +0000",
        "content:encodedSnippet": "Cryptographic monitoring at scale has been instrumental in helping our engineers understand how cryptography is used at Meta.\nMonitoring has given us a distinct advantage in our efforts to proactively detect and remove weak cryptographic algorithms and has assisted with our general change safety and reliability efforts.\nWe’re sharing insights into our own cryptographic monitoring system, including challenges faced in its implementation, with the hope of assisting others in the industry aiming to deploy cryptographic monitoring at a similar scale.\nMeta’s managed cryptographic library, FBCrypto, plays an important role within Meta’s infrastructure and is used by the majority of our core infrastructure services. Given this, having a robust monitoring system in place for FBCrypto has been instrumental in ensuring its reliability as well as in helping our engineers understand how cryptography is used at Meta so they can make informed development decisions.\nMonitoring the health of our library allows us to detect and revert bugs before they reach production services. The data from our monitoring service provides insight into the usage of FBCrypto, allowing us to make data-driven decisions when deciding what improvements to make to the library. For example, it helps us identify components that need more attention either because they are on a hot path or are less stable.\nUnderstanding exactly how clients are using said library is a common pain point in managing any widely distributed library. But the improved understanding of FBCrypto provided by our monitoring helps us maintain a high bar for security posture. Since there is a limit to how much data a symmetric cryptographic key can protect, logging allows us to detect key overuse and rotate keys proactively. It also helps us build an inventory of cryptography usage, making it easy to identify the callsites of weakened algorithms that need to be migrated – a very important task because we need to proactively switch from weakened algorithms to newer, more robust ones as cryptography strength decays over time.\nMore generally, improved understanding helps us to make emergency algorithm migrations when a vulnerability of a primitive is discovered.\nMore recently, this is aiding our efforts to ensure post-quantum readiness in our asymmetric use cases. The available data improves our decision-making process while prioritizing quantum-vulnerable use cases\nHow cryptographic monitoring works at Meta\nEffective cryptographic monitoring requires storing persisted logs of cryptographic events, upon which diagnostic and analytic tools can be used to gather further insights. Supporting logging at the scale of FBCrypto requires an implementation with unique performance considerations in mind. Given that FBCrypto is used along many high-volume and critical code paths, a naive logging implementation could easily overwhelm a standard logging infrastructure or cause significant performance regressions. This is true for most widely distributed libraries and is especially true in the field of cryptography, where the sheer volume of usage can come as a complete surprise to those unfamiliar with the space. For example, we recently disclosed that roughly 0.05% of CPU cycles at Meta are spent on X25519 key exchange. \nMost of Meta’s logs are constructed and written via Scribe, Meta’s standard logging framework. From there, data persists in Scuba and Hive, Meta’s short-term and long term data stores, respectively.\nTypically, the Scribe API is called directly to construct a log for every “event” that needs to be logged. For FBCrypto, this would mean constructing a log for nearly every cryptographic operation that our library is used for. Unfortunately, given the sheer frequency of such operations, a solution like this would consume an unreasonable amount of write throughput and storage capacity. A common solution to this problem would be to introduce sampling (i.e., only log 1/X cryptographic operations, and increase X until we no longer have capacity concerns). However, we felt strongly about not introducing any sampling since doing so would result in most logs being omitted, giving us a less clear picture of the library’s usage.\nInstead, the logging uses a “buffering and flushing” strategy, in which cryptographic events are aggregated across time and flushed to a data store at a preconfigured interval.\nDuring the aggregation, a “count” is maintained for every unique event. When it comes time to flush, this count is exported along with the log to convey how often that particular event took place. \nBelow is a rough illustration of what this looks like:\n\nIn the above example, the key named “myKeyName” is used to perform encryption using the AES-GCM-SIV encryption algorithm (in practice we log more fields than just key name, method, and algorithm). The operation happens five times and is assigned on a count of five. Since machines often compute millions of cryptographic operations per day, this strategy can lead to significant compute savings in production. \nA client-side view\nThe aggregation and flushing is implemented within FBCrypto, so the logging and flushing code sits on the client hosts. When clients call a given cryptographic operation (e.g., “encrypt()”), the operation is performed and the log is added to our aggregated buffer. We refer to the object that holds the buffer as the “buffered logger.”\nNote that the logging does not change the interface of FBCrypto, so all of this is transparent to the clients of the library. \n\nIn multithreaded environments all threads will log to the same buffer. For this to be performant, we need to choose the right underlying data structure (see the section below on “Additional optimizations” for more details).\nWhile the aggregation works to reduce space and time overhead, the logs need to eventually be written to storage for further use. To do this, a background thread runs on the client host to periodically call the Scribe API to export the logs and flush the map’s contents. \nBelow is an overview of the overall flow: \n\nAdditional optimizations\nWe had to make some additional optimizations to support cryptographic monitoring on Meta’s major products (Facebook, Whatsapp, Instagram, etc.).\nWith careful design choices around the logging logic and data structures used, our cryptographic logging operates with no sampling and has had a negligible impact on compute performance across Meta’s fleet.\nPartially randomized flushing\nDue to the nature of our buffering and flushing strategy, certain clients who were running jobs that restarted large sets of machines at around the same time would have those machines’ logs get flushed at about the same time. This would result in “spiky” writes to the logging platform, followed by longer periods of underutilization between flushes. To normalize our write throughput, we distribute these spikes across time by applying a randomized delay on a per-host basis before logs are flushed for the first time. This leads to a more uniform flushing cadence, allowing for a more consistent load on Scribe. \nThe figure below demonstrates how this works:\n\nDerived crypto\nFBCrypto supports a feature called derived crypto, which allows “child” keysets to be derived from “parent” keysets by applying a key derivation function (KDF) to all the keys in the keyset with some salt. This feature is used by a few large-scale use cases that need to generate millions of keys.\nOur logging initially created a unique row in the buffered logger for every derived keyset, which used a lot of space and put increased load on backend data stores. To address this, we now aggregate the cryptographic operations of derived keys under the name of the parent key. This reduces our overall capacity needs without harming our ability to detect key overuse since, in the worst case, the aggregations would be a pessimistic counter for any given child key. \nThanks to this aggregation, we were able to cut down on the vast majority of our logging volume, compared to the space that would have been used with no aggregation. \nThe Folly library \nInternally, our buffering makes use of the folly::ConcurrentHashMap, which is built to be performant under heavy writes in multithreaded environments, while still guaranteeing atomic accesses.  \nUnified offerings\nMeta’s existing infrastructure and its emphasis on unified offerings are key to supporting this at scale (see the Scribe logging framework and the FBCrypto library). These properties often mean that solutions only have to be implemented once in order for the entire company to benefit.\nThis is especially true here. Most machines in Meta’s fleet can log to Scribe, giving us easy log ingestion support. Furthermore, the wide adoption of FBCrypto gives us insights into cryptographic operations without needing clients to migrate to a new library/API. \nFrom an engineering perspective, this helps us overcome many hurdles that others in the industry might face. For example, it helps us avoid fragmentation that might require multiple custom solutions to be implemented, which would increase our engineering workload.\nThe impact of cryptographic monitoring\nThe insights from our cryptographic monitoring efforts have served multiple use cases across our security and infrastructure reliability efforts.\nPreemptively mitigating security vulnerabilities\nThanks to our long retention window, we can monitor trends over time and use them for more predictive modeling and analysis. We can present our findings to cryptography experts, who can do further analysis and predict whether vulnerabilities may emerge. This allows us to preemptively identify clients using cryptography in risky ways and work with them to mitigate these issues before they become real security vulnerabilities. \nThis is particularly beneficial in preparation for the world of post-quantum cryptography (PQC), which requires us to find clients using vulnerable algorithms and ensure they are migrated off in a timely fashion. \nWe have also found that being able to preemptively detect these vulnerabilities well in advance has led to stronger support during cross-team collaborations. Thanks to the ample notice, teams can seamlessly integrate any necessary migration efforts into their roadmap with minimal interruption to their ongoing projects.\nPromoting infrastructure reliability\nOur root dataset has also served as a useful proxy for client health. This is partially thanks to the lack of sampling, as we can see the exact number of calls taking place, along with their respective success rates. This has been particularly important during large-scale migrations, where anomalous drops in success rate, call volume, etc., may indicate a bug in a new code path. Indeed, numerous detectors and alarms have been built off our dataset to help us perform big migrations safely.\nThe dataset also contains library versioning information, so we can monitor what versions of our library are running across the fleet in real-time. This has been especially useful for rolling out new features, as we can see exactly which clients have picked up the latest changes. This allows us to move faster and more confidently, even when running large-scale migrations across the fleet. \nChallenges to cryptographic monitoring\nSupporting cryptographic logging at Meta’s scale has had its own unique set of challenges.\nCapacity constraints\nDespite our optimizations, we have occasionally found ourselves putting increased load on Scribe (see point above about underestimating cryptographic usage) and have worked with the Scribe team to manage the unexpected increase in write throughput. Doing so has been relatively easy for the company, considering the design optimizations mentioned above.\nWe also occasionally put an increased load on Scuba, which is optimized to be performant for real-time data (i.e., warm storage) and can be inefficient if used for larger datasets. To minimize compute costs, we also rely on Hive tables for longer-term storage (i.e., cold storage). \nFlushing on shutdown\nBesides flushing the logs in the shared singleton map at a preconfigured time interval, client machines will also do one final flush to log all remaining contents of their log buffer to Scribe when a job is being shut down. We have found that operating in a “shutdown environment” can lead to a number of interesting scenarios, particularly when attempting to access Scribe and its dependencies. Many of these scenarios boil down to the nuances of folly::Singleton, which is Meta’s go-to library for managing singletons. Likewise, running something “on shutdown” in Java requires using only synchronous I/O code and operating quickly.\nOur next initiatives for cryptographic monitoring\nWhile our work thus far has been largely a success, there are many exciting avenues for improvements. For example, further optimizing Scribe throughput and Scuba storage utilization to make more efficient use of Meta’s infrastructure  \nWe will also continue to leverage the logging data to further develop monitoring and data analytics to promote security and reliability. On the security side, this means continuing to take an inventory of use cases that would be vulnerable in a PQC world and migrate them to more resilient algorithms/configurations. In terms of reliability, it means gaining a better understanding of the end-to-end latency for cryptography use cases.\nWithin all of this it’s also important that we continue driving the unification of cryptographic offerings and monitoring tooling. While FBCrypto provides a unified set of offerings, there are other cryptographic use cases across Meta that use a different set of tools for telemetry and data collection. More non-trivial work is needed to achieve full unification with all use cases.\nAcknowledgments\nThis work could not have been accomplished without the critical efforts of numerous folks, particularly Grace Wu, Ilya Maykov, Isaac Elbaz, and the rest of the CryptoEng team at Meta.\nThe post How Meta built large-scale cryptographic monitoring appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>Cryptographic monitoring at scale has been instrumental in helping our engineers understand how cryptography is used at Meta. Monitoring has given us a distinct advantage in our efforts to proactively detect and remove weak cryptographic algorithms and has assisted with our general change safety and reliability efforts. We’re sharing insights into our own cryptographic monitoring [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2024/11/12/security/how-meta-built-large-scale-cryptographic-monitoring/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2024/11/12/security/how-meta-built-large-scale-cryptographic-monitoring/\">How Meta built large-scale cryptographic monitoring</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "Cryptographic monitoring at scale has been instrumental in helping our engineers understand how cryptography is used at Meta. Monitoring has given us a distinct advantage in our efforts to proactively detect and remove weak cryptographic algorithms and has assisted with our general change safety and reliability efforts. We’re sharing insights into our own cryptographic monitoring [...]\nRead More...\nThe post How Meta built large-scale cryptographic monitoring appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=21935",
        "categories": [
          "Security"
        ],
        "isoDate": "2024-11-12T17:00:10.000Z"
      }
    ]
  },
  {
    "name": "eBay Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Twitter Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Netflix TechBlog",
    "category": "기업",
    "posts": [
      {
        "creator": "Netflix Technology Blog",
        "title": "Netflix’s Distributed Counter Abstraction",
        "link": "https://netflixtechblog.com/netflixs-distributed-counter-abstraction-8d0c45eb66b2?source=rss----2615bd06b42e---4",
        "pubDate": "Tue, 12 Nov 2024 20:45:23 GMT",
        "content:encodedSnippet": "By: Rajiv Shringi, Oleksii Tkachuk, Kartik Sathyanarayanan\nIntroduction\nIn our previous blog post, we introduced Netflix’s TimeSeries Abstraction, a distributed service designed to store and query large volumes of temporal event data with low millisecond latencies. Today, we’re excited to present the Distributed Counter Abstraction. This counting service, built on top of the TimeSeries Abstraction, enables distributed counting at scale while maintaining similar low latency performance. As with all our abstractions, we use our Data Gateway Control Plane to shard, configure, and deploy this service globally.\nDistributed counting is a challenging problem in computer science. In this blog post, we’ll explore the diverse counting requirements at Netflix, the challenges of achieving accurate counts in near real-time, and the rationale behind our chosen approach, including the necessary trade-offs.\nNote: When it comes to distributed counters, terms such as ‘accurate’ or ‘precise’ should be taken with a grain of salt. In this context, they refer to a count very close to accurate, presented with minimal delays.\nUse Cases and Requirements\nAt Netflix, our counting use cases include tracking millions of user interactions, monitoring how often specific features or experiences are shown to users, and counting multiple facets of data during A/B test experiments, among others.\nAt Netflix, these use cases can be classified into two broad categories:\n\nBest-Effort: For this category, the count doesn’t have to be very accurate or durable. However, this category requires near-immediate access to the current count at low latencies, all while keeping infrastructure costs to a minimum.\nEventually Consistent: This category needs accurate and durable counts, and is willing to tolerate a slight delay in accuracy and a slightly higher infrastructure cost as a trade-off.\n\nBoth categories share common requirements, such as high throughput and high availability. The table below provides a detailed overview of the diverse requirements across these two categories.\n\nDistributed Counter Abstraction\nTo meet the outlined requirements, the Counter Abstraction was designed to be highly configurable. It allows users to choose between different counting modes, such as Best-Effort or Eventually Consistent, while considering the documented trade-offs of each option. After selecting a mode, users can interact with APIs without needing to worry about the underlying storage mechanisms and counting methods.\nLet’s take a closer look at the structure and functionality of the API.\nAPI\nCounters are organized into separate namespaces that users set up for each of their specific use cases. Each namespace can be configured with different parameters, such as Type of Counter, Time-To-Live (TTL), and Counter Cardinality, using the service’s Control Plane.\nThe Counter Abstraction API resembles Java’s AtomicInteger interface:\nAddCount/AddAndGetCount: Adjusts the count for the specified counter by the given delta value within a dataset. The delta value can be positive or negative. The AddAndGetCount counterpart also returns the count after performing the add operation.\n{\n  \"namespace\": \"my_dataset\",\n  \"counter_name\": \"counter123\",\n  \"delta\": 2,\n  \"idempotency_token\": { \n    \"token\": \"some_event_id\",\n    \"generation_time\": \"2024-10-05T14:48:00Z\"\n  }\n}\nThe idempotency token can be used for counter types that support them. Clients can use this token to safely retry or hedge their requests. Failures in a distributed system are a given, and having the ability to safely retry requests enhances the reliability of the service.\nGetCount: Retrieves the count value of the specified counter within a dataset.\n{\n  \"namespace\": \"my_dataset\",\n  \"counter_name\": \"counter123\"\n}\nClearCount: Effectively resets the count to 0 for the specified counter within a dataset.\n{\n  \"namespace\": \"my_dataset\",\n  \"counter_name\": \"counter456\",\n  \"idempotency_token\": {...}\n}\nNow, let’s look at the different types of counters supported within the Abstraction.\nTypes of Counters\nThe service primarily supports two types of counters: Best-Effort and Eventually Consistent, along with a third experimental type: Accurate. In the following sections, we’ll describe the different approaches for these types of counters and the trade-offs associated with each.\nBest Effort Regional Counter\nThis type of counter is powered by EVCache, Netflix’s distributed caching solution built on the widely popular Memcached. It is suitable for use cases like A/B experiments, where many concurrent experiments are run for relatively short durations and an approximate count is sufficient. Setting aside the complexities of provisioning, resource allocation, and control plane management, the core of this solution is remarkably straightforward:\n// counter cache key\ncounterCacheKey = <namespace>:<counter_name>\n// add operation\nreturn delta > 0\n    ? cache.incr(counterCacheKey, delta, TTL)\n    : cache.decr(counterCacheKey, Math.abs(delta), TTL);\n// get operation\ncache.get(counterCacheKey);\n// clear counts from all replicas\ncache.delete(counterCacheKey, ReplicaPolicy.ALL);\nEVCache delivers extremely high throughput at low millisecond latency or better within a single region, enabling a multi-tenant setup within a shared cluster, saving infrastructure costs. However, there are some trade-offs: it lacks cross-region replication for the increment operation and does not provide consistency guarantees, which may be necessary for an accurate count. Additionally, idempotency is not natively supported, making it unsafe to retry or hedge requests.\nA note on probabilistic data structures:\nProbabilistic data structures like HyperLogLog (HLL) can be useful for tracking an approximate number of distinct elements, like distinct views or visits to a website, but are not ideally suited for implementing distinct increments and decrements for a given key. Count-Min Sketch (CMS) is an alternative that can be used to adjust the values of keys by a given amount. Data stores like Redis support both HLL and CMS. However, we chose not to pursue this direction for several reasons:\n\nWe chose to build on top of data stores that we already operate at scale.\nProbabilistic data structures do not natively support several of our requirements, such as resetting the count for a given key or having TTLs for counts. Additional data structures, including more sketches, would be needed to support these requirements.\nOn the other hand, the EVCache solution is quite simple, requiring minimal lines of code and using natively supported elements. However, it comes at the trade-off of using a small amount of memory per counter key.\n\nEventually Consistent Global Counter\nWhile some users may accept the limitations of a Best-Effort counter, others opt for precise counts, durability and global availability. In the following sections, we’ll explore various strategies for achieving durable and accurate counts. Our objective is to highlight the challenges inherent in global distributed counting and explain the reasoning behind our chosen approach.\nApproach 1: Storing a Single Row per Counter\nLet’s start simple by using a single row per counter key within a table in a globally replicated datastore.\n\nLet’s examine some of the drawbacks of this approach:\n\nLack of Idempotency: There is no idempotency key baked into the storage data-model preventing users from safely retrying requests. Implementing idempotency would likely require using an external system for such keys, which can further degrade performance or cause race conditions.\nHeavy Contention: To update counts reliably, every writer must perform a Compare-And-Swap operation for a given counter using locks or transactions. Depending on the throughput and concurrency of operations, this can lead to significant contention, heavily impacting performance.\n\nSecondary Keys: One way to reduce contention in this approach would be to use a secondary key, such as a bucket_id, which allows for distributing writes by splitting a given counter into buckets, while enabling reads to aggregate across buckets. The challenge lies in determining the appropriate number of buckets. A static number may still lead to contention with hot keys, while dynamically assigning the number of buckets per counter across millions of counters presents a more complex problem.\nLet’s see if we can iterate on our solution to overcome these drawbacks.\nApproach 2: Per Instance Aggregation\nTo address issues of hot keys and contention from writing to the same row in real-time, we could implement a strategy where each instance aggregates the counts in memory and then flushes them to disk at regular intervals. Introducing sufficient jitter to the flush process can further reduce contention.\n\nHowever, this solution presents a new set of issues:\n\nVulnerability to Data Loss: The solution is vulnerable to data loss for all in-memory data during instance failures, restarts, or deployments.\nInability to Reliably Reset Counts: Due to counting requests being distributed across multiple machines, it is challenging to establish consensus on the exact point in time when a counter reset occurred.\nLack of Idempotency: Similar to the previous approach, this method does not natively guarantee idempotency. One way to achieve idempotency is by consistently routing the same set of counters to the same instance. However, this approach may introduce additional complexities, such as leader election, and potential challenges with availability and latency in the write path.\n\nThat said, this approach may still be suitable in scenarios where these trade-offs are acceptable. However, let’s see if we can address some of these issues with a different event-based approach.\nApproach 3: Using Durable Queues\nIn this approach, we log counter events into a durable queuing system like Apache Kafka to prevent any potential data loss. By creating multiple topic partitions and hashing the counter key to a specific partition, we ensure that the same set of counters are processed by the same set of consumers. This setup simplifies facilitating idempotency checks and resetting counts. Furthermore, by leveraging additional stream processing frameworks such as Kafka Streams or Apache Flink, we can implement windowed aggregations.\n\nHowever, this approach comes with some challenges:\n\nPotential Delays: Having the same consumer process all the counts from a given partition can lead to backups and delays, resulting in stale counts.\nRebalancing Partitions: This approach requires auto-scaling and rebalancing of topic partitions as the cardinality of counters and throughput increases.\n\nFurthermore, all approaches that pre-aggregate counts make it challenging to support two of our requirements for accurate counters:\n\nAuditing of Counts: Auditing involves extracting data to an offline system for analysis to ensure that increments were applied correctly to reach the final value. This process can also be used to track the provenance of increments. However, auditing becomes infeasible when counts are aggregated without storing the individual increments.\nPotential Recounting: Similar to auditing, if adjustments to increments are necessary and recounting of events within a time window is required, pre-aggregating counts makes this infeasible.\n\nBarring those few requirements, this approach can still be effective if we determine the right way to scale our queue partitions and consumers while maintaining idempotency. However, let’s explore how we can adjust this approach to meet the auditing and recounting requirements.\nApproach 4: Event Log of Individual Increments\nIn this approach, we log each individual counter increment along with its event_time and event_id. The event_id can include the source information of where the increment originated. The combination of event_time and event_id can also serve as the idempotency key for the write.\n\nHowever, in its simplest form, this approach has several drawbacks:\n\nRead Latency: Each read request requires scanning all increments for a given counter potentially degrading performance.\nDuplicate Work: Multiple threads might duplicate the effort of aggregating the same set of counters during read operations, leading to wasted effort and subpar resource utilization.\nWide Partitions: If using a datastore like Apache Cassandra, storing many increments for the same counter could lead to a wide partition, affecting read performance.\nLarge Data Footprint: Storing each increment individually could also result in a substantial data footprint over time. Without an efficient data retention strategy, this approach may struggle to scale effectively.\n\nThe combined impact of these issues can lead to increased infrastructure costs that may be difficult to justify. However, adopting an event-driven approach seems to be a significant step forward in addressing some of the challenges we’ve encountered and meeting our requirements.\nHow can we improve this solution further?\nNetflix’s Approach\nWe use a combination of the previous approaches, where we log each counting activity as an event, and continuously aggregate these events in the background using queues and a sliding time window. Additionally, we employ a bucketing strategy to prevent wide partitions. In the following sections, we’ll explore how this approach addresses the previously mentioned drawbacks and meets all our requirements.\nNote: From here on, we will use the words “rollup” and “aggregate” interchangeably. They essentially mean the same thing, i.e., collecting individual counter increments/decrements and arriving at the final value.\nTimeSeries Event Store:\nWe chose the TimeSeries Data Abstraction as our event store, where counter mutations are ingested as event records. Some of the benefits of storing events in TimeSeries include:\nHigh-Performance: The TimeSeries abstraction already addresses many of our requirements, including high availability and throughput, reliable and fast performance, and more.\nReducing Code Complexity: We reduce a lot of code complexity in Counter Abstraction by delegating a major portion of the functionality to an existing service.\nTimeSeries Abstraction uses Cassandra as the underlying event store, but it can be configured to work with any persistent store. Here is what it looks like:\n\nHandling Wide Partitions: The time_bucket and event_bucket columns play a crucial role in breaking up a wide partition, preventing high-throughput counter events from overwhelming a given partition. For more information regarding this, refer to our previous blog.\nNo Over-Counting: The event_time, event_id and event_item_key columns form the idempotency key for the events for a given counter, enabling clients to retry safely without the risk of over-counting.\nEvent Ordering: TimeSeries orders all events in descending order of time allowing us to leverage this property for events like count resets.\nEvent Retention: The TimeSeries Abstraction includes retention policies to ensure that events are not stored indefinitely, saving disk space and reducing infrastructure costs. Once events have been aggregated and moved to a more cost-effective store for audits, there’s no need to retain them in the primary storage.\nNow, let’s see how these events are aggregated for a given counter.\nAggregating Count Events:\nAs mentioned earlier, collecting all individual increments for every read request would be cost-prohibitive in terms of read performance. Therefore, a background aggregation process is necessary to continually converge counts and ensure optimal read performance.\nBut how can we safely aggregate count events amidst ongoing write operations?\nThis is where the concept of Eventually Consistent counts becomes crucial. By intentionally lagging behind the current time by a safe margin, we ensure that aggregation always occurs within an immutable window.\nLets see what that looks like:\n\nLet’s break this down:\n\nlastRollupTs: This represents the most recent time when the counter value was last aggregated. For a counter being operated for the first time, this timestamp defaults to a reasonable time in the past.\nImmutable Window and Lag: Aggregation can only occur safely within an immutable window that is no longer receiving counter events. The “acceptLimit” parameter of the TimeSeries Abstraction plays a crucial role here, as it rejects incoming events with timestamps beyond this limit. During aggregations, this window is pushed slightly further back to account for clock skews.\n\nThis does mean that the counter value will lag behind its most recent update by some margin (typically in the order of seconds). This approach does leave the door open for missed events due to cross-region replication issues. See “Future Work” section at the end.\n\nAggregation Process: The rollup process aggregates all events in the aggregation window since the last rollup to arrive at the new value.\n\nRollup Store:\nWe save the results of this aggregation in a persistent store. The next aggregation will simply continue from this checkpoint.\n\nWe create one such Rollup table per dataset and use Cassandra as our persistent store. However, as you will soon see in the Control Plane section, the Counter service can be configured to work with any persistent store.\nLastWriteTs: Every time a given counter receives a write, we also log a last-write-timestamp as a columnar update in this table. This is done using Cassandra’s USING TIMESTAMP feature to predictably apply the Last-Write-Win (LWW) semantics. This timestamp is the same as the event_time for the event. In the subsequent sections, we’ll see how this timestamp is used to keep some counters in active rollup circulation until they have caught up to their latest value.\nRollup Cache\nTo optimize read performance, these values are cached in EVCache for each counter. We combine the lastRollupCount and lastRollupTs into a single cached value per counter to prevent potential mismatches between the count and its corresponding checkpoint timestamp.\n\nBut, how do we know which counters to trigger rollups for? Let’s explore our Write and Read path to understand this better.\nAdd/Clear Count:\n\nAn add or clear count request writes durably to the TimeSeries Abstraction and updates the last-write-timestamp in the Rollup store. If the durability acknowledgement fails, clients can retry their requests with the same idempotency token without the risk of overcounting. Upon durability, we send a fire-and-forget request to trigger the rollup for the request counter.\nGetCount:\n\nWe return the last rolled-up count as a quick point-read operation, accepting the trade-off of potentially delivering a slightly stale count. We also trigger a rollup during the read operation to advance the last-rollup-timestamp, enhancing the performance of subsequent aggregations. This process also self-remediates a stale count if any previous rollups had failed.\nWith this approach, the counts continually converge to their latest value. Now, let’s see how we scale this approach to millions of counters and thousands of concurrent operations using our Rollup Pipeline.\nRollup Pipeline:\nEach Counter-Rollup server operates a rollup pipeline to efficiently aggregate counts across millions of counters. This is where most of the complexity in Counter Abstraction comes in. In the following sections, we will share key details on how efficient aggregations are achieved.\nLight-Weight Roll-Up Event: As seen in our Write and Read paths above, every operation on a counter sends a light-weight event to the Rollup server:\nrollupEvent: {\n  \"namespace\": \"my_dataset\",\n  \"counter\": \"counter123\"\n}\nNote that this event does not include the increment. This is only an indication to the Rollup server that this counter has been accessed and now needs to be aggregated. Knowing exactly which specific counters need to be aggregated prevents scanning the entire event dataset for the purpose of aggregations.\n\nIn-Memory Rollup Queues: A given Rollup server instance runs a set of in-memory queues to receive rollup events and parallelize aggregations. In the first version of this service, we settled on using in-memory queues to reduce provisioning complexity, save on infrastructure costs, and make rebalancing the number of queues fairly straightforward. However, this comes with the trade-off of potentially missing rollup events in case of an instance crash. For more details, see the “Stale Counts” section in “Future Work.”\nMinimize Duplicate Effort: We use a fast non-cryptographic hash like XXHash to ensure that the same set of counters end up on the same queue. Further, we try to minimize the amount of duplicate aggregation work by having a separate rollup stack that chooses to run fewer beefier instances.\n\nAvailability and Race Conditions: Having a single Rollup server instance can minimize duplicate aggregation work but may create availability challenges for triggering rollups. If we choose to horizontally scale the Rollup servers, we allow threads to overwrite rollup values while avoiding any form of distributed locking mechanisms to maintain high availability and performance. This approach remains safe because aggregation occurs within an immutable window. Although the concept of now() may differ between threads, causing rollup values to sometimes fluctuate, the counts will eventually converge to an accurate value within each immutable aggregation window.\nRebalancing Queues: If we need to scale the number of queues, a simple Control Plane configuration update followed by a re-deploy is enough to rebalance the number of queues.\n      \"eventual_counter_config\": {             \n          \"queue_config\": {                    \n            \"num_queues\" : 8,  // change to 16 and re-deploy\n...\nHandling Deployments: During deployments, these queues shut down gracefully, draining all existing events first, while the new Rollup server instance starts up with potentially new queue configurations. There may be a brief period when both the old and new Rollup servers are active, but as mentioned before, this race condition is managed since aggregations occur within immutable windows.\nMinimize Rollup Effort: Receiving multiple events for the same counter doesn’t mean rolling it up multiple times. We drain these rollup events into a Set, ensuring a given counter is rolled up only once during a rollup window.\nEfficient Aggregation: Each rollup consumer processes a batch of counters simultaneously. Within each batch, it queries the underlying TimeSeries abstraction in parallel to aggregate events within specified time boundaries. The TimeSeries abstraction optimizes these range scans to achieve low millisecond latencies.\nDynamic Batching: The Rollup server dynamically adjusts the number of time partitions that need to be scanned based on cardinality of counters in order to prevent overwhelming the underlying store with many parallel read requests.\n\nAdaptive Back-Pressure: Each consumer waits for one batch to complete before issuing the rollups for the next batch. It adjusts the wait time between batches based on the performance of the previous batch. This approach provides back-pressure during rollups to prevent overwhelming the underlying TimeSeries store.\nHandling Convergence:\n\nIn order to prevent low-cardinality counters from lagging behind too much and subsequently scanning too many time partitions, they are kept in constant rollup circulation. For high-cardinality counters, continuously circulating them would consume excessive memory in our Rollup queues. This is where the last-write-timestamp mentioned previously plays a crucial role. The Rollup server inspects this timestamp to determine if a given counter needs to be re-queued, ensuring that we continue aggregating until it has fully caught up with the writes.\nNow, let’s see how we leverage this counter type to provide an up-to-date current count in near-realtime.\nExperimental: Accurate Global Counter\nWe are experimenting with a slightly modified version of the Eventually Consistent counter. Again, take the term ‘Accurate’ with a grain of salt. The key difference between this type of counter and its counterpart is that the delta, representing the counts since the last-rolled-up timestamp, is computed in real-time.\n\nAggregating this delta in real-time can impact the performance of this operation, depending on the number of events and partitions that need to be scanned to retrieve this delta. The same principle of rolling up in batches applies here to prevent scanning too many partitions in parallel.\n\nConversely, if the counters in this dataset are accessed frequently, the time gap for the delta remains narrow, making this approach of fetching current counts quite effective.\nNow, let’s see how all this complexity is managed by having a unified Control Plane configuration.\nControl Plane\nThe Data Gateway Platform Control Plane manages control settings for all abstractions and namespaces, including the Counter Abstraction. Below, is an example of a control plane configuration for a namespace that supports eventually consistent counters with low cardinality:\n\"persistence_configuration\": [\n  {\n    \"id\": \"CACHE\",                             // Counter cache config\n    \"scope\": \"dal=counter\",                                                   \n    \"physical_storage\": {\n      \"type\": \"EVCACHE\",                       // type of cache storage\n      \"cluster\": \"evcache_dgw_counter_tier1\"   // Shared EVCache cluster\n    }\n  },\n  {\n    \"id\": \"COUNTER_ROLLUP\",\n    \"scope\": \"dal=counter\",                    // Counter abstraction config\n    \"physical_storage\": {                     \n      \"type\": \"CASSANDRA\",                     // type of Rollup store\n      \"cluster\": \"cass_dgw_counter_uc1\",       // physical cluster name\n      \"dataset\": \"my_dataset_1\"                // namespace/dataset   \n    },\n    \"counter_cardinality\": \"LOW\",              // supported counter cardinality\n    \"config\": {\n      \"counter_type\": \"EVENTUAL\",              // Type of counter\n      \"eventual_counter_config\": {             // eventual counter type\n        \"internal_config\": {                  \n          \"queue_config\": {                    // adjust w.r.t cardinality\n            \"num_queues\" : 8,                  // Rollup queues per instance\n            \"coalesce_ms\": 10000,              // coalesce duration for rollups\n            \"capacity_bytes\": 16777216         // allocated memory per queue\n          },\n          \"rollup_batch_count\": 32             // parallelization factor\n        }\n      }\n    }\n  },\n  {\n    \"id\": \"EVENT_STORAGE\",\n    \"scope\": \"dal=ts\",                         // TimeSeries Event store\n    \"physical_storage\": {\n      \"type\": \"CASSANDRA\",                     // persistent store type\n      \"cluster\": \"cass_dgw_counter_uc1\",       // physical cluster name\n      \"dataset\": \"my_dataset_1\",               // keyspace name\n    },\n    \"config\": {                              \n      \"time_partition\": {                      // time-partitioning for events\n        \"buckets_per_id\": 4,                   // event buckets within\n        \"seconds_per_bucket\": \"600\",           // smaller width for LOW card\n        \"seconds_per_slice\": \"86400\",          // width of a time slice table\n      },\n      \"accept_limit\": \"5s\",                    // boundary for immutability\n    },\n    \"lifecycleConfigs\": {\n      \"lifecycleConfig\": [\n        {\n          \"type\": \"retention\",                 // Event retention\n          \"config\": {\n            \"close_after\": \"518400s\",\n            \"delete_after\": \"604800s\"          // 7 day count event retention\n          }\n        }\n      ]\n    }\n  }\n]\nUsing such a control plane configuration, we compose multiple abstraction layers using containers deployed on the same host, with each container fetching configuration specific to its scope.\n\nProvisioning\nAs with the TimeSeries abstraction, our automation uses a bunch of user inputs regarding their workload and cardinalities to arrive at the right set of infrastructure and related control plane configuration. You can learn more about this process in a talk given by one of our stunning colleagues, Joey Lynch : How Netflix optimally provisions infrastructure in the cloud.\nPerformance\nAt the time of writing this blog, this service was processing close to 75K count requests/second globally across the different API endpoints and datasets:\n\nwhile providing single-digit millisecond latencies for all its endpoints:\n\nFuture Work\nWhile our system is robust, we still have work to do in making it more reliable and enhancing its features. Some of that work includes:\n\nRegional Rollups: Cross-region replication issues can result in missed events from other regions. An alternate strategy involves establishing a rollup table for each region, and then tallying them in a global rollup table. A key challenge in this design would be effectively communicating the clearing of the counter across regions.\nError Detection and Stale Counts: Excessively stale counts can occur if rollup events are lost or if a rollups fails and isn’t retried. This isn’t an issue for frequently accessed counters, as they remain in rollup circulation. This issue is more pronounced for counters that aren’t accessed frequently. Typically, the initial read for such a counter will trigger a rollup, self-remediating the issue. However, for use cases that cannot accept potentially stale initial reads, we plan to implement improved error detection, rollup handoffs, and durable queues for resilient retries.\n\nConclusion\nDistributed counting remains a challenging problem in computer science. In this blog, we explored multiple approaches to implement and deploy a Counting service at scale. While there may be other methods for distributed counting, our goal has been to deliver blazing fast performance at low infrastructure costs while maintaining high availability and providing idempotency guarantees. Along the way, we make various trade-offs to meet the diverse counting requirements at Netflix. We hope you found this blog post insightful.\nStay tuned for Part 3 of Composite Abstractions at Netflix, where we’ll introduce our Graph Abstraction, a new service being built on top of the Key-Value Abstraction and the TimeSeries Abstraction to handle high-throughput, low-latency graphs.\nAcknowledgments\nSpecial thanks to our stunning colleagues who contributed to the Counter Abstraction’s success: Joey Lynch, Vinay Chella, Kaidan Fullerton, Tom DeVoe, Mengqing Wang\n\nNetflix’s Distributed Counter Abstraction was originally published in Netflix TechBlog on Medium, where people are continuing the conversation by highlighting and responding to this story.",
        "dc:creator": "Netflix Technology Blog",
        "guid": "https://medium.com/p/8d0c45eb66b2",
        "categories": [
          "counter",
          "software-architecture",
          "system-design-interview",
          "distributed-systems",
          "scalability"
        ],
        "isoDate": "2024-11-12T20:45:23.000Z"
      }
    ]
  },
  {
    "name": "JetBrains: Developer Tools for Professionals and Teams – Company Blog | JetBrains",
    "category": "기업",
    "posts": [
      {
        "creator": "Dmitriy Smirnov",
        "title": "Faster Time-to-Code in IntelliJ IDEA",
        "link": "https://blog.jetbrains.com/idea/2024/11/faster-time-to-code-in-intellij-idea/",
        "pubDate": "Thu, 14 Nov 2024 14:57:03 +0000",
        "content:encodedSnippet": "IntelliJ IDEA’s power and wide range of functionality can make it somewhat resource-hungry. Depending on the project you’re working with, the IDE has been known to lag, which can naturally be frustrating.\nPerhaps the most common scenario in which developers are required to wait is when opening a project. IntelliJ IDEA needs to load and synchronize the project, perform indexing, and do a lot of other small things to enable all the useful features it has.\nIn this post, we’ll look at the steps we’ve taken to improve performance in newer versions of IntelliJ IDEA, reducing time-to-code and making the IDE more responsive right from startup.\nDownload IntelliJ IDEA now!\n                                                    \nOur mission: improve time-to-code\nIf you take a look at an IntelliJ IDEA version from before 2023.2, the IDE had to wait for the full sync of your project’s Maven or Gradle project model before it could even start indexing. Then, while waiting for indexing to finish, all the smart features of the IDE, including code highlighting and navigation, were disabled. Only after indexing was complete could they be used.\nHere’s a schematic representation of components involved:\n\n\n\n\nThe time it took to synchronize and index projects increased the larger the projects got. While this was to be expected, as huge projects are more complex for the IDE to work with, waiting several minutes before being able to start working was still tedious.\nUnfortunately, with so many steps to perform while loading a project, significant time could be spent even on smaller ones, resulting in the perception that IntelliJ IDEA was performing slowly.\nNobody likes having to wait, especially when you’re thinking about the work you want to dive into. That’s why we made improving this situation a high-priority task.\nTo gauge our progress, we decided to track what we call time-to-code – the time between the application starting or the project opening and the moment when it becomes possible to comfortably work with code in it. Our goal was simply to reduce time-to-code as much as possible.\nImproving the project opening flow and experience\nThe problem of improving startup and project opening in IntelliJ IDEA is actually complex, as it depends on several components and their interconnection. This complexity has an advantage, however, as it allows us to approach the problem from multiple angles. While we wait for longer-term efforts on technical improvements to bear fruit, we’ve also been able to adjust IntelliJ IDEA’s approach to indexing for significant time-to-code benefits that can already be experienced.\nTechnical improvements\nOne obvious approach to reducing time-to-code is performing technical updates to improve the IDE’s performance – optimizing code and architecture, using better hardware, parallelizing, etc. IntelliJ IDEA is more than 20 years old, and some architectural and algorithmic decisions made in the early days are still present in the product. \nWork is being done here. We’ve invested a lot of effort into proper monitoring, investigating, and optimizing performance bottlenecks, and this has already delivered some noticeable results. We’ve improved the application’s startup Application Performance Index (Apdex) to the top category with a score of 0.94, improved the speed of multi-threaded indexing by 25%, and got rid of unnecessary locks during parallel indexing, reducing the time other threads have to wait for such locks to become available. But this is going to be a long journey, as refactorings can have consequences for other subsystems in the IDE and need to be evaluated carefully over a longer time. For more details about technical performance improvements, check out this great talk by Yuri Artamonov, and stay tuned for more articles.\nWhile we worked on the technical side, we also decided to take a different approach, addressing the perceived performance of the IDE. \nPhased sync indexing\nThe IDE does not necessarily need to be technically improved in order for users to experience it as faster. As long as they are able to start working sooner, they will perceive a performance improvement. From our research, we know that a lot of users think that the IDE is ready for work when they can see the project structure and proper code highlighting. So that is where we concentrated our efforts.\nThe IDE has to perform several crucial steps before highlighting and navigation can work, but we wondered whether these steps really need to run in series, sequentially.\nSome promising experiments in version 2023.3 showed that splitting the process of syncing and indexing into several stages and running them in an asynchronous manner allowed users to get to their code much faster.\nSo as a first step, we made IntelliJ IDEA start indexing the files in the project directory before it actually gets the project model from the underlying build tool like Gradle or Maven. The downside of this was that unnecessary files got indexed, and after synchronizing with the build tool, reindexing was required. Nevertheless, the overall time-to-code (including both the sync and the full indexing) decreased significantly, becoming up to 1.5 times faster on big projects, according to our test suite.\nWithout the project model loaded, however, it was not possible to properly build relationships between parts of the project, show the correct project tree, highlight, or provide navigation.\nTo address this problem, we implemented what we call phased sync. Instead of requesting the full project model from the build tool all at once, we had the IDE get the model in phases. Currently, there are two. \nPhase 1: Skip resolving dependencies\nIn the first phase, which happens as early in the project-loading process as possible, IntelliJ IDEA does not resolve dependencies or connect to the internet. It simply provides a model that’s accurate enough to allow the IDE to show the project tree, index the most necessary parts of the project, and provide some essential smart features. \nObviously, some dependencies might still be missing after this phase, causing resolution problems and cases where code gets marked red even if it is correct. The IDE is actually aware of these false positive errors, and it addresses them at the level of individual language support by suppressing errors that are caused by missing dependencies. It is also able to properly handle navigation attempts with respective messages. Since version 2024.2, this error suppression has worked for Java, and in 2024.3, the support was extended to Kotlin.\nThis first phase is especially fast in Maven because its static pom.xml configuration files can be parsed by the IDE without launching Maven, while still providing enough knowledge to build a very accurate model.\nFor Gradle, which is dynamic by nature and very flexible in its scripts, IntelliJ IDEA cannot parse scripts on its own at the moment – meaning it has to run the Gradle daemon. We sped up this process by only requesting sourceSets, the required language level, and other basic information from Gradle. However, with the Declarative Gradle initiative, we may be able to improve this dramatically in the future.\nPhase 2: Download and resolve dependencies\nDuring the second phase, IntelliJ IDEA downloads all plugins and dependencies, properly resolves all configurations, and provides a fully accurate model for the IDE to work with. Indexes are then updated based on the full model.\nWith this two-phase approach, you get an almost fully functional version of IntelliJ IDEA much faster, while dependencies are still downloaded and resolved.\nAs an additional improvement, we’ve made it possible for a lot of features to work while indexes are not yet ready, further decreasing time-to-code. The most important ones are code highlighting within individual files, partial code resolution, and run configurations. Of course, having the underlying index ready makes these operations even faster, but they work reliably even with only partial indexes.\nThe result\nFrom a bird’s eye view, the entire process now looks like this: \n\n\n\n\nHow do we know it was worth it?\nDepending on the project, time-to-code (or, more precisely, time before full highlighting in the schema above) in our test suite is up to several times faster the first time a project is opened.\nHere is an example showing how fast the project tree is displayed and highlighting is enabled in a project where it used to take tens of seconds to access these features.\n\n\n\n\nSurveys show that around 30% of our users think IntelliJ IDEA 2024.2 allows them to get started with coding faster than before.\nWhat’s next?\nWhile not all of IntelliJ IDEA’s features are available while indexing a project, the two-phased syncing approach has definitely sped up overall startup performance, giving you a faster time-to-code. Additionally, we’ve made many actions compatible with having no index or only a partial one available. And in the version 2024.2, around 10% of our users do actually write code before the entire sync and indexing process finishes. But we’re not done yet.\nOur aim now is to improve phased syncing, especially with Gradle, to improve time-to-code even further. We’re also updating the UX of working with your project while dependencies have not yet been resolved.\nIn the meantime, we hope you enjoy the fruits of the labor we put in improving time-to-code. Download the latest version of IntelliJ IDEA and let us know what you think!",
        "dc:creator": "Dmitriy Smirnov",
        "content": "IntelliJ IDEA’s power and wide range of functionality can make it somewhat resource-hungry. Depending on the project you’re working with, the IDE has been known to lag, which can naturally be frustrating. Perhaps the most common scenario in which developers are required to wait is when opening a project. IntelliJ IDEA needs to load and [&#8230;]",
        "contentSnippet": "IntelliJ IDEA’s power and wide range of functionality can make it somewhat resource-hungry. Depending on the project you’re working with, the IDE has been known to lag, which can naturally be frustrating. Perhaps the most common scenario in which developers are required to wait is when opening a project. IntelliJ IDEA needs to load and […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=525551",
        "categories": [
          "idea",
          "news",
          "indexing",
          "intellij-idea"
        ],
        "isoDate": "2024-11-14T14:57:03.000Z"
      },
      {
        "creator": "Ilia Afanasiev",
        "title": "Unveiling Game Development in Rust with Bevy: Key Insights from Herbert Wolverson’s Livestream",
        "link": "https://blog.jetbrains.com/rust/2024/11/14/unveiling-game-development-in-rust-with-bevy-key-insights-from-herbert-wolverson-s-livestream/",
        "pubDate": "Thu, 14 Nov 2024 14:12:42 +0000",
        "content:encodedSnippet": "Disclaimer: This article was created using JetBrains Grazie, an AI-based writing and communication companion. With its help, the core topics of this rich and nuanced livestream were conveniently distilled into a compact blog post format.\nGame development in Rust is gaining momentum, and Bevy, a modern game engine focusing on Rust, is at the forefront of this revolution. In a recent RustRover Livestream, Herbert Wolverson, an accomplished author and educator in the Rust community, shared his expertise on using Rust and Bevy for game development. Here’s a summary of the key insights from the live stream.\n\n\n\n\n\n\nGetting to know Herbert Wolverson\nHerbert Wolverson is renowned for his contributions to the Rust ecosystem. He authored the Rust Roguelike Tutorial, Hands-on Rust, Rust Brain Teasers, and the soon-to-be-published Advanced Hands-on Rust. His expertise extends beyond writing; he also teaches Rust through Ardan Labs, conducts workshops, and is active in open-source projects like LibreQoS.\nIntroduction to Rust\nHerbert began coding at a young age, influenced by his father, who was a computer science teacher. After exploring various programming languages including BASIC, Pascal, C, and C++, Herbert discovered Rust and found its strict, safety-oriented design appealing. He emphasized how Rust’s compiler enforces good practices, such as preventing the use of uninitialized variables and ensuring safe memory management.\nUnderstanding game development Idioms and ECS\nIn traditional game development, many use object-oriented programming (OOP), creating a deep hierarchy of objects. However, this method can lead to performance issues and complex maintenance. Herbert pointed out the limitations of OOP in game development and introduced the Entity-Component-System (ECS) model as a more suitable alternative in Rust.\nBenefits of ECS\n1. Composition Over Inheritance: ECS focuses on composing entities with various components rather than relying on deep inheritance trees.\n2. Performance: ECS models manage memory efficiently, minimizing cache misses and fragmentation.\n3. Parallel Processing: Rust’s strict guarantees allow Bevy to provide multithreading for free, enhancing performance.\nBevy’s ECS and game design\nHerbert outlined the basics of Bevy’s ECS:\n– Entities: Unique IDs without behavior.\n– Components: Data attached to entities.\n– Systems: Functions processing entities and components, forming game logic.\nPractical examples with Bevy\nSetting up Bevy\nTo start, include Bevy in your Cargo.toml file and set up a basic application:\n\n\n\n\nCreating and moving entities\nHerbert demonstrated how to create entities and add components. For instance, spawning Ferris the Crab:\n\n\n\n\nThis code sets up a basic 2D game with a camera and a sprite.\nAdding interactivity\nHerbert explained how to make entities interactive by adding systems that handle user input:\n\n\n\n\nLeveraging Bevy plugins\nHerbert highlighted the power of plugins in Bevy, such as Rapier for physics and Hanabi for particle effects. By adding a few lines, you can integrate complex functionality:\n\n\n\n\nFind the complete code from the livestream in the GitHub repository.\nHerbert Wolverson’s insights showcase the potential of Rust and Bevy for game development. By leveraging Rust’s strict safety features and Bevy’s ECS model, developers can create efficient, high-performance, and safe game applications. Whether you’re a seasoned programmer or new to game development, Bevy provides a robust and flexible framework to bring your game ideas to life. \nAdditional resources:\nFor those looking to delve deeper, Herbert’s books and tutorials are invaluable resources. Stay tuned to our blog for more guides and tutorials on game development with Rust and Bevy. Happy coding!",
        "dc:creator": "Ilia Afanasiev",
        "content": "Disclaimer: This article was created using JetBrains Grazie, an AI-based writing and communication companion. With its help, the core topics of this rich and nuanced livestream were conveniently distilled into a compact blog post format. Game development in Rust is gaining momentum, and Bevy, a modern game engine focusing on Rust, is at the forefront [&#8230;]",
        "contentSnippet": "Disclaimer: This article was created using JetBrains Grazie, an AI-based writing and communication companion. With its help, the core topics of this rich and nuanced livestream were conveniently distilled into a compact blog post format. Game development in Rust is gaining momentum, and Bevy, a modern game engine focusing on Rust, is at the forefront […]",
        "guid": "https://blog.jetbrains.com/?post_type=rust&p=527370",
        "categories": [
          "intellij-rust",
          "livestream",
          "bevy",
          "game-development-in-rust",
          "rustrover"
        ],
        "isoDate": "2024-11-14T14:12:42.000Z"
      },
      {
        "creator": "Richie Mitish",
        "title": "Discover DataGrip 2024.3: New AI Assistant Features and More",
        "link": "https://blog.jetbrains.com/datagrip/2024/11/14/discover-datagrip-2024-3-new-ai-assistant-features-and-more/",
        "pubDate": "Thu, 14 Nov 2024 14:11:40 +0000",
        "content:encodedSnippet": "DataGrip 2024.3 is here! This is the third major update of 2024. Let’s take a look at what it has to offer. For a detailed description of this update, please visit our What’s New page.\nAI Assistant\nSQL query execution error messages now include useful actions for handling the errors with AI Assistant.\n\n\n\n\n\nText-to-SQL now shows a diff in the editor.\nWorking with data\nThe grid paging control can be moved to the bottom of the data editor.\nThe in-editor query results grid now adjusts to the full width of your editor.\n\n\n\n\nCode editor\nDataGrip now automatically highlights all instances of the text you select within a file.\nThe editor can now identify and highlight queries that contain an excessive number of JOIN clauses.\n\n\n\n\n\nFor BigQuery, the editor now properly detects both table-valued functions and their return columns.\nConnectivity\nSmart refresh is now supported for MySQL and MariaDB.\n\n\n\n\nIf you’re interested in upgrading to DataGrip 2024.3, or if you have any questions or suggestions, here are a few links you might find useful:\nDownload DataGrip 2024.3.\nVisit our What’s New page for the full list of improvements.\nContact us on X.\nReport any bugs to our issue tracker.\n\n\n\n\nThe DataGrip team",
        "dc:creator": "Richie Mitish",
        "content": "DataGrip 2024.3 is here! This is the third major update of 2024. Let’s take a look at what it has to offer. For a detailed description of this update, please visit our What’s New page. AI Assistant Working with data Code editor Connectivity If you’re interested in upgrading to DataGrip 2024.3, or if you have [&#8230;]",
        "contentSnippet": "DataGrip 2024.3 is here! This is the third major update of 2024. Let’s take a look at what it has to offer. For a detailed description of this update, please visit our What’s New page. AI Assistant Working with data Code editor Connectivity If you’re interested in upgrading to DataGrip 2024.3, or if you have […]",
        "guid": "https://blog.jetbrains.com/?post_type=datagrip&p=520271",
        "categories": [
          "news",
          "releases",
          "newsletter"
        ],
        "isoDate": "2024-11-14T14:11:40.000Z"
      },
      {
        "creator": "Maha Taqi",
        "title": "Inline AI Prompting, Coding Assistance for the dataclass_transform Decorator (PEP 681), and More in PyCharm 2024.3!",
        "link": "https://blog.jetbrains.com/pycharm/2024/11/pycharm-2024-3/",
        "pubDate": "Thu, 14 Nov 2024 13:42:07 +0000",
        "content:encodedSnippet": "Code smarter, optimize performance, and stay focused on what matters most with the latest updates in PyCharm 2024.3. From enhanced support for AI Assistant and Jupyter notebooks to new features like no-code data filtering, there’s so much to explore. \nLearn about all the updates on our What’s New page, download the latest version from our website, or update your current version through our free Toolbox App.\n\n\n\n    \nDownload PyCharm 2024.3\n                                                    \nKey features of PyCharm 2024.3\nAI Assistant\nInline AI prompting\nGet help with code, generate documentation, or write tests by prompting AI directly in PyCharm’s editor. Just type your request on a new line and hit Enter.\nEdits made by AI are marked in purple in the gutter, so changes are easy to spot. Need a fresh suggestion? Press Tab, Ctrl+/ ( ⌘/ on macOS), or manually edit the purple input text yourself. This feature is available for Python, JavaScript, TypeScript, JSON, YAML, and Jupyter notebooks.\n\n\n\n\nFor a personalized AI chat experience, you can now also choose from Google Gemini, OpenAI, or your own local models. Moreover, enhanced context management now lets you control what AI Assistant takes into consideration. The brand-new UI auto-includes open files and selected code and comes with options to add or remove files and attach project-wide instructions to guide responses across your codebase.\nAbility to convert for loops into list comprehensions\nRefactor your code faster with AI Assistant, which can now help you change massive for loops into list comprehensions. This feature works for all for loops, including nested and while loops.\n\n\n\n\nLocal multiline AI code completion PyCharm Professional\nPyCharm Professional now provides local multiline AI code completion suggestions based on the proprietary JetBrains ML model used for Full Line Code Completion. Note that we don’t use your data to train the model.\n\n\n\n\nLocal multiline code completion typically generates 2–4 lines of code in scenarios where it can predict the next sequence of logical steps, such as within loops, when handling conditions, or when completing common code patterns and boilerplate sections.\nCoding assistance for the dataclass_transform decorator (PEP 681)\nPyCharm now supports intelligent coding assistance for custom data classes created with libraries using the dataclass_transform decorator. Enjoy the same support as for standard data classes, including attribute code completion and type inference for constructor signatures.\n\n\n\n    \nDownload PyCharm 2024.3\n                                                    \nJupyter Notebook PyCharm Professional\nAuto-installation for multiple packages \nPyCharm 2024.3 makes it easier to install packages that are imported in your code. A new quick-fix is available for bulk auto-installations, allowing you to download and install several packages in one click.\n\n\n\n\nAbility to open Jupyter table outputs in the Data View window\nView Jupyter table outputs in the Data View tool window to access powerful features like heatmaps, formatting, slicing, and AI functions for enhanced dataframe analysis. Just click on the Open in Data View icon to get started. \n\n\n\n\nNo-code data filtering \nEffortlessly filter data in the Data View tool window or within dataframes without writing any code. Just click the Filter icon in the upper-right corner, choose your filter options and see results in the same window. This functionality works with all supported Python frameworks, including pandas, Polars, NumPy, PyTorch, TensorFlow, and Hugging Face Datasets.\n\n\n\n\nDebug port specification PyCharm Professional\nPyCharm now allows you to specify a single debugger port for all communications, simplifying debugging in restricted environments like Docker or WSL. After you set the port in the debugger settings, the debugger runs as a server and all communication between it and the IDE flows through the specified port.\n\n\n\n    \nDownload PyCharm 2024.3\n                                                    \nVisit our What’s New page or check out the full release notes for more features and additional details about the features mentioned here. Please report any bugs on our issue tracker so we can address them promptly.\nConnect with us on X (formerly Twitter) to share your thoughts on PyCharm 2024.3. We look forward to hearing from you!",
        "dc:creator": "Maha Taqi",
        "content": "Code smarter, optimize performance, and stay focused on what matters most with the latest updates in PyCharm 2024.3. From enhanced support for AI Assistant and Jupyter notebooks to new features like no-code data filtering, there’s so much to explore.&#160; Learn about all the updates on our What’s New page, download the latest version from our [&#8230;]",
        "contentSnippet": "Code smarter, optimize performance, and stay focused on what matters most with the latest updates in PyCharm 2024.3. From enhanced support for AI Assistant and Jupyter notebooks to new features like no-code data filtering, there’s so much to explore.  Learn about all the updates on our What’s New page, download the latest version from our […]",
        "guid": "https://blog.jetbrains.com/?post_type=pycharm&p=527287",
        "isoDate": "2024-11-14T13:42:07.000Z"
      },
      {
        "creator": "Hanna Yakush",
        "title": "PhpStorm 2024.3 Is Now Available",
        "link": "https://blog.jetbrains.com/phpstorm/2024/11/phpstorm-2024-3-is-now-available/",
        "pubDate": "Thu, 14 Nov 2024 11:26:48 +0000",
        "content:encodedSnippet": "This release is a major update that includes support for PHP 8.4, xdebug_notify(), Pest 3.0, and Pest parallel and mutation testing, and more. If you’re using PhpStorm together with JetBrains AI Assistant, it also got updated with the new AI code completion model, new inline AI prompting, and more.\nDownload PhpStorm 2024.3\n\n\n\n\nPHP 8.4 support\nPhpStorm 2024.3 comes loaded with new inspections and quick-fixes to help you smoothly upgrade to the feature-rich PHP 8.4, set to be released on November 21, 2024. Discover its features in a new video by Brent Roose, our developer advocate:\n\n\n\n\n\n\nBelow is a brief overview of how the new PHP 8.4 features are supported in your PhpStorm workflow. As usual, you can try the new features by setting the project language level to PHP 8.4. You can do so in the language level settings (PHP | PHP Language Level), from the status bar at the bottom of your IDE, or by specifying the requirement in composer.json.\nProperty hooks\nOne of the biggest changes in modern PHP history, property hooks are designed to eliminate boilerplate getters and setters by allowing you to implement get and set hooks for properties.  \nFor property hooks (including the property hooks inside promoted properties), PhpStorm provides:\nA quick-fix for replacing getters and setters with get and set property hooks.\n\n\n\n\n\nAn intention action for adding property hooks to properties.\n\n\n\n\n\nCode completion for the get and set keywords with the insertion of property hook bodies. \n\n\n\n\n\nThe ability to generate get and set hooks for a property via a Generate action similar to Generate | Getters and Setters.\n\n\n\n\n\nAutomatic detection of property hooks that can be converted into their short-hand notations and a quick-fix for converting them.\n\n\n\n\n\nChecks to ensure the proper usage of the property hooks syntax and logic, including:\n\nProperty hook implementation checks in class hierarchies for abstract properties.\nHooked properties that cannot be accessed, read, or written to by reference (&get).\nIncompatible return types in property hooks.\nImproper usage of property hooks with final properties.\nUnused parameters within set property hooks.\nset hook’s parameter type not matching the parameter type declared at the property level. \nIncompatible return types within get hooks.\nDetection of the disallowed readonly hooked properties.\nAsymmetric visibility\nAsymmetric visibility allows a typed property to have separate visibility defined for read and write operations. \nPhpStorm 2024.3 helps ensure the proper implementation of asymmetric visibility scopes in your code by providing checks and quick-fixes for: \nRedundant asymmetric visibility modifiers.\nAttempts to make a property’s set visibility wider than the main (get) visibility.\nRedundant final modifiers for private (set) properties.\nAttempts to narrow property visibility in inherited properties.\nAttempts to modify an asymmetric visibility property outside of the set visibility scope.\n\n\n\n\nNew array functions\nYou can use PhpStorm 2024.3 to convert foreach loops to the newly added array_find(), array_find_key(), array_any(), and array_all() PHP 8.4 functions.\n\n\n\n\nNote that, in PhpStorm, you can run a specific inspection on the project’s whole codebase and apply the fix right from the Problems tool window. Go to Code | Analyze Code | Run Inspection by Name and search for the inspection you need.\n\n\n\n\nnew without parentheses\nPhpStorm 2024.3 supports dropping parentheses around the new expression in constructions of the (new MyClass())->method() type. \n\n\n\n\nYou can view the full list of PHP 8.4 inspections added to PhpStorm in the 2024.3 release by going to Settings | Editor | Inspections and typing “PHP 8.4” in the search field to filter the list.\n\n\n\n\nAI Assistant Plugin\nPlease note that AI Assistant features are only available with an AI Pro subscription or in the trial version. \nTry AI Assistant\nJetBrains’ new code completion model for PHP\nWe’ve significantly improved the quality and reduced the latency of our AI code completion for PHP. These enhancements are powered by Mellum – JetBrains’ new proprietary large language model (LLM) optimized for faster, smarter, and more contextually aware cloud code completion.\nFor more information about JetBrains’ new LLM, see this blog post.\nSyntax highlighting for suggested code\nInline code completion suggestions now come with syntax highlighting, improving their readability.\nIncremental acceptance of code suggestions\nMultiline code suggestions can now be accepted either all at once (by pressing Tab) or incrementally – word by word (Ctrl+→ for Windows or ⌥→ for macOS) or line by line (End for Windows or ⌘Сmd+→ for macOS).\n\n\n\n\nInline AI prompts\nWith new inline AI prompting, AI Assistant now detects and processes requests in natural language as you type them directly in the editor. It instantly interprets the requests and generates suggested code without you having to complete any extra steps. \n\n\n\n\nPhpStorm leaves a purple mark in the gutter next to lines changed by AI Assistant, so you can easily see what has been updated. If you don’t like a suggestion, you can adjust the initial prompt by clicking on the purple block in the gutter or pressing Ctrl+/ (Windows/Linux) or ⌘/ (macOS). \nTitle and description generation for pull and merge requests\nAI Assistant now helps generate accurate titles and descriptions for your pull and merge requests directly from the IDE, streamlining your workflow and ensuring your descriptions are clear and concise.\n\n\n\n\nSQL error handling by AI Assistant\nA couple of useful new actions for handling SQL query execution errors with AI Assistant are accessible in the error message area. Explain with AI opens the AI chat with a prompt automatically sent and AI Assistant’s response with an explanation of the error. The Fix with AI action generates a fix for the query execution error in the editor.\n\n\n\n\n\n\n\n\n\n\n\n\nRead about all the updates to JetBrains AI Assistant.\nTry AI Assistant\nDebugging\nxdebug_notify() support\nTo further enhance your PHP debugging experience, PhpStorm now provides a structured way to handle the output sent from the xdebug_notify() function. \n\n\n\n\nIntroduced in Xdebug 3.1, xdebug_notify() calls allow you to selectively output variables to the debugging console in PhpStorm.\nLaravel ecosystem\nLaravel Herd’s PHP interpreter in PhpStorm\nFor the Laravel developers using Laravel Herd, PhpStorm 2024.3 now automatically detects the path to the currently used Laravel Herd’s PHP executable on your machine. To use this interpreter in PhpStorm, go to the CLI interpreter settings (PHP | CLI interpreter  |  … ), and in the CLI Interpreters dialog that opens, select the PHP executable from the list of pre-configured options. \n\n\n\n\nPest framework enhancements\nPhpStorm 2024.3 significantly improves the Pest testing framework experience for Laravel developers. We’ve implemented full support for Pest 3.0 and the ability to run parallel and mutation tests using Pest right from your IDE.\nMutation testing with Pest 3.0\nThe recently released Pest 3.0 introduced mutation testing, which makes small changes to the code to track whether the tests can catch them. \nYou can trigger Pest’s Run Tests (Pest) with Mutation option in PhpStorm 2024.3 like any other test option – right from the editor, from the Project tool window, or via a run/debug configuration – and use the dedicated Pest Mutation tool window to inspect the test results. \nJust make sure that the PHP interpreter used in your IDE has Xdebug 3.0+ installed as well.\n\n\n\n\nFor details, refer to the PhpStorm documentation.\nParallel testing with Pest\nIn PhpStorm 2024.3, you no longer need to switch to the terminal to run Pest tests in parallel mode. Just navigate to the test file and select Run Tests (Pest) in Parallel from the in-editor gutter icon, from the context menu in the Project tool window, or via a run/debug configuration.\n\n\n\n\nVersion control systems\nResolution of import statement merge conflicts\nPhpStorm can now automatically resolve merge conflicts in import statements. To enable this feature, select the Resolve conflicts in import statements option in the merge dialog under the gear icon, or go to Settings | Tools | Diff & Merge and select Automatically resolve conflicts in import statements.\n\n\n\n\nUpdates to Find in Files\nThe Find in Files feature has been enhanced with a new search scope, Project Files Excluding Git-Ignored. This option excludes any files ignored in .gitignore files from your search results, helping you focus only on the relevant code when searching through your project.\n\n\n\n\nOption to disable background pre-commit checks\nYou can now manage background checks during the commit process with a new Run advanced checks after a commit is done option under Settings | Version Control | Commit. This setting lets you decide if tests and inspections should run after making a commit. If you want these checks to be completed before the commit happens, simply disable it.\n\n\n\n\nBranch name on the Welcome screen\nThe Welcome screen now shows the branch name for projects with the same name, helping you stay organized when handling multiple project versions and allowing you to easily switch between working directories.\n\n\n\n\nDatabase tools\nFragment introspection and smart refresh for MySQL and MariaDB\nPhpStorm now supports fragment introspection. Previously, the introspector could perform only a full introspection of schemas in the MySQL or MariaDB databases but not refresh the metadata of a single object. Every time a DDL statement was executed in the console and that execution could modify an object in the database schema, the IDE would start a full introspection of the entire schema. This was time-consuming and often disrupted the workflow.Now, PhpStorm can analyze a DDL statement, determine which objects could have been affected by it, and refresh only those objects. If you select a single item in Database Explorer and call the Refresh action, only one object will be refreshed, instead of the entire schema as it was before.\nInspection for an excessive number of JOIN clauses\nIn certain cases, running a query that contains an excessive number of JOIN clauses is not recommended due to performance degradation. The editor can now identify and highlight such queries. You can enable this inspection in the IDE settings. To do so, navigate to Editor | Inspections, expand the SQL section, and select Excessive JOIN count.\n\n\n\n\nFloating pagination toolbar\nTo make grid paging more noticeable in our data editor, we have moved the control for it from the toolbar to the bottom center of the data editor.\n\n\n\n\nFrontend\nCleaner search results for directories\nPhpStorm now excludes node_modules results by default when using Find in Files in project directories, reducing clutter from irrelevant files. You can restore the previous behavior by enabling the Search in library files when “Directory” is selected in Find in Files option under Settings | Advanced Settings.\n\nImproved framework component navigation and renaming\nWe’ve enhanced in-editor hints for Vue, Svelte, and Astro components. The Show component usages action now finds usages in both imports and markup templates. We’ve also added a Show Component Usages filter to exclude component usages when searching for regular file references. The Rename refactoring has also been updated with an option to include usages when renaming a component file.\n\n\n\n\nColor preview for Tailwind CSS classes\nThe color preview for Tailwind CSS classes is now shown inline in the editor, making it easier to tell the colors apart. We’ve added support for the textDocument/documentColor method from the Language Server Protocol (LSP), so all LSP-based plugins now offer this functionality out of the box.\n\n\n\n\nImprovements for Angular\nFor projects with Angular 19, PhpStorm now defaults to standalone mode for components, directives, and pipes. Quick-fixes have been added to help convert between standalone and non-standalone components. Unused standalone imports can be automatically removed during code reformatting or via a new inspection. Support for the @let syntax has also been improved.\n\n\n\n\nUI\nHighlighting for all occurrences of selected text \nBy default, PhpStorm will now automatically highlight all instances of the text you select within a file. This makes it easier to track where the selected text appears throughout your code. If you prefer the previous behavior, you can disable this feature in Settings | Editor | General | Appearance.\n\n\n\n\n\n\n\n\n\nYou can find the full list of changes included in PhpStorm 2024.3 on the release notes page.\nDownload PhpStorm 2024.3\nThat’s all for today. We hope you’ll enjoy the latest enhancement to PhpStorm!\nHere are some helpful quick links:\nDownload PhpStorm\nTweet us\nPlease report any bugs to our issue tracker. Your feedback is extremely valuable to us!",
        "dc:creator": "Hanna Yakush",
        "content": "This release is a major update that includes support for PHP 8.4, xdebug_notify(), Pest 3.0, and Pest parallel and mutation testing, and more. If you’re using PhpStorm together with JetBrains AI Assistant, it also got updated with the new AI code completion model, new inline AI prompting, and more. Download PhpStorm 2024.3 PHP 8.4 support [&#8230;]",
        "contentSnippet": "This release is a major update that includes support for PHP 8.4, xdebug_notify(), Pest 3.0, and Pest parallel and mutation testing, and more. If you’re using PhpStorm together with JetBrains AI Assistant, it also got updated with the new AI code completion model, new inline AI prompting, and more. Download PhpStorm 2024.3 PHP 8.4 support […]",
        "guid": "https://blog.jetbrains.com/?post_type=phpstorm&p=523929",
        "categories": [
          "releases",
          "2024-3",
          "release"
        ],
        "isoDate": "2024-11-14T11:26:48.000Z"
      },
      {
        "creator": "Ruslan Akhmetzianov",
        "title": "GoLand 2024.3 Is Out!",
        "link": "https://blog.jetbrains.com/go/2024/11/14/goland-2024-3-is-out/",
        "pubDate": "Thu, 14 Nov 2024 10:41:35 +0000",
        "content:encodedSnippet": "GoLand 2024.3 comes with a set of new features and inspections designed to streamline the developer workflow. For AI users, we’ve refined multiline code completion and added a brand-new inline prompts feature. Startup performance for large projects has also been significantly improved, and we’ve added support for some of the latest (and some upcoming) Go language features, too. Let’s dive right into all the new enhancements!\n      \n        Download GoLand 2024.3\n    \n\n\n\n\n\n\n\n\nNew inspection for cyclic imports: Circular imports can be quite confusing, especially in complex scenarios. And they lead to compilation errors! GoLand 2024.3 comes with an inspection that analyzes dependencies and informs you about cyclic imports before you run go build.\n\n\n\n\nManagement of multiple Go services and configurations in a single UI: To provide the best possible development experience, we’ve implemented a handy UI solution that allows you to run and manage multiple services and configurations in a single subwindow.\n\n\n\n\nFaster opening of larger projects: By migrating dependency data collection to parallel threads, we’ve significantly boosted indexing and project opening speeds. The exact speed gains will vary based on your individual hardware and project configuration, but they can reach 2x to 3x in optimal setups.\nString() object view in debugger: GoLand shows String representation and now renders specific types right in the debugger view.\nEmulate terminal in output console option: Now you can enable terminal emulation for your configurations directly from the Run/Debug tool window. This feature is perfect for CLI applications, as it allows you to view output in a real terminal built in the IDE, enhancing testing and debugging!\nData flow analysis in the Go plugin: Data flow analysis inspections are now available in the Go plugin for IntelliJ IDEA Ultimate.\nNew AI features\nMultiline cloud completion: JetBrains AI Assistant for GoLand 2024.3 introduces significant enhancements to cloud code completion, offering faster and more accurate suggestions. The UX has been reworked to better integrate AI code completion features into IDE workflows, with improvements like syntax highlighting in suggested code and incremental acceptance of code suggestions.\n\n\n\n\nInline AI prompts: In GoLand 2024.3, we’re introducing a new way to interact with AI Assistant – an inline input that detects and processes your requests as you type. This lets you express your intentions in English, which AI Assistant instantly interprets and converts into code changes without any extra steps.\n\n\n\n\nGoLand also inherits updates from IntelliJ IDEA, WebStorm, and DataGrip. Below, we share the most exciting updates:\nKubernetes\nNew resources in the Services view: GoLand 2024.3 brings enhanced control for even more Kubernetes resources in the Services view, including:\nEndpoints\nNetwork policies\nPort forwarding\nContainers in pods\nStreamline your workflow with expanded access to key resources, all from a single interface!\n\n\n\n\nPort forwarding: In GoLand 2024.3 you will be able to easily manage connections to services within your cluster directly from your local IDE. With new management tools for port forwarding, you can now:\nGet a quick overview of active port usage\nStop and reconnect with ease\nRelease ports effortlessly when you’re done using them\nYou no longer need to use ps aux | grep port-forward!\nTerraform and the HCL plugin\nSupport for OpenTofu: OpenTofu is an open-source, community-driven alternative to HashiCorp’s Terraform, which also provides support for .tofu files. This update includes autocompletion for encryption methods, key providers, and inspections for unknown references, making infrastructure-as-code development more efficient and secure.\n\n\n\n\nAdditionally, we’ve added support for modules initialized with OpenTofu, expanding the capabilities of this tool within the IDE.\nTerraform usage indicators: Check out the new quick navigation capabilities, which allow you to see where specific variables, resources, and modules are used. These indicators show the number of usages and their exact locations, enabling you to jump directly to them with a single click. This feature eliminates the need to manually search through files, making it especially useful for navigating large Terraform projects.\n\n\n\n\nThese are just the main highlights. For a complete rundown of the new features, visit our What’s New page.\nWe’d love to hear your feedback on these new features so that we can make them even better. Share your thoughts on X, leave your comments below, create an issue in our tracker, or drop us a message in the #goland-gophers Slack channel. \nHappy developing!",
        "dc:creator": "Ruslan Akhmetzianov",
        "content": "GoLand 2024.3 comes with a set of new features and inspections designed to streamline the developer workflow. For AI users, we’ve refined multiline code completion and added a brand-new inline prompts feature. Startup performance for large projects has also been significantly improved, and we’ve added support for some of the latest (and some upcoming) Go [&#8230;]",
        "contentSnippet": "GoLand 2024.3 comes with a set of new features and inspections designed to streamline the developer workflow. For AI users, we’ve refined multiline code completion and added a brand-new inline prompts feature. Startup performance for large projects has also been significantly improved, and we’ve added support for some of the latest (and some upcoming) Go […]",
        "guid": "https://blog.jetbrains.com/?post_type=go&p=526975",
        "categories": [
          "goland",
          "release"
        ],
        "isoDate": "2024-11-14T10:41:35.000Z"
      },
      {
        "creator": "Alena Guzharina",
        "title": "Datalore On-Premises or Cloud: Which Suits You Best?",
        "link": "https://blog.jetbrains.com/datalore/2024/11/13/datalore-on-premises-or-cloud/",
        "pubDate": "Wed, 13 Nov 2024 17:03:40 +0000",
        "content:encodedSnippet": "In an era where data is the new currency, the ability to quickly gain actionable insights can be a game-changer for businesses and research institutions alike. Shortening the feedback loop between data scientists, analysts, and business intelligence teams can lead to more agile and responsive strategies, ultimately speeding up innovation and optimizing operations. \nJetBrains has always been at the forefront of this challenge, delivering best-in-class tools, including Datalore – the collaborative data science platform for analysts, business teams, and anyone else who needs quicker insights from their data.\nOne of the advantages of Datalore is that it offers two different operational models: On-Premises and Cloud. In this post, we will consider a few advantages of each model and cover the most typical challenges organizations might face when adding a new tool to their daily portfolio.\n\n\n\n\nWhen is Datalore On-Premises preferable?\nDatalore On-Premises is a self-managed installation in the environment of your choice – a private cloud, a public cloud, or even your own bare-metal server.\nWorking with internally hosted data\nMany companies host their databases fully on-premises instead of migrating them offsite. The reasons vary, from compliance factors to cost savings. However, this can lead to a problem. If the data is hosted locally, but the service that needs this data is located somewhere outside of the corporate perimeter, then the data becomes inaccessible to the service. \nThat said, on-premises deployments of data-consuming or processing services are the best solution in cases where you’re working with internally hosted data, as you have full control over the networking and security aspects. This allows you to customize your configuration without jeopardizing any security measures your organization has in place.\nExtended compliance requirements\nConsidering the nature of your data is important when choosing the right tool for processing it, as specific industries may impose additional requirements for data handling systems. \nFor example, if a US-based organization wants to process health-related data, compliance with HIPAA (the Health Insurance Portability and Accountability Act) is required, while compliance with PCI DSS is necessary in the global financial sector. These requirements are often eventually mandated by law or industry standards to apply to both the product and the organization as a whole.\nIn certain cases, as long as the data doesn’t leave the organizational perimeter, the product itself doesn’t have to undergo the whole process of vetting, testing, and certification by an independent third-party authority, like the Office for Civil Rights or the National Institute of Standards and Technology. \nIf you work in a context with extensive compliance standards, on-premises deployment is preferable. Otherwise, your choice of tool vendor becomes significantly limited, as both the tool and the vendor need to be in compliance and hold the necessary certifications, which are expensive and difficult to obtain.\nJetBrains is committed to maintaining the highest level of security when it comes to our data. An annual review by our external auditors recently confirmed our SOC 2 Type II compliance status.\nSpecific environment requirements\nAnother case where on-premises installations are particularly suitable is when there’s a high demand for customization, which is often something that SaaS platforms either can’t provide or can only provide in a limited capacity.\nHere’s a story from one Datalore customer who decided to go with an on-premises deployment:\n\nBy using Datalore On-Premises, we can customize the environment using Linux shell scripts built into the agent image used by Datalore. We can also install our own packages using pip, Poetry, dependency files, and more without any restrictions. This reduces the environment bootstrapping time, which is essential for us as a fast-paced team.\n      \n      Get Datalore On-Premises demo\n    \n\n\n\n\nWhen is Datalore Cloud preferable?\nDatalore Cloud is our software-as-a-service offering, managed and operated by JetBrains.\nNo-ops strategy\nDepending on your organizational goals and priorities, it may make more sense to completely avoid having anything on-premises, including servers and data storage. Instead, you can use managed services by various cloud providers, allowing you to focus on your daily tasks rather than worrying about infrastructure management.\nDatalore Cloud is particularly advantageous for organizations following a no-ops strategy because it eliminates the need for dedicated IT staff to manage hardware or software updates. Additionally, its extensive list of machines provides workload scaling capabilities, ensuring optimal performance as data workloads grow and reducing your organization’s operational burden.\nStarting your data journey\nWhen a team begins a project, they usually need to choose their infrastructure and tooling, a process that can be lengthy enough to have a visible impact on their timeline.\nDatalore Cloud speeds this process along because the only thing you need to start using it for data exploration is your browser. It also comes with a no-commitment 14-day free trial, allowing you to easily determine whether it meets your needs.\nOnce you’ve signed up for Datalore Cloud, you’re ready to explore your data immediately. With any of the paid Datalore Cloud tiers, you get 750 hours of computation time using 4 vCPUs and 16 GB of RAM (2 vCPUs and 4 GB of RAM for free tier users). We’ve found that these resources are sufficient in about 90% of cases, but if you need more, you can scale up with just a single click. Datalore Cloud has an extensive list of machine options that will suit even the most demanding users.\nFlexibility\nYour company’s tooling landscape can change rapidly, as your business requirements evolve together with your team. Because of this, it may not be wise to commit to the fixed, long-term seat capacity offered by Datalore On-Premises. \nFor Datalore Cloud, you have more flexibility in terms of seat capacity adjustments, with an option to scale your team’s capacity based on demand and your current requirements. Additionally, having the flexibility to choose between monthly and discounted annual commitments is a plus.\nAnother important aspect in choosing between the deployment models is the pricing structure. On-premises solutions typically carry an infrastructure setup burden, both on hardware and people, that increases its total cost of ownership.\nGiven the above, Datalore Cloud might be more beneficial if you have a demand for computation-intensive tasks but you either don’t have the expensive hardware required or don’t want to invest heavily into it. In that case, Datalore Cloud offers state-of-the-art environments prepared with all of the necessary resources at a fraction of what the hardware would cost.\n      \n      Try Datalore Cloud 14 days for free\n    \n\n\n\n\nI hope this article helped you get a better idea of which key factors to consider when deciding between on-premises and cloud computing for your business needs. \nIf you have any remaining questions, do not hesitate to schedule a call. We’d be happy to discuss your specific requirements in more detail.",
        "dc:creator": "Alena Guzharina",
        "content": "In an era where data is the new currency, the ability to quickly gain actionable insights can be a game-changer for businesses and research institutions alike. Shortening the feedback loop between data scientists, analysts, and business intelligence teams can lead to more agile and responsive strategies, ultimately speeding up innovation and optimizing operations.&#160; JetBrains has [&#8230;]",
        "contentSnippet": "In an era where data is the new currency, the ability to quickly gain actionable insights can be a game-changer for businesses and research institutions alike. Shortening the feedback loop between data scientists, analysts, and business intelligence teams can lead to more agile and responsive strategies, ultimately speeding up innovation and optimizing operations.  JetBrains has […]",
        "guid": "https://blog.jetbrains.com/?post_type=datalore&p=526021",
        "isoDate": "2024-11-13T17:03:40.000Z"
      },
      {
        "creator": "Maciej Gorywoda",
        "title": "IntelliJ Scala Plugin 2024.3 Is Out!",
        "link": "https://blog.jetbrains.com/scala/2024/11/13/intellij-scala-plugin-2024-3-is-out/",
        "pubDate": "Wed, 13 Nov 2024 15:40:41 +0000",
        "content:encodedSnippet": "Scala 3 support\nTransparent inline methods (experimental)\nTransparent inline methods in Scala 3 allow the compiler to reinterpret the method being inlined in the context of information known already at the compile time. Our support of this feature is still experimental and requires more work, but what we offer in this release already covers the most popular use cases. For example, when a transparent inline method serves as an entry point to a library that uses macro, you will now get much more information about the inferred types than before:\n\n\n\n\n\n\n\n\n\nFiguring out the result type of a transparent inline method call can often be quite complicated. To do this, we rely on the type information returned by the compiler, meaning that this feature is available only with Compiler-Based Highlighting. To enable the support for transparent inline methods in IntelliJ IDEA, go to Settings | Languages & Frameworks | Scala | Editor, ensure that the error highlighting mode is set to Compiler (as is the default for Scala 3), and check “Use types reported by the Scala compiler (experimental)”.\nWe are still working on many improvements to this feature. We encourage you to try it out and let us know your thoughts. Your feedback is very valuable to us.\nNamed tuples\nIntelliJ IDEA 2024.3 fully supports named tuples, a new experimental feature in Scala 3.5 that will become a standard feature in Scala 3.6. As the title suggests, named tuples allow you to name the components of a tuple so that they can be accessed with readable names.  On top of that, the compiler can infer the types of fields based on the assigned values.\nAs we move towards Scala 3.6, named tuples will become an integral part of the Scala language, and we are proud to say that the IntelliJ Scala Plugin has supported them from day one.\n\n\n\n\n\nOpaque type aliases\nAdditionally, IntelliJ IDEA is now better at recognizing opaque type aliases. We already recognized the opaque keyword, but in practice, IntelliJ IDEA has handled opaque type aliases just like standard (i.e., transparent) type aliases. Since the current release, they are treated as abstract types, meaning their underlying definitions are hidden from the outside code.\n\n\n\n\n\nScala CLI\nIntelliJ IDEA 2024.3 introduces improved support for Scala CLI projects. When you open a folder containing a project.scala file, the plugin automatically recognizes it as a Scala CLI project. Additionally, the new release provides a convenient way to create new Scala CLI projects through the New Project wizard. And, when you do this, you can add new Scala files to the project, just as you can for sbt-based projects. This makes it easier than ever to start developing Scala CLI applications in IntelliJ IDEA.\n\n\n\n\n\nMore improvements to Compiler-Based Highlighting\nOn top of the support for transparent inline methods, the new release comes with faster and more reliable Compiler-Based Highlighting.  We reduced the number of cases when multiple compilations were necessary, e.g., in situations where refactorings that affect multiple files result in many compilation requests. IntelliJ IDEA analyzes and batches these requests in the new release and then issues a single request with a broader compilation scope. This reduces CPU resource utilization and optimizes the compiler’s highlighting experience. We’ve also fixed some edge cases where duplicated parser errors are shown, both from the IDEA Scala parser and the compiler.\n\n\n\n\nNew project model for sbt projects (beta)\nWe’re introducing a new mode that better represents the structure of sbt projects in IntelliJ IDEA by organizing main and test sources into separate modules. The improved layout resolves several issues with compilation and highlighting and allows the use of distinct compiler options for main and test sources.\nThis feature is currently in “beta”. We strongly encourage you to try it out and share your feedback! Enable it via Settings | Build, Execution, Deployment | Build Tools | sbt and select “Create separate modules for production and test sources”.\n\n\n\n\nStay tuned for a blog post we plan to publish soon, describing this new feature in detail!\nThe debugger\nIn the debugger, we now support the new encoding of lazy vals introduced in Scala 3.3, and we reintroduced the “Initialize” button for lazy vals.\n\n\n\n\n\nAI Assistant\nCompleting just one line of code quite often is not enough, so since the new release, we have made multiline cloud-based code completion available for Scala. To enable it, go to Settings | Editor | General | Inline Completion, scroll down, and check “Enable cloud completion suggestions” if it’s not checked already. On the list below, check Scala.\n\n\n\n\nAs you can see in the following short video, if the AI Assistant decides it can reliably guess the following lines of code you want to write, it will propose the whole chunk. To do it, though, the AI Assistant requires a connection to the server – the local model can still only propose one-line completions – so be sure you can use it.\nThe AI Assistant comes with many other features that can help you in your work. You can read about them here.\n\n\n\n\n\nOther improvements\nWe improved the IDE performance and fixed certain bugs that led to the UI freezing. This happened sometimes during refactorings and actions, e.g., when you extended a Java interface in Scala and requested IntelliJ IDEA implement the new class members. In some other cases, when the action actually needs some time, a progress bar will be shown.\nAlso, if you open Run | Edit Configurations…, you will notice that the “Environment variables” field now accepts .env files. All Scala-related run configurations (Scalatest, MUnit, Specs2, uTest, Play Framework, SBT, and Scala REPL) can now read environment variables directly from an .env file – a popular format for storing environment-specific configuration variables as key-value pairs. This feature was implemented with help from the Scala community members. \n\n\n\n\n\nAs always, your feedback is very welcome. Please report any issues you find to YouTrack. If you have any questions, feel free to ask us on Discord.\nHappy developing!\nThe IntelliJ Scala Plugin team",
        "dc:creator": "Maciej Gorywoda",
        "content": "Scala 3 support Transparent inline methods (experimental) Transparent inline methods in Scala 3 allow the compiler to reinterpret the method being inlined in the context of information known already at the compile time. Our support of this feature is still experimental and requires more work, but what we offer in this release already covers the [&#8230;]",
        "contentSnippet": "Scala 3 support Transparent inline methods (experimental) Transparent inline methods in Scala 3 allow the compiler to reinterpret the method being inlined in the context of information known already at the compile time. Our support of this feature is still experimental and requires more work, but what we offer in this release already covers the […]",
        "guid": "https://blog.jetbrains.com/?post_type=scala&p=523404",
        "categories": [
          "news",
          "releases",
          "scala",
          "scala-programming",
          "intellij-idea"
        ],
        "isoDate": "2024-11-13T15:40:41.000Z"
      },
      {
        "creator": "Anna Ruban",
        "title": "Share Your Insights on Using Rider and Win a Prize!",
        "link": "https://blog.jetbrains.com/dotnet/2024/11/13/share-your-insights-on-using-rider-and-win-a-prize/",
        "pubDate": "Wed, 13 Nov 2024 15:38:40 +0000",
        "content:encodedSnippet": "We’re excited to invite you to participate in our research study, which will be an informal interview. In it, we’ll ask you about your workflows, your experiences with Rider, the challenges you typically encounter, and your aspirations, as this will help us tailor our solutions to better meet the needs of developers like you.\n\n\n\n\nThe interview will last no more than one hour and will be conducted in English. \nAs a token of our appreciation for your time and insights, you’ll receive your choice of either a USD 100 Amazon Gift Card or a one-year JetBrains All Products Pack subscription.\nReady to make an impact? Sign up for our study by clicking the button in this email and taking our short survey. If your profile matches our study criteria, we will follow up with an invitation via email.\nTake a survey\n                                                    \nKind regards,\nThe JetBrains team",
        "dc:creator": "Anna Ruban",
        "content": "We’re excited to invite you to participate in our research study, which will be an informal interview. In it, we’ll ask you about your workflows, your experiences with Rider, the challenges you typically encounter, and your aspirations, as this will help us tailor our solutions to better meet the needs of developers like you. The [&#8230;]",
        "contentSnippet": "We’re excited to invite you to participate in our research study, which will be an informal interview. In it, we’ll ask you about your workflows, your experiences with Rider, the challenges you typically encounter, and your aspirations, as this will help us tailor our solutions to better meet the needs of developers like you. The […]",
        "guid": "https://blog.jetbrains.com/?post_type=dotnet&p=525878",
        "categories": [
          "net-tools",
          "survey",
          "net",
          "rider"
        ],
        "isoDate": "2024-11-13T15:38:40.000Z"
      },
      {
        "creator": "Maria Kosukhina",
        "title": "IntelliJ IDEA 2024.3 Is Out!",
        "link": "https://blog.jetbrains.com/idea/2024/11/intellij-idea-2024-3/",
        "pubDate": "Wed, 13 Nov 2024 15:36:09 +0000",
        "content:encodedSnippet": "IntelliJ IDEA 2024.3, our final major release of the year, is here! This update brings a range of new features and enhancements across the IDE to improve your daily development workflows.\nYou can download this version from our website, update directly from within the IDE, use the free Toolbox App, or install it via snap packages for Ubuntu.\nDownload IntelliJ IDEA 2024.3\nKey highlights include a visual representation of your code’s logical structure in the Structure tool window, a smoother debugging experience for Kubernetes applications, and cluster-wide Kubernetes log access. This version also moves K2 mode out of Beta.\nWatch our video overview to see these improvements in action!\n\n\n\n\n\n\nThis blog post lists dozens of additional enhancements in version 2024.3. For a full list of new features with short demos, visit our What’s New page. \nHighlights \nThe Structure tool window now includes a Logical code structure alongside the familiar Physical structure. This allows you to view not only classes, methods, and fields but also the links and interactions between components in your project. \nWe’ve made debugging Kubernetes applications even easier. You can use the Add Tunnel for Remote Debug option to make your workstation a virtual part of the Kubernetes cluster, allowing you to swap in a pod and debug microservices locally with your preferred tools. \nIntelliJ IDEA now offers cluster-wide Kubernetes log access with streaming and pattern matching. This feature provides a centralized view of all events across pods, nodes, and services, helping you quickly identify issues without manually checking each log. \nK2 mode has officially moved out of Beta and is now Stable and ready for general use. \nAI Assistant\nIntelliJ IDEA 2024.3 introduces context-aware inline AI prompts, offering a seamless way to interact with AI Assistant directly in the editor. This feature supports Java, Kotlin, Scala, Groovy, JavaScript, TypeScript, Python, JSON, and YAML file formats.\nAI Assistant now offers simplified context management with an updated UI, making it easy to view, manage, and customize files, code selections, and project-wide instructions.\nYou can now select your preferred AI chat model, choosing from Google Gemini, OpenAI, or local models on your machine.\n\n\n\n\nLearn more about these updates in this blog post. All these features, along with the AI-powered enhancements mentioned below, are available with an active AI Assistant subscription.\nJava and Kotlin \nIn version 2024.3, IntelliJ IDEA’s data flow engine handles aliasing cases more accurately, leading to fewer false positives in inspections and a more reliable Java and Kotlin coding experience. \nIntelliJ IDEA’s code formatter features a new setting that allows you to retain blank lines between annotations and field declarations.\nWith K2 mode enabled, IntelliJ IDEA supports using non-local break and continue statements inside lambdas, as well as multi-dollar interpolation – experimental language features of Kotlin 2.1.\nScala\nVersion 2024.3 improves IntelliJ IDEA’s Scala 3 support, allowing you to use compiler-based type inference for transparent inline method calls and providing full support for named tuples. Additionally, IntelliJ IDEA is better at recognizing opaque types.\nThe IDE now recognizes Scala CLI projects when you open a folder with a project.scala file. You can also create new BSP-based Scala CLI projects via the New Project wizard and add Scala files, just like you do for sbt-based projects.\nWe’ve optimized compiler-based highlighting by reducing redundant compilation requests, resulting in better CPU efficiency, and we’ve resolved issues causing duplicated parser errors from both the parser and compiler.\nIntelliJ IDEA’s project model now represents sbt projects more accurately, separating production and test sources into distinct modules. This feature is currently in Beta.\nUser experience\nIn version 2024.3, spelling and grammar checks are accessible even while indexing is in progress. \nThe updated Run widget lets you launch multiple configurations simultaneously. Additionally, the widget displays controls for all running configurations, providing a clear overview of their statuses.\nWe’ve increased the default tab limit in the editor to 30, so you can now keep more tabs open before the IDE starts closing the ones used least recently. \nWe’ve optimized the placement of the Rename action in the context menu when called on elements in the editor and the Project tool window, making it more accessible at the top level. \nIntelliJ IDEA now automatically highlights all instances of any text you select within a file. \nWe’ve added dedicated icons for messages and i18n files to make them easier to identify.\nThe New popup for adding files to Java source roots now displays only the most relevant options, reducing clutter and streamlining your workflow.\nWe’ve enabled the floating toolbar for JSON, XML, YAML, and SQL files for easy access to context-based and AI-driven actions.\nTerminal\nThe new terminal (Beta) now offers faster command processing and completion, seamless session switching, and new customization options for prompt styles, session names, and environment variables for a smoother, more responsive experience. We’ve also updated the UI with a more compact design, reducing padding to maximize your screen real estate. \nVersion control systems \nIn version 2024.3, it is possible to commit specific changes directly from the editor. \nAI Assistant now helps generate accurate titles and descriptions for your pull and merge requests.\nThe Find in Files feature has been enhanced with a new Project Files Excluding Git-Ignored search option.\nYou can now control background checks during the commit process with a new Run advanced checks after a commit is done setting.\nThe Welcome screen now shows the branch name.\nDebugger\nThe HotSwap feature is now easier and more intuitive to use. When you edit code with an active debugger session, the IDE automatically detects the changes and prompts you to reload them via a convenient button in the editor. \nA new intention action allows you to set exception breakpoints from the editor without opening the Breakpoints dialog or browsing the stack trace in the console.\nYou can now measure execution time for multiple lines by using the Run to Cursor action, and each line’s execution time will be displayed directly in the editor’s gutter.\nIntelliJ IDEA 2024.3 now prints a merged stack trace, addressing the challenges of troubleshooting asynchronous code.\nBuild tools\nThe IDE now supports Maven’s split local repositories – a feature introduced in Maven 3.9 that allows you to separate local repositories according to your needs. \nWe’ve made parallel compilation the default in IntelliJ IDEA 2024.3. Now, you will see faster compilation times for all Maven-based projects compiled by the IDE, with optimized CPU and memory consumption. \nIntelliJ IDEA now automatically detects SSL issues during Maven syncs and builds, prompting you to accept untrusted certificates when necessary.\nThe first public EAP release of our new Bazel plugin for IntelliJ IDEA is now available. The plugin currently lets you open Bazel projects for Java and Kotlin, supports building, testing, running, and debugging Bazel targets, and offers Starlark syntax, completion, navigation, and debugging support.\n\n\n\n\nThe features and enhancements in version 2024.3 that are designed to facilitate work with frameworks, technologies, and databases, as well as the updates for profiling and web development, are accessible in IntelliJ IDEA Ultimate only.\nProfiler\nThe profiler now displays a heap memory usage graph above the thread lanes in the Timeline tab. \nFrameworks and technologies\nIntelliJ IDEA can now automatically generate derived query methods in Spring Data repositories, suggesting possible method names, providing the correct method signatures and return types, and updating repository code for you.\nVersion 2024.3 introduces the ability to access environment variables directly within the HTTP Client using the $env.ENV_VAR syntax.\nIn the HTTP Client, it is now possible to import and run requests – either all at once or specific ones by name – from one .http file to another.\nKtor 3.0, a toolkit for building server applications on the JVM with Kotlin, is out with new features and improved performance. Learn more.\nWe’ve greatly simplified the experience of debugging GraalVM native images with Docker containers, which means you can now build and debug native Java applications on any platform. \nDev Container builds now operate more smoothly on remote Docker engines, support for features is more consistent, and setting management for Dev Containers has been streamlined for improved efficiency.\nWe’ve added support for new Docker Compose attributes that give you better control over builds, resource management, service orchestration, and networking within Docker Compose.\nThis release introduces support for OpenTofu and greatly extends support for Terraform. \nWe continue to improve the reliability of projects that are hosted in the Windows Subsystem for Linux (WSL) and opened by developers from Windows in the IDE.\nKubernetes\nThe IDE now offers support for network policies, which are used to manage network traffic between pods in a cluster. \nWeb development\nWhen you use Find in Files in project directories, node_modules results are now excluded by default, reducing clutter from irrelevant files. \nWe’ve improved component navigation and renaming for Vue, Svelte, and Astro frameworks.\nIntelliJ IDEA provides greater support for Angular 19 projects.\nDatabase tools\nWhen you use AI Assistant for text-to-SQL tasks, the IDE now presents a handy in-editor diff, displaying both the original and AI-generated code for easy comparison.\nAI Assistant is now more helpful for handling SQL execution errors, offering two new actions – Explain with AI and Fix with AI.\nIntelliJ IDEA now supports fragment introspection and offers smart refresh for MySQL and MariaDB databases. \nA new inspection for an excessive number of JOIN clauses can be enabled from the IDE settings. \nTo make grid paging more noticeable in the data editor, we have moved the control for it from the toolbar to the bottom center of the data editor.\nOther \nLinux users should note that, as of version 2024.3, global menu support has been discontinued in IntelliJ IDEA.\n\n\n\n\nThese are the key improvements introduced in IntelliJ IDEA 2024.3. For a complete list of changes, please refer to the release notes.\nWe welcome your feedback on the new features and enhancements. Connect with us on X or leave a comment below. If you come across any bugs while using the IDE, please report them to our issue tracker.\nHappy developing!",
        "dc:creator": "Maria Kosukhina",
        "content": "IntelliJ IDEA 2024.3, our final major release of the year, is here! This update brings a range of new features and enhancements across the IDE to improve your daily development workflows. You can download this version from our website, update directly from within the IDE, use the free Toolbox App, or install it via snap [&#8230;]",
        "contentSnippet": "IntelliJ IDEA 2024.3, our final major release of the year, is here! This update brings a range of new features and enhancements across the IDE to improve your daily development workflows. You can download this version from our website, update directly from within the IDE, use the free Toolbox App, or install it via snap […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=523712",
        "categories": [
          "releases",
          "2024-3",
          "intellij-idea-2024-3"
        ],
        "isoDate": "2024-11-13T15:36:09.000Z"
      },
      {
        "creator": "Oleg Zinovyev",
        "title": "CLion 2024.3 Release Candidate Is Out",
        "link": "https://blog.jetbrains.com/clion/2024/11/2024-3-release-candidate/",
        "pubDate": "Wed, 13 Nov 2024 15:34:06 +0000",
        "content:encodedSnippet": "The next major CLion release is approaching, and the v2024.3 Release Candidate (RC) is already available. \n\n\n\n\nYou can download build 243.21565.198 from the link below, via the Toolbox App, or as a snap package if you’re using Ubuntu. You need an active subscription or a trial license to use the CLion 2024.3 RC.\nDOWNLOAD CLION 2024.3 RC\nWe’d like to thank all those who tested the IDE updates during the Early Access Program, gave us feedback, and helped polish the new features. Your contribution is invaluable to us.\nIf you’re unfamiliar with the key improvements coming in v2024.3, please read the previous blog post.\nSeveral bugs have been fixed in v2024.3 RC, including the following: \nAI Assistant now consistently responds to prompts.\nActive AI Assistant Pro licenses no longer falsely expire.\nUI freezes caused by deadlocks in InputContext no longer occur.\n\n\n\n\nRead the full release notes on YouTrack. Try this build and help us improve CLion by reporting any problems you find to our issue tracker. The final release is coming soon, so keep your eyes peeled!\nYour CLion team\nJetBrains\nThe Drive to Develop",
        "dc:creator": "Oleg Zinovyev",
        "content": "The next major CLion release is approaching, and the v2024.3 Release Candidate (RC) is already available. You can download build 243.21565.198 from the link below, via the Toolbox App, or as a snap package if you’re using Ubuntu. You need an active subscription or a trial license to use the CLion 2024.3 RC. DOWNLOAD CLION [&#8230;]",
        "contentSnippet": "The next major CLion release is approaching, and the v2024.3 Release Candidate (RC) is already available. You can download build 243.21565.198 from the link below, via the Toolbox App, or as a snap package if you’re using Ubuntu. You need an active subscription or a trial license to use the CLion 2024.3 RC. DOWNLOAD CLION […]",
        "guid": "https://blog.jetbrains.com/?post_type=clion&p=526231",
        "categories": [
          "eap",
          "news",
          "2024-3",
          "release-candidate"
        ],
        "isoDate": "2024-11-13T15:34:06.000Z"
      },
      {
        "creator": "Anna Zykova",
        "title": "RubyMine 2024.3: Rails 8 Support, Inline AI Prompts, Integration With RBS Collection, Ruby 3.4 Updates",
        "link": "https://blog.jetbrains.com/ruby/2024/11/rubymine-2024-3-rails-8-support/",
        "pubDate": "Wed, 13 Nov 2024 14:17:20 +0000",
        "content:encodedSnippet": "RubyMine 2024.3 is now available!\nThe latest version of JetBrains’ IDE for Ruby and Ruby on Rails comes with Rails 8 support, including Kamal 2 code completion, nilability annotations from schema.rb for type support, and Solid Queue and Solid Cache code insights. \nEnhanced by JetBrains AI Assistant, RubyMine now offers faster and more contextually aware cloud-based code completion, inline AI prompts, and more context about Rails applications for unit test generation. \nWith built-in integration with the RBS Collection, you can benefit from the type signatures included in the RBS Collection even if you don’t use RBS in your project. RubyMine 2024.3 also includes Ruby 3.4 updates, bundled spelling and grammar checks from Grazie, and much more!\nBelow is a brief overview of the most notable features. For a detailed description of this update, please visit our What’s New page.\nYou can get the new build from our website or via the free Toolbox App.\nRails 8 support\nKamal 2 support\nRails 8 provides support for deploying your applications with Kamal 2, and in RubyMine 2024.3, we’ve implemented code completion for Kamal 2 configurations.\n\n\n\n\nNilability annotations from schema.rb for type support\nRubyMine now recognizes the not-null type modifier for migration attributes and provides highlighting and warnings for incorrect nil assignments.\n\n\n\n\nCode insight for Solid Queue and Solid Cache\nIn RubyMine 2024.3, queue_schema.rb and cache_schema.rb files now feature specific icons and syntax highlighting.\n\n\n\n\nAI Assistant\nEnhanced cloud-based code completion\nRubyMine 2024.3 introduces faster and more contextually aware cloud-based code completion through the JetBrains AI Assistant plugin, featuring quality and speed improvements and adding support for multiline completion.\nPowered by the Mellum large language model (LLM), completion latency has been nearly cut down to one-tenth of what it was in previous versions, which means suggestions are almost instant. The acceptance rate for completion suggestions has approximately doubled, while the cancel rate has dropped to between half and a third of what it was in the previous version.\nPlease note that cloud-based code completion in AI Assistant is available only with an AI Pro subscription or an active free trial.\nInline AI prompts\nRubyMine 2024.3 introduces inline AI prompts, offering a seamless way to interact with AI Assistant directly in the editor. You can type requests in natural language, which AI Assistant instantly interprets and converts into code changes, marked with purple in the gutter for easy tracking. Inline AI prompts are context-aware, automatically including related files and symbols for more accurate code generation.\nThis feature is currently only available in *.rb files.\n\n\n\n\nImproved Rails context for unit tests\nRubyMine now provides AI Assistant with more context about Rails applications for better unit test generation.\nBuilt-in integration with the RBS Collection\nRubyMine now features built-in integration with the RBS Collection, a community-managed collection of RBS files for gems that do not include signatures.\nEven if you don’t use RBS in your project, you can still benefit from the type signatures included in the RBS Collection, with no additional effort required. RubyMine will automatically download and manage the type signatures for the project dependencies.\n\n\n\n\nAbility to use it as an alias for numbered parameters in blocks\nRubyMine now recognizes it as an alias for _1 in blocks without parameters, providing type support and conversion intentions for such usages.\nWe added a new error annotation that prevents you from using it in a block with regular numbered parameters.\n\n\n\n\nSupport for Ruby 3.4 “chilled” strings\nRubyMine now recognizes “chilled” strings, a new transitional state for string literals in Ruby 3.4. In projects without the frozen_string_literal pragma, strings are “chilled”. A “chilled” string will output a warning when modified; unlike a frozen string, it will not throw an error.\n\n\n\n\nError annotations for ambiguous anonymous arguments\nRubyMine now displays an error when you try to use anonymous block, rest, and keyword rest arguments in an ambiguous nested context.\n\n\n\n\nBundled spelling and grammar checks\nThe Grazie plugin is now available in RubyMine out of the box. It provides intelligent checks beyond simple spelling mistakes and typos. It understands grammar rules and can warn you about inappropriate style. Grazie checks are available in strings, HereDocs, comments, block comments, and RDoc files. \n\n\n\n\nYou can manage Grazie checks in Settings | Editor | Natural Languages | Grammar and Style | Scope.\n\n\n\n\nTo learn about the newest features as they come out, please follow RubyMine on X. \nWe invite you to share your thoughts in the comments below and to suggest and vote for new features in the issue tracker.\nHappy developing!\nThe RubyMine team",
        "dc:creator": "Anna Zykova",
        "content": "RubyMine 2024.3 is now available! The latest version of JetBrains’ IDE for Ruby and Ruby on Rails comes with Rails 8 support, including Kamal 2 code completion, nilability annotations from schema.rb for type support, and Solid Queue and Solid Cache code insights.&#160; Enhanced by JetBrains AI Assistant, RubyMine now offers faster and more contextually aware [&#8230;]",
        "contentSnippet": "RubyMine 2024.3 is now available! The latest version of JetBrains’ IDE for Ruby and Ruby on Rails comes with Rails 8 support, including Kamal 2 code completion, nilability annotations from schema.rb for type support, and Solid Queue and Solid Cache code insights.  Enhanced by JetBrains AI Assistant, RubyMine now offers faster and more contextually aware […]",
        "guid": "https://blog.jetbrains.com/?post_type=ruby&p=523767",
        "categories": [
          "releases",
          "rubymine",
          "release",
          "rubymine-2024-3"
        ],
        "isoDate": "2024-11-13T14:17:20.000Z"
      }
    ]
  },
  {
    "name": "Airbnb Engineering & Data Science",
    "category": "기업",
    "posts": [
      {
        "creator": "Pei Xiong",
        "title": "Airbnb’s AI-powered photo tour using Vision Transformer",
        "link": "https://medium.com/airbnb-engineering/airbnbs-ai-powered-photo-tour-using-vision-transformer-e470535f76d4?source=rss----53c7c27702d5---4",
        "pubDate": "Wed, 13 Nov 2024 17:39:08 GMT",
        "content:encodedSnippet": "Boosting computer vision accuracy and performance at Airbnb\n\nBy: Pei Xiong, Aaron Yin, Jian Zhang, Lifan Yang, Lu Zhang, Dean Chen\nIntroduction\nIn recent years, the integration of artificial intelligence with travel platforms has transformed how people search for and book accommodations. As a leading global marketplace for unique travel experiences and accommodations, Airbnb constantly strives to enhance the guest experience by providing informative content about the variety of homes shared by our hosts. One of the ways we help guests better understand what a listing offers before they book is through our AI-powered photo tour feature.\nThe AI-powered photo tour in the Listings tab, which helps hosts better organize their listing photos, leverages vision transformers’ fine-tuned feature to assess a diverse set of listing images and accurately identify and classify photos based into specific rooms and spaces. In this blog post, we will dive into the inner workings of the photo tour including model selection, pretraining, fine-tuning techniques, and the trade-offs between computational costs and scalability. We will also specifically discuss how we enhanced model accuracy despite having limited training data.\nFigure 1: Photo Tour product powered by ML\nMethodology\nRoom Classification\nRoom-type classification is the first aspect of the photo tour, The goal of room classification is to accurately categorize images into 16 different room types designed in the Airbnb product such as ‘Bedroom’, ‘Full bathroom’, ‘Half bathroom’, ‘Living room’, and ‘Kitchen’, providing users with a comprehensive understanding of the available spaces. The challenge lies in the diversity of room layouts, lighting conditions, and the need for models that can generalize well across various environments.\nWe conducted experiments using several state-of-the-art models, including Vision Transformer (ViT) variants — ViT-base, ViT-large and different resolutions. Additionally, we explored the performance of ConvNext2, a recently proposed convolutional neural network with comparable performance to ViT, and MaxVit, a variant combining the strengths of both Vision Transformers and CNNs. At the beginning of this project, we tested these approaches on an image classification task with Airbnb’s host-provided data, and found that ViT outperforms the other approaches. Thus we chose ViT in our following studies.\nImage Similarity\nAnother key component of photo tour is image clustering, which groups the images of the same room into a cluster. A prerequisite of that is the ability to measure the similarity between two images, which indicates the probability that the two images belong to the same room. This is a supervised classification problem, with the input being two images, and the output being a binary label of 0 or 1. As shown in Figure 2, We employed a Siamese network that simultaneously processes two images, by applying the same image embedding model to each image, and subsequently computing the cosine similarity of the resulting embeddings.\nFigure 2: An illustration of Siamese network for image similarity\nAccuracy Improvement\nOur analysis found that the volume of training data is key to higher prediction accuracy. Doubling the training data volume typically leads to a reduction of error rate of ≈5% on average, with the effect being more significant in the earlier stages.\nFigure 3: correlation between data volume and accuracy\nUnfortunately, it is very expensive to acquire high-quality training data as it requires human labeling. Therefore, we needed to find other ways to improve model accuracy with a limited amount of training data. We followed these steps to improve model accuracy:\nStep 1 — Pre-training: We started from a pre-trained model on ImageNet. We took that model and trained it with a large amount of host-provided data, which has lower accuracy and only covers some of our class labels. This provided a baseline model for transfer learning in the following steps.\nStep 2 — Multi-task training: We fine-tuned the model from the previous step using both higher-accuracy training data for the target task (e.g., room-type classification), and an additional type of training data that has been labeled for another related task (e.g., object detection). This provided additional training data and created multiple different models for future steps.\nStep 3 — Ensemble learning: We created an ensemble from multiple models in Step 2, which was achieved through training with different auxiliary tasks, and by using different versions of ViTs (e.g., ViT-base vs. ViT-large, and/or those consuming images of size 224 vs 384). This approach allowed us to generate a diverse set of models, from which we selected the best performers to construct the final ensemble model.\nStep 4 — Distillation: Although the ensemble model has higher accuracy than any individual model, it requires more computational resources and thus increases the latency and cost of our product. We trained a distilled model to imitate the behavior of the ensemble model, which has similar accuracy but reduced computational cost by several folds.\nPre-training and Traditional Fine-tuning\nOur pretraining process involved harnessing the vast repository of Airbnb listing photos, comprising of millions of images, to train a Vision Transformer (ViT) model. While leveraging the Airbnb listing photos for pretraining provides a substantial advantage, there are also limitations in the dataset. There were inaccuracies or mislabels in the human-labeled dataset and they materially impacted the model’s ability to discern patterns effectively. Another notable limitation is the coverage of only four out of the total 16 room classifications within the pre-training dataset.\nTherefore, expanding the coverage of fine-tuning to include additional classes is imperative. We developed a detailed and updated guideline and generated a human-label dataset with the entirety of 16 room classifications. Iterative fine-tuning processes gradually encompassed the entirety of the 16 room types, contributing to a more comprehensive and versatile model.\nMulti-task Learning\nAcquiring high-quality human-labeled training data is a challenge due to the costly and time-consuming labeling process. Despite this, we had already accumulated a large repository of labeled data across other various tasks, including room-type classification, image quality prediction, same-room classification, category classification, and object detection. By fully utilizing this extensive and diversely labeled dataset, we significantly improved the prediction accuracy in our tasks. To achieve this, we implemented multi-task training that incorporates additional label classes from existing tasks, as demonstrated in Figure 4. Each learner is a vision transformer, and in addition to predicting a single set of labels, we allowed different learners to learn other label types, such as amenities and ImageNet21k labels, which further boosts overall performance as shown in Table 1.\nFigure 4: Multi-task learning illustration\nEnsemble Learning\nEnsemble learning is a powerful technique in machine learning that leverages diverse models with similar accuracies to achieve better accuracy and generalization.\nWe applied ensemble learning on diverse models with different architectures, model sizes, and auxiliary tasks such as amenities and ImageNet21k class predictions. Upon aggregating the predictions of the individual models, we observed a notable increase in the overall accuracy compared to any single model. The observed improvement is credited to the ensemble’s capability to address and reduce both misclassifications and inaccuracies of individual models, leading to more accurate predictions, despite the limited human-labeled training data.\n\nKnowledge Distillation\nWhile ensemble learning offers substantial gains in accuracy, it requires heightened computational resources as multiple large models are involved in each inference task. To prioritize model efficiency without compromising performance, we turned to knowledge distillation, a technique centered around transferring knowledge from a sophisticated ensemble of models to a more compact single model.\nOur distillation process transfers the knowledge encoded in both hard targets and the soft targets of a complex ensemble to a smaller and simpler model. Hard targets are ground-truth labels while the soft targets are the ensemble’s probabilistic predictions, enabling the smaller model to capture the nuanced decision boundaries learned by the ensemble. The overall training objective is a weighted combination of the two losses:\n\nwhere the first loss is the cross-entropy loss based on hard targets, the second loss is Kullback-Leibler divergence to evaluate the cross entropy between soft targets from the ensemble and the predictions of the student model, and the distillation coefficient determines the weight assigned to the distillation loss.\nRemarkably, our distilled model achieved performance metrics on par with the ensemble models, despite its significantly reduced inference time and resource requirements. This outcome demonstrates the efficacy of knowledge distillation in preserving the ensemble’s collective intelligence within a more streamlined model.\n\nGolden Evaluation\nAs part of the preparations for the launch of our end-to-end Photo Tour, we employed a rigorous evaluation process called “Golden Evaluation”, which mimics the actual user experience by calculating the minimum number of changes required to make the Photo Tour generated by our model identical to the human-labeled ground truth (i.e., the Golden Evaluation). In contrast to training data that is evenly distributed across classes, the golden evaluation processes at the Airbnb listing level, aiming to replicate the user’s perspective. We sampled listings, each containing an average of 25–30 photos, and defined accuracy as the minimum number of corrections required to make assignments consistent with human labels. These corrections refer to changes in room assignment, where a photo’s initial room prediction is modified to match the consensus room label provided by multiple human labels. For example, if a photo of bedroom 1 is falsely assigned to the living room, one correction is required to move it from the living room to bedroom 1.\n\nThere are photos that cannot be properly assigned to a named space. We classified miscellaneous photos, including close-up shots, images containing humans or animals, as well as nearby photos of shopping areas, restaurants, and parks, into the category labeled as “Others”. Furthermore, if a photo is of an empty space in a room such that we cannot judge its room location, we are allowed to designate some photos as “Unassigned”, which do not count in the accuracy calculation. This scenario occurs infrequently (as shown in Table 3), and is primarily used to let users decide in the most ambiguous cases. This evaluation served as the final launch criteria. Ultimately, we successfully reduced the error rate to 5.28%, passing the internal evaluation standard at Airbnb and Photo Tour was launched as a showcase feature in the November 2023 product launch.\n\nConclusion\nOur exploration of using Vision Transformers to improve our photo tour product has been successful and rewarding. By incorporating pretraining, multi-task learning, ensemble learning, and knowledge distillation, we’ve significantly enhanced model accuracy. Pretraining provided a strong foundation, while multi-task learning enriched the model’s ability to interpret diverse visuals. Ensemble learning combined model strengths for robust predictions, and knowledge distillation enabled efficient deployment without sacrificing accuracy.\nThe AI-powered photo tour was launched as part of Airbnb’s 2023 Winter Release. Since then, we have been diligently monitoring the performance of this product and continue to refine our models further for an even more seamless user experience.\nAcknowledgments\nWe would like to thank everyone involved in the project. A special thanks to the entire Airbnb user, listing, and platform team for their relentless efforts in developing and launching the product, ensuring its continued excellence. Additionally, we extend our gratitude to the Airbnb Machine Learning Infra team for their crucial support in building a robust infrastructure that photo tour relies upon.\nIf this type of work interests you, check out some of our related roles!\n\nAirbnb’s AI-powered photo tour using Vision Transformer was originally published in The Airbnb Tech Blog on Medium, where people are continuing the conversation by highlighting and responding to this story.",
        "dc:creator": "Pei Xiong",
        "guid": "https://medium.com/p/e470535f76d4",
        "categories": [
          "engineering",
          "technology",
          "computer-vision",
          "machine-learning",
          "ai"
        ],
        "isoDate": "2024-11-13T17:39:08.000Z"
      },
      {
        "creator": "Sharmila Jesupaul",
        "title": "Adopting Bazel for Web at Scale",
        "link": "https://medium.com/airbnb-engineering/adopting-bazel-for-web-at-scale-a784b2dbe325?source=rss----53c7c27702d5---4",
        "pubDate": "Tue, 12 Nov 2024 18:22:17 GMT",
        "content:encodedSnippet": "How and Why We Migrated Airbnb’s Large-Scale Web Monorepo to Bazel\nBy: Brie Bunge and Sharmila Jesupaul\nIntroduction\nAt Airbnb, we’ve recently adopted Bazel — Google’s open source build tool–as our universal build system across backend, web, and iOS platforms. This post will cover our experience adopting Bazel for Airbnb’s large-scale (over 11 million lines of code) web monorepo. We’ll share how we prepared the code base, the principles that guided the migration, and the process of migrating selected CI jobs. Our goal is to share information that would have been valuable to us when we embarked on this journey and to contribute to the growing discussion around Bazel for web development.\nWhy did we do this?\nHistorically, we wrote bespoke build scripts and caching logic for various continuous integration (CI) jobs that proved challenging to maintain and consistently reached scaling limits as the repo grew. For example, our linter, ESLint, and TypeScript’s type checking did not support multi-threaded concurrency out-of-the-box. We extended our unit testing tool, Jest, to be the runner for these tools because it had an API to leverage multiple workers.\nIt was not sustainable to continually create workarounds to overcome the inefficiencies of our tooling which did not support concurrency and we were incurring a long-run maintenance cost. To tackle these challenges and to best support our growing codebase, we found that Bazel’s sophistication, parallelism, caching, and performance fulfilled our needs.\nAdditionally, Bazel is language agnostic. This facilitated consolidation onto a single, universal build system across Airbnb and allowed us to share common infrastructure and expertise. Now, an engineer who works on our backend monorepo can switch to the web monorepo and know how to build and test things.\nWhy was this hard?\nWhen we began the migration in 2021, there was no publicized industry precedent for integrating Bazel with web at scale outside of Google. Open source tooling didn’t work out-of-the-box, and leveraging remote build execution (RBE) introduced additional challenges. Our web codebase is large and contains many loose files, which led to performance issues when transmitting them to the remote environment. Additionally, we established migration principles that included improving or maintaining overall performance and reducing the impact on developers contributing to the monorepo during the transition. We effectively achieved both of these goals. Read on for more details.\nReadying the Repository\nWe did some work up front to make the repository Bazel-ready–namely, cycle breaking and automated BUILD.bazel file generation.\nCycle Breaking\nOur monorepo is laid out with projects under a top-level frontend/ directory. To start, we wanted to add BUILD.bazel files to each of the ~1000 top-level frontend directories. However, doing so created cycles in the dependency graph. This is not allowed in Bazel because there needs to be a DAG of build targets. Breaking these often felt like battling a hydra, as removing one cycle spawns more in its place. To accelerate the process, we modeled the problem as finding the minimum feedback arc set (MFAS)¹ to identify the minimal set of edges to remove leaving a DAG. This set presented the least disruption, level of effort, and surfaced pathological edges.\nAutomated BUILD.bazel Generation\nWe automatically generate BUILD.bazel files for the following reasons:\n\nMost contents are knowable from statically analyzable import / require statements.\nAutomation allowed us to quickly iterate on BUILD.bazel changes as we refined our rule definitions.\nIt would take time for the migration to complete and we didn’t want to ask users to keep these files up-to-date when they weren’t yet gaining value from them.\nManually keeping these files up-to-date would constitute an additional Bazel tax, regressing the developer experience.\n\nWe have a CLI tool called sync-configs that generates dependency-based configurations in the monorepo (e.g., tsconfig.json, project configuration, now BUILD.bazel). It uses jest-haste-map and watchman with a custom version of the dependencyExtractor to determine the file-level dependency graph and part of Gazelle to emit BUILD.bazel files. This CLI tool is similar to Gazelle but also generates additional web specific configuration files such as tsconfig.json files used in TypeScript compilation.\nCI Migration\nWith preparation work complete, we proceeded to migrate CI jobs to Bazel. This was a massive undertaking, so we divided the work into incremental milestones. We audited our CI jobs and chose to migrate the ones that would benefit the most: type checking, linting, and unit testing². To reduce the burden on our developers, we assigned the central Web Platform team the responsibility for porting CI jobs to Bazel. We proceeded one job at a time to deliver incremental value to developers sooner, gain confidence in our approach, focus our efforts, and build momentum. With each job, we ensured that the developer experience was high-quality, that performance improved, CI failures were reproducible locally, and that the tooling Bazel replaced was fully deprecated and removed.\nEnabling TypeScript\nWe started with the TypeScript (TS) CI job. We first tried the open source ts_project rule³. However, it didn’t work well with RBE due to the sheer number of inputs, so we wrote a custom rule to reduce the number and size of the inputs.\nThe biggest source of inputs came from node_modules. Prior to this, the files for each npm package were being uploaded individually. Since Bazel works well with Java, we packaged up a full tar and a TS-specific tar (only containing the *.ts and package.json) for each npm package along the lines of Java JAR files (essentially zips).\nAnother source of inputs came through transitive dependencies. Transitive node_modules and d.ts files in the sandbox were being included because technically they can be needed for subsequent project compilations. For example, suppose project foo depends on bar, and types from bar are exposed in foo’s emit. As a result, project baz which depends on foo would also need bar’s outputs in the sandbox. For long chains of dependencies, this can bloat the inputs significantly with files that aren’t actually needed. TypeScript has a — listFiles flag that tells us which files are part of the compilation. We can package up this limited set of files along with the emitted d.ts files into an output tsc.tar.gz file⁴. With this, targets need only include direct dependencies, rather than all transitive dependencies⁵.\nDiagram showing how we use tars and the — listFiles flag to prune inputs/outputs of :types targets\nThis custom rule unblocked switching to Bazel for TypeScript, as the job was now well under our CI runtime budget.\nBar chart showing the speed up from switching to using our custom genrule\nEnabling ESLint\nWe migrated the ESLint job next. Bazel works best with actions that are independent and have a narrow set of inputs. Some of our lint rules (e.g., special internal rules, import/export, import/extensions) inspected files outside of the linted file. We restricted our lint rules to those that could operate in isolation as a way of reducing input size and having only to lint directly affected files. This meant moving or deleting lint rules (e.g., those that were made redundant with TypeScript). As a result, we reduced CI times by over 70%.\nTime series graph showing the runtime speed-up in early May from only running ESLint on directly affected targets\nEnabling Jest\nOur next challenge was enabling Jest. This presented unique challenges, as we needed to bring along a much larger set of first and third-party dependencies, and there were more Bazel-specific failures to fix.\nWorker and Docker Cache\nWe tarred up dependencies to reduce input size, but extraction was still slow. To address this, we introduced caching. One layer of cache is on the remote worker and another is on the worker’s Docker container, baked into the image at build time. The Docker layer exists to avoid losing our cache when remote workers are auto-scaled. We run a cron job once a week to update the Docker image with the newest set of cached dependencies, striking a balance of keeping them fresh while avoiding image thrashing. For more details, check out this Bazel Community Day talk.\nDiagram showing symlinked npm dependencies to a Docker cache and worker cache\nThis added caching provided us with a ~25% speed up of our Jest unit testing CI job overall and reduced the time to extract our dependencies from 1–3 minutes to 3–7 seconds per target. This implementation required us to enable the NodeJS preserve-symlinks option and patch some of our tools that followed symlinks to their real paths. We extended this caching strategy to our Babel transformation cache, another source of poor performance.\nImplicit Dependencies\nNext, we needed to fix Bazel-specific test failures. Most of these were due to missing files. For any inputs not statically analyzable (e.g., referenced as a string without an import, babel plugin string referenced in .babelrc), we added support for a Bazel keep comment (e.g., // bazelKeep: path/to/file) which acts as though the file were imported. The advantages of this approach are:\n1. It is colocated with the code that uses the dependency,\n2. BUILD.bazel files don’t need to be manually edited to add/move # keep comments,\n3. There is no effect on runtime.\nA small number of tests were unsuitable for Bazel because they required a large view of the repository or a dynamic and implicit set of dependencies. We moved these tests out of our unit testing job to separate CI checks.\nPreventing Backsliding\nWith over 20,000 test files and hundreds of people actively working in the same repository, we needed to pursue test fixes such that they would not be undone as product development progressed.\nOur CI has three types of build queues:\n1. “Required”, which blocks changes,\n2. “Optional”, which is non-blocking,\n3. “Hidden”, which is non-blocking and not shown on PRs.\nAs we fixed tests, we moved them from “hidden” to “required” via a rule attribute. To ensure a single source of truth, tests run in “required” under Bazel were not run under the Jest setup being replaced.\n# frontend/app/script/__tests__/BUILD.bazel\njest_test(\n    name = \"jest_test\",\n    is_required = True, # makes this target a required check on pull requests \n    deps = [\n        \":source_library\",\n    ],\n)\nExample jest_test rule. This signifies that this target will run on the “required” build queue.\nWe wrote a script comparing before and after Bazel to determine migration-readiness, using the metrics of test runtime, code coverage stats, and failure rate. Fortunately, the bulk of tests could be enabled without additional changes, so we enabled these in batches. We divided and conquered the remaining burndown list of failures with the central team, Web Platform, fixing and updating tests in Bazel to avoid putting this burden on our developers. After a grace period, we fully disabled and deleted the non-Bazel Jest infrastructure and removed the is_required param.\nLocal Bazel Experience\nIn tandem with our CI migration, we ensured that developers can run Bazel locally to reproduce and iterate on CI failures. Our migration principles included delivering only what was on par with or superior to the existing developer experience and performance. JavaScript tools have developer-friendly CLI experiences (e.g., watch mode, targeting select files, rich interactivity) and IDE integrations that we wanted to retain. By default, frontend developers can continue using the tools they know and love, and in cases where it is beneficial they can opt into Bazel. Discrepancies between Bazel and non-Bazel are rare and when they do occur, developers have a means of resolving the issue. For example, developers can run a single script, failed-on-pr which will re-run any targets failing CI locally to easily reproduce issues.\nAnnotations on a failing build with scripts to recreate the failures, e.g. yak script jest:failed-on-pr\nWe also do some normalization of platform specific binaries so that we can reuse the cache between Linux and MacOS builds. This speeds up local development and CI jobs by sharing cache between a local developer’s macbook and linux machines in CI. For native npm packages (node-gyp dependencies) we exclude platform-specific files and build the package on the execution machine. The execution machine will be the machine executing the test or build process. We also use “universal binaries” (e.g., for node and zstd), where all platform binaries are included as inputs (so that inputs are consistent no matter which platform the action is run from) and the proper binary is chosen at runtime.\nConclusion\nAdopting Bazel for our core CI jobs yielded significant performance improvements for TypeScript type checking (34% faster), ESLint linting (35% faster), and Jest unit tests (42% faster incremental runs, 29% overall). Moreover, our CI can now better scale as the repo grows.\nNext, to further improve Bazel performance, we will be focusing on persisting a warm Bazel host across CI runs, taming our build graph, powering CI jobs that do not use Bazel with the Bazel build graph, and potentially exploring SquashFS to further compress and optimize our Bazel sandboxes.\nWe hope that sharing our journey has provided insights for organizations considering a Bazel migration for web.\nAcknowledgments\nThank you Madison Capps, Meghan Dow, Matt Insler, Janusz Kudelka, Joe Lencioni, Rae Liu, James Robinson, Joel Snyder, Elliott Sprehn, Fanying Ye, and various other internal and external partners who helped bring Bazel to Airbnb.\nWe are also grateful to the broader Bazel community for being welcoming and sharing ideas.\n****************\n[1]: This problem is NP-complete, though approximation algorithms have been devised that still guarantee no cycles; we chose the implementation outlined in “Breaking Cycles in Noisy Hierarchies”.\n[2]: After initial evaluation, we considered migrating web asset bundling as out of scope (though we may revisit this in the future) due to high level of effort, unknowns in the bundler landscape, and neutral return on investment given our recent adoption of Metro, as Metro’s architecture already factors in scalability features (e.g. parallelism, local and remote caching, and incremental builds).\n[3]: There are newer TS rules that may work well for you here.\n[4]: We later switched to using zstd instead of gzip because it produces archives that are better compressed and more deterministic, keeping tarballs consistent across different platforms.\n[5]: While unnecessary files may still be included, it’s a much narrower set (and could be pruned as a further optimization).\nAll product names, logos, and brands are property of their respective owners. All company, product and service names used in this website are for identification purposes only. Use of these names, logos, and brands does not imply endorsement.\n\nAdopting Bazel for Web at Scale was originally published in The Airbnb Tech Blog on Medium, where people are continuing the conversation by highlighting and responding to this story.",
        "dc:creator": "Sharmila Jesupaul",
        "guid": "https://medium.com/p/a784b2dbe325",
        "categories": [
          "bazel",
          "migration",
          "web",
          "typescript",
          "engineering"
        ],
        "isoDate": "2024-11-12T18:22:17.000Z"
      },
      {
        "creator": "Dillon Davis",
        "title": "Transforming Location Retrieval at Airbnb: A Journey from Heuristics to Reinforcement Learning",
        "link": "https://medium.com/airbnb-engineering/transforming-location-retrieval-at-airbnb-a-journey-from-heuristics-to-reinforcement-learning-d33ffc4ddb8f?source=rss----53c7c27702d5---4",
        "pubDate": "Mon, 11 Nov 2024 18:14:35 GMT",
        "content:encodedSnippet": "How Airbnb leverages machine learning and reinforcement learning techniques to solve a unique information retrieval task in order to provide guests with unique, affordable, and differentiated accommodations around the world.\nBy: Dillon Davis, Huiji Gao, Thomas Legrand, Weiwei Guo, Malay Haldar, Alex Deng, Han Zhao, Liwei He, Sanjeev Katariya\nIntroduction\nAirbnb has transformed the way people travel around the globe. As Airbnb’s inventory spans diverse locations and property types, providing guests with relevant options in their search results has become increasingly complex. In this blog post, we’ll discuss shifting from using simple heuristics to advanced machine learning and reinforcement learning techniques to transform what we call location retrieval in order to address this challenge.\nThe Challenge of Location Retrieval\nGuests typically start searching by entering a destination in the search bar and expect the most relevant results to be surfaced. These destinations can be countries, states, cities, neighborhoods, streets, addresses, or points of interest. Unlike traditional travel accommodations, Airbnb listings are spread across different neighborhoods and surrounding areas. For example, a family searching for a vacation rental in San Francisco might find better options in nearby cities like Daly City, where there are larger single-family homes. Thus, the system needs to account for not just the searched location but also nearby areas that might offer better options for the guest. This is evidenced by the locations of booked listings when searching for San Francisco shown below.\n\nGiven Airbnb’s scale, we cannot rank every listing for every search. This presented a challenge to create a system that dynamically infers a relevant map area for a query. This system, known as location retrieval, needed to balance including a wide variety of listings to appeal to all guests’ needs while still being relevant to the query. Our search ranking models can then efficiently rank the subset of our inventory that is within the relevant map area and surface the most relevant inventory to our guests. This system and more is outlined below\n\nStarting with Heuristics: The Cold Start Problem\nInitially, Airbnb relied on heuristics to define map areas based on the type of search. For example, if a guest searched for a country, the system would use administrative boundaries to filter listings within that country. If they searched for a city, the system would create a 25-mile radius around the city center to retrieve listings.\nImproving these heuristics proved to be profoundly impactful. One such example is the introduction of a log scale parameterized smooth function to compute an expansion factor for the diagonal size of the administrative bounds of the searched destination. We applied this for very precise locations like addresses, buildings, and POI’s resulting in a 0.35% increase in uncancelled bookers on the platform when tested in an online A/B experiment against the baseline heuristics. Figures below demonstrate how search results for a building in Ibiza, Spain improved dramatically with this heuristic by surfacing significantly more and higher quality inventory.\n\nThese heuristics were simple and worked well enough to start, but they had limitations. They couldn’t differentiate between different types of searches (e.g., a family looking for a large home versus a solo traveler looking for a small apartment), and they didn’t adapt well to new data as Airbnb’s inventory and guest preferences evolved.\nExploring Statistics to Help Improve Location Retrieval\nWith more data available over time from these intuition based heuristics, we thought there might be a way to take advantage of this historical user booking behavior to improve location retrieval. We built a dataset for each travel destination that recorded where guests booked listings when searching for that destination. Based on this data, the system could create retrieval map areas that included 96% of the nearest booked listings for a given destination.\nWe tested these newly constructed retrieval map areas in lieu of the intuition based heuristics outlined above based on the hypothesis that it would provide guests a more bookable selection of inventory. While this statistical approach was more aligned with guest booking behavior, it still had limitations. It treated all searches for a location the same, regardless of specific search parameters like group size or travel dates. This uniform approach meant that some guests might not see the best listings for their particular needs. As a result, this statistics based method had no detectable increase in uncancelled bookers on the platform when tested against the heuristics outlined above in an online A/B experiment. This led us to believe that location retrieval may require more advanced techniques such as machine learning.\nAdvancing to Machine Learning\nInstead of only relying on past booking data, the new system could learn from various search parameters, such as the number of guests and stay duration. By analyzing this data, a model could predict more relevant map areas for each search, rather than applying a one-size-fits-all approach.\nFor example, a group of ten travelers searching for a San Francisco vacation rental might prefer larger homes in the suburbs, while solo travelers might prioritize central locations. The machine learning model could distinguish between these different preferences and adjust the retrieval map areas accordingly, providing more tailored results.\nWe constructed our machine learning model in the following manner. This is a result of three iterations that introduced the machine learning model, expanded its feature set, and expanded search attribution. The architecture is depicted in the figure below.\n\nTraining Examples: Searches issued by a booker by entering a destination in the search bar or manipulating the map that contained the booked listing in their search results on the same day or one day before the booking. We discard any bookings that are canceled 7 days after booking.\nTraining Features: We derive features directly from the search request such as location name, stay length, number of guests, price filters, location country, etc. There are 9 continuous features and 19 categorical features in total.\nTraining Labels: The latitude and longitude coordinates of the booked listing attributed to the search\nArchitecture: A two layer neural network of size 256 was chosen in order to have more flexibility for loss formulation compared to traditional regression and decision tree based approaches.\nModel Output: 4 floats that define the latitude and longitude offsets from the center latitude and longitude coordinates of the searched destination that represent the relevant map area.\nLoss: Trained to predict map areas that contain their associated booked listing while minimizing the size of the predicted map area and the occurrence of predictions that cannot construct a valid rectangular map area.\n\nThe machine learning system increased the recall of booked listings (i.e., how often the system retrieved a listing that was eventually booked) by 7.12% and reduced the size of the retrieval map area by 40.83%. It had a cumulative impact of +1.8% in uncancelled bookers on the platform. The initial model was evaluated against the baseline and each subsequent model iteration was evaluated against the preceding outgoing model.\nFigures below demonstrate how search results for a specific street in Lima, Peru improved dramatically with the model by surfacing results that are much closer to the searched street.\nBefore\n\nAfter\n\nExploring New Frontiers with Reinforcement Learning\nWhile machine learning improved the system’s ability to differentiate search results, there was still room for improvement, particularly in learning whether locations that had never been surfaced before were relevant to guests for a search. To address this, Airbnb introduced reinforcement learning to the location retrieval process.\nReinforcement learning allowed the system to continuously learn from guest interactions by surfacing new areas for a given destination and adjusting the retrieval map area based on guest booking behavior. This approach, known as a contextual multi-armed bandit problem, involved balancing exploration (surfacing new locations) with exploitation (surfacing previous successful locations). The system could actively experiment with different retrieval map areas learning from guest bookings to refine its predictions.\nApplying a contextual multi-armed bandit traditionally requires defining an active contextual estimator, a method for uncertainty estimation, and an exploration strategy. We took the following approach given product constraints, system constraints, and the nature of our model formulation. The architecture is depicted in the figure below.\n\nActive contextual estimation: We employed our existing machine learning model for location retrieval retrained on a daily basis to regularly learn from any new bookings data that we collect while surfacing previously unshown locations.\nUncertainty estimation: We modified our model architecture with a random dropout layer to generate 32 unique predictions for a given search (Monte Carlo Dropout). This allows us to measure the mean and standard deviation of our prediction while minimizing negative impact to system performance and changes to our existing model formulation.\nExploration Strategy: We compute an upper confidence bound using the mean and standard deviation of our prediction in order to construct larger retrieval map areas based on the model’s confidence in its prediction for the search.\n\nThis system successfully explored more for less-traveled locations where it was less confident and explored less for locations that are often searched and booked. For example, pictured below are the mean (inner) and upper confidence bound (outer) estimates of retrieval map areas for San Francisco, CA (left) and Smith Mountain Lake, Virginia (right). San Francisco is searched almost 25x more than Smith Mountain Lake with proportionately more bookings as well. As a result, the model is more confident in its retrieval map area estimate for San Francisco vs Smith Mountain Lake resulting in 2–3x less exploration for San Francisco queries vs Smith Mountain Lake.\n\nThe reinforcement learning system was also tested against the outgoing machine learning model in online A/B experiments showing a cumulative 0.51% increase in uncanceled bookers and 0.71% increase in 5 star trip rate over two iterations that introduced reinforcement learning and optimized scoring of the more complex model.\nConclusion: A Transformative Journey\nAirbnb’s journey from simple heuristics to sophisticated machine learning and reinforcement learning models demonstrates the power of data-driven approaches in transforming complex systems. By continually iterating and improving its location retrieval process, Airbnb has not only enhanced the relevance of its search results but also helped guests experience more 5 star trips.\nThis transformation cumulatively results in a 2.66% increase in uncanceled bookers — a major achievement for a company operating at Airbnb’s scale. More details can be found in our technical paper. As Airbnb continues to innovate, we are continuously evaluating and introducing more advanced features and retrieval mechanisms like retrieving with complex polygons . These will further refine and enhance the search experience for millions of guests worldwide.\nIf this type of work interests you, check out some of our related positions and more at Careers at Airbnb!\n****************\nAll product names, logos, and brands are property of their respective owners. All company, product and service names used in this website are for identification purposes only. Use of these names, logos, and brands does not imply endorsement.\n\nTransforming Location Retrieval at Airbnb: A Journey from Heuristics to Reinforcement Learning was originally published in The Airbnb Tech Blog on Medium, where people are continuing the conversation by highlighting and responding to this story.",
        "dc:creator": "Dillon Davis",
        "guid": "https://medium.com/p/d33ffc4ddb8f",
        "categories": [
          "search-engines",
          "machine-learning",
          "information-retrieval",
          "engineering",
          "artificial-intelligence"
        ],
        "isoDate": "2024-11-11T18:14:35.000Z"
      }
    ]
  },
  {
    "name": "PayPal Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Visual Studio Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Mika Dumont",
        "title": "Fix Code with GitHub Copilot",
        "link": "https://devblogs.microsoft.com/visualstudio/fix-code-with-github-copilot/",
        "pubDate": "Thu, 14 Nov 2024 11:00:55 +0000",
        "content:encodedSnippet": "Looking to resolve code issues quickly? The new GitHub Copilot feature integrated into the lightbulb and error list in Visual Studio 2022 offers a valuable solution for developers. Whether you’re working in C# or C++, this feature will help you understand and address problems in your codebase more efficiently.\nThe integration of GitHub Copilot into Visual Studio 2022 provides quick fixes and insightful explanations right at your fingertips. Say goodbye to sifting through documentation or conducting endless online searches to debug your code. The lightbulb and error list now offers direct access to GitHub Copilot’s AI capabilities, streamlining your development process.\nQuick Fixes at Your Fingertips\nTo get started, simply invoke the lightbulb and select Fix with Copilot. This launches an inline chat with GitHub Copilot, offering you an available fix. This seamless interaction allows you to address issues at once, keeping your workflow uninterrupted.\n\nInsightful Explanations for Code Issues\nUnderstanding errors in your code can be challenging, but with GitHub Copilot, clarity is just a click away. Select the GitHub Copilot icon from the error list to open the chat panel, where you’ll find detailed explanations and solutions for the error at hand.\n\nElevate Your Coding Experience\nBy integrating GitHub Copilot, Visual Studio 2022 enhances your coding experience, making it easier to tackle complex problems and improve code quality. We encourage you to explore this feature and see how GitHub Copilot can transform your coding experience.\nWe deeply appreciate the continuous feedback from our users, which drives us to improve and innovate. Your input is invaluable in making Visual Studio better with each update. Happy coding!\nThe post Fix Code with GitHub Copilot appeared first on Visual Studio Blog.",
        "dc:creator": "Mika Dumont",
        "content": "<p>Looking to resolve code issues quickly? The new GitHub Copilot feature integrated into the lightbulb and error list in Visual Studio 2022 offers a valuable solution for developers. Whether you&#8217;re working in C# or C++, this feature will help you understand and address problems in your codebase more efficiently. The integration of GitHub Copilot into [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/fix-code-with-github-copilot/\">Fix Code with GitHub Copilot</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "Looking to resolve code issues quickly? The new GitHub Copilot feature integrated into the lightbulb and error list in Visual Studio 2022 offers a valuable solution for developers. Whether you’re working in C# or C++, this feature will help you understand and address problems in your codebase more efficiently. The integration of GitHub Copilot into […]\nThe post Fix Code with GitHub Copilot appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=251319",
        "categories": [
          "Artificial Intelligence",
          "Copilot",
          "Cross-Platform",
          "GitHub Copilot",
          "Lightbulb Improvements"
        ],
        "isoDate": "2024-11-14T11:00:55.000Z"
      },
      {
        "creator": "Mads Kristensen",
        "title": "First preview of Visual Studio 2022 v17.13  ",
        "link": "https://devblogs.microsoft.com/visualstudio/first-preview-of-visual-studio-2022-v17-13/",
        "pubDate": "Wed, 13 Nov 2024 15:14:05 +0000",
        "content:encodedSnippet": "We’re excited to announce the availability of Visual Studio 2022 v17.13 Preview 1 – the first preview of our next update to Visual Studio. This update focuses on providing fantastic developer experiences across the board, with a focus on stability & security, and AI & productivity. Download the preview and see the full list of enhancements in the release notes.  \n\nQuality & security \nEnsuring the highest standards of quality and security is paramount. Visual Studio 2022 v17.13 incorporates robust quality and security enhancements designed to provide a seamless and secure development environment. With improved diagnostics and debugging tools, developers can now identify and resolve issues more efficiently, leading to more reliable and stable applications. Furthermore, enhanced security features offer protection against potential threats, safeguarding your code and data. These improvements not only streamline your workflow but also bolster your confidence in delivering high-quality, secure software solutions. \nAI & productivity \nVisual Studio 2022 v17.13 integrates advanced AI to boost developer productivity by automating routine tasks, offering intelligent code suggestions, and enhancing coding efficiency. With AI-assisted code completion, refactoring tools, and personalized insights, developers can write cleaner, more efficient code and focus on complex, creative aspects of their projects, ultimately accelerating development cycles. This new release also brings general productivity improvements across the IDE, making it a robust tool for developers at every level. \n \nDownload Visual Studio Preview\n\nWe hope you enjoy this preview of Visual Studio, and we look forward to hearing what you think. You can share feedback with us via Developer Community, by reporting issues via report a problem and share your suggestions for new features or improvements to existing ones. \nYou can download the preview from our website or update it from within the IDE. Please note that you should not use this preview in production environments, and some extensions or workloads may not be compatible with it. \nThank you for using Visual Studio and happy coding! \nThe post First preview of Visual Studio 2022 v17.13   appeared first on Visual Studio Blog.",
        "dc:creator": "Mads Kristensen",
        "content": "<p>We’re excited to announce the availability of Visual Studio 2022 v17.13 Preview 1 – the first preview of our next update to Visual Studio. This update focuses on providing fantastic developer experiences across the board, with a focus on stability &#38; security, and AI &#38; productivity. Download the preview and see the full list of [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/first-preview-of-visual-studio-2022-v17-13/\">First preview of Visual Studio 2022 v17.13  </a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "We’re excited to announce the availability of Visual Studio 2022 v17.13 Preview 1 – the first preview of our next update to Visual Studio. This update focuses on providing fantastic developer experiences across the board, with a focus on stability & security, and AI & productivity. Download the preview and see the full list of […]\nThe post First preview of Visual Studio 2022 v17.13   appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=251307",
        "categories": [
          "Visual Studio",
          "Preview Release"
        ],
        "isoDate": "2024-11-13T15:14:05.000Z"
      },
      {
        "creator": "Mads Kristensen",
        "title": "Visual Studio 2022 v17.12 with .NET 9",
        "link": "https://devblogs.microsoft.com/visualstudio/visual-studio-2022-v17-12-with-dotnet-9/",
        "pubDate": "Tue, 12 Nov 2024 18:12:48 +0000",
        "content:encodedSnippet": "We are thrilled to announce the General Availability (GA) of Visual Studio 2022 version 17.12. This update focuses on providing fantastic developer experiences for working with .NET 9 projects and new AI productivity features, along with continuous improvements for all developers.\n\nThanks to your continuous feature requests, we’ve incorporated many of them in this release. There’s something new for every developer. We have added several new tools and enhancements that simplify your workflow and improve productivity. Whether you’re looking for advanced debugging capabilities, more efficient code management, or enhanced security features, this update has it all.\n\nDownload Visual Studio 2022 v17.12\n\nFor detailed information on each new feature, check out the release notes. If you’re pressed for time, here are the key highlights.\nProductivity\nCopy from the Error List: Copying an error from the Error List now copies just the description instead of the entire row to the clipboard.\nGo to line anywhere in Code Search: In Code Search, you can now navigate to a specific line in the current document or other specified document.\nDock the Code Search window: You can now freely position the Code Search window with capabilities like docking and auto-hiding.\nCustomize collapsed text indicator: Set custom colors for the collapsed text indicator in the Visual Studio editor.\nRefresh your Find results: You can now refresh the results to a previous Find to get up-to-date search matches.\nMore space for horizontal scrollbar: You can now control the visibility of the file level indicators in CodeLens.\nNon-blocking Code Cleanup on save: When Code Cleanup is run on Save, it now operates in a non-blocking manner, for a smoother coding experience.\nGitHub Copilot\nAI smart variable inspection: Optimize your debugging workflow with Integrated AI variable inspection.\nAI-powered IEnumerable visualizer: AI-powered LINQ Editable Expressions in the IEnumerable visualizer.\nFix code with GitHub Copilot: GitHub Copilot assists you in resolving code issues.\nBetter AI completions for C#: GitHub Copilot brings in additional context from relevant source files to improve completions for C#.\nDebug tests with GitHub Copilot: Get help with debugging failed tests by using Debug Tests with GitHub Copilot.\nDebugging & diagnostics\nShows method return values when debugging: The debugger now displays inline return values for enhanced debugging efficiency.\nExport breakpoint groups with ease: Effortless import and export of breakpoint groups.\nBlazor WebAssembly debugging: An improved debugging experience for Blazor WebAssembly apps targeting .NET 9 or later.\nMeter Histogram in Profiler Counter Tool: Enhanced performance insights using Meter Histogram in Profiler Counter Tool.\nAnalyze memory use over time: Select and compare multiple memory snapshots using the Diagnostics Tool window.\nGit tooling\nManage file renaming with Git: Get peace of mind when renaming files with a new notification.\nPull requests using drafts and templates: Create pull request drafts and start your descriptions with templates in Visual Studio.\nCreate internal GitHub repos: Visual Studio now supports creating internal repos and includes guidance for each type of repository to give you more confidence when starting a new project.\nCopy Git link: You can get a GitHub or Azure DevOps link to a specific line of code to make it easy to share with your colleagues.\nCustomize your AI Git commit message: You can add additional instructions to the prompt for generating your Git commit message with GitHub Copilot.\nMulti-repo for GitHub and Azure DevOps: You can now create pull requests and link work items in multi-repo scenarios.\nIDE\nPreserve font across theme changes: Changing themes will now remember your font and font size preferences.\nMulti-Project Launch Configuration: Streamline debugging by setting up and saving launch profiles for specific projects within multi-project solutions. Share configurations effortlessly with your team.\nCopy files between instances: You can now copy files and folders from Solution Explorer in one instance of Visual Studio to another.\nMultiple GitHub accounts: You can now add multiple GitHub accounts and set an active account to drive GitHub features like GitHub Copilot and Version Control.\nCertificate Revocation Checks: Visual Studio now alerts you if it detects digital certificate problems during network calls.\nMotW security warnings: Mark of the web (MotW) security warnings are now integrated into the overall trust functionality.\nTeams Toolkit new AI templates: The Teams Toolkit onboards new AI Teams app templates.\nCloud\nAzure App Service publish security updates: Publishing to Azure App Service securely using integrated security updates.\nAzure WebJobs Linux support: Publishing to Azure WebJobs on Linux is now supported by right-click publish in Visual Studio.\nAzure Functions Flex Consumption: Publish to Azure Flex Consumption hosting plan, currently in Preview.\nConnected Services security update: Making your apps and development experienced more secure.\nDesktop\nEnhanced WinUI components search: Enhance WinUI project setup with improved Visual Studio Installer search, simplifying component location for developers.\nWeb\nRequest variables in HTTP files: HTTP files now support request variables. That is where you can send a request and then use data from the response, or request, in future requests.\nHTTP files shared environment: In HTTP environment files we have added support to share variables across environments.\nVitest support in JavaScript and TypeScript: When using JavaScript and TypeScript projects you can now author test cases with Vitest.\nInlay Hints support for more languages: Inlay Hint support has been added to JavaScript, TypeScript, Python and Razor as well as a setting to control its behavior.\nData\nSDK-style SQL projects in SSDT: You can now use the SDK-style project file format in your SQL Server Data Tools projects.\n.NET\nAchieve more with .NET 9: .NET 9 elevates cloud-native and intelligent app development, focusing on productivity enhancements, streamlined deployments, and accelerated AI integration.\nNuGet audits transitive packages: NuGet is changing default audit settings to include transitive packages.\nC++\nSet C++ Command Line Arguments: A new way to set your command line arguments right from the toolbar.\nBuild Insights view explanations: Learn how to use each tab of Build Insights via a newly added link to documentation.\nBuild Insights path adjustments: Get a clearer view of your file in Build Insights, see full path on hover.\nOpen Folder for Unreal Engine uproject: A new way of opening your uproject.\nChange signature improved: You can now effectively change signatures with our improved feature for C++.\nSHARE YOUR FEEDBACK AND STAY CONNECTED\nAs you use Visual Studio, let us know what you love, what you like, and where you’d like us to improve. You can share feedback with us via Developer Community: report any bugs or issues via report a problem and share your suggestions for new features or improvements to existing ones.\nStay connected with the Visual Studio team by following us on YouTube, Twitter, LinkedIn, Twitch and on Microsoft Learn.\nAs always, we appreciate the time you’ve spent reporting issues and hope you continue to give us feedback on how we’re doing and what we can improve.\nThe post Visual Studio 2022 v17.12 with .NET 9 appeared first on Visual Studio Blog.",
        "dc:creator": "Mads Kristensen",
        "content": "<p>We are thrilled to announce the General Availability (GA) of Visual Studio 2022 version 17.12. This update focuses on providing fantastic developer experiences for working with .NET 9 projects and new AI productivity features, along with continuous improvements for all developers. Thanks to your continuous feature requests, we&#8217;ve incorporated many of them in this release. [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/visual-studio-2022-v17-12-with-dotnet-9/\">Visual Studio 2022 v17.12 with .NET 9</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "We are thrilled to announce the General Availability (GA) of Visual Studio 2022 version 17.12. This update focuses on providing fantastic developer experiences for working with .NET 9 projects and new AI productivity features, along with continuous improvements for all developers. Thanks to your continuous feature requests, we’ve incorporated many of them in this release. […]\nThe post Visual Studio 2022 v17.12 with .NET 9 appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=251184",
        "categories": [
          "Visual Studio",
          "Release"
        ],
        "isoDate": "2024-11-12T18:12:48.000Z"
      },
      {
        "creator": "Mika Dumont",
        "title": "Better GitHub Copilot Completions for C#",
        "link": "https://devblogs.microsoft.com/visualstudio/better-github-copilot-completions-for-c/",
        "pubDate": "Mon, 11 Nov 2024 15:27:27 +0000",
        "content:encodedSnippet": "We’re excited to announce a significant enhancement to GitHub Copilot that elevates your C# coding experience. Introducing the new update: GitHub Copilot code completions now provide more accurate and relevant autocomplete suggestions by incorporating additional C# context.\nPreviously, GitHub Copilot generated suggestions based on the content of your currently active file and any other open files in your editor. While this approach was helpful, we have discovered that including more relevant context can greatly improve the quality of these suggestions.\nWith this latest update, GitHub Copilot now automatically considers semantically relevant files for additional context, even if these files are not open in your editor. This enhancement helps reduce hallucinations and ensures that you receive more pertinent and precise code completions.\nBefore: Semantically relevant files are not considered as context for GitHub Copilot Completions\n﻿without-related-files.mp4″ width=”560″ height=”315″ allowfullscreen=”allowfullscreen”>﻿\nAfter: Semantically relevant files are considered as context for GitHub Copilot Completions\n﻿﻿without-related-files.mp4″ width=”560″ height=”315″ allowfullscreen=”allowfullscreen”>﻿\nTo dive deeper into how this new feature works and how it can improve your coding productivity, check out our detailed blog post Improving GitHub Copilot Completions in Visual Studio for C# Developers on the .NET blog.\nStay tuned for more updates and thank you for being a part of our developer community.\nThe post Better GitHub Copilot Completions for C# appeared first on Visual Studio Blog.",
        "enclosure": {
          "url": "https://devblogs.microsoft.com/visualstudio/wp-content/uploads/sites/4/2024/11/without-related-files.mp4",
          "length": "146986",
          "type": "video/mp4"
        },
        "dc:creator": "Mika Dumont",
        "content": "<p>We&#8217;re excited to announce a significant enhancement to GitHub Copilot that elevates your C# coding experience. Introducing the new update: GitHub Copilot code completions now provide more accurate and relevant autocomplete suggestions by incorporating additional C# context. Previously, GitHub Copilot generated suggestions based on the content of your currently active file and any other open [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/better-github-copilot-completions-for-c/\">Better GitHub Copilot Completions for C#</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "We’re excited to announce a significant enhancement to GitHub Copilot that elevates your C# coding experience. Introducing the new update: GitHub Copilot code completions now provide more accurate and relevant autocomplete suggestions by incorporating additional C# context. Previously, GitHub Copilot generated suggestions based on the content of your currently active file and any other open […]\nThe post Better GitHub Copilot Completions for C# appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=251281",
        "categories": [
          "Copilot",
          "Visual Studio",
          "C#",
          "GitHub Copilot",
          "Visual Studio 2022"
        ],
        "isoDate": "2024-11-11T15:27:27.000Z"
      }
    ]
  },
  {
    "name": "Instagram Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Dropbox Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Joshua",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권재명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김석기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권진호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강대명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권정혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "줌구",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수보",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김시은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "곽민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김범진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민서",
    "category": "개인",
    "posts": []
  },
  {
    "name": "I am not Okay",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권창현",
    "category": "개인",
    "posts": [
      {
        "creator": "권창현",
        "title": "학생 지도의 즐거움에 대하여",
        "link": "https://thoughts.chkwon.net/happy-advisor/",
        "pubDate": "Sun, 10 Nov 2024 06:17:06 +0000",
        "content:encodedSnippet": "지난해 8월에 한국에 들어와서 KAIST에서 근무한 지 1년이 지났다. 그동안 국내외에 계신 분들을 만날 때면, 한국에 들어가서 어떠냐, 좋으냐는 질문을 많이 들었고, 그때마다 “너무 좋아요, 행복해요”라는 말을 많이도 하고 다녔다.\n최근에 ‘나는 왜 한국 생활이 행복한가?’라는 질문에 대해 자세히 살펴볼 기회가 있었다. 내가 한국 생활에서 만족스러운 점들, 어떤 순간들에 재미를 느꼈는지는 어렴풋하게는 파악하고 있었지만, ‘왜?’라는 질문에 답하려고 시도한 것은 처음이다.\n \n\nKAIST 부임 벌써 1년. 바쁜지, 행복한지 묻는 중요한 질문 앞에서, 오늘 저녁 메뉴를 생각하며 고뇌에 빠진 모습이다.\n\n \n \n우선 정말 단순하게도 내가 태어나고 자란 나라, 한국이기 때문이다. 한국을 떠난 지 20년이나 됐기 때문에 나도 한국도 여러 가지 의미로 달라진 것은 사실이지만, 여전히 내가 태어난 나라이고, 언어적·문화적 뿌리를 공유하는 사람들이 많이 모여 사는 나라다. 이런 환경이 주는 알 수 없는 심리적 안정감이 있다.\nKAIST이기 때문이다. 이것은 몇 가지 의미를 갖고 있다. 첫째로는 내 모교라는 점이다. 내 추억이 있는 곳에서 일하는 것이 단순한 직장 이상의 의미를 준다. 둘째로는 한국 사회에서 KAIST가 가지는 지위 때문에 내게 주어지는 많은 기회들이 있다. 좋은 학생들을 만나기에도, 좋은 연구 프로젝트를 만나기에도 유리한 환경이다. 셋째로는 사회에 기여하기를 바라는 KAIST의 미션 때문이다. 한국 사회에 기여할 기회가 KAIST 교수에게만 주어지는 것은 아닐 테지만, 내가 개인적으로 갖고 있는 미션과 내가 속한 기관의 미션이 일치하는 점이 있다는 것에 대한 만족감이 있다.\n자극이 되는 동료 교수님들 때문이다. 내가 속한 학과 안팎에 지적으로 자극을 주시는 여러 동료 교수님들이 계시고, 그런 분들과 편안하게 어울리기도 하고 함께 일하기도 한다. 그분들의 프로페셔널한 모습도 자극이 많이 되지만, 그분들과 사적이며 내밀한 이야기를 나누기도 하며, 서로의 개인사를 공유하기도 한다. 그 과정에서 서로의 가치관에 대해 이야기도 해보는데, 그 과정이 많은 자극이 된다. 당연히, 미국이라고 그런 분들이 없었던 건 아니지만, 한국에는, KAIST에는 바로 옆 방에 계시기도 하고, 같은 건물, 같은 캠퍼스에 계신다. 그러다 보니 아무래도 그런 자극의 빈도가 높다.\n오믈렛 때문이다. 한국에 들어오면서 같은 학과 교수님과 창업을 하게 되었고, 아직까지는 순항 중이다. 창업하고, 동료를 모으고, 투자받고, 회사의 모양을 가꾸어 가면서 여러 가지 어려움이 있지만, 학교에서는 볼 수 없었던 새로운 도전을 맞이하고 있다. 그 도전들을 극복해나가는 과정에서 ‘내가 왜 그랬을까’라는 생각이 들 때도 있었지만, 내가 하고 있는 연구를 기반으로 한 회사를 만들고 있다는 것이 즐겁다. 훌륭한 동료들을 맞이했다는 것도 자랑스럽고, 그 사이에서 내가 할 수 있는 역할이 있다는 점도 흥미롭다. 나는 CTO 역할을 맡고 있지만, 인사, 법무, 계약, 재무, 세무 등 관련 일들도 많이 하면서 새로운 도전을 즐기고 있다. 교원의 기술 기반 회사 창업이라는 점이 KAIST의 미션과 부합한다는 것도 동기부여에 도움이 된다.\n그리고, 가장 중요하게, 내 학생들 때문이다.\n나는 한국에 와서 지금 만난 학생들을 지도하는 것이 매우 즐거운데, 그 이유에 대해 조금 더 곰곰이 생각해봤다. 이 말 하고 싶어서 이 글을 쓴다.\n내가 만난 KAIST 학생들은 그 누구보다 재능 넘치고 성실한 학생들이다. Work ethic이 매우 훌륭하고, 노력을 많이 기울이는 것에 대한 인내심이 높은 편이다. 이런 학생들을 마다할 교수가 어디 있겠나? 나는 이것만으로도 복받았다. 독립적인 사고, 자신의 의견에 대한 고집, 비정형 문제 해결 능력 등은 아직 부족한 편으로 보일 때도 있는데, 아직 학부 졸업한 지 1년밖에 안 된 학생들이니 당연할 것이라 생각된다. 부족한 점은 지도교수인 내가 잘 가이드해주고 조언해주면 될 일이다.\n언어와 문화를 공유하는 학생들이라는 점이 주는 이점이 꽤 있다. 학생들과 공부만 하고 연구만 하면 될 일이겠지만, 나는 그 과정에서 섬세한 피드백을 주는 것을 즐기는 사람이라는 것을 알게 되었다. 학생과 대화할 때 모국어가 아닌 영어로만 대화할 때와 비교해서는 커뮤니케이션의 해상도가 매우 높아진다. “잘 이해되었나요? 네, 이해했습니다.”와 같은 단순한 대화에서도 내가 그 학생에 대해 파악할 수 있는 것들이 많다. 그 학생의 표정과 몸짓, 말하는 억양 같은 것에서 읽을 수 있는 것들이 많고, 그에 맞게 내 다음 행동을 이어나갈 수 있다. 모든 사람들이 이런 해상도 높은 커뮤니케이션을 즐기는 것은 아니겠지만, 나는 그런 걸 즐기는 사람이었다. 미국에서는 경험하기 어려운 것들이었다. 물론, 이런 방식의 커뮤니케이션을 학생들도 즐기고 있는지, 학생들의 성장에 정말 도움이 될 것인지에 대해서는 아직 의문이 있으나, 다만 이런 방식이 내가 선호하고 즐기는 방식이라는 거다.\n한국 학교에서 한국 학생들을 가르치고 지도하여 성장에 도움을 주고 있다는 사실 그 자체가 주는 충족감이 있다. 한국으로 돌아오면서 남긴 글에서 미국에서 지낼 때는 내가 속한 커뮤니티를 명확히 구분하기가 쉽지 않아서 혼란스러웠다고 말한 바 있는데, 한국에 돌아와서야 아무래도 그 점들이 좀 더 명확해졌다. 한국 학생들을 성실히 지도한다는 것 자체가 내가 속한 커뮤니티에 기여할 수 있는 점이라고 생각되며, 그 점에서 학생 지도에 대한 동기부여가 잘 되고 있다.\n그런데, 아무리 이렇다고 한들, 학생들을 지도하는 점이 나를 그렇게까지 행복하게 만들 일인가?\n대체 왜?\n둘째 아이 키우는 것 같다. 이게 내 결론이다.\n흔히 첫째 아이는 부부가 직업적으로 경제적으로 가장 도전적인 상황에서 맞게 되는 경우가 많고, 부모로서의 경험 미숙 등으로 좀 더 엄격하게 대하게 되는 경향이 있다. 사랑스러운 아이지만, 필요 이상의 텐션을 유지하며 키우게 되어 부모와 아이 양쪽의 스트레스가 높아지기도 한다. 반면에 둘째 아이는 대체로 부부가 조금 더 안정되었을 때, 그리고 아이 양육 경험도 충분히 쌓였을 때 맞이하게 되며, 그래서 좀 더 여유가 있다. 흔히 ‘숨만 쉬어도 예쁘다’라는 표현으로 둘째 아이의 사랑스러움에 대해 이야기한다. 적어도 내 개인적인 경험과는 일치한다. 내 첫째 아이는 박사과정 막학기에 태어났고 엄마, 아빠가 모두 테뉴어 트랙 조교수일 때 자랐다. 둘째 아이는 엄마, 아빠가 모두 테뉴어를 받을 때쯤 나고 자랐다. 여전히 바쁘고 힘들었지만, 둘째 양육은 첫째 때와는 양상이 좀 다를 수밖에 없었다. 이런저런 이유로 첫째 아이는 좀 더 차분하고, 둘째 아이는 좀 더 애교 넘친다.\n한국에서 바로 테뉴어트랙을 시작한 교수님들도 첫 지도 학생 그룹이 기억에 많이 남으실 거다. 서로 혼란스러운 시기를 같이 공부하고 같이 연구하며 헤쳐 나가면서 교수와 학생 모두 성공적으로 커리어에 안착하고 독립적인 학자가 되어 졸업하는 시기를 보내면 서로 미운 정 고운 정 다 들 것이다. 하지만 그 과정에서 겪는 테뉴어 트랙 조교수의 스트레스가 무시무시할 수 있다. 미래에 대한 불확실성, 연구비 확보의 어려움, 연구 성과가 잘 나오지 않을 때 겪는 초조함 등으로 교수는 스트레스를 받고, 어쩌면 학생들에게 불필요하게 모질게 대하는 경우도 있을 테다. 학생들도 그 과정에서 힘들고 스트레스를 많이 받을 테고, 졸업할 때쯤이면 지도교수가 미워질지도 모른다. 첫째 아이를 양육하는 것과 비슷한 일이 생긴다.\n나는 미국에서 15년간 15명의 박사과정 학생을 지도하면서 이 과정을 모두 다 겪고 한국에 왔다. 다양한 유형의 학생을 이미 지도 해 본 적 있으며, 연구 역량도 쌓았고, 인적 네트워크도 갖추었으며, 테뉴어도 받아서 마음 조급할 일들은 많이 줄어들었다. 그래서 여유롭다. 위에서 말한 KAIST의 여러 이점들 때문에, 또 여러 멋진 동료 교수님들의 도움으로 첫해부터 매우 운이 좋게도 연구비에 대한 걱정도 많이 없는 상황이다. 내가 학생들에게 해주고 싶은 걸 충분히 해줄 수 있는 상황인 것 같다.\n이런 심적으로 물적으로 여유 있는 상황에서 학생 지도를 하니, 성실하고 재능 있는 내 학생들이 안 예뻐 보일 리 없다. 학생들을 지도하기 위해 만나는 주간 미팅이 즐겁지 않을 리 없다. 학생들이 조금씩 성장해 나가고 성취를 이뤄 나가는 걸 지켜보는 것이 조마조마하면서도 매우 즐겁다. 학생들에게 아쉬운 소리를 하는 경우가 없는 것은 아니지만, 학생들에게 좀 더 관대한 마음으로 조언을 해 줄 수 있다. 운 좋게 여유로운 상황에서 내 마음에 드는 훌륭한 학생들을 만나게 되었고, 그 과정이 매우 즐겁다. 학생들은 훌륭하고, 나만 잘하면 된다.\n‘숨만 쉬어도 예쁜’ 내 학생들은, 다만 숨을 좀 열심히 쉬어야 하기는 한다. 아직 대학원 1~2년 차들이라 수업 들으면서 숙제도 많은데, 내가 진행하고 있는 연구 프로젝트들도 좀 있고, 개인 연구도 진행해야 한다. 그걸 모두 다 해내야 하는데, 또 내가 신나서 벌리는 일들이 좀 있다. 그런 것들 서포트하느라 힘들어하기도 하지만, 아직까지는 모든 학생들이 다 잘 해나가고 있는 것 같다. 한계점에 가까워질 뻔한 일들도 몇 차례 있었던 것 같은데, 해상도 높은 커뮤니케이션의 도움으로 일단은 잘 지나간 것으로 믿고 있다. (이건 학생들 말도 들어봐야…)\n즐거운 마음으로 학생들을 지도하고 있고, 앞으로 좋은 연구자가 될 수 있도록 성실히 잘 지도해야겠다고 다짐한다. 내가 즐기는 만큼, 내 학생들도 나와 함께 공부하고 연구하는 것을 즐길 수 있으면 좋겠다. 학위 과정 중 언젠가 밑바닥으로 내려가는 학생들도 있을 텐데, 그때도 내가 도움이 될 수 있으면 좋겠다. 5년 뒤에도, 10년 뒤에도 계속 학생 지도하는 것이 이렇게 즐거웠으면 좋겠다는 생각을 많이 하고, 그러기 위해 지금부터 내가 해야 할 일이 무엇인지 고민이 많다.\n…\n셋째가 그렇게 예쁘다던데…",
        "dc:creator": "권창현",
        "comments": "https://thoughts.chkwon.net/happy-advisor/#respond",
        "content": "지난해 8월에 한국에 들어와서 KAIST에서 근무한 지 1년이 지났다. 그동안 국내외에 계신 분들을 만날 때면, 한국에 들어가서 어떠냐, 좋으냐는 질문을 많이 들었고, 그때마다 &#8220;너무 좋아요, 행복해요&#8221;라는 말을 많이도 하고 다녔다. 최근에 &#8216;나는 왜 한국&#46;&#46;&#46;",
        "contentSnippet": "지난해 8월에 한국에 들어와서 KAIST에서 근무한 지 1년이 지났다. 그동안 국내외에 계신 분들을 만날 때면, 한국에 들어가서 어떠냐, 좋으냐는 질문을 많이 들었고, 그때마다 “너무 좋아요, 행복해요”라는 말을 많이도 하고 다녔다. 최근에 ‘나는 왜 한국...",
        "guid": "https://thoughts.chkwon.net/?p=987",
        "categories": [
          "잡생각"
        ],
        "isoDate": "2024-11-10T06:17:06.000Z"
      }
    ]
  },
  {
    "name": "권기호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강태욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권용진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권영재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김승호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for boyism Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성준의 린스타트업과 디자인씽킹",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권혁우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김준형",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강동혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고종범",
    "category": "개인",
    "posts": [
      {
        "creator": "고종범",
        "title": "정말 어려운 비폭력 대화",
        "link": "https://brunch.co.kr/@@24SO/48",
        "pubDate": "Sun, 10 Nov 2024 01:42:07 GMT",
        "author": "고종범",
        "content": "비폭력대화라는 것을 접하게 된 것은 애자일 코칭을 배우면서이다. 애자일 코칭은 팀이나 조직이 애자일 방법론을 도입하고 적용할 때 도와주는 역할을 말한다. 애자일 방법론을 도입한다는 것은 변화를 만드는 것이고 변화에는 저항과 갈등이 발생하기 때문에 이를 해결하기 위한 방법으로 애자일 코칭이란 것을 배우게 되었다. 처음 배웠을 때는 좀 막연함이 있었고 사람들과<img src= \"https://img1.daumcdn.net/thumb/R1280x0/?fname=http%3A%2F%2Ft1.daumcdn.net%2Fbrunch%2Fservice%2Fuser%2F24SO%2Fimage%2FhbYaGt75CRMobQQ2X6fEfYpApz0.png\" width=\"500\" />",
        "contentSnippet": "비폭력대화라는 것을 접하게 된 것은 애자일 코칭을 배우면서이다. 애자일 코칭은 팀이나 조직이 애자일 방법론을 도입하고 적용할 때 도와주는 역할을 말한다. 애자일 방법론을 도입한다는 것은 변화를 만드는 것이고 변화에는 저항과 갈등이 발생하기 때문에 이를 해결하기 위한 방법으로 애자일 코칭이란 것을 배우게 되었다. 처음 배웠을 때는 좀 막연함이 있었고 사람들과",
        "guid": "https://brunch.co.kr/@@24SO/48",
        "isoDate": "2024-11-10T01:42:07.000Z"
      }
    ]
  },
  {
    "name": "cheese10yun",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구자철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "FSS",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권동준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김용일",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도균",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김상훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김동우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권윤학",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김만수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "엘키",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태환",
    "category": "개인",
    "posts": [
      {
        "title": "데이터 흐름(Data flow)을 이해해 보는 데 있어 필요한 것은? 짝퉁 개발자처럼 논하기",
        "link": "https://thdev.tech/dataflow/2024/11/09/Data-flow/",
        "pubDate": "Sat, 09 Nov 2024 00:00:00 +0000",
        "content": "<p>제미나이에게 <code class=\"language-plaintext highlighter-rouge\">개발에서 데이터 흐름이란?</code>를 알려달라고 했다.</p>\n\n<blockquote>\n  <p>개발에서 데이터 흐름은 어떤 시스템이나 소프트웨어에서 데이터가 생성되고, 변환되며, 저장되고, 전송되는 과정을 의미합니다. 마치 물이 강을 따라 흐르듯이, 데이터는 시스템 내에서 특정한 경로를 따라 이동하며 가치를 창출합니다.</p>\n</blockquote>\n\n<p>위키백과도 한번 확인해 보았다.</p>\n\n<p><a href=\"https://ko.wikipedia.org/wiki/%EB%8D%B0%EC%9D%B4%ED%84%B0_%ED%9D%90%EB%A6%84\">위키 백과 데이터 흐름 - 링크</a></p>\n\n<blockquote>\n  <p>데이터 흐름(Data flow, 데이터 플로)란 하나의 작업을 수행하기 위하여 실행되는 각각의 세부 작업들 사이에서 자료가 입력되고 출력되는 모습을 의미한다.</p>\n</blockquote>\n\n<p>결국 같은 말이다.</p>\n\n<p>우리가 매우 흔하게 사용하는 데이터 흐름을 가볍게 이해하는 표현으로 서문을 작성해 보았다.</p>\n\n<p>이 글에서 데이터 다양한 데이터 흐름을 이해하는 데 도움이 될만한 내용을 정리해 본 글인데, 실제 함수 위주이니 참고만 한다고 생각하길</p>\n\n<h3>이 글에서는</h3>\n<ul>\n  <li>함수의 blocking vs nonblocking</li>\n  <li>Observer pattern + stream</li>\n  <li>UDF(unidirectional data flow)</li>\n  <li>매우 주관적으로 작성한 글이다.</li>\n  <li>데이터 흐름(Data flow)에 대한 새로운 형태를 만드는 짝퉁 설명이니 재미로 읽기를</li>\n</ul>\n\n<!--more-->\n\n<h2>함수의 blocking vs nonblocking</h2>\n\n<p>함수에는 blocking과 nonblocking으로 구분된다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">fun</span> <span class=\"nf\">main</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n    <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"s\">\"main\"</span><span class=\"p\">)</span>\n    <span class=\"nf\">someA</span><span class=\"p\">()</span>\n    <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"s\">\"end)\n</span><span class=\"p\">}</span>\n\n<span class=\"k\">fun</span> <span class=\"nf\">someA</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n    <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"s\">\"run some a\"</span><span class=\"p\">)</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>이 함수의 결과는 다음과 같다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">main</span>\n<span class=\"n\">run</span> <span class=\"n\">some</span> <span class=\"n\">a</span>\n<span class=\"n\">end</span>\n</code></pre></div></div>\n\n<p>이유는 간단하다. blocking이기 때문이다.</p>\n\n<p>그럼 아래의 코드는?</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">fun</span> <span class=\"nf\">main</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n    <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"s\">\"main\"</span><span class=\"p\">)</span>\n    <span class=\"nf\">someA</span><span class=\"p\">()</span>\n    <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"s\">\"end\"</span><span class=\"p\">)</span>\n<span class=\"p\">}</span>\n\n<span class=\"k\">fun</span> <span class=\"nf\">someA</span><span class=\"p\">()</span> <span class=\"p\">=</span> <span class=\"nc\">CoroutinesScope</span><span class=\"p\">().</span><span class=\"nf\">launch</span> <span class=\"p\">{</span>\n    <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"s\">\"run coroutines)\n</span><span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>이 함수의 결과는 다음과 같을 수 있다.</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>main\nend\nrun coroutines\n</code></pre></div></div>\n\n<p>이는 nonblocking이니 가능한 결과이지만 end 전에 coroutines이 실행되어 순서대로 나올 순 있다.</p>\n\n<p>여기서의 흐름은 처음 예제는 명확히 순서를 보장한다는 점이고, 후자는 비동기가 필요하기에 순서의 보장이 필요 없는 경우를 말한다.</p>\n\n<p>데이터 흐름에서 가장 중요한 부분은 비동기라고 할 수 있다.</p>\n\n<p><br /></p>\n\n<h3>그럼 아래의 코드는 blocking, nonblocking 중 어느 것일까?</h3>\n\n<p>아래 링크에 포함되어 있는 코드를 그대로 가져왔다.</p>\n\n<p><a href=\"https://kotlinlang.org/api/kotlinx.coroutines/kotlinx-coroutines-core/kotlinx.coroutines/coroutine-scope.html\">coroutineScope - link</a></p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">fun</span> <span class=\"nf\">main</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n    <span class=\"nc\">CoroutinesScope</span><span class=\"p\">().</span><span class=\"nf\">launch</span> <span class=\"p\">{</span>\n        <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"s\">\"main\"</span><span class=\"p\">)</span>\n        <span class=\"nf\">showSomeData</span><span class=\"p\">()</span>\n        <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"s\">\"end\"</span><span class=\"p\">)</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n\n<span class=\"k\">suspend</span> <span class=\"k\">fun</span> <span class=\"nf\">showSomeData</span><span class=\"p\">()</span> <span class=\"p\">=</span> <span class=\"nf\">coroutineScope</span> <span class=\"p\">{</span>\n    <span class=\"kd\">val</span> <span class=\"py\">data</span> <span class=\"p\">=</span> <span class=\"nf\">async</span><span class=\"p\">(</span><span class=\"nc\">Dispatchers</span><span class=\"p\">.</span><span class=\"nc\">IO</span><span class=\"p\">)</span> <span class=\"p\">{</span> <span class=\"c1\">// &lt;- extension on current scope</span>\n     <span class=\"o\">..</span><span class=\"p\">.</span> <span class=\"n\">load</span> <span class=\"n\">some</span> <span class=\"nc\">UI</span> <span class=\"n\">data</span> <span class=\"k\">for</span> <span class=\"n\">the</span> <span class=\"nc\">Main</span> <span class=\"n\">thread</span> <span class=\"o\">..</span><span class=\"p\">.</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"nf\">withContext</span><span class=\"p\">(</span><span class=\"nc\">Dispatchers</span><span class=\"p\">.</span><span class=\"nc\">Main</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n        <span class=\"nf\">doSomeWork</span><span class=\"p\">()</span>\n        <span class=\"kd\">val</span> <span class=\"py\">result</span> <span class=\"p\">=</span> <span class=\"n\">data</span><span class=\"p\">.</span><span class=\"nf\">await</span><span class=\"p\">()</span>\n        <span class=\"nf\">display</span><span class=\"p\">(</span><span class=\"n\">result</span><span class=\"p\">)</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<ul>\n  <li>main 함수는 blocking</li>\n  <li>main 함수의 CoroutinesScope().launch의 시작점은 nonblocking</li>\n  <li>launch { } 안의 내용은 blocking</li>\n  <li>showSomeData()의 async 시작 부분은 nonblocking</li>\n  <li>showSomeData()의 async 내부는 blocking</li>\n  <li>showSomeData()의 withContext 부분은 blocking</li>\n</ul>\n\n<p>이 코드는 blocking과 nonblocking이 매우 많이 뒤섞여있다.</p>\n\n<p>이런 코드가 아주 흔한 일이다. 여기서 동기와 비동기 부분을 명확히 이해해야 데이터 흐름을 빠르게 파악할 수 있다.</p>\n\n<p>이 코드는 이 글의 핵심은 아니지만 동기와 비동기를 이해하는 데 있어 중요한 코드이며, coroutines은 일반적인 함수의 사용만큼이나 쉽다는 점이다.</p>\n\n<p><br /></p>\n\n<h2>Observer pattern + stream</h2>\n\n<p>다음 문장은 어떤 부분을 설명하는 걸까?</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>물이 흐르고 있다. 이 흐르는 물에 새로운 물줄기를 추가했다.\n</code></pre></div></div>\n\n<p>이 설명은 개발에서 <code class=\"language-plaintext highlighter-rouge\">HotFlow</code>/<code class=\"language-plaintext highlighter-rouge\">HotObserve</code>에 대한 설명일 수 있지만 내가 적었으니 맞다.</p>\n\n<p>여기서 중요한 부분은 무엇일까?</p>\n\n<p>바로 흐름(flow)이다. Observer pattern에서 데이터 흐름을 설명하는 쉬운 방법 중 하나이다.</p>\n\n<p>물이 흐른다는 표현을 적었으니 흐르는구나를 알 수 있고, 지속적인 흐름을 의미할 수 있다.</p>\n\n<p>반대로 흐르지 않는 경우도 있는데 어떻게 설명해 볼 수 있을까?</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>나는 얼음이다. 땡 해주기 전에는 움직일 수 없다.\n</code></pre></div></div>\n\n<p><br /></p>\n\n<h3>Coroutines flow는?</h3>\n\n<p><a href=\"https://kotlinlang.org/docs/flow.html\">Asynchronous Flow - link</a></p>\n\n<blockquote>\n  <p>A suspending function asynchronously returns a single value, but how can we return multiple asynchronously computed values? This is where Kotlin Flows come in.</p>\n</blockquote>\n\n<p>코루틴 flow는 단일 값을 한 번씩 호출하여 사용할 수 있는 suspend 대신 지속적인 흐름을 가지기 위한 개념을 포함한다. 바로 Observer + stream을 포함한다.</p>\n\n<p><br /></p>\n\n<h3>HotFlow/ColdFlow?</h3>\n\n<p>서문에 적은 설명은 오류를 가질 수 있지만 HotFlow/ColdFlow를 각각 설명하기 쉬운 주제라고 생각하여 필자가 주로 설명하는 방식이다.</p>\n\n<p>HotFlow는 두 가지가 존재하는데</p>\n\n<ul>\n  <li>StateFlow</li>\n  <li>SharedFlow</li>\n</ul>\n\n<p>사용법이 다를 뿐 둘 다 HotFlow이다.</p>\n\n<p>ColdFlow는</p>\n\n<ul>\n  <li>flow {}</li>\n  <li>flowOf()</li>\n</ul>\n\n<p>flow의 시작점이다.</p>\n\n<p><br /></p>\n\n<h3>추가로 - O 어떤 걸로 구성되어 있을까?</h3>\n\n<p>이 글에서는 상세한 내용을 알아보기 위해서 적는 글은 아니니 가볍게 가볍게 어떤 구성으로 이루어져 있을까만 적어본다.</p>\n\n<p><code class=\"language-plaintext highlighter-rouge\">얼음</code>이거나 <code class=\"language-plaintext highlighter-rouge\">물이 흐르거나</code>로 표현할 수 있었던 이유는 흐르는 물 사이에 새로운 물줄기를 만들거나 얼음을 깨어 새로운 데이터 흐름을 추가할 수 있다는 소리인데</p>\n\n<p>요즘 안드로이드에서는 잘 사용하지 않는 ReactiveX 문서에는 여전히</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>ReactiveX is a combination of the best ideas from\nthe Observer pattern, the Iterator pattern, and functional programming\n</code></pre></div></div>\n\n<p>이라고 표현하고 있다.</p>\n\n<p>이 데이터 흐름을 이해하기 위해서는 결국 <code class=\"language-plaintext highlighter-rouge\">Observer pattern</code>과 <code class=\"language-plaintext highlighter-rouge\">Iterator pattern</code> 만 알아도 충분히 이해할 수 있다는 이야기다.</p>\n\n<p>그럼 안드로이드 개발에서 상태의 기억을 가지는 3가지 나열해 보면 아래와 같다.</p>\n\n<ul>\n  <li>RxJava - Subject 패턴들 4가지가 있으나 상황에 따라 다른 사용을 가짐</li>\n  <li>StateFlow</li>\n  <li>LiveData</li>\n</ul>\n\n<p>이들은 모두 데이터의 제공과 이를 소비하는 패턴으로 만들어져있다.</p>\n\n<p>이때 중요한 부분은 불변으로 데이터를 소비할 수 있도록 만들어주는 데 있다. 불변과 equals/hashCode의 중요성을 각각 확인할 수 있는 관련 글 2개를 링크로 추가한다.</p>\n\n<ul>\n  <li><a href=\"https://haeti.palms.blog/effective-kotlin\">Item 1. 가변성을 제한하라 - 안정성 - link</a></li>\n  <li><a href=\"https://medium.com/@mangbaam/kotlin-java-hashset-hashmap-%EB%82%B4%EB%B6%80-%EA%B5%AC%ED%98%84-%EC%82%B4%ED%8E%B4%EB%B3%B4%EA%B8%B0-032e352546b1\">[Kotlin/Java] HashSet, HashMap 내부 구현 살펴보기 - link</a></li>\n</ul>\n\n<p>추가로 RxJava를 제외한 Flow와 LiveData는 Android에서 라이프 사이클에 따른 처리가 잘 되어있는 반면 RxJava는 직접 처리해야 할 부분이 많고 현재는 레거시로 취급되니 궁금하신 분은 RxJava 관련 문서를 참고하시길</p>\n\n<p><br /></p>\n\n<h2>UDF(unidirectional data flow)</h2>\n\n<p>아키텍처를 적극 사용하는 현재는 데이터 흐름이 복잡할 수밖에 없다. 이를 가장 쉽게 설명할 수 있는 부분이 바로 UDF이다.</p>\n\n<p><a href=\"https://developer.android.com/develop/ui/compose/architecture\">Architecting your Compose UI - UDF 부분 참고 - link</a></p>\n\n<p>UDF는 단방향 데이터 플로우인데, 위에서 설명한 blocking, nonblocking 역시 단방향 플로우를 가진다.</p>\n\n<ul>\n  <li>A 함수를 실행</li>\n  <li>B 함수의 처리</li>\n  <li>다시 A 함수로 돌아와 이어가기</li>\n</ul>\n\n<p>데이터 흐름상 단방향이다.</p>\n\n<p>Observer pattern + stream에서는?</p>\n\n<ul>\n  <li>A 함수를 실행</li>\n  <li>B 함수에 구독을 요청하고, stream으로 데이터 흐름을 전달 받는 대기</li>\n  <li>A 함수로 돌아와 A 함수는 끝나고, Stream의 데이터 흐름을 대기</li>\n</ul>\n\n<p>동기와 비동기가 적절하게 포함되어 있는 형태이다.</p>\n\n<p><br /></p>\n\n<h3>아키텍처에서의 UDF</h3>\n\n<p>UDF는 데이터 흐름을 쉽게 이해하는 데 이를 아주 쉽게 설명한 설명이다.</p>\n\n<p>모든 흐름은 함수의 호출과 그 함수 안에서 새로운 함수의 호출 또는 구독으로 이루어진다. 이를 설명하는 가장 쉬운 방법이 UDF 인 것이다.</p>\n\n<p>그럼 아래의 코드에 대해서 UDF로 설명해 보자.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nd\">@Composable</span>\n<span class=\"k\">fun</span> <span class=\"nf\">Screen</span><span class=\"p\">(</span><span class=\"n\">viewModel</span><span class=\"p\">:</span> <span class=\"nc\">SomeViewModel</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"kd\">val</span> <span class=\"py\">someUiState</span> <span class=\"k\">by</span> <span class=\"n\">viewModel</span><span class=\"p\">.</span><span class=\"n\">someUiState</span><span class=\"p\">.</span><span class=\"nf\">collectAsStateWithLifecycle</span><span class=\"p\">()</span>\n    \n    <span class=\"nc\">Screen</span><span class=\"p\">(</span>\n        <span class=\"n\">someUiState</span> <span class=\"p\">=</span> <span class=\"n\">someUiState</span><span class=\"p\">,</span>\n        <span class=\"n\">onClick</span> <span class=\"p\">=</span> <span class=\"p\">{</span> <span class=\"n\">viewModel</span><span class=\"p\">.</span><span class=\"nf\">fatchSome</span><span class=\"p\">()</span> <span class=\"p\">},</span>\n    <span class=\"p\">)</span>\n<span class=\"p\">}</span>\n\n<span class=\"nd\">@Composable</span>\n<span class=\"k\">fun</span> <span class=\"nf\">Screen</span><span class=\"p\">(</span>\n    <span class=\"n\">someUiState</span><span class=\"p\">:</span> <span class=\"nc\">SomeUiState</span><span class=\"p\">,</span>\n    <span class=\"n\">onClick</span><span class=\"p\">:</span> <span class=\"p\">()</span> <span class=\"p\">-&gt;</span> <span class=\"nc\">Unit</span><span class=\"p\">,</span>\n<span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"nc\">Button</span><span class=\"p\">(</span>\n        <span class=\"n\">onClick</span> <span class=\"p\">=</span> <span class=\"n\">onClick</span><span class=\"p\">,</span>\n    <span class=\"p\">)</span>\n<span class=\"p\">}</span>\n\n<span class=\"kd\">class</span> <span class=\"nc\">SomeViewModel</span><span class=\"p\">(</span>\n    <span class=\"k\">private</span> <span class=\"kd\">val</span> <span class=\"py\">someRepository</span><span class=\"p\">:</span> <span class=\"nc\">SomeRepository</span><span class=\"p\">,</span>\n<span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"k\">private</span> <span class=\"kd\">val</span> <span class=\"py\">_uiState</span> <span class=\"p\">=</span> <span class=\"nc\">MutableStateFlow</span><span class=\"p\">(</span><span class=\"nc\">SomeUiState</span><span class=\"p\">.</span><span class=\"nc\">Default</span><span class=\"p\">)</span>\n    <span class=\"kd\">val</span> <span class=\"py\">uiState</span> <span class=\"p\">=</span> <span class=\"n\">_uiState</span><span class=\"p\">.</span><span class=\"nf\">asStateFlow</span><span class=\"p\">()</span>\n\n    <span class=\"nf\">init</span> <span class=\"p\">{</span>\n        <span class=\"n\">someRepository</span><span class=\"p\">.</span><span class=\"nf\">flowSome</span><span class=\"p\">()</span>\n            <span class=\"p\">.</span><span class=\"nf\">map</span> <span class=\"p\">{</span> <span class=\"n\">it</span><span class=\"p\">.</span><span class=\"nf\">toState</span><span class=\"p\">()</span> <span class=\"p\">}</span>\n            <span class=\"p\">.</span><span class=\"nf\">onEach</span> <span class=\"p\">{</span> <span class=\"n\">_uiState</span><span class=\"p\">.</span><span class=\"n\">value</span> <span class=\"p\">=</span> <span class=\"n\">it</span> <span class=\"p\">}</span>\n            <span class=\"p\">.</span><span class=\"nf\">launchIn</span><span class=\"p\">(</span><span class=\"n\">viewModelScope</span><span class=\"p\">)</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"k\">fun</span> <span class=\"nf\">fatchSome</span><span class=\"p\">()</span> <span class=\"p\">=</span> <span class=\"n\">viewModelScope</span><span class=\"p\">.</span><span class=\"nf\">launch</span> <span class=\"p\">{</span>\n        <span class=\"n\">someRepository</span><span class=\"p\">.</span><span class=\"nf\">fatchSome</span><span class=\"p\">()</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n\n<span class=\"kd\">interface</span> <span class=\"nc\">SomeRepository</span> <span class=\"p\">{</span>\n\n    <span class=\"k\">fun</span> <span class=\"nf\">flowSome</span><span class=\"p\">():</span> <span class=\"nc\">Flow</span><span class=\"p\">&lt;</span><span class=\"nc\">SomeEntity</span><span class=\"p\">&gt;</span>\n\n    <span class=\"k\">suspend</span> <span class=\"k\">fun</span> <span class=\"nf\">fatchSome</span><span class=\"p\">()</span>\n<span class=\"p\">}</span>\n\n<span class=\"n\">calss</span> <span class=\"nc\">SomeRepsotiryImpl</span><span class=\"p\">(</span>\n    <span class=\"k\">private</span> <span class=\"kd\">val</span> <span class=\"py\">api</span><span class=\"p\">:</span> <span class=\"nc\">SomeApi</span><span class=\"p\">,</span>\n<span class=\"p\">)</span> <span class=\"p\">:</span> <span class=\"nc\">SomeRepository</span> <span class=\"p\">{</span>\n\n    <span class=\"k\">private</span> <span class=\"kd\">val</span> <span class=\"py\">flowSome</span> <span class=\"p\">=</span> <span class=\"nc\">MutableStateFlow</span><span class=\"p\">&lt;</span><span class=\"nc\">SomeEntity</span><span class=\"p\">?&gt;(</span><span class=\"k\">null</span><span class=\"p\">)</span>\n\n    <span class=\"k\">override</span> <span class=\"k\">fun</span> <span class=\"nf\">flowSome</span><span class=\"p\">():</span> <span class=\"nc\">Flow</span><span class=\"p\">&lt;</span><span class=\"nc\">SomeEntity</span><span class=\"p\">&gt;</span> <span class=\"p\">=</span>\n        <span class=\"n\">flowSome</span><span class=\"p\">.</span><span class=\"nf\">filterNotNull</span><span class=\"p\">()</span>\n\n    <span class=\"k\">override</span> <span class=\"k\">suspend</span> <span class=\"k\">fun</span> <span class=\"nf\">fatchSome</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n        <span class=\"kd\">val</span> <span class=\"py\">resutl</span> <span class=\"p\">=</span> <span class=\"n\">api</span><span class=\"p\">.</span><span class=\"nf\">fatchSome</span><span class=\"p\">()</span>\n        <span class=\"n\">flowSome</span><span class=\"p\">.</span><span class=\"n\">value</span> <span class=\"p\">=</span> <span class=\"n\">result</span><span class=\"p\">.</span><span class=\"nf\">toEntity</span><span class=\"p\">()</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>코드에 대한 설명은 제외하고 데이터 흐름만을 알아보자.</p>\n\n<ul>\n  <li>사용자의 onClick Event를 Composable 함수 Screen에서 발생</li>\n  <li>ViewModel fatchSome() 함수가 호출</li>\n  <li>ViewModel에서는 fatchSome() 함수에서 repository의 fatchSome() 함수를 호출\n    <ul>\n      <li>repository에서는 fatchSome 함수의 응답을 지속적인 흐름을 가지기 위해 flow를 별도로 가진다</li>\n    </ul>\n  </li>\n  <li>repository에서는 someApi를 통해 fatchSome()을 호출한다.</li>\n  <li>응답받은 fatchSome()의 결과를 flowSome에 전달한다.</li>\n  <li>ViewModel에서는 구독 중인 flowSome으로부터 응답을 받고, 상태를 변환하여 UI에 통지하여 UI를 갱신한다.</li>\n</ul>\n\n<p>이 코드는 아주 일반적인 UiState를 서버와의 통신을 통해 갱신하기 위한 부분이다. 여기서 조금 더 나아가면 리엑트의 이펙트까지 포함할 수 있다.</p>\n\n<p>말은 길지만 이 방식은 UDF로 설명하지 않았을 뿐 오래전부터 써오던 방식이다.</p>\n\n<p>그리고 다른 사람들에게 설명하는 가장 간단한 프로세스인데, 필자의 블로그에서도 다양하게 확인할 수 있는 과거의 글들이 많이 있다.</p>\n\n<p>UDF. 단방향을 통해 데이터 흐름을 설명할 수 있다는 부분이 중요한 포인트이다.</p>\n\n<p>이 시점에서 추가로 알아두면 좋은 글들을 나열한다.</p>\n\n<ul>\n  <li><a href=\"https://medium.com/@wisemuji/33910e8f09df\">Jetpack Compose로 UI 조합(Composition)하기 심화 - link</a></li>\n  <li><a href=\"https://thdev.tech/compose/2024/08/04/Android-Compose-Split-Funcation/\">Compose 함수는 어떤 조건으로 나누는것이 좋을까?(Stateful, stateless) - link</a></li>\n  <li><a href=\"https://chanho-study.tistory.com/150\">MVVM에서 MVI로 - link</a></li>\n  <li><a href=\"https://velog.io/@mraz3068/Circuit-Try-Out\">[Android / Compose] Circuit 찍먹 해보기 - link</a></li>\n</ul>\n\n<p>Composable 함수를 어떻게 분리하는 것이 좋을지에 대한 글과 MVI에 대한 설명의 글이다.</p>\n\n<p>그리고 직전에 작성했던 Theme를 다루는 내용도 있으니 함께 보아도 좋을 듯하다.</p>\n\n<ul>\n  <li><a href=\"https://thdev.tech/compose/2024/11/03/GetStream-Theme/\">안드로이드 Theme와 GetStream Theme를 알아보고 CompositionLocalProvider의 역할을 알아본다. - link</a></li>\n</ul>\n\n<p><br /></p>\n\n<h2>서버와의 데이터 흐름</h2>\n\n<p>데이터 흐름의 마지막을 서버와 데이터 흐름을 이야기해 볼 수 있지만 자세한 내용은 없이 어떤 도구를 활용하는지 정도만 이야기해 보려 한다.</p>\n\n<p>클라 입장에서는 서버와의 데이터 통신할 때는 json을 주로 활용한다. 최근에는 protobuf를 활용하는 곳도 많은데 장/단점이 있으니 각각 기술은 서버 개발자와 논의하면 좋다.</p>\n\n<ul>\n  <li>json : <a href=\"https://en.wikipedia.org/wiki/JSON\">JSON(JavaScript Object Notation) - link</a></li>\n  <li>xml : <a href=\"https://en.wikipedia.org/wiki/XML\">Extensible Markup Language (XML) - link</a></li>\n  <li>protobuf : <a href=\"https://en.wikipedia.org/wiki/Protocol_Buffers\">Protocol Buffers (Protobuf) - link</a></li>\n</ul>\n\n<p>데이터 흐름을 얼마나 더 넓게 보는지에 따라 서버에서 제공하는 직전까지의 데이터 흐름으로 설명할 것인지, 이를 넘어가서 설명할 것인지도 정의할 수 있을 것 같다.</p>\n\n<p>우리는 string 형태의 데이터를 주고받는 것이 일반적이지만 결국 이런 데이터는 0/1의 데이터로 변환된다.</p>\n\n<p><br /></p>\n\n<h3>서버까지 포함하여 데이터의 개념은?</h3>\n\n<p>필자는 클라 개발자라 서버에 대해 자세한 이해는 없으니 가볍게 설명해 보겠다.</p>\n\n<ul>\n  <li>클라에서의 데이터 응답을 http 통신을 통해 요청하게 된다.\n    <ul>\n      <li>이때 http는 블로킹 상태로 클라에서는 서버가 응답을 주기 전까지 대기하는데, 이때 클라에서는 UI 상 사용자에게 처리 중임을 알려준다.</li>\n    </ul>\n  </li>\n  <li>서버는 캐싱 상태를 체크하고, DB 서버에 응답을 요청한다.</li>\n  <li>DB 서버는 동기/비동기 상태로 entity를 전달해 주고, 이를 기반으로 클라와 약속한 json 데이터로 변환 후 bloking 상태의 http에 응답해 준다.</li>\n</ul>\n\n<p>클라 입장에서는 nonblocking이겠지만 nonblocking 이후에는 모두 blocking 상태로 서버도 동작한다는 점이다.</p>\n\n<p>서버는 사실상 blocking 작업 상태처럼 보이지만 nonblocking으로 보일 수 있다. 그 안에서 또 nonblocking 작업들이 일어나는 것이다.</p>\n\n<p>모든 처리가 완료되면 클라이언트는 이를 바탕으로 UI에 표현하는 작업을 할 수 있다.</p>\n\n<p>여기서는 아키텍처 개념이 포함될 수 있지만 이 글에서는 다루지 않고, 좀 더 넓은 개념의 아키텍처에 대한 이야기를 준비 중이다.</p>\n\n<p><br /></p>\n\n<h2>데이터 흐름으로 리액트를 이해할 수 있을까?</h2>\n\n<p>리덕스에 대해 제미나이의 응답은 아래와 같다.</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>리덕스(Redux)는 자바스크립트 애플리케이션의 상태 관리를 위한 예측 가능한 상태 컨테이너이다.\n쉽게 말해, 애플리케이션의 데이터를 효율적으로 관리하고 예측 가능하게 만들어주는 도구라고 할 수 있다.\n</code></pre></div></div>\n\n<p>이미 많은 안드로이드 개념에서 리덕스 개념이 포함되어 있는데, UiState와 UDF? 부분일 것 같다.</p>\n\n<p>필자가 직접 iOS TCA를 접하고 있는데, 직접 써보고, 설명을 통해 파악한 리덕스 개념은 아래와 같다.</p>\n\n<ul>\n  <li>\n    <p><a href=\"https://github.com/pointfreeco/swift-composable-architecture\">The Composable Architecture - link</a></p>\n  </li>\n  <li>이벤트의 흐름 : 이벤트의 흐름은 최종 사용자가 가장 아래에 있으니 이를 거슬러 올라가듯 설명한다.\n  현재 나의 이벤트가 보이는 화면상이라면 이를 이전 화면에 전달한다. 이런 흐름의 설명이 업스트림으로 설명할 수 있다.</li>\n  <li>데이터 흐름 : 데이터는 위에서 아래로 흘러간다.\n  데이터 최신화 시 아래로 아래로 흘러간다. 이런 데이터 흐름을 통해 내가 필요한 부분을 캐치하고 화면을 갱신할 수 있다.</li>\n</ul>\n\n<p>검색과 짧은 지식으로 정리할 수 있는 개념은 딱 요 정도일 것 같다. Redux의 데이터 흐름 글이 있어 링크를 추가한다.</p>\n\n<p><a href=\"https://velog.io/@jos9187/Redux%EC%9D%98-%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%9D%90%EB%A6%84\">Redux의 데이터 흐름 - link</a></p>\n\n<p>그리고 안드로이드에서 리액트 형태를 가장 잘 구현한 코드가 드로이드 카이기 아닐까 하여 링크를 추가한다.</p>\n\n<ul>\n  <li><a href=\"https://github.com/DroidKaigi/conference-app-2024\">DroidKaigi 2024 official app - link</a></li>\n</ul>\n\n<p><br /></p>\n\n<h2>마무리</h2>\n\n<p>데이터 흐름을 이해한다는 것은 더 많은 것을 볼 수 있고, 파악할 수 있음을 뜻한다고 생각한다.</p>\n\n<p>짝퉁처럼 개념을 이해하는 데 도움이 될 수 있으면 좋겠지만 이 글에서도 알 수 있는데 동기/비동기/ReactiveX 개념까지 알면 이를 통해 리액트의 리덕스 개념도 이해할 수 있는 시점이 된 것 같다.</p>\n\n<p>아직 부족한 부분이 많아서 이 내용으로 모든 걸 다 설명할 순 없지만 어느 정도 충분히 가장 표면적인 내용을 이해하는 데 도움이 되었길.</p>\n\n<p>마지막으로 재웅님의 안드로이드 면접 질문과 관련한 내용 중 compose 개념 설명이 잘 되어있어 링크를 추가한다.</p>\n\n<p><a href=\"https://skydoves.medium.com/top-9-android-developer-interview-questions-you-should-know-05e8fe2acd2c\">Top 9 Android Developer Interview Questions You Should Know - link</a></p>\n",
        "contentSnippet": "제미나이에게 개발에서 데이터 흐름이란?를 알려달라고 했다.\n개발에서 데이터 흐름은 어떤 시스템이나 소프트웨어에서 데이터가 생성되고, 변환되며, 저장되고, 전송되는 과정을 의미합니다. 마치 물이 강을 따라 흐르듯이, 데이터는 시스템 내에서 특정한 경로를 따라 이동하며 가치를 창출합니다.\n위키백과도 한번 확인해 보았다.\n위키 백과 데이터 흐름 - 링크\n데이터 흐름(Data flow, 데이터 플로)란 하나의 작업을 수행하기 위하여 실행되는 각각의 세부 작업들 사이에서 자료가 입력되고 출력되는 모습을 의미한다.\n결국 같은 말이다.\n우리가 매우 흔하게 사용하는 데이터 흐름을 가볍게 이해하는 표현으로 서문을 작성해 보았다.\n이 글에서 데이터 다양한 데이터 흐름을 이해하는 데 도움이 될만한 내용을 정리해 본 글인데, 실제 함수 위주이니 참고만 한다고 생각하길\n이 글에서는\n함수의 blocking vs nonblocking\nObserver pattern + stream\nUDF(unidirectional data flow)\n매우 주관적으로 작성한 글이다.\n데이터 흐름(Data flow)에 대한 새로운 형태를 만드는 짝퉁 설명이니 재미로 읽기를\n함수의 blocking vs nonblocking\n함수에는 blocking과 nonblocking으로 구분된다.\n\nfun main() {\n    println(\"main\")\n    someA()\n    println(\"end)\n}\n\nfun someA() {\n    println(\"run some a\")\n}\n\n\n이 함수의 결과는 다음과 같다.\n\nmain\nrun some a\nend\n\n\n이유는 간단하다. blocking이기 때문이다.\n그럼 아래의 코드는?\n\nfun main() {\n    println(\"main\")\n    someA()\n    println(\"end\")\n}\n\nfun someA() = CoroutinesScope().launch {\n    println(\"run coroutines)\n}\n\n\n이 함수의 결과는 다음과 같을 수 있다.\n\nmain\nend\nrun coroutines\n\n\n이는 nonblocking이니 가능한 결과이지만 end 전에 coroutines이 실행되어 순서대로 나올 순 있다.\n여기서의 흐름은 처음 예제는 명확히 순서를 보장한다는 점이고, 후자는 비동기가 필요하기에 순서의 보장이 필요 없는 경우를 말한다.\n데이터 흐름에서 가장 중요한 부분은 비동기라고 할 수 있다.\n\n그럼 아래의 코드는 blocking, nonblocking 중 어느 것일까?\n아래 링크에 포함되어 있는 코드를 그대로 가져왔다.\ncoroutineScope - link\n\nfun main() {\n    CoroutinesScope().launch {\n        println(\"main\")\n        showSomeData()\n        println(\"end\")\n    }\n}\n\nsuspend fun showSomeData() = coroutineScope {\n    val data = async(Dispatchers.IO) { // <- extension on current scope\n     ... load some UI data for the Main thread ...\n    }\n\n    withContext(Dispatchers.Main) {\n        doSomeWork()\n        val result = data.await()\n        display(result)\n    }\n}\n\n\nmain 함수는 blocking\nmain 함수의 CoroutinesScope().launch의 시작점은 nonblocking\nlaunch { } 안의 내용은 blocking\nshowSomeData()의 async 시작 부분은 nonblocking\nshowSomeData()의 async 내부는 blocking\nshowSomeData()의 withContext 부분은 blocking\n이 코드는 blocking과 nonblocking이 매우 많이 뒤섞여있다.\n이런 코드가 아주 흔한 일이다. 여기서 동기와 비동기 부분을 명확히 이해해야 데이터 흐름을 빠르게 파악할 수 있다.\n이 코드는 이 글의 핵심은 아니지만 동기와 비동기를 이해하는 데 있어 중요한 코드이며, coroutines은 일반적인 함수의 사용만큼이나 쉽다는 점이다.\n\nObserver pattern + stream\n다음 문장은 어떤 부분을 설명하는 걸까?\n\n물이 흐르고 있다. 이 흐르는 물에 새로운 물줄기를 추가했다.\n\n\n이 설명은 개발에서 HotFlow/HotObserve에 대한 설명일 수 있지만 내가 적었으니 맞다.\n여기서 중요한 부분은 무엇일까?\n바로 흐름(flow)이다. Observer pattern에서 데이터 흐름을 설명하는 쉬운 방법 중 하나이다.\n물이 흐른다는 표현을 적었으니 흐르는구나를 알 수 있고, 지속적인 흐름을 의미할 수 있다.\n반대로 흐르지 않는 경우도 있는데 어떻게 설명해 볼 수 있을까?\n\n나는 얼음이다. 땡 해주기 전에는 움직일 수 없다.\n\n\n\nCoroutines flow는?\nAsynchronous Flow - link\nA suspending function asynchronously returns a single value, but how can we return multiple asynchronously computed values? This is where Kotlin Flows come in.\n코루틴 flow는 단일 값을 한 번씩 호출하여 사용할 수 있는 suspend 대신 지속적인 흐름을 가지기 위한 개념을 포함한다. 바로 Observer + stream을 포함한다.\n\nHotFlow/ColdFlow?\n서문에 적은 설명은 오류를 가질 수 있지만 HotFlow/ColdFlow를 각각 설명하기 쉬운 주제라고 생각하여 필자가 주로 설명하는 방식이다.\nHotFlow는 두 가지가 존재하는데\nStateFlow\nSharedFlow\n사용법이 다를 뿐 둘 다 HotFlow이다.\nColdFlow는\nflow {}\nflowOf()\nflow의 시작점이다.\n\n추가로 - O 어떤 걸로 구성되어 있을까?\n이 글에서는 상세한 내용을 알아보기 위해서 적는 글은 아니니 가볍게 가볍게 어떤 구성으로 이루어져 있을까만 적어본다.\n얼음이거나 물이 흐르거나로 표현할 수 있었던 이유는 흐르는 물 사이에 새로운 물줄기를 만들거나 얼음을 깨어 새로운 데이터 흐름을 추가할 수 있다는 소리인데\n요즘 안드로이드에서는 잘 사용하지 않는 ReactiveX 문서에는 여전히\n\nReactiveX is a combination of the best ideas from\nthe Observer pattern, the Iterator pattern, and functional programming\n\n\n이라고 표현하고 있다.\n이 데이터 흐름을 이해하기 위해서는 결국 Observer pattern과 Iterator pattern 만 알아도 충분히 이해할 수 있다는 이야기다.\n그럼 안드로이드 개발에서 상태의 기억을 가지는 3가지 나열해 보면 아래와 같다.\nRxJava - Subject 패턴들 4가지가 있으나 상황에 따라 다른 사용을 가짐\nStateFlow\nLiveData\n이들은 모두 데이터의 제공과 이를 소비하는 패턴으로 만들어져있다.\n이때 중요한 부분은 불변으로 데이터를 소비할 수 있도록 만들어주는 데 있다. 불변과 equals/hashCode의 중요성을 각각 확인할 수 있는 관련 글 2개를 링크로 추가한다.\nItem 1. 가변성을 제한하라 - 안정성 - link\n[Kotlin/Java] HashSet, HashMap 내부 구현 살펴보기 - link\n추가로 RxJava를 제외한 Flow와 LiveData는 Android에서 라이프 사이클에 따른 처리가 잘 되어있는 반면 RxJava는 직접 처리해야 할 부분이 많고 현재는 레거시로 취급되니 궁금하신 분은 RxJava 관련 문서를 참고하시길\n\nUDF(unidirectional data flow)\n아키텍처를 적극 사용하는 현재는 데이터 흐름이 복잡할 수밖에 없다. 이를 가장 쉽게 설명할 수 있는 부분이 바로 UDF이다.\nArchitecting your Compose UI - UDF 부분 참고 - link\nUDF는 단방향 데이터 플로우인데, 위에서 설명한 blocking, nonblocking 역시 단방향 플로우를 가진다.\nA 함수를 실행\nB 함수의 처리\n다시 A 함수로 돌아와 이어가기\n데이터 흐름상 단방향이다.\nObserver pattern + stream에서는?\nA 함수를 실행\nB 함수에 구독을 요청하고, stream으로 데이터 흐름을 전달 받는 대기\nA 함수로 돌아와 A 함수는 끝나고, Stream의 데이터 흐름을 대기\n동기와 비동기가 적절하게 포함되어 있는 형태이다.\n\n아키텍처에서의 UDF\nUDF는 데이터 흐름을 쉽게 이해하는 데 이를 아주 쉽게 설명한 설명이다.\n모든 흐름은 함수의 호출과 그 함수 안에서 새로운 함수의 호출 또는 구독으로 이루어진다. 이를 설명하는 가장 쉬운 방법이 UDF 인 것이다.\n그럼 아래의 코드에 대해서 UDF로 설명해 보자.\n\n@Composable\nfun Screen(viewModel: SomeViewModel) {\n    val someUiState by viewModel.someUiState.collectAsStateWithLifecycle()\n    \n    Screen(\n        someUiState = someUiState,\n        onClick = { viewModel.fatchSome() },\n    )\n}\n\n@Composable\nfun Screen(\n    someUiState: SomeUiState,\n    onClick: () -> Unit,\n) {\n    Button(\n        onClick = onClick,\n    )\n}\n\nclass SomeViewModel(\n    private val someRepository: SomeRepository,\n) {\n    private val _uiState = MutableStateFlow(SomeUiState.Default)\n    val uiState = _uiState.asStateFlow()\n\n    init {\n        someRepository.flowSome()\n            .map { it.toState() }\n            .onEach { _uiState.value = it }\n            .launchIn(viewModelScope)\n    }\n\n    fun fatchSome() = viewModelScope.launch {\n        someRepository.fatchSome()\n    }\n}\n\ninterface SomeRepository {\n\n    fun flowSome(): Flow<SomeEntity>\n\n    suspend fun fatchSome()\n}\n\ncalss SomeRepsotiryImpl(\n    private val api: SomeApi,\n) : SomeRepository {\n\n    private val flowSome = MutableStateFlow<SomeEntity?>(null)\n\n    override fun flowSome(): Flow<SomeEntity> =\n        flowSome.filterNotNull()\n\n    override suspend fun fatchSome() {\n        val resutl = api.fatchSome()\n        flowSome.value = result.toEntity()\n    }\n}\n\n\n코드에 대한 설명은 제외하고 데이터 흐름만을 알아보자.\n사용자의 onClick Event를 Composable 함수 Screen에서 발생\nViewModel fatchSome() 함수가 호출\nViewModel에서는 fatchSome() 함수에서 repository의 fatchSome() 함수를 호출\n    \nrepository에서는 fatchSome 함수의 응답을 지속적인 흐름을 가지기 위해 flow를 별도로 가진다\nrepository에서는 someApi를 통해 fatchSome()을 호출한다.\n응답받은 fatchSome()의 결과를 flowSome에 전달한다.\nViewModel에서는 구독 중인 flowSome으로부터 응답을 받고, 상태를 변환하여 UI에 통지하여 UI를 갱신한다.\n이 코드는 아주 일반적인 UiState를 서버와의 통신을 통해 갱신하기 위한 부분이다. 여기서 조금 더 나아가면 리엑트의 이펙트까지 포함할 수 있다.\n말은 길지만 이 방식은 UDF로 설명하지 않았을 뿐 오래전부터 써오던 방식이다.\n그리고 다른 사람들에게 설명하는 가장 간단한 프로세스인데, 필자의 블로그에서도 다양하게 확인할 수 있는 과거의 글들이 많이 있다.\nUDF. 단방향을 통해 데이터 흐름을 설명할 수 있다는 부분이 중요한 포인트이다.\n이 시점에서 추가로 알아두면 좋은 글들을 나열한다.\nJetpack Compose로 UI 조합(Composition)하기 심화 - link\nCompose 함수는 어떤 조건으로 나누는것이 좋을까?(Stateful, stateless) - link\nMVVM에서 MVI로 - link\n[Android / Compose] Circuit 찍먹 해보기 - link\nComposable 함수를 어떻게 분리하는 것이 좋을지에 대한 글과 MVI에 대한 설명의 글이다.\n그리고 직전에 작성했던 Theme를 다루는 내용도 있으니 함께 보아도 좋을 듯하다.\n안드로이드 Theme와 GetStream Theme를 알아보고 CompositionLocalProvider의 역할을 알아본다. - link\n\n서버와의 데이터 흐름\n데이터 흐름의 마지막을 서버와 데이터 흐름을 이야기해 볼 수 있지만 자세한 내용은 없이 어떤 도구를 활용하는지 정도만 이야기해 보려 한다.\n클라 입장에서는 서버와의 데이터 통신할 때는 json을 주로 활용한다. 최근에는 protobuf를 활용하는 곳도 많은데 장/단점이 있으니 각각 기술은 서버 개발자와 논의하면 좋다.\njson : JSON(JavaScript Object Notation) - link\nxml : Extensible Markup Language (XML) - link\nprotobuf : Protocol Buffers (Protobuf) - link\n데이터 흐름을 얼마나 더 넓게 보는지에 따라 서버에서 제공하는 직전까지의 데이터 흐름으로 설명할 것인지, 이를 넘어가서 설명할 것인지도 정의할 수 있을 것 같다.\n우리는 string 형태의 데이터를 주고받는 것이 일반적이지만 결국 이런 데이터는 0/1의 데이터로 변환된다.\n\n서버까지 포함하여 데이터의 개념은?\n필자는 클라 개발자라 서버에 대해 자세한 이해는 없으니 가볍게 설명해 보겠다.\n클라에서의 데이터 응답을 http 통신을 통해 요청하게 된다.\n    \n이때 http는 블로킹 상태로 클라에서는 서버가 응답을 주기 전까지 대기하는데, 이때 클라에서는 UI 상 사용자에게 처리 중임을 알려준다.\n서버는 캐싱 상태를 체크하고, DB 서버에 응답을 요청한다.\nDB 서버는 동기/비동기 상태로 entity를 전달해 주고, 이를 기반으로 클라와 약속한 json 데이터로 변환 후 bloking 상태의 http에 응답해 준다.\n클라 입장에서는 nonblocking이겠지만 nonblocking 이후에는 모두 blocking 상태로 서버도 동작한다는 점이다.\n서버는 사실상 blocking 작업 상태처럼 보이지만 nonblocking으로 보일 수 있다. 그 안에서 또 nonblocking 작업들이 일어나는 것이다.\n모든 처리가 완료되면 클라이언트는 이를 바탕으로 UI에 표현하는 작업을 할 수 있다.\n여기서는 아키텍처 개념이 포함될 수 있지만 이 글에서는 다루지 않고, 좀 더 넓은 개념의 아키텍처에 대한 이야기를 준비 중이다.\n\n데이터 흐름으로 리액트를 이해할 수 있을까?\n리덕스에 대해 제미나이의 응답은 아래와 같다.\n\n리덕스(Redux)는 자바스크립트 애플리케이션의 상태 관리를 위한 예측 가능한 상태 컨테이너이다.\n쉽게 말해, 애플리케이션의 데이터를 효율적으로 관리하고 예측 가능하게 만들어주는 도구라고 할 수 있다.\n\n\n이미 많은 안드로이드 개념에서 리덕스 개념이 포함되어 있는데, UiState와 UDF? 부분일 것 같다.\n필자가 직접 iOS TCA를 접하고 있는데, 직접 써보고, 설명을 통해 파악한 리덕스 개념은 아래와 같다.\nThe Composable Architecture - link\n이벤트의 흐름 : 이벤트의 흐름은 최종 사용자가 가장 아래에 있으니 이를 거슬러 올라가듯 설명한다.\n  현재 나의 이벤트가 보이는 화면상이라면 이를 이전 화면에 전달한다. 이런 흐름의 설명이 업스트림으로 설명할 수 있다.\n데이터 흐름 : 데이터는 위에서 아래로 흘러간다.\n  데이터 최신화 시 아래로 아래로 흘러간다. 이런 데이터 흐름을 통해 내가 필요한 부분을 캐치하고 화면을 갱신할 수 있다.\n검색과 짧은 지식으로 정리할 수 있는 개념은 딱 요 정도일 것 같다. Redux의 데이터 흐름 글이 있어 링크를 추가한다.\nRedux의 데이터 흐름 - link\n그리고 안드로이드에서 리액트 형태를 가장 잘 구현한 코드가 드로이드 카이기 아닐까 하여 링크를 추가한다.\nDroidKaigi 2024 official app - link\n\n마무리\n데이터 흐름을 이해한다는 것은 더 많은 것을 볼 수 있고, 파악할 수 있음을 뜻한다고 생각한다.\n짝퉁처럼 개념을 이해하는 데 도움이 될 수 있으면 좋겠지만 이 글에서도 알 수 있는데 동기/비동기/ReactiveX 개념까지 알면 이를 통해 리액트의 리덕스 개념도 이해할 수 있는 시점이 된 것 같다.\n아직 부족한 부분이 많아서 이 내용으로 모든 걸 다 설명할 순 없지만 어느 정도 충분히 가장 표면적인 내용을 이해하는 데 도움이 되었길.\n마지막으로 재웅님의 안드로이드 면접 질문과 관련한 내용 중 compose 개념 설명이 잘 되어있어 링크를 추가한다.\nTop 9 Android Developer Interview Questions You Should Know - link",
        "guid": "https://thdev.tech/dataflow/2024/11/09/Data-flow/",
        "isoDate": "2024-11-09T00:00:00.000Z"
      }
    ]
  },
  {
    "name": "김슬기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김광현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김영우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강명훈",
    "category": "개인",
    "posts": [
      {
        "title": "VirtualBox 네트워크",
        "link": "https://kangmyounghun.blogspot.com/2024/11/virtualbox.html",
        "pubDate": "2024-11-10T05:02:00.004Z",
        "author": "강명훈",
        "content": "<div>집에서 잘 되는 브리지 모드가 밖에만 나가면 안 돼서 NAT 모드를 쓰는데 VM 복제 시 IP가 바뀌지 않는다. 맥어드레스를 바꿔도 안 됨. machine-id가 같아서 그런가?</div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiNV-Xvln_p9C1dmXVmTNiGL5WQYVxIorVE6a1LhkZcc-I6ZD3YcdSFVjZXAh3XWVW68I0JeFkk-CjEsKSOD5vY1gkXO4-HAWGciNXFyLeFdqB4xtDZlDirPDHkqEO2jZhntXXIShCdF_Mefp2GZd6AlabKp1KZlAyBJNMnpCl-fLt_ngS3-9c84eK64Cjs/s795/virtualbox_nat.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"531\" data-original-width=\"795\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiNV-Xvln_p9C1dmXVmTNiGL5WQYVxIorVE6a1LhkZcc-I6ZD3YcdSFVjZXAh3XWVW68I0JeFkk-CjEsKSOD5vY1gkXO4-HAWGciNXFyLeFdqB4xtDZlDirPDHkqEO2jZhntXXIShCdF_Mefp2GZd6AlabKp1KZlAyBJNMnpCl-fLt_ngS3-9c84eK64Cjs/s16000/virtualbox_nat.png\" /></a></div><div></div><span><a name='more'></a></span><div><div><pre><code><div>[root@Snort ~]# ifconfig eth0</div><div>eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;&nbsp; mtu 1500</div><div>&nbsp; &nbsp; &nbsp; &nbsp; inet 10.0.2.15&nbsp; netmask 255.255.255.0&nbsp; broadcast 10.0.2.255</div><div>&nbsp; &nbsp; &nbsp; &nbsp; inet6 fe80::a00:27ff:fe6b:e0d9&nbsp; prefixlen 64&nbsp; scopeid 0x20&lt;link&gt;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; ether 08:00:27:6b:e0:d9&nbsp; txqueuelen 1000&nbsp; (Ethernet)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; RX packets 675055&nbsp; bytes 999902873 (953.5 MiB)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; RX errors 0&nbsp; dropped 0&nbsp; overruns 0&nbsp; frame 0</div><div>&nbsp; &nbsp; &nbsp; &nbsp; TX packets 78402&nbsp; bytes 4788435 (4.5 MiB)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; TX errors 0&nbsp; dropped 0 overruns 0&nbsp; carrier 0&nbsp; collisions 0</div></code></pre></div></div><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjDOBwpWHacDeVJeHd4sjv0o7NEjtlc0R0b0K6eAxthyn7t4oAVWgfJvvt8lee2_rDM67KBOExMXOmfxrpcIzDY3D4_2LmnU3Z89Y4leIBSqmVB1sErMEoGlEj-HOGCWhoiqjkVGwRYsk5X3PDfIorBrlazSNwNyi3QlZXBSyFlofgIVvZEoaiU6F-qN_T6/s795/virtualbox_nat2.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"531\" data-original-width=\"795\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjDOBwpWHacDeVJeHd4sjv0o7NEjtlc0R0b0K6eAxthyn7t4oAVWgfJvvt8lee2_rDM67KBOExMXOmfxrpcIzDY3D4_2LmnU3Z89Y4leIBSqmVB1sErMEoGlEj-HOGCWhoiqjkVGwRYsk5X3PDfIorBrlazSNwNyi3QlZXBSyFlofgIVvZEoaiU6F-qN_T6/s16000/virtualbox_nat2.png\" /></a></div><div><div><pre><code><div>[root@Snort ~]# ifconfig eth0</div><div>eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;&nbsp; mtu 1500</div><div>&nbsp; &nbsp; &nbsp; &nbsp; inet 10.0.2.15&nbsp; netmask 255.255.255.0&nbsp; broadcast 10.0.2.255</div><div>&nbsp; &nbsp; &nbsp; &nbsp; inet6 fe80::a00:27ff:fe6b:e0d9&nbsp; prefixlen 64&nbsp; scopeid 0x20&lt;link&gt;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; ether 08:00:27:6b:e0:d9&nbsp; txqueuelen 1000&nbsp; (Ethernet)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; RX packets 675055&nbsp; bytes 999902873 (953.5 MiB)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; RX errors 0&nbsp; dropped 0&nbsp; overruns 0&nbsp; frame 0</div><div>&nbsp; &nbsp; &nbsp; &nbsp; TX packets 78402&nbsp; bytes 4788435 (4.5 MiB)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; TX errors 0&nbsp; dropped 0 overruns 0&nbsp; carrier 0&nbsp; collisions 0</div></code></pre></div><br /></div><div><b><span style=\"font-size: x-large;\">NAT Network</span></b></div><div><br /></div><div>도구 &gt; 만들기 &gt; Nat Network 생성.</div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgsQDsetx-nF5g0uu5_y4bHOoCnIeldiewynH4wiTVu0cZ0KEi-v_Pyq0WEywZyvY9MgmimYmYoGYYpqtSMNsGYPabmM0lxCgCZ87TVeIrfW0sQ4QIRnAaIrS9k7r4QbC-MGxKQSl3zgYXuq92ExaHQcmpWetqQ8zO5bNiRf1Ax9hU2brihpXRuY0dSNwcJ/s904/virtualbox_nat_network.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"593\" data-original-width=\"904\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgsQDsetx-nF5g0uu5_y4bHOoCnIeldiewynH4wiTVu0cZ0KEi-v_Pyq0WEywZyvY9MgmimYmYoGYYpqtSMNsGYPabmM0lxCgCZ87TVeIrfW0sQ4QIRnAaIrS9k7r4QbC-MGxKQSl3zgYXuq92ExaHQcmpWetqQ8zO5bNiRf1Ax9hU2brihpXRuY0dSNwcJ/s16000/virtualbox_nat_network.png\" /></a></div><div><br /></div><div>어댑터 설정을 'NAT -&gt; NAT 네트워크'로 수정. 이후 맥어드레스 변경도 필수.</div><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhc0DWCPTEN-rr5xnCYM0LdyhjXbcUZUMank6cVwbOfeT2sH9-OKnOnfvkpmgnjuVP_YIxDihd4iNQIs2PnHF9OiTQN_zvveHrQfkCB_cAJeh_1DuyvR13TeP-Klg-7EQgACBoUmJdnafmCfoT_PKRs7SQXDGHc350Y0m3jEhhCY4QdfTv6o1BRqVuBTdi1/s795/virtualbox_nat_network2.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"531\" data-original-width=\"795\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhc0DWCPTEN-rr5xnCYM0LdyhjXbcUZUMank6cVwbOfeT2sH9-OKnOnfvkpmgnjuVP_YIxDihd4iNQIs2PnHF9OiTQN_zvveHrQfkCB_cAJeh_1DuyvR13TeP-Klg-7EQgACBoUmJdnafmCfoT_PKRs7SQXDGHc350Y0m3jEhhCY4QdfTv6o1BRqVuBTdi1/s16000/virtualbox_nat_network2.png\" /></a></div><div><div><pre><code><div>[root@Snort ~]# ifconfig eth0</div><div>eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;&nbsp; mtu 1500</div><div>&nbsp; &nbsp; &nbsp; &nbsp; inet 10.0.2.15&nbsp; netmask 255.255.255.0&nbsp; broadcast 10.0.2.255</div><div>&nbsp; &nbsp; &nbsp; &nbsp; inet6 fe80::a00:27ff:fe6b:e0d9&nbsp; prefixlen 64&nbsp; scopeid 0x20&lt;link&gt;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; ether 08:00:27:6b:e0:d9&nbsp; txqueuelen 1000&nbsp; (Ethernet)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; RX packets 675055&nbsp; bytes 999902873 (953.5 MiB)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; RX errors 0&nbsp; dropped 0&nbsp; overruns 0&nbsp; frame 0</div><div>&nbsp; &nbsp; &nbsp; &nbsp; TX packets 78402&nbsp; bytes 4788435 (4.5 MiB)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; TX errors 0&nbsp; dropped 0 overruns 0&nbsp; carrier 0&nbsp; collisions 0</div></code></pre></div></div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh13CUPx8mNmMYlfofiDXHPW3FEGIR-kihIhLGZy8Qpt0sGHV3cSZuhWSuRjhyOQKo23DXd_zzJp8wjH5LIGBetAJKXjBWtk-9u8p_ADPXHryzIGWbg-mrNF-bOM1C2KD2RQAwjGQySeBIWlXXvrqgrYOHuylqScI3GjRVRFKBe1c7yeS-hj92YlRUK6qW-/s795/virtualbox_nat_network3.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"531\" data-original-width=\"795\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh13CUPx8mNmMYlfofiDXHPW3FEGIR-kihIhLGZy8Qpt0sGHV3cSZuhWSuRjhyOQKo23DXd_zzJp8wjH5LIGBetAJKXjBWtk-9u8p_ADPXHryzIGWbg-mrNF-bOM1C2KD2RQAwjGQySeBIWlXXvrqgrYOHuylqScI3GjRVRFKBe1c7yeS-hj92YlRUK6qW-/s16000/virtualbox_nat_network3.png\" /></a></div><div><div><pre><code><div>[root@Snort ~]# ifconfig eth0</div><div>eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;&nbsp; mtu 1500</div><div>&nbsp; &nbsp; &nbsp; &nbsp; inet 10.0.2.4&nbsp; netmask 255.255.255.0&nbsp; broadcast 10.0.2.255</div><div>&nbsp; &nbsp; &nbsp; &nbsp; inet6 fe80::a00:27ff:fe6b:e0d9&nbsp; prefixlen 64&nbsp; scopeid 0x20&lt;link&gt;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; ether 08:00:27:6b:e0:d9&nbsp; txqueuelen 1000&nbsp; (Ethernet)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; RX packets 675055&nbsp; bytes 999902873 (953.5 MiB)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; RX errors 0&nbsp; dropped 0&nbsp; overruns 0&nbsp; frame 0</div><div>&nbsp; &nbsp; &nbsp; &nbsp; TX packets 78402&nbsp; bytes 4788435 (4.5 MiB)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; TX errors 0&nbsp; dropped 0 overruns 0&nbsp; carrier 0&nbsp; collisions 0</div></code></pre></div><br /></div><div>이 간단한 걸 몰라서 여태 헤맸네<span style=\"font-size: x-small;\">(..)</span></div><div><br /></div>",
        "contentSnippet": "집에서 잘 되는 브리지 모드가 밖에만 나가면 안 돼서 NAT 모드를 쓰는데 VM 복제 시 IP가 바뀌지 않는다. 맥어드레스를 바꿔도 안 됨. machine-id가 같아서 그런가?\n\n\n\n\n\n\n\n[root@Snort ~]# ifconfig eth0\neth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n        inet 10.0.2.15  netmask 255.255.255.0  broadcast 10.0.2.255\n        inet6 fe80::a00:27ff:fe6b:e0d9  prefixlen 64  scopeid 0x20<link>\n        ether 08:00:27:6b:e0:d9  txqueuelen 1000  (Ethernet)\n        RX packets 675055  bytes 999902873 (953.5 MiB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 78402  bytes 4788435 (4.5 MiB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\n\n\n\n\n\n[root@Snort ~]# ifconfig eth0\neth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n        inet 10.0.2.15  netmask 255.255.255.0  broadcast 10.0.2.255\n        inet6 fe80::a00:27ff:fe6b:e0d9  prefixlen 64  scopeid 0x20<link>\n        ether 08:00:27:6b:e0:d9  txqueuelen 1000  (Ethernet)\n        RX packets 675055  bytes 999902873 (953.5 MiB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 78402  bytes 4788435 (4.5 MiB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\n\n\nNAT Network\n\n\n도구 > 만들기 > Nat Network 생성.\n\n\n\n\n\n어댑터 설정을 'NAT -> NAT 네트워크'로 수정. 이후 맥어드레스 변경도 필수.\n\n\n\n\n[root@Snort ~]# ifconfig eth0\neth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n        inet 10.0.2.15  netmask 255.255.255.0  broadcast 10.0.2.255\n        inet6 fe80::a00:27ff:fe6b:e0d9  prefixlen 64  scopeid 0x20<link>\n        ether 08:00:27:6b:e0:d9  txqueuelen 1000  (Ethernet)\n        RX packets 675055  bytes 999902873 (953.5 MiB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 78402  bytes 4788435 (4.5 MiB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\n\n\n\n\n\n\n[root@Snort ~]# ifconfig eth0\neth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n        inet 10.0.2.4  netmask 255.255.255.0  broadcast 10.0.2.255\n        inet6 fe80::a00:27ff:fe6b:e0d9  prefixlen 64  scopeid 0x20<link>\n        ether 08:00:27:6b:e0:d9  txqueuelen 1000  (Ethernet)\n        RX packets 675055  bytes 999902873 (953.5 MiB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 78402  bytes 4788435 (4.5 MiB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\n\n\n이 간단한 걸 몰라서 여태 헤맸네(..)",
        "id": "tag:blogger.com,1999:blog-2597780270996323853.post-8727583642918527329",
        "isoDate": "2024-11-10T05:02:00.004Z"
      }
    ]
  },
  {
    "name": "김민장",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕홍",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성중",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구교준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고명환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성희",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강병수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김봉현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강형석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수로",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강미경",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강진우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권민재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태관",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도곤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "칡토스의 게임 개발",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김놀부",
    "category": "개인",
    "posts": []
  },
  {
    "name": "프리웨어 이야기",
    "category": "개인",
    "posts": [
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "AI 최신 자료 검색 최강자, 퍼플렉시티(Perplexity) 활용법",
        "link": "http://muzbox.tistory.com/483497",
        "pubDate": "Wed, 13 Nov 2024 10:52:30 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483497#entry483497comment",
        "content": "<p data-ke-size=\"size16\">퍼플렉시티(Perplexity AI) 의 독보적인 기능과 활용 방법을 통해 정보 탐색, 연구 분석, 생산성 향상에 도움을 받을 수 있습니다. Copilot 기능과 실시간 업데이트로 업무 효율을 극대화하세요.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"퍼플렉시티 사용법.jpg\" data-origin-width=\"700\" data-origin-height=\"368\"><span data-url=\"https://blog.kakaocdn.net/dn/bWlh8Y/btsKFLYLP34/GoTpVX4zm3YQlFFj840VZK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bWlh8Y/btsKFLYLP34/GoTpVX4zm3YQlFFj840VZK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/bWlh8Y/btsKFLYLP34/GoTpVX4zm3YQlFFj840VZK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbWlh8Y%2FbtsKFLYLP34%2FGoTpVX4zm3YQlFFj840VZK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"퍼플렉시티 활용법\" data-filename=\"퍼플렉시티 사용법.jpg\" data-origin-width=\"700\" data-origin-height=\"368\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;최근 몇 년간 인공지능(AI) 기술은 빠르게 발전하며 일상 생활과 업무 환경에 큰 변화를 가져왔습니다. 많은 사람들이 AI 도구에 대해 관심을 갖고 있지만, 여전히 AI 활용에 대한 부정적인 시각도 존재합니다. 저 역시 한때는 AI에 대해 회의적이었으나, <b>Perplexity AI</b>라는 새로운 도구를 사용하면서 생각이 완전히 바뀌었습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이 글에서는 Perplexity AI가 어떻게 생산성을 높이고 일상적인 작업에 도움을 주는지, 특히 정보 탐색과 분석에서 어떤 혁신적인 기능을 제공하는지 알아보겠습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>Perplexity AI란 무엇인가?</b></span></h2>\n<p data-ke-size=\"size16\">Perplexity AI는 \"정보 탐색과 호기심을 위한 스위스 군용 칼\"로 불리며, 사용자의 질문에 대해 방대한 데이터베이스를 통해 실시간으로 답변을 제공합니다. 그 과정에서 정확한 출처를 제시하며, 최신 정보를 반영해 사용자에게 신뢰도 높은 결과를 제공합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>Perplexity AI의 주요 기능</b></span></h3>\n<ol style=\"list-style-type: decimal;\" data-ke-list-type=\"decimal\">\n<li><b>정보 검색 및 분석</b>: 사용자가 질문을 입력하면 AI가 신속하게 관련 데이터를 분석하여 정확한 답변을 제시합니다. 단순한 질문 답변을 넘어 복잡한 데이터 분석까지 가능해, 특히 연구와 학습에 유용합니다.</li>\n<li><b>다양한 AI 모델 지원</b>: 무료 버전과 유료 Pro 버전으로 나뉘어져 있으며, 유료 사용자는 Claude 3.5 Sonnet, GPT-4, Grok-2와 같은 다양한 모델을 선택할 수 있습니다. 이를 통해 특정 작업에 맞는 AI를 활용할 수 있습니다.</li>\n<li><b>문서 업로드 및 분석</b>: Pro 버전에서는 사용자가 문서를 업로드하면 해당 문서의 주요 내용을 요약하고 분석하는 기능도 제공합니다. 이로 인해 대량의 텍스트 데이터를 효율적으로 관리할 수 있습니다.</li>\n</ol>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>Perplexity AI의 차별화된 기능</b></span></h2>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>1. 실시간 정보 업데이트와 정확한 출처 제공</b></span></h3>\n<p data-ke-size=\"size16\">많은 AI 도구들이 존재하지만 Perplexity AI는 특히 <b>실시간 정보 업데이트</b> 기능으로 차별화됩니다. 예를 들어, 특정 뉴스나 트렌드에 대해 질문하면 가장 최신의 정보가 반영된 답변을 제공합니다. 또한, 모든 답변에 <b>출처를 명확히 제시</b>하므로 사용자는 제시된 정보를 신뢰하고 참고할 수 있습니다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>실시간 업데이트</b>: 검색할 때마다 최신 정보가 반영되어 더 정확한 답변을 제공합니다.</li>\n<li><b>출처 확인 기능</b>: 답변과 함께 관련된 출처를 명시하여 정보의 신뢰도를 높입니다. 특히 연구 논문 작성이나 학술 자료 수집에 유용합니다.</li>\n</ul>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>2. Copilot 기능을 통한 맞춤형 검색 경험 제공</b></span></h3>\n<p data-ke-size=\"size16\">Perplexity AI의 <b>Copilot 기능</b>은 사용자의 질문에 대해 추가적인 질문을 던져 보다 정교하고 맞춤형 답변을 도출합니다. 이 기능은 사용자가 모호한 질문을 했을 때 추가적인 정보를 요구하여, 사용자가 원래 찾고자 했던 정보를 정확하게 찾아줍니다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>개인화된 검색 지원</b>: Copilot이 사용자의 의도를 파악해 구체적인 정보를 제공합니다.</li>\n<li><b>대화형 인터페이스</b>: 질문에 대한 추가 질문을 통해 사용자 맞춤형 검색 결과를 제공합니다.</li>\n</ul>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>3. 다양한 활용 사례</b></span></h3>\n<p data-ke-size=\"size16\">Perplexity AI는 단순한 검색 도구 이상의 가치를 제공합니다. 특히 다양한 분야에서 유용하게 활용될 수 있습니다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>제품 조사</b>: 쇼핑할 때 여러 사이트를 비교하는 대신, Perplexity AI를 사용해 추천 제품을 찾을 수 있습니다. 예를 들어, 반려견 하네스를 찾는 데 사용했을 때, 다양한 리뷰와 평점을 기반으로 최적의 선택을 도와줍니다.</li>\n<li><b>과학적 자료 조사</b>: 운동 프로그램 설계 시, 근거 기반의 자료를 빠르게 수집하고 정리할 수 있습니다. 이를 통해 효과적인 운동 계획을 세우는 데 도움을 받았습니다.</li>\n<li><b>SEO 최적화</b>: 블로그나 웹사이트 콘텐츠 작성 시, 키워드 연구를 통해 더 나은 SEO 성과를 거둘 수 있도록 지원합니다.</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>Perplexity AI 기본 사용법</b></span></h2>\n<p data-ke-size=\"size16\">퍼플렉시티 초기화면은 챗GPT와 비슷합니다. 퍼플렉시티의 기본 옵션은 '웹'검색이나, 모드 선택에서 다양한 옵션으로 사용자 응답 효율을 극대화 할 수 있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"퍼플렉시티 사용법 2.jpg\" data-origin-width=\"823\" data-origin-height=\"443\"><span data-url=\"https://blog.kakaocdn.net/dn/nMTH2/btsKHtWCxh1/5GIOu7R84SrDceDoKkpUek/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/nMTH2/btsKHtWCxh1/5GIOu7R84SrDceDoKkpUek/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/nMTH2/btsKHtWCxh1/5GIOu7R84SrDceDoKkpUek/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FnMTH2%2FbtsKHtWCxh1%2F5GIOu7R84SrDceDoKkpUek%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"퍼플렉시티 사용법 2.jpg\" data-origin-width=\"823\" data-origin-height=\"443\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>Perplexity AI 활용 팁</b></span></h2>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>1. 키워드 연구 및 SEO 최적화</b></span></h3>\n<p data-ke-size=\"size16\">Perplexity AI는 단순한 검색 도구를 넘어 <b>SEO 최적화 도구</b>로도 활용될 수 있습니다. 주제에 맞는 핵심 키워드를 찾아내어 콘텐츠의 가독성과 검색 순위를 높이는 데 도움을 줍니다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>키워드 분석</b>: 특정 주제와 관련된 트렌드 키워드를 찾아 SEO 전략에 반영할 수 있습니다.</li>\n<li><b>SEO 성과 향상</b>: 블로그 포스팅이나 제품 페이지 최적화에 활용하여 검색 노출을 극대화할 수 있습니다.</li>\n</ul>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>2. 학술 자료 정리 및 요약</b></span></h3>\n<p data-ke-size=\"size16\">Perplexity AI는 학술 논문이나 연구 자료를 <b>신속하게 분석하고 요약</b>하는 데 탁월합니다. 복잡한 논문을 빠르게 읽고 이해할 수 있어 연구자나 학생들에게 유용한 도구입니다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>논문 요약</b>: 방대한 학술 자료를 요약하여 핵심 내용을 빠르게 파악할 수 있습니다.</li>\n<li><b>자료 검증</b>: AI가 제시한 출처를 통해 자료의 신뢰성을 직접 확인할 수 있습니다.</li>\n</ul>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>3. 소비자 제품 리뷰 분석</b></span></h3>\n<p data-ke-size=\"size16\">Perplexity AI를 사용하면 다양한 리뷰와 평점을 분석하여 <b>소비자 제품 선택</b>에 도움을 받을 수 있습니다. 단순한 평점 비교를 넘어, 사용자 리뷰를 분석해 제품의 강점과 약점을 파악할 수 있습니다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>구매 결정 지원</b>: 제품의 장단점을 한눈에 파악하여 현명한 소비 결정을 내릴 수 있습니다.</li>\n<li><b>제품 리뷰 요약</b>: 여러 리뷰를 요약해 시간 절약이 가능합니다.</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>Perplexity AI 프롬프트 예시 모음</b></span></h2>\n<p data-ke-size=\"size16\">Perplexity AI를 최대한 효과적으로 활용하기 위해서는 <b>질문 방식과 프롬프트 설정</b>이 매우 중요합니다. 아래는 다양한 상황에서 활용할 수 있는 <b>프롬프트 예시</b>들을 제시합니다. 이를 통해 더 정확하고 유용한 정보를 빠르게 얻을 수 있습니다.</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>1. 일반 정보 탐색</b></span></h3>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"퍼플렉시티 사용법 1.jpg\" data-origin-width=\"1134\" data-origin-height=\"635\"><span data-url=\"https://blog.kakaocdn.net/dn/lRBQ5/btsKHaCZstF/hY2Z8A59kcmNLMgXul22O1/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/lRBQ5/btsKHaCZstF/hY2Z8A59kcmNLMgXul22O1/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/lRBQ5/btsKHaCZstF/hY2Z8A59kcmNLMgXul22O1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FlRBQ5%2FbtsKHaCZstF%2FhY2Z8A59kcmNLMgXul22O1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"700\" height=\"392\" data-filename=\"퍼플렉시티 사용법 1.jpg\" data-origin-width=\"1134\" data-origin-height=\"635\"/></span></figure>\n</p>\n<h4 data-ke-size=\"size20\">질문 예시:</h4>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>\"2024년 웹 디자인 트렌드에 대해 알려줘.\"</li>\n<li>\"최신 스마트폰 모델 비교 분석 부탁해.\"</li>\n<li>\"AI 기반 마케팅 전략의 성공 사례를 설명해줘.\"</li>\n</ul>\n<h4 data-ke-size=\"size20\">프롬프트 팁:</h4>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>구체적인 연도나 키워드</b>를 포함해 최신 정보를 요청합니다.</li>\n<li>검색할 분야를 명확히 지정하여 결과의 정확도를 높입니다.</li>\n</ul>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>2. 제품 리뷰 및 비교 분석</b></span></h3>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"퍼플렉시티 사용법 3.jpg\" data-origin-width=\"1121\" data-origin-height=\"592\"><span data-url=\"https://blog.kakaocdn.net/dn/bZzdOu/btsKFC17fgJ/GMeriPAoXk4llV8AykWLgK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bZzdOu/btsKFC17fgJ/GMeriPAoXk4llV8AykWLgK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/bZzdOu/btsKFC17fgJ/GMeriPAoXk4llV8AykWLgK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbZzdOu%2FbtsKFC17fgJ%2FGMeriPAoXk4llV8AykWLgK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"퍼플렉시티 사용법 3.jpg\" data-origin-width=\"1121\" data-origin-height=\"592\"/></span></figure>\n</p>\n<h4 data-ke-size=\"size20\">질문 예시:</h4>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>\"현재 최고의 게이밍 노트북 추천해줘.\"</li>\n<li>\"무선 이어폰 중 가성비 좋은 제품 목록을 알려줘.\"</li>\n<li>\"반려견용 하네스 중 가장 인기 있는 제품은 무엇이야?\"</li>\n</ul>\n<h4 data-ke-size=\"size20\">프롬프트 팁:</h4>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>특정 요구 조건</b>(예: 예산, 기능, 브랜드)을 추가하여 결과를 세분화합니다.</li>\n<li><b>\"가장 평점이 높은\"</b>, <b>\"가성비 좋은\"</b>과 같은 수식어를 활용해 더욱 맞춤형 정보를 얻습니다.</li>\n</ul>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>3. 학술 자료 분석 및 요약 (학문 모드 설정)</b></span></h3>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"퍼플렉시티 사용법 5.jpg\" data-origin-width=\"905\" data-origin-height=\"552\"><span data-url=\"https://blog.kakaocdn.net/dn/JU7vA/btsKGU1s2Vg/RTLV2CBfiVeFLrFaqTmbKk/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/JU7vA/btsKGU1s2Vg/RTLV2CBfiVeFLrFaqTmbKk/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/JU7vA/btsKGU1s2Vg/RTLV2CBfiVeFLrFaqTmbKk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FJU7vA%2FbtsKGU1s2Vg%2FRTLV2CBfiVeFLrFaqTmbKk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"퍼플렉시티 사용법 5.jpg\" data-origin-width=\"905\" data-origin-height=\"552\"/></span></figure>\n</p>\n<h4 data-ke-size=\"size20\">질문 예시:</h4>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>\"최신 비만 치료 방법에 대한 논문 요약해줘.\"</li>\n<li>\"전기 자동차 배터리 기술의 최신 연구 동향을 분석해줘.\"</li>\n<li>\"지속 가능한 에너지의 경제적 영향에 대한 학술 자료 추천해줘.\"</li>\n</ul>\n<h4 data-ke-size=\"size20\">프롬프트 팁:</h4>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>\"논문 요약\"</b>, <b>\"학술 자료\"</b> 등의 키워드를 추가해 전문 자료를 빠르게 찾아냅니다.</li>\n<li>특정 주제나 <b>\"연구 결과\"</b>, <b>\"메타 분석\"</b> 등과 같은 구체적인 용어를 사용해 더욱 깊이 있는 정보를 요청합니다.</li>\n</ul>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>4. SEO 키워드 분석 및 콘텐츠 최적화</b></span></h3>\n<h4 data-ke-size=\"size20\">질문 예시:</h4>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>\"IT 블로그를 위한 2024년 SEO 키워드 추천해줘.\"</li>\n<li>\"마케팅 관련 블로그 포스팅에 효과적인 키워드 분석 부탁해.\"</li>\n<li>\"한국어 콘텐츠의 SEO 전략을 제시해줘.\"</li>\n</ul>\n<h4 data-ke-size=\"size20\">프롬프트 팁:</h4>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>\"블로그 주제\"</b>, <b>\"타겟 시장\"</b> 등을 명확히 하여 관련성 높은 키워드를 제안받습니다.</li>\n<li><b>\"검색 순위 향상\"</b>, <b>\"구글 SEO 최적화\"</b>와 같은 수식어를 추가해 SEO에 특화된 조언을 받습니다.</li>\n</ul>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>5. 건강 및 웰니스 조언</b></span></h3>\n<h4 data-ke-size=\"size20\">질문 예시:</h4>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>\"근거 기반으로 다이어트 식단 계획 세워줘.\"</li>\n<li>\"중년 남성을 위한 근력 운동 프로그램 추천해.\"</li>\n<li>\"면역력을 높이는 자연적인 방법을 알려줘.\"</li>\n</ul>\n<h4 data-ke-size=\"size20\">프롬프트 팁:</h4>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>\"과학적 근거\"</b>, <b>\"증명된 연구\"</b> 등의 키워드를 사용하여 신뢰할 수 있는 정보를 얻습니다.</li>\n<li>특정 건강 상태나 목표(예: 체중 감량, 근력 향상)에 맞춘 프롬프트를 사용합니다.</li>\n</ul>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>6. Copilot 기능 활용 예시</b></span></h3>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"퍼플렉시티 사용법 6.jpg\" data-origin-width=\"964\" data-origin-height=\"445\"><span data-url=\"https://blog.kakaocdn.net/dn/PD3Vg/btsKGNagfBk/6yETkLKvE0j0NA9GZXLBNK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/PD3Vg/btsKGNagfBk/6yETkLKvE0j0NA9GZXLBNK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/PD3Vg/btsKGNagfBk/6yETkLKvE0j0NA9GZXLBNK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FPD3Vg%2FbtsKGNagfBk%2F6yETkLKvE0j0NA9GZXLBNK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"퍼플렉시티 사용법 6.jpg\" data-origin-width=\"964\" data-origin-height=\"445\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">Copilot 기능을 활용하면 <b>추가적인 질문을 통해 검색 결과를 세분화</b>할 수 있습니다.</p>\n<h4 data-ke-size=\"size20\">예시 프롬프트 시나리오:</h4>\n<p data-ke-size=\"size16\"><b>사용자 질문</b>: \"2024년 마케팅 트렌드에 대해 알려줘.\"</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>Copilot 추가 질문: \"B2B 마케팅과 B2C 마케팅 중 어느 분야에 관심이 있나요?\"</li>\n<li><b>답변 후</b>: \"B2B 마케팅 전략에 대해 더 자세히 알려줘.\"</li>\n</ul>\n<p data-ke-size=\"size16\"><b>사용자 질문</b>: \"가장 효과적인 운동 루틴을 추천해줘.\"</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>Copilot 추가 질문: \"체중 감량을 목표로 하나요, 아니면 근력 강화를 목표로 하나요?\"</li>\n<li><b>답변 후</b>: \"근력 강화 운동에 집중하고 싶어.\"</li>\n</ul>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>7. 비즈니스 전략 및 분석</b></span></h3>\n<h4 data-ke-size=\"size20\">질문 예시:</h4>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>\"2024년 스타트업을 위한 효과적인 마케팅 전략 제안해줘.\"</li>\n<li>\"소매업에서 성공적인 고객 유지 전략을 분석해줘.\"</li>\n<li>\"B2B 세일즈를 위한 최신 트렌드를 알려줘.\"</li>\n</ul>\n<h4 data-ke-size=\"size20\">프롬프트 팁:</h4>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>산업 분야</b>(예: IT, 헬스케어, 패션)와 <b>구체적인 전략</b>(예: 마케팅, 세일즈)을 명확히 지정하여 맞춤형 정보를 얻습니다.</li>\n<li><b>\"성공 사례\"</b>, <b>\"최신 트렌드\"</b> 등을 추가하여 깊이 있는 분석을 요청합니다.</li>\n</ul>\n<p data-ke-size=\"size16\">이러한 프롬프트 예시를 참고하여 <b>Perplexity AI</b>를 보다 효과적으로 활용해 보세요. 사용자의 질문 방식에 따라 <b>더 정밀하고 유용한 결과</b>를 얻을 수 있습니다.  </p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>마치며</b></span></h2>\n<p data-ke-size=\"size16\">&nbsp;Perplexity AI를 사용하기 전에는 AI 도구들이 단순한 자동화 도구에 불과하다고 생각했지만, 실제로 사용해 보니 업무 효율을 크게 높일 수 있다는 점을 깨달았습니다. 특히 실시간 정보 업데이트와 Copilot 기능은 정보를 보다 정확하고 빠르게 얻을 수 있도록 도와줍니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;AI 도구를 활용해 일상 업무에서 더 많은 가치를 창출하고 싶다면, Perplexity AI를 직접 사용해 보시길 권장합니다. 여러분도 이 도구를 사용하여 새로운 차원의 생산성을 경험해 보세요!</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #ee2323;\"><b>Q&amp;A</b></span></h2>\n<h3 data-ke-size=\"size23\">1. Perplexity AI는 무료로 사용할 수 있나요?</h3>\n<p data-ke-size=\"size16\">네, Perplexity AI는 무료로 기본 기능을 제공하며, 유료 Pro 버전을 통해 더 많은 고급 기능을 사용할 수 있습니다. Pro 버전에서는 다양한 AI 모델 선택과 무제한 문서 업로드 분석 기능을 추가로 이용할 수 있습니다.</p>\n<h3 data-ke-size=\"size23\">2. Copilot 기능은 어떻게 활용하나요?</h3>\n<p data-ke-size=\"size16\">Copilot 기능은 사용자의 질문에 대한 추가적인 질문을 통해 보다 정확한 답변을 제공합니다. 이를 통해 보다 맞춤형 검색 결과를 얻을 수 있으며, 특히 모호한 질문에 대해 유용합니다.</p>\n<h3 data-ke-size=\"size23\">3. Perplexity AI는 어떤 상황에서 가장 유용한가요?</h3>\n<p data-ke-size=\"size16\">Perplexity AI는 제품 조사, 학술 자료 분석, SEO 최적화, 소비자 리뷰 분석 등 다양한 상황에서 유용하게 활용할 수 있습니다. 특히 빠르고 정확한 정보 탐색이 필요한 경우에 큰 도움을 줍니다.</p>",
        "contentSnippet": "퍼플렉시티(Perplexity AI) 의 독보적인 기능과 활용 방법을 통해 정보 탐색, 연구 분석, 생산성 향상에 도움을 받을 수 있습니다. Copilot 기능과 실시간 업데이트로 업무 효율을 극대화하세요.\n\n\n \n 최근 몇 년간 인공지능(AI) 기술은 빠르게 발전하며 일상 생활과 업무 환경에 큰 변화를 가져왔습니다. 많은 사람들이 AI 도구에 대해 관심을 갖고 있지만, 여전히 AI 활용에 대한 부정적인 시각도 존재합니다. 저 역시 한때는 AI에 대해 회의적이었으나, Perplexity AI라는 새로운 도구를 사용하면서 생각이 완전히 바뀌었습니다.\n \n이 글에서는 Perplexity AI가 어떻게 생산성을 높이고 일상적인 작업에 도움을 주는지, 특히 정보 탐색과 분석에서 어떤 혁신적인 기능을 제공하는지 알아보겠습니다.\n \nPerplexity AI란 무엇인가?\nPerplexity AI는 \"정보 탐색과 호기심을 위한 스위스 군용 칼\"로 불리며, 사용자의 질문에 대해 방대한 데이터베이스를 통해 실시간으로 답변을 제공합니다. 그 과정에서 정확한 출처를 제시하며, 최신 정보를 반영해 사용자에게 신뢰도 높은 결과를 제공합니다.\n \nPerplexity AI의 주요 기능\n정보 검색 및 분석: 사용자가 질문을 입력하면 AI가 신속하게 관련 데이터를 분석하여 정확한 답변을 제시합니다. 단순한 질문 답변을 넘어 복잡한 데이터 분석까지 가능해, 특히 연구와 학습에 유용합니다.\n다양한 AI 모델 지원: 무료 버전과 유료 Pro 버전으로 나뉘어져 있으며, 유료 사용자는 Claude 3.5 Sonnet, GPT-4, Grok-2와 같은 다양한 모델을 선택할 수 있습니다. 이를 통해 특정 작업에 맞는 AI를 활용할 수 있습니다.\n문서 업로드 및 분석: Pro 버전에서는 사용자가 문서를 업로드하면 해당 문서의 주요 내용을 요약하고 분석하는 기능도 제공합니다. 이로 인해 대량의 텍스트 데이터를 효율적으로 관리할 수 있습니다.\n \nPerplexity AI의 차별화된 기능\n1. 실시간 정보 업데이트와 정확한 출처 제공\n많은 AI 도구들이 존재하지만 Perplexity AI는 특히 실시간 정보 업데이트 기능으로 차별화됩니다. 예를 들어, 특정 뉴스나 트렌드에 대해 질문하면 가장 최신의 정보가 반영된 답변을 제공합니다. 또한, 모든 답변에 출처를 명확히 제시하므로 사용자는 제시된 정보를 신뢰하고 참고할 수 있습니다.\n실시간 업데이트: 검색할 때마다 최신 정보가 반영되어 더 정확한 답변을 제공합니다.\n출처 확인 기능: 답변과 함께 관련된 출처를 명시하여 정보의 신뢰도를 높입니다. 특히 연구 논문 작성이나 학술 자료 수집에 유용합니다.\n2. Copilot 기능을 통한 맞춤형 검색 경험 제공\nPerplexity AI의 Copilot 기능은 사용자의 질문에 대해 추가적인 질문을 던져 보다 정교하고 맞춤형 답변을 도출합니다. 이 기능은 사용자가 모호한 질문을 했을 때 추가적인 정보를 요구하여, 사용자가 원래 찾고자 했던 정보를 정확하게 찾아줍니다.\n개인화된 검색 지원: Copilot이 사용자의 의도를 파악해 구체적인 정보를 제공합니다.\n대화형 인터페이스: 질문에 대한 추가 질문을 통해 사용자 맞춤형 검색 결과를 제공합니다.\n3. 다양한 활용 사례\nPerplexity AI는 단순한 검색 도구 이상의 가치를 제공합니다. 특히 다양한 분야에서 유용하게 활용될 수 있습니다.\n제품 조사: 쇼핑할 때 여러 사이트를 비교하는 대신, Perplexity AI를 사용해 추천 제품을 찾을 수 있습니다. 예를 들어, 반려견 하네스를 찾는 데 사용했을 때, 다양한 리뷰와 평점을 기반으로 최적의 선택을 도와줍니다.\n과학적 자료 조사: 운동 프로그램 설계 시, 근거 기반의 자료를 빠르게 수집하고 정리할 수 있습니다. 이를 통해 효과적인 운동 계획을 세우는 데 도움을 받았습니다.\nSEO 최적화: 블로그나 웹사이트 콘텐츠 작성 시, 키워드 연구를 통해 더 나은 SEO 성과를 거둘 수 있도록 지원합니다.\n \nPerplexity AI 기본 사용법\n퍼플렉시티 초기화면은 챗GPT와 비슷합니다. 퍼플렉시티의 기본 옵션은 '웹'검색이나, 모드 선택에서 다양한 옵션으로 사용자 응답 효율을 극대화 할 수 있습니다.\n\n\n \n \nPerplexity AI 활용 팁\n1. 키워드 연구 및 SEO 최적화\nPerplexity AI는 단순한 검색 도구를 넘어 SEO 최적화 도구로도 활용될 수 있습니다. 주제에 맞는 핵심 키워드를 찾아내어 콘텐츠의 가독성과 검색 순위를 높이는 데 도움을 줍니다.\n키워드 분석: 특정 주제와 관련된 트렌드 키워드를 찾아 SEO 전략에 반영할 수 있습니다.\nSEO 성과 향상: 블로그 포스팅이나 제품 페이지 최적화에 활용하여 검색 노출을 극대화할 수 있습니다.\n2. 학술 자료 정리 및 요약\nPerplexity AI는 학술 논문이나 연구 자료를 신속하게 분석하고 요약하는 데 탁월합니다. 복잡한 논문을 빠르게 읽고 이해할 수 있어 연구자나 학생들에게 유용한 도구입니다.\n논문 요약: 방대한 학술 자료를 요약하여 핵심 내용을 빠르게 파악할 수 있습니다.\n자료 검증: AI가 제시한 출처를 통해 자료의 신뢰성을 직접 확인할 수 있습니다.\n3. 소비자 제품 리뷰 분석\nPerplexity AI를 사용하면 다양한 리뷰와 평점을 분석하여 소비자 제품 선택에 도움을 받을 수 있습니다. 단순한 평점 비교를 넘어, 사용자 리뷰를 분석해 제품의 강점과 약점을 파악할 수 있습니다.\n구매 결정 지원: 제품의 장단점을 한눈에 파악하여 현명한 소비 결정을 내릴 수 있습니다.\n제품 리뷰 요약: 여러 리뷰를 요약해 시간 절약이 가능합니다.\n \nPerplexity AI 프롬프트 예시 모음\nPerplexity AI를 최대한 효과적으로 활용하기 위해서는 질문 방식과 프롬프트 설정이 매우 중요합니다. 아래는 다양한 상황에서 활용할 수 있는 프롬프트 예시들을 제시합니다. 이를 통해 더 정확하고 유용한 정보를 빠르게 얻을 수 있습니다.\n1. 일반 정보 탐색\n\n\n질문 예시:\n\"2024년 웹 디자인 트렌드에 대해 알려줘.\"\n\"최신 스마트폰 모델 비교 분석 부탁해.\"\n\"AI 기반 마케팅 전략의 성공 사례를 설명해줘.\"\n프롬프트 팁:\n구체적인 연도나 키워드를 포함해 최신 정보를 요청합니다.\n검색할 분야를 명확히 지정하여 결과의 정확도를 높입니다.\n2. 제품 리뷰 및 비교 분석\n\n\n질문 예시:\n\"현재 최고의 게이밍 노트북 추천해줘.\"\n\"무선 이어폰 중 가성비 좋은 제품 목록을 알려줘.\"\n\"반려견용 하네스 중 가장 인기 있는 제품은 무엇이야?\"\n프롬프트 팁:\n특정 요구 조건(예: 예산, 기능, 브랜드)을 추가하여 결과를 세분화합니다.\n\"가장 평점이 높은\", \"가성비 좋은\"과 같은 수식어를 활용해 더욱 맞춤형 정보를 얻습니다.\n3. 학술 자료 분석 및 요약 (학문 모드 설정)\n\n\n질문 예시:\n\"최신 비만 치료 방법에 대한 논문 요약해줘.\"\n\"전기 자동차 배터리 기술의 최신 연구 동향을 분석해줘.\"\n\"지속 가능한 에너지의 경제적 영향에 대한 학술 자료 추천해줘.\"\n프롬프트 팁:\n\"논문 요약\", \"학술 자료\" 등의 키워드를 추가해 전문 자료를 빠르게 찾아냅니다.\n특정 주제나 \"연구 결과\", \"메타 분석\" 등과 같은 구체적인 용어를 사용해 더욱 깊이 있는 정보를 요청합니다.\n4. SEO 키워드 분석 및 콘텐츠 최적화\n질문 예시:\n\"IT 블로그를 위한 2024년 SEO 키워드 추천해줘.\"\n\"마케팅 관련 블로그 포스팅에 효과적인 키워드 분석 부탁해.\"\n\"한국어 콘텐츠의 SEO 전략을 제시해줘.\"\n프롬프트 팁:\n\"블로그 주제\", \"타겟 시장\" 등을 명확히 하여 관련성 높은 키워드를 제안받습니다.\n\"검색 순위 향상\", \"구글 SEO 최적화\"와 같은 수식어를 추가해 SEO에 특화된 조언을 받습니다.\n5. 건강 및 웰니스 조언\n질문 예시:\n\"근거 기반으로 다이어트 식단 계획 세워줘.\"\n\"중년 남성을 위한 근력 운동 프로그램 추천해.\"\n\"면역력을 높이는 자연적인 방법을 알려줘.\"\n프롬프트 팁:\n\"과학적 근거\", \"증명된 연구\" 등의 키워드를 사용하여 신뢰할 수 있는 정보를 얻습니다.\n특정 건강 상태나 목표(예: 체중 감량, 근력 향상)에 맞춘 프롬프트를 사용합니다.\n6. Copilot 기능 활용 예시\n\n\nCopilot 기능을 활용하면 추가적인 질문을 통해 검색 결과를 세분화할 수 있습니다.\n예시 프롬프트 시나리오:\n사용자 질문: \"2024년 마케팅 트렌드에 대해 알려줘.\"\nCopilot 추가 질문: \"B2B 마케팅과 B2C 마케팅 중 어느 분야에 관심이 있나요?\"\n답변 후: \"B2B 마케팅 전략에 대해 더 자세히 알려줘.\"\n사용자 질문: \"가장 효과적인 운동 루틴을 추천해줘.\"\nCopilot 추가 질문: \"체중 감량을 목표로 하나요, 아니면 근력 강화를 목표로 하나요?\"\n답변 후: \"근력 강화 운동에 집중하고 싶어.\"\n7. 비즈니스 전략 및 분석\n질문 예시:\n\"2024년 스타트업을 위한 효과적인 마케팅 전략 제안해줘.\"\n\"소매업에서 성공적인 고객 유지 전략을 분석해줘.\"\n\"B2B 세일즈를 위한 최신 트렌드를 알려줘.\"\n프롬프트 팁:\n산업 분야(예: IT, 헬스케어, 패션)와 구체적인 전략(예: 마케팅, 세일즈)을 명확히 지정하여 맞춤형 정보를 얻습니다.\n\"성공 사례\", \"최신 트렌드\" 등을 추가하여 깊이 있는 분석을 요청합니다.\n이러한 프롬프트 예시를 참고하여 Perplexity AI를 보다 효과적으로 활용해 보세요. 사용자의 질문 방식에 따라 더 정밀하고 유용한 결과를 얻을 수 있습니다.  \n \n \n마치며\n Perplexity AI를 사용하기 전에는 AI 도구들이 단순한 자동화 도구에 불과하다고 생각했지만, 실제로 사용해 보니 업무 효율을 크게 높일 수 있다는 점을 깨달았습니다. 특히 실시간 정보 업데이트와 Copilot 기능은 정보를 보다 정확하고 빠르게 얻을 수 있도록 도와줍니다.\n \n AI 도구를 활용해 일상 업무에서 더 많은 가치를 창출하고 싶다면, Perplexity AI를 직접 사용해 보시길 권장합니다. 여러분도 이 도구를 사용하여 새로운 차원의 생산성을 경험해 보세요!\n \nQ&A\n1. Perplexity AI는 무료로 사용할 수 있나요?\n네, Perplexity AI는 무료로 기본 기능을 제공하며, 유료 Pro 버전을 통해 더 많은 고급 기능을 사용할 수 있습니다. Pro 버전에서는 다양한 AI 모델 선택과 무제한 문서 업로드 분석 기능을 추가로 이용할 수 있습니다.\n2. Copilot 기능은 어떻게 활용하나요?\nCopilot 기능은 사용자의 질문에 대한 추가적인 질문을 통해 보다 정확한 답변을 제공합니다. 이를 통해 보다 맞춤형 검색 결과를 얻을 수 있으며, 특히 모호한 질문에 대해 유용합니다.\n3. Perplexity AI는 어떤 상황에서 가장 유용한가요?\nPerplexity AI는 제품 조사, 학술 자료 분석, SEO 최적화, 소비자 리뷰 분석 등 다양한 상황에서 유용하게 활용할 수 있습니다. 특히 빠르고 정확한 정보 탐색이 필요한 경우에 큰 도움을 줍니다.",
        "guid": "http://muzbox.tistory.com/483497",
        "categories": [
          "AI, 미래기술",
          "AI 도구",
          "ai 활용 사례",
          "copilot 기능",
          "perplexity ai",
          "생산성 향상",
          "실시간 업데이트",
          "정보 탐색",
          "퍼플렉시티",
          "퍼플렉시티 사용법",
          "학술 자료 분석"
        ],
        "isoDate": "2024-11-13T01:52:30.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "엑셀의 눈금선 색상을 변경하는 방법",
        "link": "http://muzbox.tistory.com/483496",
        "pubDate": "Mon, 11 Nov 2024 18:47:31 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483496#entry483496comment",
        "content": "<p data-ke-size=\"size16\">&nbsp;Microsoft Excel에서 기본 그리드라인 색상을 변경하는 방법을 소개합니다. 기존의 회색에서 사용자가 원하는 색상으로 설정해, 시각적 효과를 향상시킬 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"엑셀 눈금선 색상 변경 방법.png\" data-origin-width=\"500\" data-origin-height=\"500\"><span data-url=\"https://blog.kakaocdn.net/dn/rEWXm/btsKE1NhK14/ZW5mvf3AUU38kDmgAo5kAk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/rEWXm/btsKE1NhK14/ZW5mvf3AUU38kDmgAo5kAk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/rEWXm/btsKE1NhK14/ZW5mvf3AUU38kDmgAo5kAk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FrEWXm%2FbtsKE1NhK14%2FZW5mvf3AUU38kDmgAo5kAk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"엑셀의 눈금선 색상을 변경하는 방법\" data-filename=\"엑셀 눈금선 색상 변경 방법.png\" data-origin-width=\"500\" data-origin-height=\"500\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;Microsoft Excel을 사용할 때 기본적으로 제공되는 회색 그리드라인을 별로 신경 쓰지 않았던 적이 있으신가요? 저 역시 25년 넘게 Excel을 사용하면서 그리드라인 색상에 대한 생각은 해본 적이 없었어요. 하지만 최근, Excel에서 기본 그리드라인 색상을 자유롭게 변경할 수 있는 설정을 발견했습니다. 이 기능을 활용하면 문서의 가독성을 높이고, 시각적으로 더 매력적인 스프레드시트를 만들 수 있습니다. 오늘은 Excel에서 그리드라인 색상을 변경하는 방법을 소개해 드릴게요.  </p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>Microsoft Excel 그리드라인 색상 변경 방법</b></span></h2>\n<h3 data-ke-size=\"size23\"><b><span style=\"color: #ee2323;\">Excel 옵션 메뉴에서 색상 변경</span></b></h3>\n<p data-ke-size=\"size16\"><b>1. Excel을 열고</b> 상단 메뉴에서 <b>파일(File)</b>을 클릭한 후, <b>옵션(Options)</b>으로 이동합니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"01.png\" data-origin-width=\"1203\" data-origin-height=\"687\"><span data-url=\"https://blog.kakaocdn.net/dn/ZnPDh/btsKFn98J9E/SZ3WS9tkYXPsPCcukzjkk1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/ZnPDh/btsKFn98J9E/SZ3WS9tkYXPsPCcukzjkk1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/ZnPDh/btsKFn98J9E/SZ3WS9tkYXPsPCcukzjkk1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FZnPDh%2FbtsKFn98J9E%2FSZ3WS9tkYXPsPCcukzjkk1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"01.png\" data-origin-width=\"1203\" data-origin-height=\"687\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><b>2.고급(Advanced)</b> 탭을 클릭하고, 스크롤을 내려 <b>현재 시트의 표시 옵션(Display options for this worksheet)</b> 항목을 찾습니다. <b>그리드라인 색상(Gridline color)</b> 선택기에서 원하는 색상을 선택합니다. <b>확인(OK)</b> 버튼을 눌러 설정을 저장합니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"02.png\" data-origin-width=\"936\" data-origin-height=\"678\"><span data-url=\"https://blog.kakaocdn.net/dn/ofMKS/btsKDUVK4no/xeCD1frU2xjZYCrjKkTDzk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/ofMKS/btsKDUVK4no/xeCD1frU2xjZYCrjKkTDzk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/ofMKS/btsKDUVK4no/xeCD1frU2xjZYCrjKkTDzk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FofMKS%2FbtsKDUVK4no%2FxeCD1frU2xjZYCrjKkTDzk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"02.png\" data-origin-width=\"936\" data-origin-height=\"678\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">3. 이제 문서에서 회색 그리드라인이 아닌, 사용자가 설정한 색상이 적용된 것을 볼 수 있습니다. 예를 들어, 빨간색으로 변경하면 다음과 같이 시트가 표시됩니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"03.png\" data-origin-width=\"1203\" data-origin-height=\"687\"><span data-url=\"https://blog.kakaocdn.net/dn/bI9sxR/btsKEeNhgan/Odn4ZfmLXl8lBa0zRKIxJk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bI9sxR/btsKEeNhgan/Odn4ZfmLXl8lBa0zRKIxJk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bI9sxR/btsKEeNhgan/Odn4ZfmLXl8lBa0zRKIxJk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbI9sxR%2FbtsKEeNhgan%2FOdn4ZfmLXl8lBa0zRKIxJk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"03.png\" data-origin-width=\"1203\" data-origin-height=\"687\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>색상 변경 시 유의 사항</b></span></h3>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>이 설정은 <b>현재 작업 중인 시트에만 적용</b>되며, 다른 Excel 파일이나 새로 생성하는 파일에는 적용되지 않습니다.</li>\n<li>다시 기본 색상으로 되돌리고 싶다면, 동일한 경로에서 <b>'자동(Automatic)'</b>으로 변경하면 됩니다.</li>\n<li>이 설정은 모든 최신 Excel 버전에서 사용할 수 있습니다.</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>색상 변경의 활용 방법</b></span></h2>\n<p data-ke-size=\"size16\">Excel에서 그리드라인 색상을 변경하면, 시트의 가독성을 높이고, 중요한 데이터를 강조할 수 있습니다. 특히, 여러 시트 간에 시각적인 구분을 두고 싶을 때 유용하게 활용할 수 있습니다. 예를 들어, 재무 보고서에서 특정 시트의 데이터가 강조되어야 할 때 색상을 다르게 설정해 보세요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>마치며</b></span></h2>\n<p data-ke-size=\"size16\">Excel의 기본 설정을 활용하여 시각적인 변화를 줄 수 있다는 점이 참 흥미롭습니다. 이처럼 작은 변화가 문서의 가독성을 크게 높일 수 있어요. 여러분도 지금 바로 Excel을 열어, 그리드라인 색상을 변경해 보세요!  </p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #ee2323;\"><b>Q&amp;A</b></span></h2>\n<p data-ke-size=\"size18\"><b>Q1: Excel 그리드라인 색상을 변경해도 새 파일에는 적용되지 않나요?</b></p>\n<p data-ke-size=\"size18\">네, 현재 변경한 색상은 <b>현재 작업 중인 시트에만 적용</b>되며, 새 파일에는 기본 설정이 적용됩니다.</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\"><b>Q2: 모든 버전의 Excel에서 그리드라인 색상을 변경할 수 있나요?</b></p>\n<p data-ke-size=\"size18\">네, 이 기능은 <b>모든 최신 Excel 버전에서 지원</b>됩니다.</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\"><b>Q3: 그리드라인 색상 변경이 작업 속도에 영향을 줄 수 있나요?</b></p>\n<p data-ke-size=\"size18\">그리드라인 색상 변경은 <b>시각적 효과만 조정</b>할 뿐, Excel의 성능이나 작업 속도에는 영향을 주지 않습니다.</p>",
        "contentSnippet": "Microsoft Excel에서 기본 그리드라인 색상을 변경하는 방법을 소개합니다. 기존의 회색에서 사용자가 원하는 색상으로 설정해, 시각적 효과를 향상시킬 수 있습니다.\n \n\n\n \n Microsoft Excel을 사용할 때 기본적으로 제공되는 회색 그리드라인을 별로 신경 쓰지 않았던 적이 있으신가요? 저 역시 25년 넘게 Excel을 사용하면서 그리드라인 색상에 대한 생각은 해본 적이 없었어요. 하지만 최근, Excel에서 기본 그리드라인 색상을 자유롭게 변경할 수 있는 설정을 발견했습니다. 이 기능을 활용하면 문서의 가독성을 높이고, 시각적으로 더 매력적인 스프레드시트를 만들 수 있습니다. 오늘은 Excel에서 그리드라인 색상을 변경하는 방법을 소개해 드릴게요.  \n \n \nMicrosoft Excel 그리드라인 색상 변경 방법\nExcel 옵션 메뉴에서 색상 변경\n1. Excel을 열고 상단 메뉴에서 파일(File)을 클릭한 후, 옵션(Options)으로 이동합니다.\n\n\n \n \n2.고급(Advanced) 탭을 클릭하고, 스크롤을 내려 현재 시트의 표시 옵션(Display options for this worksheet) 항목을 찾습니다. 그리드라인 색상(Gridline color) 선택기에서 원하는 색상을 선택합니다. 확인(OK) 버튼을 눌러 설정을 저장합니다.\n\n\n \n3. 이제 문서에서 회색 그리드라인이 아닌, 사용자가 설정한 색상이 적용된 것을 볼 수 있습니다. 예를 들어, 빨간색으로 변경하면 다음과 같이 시트가 표시됩니다.\n\n\n \n \n색상 변경 시 유의 사항\n이 설정은 현재 작업 중인 시트에만 적용되며, 다른 Excel 파일이나 새로 생성하는 파일에는 적용되지 않습니다.\n다시 기본 색상으로 되돌리고 싶다면, 동일한 경로에서 '자동(Automatic)'으로 변경하면 됩니다.\n이 설정은 모든 최신 Excel 버전에서 사용할 수 있습니다.\n \n색상 변경의 활용 방법\nExcel에서 그리드라인 색상을 변경하면, 시트의 가독성을 높이고, 중요한 데이터를 강조할 수 있습니다. 특히, 여러 시트 간에 시각적인 구분을 두고 싶을 때 유용하게 활용할 수 있습니다. 예를 들어, 재무 보고서에서 특정 시트의 데이터가 강조되어야 할 때 색상을 다르게 설정해 보세요.\n \n마치며\nExcel의 기본 설정을 활용하여 시각적인 변화를 줄 수 있다는 점이 참 흥미롭습니다. 이처럼 작은 변화가 문서의 가독성을 크게 높일 수 있어요. 여러분도 지금 바로 Excel을 열어, 그리드라인 색상을 변경해 보세요!  \n \n \nQ&A\nQ1: Excel 그리드라인 색상을 변경해도 새 파일에는 적용되지 않나요?\n네, 현재 변경한 색상은 현재 작업 중인 시트에만 적용되며, 새 파일에는 기본 설정이 적용됩니다.\n \nQ2: 모든 버전의 Excel에서 그리드라인 색상을 변경할 수 있나요?\n네, 이 기능은 모든 최신 Excel 버전에서 지원됩니다.\n \nQ3: 그리드라인 색상 변경이 작업 속도에 영향을 줄 수 있나요?\n그리드라인 색상 변경은 시각적 효과만 조정할 뿐, Excel의 성능이나 작업 속도에는 영향을 주지 않습니다.",
        "guid": "http://muzbox.tistory.com/483496",
        "categories": [
          "오피스 프로그램 사용법/엑셀",
          "excel 설정",
          "excel 활용법",
          "엑셀",
          "엑셀 고급 설정",
          "엑셀 눈금선 색상변경",
          "엑셀 눈금선 칼라변경",
          "엑셀 팁"
        ],
        "isoDate": "2024-11-11T09:47:31.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "윈도우11 라이센스 OEM, Retail, Volume 차이와 확인 방법",
        "link": "http://muzbox.tistory.com/483495",
        "pubDate": "Fri, 8 Nov 2024 17:07:33 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483495#entry483495comment",
        "content": "<p data-ke-size=\"size16\">&nbsp;윈도우11 라이센스 종류 확인하는 방법을 알아보세요. OEM, Retail, Volume 라이센스의 차이와 확인 방법을 상세히 안내해 드립니다. 올바른 라이센스 확인으로 정품 인증 문제를 예방하세요!</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"윈도우11 라인센스 확인방법.jpg\" data-origin-width=\"500\" data-origin-height=\"500\"><span data-url=\"https://blog.kakaocdn.net/dn/DQXHg/btsKBTWxCTW/KEE5kQ3xORAbKvECgGXgLk/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/DQXHg/btsKBTWxCTW/KEE5kQ3xORAbKvECgGXgLk/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/DQXHg/btsKBTWxCTW/KEE5kQ3xORAbKvECgGXgLk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FDQXHg%2FbtsKBTWxCTW%2FKEE5kQ3xORAbKvECgGXgLk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"윈도우11 라이센스 OEM, Retail, Volume 차이와 확인 방법\" data-filename=\"윈도우11 라인센스 확인방법.jpg\" data-origin-width=\"500\" data-origin-height=\"500\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;여러분은 윈도우11을 사용하면서 자신의 <b>윈도우 라이센스 종류</b>가 무엇인지 궁금해 본 적 있으신가요?   새로운 PC를 구입했거나 중고로 PC를 구매할 경우, 설치된 윈도우가 <b>정품인지 확인</b>하는 것은 매우 중요합니다. 특히, 라이센스 종류에 따라 PC 변경 시 재설치 가능 여부나 사용 제한이 달라질 수 있기 때문에, 자신이 보유한 라이센스 유형을 정확히 파악하는 것이 필요합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;윈도우11 라이센스는 OEM, Retail, Volume 라이센스로 크게 나뉘며, 각 유형마다 특징이 다릅니다. 이 글에서는 <b>윈도우11 라이센스 종류를 쉽게 확인하는 방법</b>을 단계별로 안내하고, 각 라이센스의 차이점을 설명해 드리겠습니다. 이 정보를 통해 여러분의 PC 라이센스를 더욱 효율적으로 관리하고 활용할 수 있기를 바랍니다.  </p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>윈도우11 라이센스 종류 이해하기</b></span></h2>\n<p data-ke-size=\"size16\">윈도우11의 라이센스는 사용 목적과 배포 방식에 따라 크게 <b>OEM</b>, <b>Retail</b>, <b>Volume</b>의 세 가지로 구분됩니다. 각 라이센스 유형은 설치, 재설치, PC 변경 시의 사용 제한 조건이 다릅니다. 아래에서 각각의 라이센스 유형을 자세히 설명드리겠습니다.</p>\n<h3 data-ke-size=\"size23\"><b><span style=\"color: #ee2323;\">  1. OEM 라이센스</span></b></h3>\n<p data-ke-size=\"size16\">OEM(Original Equipment Manufacturer) 라이센스는 주로 <b>PC 제조사</b>에서 사전에 설치된 상태로 제공되는 윈도우 버전입니다. 여러분이 새로 구입한 노트북이나 데스크탑 컴퓨터에는 대부분 이 OEM 라이센스가 포함되어 있을 것입니다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>특징 및 사용 제한</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>특정 PC 하드웨어에 종속되며, <b>해당 PC에서만 사용 가능</b>합니다.</li>\n<li>만약 메인보드와 같은 주요 하드웨어를 교체하면 라이센스가 무효화될 수 있습니다.</li>\n<li>재설치는 가능하지만, 동일한 PC 내에서만 가능합니다.</li>\n</ul>\n</li>\n<li><b>장점</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>초기 설정이 완료된 상태로 제공되므로, 별도의 설치 과정 없이 바로 사용할 수 있어 <b>편리합니다</b>.</li>\n<li>상대적으로 저렴한 가격으로 제공됩니다.</li>\n</ul>\n</li>\n<li><b>단점</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>다른 PC로 <b>라이센스를 이전할 수 없으므로</b> 중고 PC를 구매할 때 주의해야 합니다.</li>\n<li>PC를 교체하거나 하드웨어를 업그레이드할 경우 <b>추가 라이센스 구매</b>가 필요할 수 있습니다.</li>\n</ul>\n</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>  2. Retail(리테일) 라이센스</b></span></h3>\n<p data-ke-size=\"size16\">리테일 라이센스는 일반 사용자들이 <b>마이크로소프트 스토어</b>나 공식 판매처에서 직접 구매할 수 있는 버전입니다. <b>가정용 사용자</b>나 <b>프리랜서</b>에게 가장 적합한 라이센스로, 기존 PC에서 새로운 PC로 <b>자유롭게 이전이 가능합니다</b>.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>특징 및 사용 제한</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>여러 번 재설치 가능하며, <b>다른 PC로 라이센스를 이전</b>할 수 있습니다.</li>\n<li>정품 인증을 받은 후에도 다른 PC로 이동할 수 있지만, <b>동시에 두 대의 PC에서 사용할 수는 없습니다</b>.</li>\n</ul>\n</li>\n<li><b>장점</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>PC 변경 시 <b>자유롭게 라이센스 이전</b>이 가능하므로, 새로운 PC를 구매하더라도 추가 비용이 들지 않습니다.</li>\n<li>고객 지원 및 업데이트가 보장되므로, <b>문제 발생 시 마이크로소프트의 지원</b>을 받을 수 있습니다.</li>\n</ul>\n</li>\n<li><b>단점</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>OEM 라이센스에 비해 <b>가격이 높습니다</b>.</li>\n<li>온라인 구매 시 가짜 라이센스에 주의해야 합니다.</li>\n</ul>\n</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>  3. Volume(볼륨) 라이센스</b></span></h3>\n<p data-ke-size=\"size16\">볼륨 라이센스는 주로 <b>기업이나 교육 기관</b>에서 대량으로 구매하는 라이센스 방식입니다. 대규모로 운영되는 조직에서 여러 대의 PC에 윈도우를 설치할 수 있도록 지원합니다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>특징 및 사용 제한</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>여러 대의 PC에 동일한 라이센스 키를 사용하여 <b>대량 배포</b>할 수 있습니다.</li>\n<li>특정 기간 동안 유효한 <b>정품 인증 서버(KMS)</b>를 사용하여 인증합니다.</li>\n</ul>\n</li>\n<li><b>장점</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>대량 구매 시 비용을 절감</b>할 수 있어, IT 예산이 제한된 기업에 유리합니다.</li>\n<li>중앙 집중식 관리가 가능해, <b>조직 내 PC의 일괄 관리 및 유지보수</b>가 편리합니다.</li>\n</ul>\n</li>\n<li><b>단점</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>개인 사용자에게는 구매 및 사용이 <b>제한됩니다</b>.</li>\n<li>기간 만료 시 정품 인증이 해제되므로, <b>정기적인 갱신이 필요</b>합니다.</li>\n</ul>\n</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>윈도우11 라이센스 종류 확인 방법</b></span></h2>\n<p data-ke-size=\"size16\">이제 자신의 윈도우11 라이센스 종류를 확인하는 방법을 소개하겠습니다. 특히, 중고 PC를 구매했거나 라이센스를 이전할 계획이 있을 때 유용하게 사용할 수 있는 팁입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">윈도우11에서 라이센스 종류를 확인하는 가장 쉬운 방법 중 하나는 <b>명령 프롬프트(CMD)</b>를 사용하는 것입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><b>Step 1</b>: <code>윈도우 검색창</code>에 <code>cmd</code>를 입력한 후, '명령 프롬프트'를 <b>관리자 권한으로 실행</b>합니다. ▼</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"01.png\" data-origin-width=\"800\" data-origin-height=\"457\"><span data-url=\"https://blog.kakaocdn.net/dn/beUhuL/btsKCwGD3yg/J4wLLH8OOxwNkcmkTqAXJ1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/beUhuL/btsKCwGD3yg/J4wLLH8OOxwNkcmkTqAXJ1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/beUhuL/btsKCwGD3yg/J4wLLH8OOxwNkcmkTqAXJ1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbeUhuL%2FbtsKCwGD3yg%2FJ4wLLH8OOxwNkcmkTqAXJ1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"01.png\" data-origin-width=\"800\" data-origin-height=\"457\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\"><br /><b>Step 2</b><span style=\"letter-spacing: 0px;\">: 아래의 명령어를 입력한 후 Enter를 누릅니다. ▼</span></p>\n<pre class=\"jboss-cli\" style=\"letter-spacing: 0px;\"><code>slmgr /dli</code></pre>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>결과</b>: 몇 초 후 팝업 창이 열리며, <b>설치된 라이센스의 종류</b>(OEM, Retail, Volume)가 표시됩니다.</li>\n</ul>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"02.png\" data-origin-width=\"800\" data-origin-height=\"438\"><span data-url=\"https://blog.kakaocdn.net/dn/vksGi/btsKC3qnPfU/WxFYCJysaVCmCi7uKa9vE0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/vksGi/btsKC3qnPfU/WxFYCJysaVCmCi7uKa9vE0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/vksGi/btsKC3qnPfU/WxFYCJysaVCmCi7uKa9vE0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FvksGi%2FbtsKC3qnPfU%2FWxFYCJysaVCmCi7uKa9vE0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"02.png\" data-origin-width=\"800\" data-origin-height=\"438\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>마치며</b></span></h2>\n<p data-ke-size=\"size16\">윈도우11 라이센스 종류를 정확히 파악하는 것은 PC 사용 시 매우 중요합니다. 특히, 새로 구매한 PC의 라이센스가 정품인지 확인하거나 기존 PC를 업그레이드할 때 유용하게 활용할 수 있습니다. 이번 기회에 여러분의 윈도우 라이센스 상태를 확인하여 불필요한 비용 낭비를 줄여보세요!  </p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #ee2323;\"><b>Q&amp;A</b></span></h2>\n<h3 data-ke-size=\"size23\">Q1. OEM 라이센스를 Retail 라이센스로 변경할 수 있나요?</h3>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>직접 변경할 수는 없지만, <b>Retail 라이센스를 추가 구매</b>하여 새롭게 설치할 수는 있습니다.</li>\n</ul>\n<h3 data-ke-size=\"size23\">Q2. 윈도우11 라이센스를 다른 PC로 이전할 수 있나요?</h3>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>Retail 라이센스는 가능하지만, <b>OEM 라이센스는 특정 PC에 종속되므로 이전이 불가능</b>합니다.</li>\n</ul>\n<h3 data-ke-size=\"size23\">Q3. 중고 PC 구매 시 정품 인증 상태를 확인하려면 어떻게 해야 하나요?</h3>\n<p data-ke-size=\"size16\">명령 프롬프트에서 <code>slmgr /dli</code> 명령어를 사용하여 <b>정품 여부와 라이센스 종류를 확인</b>하세요.</p>",
        "contentSnippet": "윈도우11 라이센스 종류 확인하는 방법을 알아보세요. OEM, Retail, Volume 라이센스의 차이와 확인 방법을 상세히 안내해 드립니다. 올바른 라이센스 확인으로 정품 인증 문제를 예방하세요!\n\n\n \n 여러분은 윈도우11을 사용하면서 자신의 윈도우 라이센스 종류가 무엇인지 궁금해 본 적 있으신가요?   새로운 PC를 구입했거나 중고로 PC를 구매할 경우, 설치된 윈도우가 정품인지 확인하는 것은 매우 중요합니다. 특히, 라이센스 종류에 따라 PC 변경 시 재설치 가능 여부나 사용 제한이 달라질 수 있기 때문에, 자신이 보유한 라이센스 유형을 정확히 파악하는 것이 필요합니다.\n \n 윈도우11 라이센스는 OEM, Retail, Volume 라이센스로 크게 나뉘며, 각 유형마다 특징이 다릅니다. 이 글에서는 윈도우11 라이센스 종류를 쉽게 확인하는 방법을 단계별로 안내하고, 각 라이센스의 차이점을 설명해 드리겠습니다. 이 정보를 통해 여러분의 PC 라이센스를 더욱 효율적으로 관리하고 활용할 수 있기를 바랍니다.  \n \n윈도우11 라이센스 종류 이해하기\n윈도우11의 라이센스는 사용 목적과 배포 방식에 따라 크게 OEM, Retail, Volume의 세 가지로 구분됩니다. 각 라이센스 유형은 설치, 재설치, PC 변경 시의 사용 제한 조건이 다릅니다. 아래에서 각각의 라이센스 유형을 자세히 설명드리겠습니다.\n  1. OEM 라이센스\nOEM(Original Equipment Manufacturer) 라이센스는 주로 PC 제조사에서 사전에 설치된 상태로 제공되는 윈도우 버전입니다. 여러분이 새로 구입한 노트북이나 데스크탑 컴퓨터에는 대부분 이 OEM 라이센스가 포함되어 있을 것입니다.\n특징 및 사용 제한\n\n특정 PC 하드웨어에 종속되며, 해당 PC에서만 사용 가능합니다.\n만약 메인보드와 같은 주요 하드웨어를 교체하면 라이센스가 무효화될 수 있습니다.\n재설치는 가능하지만, 동일한 PC 내에서만 가능합니다.\n장점\n\n초기 설정이 완료된 상태로 제공되므로, 별도의 설치 과정 없이 바로 사용할 수 있어 편리합니다.\n상대적으로 저렴한 가격으로 제공됩니다.\n단점\n\n다른 PC로 라이센스를 이전할 수 없으므로 중고 PC를 구매할 때 주의해야 합니다.\nPC를 교체하거나 하드웨어를 업그레이드할 경우 추가 라이센스 구매가 필요할 수 있습니다.\n \n  2. Retail(리테일) 라이센스\n리테일 라이센스는 일반 사용자들이 마이크로소프트 스토어나 공식 판매처에서 직접 구매할 수 있는 버전입니다. 가정용 사용자나 프리랜서에게 가장 적합한 라이센스로, 기존 PC에서 새로운 PC로 자유롭게 이전이 가능합니다.\n특징 및 사용 제한\n\n여러 번 재설치 가능하며, 다른 PC로 라이센스를 이전할 수 있습니다.\n정품 인증을 받은 후에도 다른 PC로 이동할 수 있지만, 동시에 두 대의 PC에서 사용할 수는 없습니다.\n장점\n\nPC 변경 시 자유롭게 라이센스 이전이 가능하므로, 새로운 PC를 구매하더라도 추가 비용이 들지 않습니다.\n고객 지원 및 업데이트가 보장되므로, 문제 발생 시 마이크로소프트의 지원을 받을 수 있습니다.\n단점\n\nOEM 라이센스에 비해 가격이 높습니다.\n온라인 구매 시 가짜 라이센스에 주의해야 합니다.\n \n  3. Volume(볼륨) 라이센스\n볼륨 라이센스는 주로 기업이나 교육 기관에서 대량으로 구매하는 라이센스 방식입니다. 대규모로 운영되는 조직에서 여러 대의 PC에 윈도우를 설치할 수 있도록 지원합니다.\n특징 및 사용 제한\n\n여러 대의 PC에 동일한 라이센스 키를 사용하여 대량 배포할 수 있습니다.\n특정 기간 동안 유효한 정품 인증 서버(KMS)를 사용하여 인증합니다.\n장점\n\n대량 구매 시 비용을 절감할 수 있어, IT 예산이 제한된 기업에 유리합니다.\n중앙 집중식 관리가 가능해, 조직 내 PC의 일괄 관리 및 유지보수가 편리합니다.\n단점\n\n개인 사용자에게는 구매 및 사용이 제한됩니다.\n기간 만료 시 정품 인증이 해제되므로, 정기적인 갱신이 필요합니다.\n \n윈도우11 라이센스 종류 확인 방법\n이제 자신의 윈도우11 라이센스 종류를 확인하는 방법을 소개하겠습니다. 특히, 중고 PC를 구매했거나 라이센스를 이전할 계획이 있을 때 유용하게 사용할 수 있는 팁입니다.\n \n윈도우11에서 라이센스 종류를 확인하는 가장 쉬운 방법 중 하나는 명령 프롬프트(CMD)를 사용하는 것입니다.\n \nStep 1: 윈도우 검색창에 cmd를 입력한 후, '명령 프롬프트'를 관리자 권한으로 실행합니다. ▼\n\n\n\nStep 2: 아래의 명령어를 입력한 후 Enter를 누릅니다. ▼\nslmgr /dli\n결과: 몇 초 후 팝업 창이 열리며, 설치된 라이센스의 종류(OEM, Retail, Volume)가 표시됩니다.\n\n\n \n마치며\n윈도우11 라이센스 종류를 정확히 파악하는 것은 PC 사용 시 매우 중요합니다. 특히, 새로 구매한 PC의 라이센스가 정품인지 확인하거나 기존 PC를 업그레이드할 때 유용하게 활용할 수 있습니다. 이번 기회에 여러분의 윈도우 라이센스 상태를 확인하여 불필요한 비용 낭비를 줄여보세요!  \n \n \nQ&A\nQ1. OEM 라이센스를 Retail 라이센스로 변경할 수 있나요?\n직접 변경할 수는 없지만, Retail 라이센스를 추가 구매하여 새롭게 설치할 수는 있습니다.\nQ2. 윈도우11 라이센스를 다른 PC로 이전할 수 있나요?\nRetail 라이센스는 가능하지만, OEM 라이센스는 특정 PC에 종속되므로 이전이 불가능합니다.\nQ3. 중고 PC 구매 시 정품 인증 상태를 확인하려면 어떻게 해야 하나요?\n명령 프롬프트에서 slmgr /dli 명령어를 사용하여 정품 여부와 라이센스 종류를 확인하세요.",
        "guid": "http://muzbox.tistory.com/483495",
        "categories": [
          "윈도우 사용팁/윈도우11 사용법",
          "OEM",
          "pc 라이센스 이전",
          "powershell 활용",
          "retail",
          "라이센스 확인",
          "명령어 사용법",
          "볼륨 라이센스",
          "윈도우 설정",
          "윈도우11",
          "정품 인증"
        ],
        "isoDate": "2024-11-08T08:07:33.000Z"
      }
    ]
  },
  {
    "name": "동우리의 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "하테나",
    "category": "개인",
    "posts": []
  },
  {
    "name": "늑돌이네 라지온",
    "category": "개인",
    "posts": []
  },
  {
    "name": "루리웹 - 루리웹 리뷰 게시판",
    "category": "게임",
    "posts": [
      {
        "creator": "(RULIWEB`Д')/",
        "title": "[MULTI] 못내 아쉬운 그러나 대체불가능한, 삼국지 8 리메이크",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2266",
        "pubDate": "Fri, 08 Nov 2024 19:49:24 +0900",
        "author": "(RULIWEB`Д')/",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i2.ruliweb.com/thumb/24/11/08/1930b62f0c14c329e.jpg\">",
        "contentSnippet": "",
        "categories": [
          "리뷰"
        ],
        "isoDate": "2024-11-08T10:49:24.000Z"
      }
    ]
  },
  {
    "name": "Reasontobe",
    "category": "개인",
    "posts": []
  },
  {
    "name": "자유로운 생활",
    "category": "개인",
    "posts": []
  },
  {
    "name": "에스티마의 인터넷이야기 EstimaStory.com",
    "category": "개인",
    "posts": []
  },
  {
    "name": "나긋한 개발 - 데비안 리눅스와 프로그램 언어",
    "category": "개인",
    "posts": []
  },
  {
    "name": "일상을 여행처럼...",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Just hack'em",
    "category": "개인",
    "posts": []
  },
  {
    "name": "C++ Truths",
    "category": "개인",
    "posts": []
  },
  {
    "name": "jacking75",
    "category": "개인",
    "posts": [
      {
        "title": "GitHub Copilot의 기능을 보다 편리하게 활용하는 방법. 조작 방법이나 프로그래밍 등의 활용 예",
        "link": "https://jacking75.github.io/tech-ai_20241114/",
        "pubDate": "Thu, 14 Nov 2024 00:00:00 +0900",
        "content": "<iframe width=\"1024\" height=\"1024\" src=\"https://docs.google.com/document/d/e/2PACX-1vTjzldVtjcXWo5Yfnos16w51P5zTYKD8Xr4E6l6ii4MH2QCmcDcoS0sH2Bl3PFzb0EclNLEdrasuKBh/pub?embedded=true\"></iframe>\n\n",
        "contentSnippet": "",
        "guid": "https://jacking75.github.io/tech-ai_20241114/",
        "isoDate": "2024-11-13T15:00:00.000Z"
      }
    ]
  },
  {
    "name": "Joel on Software",
    "category": "개인",
    "posts": []
  },
  {
    "name": "벤자민로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "악보쓰는 프로그래머",
    "category": "개인",
    "posts": []
  },
  {
    "name": "쭌안아빠",
    "category": "개인",
    "posts": []
  },
  {
    "name": "A Gangster World",
    "category": "개인",
    "posts": []
  },
  {
    "name": "요우의 내맘대로 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자스럽다",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Against All Odds.",
    "category": "개인",
    "posts": []
  },
  {
    "name": "움직이는 게임서버",
    "category": "개인",
    "posts": []
  },
  {
    "name": "이상욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "임철재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "어쩐지 오늘은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "oddpoet’s étude",
    "category": "개인",
    "posts": []
  },
  {
    "name": "0x00 - NULL",
    "category": "개인",
    "posts": []
  },
  {
    "name": "퇴근 후 서버다운",
    "category": "개인",
    "posts": [
      {
        "creator": "SIDNFT",
        "title": "중국이 살아남는 엄청 난 전략 / 200년짜리 전략",
        "link": "http://serverdown.tistory.com/966",
        "pubDate": "Fri, 15 Nov 2024 00:51:05 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/966#entry966comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=31GohM5BikI\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=31GohM5BikI</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=31GohM5BikI\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/djXPp9/hyXzQ5u2NB/8K0KPiWlxfgIxsvKStZOTk/img.jpg?width=1280&amp;height=720&amp;face=86_332_1176_442,https://scrap.kakaocdn.net/dn/du3gKC/hyXzJZAVS6/FclhfhaNsouBsptbpGRQa1/img.jpg?width=1280&amp;height=720&amp;face=86_332_1176_442\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"만리장성의 시작과 끝은 어딜까? 만리장성의 비밀 (강인욱X곽재식)ㅣ10분 토론 / 14F\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/31GohM5BikI\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">15분에 나옵니다.</p>\n<p data-ke-size=\"size16\">중국은 예로부터 북쪽에서 쳐들어와서 혼나는데요</p>\n<p data-ke-size=\"size16\">그때마다 궁녀와 뇌물을 바칩니다.&nbsp;</p>\n<p data-ke-size=\"size16\">이걸 200년간 지속해버리면 유목민의 유전자도 섞이게 되면서 결국 다 중국인이 되어버립니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상에 없는 이야기</p>\n<p data-ke-size=\"size16\">신장이나 티벳에서도 본토사람들을 보조금을 주면서 계속 보내는데</p>\n<p data-ke-size=\"size16\">이것도 결국 뇌물과 유전자를 섞는 전략이라고 볼 수 있습니다.</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=31GohM5BikI\n\n\n\n15분에 나옵니다.\n중국은 예로부터 북쪽에서 쳐들어와서 혼나는데요\n그때마다 궁녀와 뇌물을 바칩니다. \n이걸 200년간 지속해버리면 유목민의 유전자도 섞이게 되면서 결국 다 중국인이 되어버립니다.\n \n영상에 없는 이야기\n신장이나 티벳에서도 본토사람들을 보조금을 주면서 계속 보내는데\n이것도 결국 뇌물과 유전자를 섞는 전략이라고 볼 수 있습니다.",
        "guid": "http://serverdown.tistory.com/966",
        "categories": [
          "유튜브",
          "오블완",
          "중국",
          "티스토리챌린지"
        ],
        "isoDate": "2024-11-14T15:51:05.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "2차전지 생산은 어렵다. / 노스볼트 인터뷰 / 회고록",
        "link": "http://serverdown.tistory.com/965",
        "pubDate": "Thu, 14 Nov 2024 20:16:16 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/965#entry965comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=SHbQCWgOdK4\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=SHbQCWgOdK4</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=SHbQCWgOdK4\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/vhBDR/hyXwpItzeB/T3MIUm6ExuNWvdKdaLgwgK/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/HaDvG/hyXwvomb4o/kKBp79Ok2gDWd4vHszwCWK/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"배터리 생산은 정말 어렵다 노스볼트 내부자 인터뷰\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/SHbQCWgOdK4\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">노스볼트는 올해 생산 포기를 선언했죠</p>\n<p data-ke-size=\"size16\">하나기술도 노스폴트랑 협력중이였는데 같이 맛탱이 갔죠</p>\n<p data-ke-size=\"size16\">그들이 말하는 베터리 생산에 대한 이야기 입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">실체는 없고 결국 못만들어서 무너지는 그런 그림입니다.</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=SHbQCWgOdK4\n\n\n\n노스볼트는 올해 생산 포기를 선언했죠\n하나기술도 노스폴트랑 협력중이였는데 같이 맛탱이 갔죠\n그들이 말하는 베터리 생산에 대한 이야기 입니다.\n \n실체는 없고 결국 못만들어서 무너지는 그런 그림입니다.",
        "guid": "http://serverdown.tistory.com/965",
        "categories": [
          "투자"
        ],
        "isoDate": "2024-11-14T11:16:16.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "중국인 불행 단계 / 11단계까지 있군요 ㄷㄷ",
        "link": "http://serverdown.tistory.com/964",
        "pubDate": "Thu, 14 Nov 2024 20:11:57 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/964#entry964comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=baXUT3G1ji4\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=baXUT3G1ji4</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=baXUT3G1ji4\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/cuIklW/hyXzLC37gq/RkyXdm6PX0ERRVvhwSzWs0/img.jpg?width=1280&amp;height=720&amp;face=144_102_236_204,https://scrap.kakaocdn.net/dn/kBqJ6/hyXwpItwqV/qos3eyrOvvIKERbbO9G2E1/img.jpg?width=1280&amp;height=720&amp;face=144_102_236_204\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"중국 현지 상황: 본인이 비참하다고 생각하십니까? 무엇을 상상하든 상상 그 이상입니다!\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/baXUT3G1ji4\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">자꾸 붙다보니 계속 단계가 생기넹 ㄷㄷ</p>\n<p data-ke-size=\"size16\">1단계 : 무직</p>\n<p data-ke-size=\"size16\">2단계 : + 무저축</p>\n<p data-ke-size=\"size16\">3단계 : + 주택 대출</p>\n<p data-ke-size=\"size16\">4단계 : + 자녀 양육</p>\n<p data-ke-size=\"size16\">5단계 : + 빚 있음</p>\n<p data-ke-size=\"size16\">6단계 : + 빚 추심</p>\n<p data-ke-size=\"size16\">7단계 : + 질병 있음</p>\n<p data-ke-size=\"size16\">8단계 : + 부모도 질병 있음</p>\n<p data-ke-size=\"size16\">9단계 : + 주택 압류</p>\n<p data-ke-size=\"size16\">10단계 : + 집값이 절반 하락 (이쯤오면 별로 의미 없는거 같긴하지만)</p>\n<p data-ke-size=\"size16\">11단계 : + 집이 아직 지어지지 않았다. (어쩌지 ...)</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">불행한 시기 입니다.</p>\n<p data-ke-size=\"size16\">하필 중국개방 30년 중에 이게 끝물이라니 ...</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">참고로 저도 2차전지 끝물에서 ㅠㅠ</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=baXUT3G1ji4\n\n\n\n \n자꾸 붙다보니 계속 단계가 생기넹 ㄷㄷ\n1단계 : 무직\n2단계 : + 무저축\n3단계 : + 주택 대출\n4단계 : + 자녀 양육\n5단계 : + 빚 있음\n6단계 : + 빚 추심\n7단계 : + 질병 있음\n8단계 : + 부모도 질병 있음\n9단계 : + 주택 압류\n10단계 : + 집값이 절반 하락 (이쯤오면 별로 의미 없는거 같긴하지만)\n11단계 : + 집이 아직 지어지지 않았다. (어쩌지 ...)\n \n불행한 시기 입니다.\n하필 중국개방 30년 중에 이게 끝물이라니 ...\n \n참고로 저도 2차전지 끝물에서 ㅠㅠ",
        "guid": "http://serverdown.tistory.com/964",
        "categories": [
          "유튜브",
          "중국"
        ],
        "isoDate": "2024-11-14T11:11:57.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "고프로 회사에 대해 알아보자",
        "link": "http://serverdown.tistory.com/963",
        "pubDate": "Thu, 14 Nov 2024 16:21:32 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/963#entry963comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://youtu.be/n-qaqNU13h4?si=ja5mRh5Qd5cshgBo\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://youtu.be/n-qaqNU13h4?si=ja5mRh5Qd5cshgBo</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=n-qaqNU13h4\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/j3v1H/hyXwnw1NSY/fBpLycMDmZzNdnAjH82ZhK/img.jpg?width=1280&amp;height=720&amp;face=832_80_1054_322,https://scrap.kakaocdn.net/dn/jpw5D/hyXwopdAYr/9eDxbwE1QaYno5OfLPORs0/img.jpg?width=1280&amp;height=720&amp;face=832_80_1054_322\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"&lsquo;억만장자&rsquo;에서 &lsquo;대량해고&rsquo;로 이어진 회사ㅣ최고였던 고프로는 왜 최악의 위기에 빠진 걸\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/n-qaqNU13h4\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">드론에 카메라를 달려고 DJI 랑 접촉했다가</p>\n<p data-ke-size=\"size16\">DJI 를 무시해버렸넹</p>\n<p data-ke-size=\"size16\">비지니스 보는 눈이 없나봅니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"807\" data-origin-height=\"654\"><span data-url=\"https://blog.kakaocdn.net/dn/o2Z5m/btsKITaUp6W/yBmcUuE9CFSK4DncK4MYf0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/o2Z5m/btsKITaUp6W/yBmcUuE9CFSK4DncK4MYf0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/o2Z5m/btsKITaUp6W/yBmcUuE9CFSK4DncK4MYf0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fo2Z5m%2FbtsKITaUp6W%2FyBmcUuE9CFSK4DncK4MYf0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"807\" data-origin-height=\"654\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">ㅎㅎ 10년 맛탱기가는 차트</p>",
        "contentSnippet": "영상: https://youtu.be/n-qaqNU13h4?si=ja5mRh5Qd5cshgBo\n\n\n\n \n드론에 카메라를 달려고 DJI 랑 접촉했다가\nDJI 를 무시해버렸넹\n비지니스 보는 눈이 없나봅니다.\n \n\n\nㅎㅎ 10년 맛탱기가는 차트",
        "guid": "http://serverdown.tistory.com/963",
        "categories": [
          "유튜브"
        ],
        "isoDate": "2024-11-14T07:21:32.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "차트 공부 해봅시다. / 바닥이 나오는 과정",
        "link": "http://serverdown.tistory.com/962",
        "pubDate": "Thu, 14 Nov 2024 00:31:22 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/962#entry962comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"524\" data-origin-height=\"447\"><span data-url=\"https://blog.kakaocdn.net/dn/Bkdd4/btsKGRLKKb6/VZ8mXEiy88T8SJnvnsnfR1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/Bkdd4/btsKGRLKKb6/VZ8mXEiy88T8SJnvnsnfR1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/Bkdd4/btsKGRLKKb6/VZ8mXEiy88T8SJnvnsnfR1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FBkdd4%2FbtsKGRLKKb6%2FVZ8mXEiy88T8SJnvnsnfR1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"524\" data-origin-height=\"447\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">국내 주식은 맛탱이가서 살리기 어려울꺼 같습니다.</p>\n<p data-ke-size=\"size16\">언젠간 반등하겠죠 코로나때 처럼 크게 오를꺼 같긴한데 그게 언제인지는 모릅니다.</p>\n<p data-ke-size=\"size16\">그 반등을 놓치지 않기 위해 차트공부를 해봅니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이 차트는미국&nbsp; IONQ 현재 일봉 차트입니다.<br />IONQ 는 양자컴퓨터 회사죠.<br />정부 지원을 받나봅니다.</p>\n<p data-ke-size=\"size16\">반도체는 때리고 양자컴은 키우고 ... 어지럽군요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">1번은 RSI 지표구요 30갔다 올라왔죠</p>\n<p data-ke-size=\"size16\">여기서 한당뒤에 한번더 바닥을 찍습니다.</p>\n<p data-ke-size=\"size16\">정말 긴시간의 텀을 두고 움직이네요. 급하면 지는 겁니다.</p>\n<p data-ke-size=\"size16\">그 뒤로 2달을 더 기다가 갑자기 올라갔습니다.</p>\n<p data-ke-size=\"size16\">한국증시도 지금 몇번째 \"바닥이니\" 를 시전 중이지만 바닥이 그렇게 쉽게 오지 않는다는 것을 배울 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">2번 지표는 MACD 입니다. 이평선이 점점 벌어지는 모양입니다.</p>\n<p data-ke-size=\"size16\">그러고 보니 그 근처에 거래량이 크게 증가하는것을 보실 수 있습니다.&nbsp;</p>\n<p data-ke-size=\"size16\">이러면 찐바닥인것입니다.</p>\n<p data-ke-size=\"size16\">그뒤로도 위아래로 난리라 들어갈 기회는 많았었는데 ...</p>\n<p data-ke-size=\"size16\">제가 양자컴퓨터를 무시했네요 ...</p>\n<p data-ke-size=\"size16\">당시에 태양광 열심히 보고 있었는데 그건 지옥갔습니다.</p>\n<p data-ke-size=\"size16\">다음번에는 무시하지 말아야 겠습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">한국도 RSI 지표를 보면 뭔가 답이 좀 있을꺼 같군요 RSI 가 살아나도 다시 3개월이 걸린다니 ....</p>\n<p data-ke-size=\"size16\">한참 남았다는 말이 이를때 쓰는건가봅니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">바닥이 나올때는 이런 패턴이 나오더라 쯤으로 알아주세요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "국내 주식은 맛탱이가서 살리기 어려울꺼 같습니다.\n언젠간 반등하겠죠 코로나때 처럼 크게 오를꺼 같긴한데 그게 언제인지는 모릅니다.\n그 반등을 놓치지 않기 위해 차트공부를 해봅니다.\n \n이 차트는미국  IONQ 현재 일봉 차트입니다.\nIONQ 는 양자컴퓨터 회사죠.\n정부 지원을 받나봅니다.\n반도체는 때리고 양자컴은 키우고 ... 어지럽군요\n \n1번은 RSI 지표구요 30갔다 올라왔죠\n여기서 한당뒤에 한번더 바닥을 찍습니다.\n정말 긴시간의 텀을 두고 움직이네요. 급하면 지는 겁니다.\n그 뒤로 2달을 더 기다가 갑자기 올라갔습니다.\n한국증시도 지금 몇번째 \"바닥이니\" 를 시전 중이지만 바닥이 그렇게 쉽게 오지 않는다는 것을 배울 수 있습니다.\n \n2번 지표는 MACD 입니다. 이평선이 점점 벌어지는 모양입니다.\n그러고 보니 그 근처에 거래량이 크게 증가하는것을 보실 수 있습니다. \n이러면 찐바닥인것입니다.\n그뒤로도 위아래로 난리라 들어갈 기회는 많았었는데 ...\n제가 양자컴퓨터를 무시했네요 ...\n당시에 태양광 열심히 보고 있었는데 그건 지옥갔습니다.\n다음번에는 무시하지 말아야 겠습니다.\n \n한국도 RSI 지표를 보면 뭔가 답이 좀 있을꺼 같군요 RSI 가 살아나도 다시 3개월이 걸린다니 ....\n한참 남았다는 말이 이를때 쓰는건가봅니다.\n \n바닥이 나올때는 이런 패턴이 나오더라 쯤으로 알아주세요.",
        "guid": "http://serverdown.tistory.com/962",
        "categories": [
          "투자",
          "오블완",
          "티스토리챌린지"
        ],
        "isoDate": "2024-11-13T15:31:22.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "새로운 주식 지식 채널 찾았습니다. / 열띵히하자",
        "link": "http://serverdown.tistory.com/961",
        "pubDate": "Wed, 13 Nov 2024 11:50:00 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/961#entry961comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=DZXbHptu1eQ\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=DZXbHptu1eQ</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=DZXbHptu1eQ\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/eL5pK/hyXzIF6J4q/5hcSuMCpb9ZDRF8NHgMgNK/img.jpg?width=1280&amp;height=720&amp;face=548_234_834_546,https://scrap.kakaocdn.net/dn/QNmaP/hyXzMhrcSJ/UKajQpHn1qw9s5cTgt4ktk/img.jpg?width=1280&amp;height=720&amp;face=548_234_834_546\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"2차전지는 이 기업만 최대한 사모우세요\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/DZXbHptu1eQ\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">구독자도 200명 정도인 이시점 빠르게 탑승해봅니다.</p>\n<p data-ke-size=\"size16\">일단 미국이랑 코인으로 벌어 다시 들어오겠습니다.</p>\n<p data-ke-size=\"size16\">한국은 오를때 금방 오릅니다.</p>\n<p data-ke-size=\"size16\">내년 2월 아니면 내년 11월 정도로 보고 있습니다..</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=DZXbHptu1eQ\n\n\n\n구독자도 200명 정도인 이시점 빠르게 탑승해봅니다.\n일단 미국이랑 코인으로 벌어 다시 들어오겠습니다.\n한국은 오를때 금방 오릅니다.\n내년 2월 아니면 내년 11월 정도로 보고 있습니다..",
        "guid": "http://serverdown.tistory.com/961",
        "categories": [
          "투자",
          "리더"
        ],
        "isoDate": "2024-11-13T02:50:00.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "비트액스 ckpool 설정 방법 / Bisaxe",
        "link": "http://serverdown.tistory.com/960",
        "pubDate": "Wed, 13 Nov 2024 00:34:27 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/960#entry960comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"713\" data-origin-height=\"568\"><span data-url=\"https://blog.kakaocdn.net/dn/cJP40D/btsKHuHTw2l/sfq9K6TsErKcXnVQZNAhJK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cJP40D/btsKHuHTw2l/sfq9K6TsErKcXnVQZNAhJK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/cJP40D/btsKHuHTw2l/sfq9K6TsErKcXnVQZNAhJK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcJP40D%2FbtsKHuHTw2l%2Fsfq9K6TsErKcXnVQZNAhJK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"713\" data-origin-height=\"568\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">ckpool 홈페이지:<a href=\"https://solo.ckpool.org/\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://solo.ckpool.org/</a></p>\n<p data-ke-size=\"size16\">ckpool 운영방식 설명: <a href=\"https://bitcointalk.org/index.php?topic=5237323.0\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://bitcointalk.org/index.php?topic=5237323.0</a></p>\n<p data-ke-size=\"size16\">여기 룰 설명중에 이부분이 중요한거 같습니다.</p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">Note that if you do not find a block, you get no reward at all with solo mining.</span></p>\n<p data-ke-size=\"size16\">블록을&nbsp;찾지&nbsp;못하면&nbsp;솔로&nbsp;채굴을&nbsp;해도&nbsp;전혀&nbsp;보상을&nbsp;받을&nbsp;수&nbsp;없다는&nbsp;점에&nbsp;유의하세요.</p>\n<p data-ke-size=\"size16\"><br /><span style=\"text-align: start;\">2% goes to bc1q28kkr5hk4gnqe3evma6runjrd2pvqyp8fpwfzu to operate the pool and contribute to further ckpool code development.</span></p>\n<p data-ke-size=\"size16\">2%는&nbsp;bc1q28kkr5hk4gnqe3evma6runjrd2pvqyp8fpwfzu에&nbsp;전달되어&nbsp;풀을&nbsp;운영하고&nbsp;추가&nbsp;ckpool&nbsp;코드&nbsp;개발에&nbsp;기여합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">솔로 채굴이라 원래 보상없는 거구요<br />풀마다 운영 규칙이 조금씩 다르긴하더라구요</p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">당첨되면 2% + 이체 수수료는 빼고</span> 즉시 전송해줍니다.</p>\n<p data-ke-size=\"size16\">단순하면서 좋은 룰 같습니다. 한두달에 한명정도 나오는거 같더군요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">설정방법</h2>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">Stratum URL: solo.ckpool.org</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">Stratum Port: 4334</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">Stratum User: 지갑주소.별명<br />예를 들어 제꺼는 bc1qc272dkew26ea46z2egmt22a3uplpzqgc7snlcs.bitaxekorean</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">Stratum Password: x<br />아무거나 넣으라는데 보통 x 를 넣습니다.</span></p>\n<h2 data-ke-size=\"size26\"><span style=\"text-align: start;\">주의: 별명부분은 블록에 기록되고 모두가 볼 수 있으니 [개인정보] 넣지 마세요</span></h2>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "ckpool 홈페이지:https://solo.ckpool.org/\nckpool 운영방식 설명: https://bitcointalk.org/index.php?topic=5237323.0\n여기 룰 설명중에 이부분이 중요한거 같습니다.\nNote that if you do not find a block, you get no reward at all with solo mining.\n블록을 찾지 못하면 솔로 채굴을 해도 전혀 보상을 받을 수 없다는 점에 유의하세요.\n2% goes to bc1q28kkr5hk4gnqe3evma6runjrd2pvqyp8fpwfzu to operate the pool and contribute to further ckpool code development.\n2%는 bc1q28kkr5hk4gnqe3evma6runjrd2pvqyp8fpwfzu에 전달되어 풀을 운영하고 추가 ckpool 코드 개발에 기여합니다.\n \n솔로 채굴이라 원래 보상없는 거구요\n풀마다 운영 규칙이 조금씩 다르긴하더라구요\n당첨되면 2% + 이체 수수료는 빼고 즉시 전송해줍니다.\n단순하면서 좋은 룰 같습니다. 한두달에 한명정도 나오는거 같더군요\n \n설정방법\nStratum URL: solo.ckpool.org\nStratum Port: 4334\nStratum User: 지갑주소.별명\n예를 들어 제꺼는 bc1qc272dkew26ea46z2egmt22a3uplpzqgc7snlcs.bitaxekorean\nStratum Password: x\n아무거나 넣으라는데 보통 x 를 넣습니다.\n주의: 별명부분은 블록에 기록되고 모두가 볼 수 있으니 [개인정보] 넣지 마세요",
        "guid": "http://serverdown.tistory.com/960",
        "categories": [
          "코인",
          "비트액스",
          "오블완",
          "채굴",
          "티스토리챌린지"
        ],
        "isoDate": "2024-11-12T15:34:27.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "비트액스 과열 해결기 / 열관리 / 쿨링 패드 / 선풍기 / Bitaxe Overheat",
        "link": "http://serverdown.tistory.com/959",
        "pubDate": "Tue, 12 Nov 2024 17:14:32 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/959#entry959comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1108\" data-origin-height=\"1113\"><span data-url=\"https://blog.kakaocdn.net/dn/Zjv2L/btsKJJMiMoo/PKXp5Z2nF9uQUwUKrAYTg0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/Zjv2L/btsKJJMiMoo/PKXp5Z2nF9uQUwUKrAYTg0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/Zjv2L/btsKJJMiMoo/PKXp5Z2nF9uQUwUKrAYTg0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FZjv2L%2FbtsKJJMiMoo%2FPKXp5Z2nF9uQUwUKrAYTg0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"1108\" data-origin-height=\"1113\"/></span></figure>\n</p>\n<h2 data-ke-size=\"size26\">오버히트 에러 해결법 / 조치 방법</h2>\n<p data-ke-size=\"size16\">스샷1 - Setting 화면</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1155\" data-origin-height=\"511\"><span data-url=\"https://blog.kakaocdn.net/dn/54C4j/btsKFM31CGr/nlBbUn7RMyuJAapnmZDD60/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/54C4j/btsKFM31CGr/nlBbUn7RMyuJAapnmZDD60/img.png\"><img src=\"https://blog.kakaocdn.net/dn/54C4j/btsKFM31CGr/nlBbUn7RMyuJAapnmZDD60/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F54C4j%2FbtsKFM31CGr%2FnlBbUn7RMyuJAapnmZDD60%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"1155\" data-origin-height=\"511\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">과열이 되어 멈추면 Setting 화면에 빨간 버튼이 생깁니다.</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">Disabled Overheat Mode</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">앗 이게 버튼인지 경고 문구인지 확인을 안해봤군요.</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">빨간색이라 누르면 안될꺼 같았습니다.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">과열이 되면 채굴이 중단되고</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">Frequency 와 <span style=\"text-align: start;\">Core Voltage 값이 비어있습니다.</span></span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\"><span style=\"text-align: start;\">이걸 default 값으로 바꾼후에 Save 및 Restart 를 해주시면 됩니다.</span></span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">스샷2 - Dashboard 화면</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1195\" data-origin-height=\"443\"><span data-url=\"https://blog.kakaocdn.net/dn/c7vgHv/btsKEXytGFH/WLD4slKdvk21cgLoUs9BI1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/c7vgHv/btsKEXytGFH/WLD4slKdvk21cgLoUs9BI1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/c7vgHv/btsKEXytGFH/WLD4slKdvk21cgLoUs9BI1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fc7vgHv%2FbtsKEXytGFH%2FWLD4slKdvk21cgLoUs9BI1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"1195\" data-origin-height=\"443\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">과열 설정을 수정하지 않으면 Dashboard 화면 상단에 경고 문구가 듭니다.</p>\n<p data-ke-size=\"size16\">결국 Settings 에서 고치고 오라는 뜻입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">노트북 쿨링패드는 어떨까?</h2>\n<p data-ke-size=\"size16\">결론 부터 말하자면 쿨링 패드 보다 더 추천하는 방법은 선풍기 입니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"548\" data-origin-height=\"582\"><span data-url=\"https://blog.kakaocdn.net/dn/dLLMXe/btsKF4J7EPf/Vre2Uyext90dWsyW4rAL7k/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/dLLMXe/btsKF4J7EPf/Vre2Uyext90dWsyW4rAL7k/img.png\"><img src=\"https://blog.kakaocdn.net/dn/dLLMXe/btsKF4J7EPf/Vre2Uyext90dWsyW4rAL7k/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdLLMXe%2FbtsKF4J7EPf%2FVre2Uyext90dWsyW4rAL7k%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"548\" data-origin-height=\"582\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">노트북 냉각 패드위에 올려놓은 사진인데요&nbsp;</p>\n<p data-ke-size=\"size16\">바람나오는 방향 잘 맞춰서 세워놓으면 효과가 있는거 같습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"502\" data-origin-height=\"477\"><span data-url=\"https://blog.kakaocdn.net/dn/bkPr7n/btsKFIm8Nxn/aeh4ptMVoP9M44kA8Kgya1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bkPr7n/btsKFIm8Nxn/aeh4ptMVoP9M44kA8Kgya1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bkPr7n/btsKFIm8Nxn/aeh4ptMVoP9M44kA8Kgya1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbkPr7n%2FbtsKFIm8Nxn%2Faeh4ptMVoP9M44kA8Kgya1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"502\" data-origin-height=\"477\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">결국 65도에서 57도까지 떨어졌습니당.</p>\n<p data-ke-size=\"size16\">노트북 쿨링패드 좋긴한데 각도 맞추기가 쉽지 않네요</p>\n<p data-ke-size=\"size16\">제껀 [링킨 LS-410] 인데 이건 싸고 별로구요 7천원</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"322\" data-origin-height=\"645\"><span data-url=\"https://blog.kakaocdn.net/dn/bZsCmd/btsKGBgPfEV/TfSnAdFj9YeQBJao2aCnPk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bZsCmd/btsKGBgPfEV/TfSnAdFj9YeQBJao2aCnPk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bZsCmd/btsKGBgPfEV/TfSnAdFj9YeQBJao2aCnPk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbZsCmd%2FbtsKGBgPfEV%2FTfSnAdFj9YeQBJao2aCnPk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"322\" data-origin-height=\"645\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">모양은이게 좋아보이네요 선풍기가 많네요</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"318\" data-origin-height=\"572\"><span data-url=\"https://blog.kakaocdn.net/dn/l0Pzb/btsKGG9WLWN/7khadzoHB3vTB7Pfnho2Ik/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/l0Pzb/btsKGG9WLWN/7khadzoHB3vTB7Pfnho2Ik/img.png\"><img src=\"https://blog.kakaocdn.net/dn/l0Pzb/btsKGG9WLWN/7khadzoHB3vTB7Pfnho2Ik/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fl0Pzb%2FbtsKGG9WLWN%2F7khadzoHB3vTB7Pfnho2Ik%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"318\" data-origin-height=\"572\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">좌우로 두개 분리된 제품은 이것입니다.</p>\n<p data-ke-size=\"size16\">채굴기는 작으니 좁은 공간에 강력하게 나와주는게 좋겟습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">더 좋은 방법 USB 선풍기</h2>\n<h2 data-ke-size=\"size26\">&nbsp;</h2>\n<h3 data-ke-size=\"size23\">USB 전원 공급 쿨링팬</h3>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"471\" data-origin-height=\"392\"><span data-url=\"https://blog.kakaocdn.net/dn/bOUJKc/btsKIee54P6/6h3naUDNPf8R6jpbFfagD0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bOUJKc/btsKIee54P6/6h3naUDNPf8R6jpbFfagD0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bOUJKc/btsKIee54P6/6h3naUDNPf8R6jpbFfagD0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbOUJKc%2FbtsKIee54P6%2F6h3naUDNPf8R6jpbFfagD0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"471\" data-origin-height=\"392\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\"><a href=\"https://www.coupang.com/vp/products/8011240760?itemId=22351166795&amp;vendorItemId=89396281688&amp;src=1042503&amp;spec=10304025&amp;addtag=400&amp;ctag=8011240760&amp;lptag=10304025I22351166795V89396281688&amp;itime=20241114135512&amp;pageType=PRODUCT&amp;pageValue=8011240760&amp;wPcid=16066276239327679299440&amp;wRef=&amp;wTime=20241114135512&amp;redirect=landing&amp;gclid=CjwKCAiAudG5BhAREiwAWMlSjAMcisoItJ1NgUcNo5SwlUxVHT8B0CDPDJm2WwHQBTnfQjdpcAsKXhoCftQQAvD_BwE&amp;mcid=386042d37fe7427e8d43ca17a08ccecd&amp;campaignid=21519412236&amp;adgroupid=\">5V 쿨링팬 USB 타입 60x60x10mm 1개 쿨러 - 케이스쿨러 | 쿠팡</a></p>\n<p data-ke-size=\"size16\">좋은 선풍기는 몇만원 해버리는군요</p>\n<p data-ke-size=\"size16\">수명보단 여러개 사서 고장나면 바꿔주는 식으로 써야겠습니다.<br />몸통이 없어서 세워쓰기 쉽지 않아 보이긴 하지만요.<br />옷걸이 같은거 구부려서 다리 만들어줘야겟습니다.</p>\n<h2 data-ke-size=\"size26\">&nbsp;</h2>\n<h3 data-ke-size=\"size23\">아래 싸구려 선풍기는 내구성 문제가 있습니다. 쓰지마세요&nbsp;</h3>\n<p style=\"background-color: #000000; color: #000000;\" data-ke-size=\"size16\">결론부터 쓰자면 하루만에 고장났습니다.</p>\n<p style=\"background-color: #000000; color: #000000;\" data-ke-size=\"size16\">12시간 연속으로 돌리던 중에 가버렸습니다. ㅠㅠ<br />좀더 내구성 좋고 큰 선풍기를 사야겠습니다.<br />효과는 대박이였습니다. 쿨링패드보다 훨씬 좋습니다. <br />좁은 영역에 가까이 붙일 수 있는게 핵심인것을 알았습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"314\" data-origin-height=\"497\"><span data-url=\"https://blog.kakaocdn.net/dn/b3OQXM/btsKFnYcm0N/IuRzifiKpmkkTnq8xKSHPK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/b3OQXM/btsKFnYcm0N/IuRzifiKpmkkTnq8xKSHPK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/b3OQXM/btsKFnYcm0N/IuRzifiKpmkkTnq8xKSHPK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb3OQXM%2FbtsKFnYcm0N%2FIuRzifiKpmkkTnq8xKSHPK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"314\" data-origin-height=\"497\"/></span></figure>\n</p>\n<h4 data-ke-size=\"size20\">고장나기 전에 쓴 내용</h4>\n<p data-ke-size=\"size16\">이게 수정이 얼만지는 모르겠는데 가격이 아주 저렴합니다.</p>\n<p data-ke-size=\"size16\">저는 1,300원에 두개 사봤습니다. 배송비 3,000원</p>\n<p data-ke-size=\"size16\">1. <span style=\"text-align: start;\">가격이 저렴</span>&nbsp;<br />2. <span style=\"text-align: start;\">직접 방향을 맞춰줄 수 있음</span></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"313\" data-origin-height=\"542\"><span data-url=\"https://blog.kakaocdn.net/dn/yRA1R/btsKGqtafNt/iMyx1ik5kskAnq5F4G93w1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/yRA1R/btsKGqtafNt/iMyx1ik5kskAnq5F4G93w1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/yRA1R/btsKGqtafNt/iMyx1ik5kskAnq5F4G93w1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FyRA1R%2FbtsKGqtafNt%2FiMyx1ik5kskAnq5F4G93w1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"313\" data-origin-height=\"542\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">바닥이 없는 선풍기는 스탠드 같은게 필요합니다.<br />usb 크래들이라고 부르는데 왜이케 비싸징 ㄷㄷㄷ</p>\n<p data-ke-size=\"size16\">저는 집에 하나 굴러다니는게 있군</p>\n<p data-ke-size=\"size16\">배송비까지 따지자면 적당한 미니 선풍기가 나을꺼 같군요</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"554\" data-origin-height=\"554\"><span data-url=\"https://blog.kakaocdn.net/dn/LSii2/btsKFq8tUd9/MRlqEhOKHNTpvWzuapcdL1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/LSii2/btsKFq8tUd9/MRlqEhOKHNTpvWzuapcdL1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/LSii2/btsKFq8tUd9/MRlqEhOKHNTpvWzuapcdL1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FLSii2%2FbtsKFq8tUd9%2FMRlqEhOKHNTpvWzuapcdL1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"554\" data-origin-height=\"554\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">1. usb 허브 / 전원 공급용<br />2. usb 선풍기</p>\n<p data-ke-size=\"size16\">usb 전원을 전원 공급해야해서 <br />멀치 usb 충전기가 필요하군요.</p>\n<p data-ke-size=\"size16\">거리는 가까울 수록 좋습니다.<br />멀리서 바람 부쳐봐야 거리의 제곱 만큼 약해집니다. (물리)</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">채굴기가 속도를 제어하는 원리</h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"298\" data-origin-height=\"422\"><span data-url=\"https://blog.kakaocdn.net/dn/chpgy2/btsKGLX6tKP/C1ZWIGU2Y7YSzgWPCHqlGk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/chpgy2/btsKGLX6tKP/C1ZWIGU2Y7YSzgWPCHqlGk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/chpgy2/btsKGLX6tKP/C1ZWIGU2Y7YSzgWPCHqlGk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fchpgy2%2FbtsKGLX6tKP%2FC1ZWIGU2Y7YSzgWPCHqlGk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"298\" data-origin-height=\"422\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">제가 찾아낸 규칙으로는&nbsp;</p>\n<p data-ke-size=\"size16\">온도가 올라가면 알아서 성능을 줄입니다. <br />열을 덜 내기 위한 조치 인거 같습니다.</p>\n<p data-ke-size=\"size16\">그러니까 열만 내려주면 채굴 속도도 빨라진다는 것입니다.</p>\n<p data-ke-size=\"size16\">채굴기 가격을 생각한다면 1 ~ 2 만원 더 쓰고 안정적으로 돌아가는게 더 중요할 것같습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">스샷 찍고 보니 성능이랑 관계는 없는데&nbsp;</p>\n<p data-ke-size=\"size16\"><span style=\"text-align: center;\">Voltage Regulator Temperature / 전압&nbsp;조정기&nbsp;온도</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: center;\">이 온도가 빨리 떨어지네요<br />이 값은 전원 공급용 반도체의 온도 값입니다.<br /></span><span style=\"text-align: center;\">보통&nbsp; cpu 보다 <span style=\"text-align: center;\">전압 조정기</span>가 먼저 고장나는데요<br /></span><span style=\"color: initial; text-align: center; letter-spacing: 0px;\">온도가 낮아지면 수명에 도움이 될 것 같습니다.<br /></span><span style=\"text-align: center;\">전원 공급 반도체는 성능이랑은 관련은 없습니다. <br />고장이 먼저 나는 부품이다 정도</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">최종적으로</h2>\n<p data-ke-size=\"size16\">선풍기만 틀어주면 관리가 되구요&nbsp;</p>\n<p data-ke-size=\"size16\">최종 설정은</p>\n<p data-ke-size=\"size16\">Frequency&nbsp; &nbsp; &nbsp; &nbsp; 595<br /><span style=\"text-align: start;\">Core Voltage&nbsp; &nbsp; &nbsp;1150 (기본값)</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">스샷</span></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"935\" data-origin-height=\"1606\"><span data-url=\"https://blog.kakaocdn.net/dn/WuQhh/btsKJHgFpEP/xNrtiwWyCGqfCkQvavcIEk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/WuQhh/btsKJHgFpEP/xNrtiwWyCGqfCkQvavcIEk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/WuQhh/btsKJHgFpEP/xNrtiwWyCGqfCkQvavcIEk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FWuQhh%2FbtsKJHgFpEP%2FxNrtiwWyCGqfCkQvavcIEk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"935\" data-origin-height=\"1606\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">좀 빠를때 찍을껄 그랬네요 1.2TH 로 다시 내려왔네요.<br />왔다갔다 하는거라.</span></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1108\" data-origin-height=\"1113\"><span data-url=\"https://blog.kakaocdn.net/dn/Zjv2L/btsKJJMiMoo/PKXp5Z2nF9uQUwUKrAYTg0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/Zjv2L/btsKJJMiMoo/PKXp5Z2nF9uQUwUKrAYTg0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/Zjv2L/btsKJJMiMoo/PKXp5Z2nF9uQUwUKrAYTg0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FZjv2L%2FbtsKJJMiMoo%2FPKXp5Z2nF9uQUwUKrAYTg0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"1108\" data-origin-height=\"1113\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">이런식으로 선풍기에 바짝 붙여줬면 좋습니다.</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">아참 조립도 뒤집어서 했습니다. 팬이 상단, 디스플레이가 하단 에 가 잇습니다.<br />선풍기랑 최대한 가까이 붙도록 하기위한 배치 입니다.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "오버히트 에러 해결법 / 조치 방법\n스샷1 - Setting 화면\n\n\n과열이 되어 멈추면 Setting 화면에 빨간 버튼이 생깁니다.\nDisabled Overheat Mode\n앗 이게 버튼인지 경고 문구인지 확인을 안해봤군요.\n빨간색이라 누르면 안될꺼 같았습니다.\n \n과열이 되면 채굴이 중단되고\nFrequency 와 Core Voltage 값이 비어있습니다.\n이걸 default 값으로 바꾼후에 Save 및 Restart 를 해주시면 됩니다.\n \n \n스샷2 - Dashboard 화면\n\n\n과열 설정을 수정하지 않으면 Dashboard 화면 상단에 경고 문구가 듭니다.\n결국 Settings 에서 고치고 오라는 뜻입니다.\n \n노트북 쿨링패드는 어떨까?\n결론 부터 말하자면 쿨링 패드 보다 더 추천하는 방법은 선풍기 입니다.\n\n\n노트북 냉각 패드위에 올려놓은 사진인데요 \n바람나오는 방향 잘 맞춰서 세워놓으면 효과가 있는거 같습니다.\n\n\n결국 65도에서 57도까지 떨어졌습니당.\n노트북 쿨링패드 좋긴한데 각도 맞추기가 쉽지 않네요\n제껀 [링킨 LS-410] 인데 이건 싸고 별로구요 7천원\n\n\n모양은이게 좋아보이네요 선풍기가 많네요\n\n\n좌우로 두개 분리된 제품은 이것입니다.\n채굴기는 작으니 좁은 공간에 강력하게 나와주는게 좋겟습니다.\n \n더 좋은 방법 USB 선풍기\n \nUSB 전원 공급 쿨링팬\n\n\n5V 쿨링팬 USB 타입 60x60x10mm 1개 쿨러 - 케이스쿨러 | 쿠팡\n좋은 선풍기는 몇만원 해버리는군요\n수명보단 여러개 사서 고장나면 바꿔주는 식으로 써야겠습니다.\n몸통이 없어서 세워쓰기 쉽지 않아 보이긴 하지만요.\n옷걸이 같은거 구부려서 다리 만들어줘야겟습니다.\n \n아래 싸구려 선풍기는 내구성 문제가 있습니다. 쓰지마세요 \n결론부터 쓰자면 하루만에 고장났습니다.\n12시간 연속으로 돌리던 중에 가버렸습니다. ㅠㅠ\n좀더 내구성 좋고 큰 선풍기를 사야겠습니다.\n효과는 대박이였습니다. 쿨링패드보다 훨씬 좋습니다. \n좁은 영역에 가까이 붙일 수 있는게 핵심인것을 알았습니다.\n\n\n고장나기 전에 쓴 내용\n이게 수정이 얼만지는 모르겠는데 가격이 아주 저렴합니다.\n저는 1,300원에 두개 사봤습니다. 배송비 3,000원\n1. 가격이 저렴 \n2. 직접 방향을 맞춰줄 수 있음\n\n\n바닥이 없는 선풍기는 스탠드 같은게 필요합니다.\nusb 크래들이라고 부르는데 왜이케 비싸징 ㄷㄷㄷ\n저는 집에 하나 굴러다니는게 있군\n배송비까지 따지자면 적당한 미니 선풍기가 나을꺼 같군요\n\n\n1. usb 허브 / 전원 공급용\n2. usb 선풍기\nusb 전원을 전원 공급해야해서 \n멀치 usb 충전기가 필요하군요.\n거리는 가까울 수록 좋습니다.\n멀리서 바람 부쳐봐야 거리의 제곱 만큼 약해집니다. (물리)\n \n \n \n \n채굴기가 속도를 제어하는 원리\n\n\n제가 찾아낸 규칙으로는 \n온도가 올라가면 알아서 성능을 줄입니다. \n열을 덜 내기 위한 조치 인거 같습니다.\n그러니까 열만 내려주면 채굴 속도도 빨라진다는 것입니다.\n채굴기 가격을 생각한다면 1 ~ 2 만원 더 쓰고 안정적으로 돌아가는게 더 중요할 것같습니다.\n \n스샷 찍고 보니 성능이랑 관계는 없는데 \nVoltage Regulator Temperature / 전압 조정기 온도\n이 온도가 빨리 떨어지네요\n이 값은 전원 공급용 반도체의 온도 값입니다.\n보통  cpu 보다 전압 조정기가 먼저 고장나는데요\n온도가 낮아지면 수명에 도움이 될 것 같습니다.\n전원 공급 반도체는 성능이랑은 관련은 없습니다. \n고장이 먼저 나는 부품이다 정도\n \n \n최종적으로\n선풍기만 틀어주면 관리가 되구요 \n최종 설정은\nFrequency        595\nCore Voltage     1150 (기본값)\n스샷\n\n\n좀 빠를때 찍을껄 그랬네요 1.2TH 로 다시 내려왔네요.\n왔다갔다 하는거라.\n\n\n이런식으로 선풍기에 바짝 붙여줬면 좋습니다.\n아참 조립도 뒤집어서 했습니다. 팬이 상단, 디스플레이가 하단 에 가 잇습니다.\n선풍기랑 최대한 가까이 붙도록 하기위한 배치 입니다.",
        "guid": "http://serverdown.tistory.com/959",
        "categories": [
          "코인",
          "bitaxe",
          "비트액스"
        ],
        "isoDate": "2024-11-12T08:14:32.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "공포의 한자 공부",
        "link": "http://serverdown.tistory.com/958",
        "pubDate": "Tue, 12 Nov 2024 14:33:39 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/958#entry958comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=V6i2aiH8oac&amp;t=11s\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=V6i2aiH8oac&amp;t=11s</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=V6i2aiH8oac\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/NN3Nz/hyXwqz3qoL/kkSc2rkTt4PQKqHJT0xR30/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/zbPUq/hyXwmxFdbW/ygnUooI1ZBi66q9UFuOYo1/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"고대에서 현대로 접어들며 의미와 발음이 전부 소실되어 버린 '유령 한자'에 얽힌 소름 끼치는 \" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/V6i2aiH8oac\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">한자 무서워</p>\n<p data-ke-size=\"size16\">입두개 달린 괴물 - 에어리언 아닌가</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=V6i2aiH8oac&t=11s\n\n\n\n한자 무서워\n입두개 달린 괴물 - 에어리언 아닌가",
        "guid": "http://serverdown.tistory.com/958",
        "categories": [
          "유튜브"
        ],
        "isoDate": "2024-11-12T05:33:39.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "금투세 폐지, 이젠 외국계 투자자들도 외치네요 ㄷㄷ",
        "link": "http://serverdown.tistory.com/957",
        "pubDate": "Tue, 12 Nov 2024 12:07:01 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/957#entry957comment",
        "content": "<p data-ke-size=\"size16\">기사: <a href=\"https://m.edaily.co.kr/News/Read?newsId=03132406639084736&amp;mediaCodeNo=257\">美행동주의 \"韓 증시, 금투세 폐지&middot;밸류업으로 매력 높아져\"</a></p>\n<figure id=\"og_1731380693228\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"article\" data-og-title=\"美행동주의 &quot;韓 증시, 금투세 폐지&middot;밸류업으로 매력 높아져&quot;\" data-og-description=\"미국 행동주의 펀드인 돌턴인베스트먼트가 국내 증시에 대한 투자 매력도가 높아지고 있다고 11일 짚었다. 금융투자소득세(금투세) 폐지와 밸류업 정책 등으로 시장 환경이 개선됨에 따라 저평\" data-og-host=\"m.edaily.co.kr\" data-og-source-url=\"https://m.edaily.co.kr/News/Read?newsId=03132406639084736&amp;mediaCodeNo=257\" data-og-url=\"https://m.edaily.co.kr/News/Read?mediaCodeNo=257&amp;newsId=03132406639084736\" data-og-image=\"https://scrap.kakaocdn.net/dn/Bn5bN/hyXwjHHYoD/hOcAMjcXGP4AGz9GOFnN7k/img.jpg?width=670&amp;height=181&amp;face=0_0_670_181,https://scrap.kakaocdn.net/dn/cRBMKC/hyXwmLaq4U/Vk7GXKIgELeF1mUjNjuqI1/img.jpg?width=670&amp;height=181&amp;face=0_0_670_181\"><a href=\"https://m.edaily.co.kr/News/Read?newsId=03132406639084736&amp;mediaCodeNo=257\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://m.edaily.co.kr/News/Read?newsId=03132406639084736&amp;mediaCodeNo=257\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/Bn5bN/hyXwjHHYoD/hOcAMjcXGP4AGz9GOFnN7k/img.jpg?width=670&amp;height=181&amp;face=0_0_670_181,https://scrap.kakaocdn.net/dn/cRBMKC/hyXwmLaq4U/Vk7GXKIgELeF1mUjNjuqI1/img.jpg?width=670&amp;height=181&amp;face=0_0_670_181');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">美행동주의 \"韓 증시, 금투세 폐지&middot;밸류업으로 매력 높아져\"</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">미국 행동주의 펀드인 돌턴인베스트먼트가 국내 증시에 대한 투자 매력도가 높아지고 있다고 11일 짚었다. 금융투자소득세(금투세) 폐지와 밸류업 정책 등으로 시장 환경이 개선됨에 따라 저평</p>\n<p class=\"og-host\" data-ke-size=\"size16\">m.edaily.co.kr</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">이게 무슨일이죠 ㄷㄷㄷ&nbsp;</p>\n<p data-ke-size=\"size16\">12 -13일은 빠때리아저씨의 예언일 중 하나인데요</p>\n<p data-ke-size=\"size16\">표결 이야기가 나와야 할 대입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">외국계 투자자들도 금투세 보고 잇었네요</p>\n<p data-ke-size=\"size16\">민주당 놈들아 아니라메<br />금투세 도입해야 건전해진다메</p>\n<p data-ke-size=\"size16\">다 매국노 였습니다.<br />어덯게든 부동산 살리려고 증시에 돈을 빼개 만드네요</p>\n<p data-ke-size=\"size16\">그냥 푸념이였습니다.</p>\n<p data-ke-size=\"size16\">코인이랑 미국 주식은 잘되네요</p>",
        "contentSnippet": "기사: 美행동주의 \"韓 증시, 금투세 폐지·밸류업으로 매력 높아져\"\n\n \n美행동주의 \"韓 증시, 금투세 폐지·밸류업으로 매력 높아져\"\n미국 행동주의 펀드인 돌턴인베스트먼트가 국내 증시에 대한 투자 매력도가 높아지고 있다고 11일 짚었다. 금융투자소득세(금투세) 폐지와 밸류업 정책 등으로 시장 환경이 개선됨에 따라 저평\nm.edaily.co.kr\n\n이게 무슨일이죠 ㄷㄷㄷ \n12 -13일은 빠때리아저씨의 예언일 중 하나인데요\n표결 이야기가 나와야 할 대입니다.\n \n외국계 투자자들도 금투세 보고 잇었네요\n민주당 놈들아 아니라메\n금투세 도입해야 건전해진다메\n다 매국노 였습니다.\n어덯게든 부동산 살리려고 증시에 돈을 빼개 만드네요\n그냥 푸념이였습니다.\n코인이랑 미국 주식은 잘되네요",
        "guid": "http://serverdown.tistory.com/957",
        "categories": [
          "투자",
          "금투세"
        ],
        "isoDate": "2024-11-12T03:07:01.000Z"
      }
    ]
  },
  {
    "name": "coolspeed",
    "category": "개인",
    "posts": [
      {
        "creator": "coolspeed",
        "title": "라즈베리파이에서 LLM을 돌려봤다",
        "link": "https://coolspeed.wordpress.com/2024/11/10/%eb%9d%bc%ec%a6%88%eb%b2%a0%eb%a6%ac%ed%8c%8c%ec%9d%b4%ec%97%90%ec%84%9c-llm%ec%9d%84-%eb%8f%8c%eb%a0%a4%eb%b4%a4%eb%8b%a4/",
        "pubDate": "Sun, 10 Nov 2024 08:56:09 +0000",
        "content:encodedSnippet": "별건 없다. 그냥 Ollama 설치해서 돌리면 잘 돌아간다. 하지만 경험이 재미 있다.\n신용카드만한 컴퓨터에서 튜링테스트 통과할만한 인공지능이 작동하는 것을 목격하는 것은 신기한 경험이었다.\n방법\n라즈베리파이는 라즈베리파이 5, 8GB 램 버전을 썼다. LLM 모델은 2b 사이즈의 Gemma 2를 사용했다.\n(라즈베리파이를 포함한) 리눅스 환경에 Ollama 설치 방법:\nhttps://ollama.com/download/linux\n설치하고 나면 NVIDIA나 AMD의 그래픽카드가 탐지되지 않아서, CPU only로 돌릴거라는 메시지가 뜬다. 무시하면 된다.\nGemma 2 실행 방법:\nollama run gemma2:2b\n그러면 gemma2:2b 모델이 자동으로 다운로드 되고, 실행된다.\n프롬프트가 뜨면 이제부터 LLM과 대화할 수가 있다.",
        "dc:creator": "coolspeed",
        "comments": "https://coolspeed.wordpress.com/2024/11/10/%eb%9d%bc%ec%a6%88%eb%b2%a0%eb%a6%ac%ed%8c%8c%ec%9d%b4%ec%97%90%ec%84%9c-llm%ec%9d%84-%eb%8f%8c%eb%a0%a4%eb%b4%a4%eb%8b%a4/#respond",
        "content": "별건 없다. 그냥 Ollama 설치해서 돌리면 잘 돌아간다. 하지만 경험이 재미 있다. 신용카드만한 컴퓨터에서 튜링테스트 통과할만한 인공지능이 작동하는 것을 목격하는 것은 신기한 경험이었다. 방법 라즈베리파이는 라즈베리파이 5, 8GB 램 버전을 썼다. LLM 모델은 2b 사이즈의 Gemma 2를 사용했다. (라즈베리파이를 포함한) 리눅스 환경에 Ollama 설치 방법: https://ollama.com/download/linux 설치하고 나면 NVIDIA나 AMD의 그래픽카드가 탐지되지 않아서, CPU only로 [&#8230;]",
        "contentSnippet": "별건 없다. 그냥 Ollama 설치해서 돌리면 잘 돌아간다. 하지만 경험이 재미 있다. 신용카드만한 컴퓨터에서 튜링테스트 통과할만한 인공지능이 작동하는 것을 목격하는 것은 신기한 경험이었다. 방법 라즈베리파이는 라즈베리파이 5, 8GB 램 버전을 썼다. LLM 모델은 2b 사이즈의 Gemma 2를 사용했다. (라즈베리파이를 포함한) 리눅스 환경에 Ollama 설치 방법: https://ollama.com/download/linux 설치하고 나면 NVIDIA나 AMD의 그래픽카드가 탐지되지 않아서, CPU only로 […]",
        "guid": "http://coolspeed.wordpress.com/?p=3464",
        "categories": [
          "未分类"
        ],
        "isoDate": "2024-11-10T08:56:09.000Z"
      }
    ]
  },
  {
    "name": "오늘도 끄적끄적",
    "category": "개인",
    "posts": []
  },
  {
    "name": "dx11 Vanica's Lifelog - 夢が夢で終わらないように",
    "category": "개인",
    "posts": []
  },
  {
    "name": "초코사랑",
    "category": "개인",
    "posts": []
  },
  {
    "name": "ZeroCho Blog",
    "category": "개인",
    "posts": [
      {
        "creator": "ZeroCho",
        "title": "여러 커밋 합치기 - git squash",
        "link": "https://www.zerocho.com/category/Git/post/6735635ff3923a320c714a92",
        "pubDate": "Thu, 14 Nov 2024 02:41:35 GMT",
        "dc:creator": "ZeroCho",
        "content": "정신없이 깃 커밋을 하다보면 하나의 기능이 너무 여러 개의 커밋으로 쪼개져 있는 상황이 발생합니다. 다음과 같이 README.md를 수정하는 6개의 커밋이 있다고 칩시다.\nUpdate README.mdUpdate README.md Update README.md Update README.md Update README.md Create README.md\n커밋 기록에 이렇게 나와있으면 지저분하기 때문에 커밋을 하나로 합치면 좋을 것 같습니다.\n마지막으로부터 6개의 커밋을 합칠 것이므로 git rest --soft HEAD~개수 명령어를 사용합니다. 그러면 커밋들이 합쳐지는데 최종적으로 git commit으로 커밋하면 됩니다.\ngit reset --soft HEAD~6git commit -m \"커밋메시지\"\ngit rebase를 사용하는 방법도 있습니다. 다만 여기서는 합치길 원하는 숫자보다 1 더 큰 숫자를 입력해야 합니다. 저희가 마지막 6개 커밋을 합치길 원하므로 다음과 같이 입력합니다.\ngit rebase -i HEAD~7\n그러면 vim 에디터로 연결되는데 합칠 커밋들 앞에 붙은 pick을 전부 squash로 바꾸면 됩니다.\n",
        "contentSnippet": "정신없이 깃 커밋을 하다보면 하나의 기능이 너무 여러 개의 커밋으로 쪼개져 있는 상황이 발생합니다. 다음과 같이 README.md를 수정하는 6개의 커밋이 있다고 칩시다.\nUpdate README.mdUpdate README.md Update README.md Update README.md Update README.md Create README.md\n커밋 기록에 이렇게 나와있으면 지저분하기 때문에 커밋을 하나로 합치면 좋을 것 같습니다.\n마지막으로부터 6개의 커밋을 합칠 것이므로 git rest --soft HEAD~개수 명령어를 사용합니다. 그러면 커밋들이 합쳐지는데 최종적으로 git commit으로 커밋하면 됩니다.\ngit reset --soft HEAD~6git commit -m \"커밋메시지\"\ngit rebase를 사용하는 방법도 있습니다. 다만 여기서는 합치길 원하는 숫자보다 1 더 큰 숫자를 입력해야 합니다. 저희가 마지막 6개 커밋을 합치길 원하므로 다음과 같이 입력합니다.\ngit rebase -i HEAD~7\n그러면 vim 에디터로 연결되는데 합칠 커밋들 앞에 붙은 pick을 전부 squash로 바꾸면 됩니다.",
        "guid": "https://www.zerocho.com/category/Git/post/6735635ff3923a320c714a92",
        "categories": [
          "Git"
        ],
        "isoDate": "2024-11-14T02:41:35.000Z"
      },
      {
        "creator": "ZeroCho",
        "title": "중간 커밋 수정하기 - git rebase -i",
        "link": "https://www.zerocho.com/category/Git/post/67356085f3923a320c7145f9",
        "pubDate": "Thu, 14 Nov 2024 02:29:25 GMT",
        "dc:creator": "ZeroCho",
        "content": "가끔씩 git commit 중에 중간에 낀 커밋 내용을 수정해야 하는 경우가 있습니다. 다만 위 아래로 커밋들이 쌓여있어 어떻게 해야 할지 난감한 경우가 많았죠. 다행히도 중간 커밋을 바꿀 수 있는 방법이 있습니다. 해당 git 커밋의 아이디를 안다면 git rebase -i 명령어를 사용하면 됩니다. 제가 바꾸고 싶은 커밋 아이디가 b08c300이라면 git rebase -i b08c300^을 입력합니다.\ngit rebase -i 아이디^  // 예시 git rebase -i b08c300^\n아이디 뒤에 ^가 포인트입니다. ^를 붙이지 않으면 해당 아이디의 커밋이 포함되지 않습니다.\n그러면 터미널이 에디터 모드로 전환되는데 내용 중에 제일 위에 pick 아이디라는 글자가 보일겁니다. 여기서 pick을 edit으로 바꾸고 저장하면 됩니다. 저장하는 방법이 처음 하는 사람에게는 조금 어려울 수 있습니다.\npick b08c300 add: builder  &lt;--------------- 내가 바꾸고 싶은 커밋이 이거라고 칩시다pick 7f6287f add: prototypepick cc8382d add: commandpick 6d486a8 add: command2pick 4b153de add: statepick d418140 add: strategypick d7ea826 add: template methodpick 573aff2 add: chain of responsibilitypick b6633fd add: observer pattern.git/rebase-merge/git-rebase-todo [unix] (11:29 14/11/2024)                                             1,1 꼭대기\"~/WebstormProjects/grimpan/.git/rebase-merge/git-rebase-todo\" [유닉스] 54L, 2149B\n터미널에 vim 에디터가 보통 뜰텐데 a를 눌러서 입력모드(제일 하단에 -- 끼워넣기 --나 -- insert --가 보입니다)로 간 뒤 pick을 edit으로 변경합니다.\nedit b08c300 add: builder  &lt;--------------- pick을 edit으로 변경pick 7f6287f add: prototypepick cc8382d add: commandpick 6d486a8 add: command2pick 4b153de add: statepick d418140 add: strategypick d7ea826 add: template methodpick 573aff2 add: chain of responsibilitypick b6633fd add: observer pattern.git/rebase-merge/git-rebase-todo [unix] (11:29 14/11/2024)-- 끼워넣기 --\nesc 키를 눌러 명령어모드로 되돌아가 :wq 입력 후 엔터 키를 눌러 저장할 수 있습니다.\nedit b08c300 add: builderpick 7f6287f add: prototypepick cc8382d add: commandpick 6d486a8 add: command2pick 4b153de add: statepick d418140 add: strategypick d7ea826 add: template methodpick 573aff2 add: chain of responsibilitypick b6633fd add: observer pattern.git/rebase-merge/git-rebase-todo [unix] (11:29 14/11/2024):wq   &lt;------------------ esc를 누른 후 :wq입력하면 글자가 여기에 입력됩니다.\n그러면 소스 코드가 해당 커밋으로 되돌아갑니다. 여기서 여러분이 원하는 수정을 한 뒤 다음 명령어를 입력합니다\ngit add .git rebase --conitue \n그러면 다시 에디터 모드가 되면서 커밋 메시지를 수정하는 부분이 나오는데, 커밋 메시지를 변경할 게 없다면 :wq를 입력하고 엔터를 눌러 저장하면 중간 커밋이 변경된 모습을 확인할 수 있습니다.\n",
        "contentSnippet": "가끔씩 git commit 중에 중간에 낀 커밋 내용을 수정해야 하는 경우가 있습니다. 다만 위 아래로 커밋들이 쌓여있어 어떻게 해야 할지 난감한 경우가 많았죠. 다행히도 중간 커밋을 바꿀 수 있는 방법이 있습니다. 해당 git 커밋의 아이디를 안다면 git rebase -i 명령어를 사용하면 됩니다. 제가 바꾸고 싶은 커밋 아이디가 b08c300이라면 git rebase -i b08c300^을 입력합니다.\ngit rebase -i 아이디^  // 예시 git rebase -i b08c300^\n아이디 뒤에 ^가 포인트입니다. ^를 붙이지 않으면 해당 아이디의 커밋이 포함되지 않습니다.\n그러면 터미널이 에디터 모드로 전환되는데 내용 중에 제일 위에 pick 아이디라는 글자가 보일겁니다. 여기서 pick을 edit으로 바꾸고 저장하면 됩니다. 저장하는 방법이 처음 하는 사람에게는 조금 어려울 수 있습니다.\npick b08c300 add: builder  <--------------- 내가 바꾸고 싶은 커밋이 이거라고 칩시다pick 7f6287f add: prototypepick cc8382d add: commandpick 6d486a8 add: command2pick 4b153de add: statepick d418140 add: strategypick d7ea826 add: template methodpick 573aff2 add: chain of responsibilitypick b6633fd add: observer pattern.git/rebase-merge/git-rebase-todo [unix] (11:29 14/11/2024)                                             1,1 꼭대기\"~/WebstormProjects/grimpan/.git/rebase-merge/git-rebase-todo\" [유닉스] 54L, 2149B\n터미널에 vim 에디터가 보통 뜰텐데 a를 눌러서 입력모드(제일 하단에 -- 끼워넣기 --나 -- insert --가 보입니다)로 간 뒤 pick을 edit으로 변경합니다.\nedit b08c300 add: builder  <--------------- pick을 edit으로 변경pick 7f6287f add: prototypepick cc8382d add: commandpick 6d486a8 add: command2pick 4b153de add: statepick d418140 add: strategypick d7ea826 add: template methodpick 573aff2 add: chain of responsibilitypick b6633fd add: observer pattern.git/rebase-merge/git-rebase-todo [unix] (11:29 14/11/2024)-- 끼워넣기 --\nesc 키를 눌러 명령어모드로 되돌아가 :wq 입력 후 엔터 키를 눌러 저장할 수 있습니다.\nedit b08c300 add: builderpick 7f6287f add: prototypepick cc8382d add: commandpick 6d486a8 add: command2pick 4b153de add: statepick d418140 add: strategypick d7ea826 add: template methodpick 573aff2 add: chain of responsibilitypick b6633fd add: observer pattern.git/rebase-merge/git-rebase-todo [unix] (11:29 14/11/2024):wq   <------------------ esc를 누른 후 :wq입력하면 글자가 여기에 입력됩니다.\n그러면 소스 코드가 해당 커밋으로 되돌아갑니다. 여기서 여러분이 원하는 수정을 한 뒤 다음 명령어를 입력합니다\ngit add .git rebase --conitue \n그러면 다시 에디터 모드가 되면서 커밋 메시지를 수정하는 부분이 나오는데, 커밋 메시지를 변경할 게 없다면 :wq를 입력하고 엔터를 눌러 저장하면 중간 커밋이 변경된 모습을 확인할 수 있습니다.",
        "guid": "https://www.zerocho.com/category/Git/post/67356085f3923a320c7145f9",
        "categories": [
          "Git"
        ],
        "isoDate": "2024-11-14T02:29:25.000Z"
      }
    ]
  },
  {
    "name": "imays게임엔진개발자",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for hurinmon Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "기억보단 기록을",
    "category": "개인",
    "posts": []
  },
  {
    "name": "WestwoodForever's Dev Log",
    "category": "개인",
    "posts": []
  },
  {
    "name": "허니몬(Honeymon)의 자바guru",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Wolf Loves Fox :: 일상",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Game Programmer Life",
    "category": "개인",
    "posts": []
  },
  {
    "name": "IT 프리랜서 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "yuchi's dev",
    "category": "개인",
    "posts": []
  },
  {
    "name": "만화로 나누는 자유/오픈소스 소프트웨어 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "신현석(Hyeonseok Shin)",
    "category": "개인",
    "posts": []
  },
  {
    "name": "한상곤 - Sigmadream",
    "category": "개인",
    "posts": [
      {
        "creator": "Sangkon Han",
        "title": "내 맘대로 위클리 뉴스 - 2024년 44주(2024.11.03 - 2024.11.09)",
        "link": "https://www.sangkon.com/sigmadream_weekly_2024_44/",
        "pubDate": "Fri, 08 Nov 2024 18:06:00 GMT",
        "content:encodedSnippet": "Python\nWrite more pythonic code with context managers\nPython의 context managers를 활용하는 방법을 소개하는 기사 입니다.\nHost a FastAPI Application Without a Server\nFastAPI를 빠르게 배포하는 방법을 소개합니다.\nJavaScript\nConditional React hooks pattern\n\n조건부 Hooks을 활용하는 방법을 소개하는 기사 입니다.\nOOP\nBuilding a Full-Stack Application with Next.js and .NET API Backend\n\n.NET과 Next.js를 함꼐 활용하는 방법을 소개하는 기사 입니다.",
        "dc:creator": "Sangkon Han",
        "content": "<h2 id=\"python\">Python</h2>\n<ul>\n<li>\n<p><a href=\"https://hamatti.org/posts/write-more-pythonic-code-with-context-managers/?ref=sangkon.com\">Write more pythonic code with context managers</a></p>\n<ul>\n<li>Python&#xC758; context managers&#xB97C; &#xD65C;&#xC6A9;&#xD558;&#xB294; &#xBC29;&#xBC95;&#xC744; &#xC18C;&#xAC1C;&#xD558;&#xB294; &#xAE30;&#xC0AC; &#xC785;&#xB2C8;&#xB2E4;.</li>\n</ul>\n</li>\n<li>\n<p><a href=\"https://pinggy.io/blog/host_a_fastapi_app_without_a_server/?ref=sangkon.com\">Host a FastAPI Application Without a Server</a></p>\n<ul>\n<li>FastAPI&#xB97C; &#xBE60;&#xB974;&#xAC8C; &#xBC30;&#xD3EC;&#xD558;&#xB294; &#xBC29;&#xBC95;&#xC744; &#xC18C;&#xAC1C;</li></ul></li></ul>",
        "contentSnippet": "Python\nWrite more pythonic code with context managers\nPython의 context managers를 활용하는 방법을 소개하는 기사 입니다.\nHost a FastAPI Application Without a Server\nFastAPI를 빠르게 배포하는 방법을 소개",
        "guid": "672e5302bf78853c742b06ce",
        "categories": [
          "주간 뉴스"
        ],
        "isoDate": "2024-11-08T18:06:00.000Z"
      }
    ]
  },
  {
    "name": "개발자 울이 노트",
    "category": "개인",
    "posts": []
  },
  {
    "name": "즐거운 개발자 :: 네이버  블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황제펭귄의 게임개발이야기 [여기는 한국]",
    "category": "개인",
    "posts": []
  },
  {
    "name": "LINE ENGINEERING",
    "category": "기업",
    "posts": []
  },
  {
    "name": "뱅크샐러드 블로그",
    "category": "기업",
    "posts": [
      {
        "title": "테크스펙은 문서가 아니다",
        "link": "https://blog.banksalad.com/tech/techspec-is-not-doc/",
        "pubDate": "Mon, 11 Nov 2024 00:00:00 GMT",
        "content": "안녕하세요. 뱅크샐러드에서 Tech Lead…",
        "contentSnippet": "안녕하세요. 뱅크샐러드에서 Tech Lead…",
        "guid": "https://blog.banksalad.com/tech/techspec-is-not-doc/",
        "isoDate": "2024-11-11T00:00:00.000Z"
      }
    ]
  },
  {
    "name": "우아한형제들 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "TOAST Meetup",
    "category": "기업",
    "posts": [
      {
        "title": "OpenInfra Asia Summit 2024 돌아보기",
        "link": "https://meetup.nhncloud.com/posts/389",
        "pubDate": "Mon, 11 Nov 2024 02:16:45 GMT",
        "content": "![1.jpg](https://image.toast.com/aaaadh/real/2024/techblog/1.jpg)\r\r\n\r\r\n\r\r\n> 본 콘텐츠는 OpenInfra Foundation의 공식 블로그 [Superuser](https://superuser.openinfra.dev/articles/openinfra-asia-summit-2024-recap/)에 영문본이 게시되었습니다.\r\r\n<br/>\r\r\n\r\r\n\r\r\n지난 9월 3일 개최된 오픈인프라 아시아 서밋(OpenInfra Summit Asia) 2024에 참여하는 좋은 기회를 얻게 되었습니다. 오픈인프라 아시아 서밋은 아시아 전역의 오픈소스 커뮤니티를 지원하기 위해 2023년 설립된 지역 허브인 [오픈인프라 아시아(OpenInfra Asia)](https://openinfraasia.org/)가 개최하는 첫 번째 서밋으로 그 자체로 매우 의미 있는 행사였습니다. 이번 서밋에는 앤트그룹, 화웨이 등 아시아 지역 유수의 기업이 참여했는데요. 그 중 [NHN Cloud](https://www.nhncloud.com/kr)도 아시아 지역의 핵심 클라우드 서비스 기업으로서 오픈스택 기술력과 그간의 커뮤니티 활동을 인정받아 오픈인프라 아시아의 창립 멤버로 초대되었다고 합니다.\r\r\n\r\r\n또한 이번 행사는 주요 오픈 소스 재단인 [Open Compute Project(OCP)](https://www.opencompute.org/) 재단과 공동으로 주최되어, 두 글로벌 오픈 소스 커뮤니티의 핵심 재단이 손잡은 만큼 규모도 크고 프로그램도 매우 다양하고 풍성하게 구성되었습니다.\r\r\n\r\r\n무려 240명이 넘는 연사가 190개 이상의 세션을 제공했으며, 리눅스, 오픈스택, Kubernetes 외 30개 이상의 오픈소스 프로젝트 등 다루는 주제도 무척 다양했습니다. 30개국이 넘는 국가에서 1500명이 넘는 참가자와 함께 저도 유익하고 인사이트가 풍부한 세션들을 들을 수 있었습니다.\r\r\n\r\r\n![2.jpg](https://image.toast.com/aaaadh/real/2024/techblog/2%281%29.jpg)\r\r\n귀중한 정보를 담은 세션들이 주로 영어와 한국어로 제공되었으며 영어 세션이 다수를 이루었습니다. 따라서 영어가 익숙지 않은 청중들을 위해 flitto 동시번역 서비스로 16개국 이상의 언어를 제공한다는 점이 무척 흥미로웠습니다. 세션 룸에 동시번역 서비스 QR 코드가 배치되어있어, 앱 다운없이 손쉽고 간편하게 접근할 수 있었습니다.\r\r\n\r\r\n많은 참가자들이 자신의 패드에서 번역 서비스를 통해 연사가 말하자마자 매끄럽게 번역된 콘텐츠를 접할 수 있었습니다.\r\r\n\r\r\n## Keynotes\r\r\n\r\r\n![3.jpg](https://image.toast.com/aaaadh/real/2024/techblog/3%281%29.jpg)\r\r\n오픈 인프라 재단의 최고운영책임자(COO)인 Mark Collier의 키노트가 무척 인상 깊었는데요. 인프라 전반의 트렌드 4가지를 일목요연하고 간결하게 정리해 주었습니다.\r\r\n\r\r\n### Digital Sovereignty\r\r\n\r\r\n\r\r\n내 데이터가 어디에 저장되고 누가 접근 가능하며 어떤 법률의 지배를 받는지에 대한 관심이 커지고 중요한 사안이 되었는데요. 이는 개인에 국한되지 않고, 국가 기관 및 정부에게도 중요한 사안이 되었습니다.\r\r\n대표적인 예로 프랑스의 주요 은행들이 오픈 스택을 채택해 자신들의 데이터 위치와 접근 권한, 적용되는 법률을 직접 관리하고 있습니다. 이렇게 주요 기관들이 자신들의 데이터를 매우 독점적으로 처리하고 보유하고자하는 트렌드는 전 세계적으로 나타나고 있습니다.\r\r\n\r\r\n이 같은 트렌드는 하드웨어 영역에서도 나타나고 있는데요. RISC-V가 그 예입니다.\r\r\n\r\r\n> RISC-V는 2010년 UC 버클리에서 개발한 오픈소스 RISC(Reduced Instruction Set Computer) 명령어 세트 아키텍처입니다. RISC-V 아키텍처를 통해 설계자는 최종 애플리케이션에 맞게 프로세서를 맞춤화하고 설계할 수 있습니다.\r\r\n\r\r\n즉 현재는 기존에 사용하는 프로그램이나 하드웨어에 대해 영구적인 접근 권한을 갖고 통제하고 원하는 대로 사용하고 싶어 하는 산업 전반의 트렌드가 있다고 합니다. 이 같은 트렌드로 오픈 소스 및 오픈 테크놀로지는 그 어느 때보다 중요해졌다고 합니다.\r\r\n\r\r\n### License Changes\r\r\n\r\r\n\r\r\n* Terraform\r\r\n예상치 못한 라이선스 변경으로 시장에 악영향을 미쳤지만, 오픈소스가 이에 대한 해결책을 제시해 줄 수 있습니다. Terraform의 라이선스 변경으로 인해 오픈 소스 프로젝트인 Open Tofu가 등장하여 테라폼을 대체하는 역할을 수행해 사용자들에게 신뢰를 제공하고 있습니다.\r\r\n\r\r\n* VMware\r\r\nVMware의 라이선스가 변경됨에 따라 많은 사용자들이 VMware에서 OpenStack으로 마이그레이션에 대한 관심이 커지고 있습니다. 대표적으로 미국의 주요 자동차 보험사인 GEICO가 최근 VMware를 버리고 오픈스택으로 대규모 클라우드 인프라를 구축해 큰 주목을 받았다고 합니다. Mark Collier는 마이그레이션에 관한 백서를 행사 당일에 [QR](https://www.openstack.org/vmware-migration-to-openstack-white-paper)로 공개하기도 했습니다.\r\r\n\r\r\n### Security Concerns\r\r\n\r\r\n\r\r\n최근 운영 중인 컨테이너 이미지의 87%에 치명적이거나 심각도가 높은 취약점이 있다는 사실이 밝혀져 우려를 자아내고 있습니다. 이 문제를 해결하기 위한 방안으로 오픈 인프라 재단에서 주최하는 카타 컨테이너(Kata Container) 프로젝트가 큰 주목을 받고 있습니다. 카타 컨테이너는 컨테이너의 속도와 가상 머신의 보안을 결합한 경량 가상화를 제공함으로써 속도와 보안 사이의 균형을 제공합니다. 컨테이너 환경 보안에 효과적이라는 점에서 Microsoft Azure, NVIDIA, AWS 등 주요 기업들이 카타 컨테이너에 투자하고 지원하고 있습니다.\r\r\n\r\r\n### AI Redefining Infra\r\r\n\r\r\n\r\r\nAI에 대한 기업들의 관심이 이례적입니다. 너도 나도 할 것 없이 기업들은 GPU를 최대한 많이 확보해 방대한 규모로 자신의 데이터 센터에 구축하고 있습니다. 기업이 AI 용량 구축에 거대한 투자하고 있으며, 오픈스택이 AI 워크 로드를 지원하는 데 중요한 역할을 하고 있습니다.\r\r\n\r\r\n이렇게 디지털 주권, 라이선스 변경, 보안 문제, 인공지능과 같이 네 가지 주요 트렌드로 오픈 소스에 대한 관심과 투자가 그 어느 때보다도 활발하게 일어나고 있고 오픈 소스 커뮤니티의 성장을 이끌고 있다고 합니다.\r\r\n\r\r\n## Sessions\r\r\n\r\r\n오픈인프라 아시아 서밋 2024에는 다양한 주제에 대해 심도 있는 내용을 다루는 세션이 많았는데요. 저는 그중 NHN Cloud 인프라서비스개발랩 박성우 이사님이 발표하신 세션 **Openstack of NHN Cloud from a network perspective**을 통해 오픈스택의 실제 적용 사례와 오픈스택의 한계점을 어떻게 보완했는지를 배울 수 있었습니다. 아래는 세션 내용의 일부를 요약해 보았습니다.\r\r\n\r\r\n### 1. Openstack of NHN Cloud from a network perspective\r\r\n\r\r\n![4.jpg](https://image.toast.com/aaaadh/real/2024/techblog/4%281%29.jpg)\r\r\n\r\r\n>  [영상 보러 가기](https://www.youtube.com/watch?v=IgXJq8jmuJI&t=1s)\r\r\n\r\r\nNHN Cloud는 2015년에 OpenStack의 Neutron 모듈을 활용해 네트워크를 구축하고 서비스를 시작했습니다. 하지만 서비스 초기 단계에서는 Neutron 모듈의 기본 기능만으로는 NHN Cloud의 서비스들을 효율적이고 안정적으로 운영하는 데 한계가 있었다고 합니다. 이중화가 불가능하고 장애 조치 및 스케일업 기능이 지원되지 않았기 때문입니다. 이번 세션에서는 NHN Cloud가 이러한 문제를 어떻게 해결했는지에 대해 자세히 다뤘습니다.\r\r\n\r\r\nNeutron의 기본 구조는 컴퓨트 노드 안에 큐라우터와 OVS integration bridge, 그리고 그 사이에 위치한 리눅스 브릿지로 구성됩니다. 여기에 IP 테이블을 연결하여 보안 규칙(Security Rules)을 설정하게 됩니다. 하지만 이 구조는 보안 규칙이 많아질수록 코드 오류의 원인을 파악하고 문제를 분석하는 데 어려움을 겪게 되며 유지 보수에 큰 부담이 따랐다고 합니다. 더구나 리눅스 브릿지는 OSI 모델의 2계층에서만 동작하기 때문에, 라우팅이나 IP 주소를 기반으로 트래픽을 처리하는 데도 한계가 있었습니다.\r\r\n\r\r\n![5.png](https://image.toast.com/aaaadh/real/2024/techblog/5.png)\r\r\n\r\r\n이러한 문제를 해결하기 위해 NHN Cloud는 컴퓨트 노드에서 리눅스 브릿지와 큐라우터를 제거하고, OVS integration bridge로 대체하는 방식을 채택했습니다. 네트워크를 VxLAN마다 나누고 각 브릿지와 연결하는 방식으로 구성하여 더 효율적인 네트워크 구조를 구현했습니다. 또한, NVIDIA의 SR-IOV Representer를 OVS bridge와 연결해 I/O 성능을 대폭 개선한 점이 인상 깊었습니다.\r\r\n\r\r\n> SR-IOV는 하나의 물리적 PCI Express 장치를 여러 가상 머신이 동시에 사용할 수 있게 해주는 기술로, 가상화 환경에서 매우 유용한 기술입니다.\r\r\n\r\r\n앞서 컴퓨트 노드에서 큐라우터를 제거했다고 했는데요. 이는 큐라우터의 한계를 극복하기 위한 조치로 랙 상단으로 이동시켰습니다. 즉, 각 랙이 하이퍼바이저처럼 작동하게 되어 컴퓨트 노드의 구조가 단순화되고, 최대 효율을 추구할 수 있었습니다.\r\r\n\r\r\n하지만 이러한 구조에서는 모든 트래픽이 랙 상단의 라우터로 집중되는 문제가 발생했습니다. 이를 해결하기 위해 NHN Cloud는 vSwitch를 개발했으며, 이 vSwitch는 5mpps(초당 500만 패킷)의 뛰어난 처리 속도를 자랑합니다.\r\r\n\r\r\n또한, VLAN에서 VxLAN으로 전환한 이유도 흥미로웠는데, 이는 고객 수가 증가함에 따라 퍼블릭 환경에서 여러 VPC(Virtual Private Cloud)를 생성해야 했기 때문입니다.\r\r\n\r\r\n### 보안과 안정성\r\r\n\r\r\n\r\r\n보안과 안정성 측면에서도 다양한 개선이 이루어졌습니다. 기본적으로 Neutron이 제공하는 Security Groups와 함께 Network ACL을 구성하여, 서버가 클라이언트 상태 정보를 저장하지 않아도 통신할 수 있는 환경을 구축했습니다. 또한, Internet Gateway 없이도 원격 호스트와 통신할 수 있도록 VPN Gateway를 연결해 네트워크 통신의 유연성을 강화했습니다.\r\r\n\r\r\n![6.png](https://image.toast.com/aaaadh/real/2024/techblog/6.png)\r\r\n\r\r\nNHN Cloud는 2015년 서비스 시작 이후, OpenStack Neutron에 다양한 기능을 추가하기 위해 여러 플러그인과 자체 개발한 에이전트들을 도입해왔는데요. 세션을 통해 NHN Cloud가 기존의 네트워크 문제를 혁신적으로 해결하고, 서비스 안정성과 보안을 동시에 강화한 점을 직접 확인할 수 있었습니다. 동시에 클라우드 네트워크 관리의 복잡성을 체감할 수 있었습니다.\r\r\n\r\r\n<br/>\r\r\n\r\r\n### 2. Bridging the Gap Between Community and Contributing Orgs\r\r\n\r\r\n![7.jpg](https://image.toast.com/aaaadh/real/2024/techblog/7.jpg)\r\r\n\r\r\n강의 형태로 진행되는 세션이 아닌 참석자들과 함께 자유롭게 토의하는 포럼 형태의 세션도 제공되었습니다. 그중 하나인 **Bridging the Gap Between Community and Contributing Orgs**은 오픈 소스 커뮤니티를 더욱 활성화하기 위해 자유롭게 의견을 공유하는 자리였습니다. 주요 논의는 신규 기여자와 기존 기여자가 모두를 위한 커뮤니케이션을 활성화하고 기여자 경험을 개선하기 위한 방안을 논의하는 세션이었습니다.\r\r\n\r\r\n다양한 국가의 수많은 사람들이 오픈인프라 프로젝트에 기여하고 있는 만큼 커뮤니케이션의 한계를 극복하고 다양성을 높이고자하는 열정이 느껴지는 세션이었습니다.\r\r\n\r\r\n## OpenStack’s Role in the Future\r\r\n\r\r\n\r\r\n오픈인프라 서밋 아시아 2024는 클라우드 산업의 혁신을 선도하는 오픈소스 커뮤니티의 중요성을 다시 한 번 강조한 행사였습니다.\r\r\n\r\r\n특히 VMware에서 오픈스택으로의 마이그레이션이 주목을 받으면서 확장 가능하고, 안전하며, 비용 효율적인 솔루션으로 오픈스택을 도입하려는 기업들이 전 세계적으로 많다는 것을 느낄 수 있었습니다.\r\r\n\r\r\n또한, AI와 같은 고성능 컴퓨팅을 위한 지속 가능한 인프라에 대한 요구가 커지고 있는 상황에서, 오픈인프라 커뮤니티는 혁신적이고 획기적인 솔루션으로 이러한 글로벌 과제에 대응할 준비가 충분히 갖추어져 있음을 확인할 수 있었습니다. 이번 서밋을 통해 오픈소스 기반 인프라의 미래와 지속 가능한 기술 개발에 대한 기대감이 더욱 커졌습니다.",
        "contentSnippet": "![1.jpg](https://image.toast.com/aaaadh/real/2024/techblog/1.jpg)\r\r\n\r\r\n\r\r\n> 본 콘텐츠는 OpenInfra Foundation의 공식 블로그 [Superuser](https://superuser.openinfra.dev/articles/openinfra-asia-summit-2024-recap/)에 영문본이 게시되었습니다.\r\r\n\r\r\n\r\r\n\r\r\n지난 9월 3일 개최된 오픈인프라 아시아 서밋(OpenInfra Summit Asia) 2024에 참여하는 좋은 기회를 얻게 되었습니다. 오픈인프라 아시아 서밋은 아시아 전역의 오픈소스 커뮤니티를 지원하기 위해 2023년 설립된 지역 허브인 [오픈인프라 아시아(OpenInfra Asia)](https://openinfraasia.org/)가 개최하는 첫 번째 서밋으로 그 자체로 매우 의미 있는 행사였습니다. 이번 서밋에는 앤트그룹, 화웨이 등 아시아 지역 유수의 기업이 참여했는데요. 그 중 [NHN Cloud](https://www.nhncloud.com/kr)도 아시아 지역의 핵심 클라우드 서비스 기업으로서 오픈스택 기술력과 그간의 커뮤니티 활동을 인정받아 오픈인프라 아시아의 창립 멤버로 초대되었다고 합니다.\r\r\n\r\r\n또한 이번 행사는 주요 오픈 소스 재단인 [Open Compute Project(OCP)](https://www.opencompute.org/) 재단과 공동으로 주최되어, 두 글로벌 오픈 소스 커뮤니티의 핵심 재단이 손잡은 만큼 규모도 크고 프로그램도 매우 다양하고 풍성하게 구성되었습니다.\r\r\n\r\r\n무려 240명이 넘는 연사가 190개 이상의 세션을 제공했으며, 리눅스, 오픈스택, Kubernetes 외 30개 이상의 오픈소스 프로젝트 등 다루는 주제도 무척 다양했습니다. 30개국이 넘는 국가에서 1500명이 넘는 참가자와 함께 저도 유익하고 인사이트가 풍부한 세션들을 들을 수 있었습니다.\r\r\n\r\r\n![2.jpg](https://image.toast.com/aaaadh/real/2024/techblog/2%281%29.jpg)\r\r\n귀중한 정보를 담은 세션들이 주로 영어와 한국어로 제공되었으며 영어 세션이 다수를 이루었습니다. 따라서 영어가 익숙지 않은 청중들을 위해 flitto 동시번역 서비스로 16개국 이상의 언어를 제공한다는 점이 무척 흥미로웠습니다. 세션 룸에 동시번역 서비스 QR 코드가 배치되어있어, 앱 다운없이 손쉽고 간편하게 접근할 수 있었습니다.\r\r\n\r\r\n많은 참가자들이 자신의 패드에서 번역 서비스를 통해 연사가 말하자마자 매끄럽게 번역된 콘텐츠를 접할 수 있었습니다.\r\r\n\r\r\n## Keynotes\r\r\n\r\r\n![3.jpg](https://image.toast.com/aaaadh/real/2024/techblog/3%281%29.jpg)\r\r\n오픈 인프라 재단의 최고운영책임자(COO)인 Mark Collier의 키노트가 무척 인상 깊었는데요. 인프라 전반의 트렌드 4가지를 일목요연하고 간결하게 정리해 주었습니다.\r\r\n\r\r\n### Digital Sovereignty\r\r\n\r\r\n\r\r\n내 데이터가 어디에 저장되고 누가 접근 가능하며 어떤 법률의 지배를 받는지에 대한 관심이 커지고 중요한 사안이 되었는데요. 이는 개인에 국한되지 않고, 국가 기관 및 정부에게도 중요한 사안이 되었습니다.\r\r\n대표적인 예로 프랑스의 주요 은행들이 오픈 스택을 채택해 자신들의 데이터 위치와 접근 권한, 적용되는 법률을 직접 관리하고 있습니다. 이렇게 주요 기관들이 자신들의 데이터를 매우 독점적으로 처리하고 보유하고자하는 트렌드는 전 세계적으로 나타나고 있습니다.\r\r\n\r\r\n이 같은 트렌드는 하드웨어 영역에서도 나타나고 있는데요. RISC-V가 그 예입니다.\r\r\n\r\r\n> RISC-V는 2010년 UC 버클리에서 개발한 오픈소스 RISC(Reduced Instruction Set Computer) 명령어 세트 아키텍처입니다. RISC-V 아키텍처를 통해 설계자는 최종 애플리케이션에 맞게 프로세서를 맞춤화하고 설계할 수 있습니다.\r\r\n\r\r\n즉 현재는 기존에 사용하는 프로그램이나 하드웨어에 대해 영구적인 접근 권한을 갖고 통제하고 원하는 대로 사용하고 싶어 하는 산업 전반의 트렌드가 있다고 합니다. 이 같은 트렌드로 오픈 소스 및 오픈 테크놀로지는 그 어느 때보다 중요해졌다고 합니다.\r\r\n\r\r\n### License Changes\r\r\n\r\r\n\r\r\n* Terraform\r\r\n예상치 못한 라이선스 변경으로 시장에 악영향을 미쳤지만, 오픈소스가 이에 대한 해결책을 제시해 줄 수 있습니다. Terraform의 라이선스 변경으로 인해 오픈 소스 프로젝트인 Open Tofu가 등장하여 테라폼을 대체하는 역할을 수행해 사용자들에게 신뢰를 제공하고 있습니다.\r\r\n\r\r\n* VMware\r\r\nVMware의 라이선스가 변경됨에 따라 많은 사용자들이 VMware에서 OpenStack으로 마이그레이션에 대한 관심이 커지고 있습니다. 대표적으로 미국의 주요 자동차 보험사인 GEICO가 최근 VMware를 버리고 오픈스택으로 대규모 클라우드 인프라를 구축해 큰 주목을 받았다고 합니다. Mark Collier는 마이그레이션에 관한 백서를 행사 당일에 [QR](https://www.openstack.org/vmware-migration-to-openstack-white-paper)로 공개하기도 했습니다.\r\r\n\r\r\n### Security Concerns\r\r\n\r\r\n\r\r\n최근 운영 중인 컨테이너 이미지의 87%에 치명적이거나 심각도가 높은 취약점이 있다는 사실이 밝혀져 우려를 자아내고 있습니다. 이 문제를 해결하기 위한 방안으로 오픈 인프라 재단에서 주최하는 카타 컨테이너(Kata Container) 프로젝트가 큰 주목을 받고 있습니다. 카타 컨테이너는 컨테이너의 속도와 가상 머신의 보안을 결합한 경량 가상화를 제공함으로써 속도와 보안 사이의 균형을 제공합니다. 컨테이너 환경 보안에 효과적이라는 점에서 Microsoft Azure, NVIDIA, AWS 등 주요 기업들이 카타 컨테이너에 투자하고 지원하고 있습니다.\r\r\n\r\r\n### AI Redefining Infra\r\r\n\r\r\n\r\r\nAI에 대한 기업들의 관심이 이례적입니다. 너도 나도 할 것 없이 기업들은 GPU를 최대한 많이 확보해 방대한 규모로 자신의 데이터 센터에 구축하고 있습니다. 기업이 AI 용량 구축에 거대한 투자하고 있으며, 오픈스택이 AI 워크 로드를 지원하는 데 중요한 역할을 하고 있습니다.\r\r\n\r\r\n이렇게 디지털 주권, 라이선스 변경, 보안 문제, 인공지능과 같이 네 가지 주요 트렌드로 오픈 소스에 대한 관심과 투자가 그 어느 때보다도 활발하게 일어나고 있고 오픈 소스 커뮤니티의 성장을 이끌고 있다고 합니다.\r\r\n\r\r\n## Sessions\r\r\n\r\r\n오픈인프라 아시아 서밋 2024에는 다양한 주제에 대해 심도 있는 내용을 다루는 세션이 많았는데요. 저는 그중 NHN Cloud 인프라서비스개발랩 박성우 이사님이 발표하신 세션 **Openstack of NHN Cloud from a network perspective**을 통해 오픈스택의 실제 적용 사례와 오픈스택의 한계점을 어떻게 보완했는지를 배울 수 있었습니다. 아래는 세션 내용의 일부를 요약해 보았습니다.\r\r\n\r\r\n### 1. Openstack of NHN Cloud from a network perspective\r\r\n\r\r\n![4.jpg](https://image.toast.com/aaaadh/real/2024/techblog/4%281%29.jpg)\r\r\n\r\r\n>  [영상 보러 가기](https://www.youtube.com/watch?v=IgXJq8jmuJI&t=1s)\r\r\n\r\r\nNHN Cloud는 2015년에 OpenStack의 Neutron 모듈을 활용해 네트워크를 구축하고 서비스를 시작했습니다. 하지만 서비스 초기 단계에서는 Neutron 모듈의 기본 기능만으로는 NHN Cloud의 서비스들을 효율적이고 안정적으로 운영하는 데 한계가 있었다고 합니다. 이중화가 불가능하고 장애 조치 및 스케일업 기능이 지원되지 않았기 때문입니다. 이번 세션에서는 NHN Cloud가 이러한 문제를 어떻게 해결했는지에 대해 자세히 다뤘습니다.\r\r\n\r\r\nNeutron의 기본 구조는 컴퓨트 노드 안에 큐라우터와 OVS integration bridge, 그리고 그 사이에 위치한 리눅스 브릿지로 구성됩니다. 여기에 IP 테이블을 연결하여 보안 규칙(Security Rules)을 설정하게 됩니다. 하지만 이 구조는 보안 규칙이 많아질수록 코드 오류의 원인을 파악하고 문제를 분석하는 데 어려움을 겪게 되며 유지 보수에 큰 부담이 따랐다고 합니다. 더구나 리눅스 브릿지는 OSI 모델의 2계층에서만 동작하기 때문에, 라우팅이나 IP 주소를 기반으로 트래픽을 처리하는 데도 한계가 있었습니다.\r\r\n\r\r\n![5.png](https://image.toast.com/aaaadh/real/2024/techblog/5.png)\r\r\n\r\r\n이러한 문제를 해결하기 위해 NHN Cloud는 컴퓨트 노드에서 리눅스 브릿지와 큐라우터를 제거하고, OVS integration bridge로 대체하는 방식을 채택했습니다. 네트워크를 VxLAN마다 나누고 각 브릿지와 연결하는 방식으로 구성하여 더 효율적인 네트워크 구조를 구현했습니다. 또한, NVIDIA의 SR-IOV Representer를 OVS bridge와 연결해 I/O 성능을 대폭 개선한 점이 인상 깊었습니다.\r\r\n\r\r\n> SR-IOV는 하나의 물리적 PCI Express 장치를 여러 가상 머신이 동시에 사용할 수 있게 해주는 기술로, 가상화 환경에서 매우 유용한 기술입니다.\r\r\n\r\r\n앞서 컴퓨트 노드에서 큐라우터를 제거했다고 했는데요. 이는 큐라우터의 한계를 극복하기 위한 조치로 랙 상단으로 이동시켰습니다. 즉, 각 랙이 하이퍼바이저처럼 작동하게 되어 컴퓨트 노드의 구조가 단순화되고, 최대 효율을 추구할 수 있었습니다.\r\r\n\r\r\n하지만 이러한 구조에서는 모든 트래픽이 랙 상단의 라우터로 집중되는 문제가 발생했습니다. 이를 해결하기 위해 NHN Cloud는 vSwitch를 개발했으며, 이 vSwitch는 5mpps(초당 500만 패킷)의 뛰어난 처리 속도를 자랑합니다.\r\r\n\r\r\n또한, VLAN에서 VxLAN으로 전환한 이유도 흥미로웠는데, 이는 고객 수가 증가함에 따라 퍼블릭 환경에서 여러 VPC(Virtual Private Cloud)를 생성해야 했기 때문입니다.\r\r\n\r\r\n### 보안과 안정성\r\r\n\r\r\n\r\r\n보안과 안정성 측면에서도 다양한 개선이 이루어졌습니다. 기본적으로 Neutron이 제공하는 Security Groups와 함께 Network ACL을 구성하여, 서버가 클라이언트 상태 정보를 저장하지 않아도 통신할 수 있는 환경을 구축했습니다. 또한, Internet Gateway 없이도 원격 호스트와 통신할 수 있도록 VPN Gateway를 연결해 네트워크 통신의 유연성을 강화했습니다.\r\r\n\r\r\n![6.png](https://image.toast.com/aaaadh/real/2024/techblog/6.png)\r\r\n\r\r\nNHN Cloud는 2015년 서비스 시작 이후, OpenStack Neutron에 다양한 기능을 추가하기 위해 여러 플러그인과 자체 개발한 에이전트들을 도입해왔는데요. 세션을 통해 NHN Cloud가 기존의 네트워크 문제를 혁신적으로 해결하고, 서비스 안정성과 보안을 동시에 강화한 점을 직접 확인할 수 있었습니다. 동시에 클라우드 네트워크 관리의 복잡성을 체감할 수 있었습니다.\r\r\n\r\r\n\r\r\n\r\r\n### 2. Bridging the Gap Between Community and Contributing Orgs\r\r\n\r\r\n![7.jpg](https://image.toast.com/aaaadh/real/2024/techblog/7.jpg)\r\r\n\r\r\n강의 형태로 진행되는 세션이 아닌 참석자들과 함께 자유롭게 토의하는 포럼 형태의 세션도 제공되었습니다. 그중 하나인 **Bridging the Gap Between Community and Contributing Orgs**은 오픈 소스 커뮤니티를 더욱 활성화하기 위해 자유롭게 의견을 공유하는 자리였습니다. 주요 논의는 신규 기여자와 기존 기여자가 모두를 위한 커뮤니케이션을 활성화하고 기여자 경험을 개선하기 위한 방안을 논의하는 세션이었습니다.\r\r\n\r\r\n다양한 국가의 수많은 사람들이 오픈인프라 프로젝트에 기여하고 있는 만큼 커뮤니케이션의 한계를 극복하고 다양성을 높이고자하는 열정이 느껴지는 세션이었습니다.\r\r\n\r\r\n## OpenStack’s Role in the Future\r\r\n\r\r\n\r\r\n오픈인프라 서밋 아시아 2024는 클라우드 산업의 혁신을 선도하는 오픈소스 커뮤니티의 중요성을 다시 한 번 강조한 행사였습니다.\r\r\n\r\r\n특히 VMware에서 오픈스택으로의 마이그레이션이 주목을 받으면서 확장 가능하고, 안전하며, 비용 효율적인 솔루션으로 오픈스택을 도입하려는 기업들이 전 세계적으로 많다는 것을 느낄 수 있었습니다.\r\r\n\r\r\n또한, AI와 같은 고성능 컴퓨팅을 위한 지속 가능한 인프라에 대한 요구가 커지고 있는 상황에서, 오픈인프라 커뮤니티는 혁신적이고 획기적인 솔루션으로 이러한 글로벌 과제에 대응할 준비가 충분히 갖추어져 있음을 확인할 수 있었습니다. 이번 서밋을 통해 오픈소스 기반 인프라의 미래와 지속 가능한 기술 개발에 대한 기대감이 더욱 커졌습니다.",
        "isoDate": "2024-11-11T02:16:45.000Z"
      }
    ]
  },
  {
    "name": "ZUM 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "SK Planet",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Spoqa tech blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "팀 왈도 번역팀",
    "category": "게임",
    "posts": []
  },
  {
    "name": "근원님",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황의윤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "호돌맨",
    "category": "개인",
    "posts": []
  },
  {
    "name": "박우빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "문다영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "유수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "안건주",
    "category": "개인",
    "posts": []
  },
  {
    "name": "손현호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "STARTUP BIBLE",
    "category": "개인",
    "posts": [
      {
        "creator": "Kihong Bae",
        "title": "전문지식과 경험",
        "link": "https://www.thestartupbible.com/2024/11/domain-expertise-and-experience.html",
        "pubDate": "Wed, 13 Nov 2024 21:43:00 +0000",
        "content:encodedSnippet": "흔히 성공적인 VC 투자를 하기 위해서는 투자자가 ‘pattern recognition’에 능해야 한다고 한다. 그동안의 투자 경험을 기반으로 어떤 창업가와 어떤 사업이 잘됐는지, 반대로 어떤 창업가와 어떤 사업이 잘 안됐는지, 이 모든 과거의 경험에서 패턴을 찾을 수 있다면, 이 패턴을 잘 분석해서 미래의 투자의 성공 확률을 높일 수 있다는 의미다. 아마도 어느 정도 투자를 한 VC라면, 대부분 자신만의 이런 패턴 분석 능력이 있을 것이고, 새로운 창업가와 사업을 볼 때 지속적으로 본인만의 패턴 DB를 참고해서 크고 작은 결정을 할 것이다.\n나도 투자를 시작했을 때, 유명한 VC나 내가 잘 아는 선배 VC들이 이런 패턴을 잘 찾아야 한다고 이야기하면, 그 말에 많이 동의했고, 이후 몇 년 동안 나도 투자하면서 경험한 실패와 성공을 바탕으로 성공 확률이 높은 창업가에 대한 패턴을 매핑하기 시작했다. 그런데 요샌 이 pattern recognition이 쓸모없다고 생각하고 있다. 지나고 나서 보면 “성공하는 창업가들은 모두 다 이런 패턴이 있었죠.”라고 끼워서 맞추는 이야기는 할 수 있지만, 이런 과거의 패턴을 기반으로 미래의 성공을 예측하는 건 과학적으로 접근해도 힘들다는 게 내 생각이다. 우린 수학적으로는 절대로 예측할 수 없는, 즉, 특정한 패턴을 따르지 않는, 그리고 잠재 능력의 한계가 존재하지 않는 사람(=창업가)에게 투자하기 때문에 그 어떤 과거의 패턴도 여기에 적용할 수 없기 때문이다.\n이런 패턴 중 대표적인 게 바로 창업가의 전문 지식과 직장 경험이다.\n예를 들면, 대부분의 VC는 어려운 AI 사업을 하는 창업가라면 이분이 컴퓨터공학이나 다른 공학 분야의 석사나 박사 학위가 있으면 남들보다 더 뛰어날 것이라는 생각을 할 것이다. 국내 대학에서 경영학과 학부를 졸업한 창업가와 미국 top 대학에서 컴퓨터 공학 박사 학위를 받은 창업가가 둘 다 AI 관련 스타트업을 하면, 대부분의 VC는 후자의 창업가에게 투자할 확률이 더 높다. 이게 일반적인 VC들의 패턴 인식 프로세스이다.\n모빌리티 분야에서 창업한 두 스타트업이 있는데, 한 회사는 현대자동차에서 오랫동안 관련 사업을 했던 분이 창업했고, 다른 스타트업은 완전히 상관없는 직장에서 일했던 분이 창업하면, 역시나 현대자동차 출신 창업가에 더 높은 점수를 줄 것이다.\n\n\n\n\n나는 그동안 정말 여러 창업가와 회사를 만나면서, 창업가의 학력과 학벌, 그리고 과거 직장 경험은 이 분이 새로 하려고 하는 사업의 성공 여부와는 정말 아무 상관이 없다는 패턴을 발견했다. 오히려 특정 분야에 대한 학문적인 백그라운드(=학력, 학벌)나 그 분야에서의 직장 경험이 없는 창업가들이 훨씬 더 신선한 시각으로 사업을 바라보고, 그 분야에 존재하는 문제점들을 완전히 새로운 방식으로 접근하는 걸 자주 봤다. 이들은 특정 분야에 대해 너무 많은 공부를 하거나, 너무 많은 경험이 있는 분들의 고정관념에서 벗어날 수 있기 때문에, 그동안 그 누구도 생각 못 했던 파괴적이고 참신한 문제 해결 방법을 시도할 수 있다. 물론, 잘 모르기 때문에 대부분의 방법은 실패하지만, 계속 시도하다 보면 엄청난 솔루션을 찾는 경우도 있고, 이러면 정말 큰 사업을 만들 수 있다.\n내가 자주 언급하는 건데, 특정 분야의 전문 지식과 경험이 너무 많으면, “원래 그건 안 돼.” , “내가 오래전부터 해봤는데, 그건 안 되는 거야.” 등의 편견이 마음속에 자리 잡고 있지만, 완전히 백지에서 문제를 해결하려고 하는 창업가들은 “방법이 없을까?” , “가능할 것 같아. 방법을 찾아보자.” , “원래 안 되는 건 없어. 왜 꼭 저렇게 해야 할까?” 등의 생각으로 뭐든지 새로운 시도를 하기 때문에 위에서 말한 일반적인 패턴 인식 레이다에 잘 안 걸린다.\n토스의 이승건 대표는 치과대학을 졸업했고, 실제로 의사 생활까지 좀 했다. 금융업을 학교에서 공부한 적도 없고, 관련 업계에서 일 한 경험도 없다. 하지만, 이 분과의 대화에 대한 내 개인적인 기억, 그리고 이승건 대표를 잘 아는 다른 분들의 기억에 의하면, 토스를 창업했을 때 대한민국 그 어떤 금융 전문가보다 이 시장의 생리와 문제점을 잘 파악하고 있었고, 아주 새로운 방식으로 금융산업의 문제점들을 해결하는 시도를 했다.\n얼마집이라는 모바일앱을 만드는 우리 투자사 한국프롭테크의 송지연 대표도 비슷하다. 이분은 원래 부동산이나 재건축/재개발과는 완전히 상관없는 분야에서 일했고, 학교에서 경제학을 공부했다. 그런데 부모님의 아파트가 재건축을 추진하는 과정에서 여러 가지 문제점을 경험했고, 시장의 현실과 앞으로 시장이 가야 할 미래 사이에 너무나 큰 간극이 존재한다는 걸 발견하고 이걸 직접 해결해 보기로 결심해서 창업했다. 그런데 우리가 봤을 땐, 이 시장에서 수십 년 동안 일한 직장인들이나 도시개발이나 부동산학과 교수들보다 훨씬 더 이 시장의 문제에 대해서 잘 이해하고 있고, 이걸 기술로 어떻게 해결할 수 있는지 매우 구체적인 (아직 증명되지 않은)해답을 갖고 있다.\n과연 특정 분야의 학업적 지식과 경험이 그렇게 중요한가? 내가 봤을 땐 별로 안 중요하다. 학업적 지식과 경험보다 더 중요한 건 그 시장의 현실에 대한 정확한 이해와 전문성인데, 이건 인터넷 검색과 발품을 팔면 누구나 다 획득 가능하다. 하지만 더 중요한 건, 문제를 해결하겠다는 의지다. 얼마나 집요하게 이 문제를 붙잡고, 얼마나 깊게 파고 들어갈 준비가 되어 있는지, 그리고 얼마나 절박하게 내가 이 싸움에서 이기고 싶은가의 문제이다. 결국, 결승전에서 이기는 건 가장 실력이 좋은 선수가 아니라 가장 간절하게 승리하고 싶어 하는 선수이기 때문이다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2024/11/domain-expertise-and-experience.html#respond",
        "content": "흔히 성공적인 VC 투자를 하기 위해서는 투자자가 ‘pattern recognition’에 능해야 한다고 한다. 그동안의 투자 경험을 기반으로 어떤 창업가와 어떤 사업이 잘됐는지, 반대로 어떤 창업가와 어떤 사업이 잘 안됐는지, 이 모든 과거의 경험에서 패턴을 찾을 수 있다면, 이 패턴을 잘 분석해서 미래의 투자의 성공 확률을 높일 수 있다는 의미다. 아마도 어느 정도 투자를 한 VC라면, 대부분(...)",
        "contentSnippet": "흔히 성공적인 VC 투자를 하기 위해서는 투자자가 ‘pattern recognition’에 능해야 한다고 한다. 그동안의 투자 경험을 기반으로 어떤 창업가와 어떤 사업이 잘됐는지, 반대로 어떤 창업가와 어떤 사업이 잘 안됐는지, 이 모든 과거의 경험에서 패턴을 찾을 수 있다면, 이 패턴을 잘 분석해서 미래의 투자의 성공 확률을 높일 수 있다는 의미다. 아마도 어느 정도 투자를 한 VC라면, 대부분(...)",
        "guid": "https://www.thestartupbible.com/?p=9266",
        "categories": [
          "Uncategorized",
          "failure",
          "FoundersAtWork",
          "inspiring",
          "mobile",
          "Strong",
          "technology",
          "vc"
        ],
        "isoDate": "2024-11-13T21:43:00.000Z"
      },
      {
        "creator": "Kihong Bae",
        "title": "해자(垓字)는 없다",
        "link": "https://www.thestartupbible.com/2024/11/no-such-thing-as-a-moat-in-consumer-brands.html",
        "pubDate": "Sun, 10 Nov 2024 21:34:00 +0000",
        "content:encodedSnippet": "요새 VC들이 소비재 쪽의 사업은 상당히 보수적으로 검토하거나 아예 투자하지 않는 것 같은데, 우린 이런 분위기와는 상관없이 계속 이 분야에서 재미있는 일을 하고 있는 창업가들을 만나고, 투자하고 있다. 최근에도 생필품, 의류, 그리고 음식 분야에서 사업하고 있는 여러 창업가를 만났다. 자체 브랜드를 만들어서 직접 고객에게 자사몰, 그리고 다른 온라인 플랫폼이나 오프라인 유통 채널을 통해서 판매하고 있는데, 대부분 내가 이 글에서 말했던 그런 어려움을 사업의 단계와는 상관없이 직접 경험하고 있는 것 같았다.\n이분들과 이야기를 하면, 항상 등장하는 주재가 ‘해자(垓字)’이다. 사업의 종류에 상관없이 VC들이 창업가들에게 물어보는 게 그 사업만의 차별점, 진입장벽, 보호 장벽, 해자 관련 질문인데, “지금까지 비슷한 사업을 여러 번 검토했는데, 모두 다 비슷한 방식으로 비슷한 비즈니스 모델로 같은 시장에서 경쟁하는 것 같네요. 우리가 다른 경쟁사보다 더 잘할 수 있는, 우리만의 해자가 있나요?” , “이 사업이 잘되면 분명히 대기업도 같은 사업을 할 텐데요, 그 상황에서 우리가 이길 수 있는 우리만의 해자가 있을까요?”와 같은 유의 질문이다. 솔직히 이 질문에 대한 정답은 없다. 만약, 이 질문에 대한 답변이 투자에 결정적인 영향을 미친다면, 이런 질문을 한 VC는 결국엔 이 사업에 투자하지 않겠다는 의미다. 비슷한 분야에서 경쟁하는 회사들이 투자자를 설득할 만한 명확하고 논리적인 해자를 갖추긴 어렵고 – 특히, 이제 막 시작하는 초기 스타트업은 – 대기업이 이 분야에 진출했을 때 다윗 같은 스타트업이 골리앗 같은 대기업을 이길만한 해자는 없기 때문이다. 아니, 이론적으로 명확하고 논리적인 상상 속의 해자가 있더라도, 아마도 투자자는 이 말을 믿지 않을 것이다.\n특히나, 기술력이 뒷받침되는 소프트웨어 회사가 아니라, 공장에서 뭔가를 만들어서 판매하는 브랜드나 D2C 회사들은 이런 해자를 만드는 건 거의 불가능하다. 우리도 이 분야에서 사업하는 한국과 미국 회사에 꽤 많이 투자하면서 이 힘든 현실을 간접적으로 경험했고, 나는 몇 년 전부터 이런 현실을 인정하기 시작했다. 그리고, 이제 브랜드를 만드는 사업 분야에서 해자라는 건 존재하지 않는다는 걸 잘 받아들이고 있고, 아예 이 분야에서 사업하는 창업가들에겐 본인이 하는 사업의 해자는 무엇인지라는 질문을 하지 않는다.\n최근에 우리가 투자한 이런 D2C/브랜드 사업들을 보자: 제주 귤을 원료로 주스와 같은 다양한 시트러스 제품을 만드는 귤메달; 파워레이드나 게토레이드랑 같은 카테고리에 속한 기능성 스포츠 드링크 얼티밋포텐셜을 만드는 어센트스포츠; 그리고 반려동물을 위한 영양제 페노비스를 만드는 노즈워크. 모두 다 잘하고 있는 스타트업이지만, 다른 스타트업도 충분히 이 분야로 들어올 수 있고, 돈/시간/인력이 압도적으로 많은 대기업도 진출할 수 있는 매력적이고 규모가 나오는 시장이다. 이런 무시무시한 회사들이 우리 투자사들과 경쟁하기 시작하면 우리 창업가들은 어떤 해자를 만들면서 이길 수 있을까?\n정답은, 이들이 구축할 수 있는 해자는 없다. 이 치열한 분야에서 이기기 위해선 수단과 방법을 가리지 말고 모든 합법적인 방법을 동원해야 하고, 되도록 많은 소비자들의 눈에 노출되고, 그냥 무조건 많이 팔아서 매출 잘 만들어야 한다. 어떻게 많이 팔고, 어떻게 매출을 많이 만들 수 있을까? 이 또한 정답도 없고, 이를 위한 해자라는 것도 없다. 그냥 좋은 제품 만들고, 최대한 많은 채널을 통해서 유통하고, 동시에 마케팅도 잘 해야 한다. 나중에, 아주 나중에, 혹시나 자체 공장을 만들거나 우리 제품을 OEM 제조하는 공장을 인수해서 생산의 전 과정을 수직통합 할 수 있다면, 어쩌면 이건 품질관리, 공정관리, 수량 조정, 가격 조정 면에서 우리에게 해자가 될 수도 있다. 그런데 자체 공장에 대해서 고민하는 단계까지 왔다면, 이미 우린 시장에서 알아주고 인정해 주는 브랜드가 됐을 것이고, 여기에서 말한 대로, 특정 분야에서 가장 먼저 떠오르는 브랜드가 됐다면, 이 자체가 엄청난 해자가 될 수 있다.\n하지만, 누구나 다 아는 그 강력한 브랜드가 되기 전까지는, 해자라는 건 존재하지 않으니, 자꾸 우리만의 차별점이나 해자를 만들기 위해서 고민하지 말고, 그 시간에 그냥 물건 하나라도 더 팔아라. 대신, 남들보다 더 빠르게 움직이고, 너무 깊이 생각하기보단 get things done 전략으로 실행에 집중해라.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2024/11/no-such-thing-as-a-moat-in-consumer-brands.html#comments",
        "content": "요새 VC들이 소비재 쪽의 사업은 상당히 보수적으로 검토하거나 아예 투자하지 않는 것 같은데, 우린 이런 분위기와는 상관없이 계속 이 분야에서 재미있는 일을 하고 있는 창업가들을 만나고, 투자하고 있다. 최근에도 생필품, 의류, 그리고 음식 분야에서 사업하고 있는 여러 창업가를 만났다. 자체 브랜드를 만들어서 직접 고객에게 자사몰, 그리고 다른 온라인 플랫폼이나 오프라인 유통 채널을 통해서 판매하고 있는데,(...)",
        "contentSnippet": "요새 VC들이 소비재 쪽의 사업은 상당히 보수적으로 검토하거나 아예 투자하지 않는 것 같은데, 우린 이런 분위기와는 상관없이 계속 이 분야에서 재미있는 일을 하고 있는 창업가들을 만나고, 투자하고 있다. 최근에도 생필품, 의류, 그리고 음식 분야에서 사업하고 있는 여러 창업가를 만났다. 자체 브랜드를 만들어서 직접 고객에게 자사몰, 그리고 다른 온라인 플랫폼이나 오프라인 유통 채널을 통해서 판매하고 있는데,(...)",
        "guid": "https://www.thestartupbible.com/?p=9262",
        "categories": [
          "Uncategorized",
          "B2C",
          "brand",
          "consumer",
          "FoundersAtWork",
          "marketing",
          "strategy",
          "Strong",
          "vc"
        ],
        "isoDate": "2024-11-10T21:34:00.000Z"
      }
    ]
  },
  {
    "name": "Build a Great Product",
    "category": "개인",
    "posts": []
  },
  {
    "name": "지금 써보러 갑니다",
    "category": "개인",
    "posts": []
  },
  {
    "name": "매거진 입맛",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "요즘 IT",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "쿠팡 엔지니어링",
    "category": "기업",
    "posts": []
  },
  {
    "name": "지마켓 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "리멤버 (드라마 앤 컴퍼니)",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Kimchi hill",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Hudi.blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "토스",
    "category": "기업",
    "posts": [
      {
        "title": "금테크의 모든 것: 왜 지금 금값이 오르고 있을까?",
        "link": "https://blog.toss.im/article/economic-terms-36-gold-investing",
        "pubDate": "Thu, 14 Nov 2024 02:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-8atqhb{width:100%;}.css-1c1qox8{font-size:30px;letter-spacing:0em;line-height:1.55;font-weight:bold;color:var(--adaptiveGrey900);margin:40px 0 4px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-p4abj2{display:contents;line-height:1.55;}.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}🔖 이번 주 경제 용어\n금테크\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}이번 주 경제 용어는 글로벌 경제를 파악하기 위해 필요한 정보예요.\n\n.css-1pgssrp{max-width:100%;border-radius:16px;}\n금을 활용한 재테크를 의미해요.\n\n\n최근 초대받은 돌잔치에 돌반지를 선물할까 말까 고민해보셨나요? 올해 금값이 계속 오르더니 1분기에는 한 돈짜리 돌반지가 40만 원을 기록했고, 10월 말 기준으로는 60만 원까지 치솟았습니다.\n금값이 부담스러워 돌반지도 이제는 가족이나 가까운 친구에게조차 쉽게 선물할 수 있는 선택지가 아니게 된 것 같아요.\n최근 금 가격은 역대 최고 시세를 경신했습니다. 한국금거래소에 따르면 금 1돈당 가격이 10월 30일 기준 약 52만 원에 거래되었어요. (매수 기준) 11월 중순 기준 가격이 조금 내려와서 40만 원 중반대이고요.\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}* 금을 매수할 때 부가적으로 붙는 돈이 조금씩 달라요. 현물 금은 부가세 10%, 반지나 목걸이 같은 장신구는 세공비가 붙습니다.\n금값의 상승세에는 여러 요인이 있습니다. 그중 하나는 .css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}미국 연준의 금리 인하입니다. 미 연방준비제도(Fed)가 기준금리를 0.5%p 내리면서 달러 가치가 약세를 보였죠. 달러 약세는 안전 자산인 금의 수요를 증가시키며 금값을 끌어올렸습니다.\n또한 미국 대선의 불안정과 이스라엘-이란 간의 갈등이 추가되며 사람들의 불안감이 점점 커지고 있습니다. 역사가 증명하듯, 불안정한 국제 정세는 금값을 끌어올리는 핵심 요소입니다. 몇 가지 주요 사건을 살펴볼까요.\n1970년대 중동 지역의 지정학적 불안정성으로 유가가 급등하면서, 오일 쇼크가 두 차례(1973년, 1979년) 발생했는데요. 물가가 치솟자 안전자산인 금에 대한 수요가 급증하면서 금값이 크게 상승했습니다.\n2008년 글로벌 금융 위기 때도 마찬가지로, 전통 금융 시스템에 대한 신뢰가 흔들리면서 금에 대한 수요가 크게 증가했어요. 장기적으로 금 가격이 상승세를 보였었죠.\n2020년 코로나19 때도 팬데믹이 길어지면서 경제 침체기가 이어졌습니다. 경제 불확실성이 높아지면서 시장에 돈이 돌지 않자 당시 각국 중앙은행 및 정부는 막대한 규모의 유동성을 시장에 푸는 정책을 펼쳤어요. 경제를 안정시키기 위함이었죠. 금리를 사상 최저 수준으로 낮추고, 대규모 자산 매입 프로그램으로 시장에 돈을 풀었습니다. 이러한 경제 흐름은 인플레이션을 불러올 수 있다는 우려를 동반합니다. 통화 가치가 떨어지고, 물가가 상승할 가능성이 높아지죠. 이에 대비해 일부 투자자들은 안전자산 금에 대한 투자를 늘리기 시작했어요.\n결론적으로 올해 가파른 금값 상승 배경에는 ‘글로벌 경제의 불확실성’이 자리하고 있는 것으로 보입니다. 불확실성이 커질수록 금은 안전자산으로서의 가치를 발휘하며 수요가 늘어날 수밖에 없기 때문이에요.\n.css-nv7vyi{margin:24px 0 8px;padding:16px 40px 32px;border-radius:16px;background-color:var(--adaptiveGrey100);}.css-123co55{font-size:19px;letter-spacing:0em;line-height:1.6;margin:24px 0 0;font-weight:400;color:var(--adaptiveGrey900);background-color:transparent;}\n🏅 금테크 기본 상식\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n금 1돈의 중량은 3.75g입니다.\n국제 금 거래는 온스(oz)로 31.11g입니다.\n국내 금 시세는 환율과 국내 수급에 따라 차이가 있을 수 있습니다.\n금은 배당과 이자가 없고 다른 자산 대비 수익률이 낮은 편이므로, 장기적으로는 실물 금 외의 다양한 금 투자 방식도 고려해볼 필요가 있습니다.\n\n\n\n\n.css-2yhypk{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);font-style:italic;-webkit-text-decoration:underline!important;text-decoration:underline!important;}\"테슬라 뺨치는 투자\"…함평 '황금박쥐상' 몸값 27억→231억 '훌쩍'\n(서울경제 2024.10.28)\n전남 함평에서 대표 상징물로 꼽히는 '황금박쥐상'이 금값 상승으로 몸값이 10배 가까이 뛰었다.\n28일 한국표준금거래소에 따르면 26일 구매기준 순금은 1g당 13만9733원으로 1년전(9만7866원)보다 42% 올랐다. 은도 같은 기간 53% 오르며 1g당 1741원에 거래됐다.\n이에 따라 2008년 제작한 전남 함평의 황금박쥐상 가격은 231억원으로 뛰어올랐다.\n황금박쥐상은 천연기념물이자 멸종위기 1급인 황금박쥐 162마리가 1999년 함평에서 발견된 것으로 기념해 제작됐다.\n높이 2.18m, 폭 1.5m의 황금박쥐상은 제작하는 데 순금 162kg, 은 281kg이 사용됐다. 당시 27억원의 세금이 투입돼 '혈세 낭비'란 지적이 잇따랐으나 이젠 10배 가까운 수익을 눈앞에 두면서 '테슬라·엔비디아'에 비견되는 성공적인 투자란 평가가 나오고 있다.\n아울러 황금박쥐상을 만들고 남은 금 19.31kg, 은 8.94kg, 보석 0.19kg 등을 활용해 2010년 제작한 조형물 '오복포란'의 가격도 26억 9824만원으로 부쩍 뛰었다. (중략)\n\n\n2008년, 함평군에서 황금박쥐상을 만들 때 과도한 예산 낭비라고 논란이 일었습니다. 그런데 금값이 상승하며 의도치 않게 ‘지자체 금테크’ 사례로 이목이 집중되고 있어요.\n재밌게도 황금의 기운을 받으려는 관광객들이 황금박쥐상을 보러 오면서 함평군의 다른 관광지까지 둘러보게 되고, 이제 황금박쥐상이 지역 경제에 크게 기여하고 있다고 합니다.\n여기서 하나 배울 수 있는 건, ‘금은 생각보다 훨씬 쏠쏠한 투자 대상이 될 수 있다’는 겁니다. 어쩌면 우리도 이미 알게 모르게 금테크를 시작했을지도 모릅니다. 바로 첫돌에 받았던 돌반지가 실물 금 투자의 시작이었던 셈이지요.\n돌반지로 시작된 금테크, 이제는 좀 더 다양한 방법으로 확장해 볼까요? 금은방 거래에서부터 골드뱅킹, 금 펀드·ETF, 그리고 KRX 금시장에 이르기까지 금 투자 방법은 여러 가지가 있습니다. \n금테크에 관심을 가지고 투자를 시작해보고 싶은 분들을 위해, 추천 목록을 정리해봤어요. 꼼꼼히 살펴보시고 내게 맞는 방법을 선택하시길 바랍니다.\n\n🏅 금테크 추천 목록\n\n실물 금을 보유하고 싶고, 실용적으로 투자하고 싶다면 👉 금은방\n복잡한건 싫고, 금테크 투자에 있어 편의성을 최우선으로 생각한다면 👉 골드뱅킹\n증권 거래가 익숙하고, 환금성(자산의 현금화)을 중요하게 여긴다면 👉 금 펀드·ETF\n금 시세 변동에 익숙하고 유연하게 투자할 준비가 되어 있으며, 수익률이 최우선이라면 👉 KRX 금 시장\n\n\n금은방 거래: 실물 금을 직접 구매하는 가장 일반적인 방법입니다. 골드바나 금반지·금목걸이 같은 장신구 형태로도 구입할 수 있습니다.\n골드바의 경우 실물 금이기 때문에, 구입할 때 부가가치세 10%가 붙고 수수료도 발생합니다. 투자로서는 수익률이 떨어질 수 있습니다. 장신구는 세금이나 수수료는 없지만, 세공비가 추가됩니다. 구입할 때 같은 무게의 순금보다 비쌀 수 있어요.\n골드뱅킹: 은행에서 금을 0.01g 단위로 저축할 수 있는 방식입니다. 실물 금을 직접 보유하지 않고, 예금 통장에 금액을 입력해 주식처럼 관리할 수 있는 것이 특징입니다.\n다만, 투자 수익에는 배당소득세 15.4%와 수수료가 부과됩니다. 실물 금으로 인출 시 부가가치세 10%가 추가되고요.\n금 펀드·ETF: 실물 금 대신, 금 관련 펀드나 ETF 상품을 통해 투자하는 방법입니다.\n금 펀드는 전문 자산운용사가 금에 투자해 수익을 배분합니다. 투자 수익률에 따른 운용 보수와 수수료가 부과되고, 팔 때 배당소득세 15.4%가 발생해요.\n금 ETF는 주식처럼 증권사에서 거래할 수 있습니다. 1주 단위로 거래할 수 있어요. 국내 주식 수수료와 운용 보수가 발생하고, 금 펀드와 마찬가지로 팔 때 배당소득세 15.4%가 매겨져요.\n유의해야 할 점은 금 펀드·ETF는 증권 거래를 통해 투자하는 형태라, 실물 금으로 인출할 수가 없다는 것입니다. 실물 금을 금고 등에 직접 보관해야 하는 수고로움은 덜 수 있지만, 투자한 금액을 실물 금으로 바꿀 수는 없기 때문에 이런 특징을 미리 알아두고 투자 결정을 하는 것이 좋겠습니다.\n한국거래소(KRX) 금 시장: 한국거래소의 금을 주식처럼 증권앱에서 1g 단위로 매매할 수 있는 시장입니다.\n비교적 낮은 거래 수수료와 비과세 혜택이 있어, 수익률 측면에서 가장 효과적인 금 투자 방식으로 꼽힙니다. 실물 금으로도 인출할 수 있고요. 다만, 실물 금으로 인출할 때에는 부가가치세 10%가 부과됩니다.\n거래소 금시장은 금 시세 변동에 따라 유연하게 투자할 수 있기 때문에, 많은 금테크 투자자들에게 인기를 얻고 있습니다.\n\n\n\n순금: 24K 금으로 순도 99.9% 이상의 순수한 금을 말해요. 금의 순도는 'K' (Karat) 단위이며, 순도가 높을수록 금의 함량이 높아요. 장신구에서 많이 볼 수 있는 18K는 순도 75%의 금, 14K는 순도 58.5%의 금을 말한답니다.\n골드바: 금을 덩어리 형태로 가공한 투자용 금이에요. 세공비가 붙지 않아 상대적으로 저렴하게 순금에 투자할 수 있는 방식입니다. 100g (약 1,400만원),1kg(약 1억 4,000만원) 골드바가 가장 많이 거래되는 단위예요\n귀금속: 금, 은, 백금 등 희소성과 가치가 높은 금속들이에요. 주로 투자와 장신구로 사용되며, 금과 은은 안전자산으로 투자자들에게 인기가 높은 편입니다.\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 금혜원 Graphic 조수희 이동건",
        "content": "순금에서 금 ETF까지, 다양한 금테크 투자 방식과 장단점도 알려드릴게요.",
        "contentSnippet": "순금에서 금 ETF까지, 다양한 금테크 투자 방식과 장단점도 알려드릴게요.",
        "guid": "https://blog.toss.im/article/economic-terms-36-gold-investing",
        "isoDate": "2024-11-14T02:00:00.000Z"
      },
      {
        "title": "토스, 3분기 연결 영업수익 5,021억 원",
        "link": "https://blog.toss.im/article/2024-3Q",
        "pubDate": "Thu, 14 Nov 2024 00:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1kxrhf3{white-space:pre-wrap;}토스 서비스 전반에 걸쳐 고른 성장… 3분기 연결 누적 영업수익 1조4천억 원 돌파\n3분기 연결 영업이익 109억 원, 연결 당기순이익 39억 원 넘어서며 흑자 전환\n\n\n모바일 금융 서비스 토스를 운영하는 비바리퍼블리카(이하 토스)가 3분기 연결 영업수익 5,021억 원을 기록, 전년 동기 대비 47.5% 성장하며 분기 최대 실적을 달성했다고 14일 밝혔다.\n연결 누적 영업수익은 1조4,163억 원을 기록했다. 이는 2023년 연결 누적 영업수익 1조3,707억 원을 상회하는 수치다. 토스의 광고, 간편결제(토스페이), 대출중개 등 컨슈머 서비스 전반이 고르게 성장한 결과다. 특히 1,910만 월간 활성 이용자 수(Monthly Active Users, MAU)를 바탕으로 한 광고 서비스의 빠른 성장세가 주효했다.\n3분기 연결 영업이익은 109억 원, 연결 당기순이익은 39억 원으로 분기 기준 흑자 전환에도 성공했다. 이는 토스증권 등 계열사의 실적 호조가 일조했다. 토스증권은 해외 주식 위탁매매 부문 성장이 전체 실적 개선을 견인하며 같은 기간 296억 원의 영업이익을 기록했다.\n토스 이승건 대표는 “토스 서비스의 고른 성장 및 계열사 및 관계사들의 실적 호조로 분기 최대 매출 달성과 더불어 분기 영업이익 및 당기순이익 흑자를 기록했다”라며 “매출과 수익성을 모두 확보하는 플랫폼 본연의 건강한 성장을 이어갈 수 있도록 노력하겠다”라고 전했다.",
        "content": "분기 최대 실적 기록",
        "contentSnippet": "분기 최대 실적 기록",
        "guid": "https://blog.toss.im/article/2024-3Q",
        "isoDate": "2024-11-14T00:00:00.000Z"
      },
      {
        "title": "토스, 학생 대상 Apple 프로모션",
        "link": "https://blog.toss.im/article/APPLE-",
        "pubDate": "Thu, 14 Nov 2024 00:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}1995년~2010년생 대상 Apple 주요 제품 5종 할인 행사\n11월 14일부터 12월 28일까지 최대 17% 할인 혜택 제공\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n\n모바일 금융 서비스 ‘토스'를 운영하는 비바리퍼블리카(이하 ‘토스’)가 학생을 대상으로 Apple 제품 할인 프로모션을 진행한다고 14일 밝혔다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n1995년생~2010년생을 대상으로 하는 이번 프로모션에서는 △iPad 10세대 △iPad Air 11” M2 △Apple Pencil Pro △Magic Keyboard 등 Apple 인기 제품을 선보인다. MacBook Air(13 M2 모델)도 11월 중 할인 품목에 추가될 예정이다.\n행사 제품은 최대 17% 할인된 가격으로 토스 앱 및 오프라인 매장에서 구매할 수 있다. 토스 앱에서는 Apple 학생 전용관을 통해 토스페이로 결제하면 자동으로 할인이 적용된다. 프리스비, 이마트(일렉트로마트), 하이마트 등 오프라인 매장에서는 토스 앱 내 Apple 학생 전용관에서 다운로드한 바코드를 제시하면 된다.\n중고등학생은 별도 인증없이 할인 적용 가능하고 대학생(만 20세~29세)은 이메일로 학생 인증 후 프로모션 혜택을 받을 수 있다. 행사 첫날인 11월 14일 18시부터 상품 구매 가능하며, 12월 28일까지 프로모션이 진행된다.",
        "content": "최대 17% 제품 할인",
        "contentSnippet": "최대 17% 제품 할인",
        "guid": "https://blog.toss.im/article/APPLE-",
        "isoDate": "2024-11-14T00:00:00.000Z"
      },
      {
        "title": "로제와 브루노 마스의 ⟨APT.⟩는 얼마를 벌었을까?",
        "link": "https://blog.toss.im/article/fandustry-03",
        "pubDate": "Tue, 12 Nov 2024 00:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}아파트 아파트… 아파트 아파트…. 이 단어가 머리에서 나가질 않는다. 로제와 브루노 마스의 목소리도 너무 좋다. 친구들과 아파트 게임을 하며 술 마실 나이는 아니지만, 누가 아파트 아파트~ 라고 술 게임을 하자고 하면 당장 그다음 구절을 이어 부를 자신은 있다. 물론 아무도 그걸 원하진 않겠지만.\n2024년 10월 18일에 발매된 로제 & 브루노 마스의 ⟨APT.⟩가 계속 화제다. 여러모로 상징적인 순간을 보여주는 곡인데, 음악적 평가만큼 차트 기록도 매우 높다. 음악적 평가는 조금 뒤로 미루고 일단 차트 기록만 살펴보자.\n.css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}11월 3일 기준, ⟨APT.⟩는 아이튠즈, 스포티파이, 유튜브 글로벌 차트 1위를 차지하고 있다. 스포티파이의 누적 스트리밍은 1억 8,336만 9,499회, 유튜브에서는 2억 5,327만 1,907회다. 서비스별로 가장 많은 1위를 기록한 국가를 보면 인도네시아(아이튠즈 1위, 스포티파이 1위, 애플뮤직 1위, 유튜브 1위, 샤잠* 1위), 필리핀(아이튠즈 1위, 스포티파이 1위, 애플뮤직 1위, 유튜브 1위, 샤잠 1위), 호주(아이튠즈 1위, 스포티파이 1위, 유튜브 1위, 샤잠 1위), 대만(아이튠즈 1위, 스포티파이 1위, 애플뮤직 1위, 유튜브 1위), 일본(스포티파이 1위, 애플뮤직 1위, 샤잠 1위), 캐나다(스포티파이 1위, 유튜브 1위), 태국(애플뮤직 1위, 디저** 1위), 베트남(애플뮤직 1위, 유튜브 1위) 등이다. 한국은 애플뮤직과 샤잠에서 1위를 차지했다.\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}*노래를 들려주면 음원을 검색해 주는 플랫폼으로 2018년 애플이 인수했다. 2022년 월간 활성 사용자 수가 2억 2,500만 명이라고 발표했다.\n**Deezer. 프랑스 온라인 음악 스트리밍 서비스.\n이 정도의 결과라면 수익도 궁금하다. 음원 스트리밍에서의 수입은 여러 저작권이 더해진 총매출로, 국가별로 항목이 조금씩 다르다. 미국을 기준으로 보자면 크게 Sound Recording, Mechanical, Performance 항목을 기준으로 수익을 나누는데, 미국은 한국과 달리 업체별로 다른 기준을 적용하기 때문에 실제 수익은 당사자들만 안다. 물론 추정은 가능하다.\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\nSound Recording | 저작권 소유자에게 지급되는 금액. 대부분의 경우 음반사를  말하지만 포괄적으로 독립 아티스트, 프로듀서, 투자자도 포함된다.\nMechanical | 저작물을 디지털 및 물리적 형식으로 복제해 얻는 수익으로, 퍼블리셔에게 기계적으로 지급되는 로열티. 쉽게 말해 작사/작곡가가 버는 돈이다.\nPerformance | 음악 작품이 공식적으로 연주되거나 방송될 때마다 받는 로열티. ASCAP(미국 음악 저작권협회), BMI(방송음악협회), GMR(Global Music Rights) 및 SESAC 같은 공연 권리 단체들이 포함된다.\n\n미국의 음악 산업 전문 법무/컨설팅 회사인 매나트, 펠프스 앤 필립스(Manatt, Phelps & Phillips)는 음원 로열티를 지급하는 다수의 기업을 조사한 데이터를 기반으로 ‘.css-iynyr0{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);-webkit-text-decoration:underline!important;text-decoration:underline!important;}음악 스트리밍 로열티 계산기’를 만들었다. 복잡한 수식은 뒤로 숨기고, 스포티파이나 애플뮤직의 재생수를 입력하면 총매출의 추정치가 나오는 계산기다. 추정치일 뿐이지만 대략 얼마 정도의 매출을 거뒀는지 짐작할 수는 있다.\n이제 ⟨APT.⟩의 숫자를 입력할 차례다. 이 노래는 전 세계 기준으로 단 2주 만에 스포티파이에서 1억 8,336만 9,499회 재생됐다. 사실 이 계산기는 미국 내 스트리밍 로열티만 계산하기 때문에 전 세계 누적 스트리밍 횟수를 그대로 넣으면 안 되지만(미국 내 스트리밍 횟수와 국가별 환율도 고려해야 하므로) 우리의 목적은 추정치를 확인하는 것이므로, 그냥 무식하게 이대로 넣어보자.\n결괏값은 두 개다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}.css-wgpbp3{display:block;margin-top:6px;}로제와 브루노 마스의 ⟨APT.⟩를 음악 스트리밍 로열티 계산기에 넣어본 결괏값 \n스포티파이는 87만 7,932달러(약 12억 1,198만 원)를, 애플뮤직은 155만 7,129달러(약 21억 4,961만 원)를 로열티로 제공한 것으로 추정된다. 음원이 발매된 지 단 2주 만에 33억 원의 매출을 낸 것이다. 물론 로제와 브루노 마스가 이 돈을 다 가져가는 건 아니다. 이들은 여기서 작곡, 작사, 편곡, 가창의 몫을 가져갈 것이다. 글로벌에서 성공한 히트곡이란 대략 이 정도의 매출을 만드는군, 이라는 참고 자료다. 그런데 모두가 스트리밍으로 이렇게 돈을 벌 수 있을까? 이건 정말 예외적인 경우가 아닐까?\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}스트리밍이 정말 돈이 될까?\n스트리밍 시장은 계속 성장하고 있다. 2023년 기준 전 세계 음악 스트리밍 시장 규모는 364억 9,000만 달러로 추정된다. 50조 569억 8,200만 원 정도의 규모다. 2023년부터 2031년까지의 음악 스트리밍 시장의 연평균 성장률(CAGR)은 8.7%를 기록할 것으로 전망되고, 규모도 거의 두 배에 달하는 713억 2,000만 달러에 이를 것으로 예상된다. 스트리밍 이전 시대와 비교하면 사실상 그 규모*를 넘어선 수치다.\n*세계 음악시장 매출은 .css-114ityv{white-space:pre-wrap;cursor:pointer;-webkit-text-decoration:underline!important;text-decoration:underline!important;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}1999년 278억 달러를 기록한 뒤, 2011년까지 12년 연속 감소했다.\n지금이야말로 음악을 사랑하는 사람들이 늘 꿈꾸던 ‘음악으로 충만한 세상’이다. 하지만 그 결과는 우리의 상상과는 완전히 다르다. 스포티파이에 등록된 음악은 1억 곡이 넘지만, 한 번도 재생되지 않은 곡도 수백만 곡에 이른다. 에드 시런과 테일러 스위프트는 2022년까지 스포티파이에서 약 7~8천만 달러를 정산받았지만, 어떤 싱어송라이터는 1년에 100달러 미만을 정산받는다.\n시장이 성장하면서 잠재적 기회는 많아졌지만, 대부분의 수익은 상위 10% 미만의 메이저에게 돌아간다. 소위 ‘메이저’라고 불리는 이들도 모두가 큰돈을 버는 건 아니다. 더 많은 재생 수를 위해서는 더 큰 비용을 써야 하고, 그마저도 지속 가능하고 안정적인 수익을 약속해 주지 않기 때문이다.\n만약 ⟨APT.⟩가 1980년대처럼 5,000원짜리 싱글 음반으로 판매됐다면 12억 1,198만 5,126원의 매출을 위해 1억 8,336만 9,499회의 스트리밍 대신 24만 장의 CD를 파는 것으로 충분했을 것이다. 이처럼 실물 음반에 비하면 스트리밍의 수익성은 낮다. 그렇다면 이런 환경에서 ‘디지털 콘텐츠’ 형태의 음악은 어떤 역할을 하고 있을까?\n유명하지만 돈을 못 버는, 콘텐츠의 역설\n20세기에는 ‘콘텐츠’란 말 자체가 없었다. 콘텐츠의 사전적 의미는 ‘네트워크로 유통되는 멀티미디어 파일’이니까. 전자 네트워크가 생기고 콘텐츠란 말이 태어나기 전의 음악 사업은 음반을 판매하는 것이 거의 유일한 수익 모델이었다. 음악은 음반으로 듣고, 영화는 DVD로 보고, 게임은 게임 타이틀로 하고, 책은 책을 읽어야 했던 것처럼 다른 걸 고려할 수 없었기 때문이다.\n다시 말해 20세기의 음악 산업은 제조업이었다. 음반을 만들고 판매해서 돈을 벌었다. TV에 출연하거나 뮤직비디오를 만들거나 심지어 콘서트를 여는 것도 피지컬(physical) 음반을 판매하기 위한 홍보 활동이었다. (이는 영화, 게임, 출판도 마찬가지였다.)\n그런데 21세기에 디지털 전환이 일어나면서 물리적인 제품에서 멀티미디어가 분리되어 통신망으로 유통되기 시작했고, 음악과 게임의 비즈니스 모델이 무너지기 시작했다. (영화와 출판은 이제야 비슷한 문제를 겪는 중이다). 유선 인터넷, 무선 인터넷, LTE와 5G까지 네트워크 기술이 발전하는 동안 음악과 게임은 다운로드, 스트리밍, 구독 모델을 만들며 새로운 환경에 대응해 왔고, 게임 산업은 ‘인앱 결제’라는 방식으로 비즈니스 모델 문제를 해결하기도 했다.\n그런데 이건 유통 및 공급자의 입장이다. 실제로 음악이나 게임을 만드는 저작권자들은 늘어난 경쟁과 줄어든 수익성의 틈에서 버티기 어려워지고 있다. 음악(콘텐츠)의 초과 공급 아래 콘텐츠 판매 수익은 0에 수렴하기 때문이다. 스포티파이에 하루 동안 업로드되는 신곡의 수, 유튜브에 1분 동안 업로드되는 콘텐츠의 개수, 1년에 발간되는 책의 권수, 킨들에서 발행되는 전자책의 양, 넷플릭스에 업로드되는 비디오 개수… 이 모든 숫자들은 커지고 있지만, 저작권자에게 돌아가는 수익은 적어지고 있다는 점에서 그야말로 풍요 속의 빈곤이다.\n앞서 언급한 ⟨APT.⟩의 사례처럼 ‘유명해지면 되는 것 아닌가?’라고 생각할 수 있다. 하지만 일단 넘치는 콘텐츠 시대에서 유명해지기 위해서는 (매우 운이 좋지 않은 이상) 돈이 많이 들 수밖에 없다. 수많은 콘텐츠 중에서 사람들의 높은 관심을 끌어야 하기 때문이다. 앞서 우리는 스포티파이를 통해 발생한 매출이 12억 원 정도일 것으로 추정했다.\n그런데 제작비는 얼마였을까? 2020년에 니키 미나즈의 피처링 가격이 곡당 6억 원 정도였다는 자료를 참고해, 2024년 브루노 마스의 피처링 비용은 적어도 10억 원이 들었을 것으로 예상해 보자. 그 외 작곡, 편곡, 레코딩, 뮤직비디오 제작비와 마케팅 비용 등을 감안한다면 ⟨APT.⟩ 한 곡의 제작비는 최소 15억 원으로 추정해 볼 수 있을 것이다.\n이렇게 돈을 써서 스트리밍 차트에서 1위를 했더라도, 유명세를 수익으로 전환하는 건 정말 어렵다. 음악이 좋다고 모두가 음반을 구매하거나 공연장에 가는 건 아니기 때문이다. 이런 상황에서 스트리밍만으로 손익분기점을 넘는 건 일반적으로 쉽지 않다. 음악 산업에서의 깔때기 구조*에 따르면, 추상적인 인기를 구체적인 사업으로 전환하는 건 매우 복잡하다. 이게 바로 ‘콘텐츠의 역설’, 유명한데 돈을 못 버는 상황이다.\n.css-nv7vyi{margin:24px 0 8px;padding:16px 40px 32px;border-radius:16px;background-color:var(--adaptiveGrey100);}.css-123co55{font-size:19px;letter-spacing:0em;line-height:1.6;margin:24px 0 0;font-weight:400;color:var(--adaptiveGrey900);background-color:transparent;}\n💡 음악 산업에서의 깔때기 구조 \n\n소비자 행동 이론 중에 고객 퍼널 구조, 혹은 깔때기 구조라고 불리는 모델이 있다. 잠재적 소비자가 고객으로 변해 가는 과정을 분석하는 도구로, 음악에 빗대면 다음과 같다. \n\n음악에서 깔때기 구조는 스트리밍→음악→콘서트로 심화된다. 여기서 스트리밍은 관여도가 낮은 첫 단계다. 그 후 여러 요인들(듣기에 좋아서, 화제가 되어서, 추천곡으로 떠서 등) ‘좋아요’를 누르고 팔로우를 하면서 관여도가 높은(돈을 쓸 가능성이 높은) 고객으로 전환되고, 음반을 구매하거나 콘서트에도 올 수 있는 고객이 된다.\n\n그럼에도 스트리밍이 중요한 이유\n그렇다면 스트리밍 차트 1위는 수익과 관련해서는 아무런 쓸모도 없는 걸까? 아니, 그럼에도 차트 1위라는 화제는 여전히 필요하다. 스트리밍 차트 성적은 더 많은 기회를 만들기 때문이다. ⟨APT.⟩의 1위로 로제가 얻을 기회는 대략 다음과 같다.\n\n후속곡의 성공: ⟨APT.⟩는 로제가 올해 말에 발매할 솔로 1집의 선공개 싱글이었다. ⟨APT.⟩의 성공으로 이후 발표될 곡들에 대한 기대감이 높아졌고 수록곡들도 큰 인기를 얻을 수 있다.\n로제의 섭외비: 방송 출연료, 페스티벌 섭외비, 광고 출연료, 피처링 비용 등이 상승한다.\n로열티 정산 비율이 달라질 수 있다.\n\n이렇게 보면 스트리밍은 단순히 깔때기 구조의 하단에 위치하는 게 아닌, 기회비용을 높이는 전략이 된다. 이 과정에서 팬의 역할이 무엇보다 중요하다. 스트리밍은 팬을 만드는 도구이기도 하지만, 동시에 팬들이 스트리밍에 영향을 주기도 하기 때문이다.\n일반적으로 팬은 음악을 발표하고 활동을 지속하는 과정에서 만들어진다고 여겨졌다. 그러나 지금은 처음부터 팬이 필요하다. 1화에서 말했듯 팬은 소비자나 부가 가치가 아닌, 수익 그 자체를 만드는 존재이면서 산업을 지탱하는 기반이기 때문이다. 과거의 음악 산업이 팬을 아티스트 활동의 결과물로 여겼다면, 지금의 음악 산업은 팬을 처음부터 필요한 존재로 여긴다. 그렇기 때문에 데뷔와 함께, 혹은 데뷔 전에 이미 팬을 모을 수 있는 방법론을 고민한다. 신인 팀을 위한 오디션, 데뷔 전의 소셜 미디어 활동 등이 바로 그중 일부다.\n이렇게 처음부터 만들어진 팬은 (일반 소비자와 다르게) 아티스트와 밀도 높은 관계를 형성하고, 그로부터 지속 가능한 성장을 만든다. 미디어가 산산이 쪼개진 현재, 팬들은 자신의 취향과 맞는 콘텐츠를 찾아가며 그 과정에서 본인이 직접 브이로그 등의 콘텐츠를 제작해 아티스트를 알리는가 하면, 스트리밍 순위를 올리기 위한 집단행동을 하며 기업의 미디어 비용을 줄이는 역할도 맡는다.\n하지만 우리는 로제도, 브루노 마스도 아닌데 어떻게 팬을 만들 수 있을까? 여기에 정답은 없다. 당신이 뮤지션이라면 오디션 프로그램을 통해 팬을 만들 수도 있지만, 인스타그램 라이브나 소셜 미디어 활동 등을 통해 먼저 팬을 만들 수도 있다. 음악을 먼저 발표하는 게 아니라 여러 활동으로 팬을 구한 다음, 진짜 하고 싶은 것을 하는 시대가 온 것이다.\n음악에만 국한되는 얘기는 아니다. 영화도, 게임도, 글을 쓰는 저자도 마찬가지다. 지금 팬이 필요한 상황이라면, 팬이 모이고 성장하는 5단계를 참고해 보길 바란다. 아래는 내가 직접 만든 팬의 행동 변화 5단계로, 팬 비즈니스의 기반이 되는 구조다.\n팬의 행동 변화 5단계 .css-hokoge{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;counter-reset:numberedList;}.css-hokoge ul,.css-hokoge ol{margin:16px 0 0;}.css-hokoge>li{counter-increment:numberedList;margin-bottom:16px;padding-left:24px;}.css-hokoge>li:last-of-type{margin-bottom:0;}.css-hokoge>li>span{position:relative;}.css-hokoge>li>span>:first-child::before{content:counter(numberedList) '.';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n접촉(contact): 미디어 노출로 콘텐츠를 접하는 단계\n몰입(dive): 팔로우, 검색 등을 통해 적극적이지만 가벼운 관계를 형성하는 단계\n재미(play): 공유를 통해 제3자에게 정보를 공유하는 즐거움을 느끼는 단계\n사랑(love): 깊어지는 관계를 통해 감정과 관계의 밀도가 높아지는 단계\n헌신(devotion): 자신의 안정적인 감정 상태를 지키기 위해 행동하는 단계\n\n좋은 마케팅으로 짧은 성과는 낼 수 있다. 그러나 지속적이고 안정적인 성과를 내기 위해서는 반드시 팬이 필요하다. 그게 우리가 해결해야 할 문제다. \n\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 송수아 Graphic 이은호 이제현",
        "content": "디지털 콘텐츠 시대에 스트리밍의 역할",
        "contentSnippet": "디지털 콘텐츠 시대에 스트리밍의 역할",
        "guid": "https://blog.toss.im/article/fandustry-03",
        "isoDate": "2024-11-12T00:00:00.000Z"
      },
      {
        "title": "토스, 디자인 컨퍼런스 '심플리시티24' 개최",
        "link": "https://blog.toss.im/article/simplicity24",
        "pubDate": "Mon, 11 Nov 2024 23:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}모바일 금융 서비스 토스를 운영하는 비바리퍼블리카(이하 토스)가 디자인 컨퍼런스 '심플리시티24(Simplicity24)'를 개최한다고 12 일 밝혔다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n심플리시티는 토스 디자인팀의 경험과 노하우를 공유하는 컨퍼런스로, 올해로 3회째를 맞았다. 컨퍼런스 이름은 토스가 제품을 기획할 때 가장 중요하게 생각하는 원칙인 '단순함(Simplicity)'을 붙였다.\n올해는 모든 연사들이 ‘툴즈 프로덕트 디자이너(Tools Product Designer)’로 구성됐다. 툴즈 프로덕트 디자이너는 서비스를 만드는 팀원들이 더 효율적으로 일할 수 있도록 돕는 도구(Tool)를 만든다. 시중에 출시되지 않은 기능들을 구현해 생산성을 향상시키는 것이 특징이다.\n컨퍼런스의 주제는 'Simple Question, Big Wins: 성공의 문을 여는 가장 평범한 질문'이다. 주제에 맞게 세션의 제목은 모두 질문으로 시작한다. 총 11개의 세션은 △Wise Whys: 문제의 본질을 파고들어 모호함을 임팩트로 만들어낸 이야기 △Noise to Melody: 복잡한 이해관계 속에서 조화로운 솔루션을 발견한 이야기 △Beyond Frames: 역할과 제품의 틀에서 벗어나 새로운 답을 찾아낸 이야기 등 세 가지 트랙으로 구분했다.\n세션은 주제와 관련된 이미지와 자막이 화면에 함께 재생되는 '인터랙션 디자인(Interaction Design)'을 적용해 전달한다. 시작과 끝에는 영상을 삽입해 생동감 또한 높였다. 이를 통해 온라인 컨퍼런스임에도 일방적으로 내용을 전달하는 것이 아닌, 함께 생각하고 답을 고민할 수 있는 소통의 방식을 구현해 냈다.\n정희연 토스 CDO는 \"툴즈 프로덕트 디자인 분야는 생소한 만큼 다른 디자이너의 고민을 듣거나 레퍼런스를 참고하기 쉽지 않기 때문에 도움이 되기를 바라는 마음으로 이번 컨퍼런스를 기획했다”라며 “올해 심플리시티가 툴즈 프로덕트 디자이너를 꿈꾸는 분들에게, 그리고 효율적으로 문제를 해결하고 싶은 분들에게 많은 도움이 되었으면 좋겠다”라고 전했다.\n사전 신청을 완료한 경우 문자 및 이메일로 전달된 링크를 통해 세션 시청이 가능하다. 사전 신청을 하지 않았을 경우 심플리시티24 공식 홈페이지에 접속해 세션을 시청할 수 있다. 11월 24일(일)까지 시청 인증 이벤트도 진행한다. 세션 시청이 끝날 때 화면에 나타나는 인증 카드 중 하나를 개인 인스타그램 계정에 포스팅하면서 토스 디자인 챕터 계정을 태그하면 참여할 수 있다. 추첨을 통해 최대 100명에게 심플리시티24 굿즈를 증정한다.",
        "content": "툴즈 프로덕트 디자이너들이 연사로 참여… 11월 24일까지 시청 인증 이벤트 진행",
        "contentSnippet": "툴즈 프로덕트 디자이너들이 연사로 참여… 11월 24일까지 시청 인증 이벤트 진행",
        "guid": "https://blog.toss.im/article/simplicity24",
        "isoDate": "2024-11-11T23:00:00.000Z"
      },
      {
        "title": "토스, 금융보안원 주관 ‘금융보안 위협분석 대회’ 우승",
        "link": "https://blog.toss.im/article/Toss-Fiesta2024",
        "pubDate": "Mon, 11 Nov 2024 00:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}FIESTA 2024 참가…사이버 위협 관련 출제 문제 모두 풀며 최우수상 수상\n2021년부터 4번째 대회 우승…국내 최고 수준 보안 역량 입증\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n\n모바일 금융 서비스 ‘토스’를 운영하는 비바리퍼블리카(이하 ‘토스’)가 금융보안원 주관 ‘금융보안 위협분석 대회(FIESTA 2024)’에서 우승했다고 11일 밝혔다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n이 대회는 금융권 사이버 보안 위협분석 및 침해 대응 역량 강화를 목적으로 열리는 행사다. 실제 발생할 수 있는 사이버 위협 시나리오를 토대로 출제된 문제를 푸는 방식으로 우승자를 가린다. 올해 대회는 10월 4일부터 6일까지 사흘간 진행됐다.\n토스는 ‘디카페인 말차라떼’라는 팀명으로 보안팀 소속 최정수, 권재승, 강동석, 김재성 화이트해커가 참가했다. 이들은 특히 생성형 AI, 클라우드, 공급망 분야에서 침해 사고 대응 역량을 검증하는 문제들을 모두 풀어내며 대회 1위 쾌거를 이뤘다. 첫 출전인 2021년부터 올해까지 4년 연속 우승으로 국내 최고 수준 금융보안 역량을 입증했다.\n토스는 이번 대회에 참가한 4명을 비롯해 화이트해커로 구성된 팀을 두고 있다. 해당 팀은 사이버 공격에 대비한 훈련 등으로 토스 보안 체계 구축에 힘을 쏟고 있다. 상시로 버그바운티 챌린지(모의 해킹대회)를 운영하며 새로운 보안 기술을 연구에도 매진하고 있다.\n그 결과 ‘ISO27001’, ‘ISMS-P’, ‘PCI DSS Level1’, ‘ISO 27701’ 인증을 취득하는 등 보안과 정보보호 체계 전반에서 세계 최고 수준 평가를 받고 있다.\n토스 관계자는 “4년 연속 우승이라는 쾌거로 토스의 보안 역량을 더 확실하게 증명할 수 있어 기쁘다”라며 “앞으로도 보안 투자와 연구를 지속하며 고객들의 안전한 금융 생활을 위해 매진하겠다”라고 말했다.",
        "content": "4년 연속 쾌거",
        "contentSnippet": "4년 연속 쾌거",
        "guid": "https://blog.toss.im/article/Toss-Fiesta2024",
        "isoDate": "2024-11-11T00:00:00.000Z"
      }
    ]
  },
  {
    "name": "모나미",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김진홍",
    "category": "개인",
    "posts": []
  }
]