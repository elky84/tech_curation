[
  {
    "id": 1,
    "imageUrl": "",
    "title": "Title Launch Observability at Netflix Scale",
    "description": "No description available",
    "reviews": [],
    "syllabus": [],
    "link": "https://netflixtechblog.com/title-launch-observability-at-netflix-scale-8efe69ebd653?source=rss----2615bd06b42e---4",
    "pubDate": "Wed, 05 Mar 2025 01:24:53 GMT",
    "creator": "Netflix Technology Blog",
    "categories": [
      "system-design-concepts",
      "netflix",
      "software-engineering",
      "observability"
    ]
  },
  {
    "id": 2,
    "imageUrl": "",
    "title": "Announcing Guidelines Support Library v4.2.0",
    "description": "Version 4.2.0 of Microsoft's Guidelines Support Library brings performance improvements, safety features, modern compiler support.\nThe post Announcing Guidelines Support Library v4.2.0 appeared first on C++ Team Blog.",
    "reviews": [],
    "syllabus": [],
    "link": "https://devblogs.microsoft.com/cppblog/announcing-guidelines-support-library-v4-2-0/",
    "pubDate": "Thu, 06 Mar 2025 09:36:54 +0000",
    "creator": "Carson Radtke",
    "categories": [
      "Announcement",
      "C++"
    ]
  },
  {
    "id": 3,
    "imageUrl": "",
    "title": "Trino로 타임아웃 개선하기",
    "description": "![NHN Cloud_meetup banner_trino_202502-01_900.png](https://image.toast.com/aaaadh/real/2025/techblog/NHN%20Cloudmeetup%20bannertrino20250201900.png)\r\r\n\r\r\n# 들어가며\r\r\n안녕하세요. NHN Cloud의 클라우드AI팀 이태형입니다.\r\r\n로그 데이터가 쌓일수록 조회 속도가 느려지는 문제, 한 번쯤 겪어 보셨을 텐데요. 이 글에서는 이러한 문제를 해결하기 위해 저희 팀에서 Trino를 도입하여 성능을 개선한 과정을 공유해 보려 합니다. 재미있게 읽어 주세요! \r\r\n\r\r\n# 개요: NHN AppGuard\r\r\n[NHN AppGuard](https://www.nhncloud.com/kr/service/security/nhn-appguard) 서비스에 Trino를 적용한 이야기를 드릴 예정이라서 먼저 해당 서비스를 소개하겠습니다.\r\r\n\r\r\nNHN AppGuard는 모바일 애플리케이션을 보호하기 위해 사용자의 이상 행위를 탐지하거나 차단하는 모바일 앱 보안 솔루션입니다. NHN AppGuard의 서버는 탐지/차단 로그를 안전하게 저장하고, 각종 조건 검색과 대시보드를 제공합니다.\r\r\n\r\r\n![Trino_1.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino1.png)\r\r\n\r\r\n## NHN AppGuard 로그\r\r\n\r\r\nNHN AppGuard는 평균 600만개/일 가량의 로그를 수집하고 있습니다. 이러한 로그는 NHN AppGuard 로그 워크플로에 따라 DB에 적재됩니다.\r\r\n\r\r\n![Trino_2_900.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino2900.png)\r\r\n\r\r\n## 이슈 발생\r\r\n\r\r\n대부분의 쿼리가 월 단위 집계 성격을 띠는 이유로 질의 대상 row 가 1억 건이 넘는 경우가 많아 이슈가 발생했습니다.\r\r\n발생한 이슈는 아래와 같습니다.\r\r\n\r\r\n1. 검색 조건 변경 시 대시보드 화면에서 타임아웃 발생\r\r\n![Trino_3.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino3.png)\r\r\n2. 집계 쿼리가 수행되는 새벽 시간대에 slow query 발생\r\r\n![Trino_4.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino4.png)\r\r\n\r\r\n## 일반적인 해결 방안\r\r\n\r\r\n위 이슈들은 결국 쿼리의 성능이 원인이기 때문에 먼저 쿼리 최적화를 수행했습니다.\r\r\n\r\r\n1. index 문제\r\r\n    1. 쿼리 검수를 통해 index의 순서를 변경하고\r\r\n    2. 의도한 index가 적용되도록 쿼리에 index hint를 추가했습니다.\r\r\n2. 쿼리의 문제\r\r\n    1. 한 달 기간 전체 데이터를 스캔하는 쿼리를 당일 증가분만 조회하도록 수정하고\r\r\n    2. 대시보드를 매번 조회하지 않고 일 배치 작업으로 미리 계산해 둔 데이터를 조회하고\r\r\n    3. 조회 가능한 기간을 제한했습니다.\r\r\n\r\r\n이러한 최적화를 통해 일시적으로 이슈가 해소되었습니다.\r\r\n하지만 NHN AppGuard의 로그는 점차 늘어나고, 집계할 데이터의 종류도 증가했으며, 조회 기간 감소에 대한 불만이 발생하여 다른 접근이 필요했습니다.\r\r\n\r\r\n## 로그 저장소 검토\r\r\n\r\r\nMySQL을 대신해 로그를 저장하기에 적절한 로그 저장소를 검토했습니다.\r\r\n\r\r\n1. Elasticsearch (LNCS)\r\r\n    1. 검색에 좋은 성능\r\r\n    2. 상품 스펙상 최대 120일 저장 제한\r\r\n2. Trino (DataQuery)\r\r\n    1. 복잡한 집계 쿼리에 좋은 성능\r\r\n    2. 여러 데이터 소스 간 federation 지원\r\r\n    3. 저장 기간 제한 없음\r\r\n\r\r\nNHN AppGuard는 로그의 저장 기간을 기존 90일에서 늘리는 것을 계획하고 있었고, 무엇보다 대부분의 쿼리가 집계 성격을 많이 띠어 Trino가 적절하다고 판단했습니다.\r\r\n\r\r\n# Trino와 DataQuery\r\r\n\r\r\n## Trino란\r\r\n\r\r\n[Trino 공식 홈페이지](https://trino.io)를 보면 아래와 같은 문구를 찾을 수 있습니다.\r\r\n\r\r\n> Trino, a query engine that runs at ludicrous speed\r\r\n> Fast distributed SQL query engine for big data analytics that helps you explore your data universe.\r\r\n\r\r\n키워드를 뽑아 보면 아래와 같습니다.\r\r\n\r\r\n1. Fast - 빠르다\r\r\n2. Distributed - 분산 처리한다\r\r\n3. analytics - 분석에 적절하다\r\r\n\r\r\n## Trino 특징\r\r\n\r\r\n마찬가지로 [Trino 공식 홈페이지](https://trino.io)에서는 아래와 같은 특징을 소개합니다.\r\r\n![Trino_5.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino5.png)\r\r\n\r\r\n여기서도 키워드를 뽑아보면 아래와 같습니다.\r\r\n\r\r\n1. distributed: 분산 처리로 빠르고\r\r\n2. ANSI SQL: 표준 SQL 을 호환하여 현재 쿼리문을 수정할 필요가 없고\r\r\n3. S3: OBS에 저장하여 스토리지 비용을 줄일 수 있고\r\r\n4. Query Federation: OBS의 데이터와 MySQL 데이터를 하나의 쿼리로 join할 수 있다.\r\r\n\r\r\n## Trino 동작 원리\r\r\n\r\r\nTrino의 동작 원리는 [Presto: SQL on Everything](https://trino.io/Presto_SQL_on_Everything.pdf)라는 논문에 자세히 소개하고 있습니다.\r\r\n해당 논문의 일부를 가볍게 살펴보겠습니다.\r\r\n\r\r\n### 구조도\r\r\n![Trino_6.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino6.png)\r\r\n\r\r\nTrino는 하나의 Coordinator 노드와 여러 개의 Worker 노드로 구성됩니다. Coordinator 노드는 쿼리의 인입 지점으로 admit, parsing, planning, optimizing, orchestration 등을 수행하고, worker node는 query processing을 담당합니다.\r\r\n\r\r\n### 요청 처리 순서\r\r\n\r\r\nCoordinator 노드가 분산 처리를 계획하면 worker node가 병렬로 처리해서 복잡한 쿼리가 더 빠르게 실행되는 원리입니다.\r\r\n\r\r\n1. client → coordinator: http request (SQL stmt)\r\r\n2. coordinator: evaluate request(parsing, analyzing, **optimizing distributed execution plan**)\r\r\n3. coordinator: plan to worker\r\r\n    1. task 생성\r\r\n    2. **splits** 생성(addressable chunk in external storage)\r\r\n    3. splits을 task에 할당\r\r\n4. worker: run task\r\r\n    1. fetching splits\r\r\n    2. 다른 worker에서 생성한 intermediate data 처리\r\r\n        1. worker 간에는 intermediate data를 memory에 저장하여 공유\r\r\n        2. **shuffle**이 발생할 수 있음\r\r\n             \\*shuffle = node 간 데이터 재분배\r\r\n    3. query의 shape에 따라 모든 데이터를 처리하지 않고 반환\r\r\n\r\r\n## Trino 쿼리 실행 예시\r\r\n\r\r\n### 그림으로 살펴보기\r\r\n* 쿼리문\r\r\n![Trino_7.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino7.png)\r\r\n\r\r\n* logical plan\r\r\n![Trino_8.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino8.png)\r\r\n\r\r\n* distributed plan (stage)\r\r\n![Trino_9.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino9.png)\r\r\n\r\r\n* optimized plan (pipeline, parallelism)\r\r\n![Trino_10.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino10.png)\r\r\n\r\r\n\r\r\n### 실행 순서\r\r\n\r\r\n1. Planner: SQL → SQL syntax tree → Logical Planning (IR 생성)\r\r\n    * IR = Intermediate Representation\r\r\n2. Optimizer: Logical Plan → evaluate transformation rules → **optimize** → Physical Structure\r\r\n    * transformation rules = sub-tree query plan + transformation\r\r\n    * 사용되는 optimizing 기법 = predicate and limit pushdown, column pruning, decorrelation, table and column statistics 기반 cost-based 최적화\r\r\n        * Data Layouts = Connector Data Layout API로 얻어내는 위치, 파티션, 정렬, 그룹화, 인덱스\r\r\n        * Predicate Pushdown = connector에 따른 filtering 최적화\r\r\n            * \\*pushdown : 읽어야 하는 데이터를 줄이는 것\r\r\n            * \\***Predicate Pushdown** : 조회 조건에 맞는 데이터만 읽는 것\r\r\n        * **Inter**-node Parallelism = stage 단위의 병렬 실행\r\r\n        * **Intra**-node Parallelism = stage 내에서 single node의 thread에 걸친 병렬 실행\r\r\n3. Scheduler: Stage Scheduling → Task Scheduling → Split Scheduling\r\r\n    * Task Scheduling = Leaf Stage / Intermediate Stage 분리하여 배치\r\r\n4. Query Execution = Local Data Flow → Shuffles → Writes\r\r\n\r\r\n## DataQuery\r\r\n\r\r\n[NHN Cloud의 DataQuery](https://www.nhncloud.com/kr/service/data-analytics/dataquery?lang=ko) 서비스는 위에서 소개한 Trino를 기반으로 대규모 데이터에 대해 쿼리를 실행할 수 있는 서비스입니다.\r\r\n이를 통해 원하는 클러스터 스펙을 지정하고 연결할 데이터 소스만 작성하면 Trino의 복잡한 설치와 설정 과정 없이 사용이 가능합니다.\r\r\n\r\r\n# Trino 적용 - 개념\r\r\nTrino를 적용하기 위해 알아야 할 개념을 소개합니다.\r\r\n\r\r\n## 데이터 소스 선정\r\r\nTrino는 여러 종류의 데이터 소스를 지원합니다.\r\r\n\r\r\nNHN AppGuard는 로그 저장 기간 증가를 계획하고 있어 저장 비용을 절약하기 위해 OBS를 데이터 소스로 선정하였습니다.\r\r\nOBS 데이터 소스를 사용하는 경우 데이터의 타입도 Parquet, JSON, ORC, CSV, Text 중에 선택해 주어야 해서, 위와 동일한 이유로 Parquet 파일 포맷을 선택하였습니다.\r\r\n\r\r\n### Apache Parquet\r\r\n\r\r\n[Apache Parquet 홈페이지](https://parquet.apache.org)에는 Parquet를 아래와 같이 설명합니다.\r\r\n\r\r\n> Apache Parquet is an open source, column-oriented data file format designed for efficient data storage and retrieval. It provides efficient data compression and encoding schemes with enhanced performance to handle complex data in bulk. Parquet is available in multiple languages including Java, C++, Python, etc...\r\r\n\r\r\n여기서도 키워드를 뽑아보면 아래와 같습니다.\r\r\n\r\r\n* column-oriented data\r\r\n* efficient data storage and retrieval\r\r\n* efficient data compression\r\r\n* encoding schema\r\r\n* handle complex data in bulk\r\r\n\r\r\ncolumn-oriented data의 설명은 아래의 그림을 보시면 이해가 쉽습니다.\r\r\n![Trino_11.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino11.png)\r\r\n(Source: [https://devidea.tistory.com/92](https://devidea.tistory.com/92))\r\r\n\r\r\n동일한 타입의 데이터가 나열되기 때문에 압축 효율이 높아지는 효과가 있습니다.\r\r\n또한 footer에 데이터에 대한 메타데이터를 저장해 두어 reader에게 데이터에 대한 힌트를 주어 조회 성능을 높입니다.\r\r\n\r\r\n![Trino_12.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino12.png)\r\r\n(source: [https://parquet.apache.org/docs/file-format/](https://parquet.apache.org/docs/file-format/))\r\r\n\r\r\n## 구상안\r\r\n\r\r\nparquet는 columnar한 형식이기 때문에 row 단위로 데이터를 append하는 것은 비효율적입니다. 그러므로 데이터를 모아서 parquet 형식으로 파일을 생성하는 것이 효율적입니다. 이를 위해 NHN AppGuard에서는 3가지 구성 방법을 고려했고 3번째 안을 선택했습니다.\r\r\n\r\r\n1. micro batch\r\r\n    1. kafka → log-batch → create parquet / 1 minute → save obs → obs\r\r\n    2. trino는 OBS를 사용하는 경우 파일 기반으로 동작하기 때문에 파일의 개수가 많아지면 비효율적입니다.\r\r\n    3. 1분 단위로 파일을 쓸 경우 작은 파일이 많아져 조회 성능이 현저히 떨어지기 때문에 선택하지 않았습니다.\r\r\n2. hourly batch\r\r\n    1. kafka → log-batch → create parquet / 1 hour (save data in memory or redis) → save obs → obs\r\r\n    2. 메모리에 저장하는 경우 데이터 유실의 리스크가 걱정되었고\r\r\n    3. NHN AppGuard는 redis를 사용하고 있지 않아 trino와 redis 두 컴포넌트의 추가로 인한 운영 복잡도 증가가 부담되어 선택하지 않았습니다.\r\r\n3. **중간 DB 사용 - MySQL**\r\r\n    1. kafka → log-batch → save to mysql → mysql → tier down in daily-batch → save obs → obs\r\r\n    2. 기존에 사용하던 MySQL 구성을 변경하지 않아 수정 소요가 적었고\r\r\n    3. MySQL을 통해 실시간 데이터 또한 조회할 수 있어 실시간 데이터 조회가 쉬워 선택하였습니다.\r\r\n\r\r\n### 구성도\r\r\n\r\r\n* AS-IS\r\r\n![Trino_13_900.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino13900.png)\r\r\n\r\r\n* TO-BE\r\r\n![Trino_14_900.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino14900.png)\r\r\n\r\r\n\r\r\n### tier down 개념\r\r\n\r\r\nElasticSearch는 데이터의 역할 또는 접근 빈도에 따라 노드를 분배하는 기법으로 Data Tiering 을 사용합니다.\r\r\n\r\r\n![Trino_15.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino15.png)\r\r\n(source: [https://www.linkedin.com/pulse/navigating-data-tiers-optimizing-costs-reducing-risk-boosting-lim-yfeyc](https://www.linkedin.com/pulse/navigating-data-tiers-optimizing-costs-reducing-risk-boosting-lim-yfeyc))\r\r\n\r\r\n이렇게 tier를 적용한 데이터를 높은 티어에서 낮은 티어로 낮추는 것을 tier down이라고 부릅니다. hot tier는 일반적으로 성능이 좋고 반응이 빠르지만 비용이 비싸고, cold tier는 반응은 조금 느리지만 비용이 저렴한 저장소를 사용합니다.\r\r\n\r\r\nNHN AppGuard에서는 MySQL을 hot tier, Trino를 cold tier로 정의하고 daily-batch에서 MySQL 데이터를 Parquet로 변환해 Trino에 삽입시키는 작업을 tier down으로 정의했습니다.\r\r\n\r\r\n### Parquet 파일 생성 방법\r\r\n\r\r\nParquet는 원래 HDFS에 쓰는 용도로 고안되어서 Parquet 파일을 직접 쓰려면 `org.apache.hadoop:hadoop-common:3.3.6`과 같은 hdfs writer에 세그먼트 관리, 열 압축 등의 기능을 구현해야 합니다. 이러한 작업을 피하기 위해 일반적으로 Spark 등의 외부 컴포넌트를 쓰거나 avro 포맷의 파일을 거쳤다가 parquet로 변환하는 방법을 사용합니다.\r\r\n\r\r\n[Apache Avro](https://avro.apache.org)는 data를 serialize하기에 좋은 포맷으로 스키마를 갖습니다.\r\r\nParquetFileWriter를 지원하기 때문에 손쉽게 변환이 가능합니다.\r\r\n\r\r\n> Apache Avro™ is the leading serialization format for record data, and first choice for streaming data pipelines. It offers excellent schema evolution, and has implementations for the JVM (Java, Kotlin, Scala, …), Python, C/C++/C#, PHP, Ruby, Rust, JavaScript, and even Perl.\r\r\n\r\r\n# Trino 적용 - 구현\r\r\n\r\r\n## tier down 구현\r\r\n\r\r\n### 논리 구조\r\r\n![Trino_16_900.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino16900.png)\r\r\n\r\r\n\r\r\n### Trino 테이블 생성\r\r\n\r\r\nTrino 데이터 소스로 OBS를 사용하는 경우 Hive를 사용하기 때문에 HQL을 사용해야 합니다. HQL 또한 SQL 표준을 따르기 때문에 거의 유사하지만 묵시적 형 변환과 같은 편의 기능을 지원하지 않고, with 문의 external location, partitioned_by 등의 옵션이 추가됩니다.\r\r\n\r\r\n```sql\r\r\nCREATE TABLE log\r\r\n (\r\r\n    seq              bigint, \r\r\n    log_time         timestamp,\r\r\n    // 생략 \r\r\n    log_date         date,\r\r\n    appkey           varchar(64),\r\r\n ) \r\r\n WITH ( \r\r\n    format = 'Parquet',\r\r\n    external_location = 's3a://data-query/log',\r\r\n    partitioned_by = ARRAY['appkey','date']\r\r\n);\r\r\n```\r\r\n\r\r\n### avro schema 작성\r\r\n\r\r\n```javascript\r\r\n{\r\r\n  \"type\" : \"record\",\r\r\n  \"name\" : \"log\",\r\r\n  \"namespace\" : \"avro\",\r\r\n  \"fields\" : [\r\r\n    { \"name\" : \"seq\", \"type\" : \"long\" },\r\r\n    { \"name\" : \"log_time\", \"type\" : [ \"null\", \"string\" ], \"default\" : null },\r\r\n    // 생략\r\r\n  ]\r\r\n}\r\r\n```\r\r\n\r\r\n### tier down process\r\r\n![Trino_17.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino17.png)\r\r\n데이터를 메모리에 올려서 변환하기 때문에 장비와 데이터에 따라 적절한 페이징을 적용해야 합니다.\r\r\n\r\r\n### convert to parquet\r\r\n![Trino_18.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino18.png)\r\r\navro 변환은 apache avro 모듈의 schema.from 함수로 쉽게 변환이 가능합니다. parquet는 apache parquet 모듈의 PositionOutputStream 객체의 writer를 구현하여 변환할 수 있습니다.\r\r\n\r\r\n### 다른 방법은 없을까?\r\r\nCTAS(Create Table As Select)가 가장 쉬운 방법입니다. 수행 시간은 위 방법과 비슷하게 소요되지만 용량이 30% 정도 더 효율적인 것으로 확인하였습니다. 하지만 DataQuery에서 사내 DB를 아직 데이터 소스로 지원하지 않아 현재는 사용이 어렵습니다.\r\r\n여기에서는 방법만 소개하겠습니다.\r\r\n\r\r\n```sql\r\r\nCREATE TABLE obs.test.log_ctas\r\r\n    WITH (\r\r\n        format = 'Parquet',\r\r\n        external_location = 's3a://ctas-test/log-ctas',\r\r\n        partitioned_by = ARRAY['log_date', 'appkey']\r\r\n        )\r\r\nAS\r\r\nselect seq,\r\r\n// 생략\r\r\n       cast(log_time as date) as log_date,\r\r\n       appkey\r\r\nfrom \"mysql\".log\r\r\nwhere log_time >= date '2024-11-01'\r\r\n  and log_time < date '2024-11-02';\r\r\n```\r\r\n\r\r\n## 실시간 데이터 union 구현\r\r\n\r\r\n### 논리 구성도\r\r\n![Trino_19_900.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino19900.png)\r\r\n1. cold data에 마지막으로 저장된 시간을 조회하고\r\r\n2. cold data와 hot data를 조회해\r\r\n3. join / union 하여 응답합니다.\r\r\n\r\r\n### Data 조회\r\r\n\r\r\nCold - max cold data 기준 왼쪽을 조회합니다.\r\r\n![Trino_20.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino20.png)\r\r\n\r\r\nHot - max cold data 기준 오른쪽을 조회합니다.\r\r\n![Trino_21.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino21.png)\r\r\n\r\r\n### Data Join / Union\r\r\n\r\r\n집계의 경우 toMap과 id 값을 이용해 Join 합니다.\r\r\n![Trino_22.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino22.png)\r\r\n\r\r\n단순 조회의 경우 stream.concat으로 Union 합니다.\r\r\n![Trino_23.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino23.png)\r\r\n\r\r\n# 성능 테스트\r\r\n\r\r\n## 환경\r\r\n\r\r\n* DataQuery 스펙: c2m8 * 3\r\r\n* DataQuery 데이터는(log_date, appKey) 파티셔닝 되어 있고\r\r\n    * 참고 \\*partition = RDBMS의 index 와 유사. parquet 가 저장된 경로를 의미\r\r\n        ![Trino_24.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino24.png)\r\r\n* MySQL 데이터는 일 단위로 파티셔닝되어 있습니다.\r\r\n* MySQL 데이터는 log\\_time, appkey 각각의 인덱스와 (log\\_time, appkey) 복합 index 가 적용되어 있습니다.\r\r\n\r\r\n## 데이터 조회\r\r\n\r\r\n이슈 대응 등의 이유로 개발자가 쿼리 엔진에 자주 질의하는 **일반 쿼리**와 서비스에서 사용하는 **서비스 쿼리**로 구분하여 테스트했습니다.\r\r\n\r\r\n### 일반 쿼리\r\r\n\r\r\n단순한 select \\* 조회는 mysql이 7배가량 빠르고, count 등의 집계 함수가 포함된 쿼리는 DataQuery가 적게는 4배에서 6배가량 빠른 양상을 보였습니다.\r\r\nTrino + Parquet 조합은 열 기반 데이터 포맷으로 인한 행 조회의 비효율성, Trino의 쿼리 플래닝과 file fetch에서의 오버헤드로 인해 단순한 행 조회가 느리기 때문입니다.\r\r\n\r\r\n| 쿼리 | dataquery | mysql |\r\r\n| --- | --------- | ----- |\r\r\n| **단순** 조회 (select \\* limit 500) | 1 s 151 ms | 148 ms |\r\r\n| **count** 조회 (select count(\\*) 한 달 | 8 s 957 ms | 30.987 s |\r\r\n| filter - appkey \\& log\\_time **행 조회** | 1 s 323 ms | 393 ms |\r\r\n| filter - appkey \\& log\\_time **count** | 349 ms | 14.662 s |\r\r\n| group by - appkey 하루 | 814 ms | 2.385 s |\r\r\n| group by - appkey 한 달 | 18 s 530 ms | 2m 15s 538ms |\r\r\n\r\r\n### NHN AppGuard 서비스 쿼리\r\r\n\r\r\nDataQuery가 전반적으로 10배 정도 빨랐습니다.\r\r\n이상 행위 탐지 현황의 한 달치 데이터는 MySQL에서 30분 이상 소요되어 조회할 수 없었지만 DataQuery는 36초만에 조회하였습니다.\r\r\n\r\r\n| 쿼리 | dataquery | mysql |\r\r\n| --- | --------- | ----- |\r\r\n| 이상행위 탐지현황 - limit 50 하루 | 1 s 696 ms | 9.676s |\r\r\n| 이상행위 탐지현황 - limit 50 한 달 | 6 s 468 ms | 6m 19s 459ms |\r\r\n| 이상행위 탐지현황 report - 하루 | 7.06s | 21s 890ms |\r\r\n| 이상행위 탐지현황 report - 한 달 | 36.81s | **조회 불가(30분 이상)** |\r\r\n| 로그 조회 - 하루 | 1 s 531 ms | 7s 264ms |\r\r\n| 로그 조회 - 한 달 | 5 s 728 ms | 5m 58s 381ms |\r\r\n\r\r\n### Parquet 크기별 비교\r\r\n\r\r\nappkey로 파티션 되기 때문에 appkey별 로그 양이 달라 로그 개수에 따른 성능 차이를 비교해 보았습니다. 로그 수 기준 중위의 appkey까지도 MySQL이 더 빠른 양상을 보였습니다. 2-300ms가량의 차이를 보이는 만큼 로그가 적은 사용자 입장에서는 데이터가 없는데 굼뜨다는 느낌을 받을 수 있습니다. 이에 반해 로그 수가 평균을 넘어가면 MySQL은 30초가 넘어가는 응답을 보여 콘솔에서 서비스하기에 어려운 반응 속도를 보입니다.\r\r\n\r\r\n| 대시보드 조회 쿼리 | DataQuery | MySQL |\r\r\n| ---------- | --------- | ----- |\r\r\n| 데이터 없음 | 267 ms | 102 ms |\r\r\n| 최소 | 365 ms | 100 ms |\r\r\n| 중위 | 610 ms | 168 ms |\r\r\n| 평균 | 505 ms | 34 s 24 ms |\r\r\n| 최대 | 15s 85 ms | 10 m 23 s 982 ms |\r\r\n\r\r\n## 성능 테스트 결론\r\r\n\r\r\n1. 행 전체 조회, 데이터가 적은 경우는 MySQL이 빠르다.\r\r\n    1. 100ms VS 500ms의 차이 → **참을만하다.**\r\r\n2. 집계 조회, 데이터가 많은 경우에는 DataQuery가 빠르다.\r\r\n    1. 수십 초 VS 수 분 차이 → **참을 수 없다.**\r\r\n\r\r\n# 결과\r\r\n\r\r\n## 좋아졌나요?\r\r\n\r\r\n1. 이상 행위 탐지 현황의 30일치 데이터를 조회하지 못하던 고객이 이제 조회할 수 있게 되었습니다.\r\r\n2. 2024년 초 공개한 NHN AppGuard public api는 MySQL로는 30분 이상 소요되어 개발이 어려웠는데, DataQuery를 통해 7초 이내로 조회하여 개발할 수 있었습니다.\r\r\n3. 내부 집계 시간이 38m36s → 22m16s로 약 43% 개선했습니다.\r\r\n4. mysql에서의 집계로 인한 slow query가 제거되어 일 배치로 인한 서비스의 영향성이 없어졌습니다.\r\r\n5. 집계 연산이 빨라져서 집계 데이터의 종류를 늘리는 것에 부담이 없어졌습니다.\r\r\n6. 스토리지 비용 감소로 데이터 저장 기간을 60일에서 1년으로 늘렸습니다.\r\r\n\r\r\n## 나쁜 점은 없나요?\r\r\n\r\r\n1. 대시보드의 기본 응답 속도가 300ms 정도 느려졌습니다.\r\r\n2. tier down 실패 시 집계, 미터링 등에 영향을 주기 때문에 모니터링 요소가 늘어났습니다.\r\r\n3. DataQuery와 OBS 비용이 추가되었습니다. (대략 100만 원/월)\r\r\n\r\r\n## 앞으로 해야 할 것이 있을까요?\r\r\n\r\r\n1. 일 단위 tier down을 시간 단위로 변경하는 것을 고민하고 있습니다.\r\r\n2. 고객 로그 수에 따라 적절한 쿼리 엔진을 사용하도록 최적화하는 부분에 대해 고민하고 있습니다.\r\r\n\r\r\n\r\r\n\r\r\n이상 NHN AppGuard에 Trino를 적용해 본 과정과 결과에 대해 정리하였습니다. 도움이 되셨길 바라며, 긴 글을 읽어 주셔서 감사합니다. \r\r\n\r\r\n[![NHN Cloud_meetup banner_footer_gray_202408_900.png](https://image.toast.com/aaaadh/real/2025/techblog/NHN%20Cloudmeetup%20bannerfootergray202408900.png)](https://www.nhncloud.com/kr)",
    "reviews": [],
    "syllabus": [],
    "link": "https://meetup.nhncloud.com/posts/391",
    "pubDate": "Tue, 04 Mar 2025 02:22:40 GMT",
    "creator": "Unknown",
    "categories": []
  },
  {
    "id": 4,
    "imageUrl": "",
    "title": "TeamCity 2024.12.3 Bug Fix Is Out!",
    "description": "The TeamCity On-Premises 2024.12.3 bug-fix update is out and ready to be installed on your servers! This update resolves over 10 issues and, as always, includes essential security and performance fixes. We highly recommend upgrading to keep your system secure and optimized. The list of resolved issues includes: See TeamCity 2024.12.3 Upgrade Notes for the […]",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.jetbrains.com/teamcity/2025/03/teamcity-2024-12-3-bug-fix/",
    "pubDate": "Fri, 07 Mar 2025 09:54:08 +0000",
    "creator": "Dmitrii Korovin",
    "categories": [
      "bug-fix"
    ]
  },
  {
    "id": 5,
    "imageUrl": "",
    "title": "Great new productivity features in Visual Studio",
    "description": "Sometimes it’s the little things in life that matter the most. In the latest version of Visual Studio, we’ve added some features and tweaks that aim to put a smile on your face and make you more productive. Here is a list of some of these, and if you want the full list, make sure […]\nThe post Great new productivity features in Visual Studio appeared first on Visual Studio Blog.",
    "reviews": [],
    "syllabus": [],
    "link": "https://devblogs.microsoft.com/visualstudio/great-new-productivity-features-in-visual-studio/",
    "pubDate": "Mon, 03 Mar 2025 16:28:28 +0000",
    "creator": "Mads Kristensen",
    "categories": [
      "Accessibility",
      "Productivity",
      "Visual Studio",
      "Developer Productivity"
    ]
  },
  {
    "id": 6,
    "imageUrl": "",
    "title": "레이 달리오 그는 훌륭하지도 투자자도 아니였다.",
    "description": "영상: https://www.youtube.com/watch?v=3H9IzYweqAA&list=WL\n\n\n\n그는 엄청나게 고평가된 사람이며\n위기가 올때까지 7년을 위기라고 밀고 나간 사람이다.\n회사의 운영방식은 너무 이상했고\n돈을 번게 아니라 위기때 마다 인기를 얻어 투자금이 들어오면서 성공한것 처럼 보였다.",
    "reviews": [],
    "syllabus": [],
    "link": "http://serverdown.tistory.com/1169",
    "pubDate": "Fri, 7 Mar 2025 09:51:38 +0900",
    "creator": "SIDNFT",
    "categories": [
      "투자"
    ]
  },
  {
    "id": 7,
    "imageUrl": "",
    "title": "Cursor 0.46, 뭔가 달라졌다! Agent의 변화를 체크해보세요.",
    "description": "Cursor 0.46 업데이트에서 중요한 변화들이 있었네요! 주요 포인트를 정리해보면 다음과 같습니다.\n🔥 Cursor 0.46 업데이트 핵심 요약\n💡 Agent 기본 모드로 통합\nChat, Composer, Agent가 하나의 인터페이스로 정리됨.\n기존 모드 이름 변경\n          \nChat → Ask\nComposer (일반) → Edit\nComposer (Agent 모드) → Agent\n단축어: ⌘ + . (모드 전환 가능)\nAsk ↔ Agent 같은 컨텍스트에서 자유롭게 전환 가능!\n🌐 웹 검색 기본 제공\n이제 프롬프트에 @web을 포함하지 않아도 웹 검색이 자동 적용됨.\n만약 웹 검색이 되지 않는다고 느껴진다면, \"웹에서 공식 문서를 검색한 다음 구현을 진행\" 같은 문장을 포함하면 해결 가능.\n🖥️ 터미널 참조 기능 추가 (@terminals)\n@terminals를 사용하여 터미널 내용을 바로 참조 가능\n기존에 Agent에 터미널 내용을 전달하는 과정이 불편했는데, 이제 더 직관적인 디버깅 환경 제공\n✨ 이 업데이트의 의미는?\n더 자연스럽고 편리한 워크플로우 → 하나의 인터페이스에서 모든 기능을 수행 가능\n웹 검색이 더 직관적 → @web을 따로 입력할 필요 없이 자동 제공\n터미널 디버깅이 개선 → @terminals로 바로 참조 가능\n더 자세한 정보는?\nCursor 공식 변경 로그\n  \n이제 코딩할 때 더 빠르고 매끄럽게 작업할 수 있겠네요! 🚀🔥",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.gaerae.com/2025/03/cursor-046-agent.html",
    "pubDate": "Sun, 02 Mar 2025 14:57:00 +0000",
    "creator": "noreply@blogger.com (Unknown)",
    "categories": [
      {
        "_": "ai",
        "$": {
          "domain": "http://www.blogger.com/atom/ns#"
        }
      }
    ]
  },
  {
    "id": 8,
    "imageUrl": "",
    "title": "2015년 여름",
    "description": "이 여름에는 많은 일이 일어났다. 버팔로에서 탬파로 이사가고 이직하던 시기이다. 베를린에서 열렸던 TSL Workshop에서는 장영재 교수님을 처음으로 만나 카이스트 산업및시스템공학과와 연결고리가 생기기도 했다. 버팔로에서 많은 추억을 함께 쌓은 김진수 선생님의 초청으로 인천국제고와 인천과학고에서 세미나도...",
    "reviews": [],
    "syllabus": [],
    "link": "https://thoughts.chkwon.net/2015-summer/",
    "pubDate": "Mon, 03 Mar 2025 23:28:10 +0000",
    "creator": "권창현",
    "categories": [
      "잡생각"
    ]
  },
  {
    "id": 9,
    "imageUrl": "",
    "title": "지각하지 않던 사람들",
    "description": "딸을 학교에 보내고 돌아오며 저의 학창 시절이 떠올랐습니다.\n인생을 더 살면서 사소해 보이는 작은 약속을 잘 지키는 것이 얼마나 중요한지 깨닫게 되었습니다.\n어쩌면 아내의 이런 모습들이 저에게 좋은 영향을 끼친 것 아닐까?\n그럼에도 불구하고 최근 몇 년 간 약속 시간에 늦은 적이 몇 번 있음을 고백합니다.\n다시 회사에 간다면 걱정되는 한 가지는 바로 이 출근 시간입니다.\n한 편으로 몇 년 동안 한 번도 지각하지 않던 동료들도 떠오릅니다.\n\n함께 읽으면 좋은 글:\n가장 행복했던 출근길\n출근길의 강제 독서",
    "reviews": [],
    "syllabus": [],
    "link": "https://jeho.page/essay/2025/03/06/time-to-work.html",
    "pubDate": "2025-03-06T02:54:00.000Z",
    "creator": "Unknown",
    "categories": []
  },
  {
    "id": 10,
    "imageUrl": "",
    "title": "유니티 6 캔버스 셰이더 깜박이기 / Unity 6 Canvas Shader",
    "description": "빨간 사격형이 깜박이는 작업이다.\n셰이더작업은 메뉴가 버전마다 달라서 어디는지 찾다보니 기록을 남겨둔다.\n영상: https://www.youtube.com/watch?v=VuibGcamE5E&t=45s\n\n\n\n이분 영상은 유니티 2023 버전이였다.\n \n1. UI -> Canvas 로 캔버스 만듭니다.\n2. UI -> Image 로 사각형 만듭니다.\n3. 파일쪽에서 우클릭 create -> Shader Graph -> Spirte Unlit ~~ 셰이더 그래프 만듭니다.\n\n\n멀리도 있다.\n4. 더블클릭해서 Shader Graph 엽니다.\n5.Fragment 클릭\n\n\n6. 우측 상단에 떠있는 UI 인데 그림따라 가서 Canvas 로 바꾼다.\n\n\n여기까지해야 alpha 가 정상적으로 먹히는 캔버스 셰이더가 동작합니다.\n7. 셰이더 그래프 만들기\n\n\nColor 는 빨간색 그대로 박아넣었고\nAlpha 는 Time  의 sine time 을 이용해 1 ~ -1 왔다갔다 하는 값을 넣었다. \n0 ~ -1 부분은 다 0 이 되기 때문에 안보이는 시간이 좀 길더라 Absolute 를 넣으면 1 ~ 0 값으로 바꿔준다.\n(영상에선 그걸 사용함)\n좌측 상단에 디스켓 아이콘을 눌러 저장한다.\n(요즘 사람은 디스켓이 뭔지 모른다더라.)\n\n\n이렇게 생긴 아이콘이 디스켓 이다.\n \n8. 캔버스의 이미지에 셰이더를 박는다.\n\n\n내 프로젝트 기준으로 스샷을 찍은거니 각자 알아서 잘 찾아 넣는다.\nMaterial 부분에 Shader 를 넣어도 되니 편리했다.\n \n셰이더는 어려운 분야라서 UI 에 익숙해지는게 좋을것 같아 일부러 스샷을 많이 남겼다.\n \n추가작업\nFS_Blink_shader.zip 파일 링크 : https://drive.google.com/file/d/1aEqv4z_f76fntUDX60DnCDY057BDLWfV/view?usp=drive_link\n위에서 만든 셰이더는 색깔이 깜박거리는 것이라 쓸모가 없습니다.\n이 셰이더는 텍스처를 포함한 UI 를 깜박히게 합니다.\n\n\n예시 화면\n셰이더가  UI 의 scrite 를 받아드리려면 입력 텍스쳐의 이름을 고쳐주어야합니다.\n\n\n_MainTex <-- 이런식의 이름을 써야 UI 에 설정한 그림을 받아 드릴 수 있으니 주의\n관련 설명: \nSome common texture names in Unity shaders include: \n_MainTex: The main diffuse texture \n_BumpMap: The normal map \n_Cube: The reflection cubemap\nYou can use the Material.GetTexture method to get a named texture. If the texture is not found, the method will write an error message to the console and return null.",
    "reviews": [],
    "syllabus": [],
    "link": "http://serverdown.tistory.com/1172",
    "pubDate": "Fri, 7 Mar 2025 15:32:30 +0900",
    "creator": "SIDNFT",
    "categories": [
      "프로그래밍/개발메모"
    ]
  },
  {
    "id": 11,
    "imageUrl": "",
    "title": "중국 인구는 이미 5억명이 줄었다는 주장 / 괴담",
    "description": "영상: https://www.youtube.com/watch?v=cHY-ZiGFozA\n\n\n\n2억 ~ 5억명이 이미 사라졌을 가능성이 있다는 주장이 나왔습니다.\n이것은 코로나와 주택버블 붕괴로 여러명이 사망했을 가능성이 있다고 합니다.\n몇년째 화장터가 쉬지 않고 가동중이며 \n코로나 봉쇄가 너무 과했다고 생각했는데 \n그럴만한 이유가 있었던게 아닌가 하는 생각도 드는군요",
    "reviews": [],
    "syllabus": [],
    "link": "http://serverdown.tistory.com/1166",
    "pubDate": "Wed, 5 Mar 2025 01:13:43 +0900",
    "creator": "SIDNFT",
    "categories": [
      "유튜브",
      "중국"
    ]
  },
  {
    "id": 12,
    "imageUrl": "",
    "title": "분산락 적용하기 (실전)",
    "description": "이전까지는 왜 분산락을 적용했고, 해당 코드가 어떤지에 대해서 이야기해보았다. \n이번에는 적용한 코드가 우리가 원하는 동시성에 대한 대책이 제대로 되었는지에 대한 이야기를 해볼것이다. \n📌 조건은?\n우선, 난 Jmeter를 활용해서 하나의 락을 거는 @DistributedLock과 여러 락을 동시에 거는@MultiDistributedLock에 대한 동시성 테스트를 진행했다. \n조건은 둘다 똑같이 설정했다.\n\n조건을 해석해보자면, \n50개의 스레드 (동시 사용자 50명)\nRamp-up 시간 50초 (1초마다 1개의 스레드가 추가됨)\nLoop Count: 10 (각 스레드가 10번 반복 요청)\n→ 즉, 최대 500개의 요청이 순차적으로 발생\n추가적으로 설명하자면, \nRamp-up Period는 모든 스레드(사용자)를 얼마나 걸쳐서 실행할지를 결정하는 값이다.\n즉, JMeter는 총 N개의 스레드를 Ramp-up Period 동안 균등하게 분배하여 시작한다.\n이걸 공식으로 정리하자면,\n🔹 스레드 시작 간격 (초) = Ramp-up Period / 총 스레드 개수\n내가 설정한 조건에 의하면, Ramp-up Period를 50초, 스레드 개수를 50으로 설정하게 되고\n50초/50쓰레드 가 되니 1초마다 1개의 스레드가 추가되는 구조가 된다. \n정리하자면, 50초 동안 50개의 스레드가 점진적으로 늘어나며, 매 초마다 1개의 스레드가 실행된다. 50초가 지나면 모든 스레드가 동시에 실행된 상태에서 반복(Loop Count: 10번)하면서 요청을 보내게 되는 조건이다.\n📌 테스트 해볼까?\n이제 본격적으로 테스트를 해보자. \n@DistributedLock 테스트\n{\n  \"id\": \"row:2\"\n}\n하나의 키를 동시에 여러번 테스트하는 것인데 한 키만을 걸었기 때문일까\n\n모든 요청이 동시에 보냈음에도 불구하고 성공률이 100%였다 ㅋㅋㅋ \n\n하나하나 뜯어보자면, \nSamples: 500 → 총 500개의 요청이 전송됨\nAverage: 5006 ms → 모든 요청의 평균 응답 시간이 5006ms (5.006초)\nMedian: 5006 ms → 응답 시간을 작은 순서대로 정렬했을 때 중간 값이 5006ms\n90% Line:    5010 ms    → 응답 시간이 5010ms 이하인 요청이 전체의 90%\n95% Line:    5012 ms    → 응답 시간이 5012ms 이하인 요청이 전체의 95%\n99% Line:    5015 ms    → 응답 시간이 5015ms 이하인 요청이 전체의 99%\nMin: 5001 ms → 가장 빠른 응답 시간이 5001ms\nMax: 5028 ms → 가장 느린 응답 시간이 5028ms\nError %: 0.0% → 오류 없이 100% 성공\nThroughput: 5.0/sec → 초당 평균 5개의 요청을 처리\nReceived KB/sec: 0.86 KB/s → 서버에서 초당 0.86KB 데이터를 받아옴\nSent KB/sec: 1.03 KB/s → 서버로 초당 1.03KB 데이터를 보냄\n평균 응답시간 (Throughput)이 5초인게 아마 코드 상  Thread.sleep(5000) 영향인 듯 싶다. \n사실 어떻게 100% 성공일 수 있지? 설마 락이 안걸리나 싶어서 \n\nlog를 걸어서 봤는데 락이 잘 걸려있는 것을 확인할 수 있었다. \n그렇다면 멀티로 락을 걸었을때는 어떨까?\n@MultiDistributedLock 테스트\n@DistributedLock과 같은 조건으로 진행하였다. \n사실 처음에 테스트 할때는 이것도 성공률이 100%일줄 알았다. \n\n뭐야? 이건 왜 간간히 성공해?? 왜 실패한건 500에러야?\n\n에러 메세지를 확인해보니, 락 거는데 에러가 뜬거였다. \nSingle 락과 Multi 락 왜 같은 조건인데 결과가 다를까??\n✔️ @DistributedLock (Single)\n\n요청마다 하나의 키(row:2 같은 단일 값)만 사용\nwaitTime = 15이므로 락을 못 잡으면 최대 15초까지 대기 + 쓰레드 sleep 5초\n하나의 키만 처리하므로 충돌 가능성이 낮음\n결과적으로 스레드 간 충돌 없이 요청이 순차적으로 처리됨 → 실패율 낮음\n✔️ @MultiDistributedLock (Multi)\n\n여러 개의 키([\"row:2\",\"row:1\",\"row:3\"])를 락으로 사용\n만약 다른 스레드가 row:1을 선점했다면, row:2와 row:3이 잠겨 있어도 락을 얻지 못함\n락을 얻지 못하면 실패 (대기 시간이 지나도 모든 키를 얻지 못하면 실패)\n일부 키만 사용 가능해도 전체가 실패하는 구조 → 충돌 가능성이 급증\n따라서 싱글락과 달리 멀티락에서 에러가 뜨는 것은 동시성 테스트에서 잘 방어를 하고 있다는 뜻이었다. \n참고) 나의 github 코드 : https://github.com/sue4869/lockPractice",
    "reviews": [],
    "syllabus": [],
    "link": "https://velog.io/@sweet_sumin/%EB%B6%84%EC%82%B0%EB%9D%BD-%EC%A0%81%EC%9A%A9%ED%95%98%EA%B8%B0-%EC%8B%A4%EC%A0%84",
    "pubDate": "Wed, 05 Mar 2025 22:44:11 GMT",
    "creator": "Unknown",
    "categories": []
  },
  {
    "id": 13,
    "imageUrl": "",
    "title": "Try The New Toolbox App 2.6 EAP With Remote Development Support",
    "description": "With the latest update, the Toolbox App now supports remote development, allowing you to manage your JetBrains tools and projects both locally and on remote servers. This allows you to connect to cross-platform hosts, including Windows, macOS, and Linux, and use integrated OpenSSH for secure and customizable SSH connections. You can download the latest Toolbox […]",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.jetbrains.com/toolbox-app/2025/03/try-the-new-toolbox-app-2-6-eap-with-remote-development-support/",
    "pubDate": "Thu, 06 Mar 2025 10:45:29 +0000",
    "creator": "Ivan Kuzmin",
    "categories": [
      "jetbrains-toolbox",
      "toolbox-app"
    ]
  },
  {
    "id": 14,
    "imageUrl": "",
    "title": "Visual Studio v17.12 로 생산성을 높이기",
    "description": "No description available",
    "reviews": [],
    "syllabus": [],
    "link": "https://jacking75.github.io/VS_20250307/",
    "pubDate": "Fri, 07 Mar 2025 00:00:00 +0900",
    "creator": "Unknown",
    "categories": []
  },
  {
    "id": 15,
    "imageUrl": "",
    "title": "Google Play 앱 출시 오류 / 계정 세부정보 업데이트 / 대한민국에 거주하는 모든 개발자는 대한민국 법규를 준수하기 위해 Google Play에 추가 정보를 제공해야 합니다.",
    "description": "저는 남의 계정에 앱 올려주다 발생했습니다.\n비공개 테스트 까지 올리려고 하는데 발생했구요\n\n\n우측에 문제 보기 누르시면\n \n발견된 문제 1개\nclose\n검토를 위해 앱을 전송하는 것을 막는 몇 가지 일반적인 문제가 발견되었습니다. 검토를 위해 변경사항을 전송하기 전에 이러한 문제를 해결해야 합니다.\n계정 세부정보 업데이트\n대한민국에 거주하는 모든 개발자는 대한민국 법규를 준수하기 위해 Google Play에 추가 정보를 제공해야 합니다.\n이런 내용이구요\n출시국가랑은 관련 없습니다. 올리는 사람이 한국 사람이면 이걸 증명하라는 뜻입니다.\n \n\n\n버튼 누르시면 개발자 정보 메뉴로 넘어갑니다.\n아래쪽에 보시면 사업자 등록증 번호를 요구 합니다.\n \n\n\n이후 필요한 내용은 \n앱을 출시하려면 사업자등록번호\n인앱을 판매하려면 통신판매업 번호 및 통신판매업 등록 구청 이름 \n(통신판매업자 문서 받아보시면 거기 나옵니다.)\n \n제가 등록했던 방법 글 링크: https://serverdown.tistory.com/815\n\n \n1인개발자 개인사업자 등록에서 앱스토어 런칭까지 01 / 사람 안만나고 인터넷로만 진행가능\n순서1부 - 이글 입니다. 사업자 등록 같은 서류 준비 부분입니다.2부 - Googla play 스토어에 입력해야할 것 (작성중)  사전지식앱스토어에서 인앱을 팔려면 통신판매업자를 등록해야 합니다.통신\nserverdown.tistory.com\n\n \n수익나면 매달 국세청에 올리라고 했던거 같은데 수익이 안나서 그걸 못해봤군요 ㅠㅠ",
    "reviews": [],
    "syllabus": [],
    "link": "http://serverdown.tistory.com/1168",
    "pubDate": "Thu, 6 Mar 2025 17:57:22 +0900",
    "creator": "SIDNFT",
    "categories": [
      "프로그래밍/개발메모",
      "앱개발"
    ]
  }
]