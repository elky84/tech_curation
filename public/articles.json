[
  {
    "id": 1,
    "imageUrl": "",
    "title": "google OAuth2 refresh_token 이 오지 않을때",
    "description": "테스트 하다 프로덕션으로 전환되었는데 문제가 생겼다.\nrefresh_token 만 빠져서 토큰이 오는 것이다. 오지 않는 것이였다.\n이러면 refreshAccessToken() 함수로 access_token 을 갱신할 수 없게된다.\n물론 이 현상은 정상이 아니니 해결해야한다.\n가발자 개정만 문제라면 ...\n https://myaccount.google.com/connections?filters=3,4&hl=ko\n\n \n로그인 - Google 계정\n이메일 또는 휴대전화\naccounts.google.com\n\n여기로 가서 해당 계정의 프로젝트이름을 검색해서\n상세정보보기 -> 삭제 를 진행하고 다시 인증절차를 밟으면 되겠다.\n유저의 일부가 이러고 있다면 ....\n구글 클라우드의 OAuth2 클라이언트를 지우고 새로 등록해야할지도 모르겠다.\n \n질문의 원본\nhttps://stackoverflow.com/questions/52600586/cant-get-refresh-token-for-google-api-node-js\n\n \ncan't get refresh token for google api. Node js\nI've got an Apps Script script that I am running remotely through Google's API. When I go to the link it gives me for the code to retrieve the access token, it says that the file requested does not...\nstackoverflow.com\n\n \n구글은 언제나 이상해",
    "reviews": [],
    "syllabus": [],
    "link": "http://serverdown.tistory.com/1236",
    "pubDate": "Sun, 30 Mar 2025 05:26:15 +0900",
    "creator": "이건개발",
    "categories": [
      "프로그래밍/개발메모",
      "OAuth2",
      "구글"
    ]
  },
  {
    "id": 2,
    "imageUrl": "",
    "title": "node.js 을 이용한 동영상 해상도 변경 프로그램 - 샘플코드 있음 / ffmpeg / CURSOR",
    "description": "커서를 미루다 미루다 ...\n샤나 인코더 쓰다가 UI 만지기도 귀찮고 \n720p 보다 큰건 720p \n720p 보다 작은건 480p 로 변환해야하는 조건이 있어서 프로그램으로 가능한거 싶어서 \nCURSOR 를 이용해 짜달라고 했다. \n그리곤 성공했습니다. 잘되네요 (충격) \n이거 직접 찾아서 시행착오를 거치려면 몇시간에서 몇일은 써야하는데 10분만에 되었습니다. \n배울 필요가 없다니 놀랍습니다. \n\n이글 읽기도 귀찮으신분은  이걸로\n샘플코드 링크: https://drive.google.com/file/d/1JkNXjw7f03rtBN5ncuk7E6qh57g0A0OQ/view?usp=sharing\n다운로드 하시고 \nnpm i \n설치 하시고 \nrun.bat \n싱행 \n\n\n필수 모듈 설치\nnpm i fluent-ffmpeg\n\n\nindex.js 코드\nconsole.log('Node.js 프로젝트가 시작되었습니다!'); \n\nconst ffmpeg = require('fluent-ffmpeg'); \nconst path = require('path'); \n// 입력 파일 경로와 출력 파일 경로 설정 \nconst inputFile = process.argv[2] || 'input.mp4'; \nconst outputFile = path.join('output', `resized_${path.basename(inputFile)}`); \nconst targetWidth = process.argv[3] || 1280; // 기본 해상도 1280x720 \nconst targetHeight = process.argv[4] || 720; \n// 출력 디렉토리 생성 \nconst fs = require('fs'); \nif (!fs.existsSync('output')) { \n    fs.mkdirSync('output'); \n} \nconsole.log('동영상 해상도 변환을 시작합니다...'); \nconsole.log(`입력 파일: ${inputFile}`); \nconsole.log(`변환 해상도: ${targetWidth}x${targetHeight}`); \nffmpeg(inputFile) \n    .size(`${targetWidth}x${targetHeight}`) \n    .on('progress', (progress) => { \n        // 진행률 표시 \n        const percent = Math.round(progress.percent); \n        process.stdout.write(`\\r진행률: ${percent}% | 처리된 프레임: ${progress.frames} | 현재 시간: ${progress.timemark}`); \n    }) \n    .on('end', () => { \n        console.log('\\n변환이 완료되었습니다!'); \n        console.log(`출력 파일: ${outputFile}`); \n    }) \n    .on('error', (err) => { \n        console.error('\\n오류가 발생했습니다:', err); \n    }) \n    .save(outputFile);  \n\n싱행 명령어 \nnode index.js 원본영상 가로 세로 \n하면 output 폴더에 영상이 변환됩니다. \n예) node index.js a.mp4 1280 720 \n\n이제 이 프로그램을 좀 수정하면대량의 동영상 파일 해상도 관리 프로그램을 만들 수 있을 것입니다. \n저는 ffmpeg 가 설치되어있어서 문제가 없었는데 \nffmpeg 프로그램이 필요할 수 잇습니다. \n\n\nffmpeg 실행파일 설치 방법\n여기서  https://www.gyan.dev/ffmpeg/builds/\nffmpeg-release-full.7z 파일을 다운로드 \n환경변수에 bin 폴더를 걸어야합니다. \n(이 방법을 설명해야하나....) \n환경 변수 PATH 등록이 완료되면\n\n\n아무 폴더폴더에서 콘솔창에 ffmpeg 커맨드를 입력하면 동작이 됩니다. \n\n\n커서 AI 코딩 후기\n전혀 모르는 분야에 대한 프로그램 요구 했을때 \n검색해서 샘플코드를 찾고 이해하는 것보다 훨씬 수월하게 진행할  수 있었습니다. \n충격적으로 시간이 절약되었습니다. \n\n\n\nAI 코딩에대한 영상\n영상: https://www.youtube.com/watch?v=AYaQ85gPaV0\n\n\n\n은 코알누",
    "reviews": [],
    "syllabus": [],
    "link": "http://serverdown.tistory.com/1238",
    "pubDate": "Sun, 30 Mar 2025 14:21:04 +0900",
    "creator": "이건개발",
    "categories": [
      "프로그래밍/개발메모"
    ]
  },
  {
    "id": 3,
    "imageUrl": "",
    "title": "VS Code C++ Extension Updates: 4x Faster Colorization & 3.5x Faster Project Startup",
    "description": "In the latest releases of the C++ Extension in Visual Studio Code, we have focused on performance improvements and stability. A fast, responsive, and reliable development environment is essential for maintaining productivity, especially in large and complex C++ projects. These updates include many incremental optimizations that collectively speed up the time from opening a C++ […]\nThe post VS Code C++ Extension Updates: 4x Faster Colorization & 3.5x Faster Project Startup appeared first on C++ Team Blog.",
    "reviews": [],
    "syllabus": [],
    "link": "https://devblogs.microsoft.com/cppblog/vs-code-c-extension-updates-4x-faster-colorization-3-5x-faster-project-startup/",
    "pubDate": "Tue, 25 Mar 2025 22:23:36 +0000",
    "creator": "Alexandra Kemper",
    "categories": [
      "C++",
      "performance",
      "Visual Studio Code"
    ]
  },
  {
    "id": 4,
    "imageUrl": "",
    "title": "토스, ‘2025 토스 커뮤니티 대규모 채용’ 실시",
    "description": "금융을 넘어 삶을 바꾸는 여정, 이제 당신이 뛰어들 차례",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.toss.im/article/tosscareer",
    "pubDate": "Tue, 25 Mar 2025 02:00:00 GMT",
    "creator": "Unknown",
    "categories": []
  },
  {
    "id": 5,
    "imageUrl": "",
    "title": "게임과 음악의 경계가 사라지면서 벌어진 일들",
    "description": "게임 속에서 콘서트를 열고, 싱글을 발매하고, 팬덤을 만드는 시대",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.toss.im/article/fandustry-05",
    "pubDate": "Wed, 26 Mar 2025 09:00:00 GMT",
    "creator": "Unknown",
    "categories": []
  },
  {
    "id": 6,
    "imageUrl": "",
    "title": "다이얼로그 요소와 모달",
    "description": "개인적으로는 alert와 confirm과 같은 시스템 모달을 좋아하지만 이걸 그대로 쓰는 제품은 거의 없다. 어떻게든 디자인 아이덴티티를 적용하기위해 기존의 HTML 요소로 비슷하게 만드는 방법을 사용한다. 보기는 좋지만 시스템에서 제공하는 접근성이나 인터랙션을 비슷한 수준으로 만드려면 노력을 많이 해야 한다. 이러한 어려움을 없애기 위해서 dialog 요소와 관련 API가 나왔다.\n\r\n\r\n대화 상자를 의미하는 dialog 요소는 단독으로 사용하면 그다지 인상적이지 않다. 기본적으로 화면에 나오지 않고 open 속성을 줘야 화면에 나오게 된다. 사용한 위치에 마치 절대위치를 지정한 것 처럼 다른 콘텐츠를 덮는 사각 박스가 나온다. 좌우 정렬만 가운데로 된다.\n\r\n\r\n<div style=\"background: #ccc; height: 3em;\">위 박스</div>\r\n\r\n<dialog open>\r\n\t이게 바로 dialog\r\n</dialog>\r\n\r\n<div style=\"background: #ddd; height: 3em;\">아래 박스</div>\n\r\n\r\n\r\n\t\n위 박스\n\r\n\r\n\t\r\n\t\t이게 바로 dialog\r\n\t\r\n\r\n\t\n아래 박스\n\r\n\r\n\r\n다이얼로그를 동적으로 열고 닫으려면 show 또는 showModal 메서드를 사용하면 된다. show는 다이얼로그를 보여주기만 하고 모달처럼 동작하지는 않는다. showModal은 뒤 배경과의 인터랙션을 막아준다. 보통 딤(dim)이라고 하는 어두운 배경(backdrop)도 깔아준다. 닫을때는 close를 사용한다.\n\r\n\r\n<button onclick=\"document.getElementById('dialog-show-modal').showModal()\">open modal dialog</button>\r\n\r\n<dialog id=\"dialog-show-modal\">\r\n\t<button onclick=\"document.getElementById('dialog-show-modal').close()\">close</button>\r\n</dialog>\n\r\n\r\n\n\r\n\topen modal dialog\r\n\r\n\t\r\n\t\tclose\r\n\t\r\n\n\r\n\r\n다이얼로그와 서식을 같이 사용하면 내재되어 있는 좀 더 풍부한 기능을 사용할 수 있다. 다이얼로그 안에 method가 dialog인 form을 사용하면 그 안의 버튼을 닫기 버튼으로 사용할 수 있다. 닫는 버튼에 value를 설정하면 그 값이 모달의 returnValue로 설정이 되어서 버튼이 여러개 있어도 어느 버튼을 눌러서 닫았는지 파악할 수 있다. close 메서드에 스트링을 인자로 넘겨도 동일하게 returnValue 값을 설정할 수 있어서 사용자가 다이얼로그 안의 컨트롤에 설정한 값을 알 수 있다.\n\r\n\r\n<button onclick=\"document.getElementById('dialog-with-form').showModal()\">\r\n\topen dialog with form\r\n</button>\r\n\r\n<dialog id=\"dialog-with-form\">\r\n\t<form method=\"dialog\">\r\n\t\t<button value=\"Banana\">Banana</button>\r\n\t\t<button value=\"Apple\">Apple</button>\r\n\t\t<button value=\"Tomato\">Tomato</button>\r\n\t</form>\r\n</dialog>\r\n\r\n<script>\r\n\tdocument.getElementById('dialog-with-form').addEventListener('close', e => {\r\n\t\tconst output = document.getElementById('dialog-with-form-output');\r\n\t\toutput.innerHTML = e.target.returnValue;\r\n\t});\r\n</script>\r\n\r\n<p>returnValue: <output id=\"dialog-with-form-output\"></output></p>\n\r\n\r\n\r\n\t\r\n\t\topen dialog with form\r\n\t\r\n\r\n\t\r\n\t\t\r\n\t\t\tBanana\r\n\t\t\tApple\r\n\t\t\tTomato\r\n\t\t\r\n\t\r\n\r\n\t\r\n\t\tdocument.getElementById('dialog-with-form').addEventListener('close', e => {\r\n\t\t\tconst output = document.getElementById('dialog-with-form-output');\r\n\t\t\toutput.innerHTML = e.target.returnValue;\r\n\t\t});\r\n\t\r\n\r\n\t\nreturnValue: \n\r\n\r\n\r\n다이얼로그가 열려 있을 때에는 배경 콘텐츠와 인터랙션이 되지 않는다. 다이얼로그를 열면 포커스가 다이얼로그로 왔다가 닫을때 다시 이전 콘텐츠로 이동하는 등 시스템에서 제공하는 접근성 기능을 공짜로 사용할 수 있다. ESC키를 눌러서 다이얼로그를 닫는 기능도 제공된다. 한가지 많이 아쉬운 점은 다이얼로그를 열었을 때 배경이 스크롤되는 동작을 막아주지는 않는다.\n\r\n\r\n다이얼로그가 열릴 때 애니메이션을 적용하기 위해서는 조금 까다로운 작업을 해야 한다. 기본적으로 display: none이나 block으로 작동하고 상위 레이어에서 바로 없어지기 때문에 애니메이션을 적용하기가 힘들다. 결론부터 얘기 하자면 transition-behavior: allow-discrete와 overlay를 트랜지션 해주면 닫을때에도 애니메이션을 보여줄 수 있다. 이 속성이 아직 모든 브라우저에서 작동하지 않기 때문에 파이어폭스와 사파리에서는 애니메이션이 매끄럽게 나오지 않는다.\n\r\n\r\n#dialog-styled,\r\n#dialog-styled::backdrop {\r\n\ttransition: display 0.2s allow-discrete, overlay 0.2s allow-discrete;\r\n\tanimation: hide-modal 0.2s forwards;\r\n}\r\n#dialog-styled {\r\n\tbackground: #fff;\r\n\tborder: 1px solid #ccc;\r\n\tborder-radius: 12px;\r\n\tpadding: 16px;\r\n\twidth: 24em;\r\n\tbox-shadow: 0 10px 25px rgba(0, 0, 0, 0.2);\r\n}\r\n#dialog-styled::backdrop {\r\n\tbackground: rgba(0, 0, 0, 0.4);\r\n}\r\n#dialog-styled[open],\r\n#dialog-styled[open]::backdrop {\r\n\tanimation: show-modal 0.2s forwards;\r\n}\r\n\r\n@keyframes show-modal {\r\n\t0% {\r\n\t\topacity: 0;\r\n\t}\r\n\t100% {\r\n\t\topacity: 1;\r\n\t}\r\n}\r\n@keyframes hide-modal {\r\n\t0% {\r\n\t\topacity: 1;\r\n\t}\r\n\t100% {\r\n\t\topacity: 0;\r\n\t}\r\n}\n\r\n\r\n<button onclick=\"document.getElementById('dialog-styled').showModal()\">open styled dialog</button>\r\n\r\n<dialog id=\"dialog-styled\">\r\n\t<b>Styling and Animation for the dialog Element</b>\r\n\t<p>The style is straightforward. The animation should use modern CSS features like allow-discrete and overlay.</p>\r\n\t<button onclick=\"document.getElementById('dialog-styled').close()\">close</button>\r\n</dialog>\n\r\n\r\n\r\nconst css = document.createElement('style');\r\ncss.innerHTML = `\r\n#dialog-styled,\r\n#dialog-styled::backdrop {\r\n\ttransition: display 0.2s allow-discrete, overlay 0.2s allow-discrete;\r\n\tanimation: hide-modal 0.2s forwards;\r\n}\r\n#dialog-styled {\r\n\tbackground: #fff;\r\n\tborder: 1px solid #ccc;\r\n\tborder-radius: 12px;\r\n\tpadding: 16px;\r\n\twidth: 24em;\r\n\tbox-shadow: 0 10px 25px rgba(0, 0, 0, 0.2);\r\n}\r\n#dialog-styled::backdrop {\r\n\tbackground: rgba(0, 0, 0, 0.4);\r\n}\r\n#dialog-styled[open],\r\n#dialog-styled[open]::backdrop {\r\n\tanimation: show-modal 0.2s forwards;\r\n}\r\n\r\n@keyframes show-modal {\r\n\t0% {\r\n\t\topacity: 0;\r\n\t}\r\n\t100% {\r\n\t\topacity: 1;\r\n\t}\r\n}\r\n@keyframes hide-modal {\r\n\t0% {\r\n\t\topacity: 1;\r\n\t}\r\n\t100% {\r\n\t\topacity: 0;\r\n\t}\r\n}`;\r\ndocument.getElementsByTagName('head')[0].appendChild(css);\r\n\r\n\r\n\n\r\n\topen styled dialog\r\n\r\n\t\r\n\t\tStyling and Animation for the dialog Element\r\n\t\t\nThe style is straightforward. The animation should use modern CSS features like allow-discrete and overlay.\n\r\n\t\tclose",
    "reviews": [],
    "syllabus": [],
    "link": "https://hyeonseok.com/blog/934",
    "pubDate": "Sun, 30 Mar 2025 18:22:21 GMT",
    "creator": "Unknown",
    "categories": []
  },
  {
    "id": 7,
    "imageUrl": "",
    "title": "딥시크(deep seek) 오픈소스 코드 및 구조 분석하기",
    "description": "앞서 AI에이전트 오픈 미노스를 분석해 보았는 데, 내친김에 그 동안 말많았던 딥시크(deep seek)를 분석해 보기로 한다. 개인적으로 언론의 기사를 잘 믿지는 않는다. 홍보성 퍼나른 기사가 많기도 하고, 특히 테크분야에서도 약장사분들? 많아, 어디까지 진실인지 아닌지 모르기 때문이다. 정말 대단한지, 아니면 지재권 완전 무시하고 기술 탈취?해 싼 제품 잘 만드는 중국 방식으로 개발된 것인지 알려진 자료에 기반해 팩트 확인해 보고자 한다.\n\n\n\n\n딥시크 (theconversation.com, 2025)\n\n\n참고로, 마누스 오픈소스에 관심 있다면 다음 링크를 참고한다. \n\n오픈 마누스(manus) AI 에이전트 설치, 사용 및 구조 분석하기\n\n\n\n딥시크 분석 준비\n다음 링크를 방문해 코드를 클론한다.\n\ndeepseek-ai/DeepSeek-V3\n\n\n\n\n\n터미널에서 다음 명령을 실행한다. \ngit clone https://github.com/deepseek-ai/DeepSeek-V3.git\n\n\n폴더 및 파일 구조 분석 \nvscode를 띄워 보니 폴더 구조는 다음과 같다. \n\n  - workflows: 워크플로우 관련 폴더\n  - inference: 하위 폴더\n    - configs: 설정 파일 폴더\n    - convert.py: Python 파일, 4KB\n    - fp8_cast_b16f.py: Python 파일, 5KB\n    - generate.py: Python 파일, 8KB\n    - kernel.py: Python 파일, 9KB\n    - model.py: Python 파일, 8KB\n    - requirements.txt: 텍스트 파일, 1KB\n\n\n\n\n공개된 소스 코드를 보니 굳이 실행을 위한 패키지 설치는 할 필요 없을 것 같다. 일단, 오픈소스가 아니다. 단순히, inference 추론 코드만 공개되어 있다(어그로). 오픈소스라면, 최소한, train 학습 코드와 기본 데이터셋 정도는 공개되어야 한다(언론이 왜 오픈소스라 난리였는지 사실 이해가 안되는...). \n\n\n코드는 대부분 트랜스포머 구조를 그대로 사용한다. 트랜스포머스는 구글에서 이미 2017년 개발 공개된 LLM 모델 학습 메커니즘이다. 딥시크에서 사용한 상세한 기술을 알고 싶다면, 다음 링크를 참고하길 바란다.\n\n어텐션 기반 트랜스포머 딥러닝 모델 이해, 활용 사례 및 파치토치를 통한 간단한 사용방법 소개\n딥러닝 모델 트랜스포머 인코더 핵심 코드 구현을 통한 동작 메커니즘 이해하기\n트랜스포머 디코더 핵심 코드 구현을 통한 동작 메커니즘 이해하기\nSparse Mixture of Experts Language Model\n\n\n\n소스 코드 분석\n공개된 코드는 주로 추론을 위해 딥시크 측에서 공개한 학습된 가중치 모델 파일을 로딩해 사용하기 위한 model.py, 양자화로 성능 가속을 위한 fp8_cast_bf16.py, 질의 프롬프트에 대한 모델 출력을 생성하는 generate.py 정도가 분석할 필요가 있어 보인다. \n\n\nmodel.py 분석\n일단, 사용하는 라이브러리 대부분이 미국 빅테크 기업 혹은 연구소에서 개발된 것들을 임포트에 사용하고 있다. 이 분야에서 모르면 간첩인 pytorch, 심지어 triton은 NVIDIA GPU 가속 최적화를 위해 사용하는 라이브러리를 직접 사용한다(NVIDIA 종속적). \n\n\n모델의 전체 구조는 트랜스포머를 그대로 따르며, 이미 오픈소스 공개된 코드에 나오는 키워드도 다음처럼 그대로 사용하고 있다.\n\n\n\nmodel.forward를 확인해보자. 일반적인 트랜스포머스 forward 루틴으로 보여진다. \n\n    def forward(self, tokens: torch.Tensor, start_pos: int = 0):\n        seqlen = tokens.size(1)\n        h = self.embed(tokens)  # 1) 입력 임베딩\n        freqs_cis = self.freqs_cis[start_pos:start_pos+seqlen]  # 2) # 위치 인코딩\n        mask = None\n        if seqlen > 1:              # 3) 마스킹\n            mask = torch.full((seqlen, seqlen), float(\"-inf\"), device=tokens.device).triu_(1)\n        for layer in self.layers:   # 4) 트랜스포머스 레이어 실행 계산\n            h = layer(h, start_pos, freqs_cis, mask)\n        h = self.norm(h)[:, -1]   # 5) 출력 정규화\n        logits = self.head(h)     # 6) 로짓 계산\n        if world_size > 1:\n            all_logits = [torch.empty_like(logits) for _ in range(world_size)]\n            dist.all_gather(all_logits, logits)\n            logits = torch.cat(all_logits, dim=-1)\n        return logits\n\n\n이 함수는 입력 토큰을 받아 로짓(예측값)을 계산하는 역할을 한다. 예측값은 미리 준비된 사전에서 예측된 단어를 선택할 때 역할을 한다(입력 토큰에 대한 다음 토큰 예측 생성과정). 주요 동작은 다음과 같다.\n\nembed: 입력 임베딩 처리: 입력으로 제공된 토큰 텐서를 임베딩 레이어를 통해 변환하여 초기 입력 표현을 생성한다. \nfreqs_cis: 로터리 임베딩 계산:  주파수 정보를 담고 있는 로터리 임베딩 텐서를 시퀀스 길이에 맞게 선택하여, 위치 정보를 모델에 제공한다. 위치임베딩이란 기법도 이미 트랜스포머스 논문(Google, 2017)에 구현된 것이다.\nmask: 시퀀스 길이가 1보다 클 경우, 미래 정보가 영향을 미치지 않도록 상삼각형 형태의 마스크를 생성한다. 마스크는 모델이 언어 생성 시 현재 시점 이전의 정보만을 활용하게 한다.\nTransformer 레이어 통과: 모델 내부의 여러 Transformer 레이어를 입력 데이터가 순차적으로 통과하며, 각 레이어에서 입력 표현이 갱신된다. \nnorm: 출력 정규화 및 최종 표현 추출. 마지막 Transformer 레이어의 출력을 정규화하고, 시퀀스의 마지막 토큰에 해당하는 표현을 추출한다. \nlogits: 로짓 계산. 추출된 최종 표현을 출력 레이어(헤드)에 전달하여 로짓, 즉 예측값을 계산한다. 이는 각 토큰에 대한 다음 단어 또는 출력값의 확률 분포를 나타낸다.\n\n결과적으로, 이 메서드는 입력 토큰 시퀀스를 기반으로 각 토큰에 대한 예측값을 반환하며, 이는 주로 언어 모델링 및 자연어 처리 작업에 활용된다.\n\n\n모델의 전체 구조는 다음과 같다. 대부분 파이토치 기반 트랜스포머스 코드(이미 많이 공개된 코드 조각)를 사용한다(딥시크 처음 언론 보도가 실제로 얼마나 차이가 있는 지 확인할 수 있음).\n\n\n딥시크-V3 모델 구조(UML)\n다만, 실행 속도 등 최적화를 위해 병렬처리, torch.einsum 함수를 이용해 GPU 연산을 직접 이용해 트랜스포머 어텐션 모델 QKV 코사인 유사도 계산하는 등의 노력을 하고 있다(이 또한 이미 알려진 것).\n\n\n토큰 시퀀스 임베딩 벡터 간 유사도 스코어 계산 및 학습하는 부분(일부. 트랜스포머스 모델의 전형적인 루틴임. 여기서 bshd는 batch, source seqnce, heads, feature demension 의 약자로 입력 텐서의 모양-차원을 정의함)\n\n\nkernel.py 분석\n이 모듈은 주로 성능과 관련된 양자화를 다룬다. triton 라이브러리를 사용해 주어진 텐서를 양자화하여, 32비트 실수 연산을 8비트 실수 연산으로 처리할 수 있게 한다. 8비트 텐서 실수 연산을 위한 함수도 같이 구현되어 있다. 예를 들어, 다음 fp8_gemm 함수는 8비트 양자화된 a, b 텐서를 입력받아 행렬곱한 후 c를 리턴한다.\n\n\nconvert.py 분석\n이 모듈은 모델 파일 포맷을 주어진 옵션에 맞게 단순히 체크포인트 파일로 변환하는 역할을 한다. 복잡한 내용은 별로 없어 상세 설명은 생략한다.\n\n\nconfigs 파일 분석\n이 폴더 내 모델의 구조를 정의하는 주요 변수가 정의되어 있다. 예를 들어, config_16B.json 파일은 다음과 같이 정의된다. \n\n\n의미는 다음과 같다. \n\n1. 모델 구조  \n   - vocab_size: 어휘 크기 (102,400).  \n   - dim: 임베딩 차원 (2048).  \n   - inter_dim: FFN의 확장 차원 (10,944).  \n2. MoE 관련  \n   - n_routed_experts: 총 Expert 수 (64).  \n   - n_activated_experts: 활성화 Expert 수 (6).  \n   - moe_inter_dim: MoE Expert의 내부 FFN 차원 (1,408).  \n3. Attention 관련  \n   - n_layers: Transformer 레이어 수 (27).  \n   - n_heads: Attention Head 수 (16).  \n   - kv_lora_rank: 키/값 벡터의 LoRA 랭크 (512).  \n   - qk_nope_head_dim: NOPE 기반 헤드 차원 (128).  \n   - qk_rope_head_dim: RoPE 기반 헤드 차원 (64).  \n4. 기타  \n   - mscale: 모델 안정성을 위한 스케일 값 (0.707).  \n\n분석해 본 결과, 사실 LLM에서 모델 구조, 추론 구현 부분 및 양자화 모듈만 대부분 공개되어 있다는 것을 알 수 있다. \n\n\n최소한 데이터셋 모듈이라도 공개되어야 어떤 식으로 데이터를 학습했는지 확인할 수 있지만, 이런 중요 모듈은 공개되어 있지 않아, 딥시크-V3는 오픈소스를 공개했다고 말하기 어렵다(가중치와 모델 모듈만 오픈. 이건 reddit에서도 까이고 있는데, 그냥 오픈웨이트 open weights 모델 코드임).\n\n\n더 파보기\n오픈소스라기에는 좀 실망이라, 무언가 더 없는 지 공개된 자료들을 파보기로 한다. 일단, 딥시크 개발사 github에서 최근 주목받고 있는 프로젝트만 다음처럼 정렬해본다.\n\n\n이 중 체크한 부분이 먼가 있는 듯 하여, 들어가 확인해 본다. \n\n\nMIT 라이센스라 표시만 되어 있지, 코드가 없음\n\n\n딥시크 기반 코더는 평가, 데모 코드만 있고, 파인튠은 학습 데이터셋 제공 없음 \n\n평가 코드만 있음(MIT 라이센스 표시만. 오픈소스? 무슨 의미가?)\n\n딥시크-V3 학습모델(가중치파일) 공개된 부부(허깅페이스)\n더 파보았지만, 딥시크에서 주장하는 것은 오픈소스가 아닌 오픈웨이트 모델에 더 가까워보인다. 세계적인 홍보와 언론의 관심에 비해 무늬만 MIT라이센스 오픈소스가 아닌지 의문이다.\n\n마무리\n좀 시간을 내어 분석한 후, 확인 사살한 것은 다음과 같다. \n\n언론에서 말하는 것과는 상당한 차이가 있는 딥시크 기술 오픈소스였다. 대부분 이미 개발된 오픈소스를 가져다 쓴 것으로 보인다. 앞에 언급한 몇몇 성능 최적화 부분은 좋은 접근인 것이나, 메타(페북)의 라마(Llama)가 공개한 기술에 비하면 비교할 만한 것이 아니다.\n중국은 확실히 홍보(x10배)에 천재적인 능력(약팔이)이 있다(진심으로). \n중국이 잘하는 선진국(미국) 기술 가져와 자국것으로 포장해 저가로 파는 기술은 세계 최고다. \n\n의문점은 한국 언론에서 다음과 같이 패닉성 기사를 쓸 때, 왜 남이 말한 것 받아 만 쓰고 팩트 확인하지 않았냐는 것인데... 좀 생각해보니 국내 딥시크 기사는 관련 컨텐츠를 해외에서 퍼온 검증도 안된 글을 기사로 정리한 것으로 이해된다. 사실, 첨단 기술을 팩트 체크할 리소스가 있는 언론이 많지는 않다고 생각한다. 그럼에도 파급격있는 채널은 뉴스를 전할때 항상 팩트 확인하려는 노력이 필요하다.\n\n\n패닉성 딥시크 언론 보도(연합, 2025.1.27, 뉴스튜데이, 2025.3.28)\n\n\n자극적 기사들로 얼마 전 정부 국회는 패닉되고, 급하게 만든 인공지능 진흥전략이 판을 치게 된 트리거 역할을 했다. 여론은 인공지능분야도 우리가 중국에 뒤쳐졌다는 것을 확인하는 계기는 되었다. 긍정적 효과도 있었다고 생각되나, 부작용도 있다. 예를 들어,불필요한 일들이 벌어지고(갑작스런 GPU전수조사? 등), 갑작스런 대규모 GPU 센터 개발 계획이 발표되고, 이로 인해 세금이 비과적으로 계획 투입되고, .. 이상한 방향으로 국가 첨단기술 연구개발 전략이 설정되고... 대규모 세금이 투입되지 않을 까라는 생각을 들게 만든다.\n\n\n이 글에서 딥시크가 오픈소스 맞는지(거짓), 정말 중국 독자 기술로 개발했는지(거짓), 자국 GPU 사용해 개발했는 지(거짓. 기껏 추론 부분만 Google TPU같이 NPU 사용했을 가능성), 기술적 개선이 있었는지(성능 최적화 부분은 약간 인정), 정말 공개한 것은 무엇인지(모델만. 오픈웨이트) 등의 질문을 확인해 보았다. \n\n\n이 상황이면, GPT 학습 데이터를 증류해(카피해) 모델을 학습했다는 것이 더 신빙성 있어 보인다(가성비있게 실리콘밸리 테크 기술을 카피해 싸게 소프트웨어를 개발했다는 쪽이 더 맞는 듯. 물론 이것도 아무나 할 수 있는 건 아니다). 좀 더 시간이 있으면, 허깅페이스에 공개된 내용을 분석할 계획이다.\n\ndeepseek-ai/DeepSeek-V3, huggingface\n\n\n\n레퍼런스\n\nDeepSeek-V3\nWhy DeepSeek V3 is considered open-source? : r/LocalLLaMA\nThe Triton Inference Server provides an optimized cloud and edge inferencing solution\nIntroduction - Triton documentation\ndeepseek-ai/DeepSeek-V3\nOpenAI says DeepSeek ‘inappropriately’ copied ChatGPT – but it’s facing copyright claims too\nMixture of Experts\nSparse Mixture of Experts Language Model\nOpenness in Language Models: Open Source vs Open Weights vs Restricted Weights\n中 AI 딥시크, 챗GPT 제치고 美앱스토어 1위…실리콘밸리 충격, 연합뉴스\n[거꾸로 읽는 경제] 중국 딥시크 V3모델 출시\n딥시크, AI 모델 V3 업데이트 버전 공개",
    "reviews": [],
    "syllabus": [],
    "link": "http://daddynkidsmakers.blogspot.com/2025/03/deep-seek.html",
    "pubDate": "2025-03-30T03:52:00.000Z",
    "creator": "Unknown",
    "categories": []
  },
  {
    "id": 8,
    "imageUrl": "",
    "title": "A Survey for JetBrains IDE Plugin Developers",
    "description": "If you develop plugins for JetBrains IDEs, there is a good chance we have already met on the JetBrains Platform Slack, answered your questions in the plugin developer forum, or provided the IntelliJ Platform documentation you have read. Today, the IntelliJ Platform SDK team needs your help to gather feedback that will shape the future […]",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.jetbrains.com/platform/2025/03/a-survey-for-jetbrains-ide-plugin-developers/",
    "pubDate": "Fri, 28 Mar 2025 00:39:23 +0000",
    "creator": "Patrick Scheibe",
    "categories": [
      "plugin-development",
      "intellij",
      "marketplace",
      "survey",
      "intellij-platform"
    ]
  },
  {
    "id": 9,
    "imageUrl": "",
    "title": "CURSOR 리뷰 / 유니티 로 폴가이즈 만들기 도전 / 유니티 로 폴가이즈 만들기 도전",
    "description": "영상: https://www.youtube.com/watch?v=4OgU0f9N0jo\n\n\n\n유니티로 도전하는 영상입니다.\n폴가이즈를 만들어 달라고 했고\n멀티플레이 게임으로 만들려고 하네요\n너무 방대해서 그런지 실패합니다.\n어마어마하게 만들긴하는데\n제대로 동작은 안되었다고 합니다.\n \n총평 \n코파일럿 보다 좋다.\n명령을 잘 내려야 할것이다.\n좀 더 써봐야겠다.\n \n성장 더하고 오라는 뜻인거 같기도 하군요",
    "reviews": [],
    "syllabus": [],
    "link": "http://serverdown.tistory.com/1240",
    "pubDate": "Mon, 31 Mar 2025 04:24:22 +0900",
    "creator": "이건개발",
    "categories": [
      "프로그래밍/개발메모",
      "cursor"
    ]
  },
  {
    "id": 10,
    "imageUrl": "",
    "title": "오픈 마누스(manus) AI 에이전트 설치, 사용 및 구조 분석하기",
    "description": "한동안 회사 일 때문에 미뤄두었던, 딥시크(DeekSeek)와 더불어 많이 많은 마누스(manus.im)에서 영감받아 개발된 오픈마누스(open manus) 오픈소스 AI 에이전트를 설치, 사용 및 분석한다. 오픈마누스는 MetaGPT란 이름으로 활동 중인 중국인 개발자가 공개한 AI에이전트이다. 개발자는 오픈마누스가 연결된 다양한 도구들을 LLM으로 조율하고, 실행할 수 있고 주장하고 있다. 깃허브 등에 설명된 오픈 마누스는 다음과 같은 기능을 지원한다.\n\n로컬에서 AI 에이전트 실행\n여러 도구 및 API 통합: 외부 API, 로컬 모델 및 자동화 도구를 연결, 호출\n워크플로우 사용자 지정: AI가 복잡한 다단계 상호 작용을 효율적으로 처리\n여러 LLM 지원: LLaMA, Mistral 및 Mixtral과 같은 인기 있는 개방형 모델 모델과 호환\n자동화 향상: 내장 메모리 및 계획 기능을 통해 OpenManus는 코딩, 문서 처리, 연구 등을 지원\n\n다음 그림은 이 에이전트가 지원하는 기능 중 일부이다. \n\n\nprompt: Create a basic Three.js endless runner game with a cube as the player and procedurally generated obstacles. Make sure to run it only in browser. If possible also launch it in the browser automatically after creating the game.\n\n오픈 마누스는 이전 중국에서 개발된 마누스의 관심을 오픈소소로 옮겨지는 데 성공했다. 오픈 마누스는 현재 github에서 40.6k란 매우 높은 좋아요 관심을 받고 있다. \n\n\n오픈 마누스(현재 시점. 40.6k stars)\n\n\n\n개인적으로 오픈마누스에 대한 관심도가 높았던 것은, 구현된 기술보다는 에이전트 분야에서 크게 알려진 마누스에 대한 관심, 오픈소스 버전의 AI에이전트 코드 공개가 더 크게 작용했다고 생각한다. 이제 설치 사용해 보고, 성능 품질을 확인해 보자. 그리고, 코드 실행 메커니즘을 분석해 본다. \n\nOpenManus: No fortress, purely open ground. OpenManus is Coming.\n\n\n\n\n\n\n오픈마누스 설치\n개발환경은 이미 컴퓨터에 NVIDIA, CUDA, PyTorch 등이 설치되어 있다고 가정한다. 이제, 다음 명령을 터미널에서 실행해 설치한다.\n\nconda create -n open_manus python=3.12\nconda activate open_manus\n\ngit clone https://github.com/mannaandpoem/OpenManus.git\ncd OpenManus\npip install -r requirements.txt\nplaywright install\n\n\n오픈마누스가 설치하는 패키지를 보면, 많은 경우, 기존에 잘 만들어진 LLM, AI Agent 라이브러리를 사용하는 것을 알 수 있다. 여기서 사용하는 주요 라이브러리는 다음과 같다.\n\npydantic, openai, fastapi, tiktoken, html2text, unicorn, googlesearch-python, playwright, docker\n\nconfig/config.toml 설정 파일을 수정한다. api_key에 OpenAI의 API 키 등을 입력한다(만약, API 키 유출 등이 불안하다면, Ollama 오픈소스 LLM 모델로 설정한다).\n# Global LLM configuration\n\n[llm]\nmodel = \"gpt-4o\"\nbase_url = \"https://api.openai.com/v1\"\napi_key = \"sk-...\"  # Replace with your actual API key\nmax_tokens = 4096\ntemperature = 0.0\n\n\n# Optional configuration for specific LLM models\n[llm.vision]\nmodel = \"gpt-4o\"\nbase_url = \"https://api.openai.com/v1\"\napi_key = \"sk-...\"  # Replace with your actual API key\n\n\n실행\n\n일단, 예제를 간단히 실행해 본다. \npython main.py\n\n\n적절한 프롬프트를 입력해 본다. \ncreate PDF file about BIM(building information modeling). \n\n\n마누스는 이 프롬프트에 응답해, LLM에 입력하여, 마누스에 등록된 도구를 호출하는 정보와 스크립트를 생성한다. 그리고, 이를 통해 각 도구들을 적절히 호출해 실행한다.\n\n\n다음은 각 프롬트에 대한 그 예를 보여준다. \n\n\n\nprompt: Create a basic Three.js endless runner game with a cube as the player and procedurally generated obstacles. Make sure to run it only in browser. If possible also launch it in the browser automatically after creating the game.\n\n\nprompt: I need a 7-day Japan itinerary for April 15-23 from Seattle, with a $2500-5000 budget for my fiancée and me. We love historical sites, hidden gems, and Japanese culture (kendo, tea ceremonies, Zen meditation). We want to see Nara's deer and explore cities on foot. I plan to propose during this trip and need a special location recommendation. Please provide a detailed itinerary and a simple HTML travel handbook with maps, attraction descriptions, essential Japanese phrases, and travel tips we can reference throughout our journey.\n\nprompt: create PDF file about ConTech in construction\n실행결과는 많이 알려진 프롬프트를 제외하고는 그다지 품질이 좋지는 않다. 그럼에도, 나름 많은 스타를 깃허브에서 얻고 있는 오픈 마누스의 에이전트의 구조를 분석하는 것은 의미가 있어 보여, 좀 더 자세히 코드를 확인해 본다.\n\n\n코드 동적 구조 분석\n동적 구조는 실행 흐름을 타고 가며 확인한다. 참고로, 이 구조는 다음 프롬프트일때 실행되는 구조이다. \n\nI need a 7-day Japan itinerary for April 15-23 from Seattle, with a $2500-5000 budget for my fiancée and me. We love historical sites, hidden gems, and Japanese culture (kendo, tea ceremonies, Zen meditation). We want to see Nara's deer and explore cities on foot. I plan to propose during this trip and need a special location recommendation. Please provide a detailed itinerary and a simple HTML travel handbook with maps, attraction descriptions, essential Japanese phrases, and travel tips we can reference throughout our journey.\n\n\n프롬프트는 일본 여행 기간을 명시하고 7일간 일정이 필요하다 말하고 있다. \n\n\n이에 대한 마누스 에이전트의 전체 큰 실행 구조는 다음과 같다.\n\ncall main() # 메인 호출\nprompt = input() # 프롬프트 입력\nManus.BaseAgent.run(prompt) # 프롬프트 입력에 따른 에이전트 도구들 실행\n\nupdate_memory() # 과거 입출력 저장\nmax_steps 만큼 아래 루프 반복 # default max_steps = 20\nstep_result = ReActAgent.step()  # 에이전트 도구 단계별 실행\n\nshould_act = think() # 무슨 도구를 순서대로 호출할 지 LLM통해 정보얻음\n\nrecent_messages = memory.messages[-3:]\nManus.BrowserAgent.ToolCallAgent.think()  # 도구 선택 추론\n\nextract current browser page information  # 웹화면 정보 사용\nresponse = LLM.ask_tool()  # 추론 시 LLM 사용 \n\ncheck token limit  # 토큰 한계 체크\nresponse = ChatCompletion(params)  # LLM 호출\nreturn response[0].message  # 결과 리턴\n\nreturn response\n\nact()  # 에이전트 도구가 선택되었으니, 이를 실행\n\ntool_callls 에 담긴 도구 호출 명령에 따른 도구들 실행 루프 수행\n\nToolCallAgent.execute_tool(command)  # 도구 실행\n\nargs = json.loads(command) # 예. web_search. '7-day tour'\nToolCollection.execute(args)  # 도구집합에서 해당도구실행\n\nBrowserUseTool.execute(args) # 쿼리검색 후 link 리턴\n\n_ensure_browser_initialized()  #브라우저 초기화\nlinks = WebSearch.execute(args.query) # 웹서치\npage = get_current_page()  # 페이지정보\nresult = page.goto(url_to_navigate)  \nreturn ToolResult(args, result) # 검색결과 수집\n\nreturn observation(result)\n\ntool_msg = 도구 실행 명령 및 함수 정보\nmemory.add_message(tool_msg)  # 메모리 업데이트\nresults.append(result)\n\nreturn results  # 결과리턴\n\n\n\n이를 좀 더 알기 쉽게 표현하면 다음같이 설명될 수 있다. \n\n\n\n\n\n\n\n1. 프로그램 시작: 메인 함수 호출\n\n\n\n2. 프롬프트 입력: 사용자로부터 프롬프트 입력\n\n\n\n3. 에이전트 실행: BaseAgent가 입력을 기반으로 동작 시작\n\n\n\n4. 메모리 업데이트: 과거 입력/출력 내용을 memory에 저장\n\n\n\n5. 에이전트 루프 실행 (기본 max_steps = 20)\n\n\n\n    5.1. 단계 실행 (Step): ReActAgent가 현재 단계 처리 시작\n\n\n\n    5.2. 다음 행동 판단 (Think)\n\n\n\n        5.2.1. 최근 메시지 3개 불러오기\n\n\n\n        5.2.2. LLM을 통해 다음 행동(도구 호출 여부 등) 추론\n\n\n\n    5.3. Think: 도구 선택 판단\n\n\n\n        5.3.1. BrowserAgent가 어떤 도구를 쓸지 결정\n\n\n\n        5.3.2. 현재 브라우저 페이지 정보 추출\n\n\n\n        5.3.3. 필요 시 LLM에 도구 사용 목적 질의 (ask_tool)\n\n\n\n        5.3.4. 토큰 한계 체크\n\n\n\n    5.4. LLM 호출 및 응답\n\n\n\n        5.4.1. ChatCompletion으로 명령 생성\n\n\n\n        5.4.2. 생성된 메시지 반환\n\n\n\n    5.5. Act: 도구 실행 (Act)\n\n\n\n        5.5.1. 도구 호출 명령(command)을 파싱 (예: JSON)\n\n\n\n        반복 (모든 명령에 대한 도구 실행):\n\n\n\n            5.5.2. 도구 실행 수행\n\n\n\n                5.5.2.1. ToolCollection에서 해당 도구 실행\n\n\n\n                5.5.2.2. 브라우저 초기화 (_ensure_browser_initialized)\n\n\n\n                5.5.2.3. 웹 검색 수행 (WebSearch.execute)\n\n\n\n                5.5.2.4. 페이지 이동 및 정보 추출 (page.goto)\n\n\n\n            5.5.3. 도구 결과 처리\n\n\n\n                5.5.3.1. ToolResult로 실행 결과 정리\n\n\n\n                5.5.3.2. observation 형태로 결과 정리\n\n\n\n    5.6. 메모리 및 결과 저장\n\n\n\n        5.6.1. 도구 실행 정보 및 결과를 memory에 저장\n\n\n\n        5.6.2. 결과 리스트에 추가\n\n\n\n6. 최종 결과 반환: 누적된 결과 또는 마지막 응답을 사용자에게 반환\n\n\n\n\n\n이 중에 핵심 실행 단계만 확인해 보자. \n\n\n5번 단계의 think는 LLM을 이용해 사용자 프롬프트를 기반으로 다음과 같이 적절한 도구를 순서대로 선택하도록 명령하고 있다. 이런 이유로, 도구에 대한 프로토타입을 LLM 호출 시 컨텐츠로 전달해 두어야 한다.\n\n\n\n\n\"Based on user needs, proactively select the most appropriate tool or combination of tools. For complex tasks, you can break down the problem and use different tools step by step to solve it. After using each tool, clearly explain the execution results and suggest the next steps.\"\n\n\n\n\n\nthink() 함수 동작 방식(일부)\n\n\n현재 마누스 버전에서 프롬프트 템플릿은 다음처럼 정의되어 있다.\n   \n\n\n\n\nSYSTEM_PROMPT = (\n\n\n\n\n    \"You are OpenManus, an all-capable AI assistant, aimed at solving any task presented by the user. You have various tools at your disposal that you can call upon to efficiently complete complex requests. Whether it's programming, information retrieval, file processing, or web browsing, you can handle it all.\"\n\n\n\n\n    \"The initial directory is: {directory}\"\n\n\n\n\n)\n\n\n\n\n\n\n\n\n\n\nNEXT_STEP_PROMPT = \"\"\"\n\n\n\n\nBased on user needs, proactively select the most appropriate tool or combination of tools. For complex tasks, you can break down the problem and use different tools step by step to solve it. After using each tool, clearly explain the execution results and suggest the next steps.\n\n\n\n\n\"\"\"\n\n\n\n\n\n\nLLM을 호출하는 부분은 위 템플릿을 이용해 시스템 프롬프트와 함께 사용자 질의를 입력하는 부분으로 구성될 것이다. 다음은 해당 정보를 보여준다. \n\n\nprompt: create input.txt file and copy it to output.txt\n\n본인의 경우, gpt-4o LLM 을 사용했다. messages의 1번에는 사용자 프롬프트가 입력되어 있고, 이 목표를 달성하기 위해 적절한 도구를 선택하라 명령하고 있다. tools에 함수 프로토타입이 저장된 것을 확인할 수 있다. 이를 근거로, LLM은 목표를 달성하기 위한 적절한 함수 호출 시퀀스를 생성한다.\n\n\n브라우저 화면의 검색 정보가 직접 필요한 경우가 있다. playwright를 이용해 해당 정보를 얻는 부분이 think()에서 사용되는 경우도 있을 수 있다. 다음 그림은 사용자 프롬프트 질의에 따라 LLM 이 선택한 도구인 브라우저를 통해 정보를 얻고, 그 정보를 메모리에 업데이트하면서, 에이전트 도구를 실행해 가는 화면이다. \n\n\n에이전트 검색 결과\n\n\n에이전트 도구의 리턴 결과(일부)\n결론적으로 핵심만 요약해 보면, 다음과 같은 방식으로 에이전트가 실행되는 것을 확인 할 수 있다. \n\n사용자 프롬프트 입력\nLLM 이 프롬프트를 통해 어떤 에이전트 도구들을 실행할 지 결정. 도구 정보 반환\n도구 호출 정보에 따라, 현재 등록된 도구들을 호출. 결과 파일은 workspace에 저장\n도구 호출 결과는 메모리에 저장. 이는 LLM 이 도구를 호출할 때 참고 컨텐츠로 재사용\n사용자 프롬프트 요구사항(목표)을 만족할 때까지 앞의 내용 반복\n\n다음은 각 step별로 에이전트가 호출되어 파일이 생성될 경우 저장된 workspace 폴더와 예시를 보여주다. \n\n\nAI 에이전트 도구에 의해 생성된 파일(우: 게임 코드, 좌하: 일본여행일정)\n\n\n분석해 보면, 사실, 대단한 메커니즘은 아니다. 이는 기존 OpenAI LLM 플랫폼 도구, LangChain과 같은 RAG, Ollama 같은 LLM Agent 도구에도 있었던 것이다. 좀 다른 것은 다음과 같은 기능이 기본으로 구현되어 있다는 정도로 보이는 데, 이도 다른 유명 LLM, 에이전트 플랫폼에서 하고 있는 것이라 큰 차이라 보기가 어렵다.  \n1. 웹브라우저를 통해 인터넷 컨텐츠 정보로 적극 사용한 것. 화면 자체에서 정보를 얻는 기능\n2. 파일 및 폴더, MCP(Model Control Procotol), 파이썬, 터미널 조작 등 지원\n\n\n오픈마누스의 가장 큰 장점은 오픈소스로 누구나 그 메커니즘을 확인하고, 분석하는 재미와 기여하며 커가는 커뮤니티 연대 정도로 생각할 수 있겠다. \n\n\n코드 정적 구조 분석\n코드 정적 구조 분석을 위해 폴더부터 분석해 본다. 구조는 다음과 같다.\n\nOpenManus/\n├── app/                      # 애플리케이션 핵심 코드\n│   ├── agent/              # 에이전트 로직 (예: BaseAgent, ReActAgent)\n│   ├── flow/                # 실행 흐름 제어 (workflow, step control)\n│   ├── mcp/                # Model Control Procotol\n│   ├── prompt/            # 프롬프트 템플릿 관련\n│   ├── sandbox/           # 실행 격리 환경 (보호된 실행 공간)\n│   └── tool/                 # 실행 가능한 다양한 도구 모음\n│       ├── bash.py                  # Bash 명령 도구\n│       ├── browser_use_tool.py  # 브라우저 연동 도구\n│       ├── create_chat_completion.py # LLM 호출 지원\n│       ├── file_operators.py       # 파일 입출력 도구\n│       ├── file_saver.py             # 파일 저장 도구\n│       ├── mcp.py                   # 제어 관련 도구\n│       ├── planning.py             # 계획 생성 도구\n│       ├── python_execute.py    # 파이썬 코드 실행 도구\n│       ├── str_replace_editor.py  # 문자열 편집 도구\n│       ├── terminal.py              # 터미널 명령 실행 도구\n│       ├── terminate.py            # 실행 종료 도구\n│       ├── tool_collection.py      # 전체 도구 관리자\n│       └── web_search.py          # 웹 검색 도구\n├── assets/                  # 에셋, 리소스 파일\n├── config/                  # 설정 파일들\n├── examples/              # 예시 실행 계획들\n│   └── japan-travel-plan/  # 예: 여행 계획 샘플\n├── logs/                     # 실행 로그 저장\n├── tests/                    # 테스트 코드\n│   └── sandbox/         # 샌드박스 테스트\n└── workspace/             # 임시 실행 또는 작업 파일 저장소\n\n\n\n\n설치된 폴더 구조 (일부)\n각 코드를 정적 분석해, 핵심 클래스만 UML로 분석해 보겠다. 마누스의 주요 클래스 구조는 다음과 같다. \n\n\n오픈 마누스 클래스 다이어그램(UML)\n소프트웨어 공학적으로는 디자인패턴 중 strategy pattern (ToolCollection, BaseTool) 을 사용하고 있다. 나머진 일반적인 OOAD 구조이다.\nBaseTool 클래스는 execute 메서드를 공통으로 가지며, 이를 상속한 각 도구 클래스들(Terminal, FileSaver, MCPClientTool, WebSearch, DomService, BrowserUseTool 등)은 시스템 명령 실행, 파일 저장, 브라우저 제어 등 특정 기능을 담당한다. 각 도구는 ToolCollection에 집합되어 있으며, tool_map을 통해 관리되고 execute를 통해 실행된다.\nToolCallAgent는 think 메서드를 통해 어떤 도구를 사용할지 판단하고, 판단 결과를 ToolCollection에 전달하여 해당 도구를 실행한다. ReActAgent는 step, think, act 메서드를 통해 LLM 기반 추론과 도구 실행 흐름을 단계적으로 처리하며, BaseAgent는 이를 상속받아 step 단위의 실행 흐름을 제공한다. Manus 객체는 최상위 제어자로서 전체적인 에이전트의 동작을 통제하며 think 메서드를 통해 추론을 담당한다. BrowserAgent는 BrowserUseTool과 관련된 think 역할을 수행한다.\nBrowserUseTool은 WebSearch와 DomService를 포함하며 웹 페이지 탐색, 클릭, 입력 등의 브라우저 상의 조작을 담당한다. DomService는 클릭, 스크롤, 탭 전환 등 구체적인 DOM 제어 명령을 담당하며, 오른쪽 enum 박스는 이 DomService가 수행할 수 있는 구체적인 명령어 목록을 나열한 것이다.\nLLM 클래스는 ask_tool, ask_with_images, ask 등의 메서드를 제공하며, 도구 선택 판단 또는 일반 자연어 추론을 위한 언어 모델 호출 기능을 수행한다. LLM이 사용하는 모델은 gpt-4-vision, gpt-4.0, claude-3 계열 등으로 구성된 멀티모달 모델 리스트에 명시되어 있다.\n전체 구조는 에이전트가 사용자 입력을 받아 LLM을 통해 판단하고, 적절한 도구를 선택하여 실행하며, 이를 반복적으로 수행하는 다단계 추론 및 실행 체계를 중심으로 구성되어 있다.\n\n마무리\n이 글을 통해 오픈마누스를 분석해 보았다. 개발 시작한 지 얼마 안되는 따끈따끈한 코드라서 그런지, 아직 코드 리팩토링이 잘 안되어 있고, 구조도 멀티 에이전트라 하기에는 좀 부족하고 확장성에 문제가 있는 것들이 있다. 에이전트 선택 및 호출하는 부분은 막코딩(?) 같은 부분이 있어 구조적으로 깔끔하지 못하다(습작 느낌). LangChain처럼 많은 개발자가 참여하면 크게 복잡해져 입력-결과를 예측하기 어려워지거나, 버전업에 되면서 빅스텝(과거와의 단절)이 될 수 있을 것 같다. \n\n\n에이전트의 핵심기술은 결국 추론 능력을 가진 LLM을 어떻게 잘 활용하는 가이다. 이런 점에서 마누스(최근 해킹되어 코드 확인해 보았더니)나 오픈마누스는 기존 LLM과 프롬프트 템플릿을 복잡하게 wrapping 해 놓은 모듈이란 말이 나올 수 밖에 없다.\n\n\n좀 더 깃허브를 살펴보니, 이를 주도하는 개발자는 심천에 있는 중국인이며. 이외, 지장에 있는 개발자, 학생들 6명 정도가 주축으로 개발하고 있는 것 같다(소프트웨어 공학적으로는 약간 아마추어 느낌). RL 모듈은 UIUC에 다니는 중국인 대학원생, 홍콩과기대 학생 등이 주축이되고 있다(참 열심히 개발하는 느낌).\n\n\n오픈 마누스 개발 공헌자\n\n\n그럼에도 불구하고, 열심히 개발 중인 오픈소스 구조를 살펴보고 여러 구현 아이디어를 보는 것은 즐거운 것이다. 이런 이유로, 이들이 본인이 개발하는 코드를 공개하고, 고민을 공유하는 것은 브랭딩 전략이란 점을 제외하더라도 의미있는 행위라 생각한다. 시간이 된다면, OpenManus-RL 도 분석해볼 계획이다.\n\n\n레퍼런스\n\nOpenManus: the Open-Source Alternative to Manus AI\nOpenManus: No fortress, purely open ground. OpenManus is Coming.\nOpenManus-RL: A live stream development of RL tunning for LLM agents\nManus AI: The Best Autonomous AI Agent Redefining Automation and Productivity\nThe First General AI Agent Unveiled, 2025, Medium\nManus use cases\nExploring Manus AI Agent. Autonomous AI Revolution and How to Get… , Naveen Krishnan, 2025, Towards AI\nLangflow, Low-code AI builder for agentic and RAG applications\nLangflow is a powerful tool for building and deploying AI-powered agents and workflows\nOpenManus reddit",
    "reviews": [],
    "syllabus": [],
    "link": "http://daddynkidsmakers.blogspot.com/2025/03/manus-ai.html",
    "pubDate": "2025-03-28T11:24:00.000Z",
    "creator": "Unknown",
    "categories": []
  },
  {
    "id": 11,
    "imageUrl": "",
    "title": "GitHub Copilot을 사용하여 코드를 리팩토링하는 방법",
    "description": "No description available",
    "reviews": [],
    "syllabus": [],
    "link": "https://jacking75.github.io/ai-github_copilot_20250326/",
    "pubDate": "Wed, 26 Mar 2025 00:00:00 +0900",
    "creator": "Unknown",
    "categories": []
  },
  {
    "id": 12,
    "imageUrl": "",
    "title": "중소기업 취업자라면 소득세 감면 혜택 꼭 챙기세요",
    "description": "매년 최대 200만 원까지 돌려받을 수 있어요",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.toss.im/article/tossmoment-5",
    "pubDate": "Thu, 27 Mar 2025 08:12:00 GMT",
    "creator": "Unknown",
    "categories": []
  },
  {
    "id": 13,
    "imageUrl": "",
    "title": "IntelliJ IDEA 2025.1 Beta 3 Is Out!",
    "description": "IntelliJ IDEA 2025.1 Beta 3 is ready for download! You can get the latest build from our website, through the free Toolbox App, from inside the IDE, or by using snap packages for Ubuntu. Download IntelliJ IDEA 2025.1 Beta 3 This is the final Beta build, with the release candidate just around the corner. It’s […]",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.jetbrains.com/idea/2025/03/intellij-idea-2025-1-beta-3/",
    "pubDate": "Thu, 27 Mar 2025 08:47:48 +0000",
    "creator": "Maria Kosukhina",
    "categories": [
      "eap",
      "2025-1-eap",
      "intellij-idea-2025-1",
      "intellij-idea-2025-1-eap"
    ]
  },
  {
    "id": 14,
    "imageUrl": "",
    "title": "Logstash 필터 ruby - 7th",
    "description": "ruby 필터를 이용한 숫자 검사.\nfilter {\n mutate {\n  remove_field => [\"@timestamp\", \"@version\", \"path\", \"host\"]\n }\n\n dissect {\n  mapping => {\"message\" => '%{}\"%{}\" %{status} %{}'}\n  convert_datatype => {\"status\" => \"int\"}\n }\nruby {\n  code => \"\n   for i in [2,3,4,5]\n    if event.get('status').match(/#{i}\\d+/)\n     j = i * 100\n     event.set('status2', j)\n    end\n   end\n  \"\n }\n}\n\n\n[2025-03-28T12:53:15,072][ERROR][logstash.filters.ruby    ][main][9cea864b7137d9fe155b8bc242225c2bc2889d096d10ad7be31764fb047da980] \nRuby exception occurred: undefined method `match' for 200:Integer\nDid you mean?  catch {:class=>\"NoMethodError\", :backtrace=>[\"(ruby filter code):4:in `block in register'\", \"org/jruby/RubyArray.java:1981:in `each'\", \"(ruby filter code):1:in `block in register'\", \"D:/ELK/logstash-8.17.0/vendor/bundle/jruby/3.1.0/gems/logstash-filter-ruby-3.1.8/lib/logstash/filters/ruby.rb:96:in `inline_script'\", \"D:/ELK/logstash-8.17.0/vendor/bundle/jruby/3.1.0/gems/logstash-filter-ruby-3.1.8/lib/logstash/filters/ruby.rb:89:in `filter'\", \"D:/ELK/logstash-8.17.0/logstash-core/lib/logstash/filters/base.rb:158:in `do_filter'\", \"D:/ELK/logstash-8.17.0/logstash-core/lib/logstash/filters/base.rb:176:in `block in multi_filter'\", \"org/jruby/RubyArray.java:1981:in `each'\", \"D:/ELK/logstash-8.17.0/logstash-core/lib/logstash/filters/base.rb:173:in `multi_filter'\", \"org/logstash/config/ir/compiler/AbstractFilterDelegatorExt.java:133:in `multi_filter'\", \"D:/ELK/logstash-8.17.0/logstash-core/lib/logstash/java_pipeline.rb:308:in `block in start_workers'\"]}\n{\n       \"tags\" => [\n        [0] \"_rubyexception\"\n    ],\n    \"message\" => \"1.2.3.4 - - [12/Oct/2015:02:42:00 +0900] \\\"GET /bbs/view.html HTTP/1.1\\\" 404 37727\\r\",\n     \"status\" => 404\n}\n{\n       \"tags\" => [\n        [0] \"_rubyexception\"\n    ],\n    \"message\" => \"192.168.56.1 - - [12/Oct/2015:02:42:00 +0900] \\\"GET /bbs/view.php?board_id=kor%5Fmedia&gul_no=1106&idx=17&m=4&upage=25&tpage=&PAGE=4 HTTP/1.1\\\" 200 37727\\r\",\n     \"status\" => 200\n}\n\n\n\n왜 검사를 못하지? 그분께 물어봤다.\n\n\n\n\nmatch 메서드는 문자열만 검사할 수 있다고 알려주는 chatgpt느님(..) 가르쳐준대로 수정.\nfilter {\n mutate {\n  remove_field => [\"@timestamp\", \"@version\", \"path\", \"host\"]\n }\n\n dissect {\n  mapping => {\"message\" => '%{}\"%{}\" %{status} %{}'}\n  convert_datatype => {\"status\" => \"int\"}\n }\n\n ruby {\n  code => \"\n   for i in [2,3,4,5]\n    if event.get('status').to_s.match(/#{i}\\d+/)\n     j = i * 100\n     event.set('status2', j)\n    end\n   end\n  \"\n }\n}\n\n\n{\n    \"status2\" => 400,\n    \"message\" => \"1.2.3.4 - - [12/Oct/2015:02:42:00 +0900] \\\"GET /bbs/view.html HTTP/1.1\\\" 404 37727\\r\",\n     \"status\" => 404\n}\n{\n    \"status2\" => 200,\n    \"message\" => \"192.168.56.1 - - [12/Oct/2015:02:42:00 +0900] \\\"GET /bbs/view.php?board_id=kor%5Fmedia&gul_no=1106&idx=17&m=4&upage=25&tpage=&PAGE=4 HTTP/1.1\\\" 200 37727\\r\",\n     \"status\" => 200\n}\n\n\n\n관련 글\n\nLogstash 필터 ruby - 6th\nLogstash 필터 ruby\nLogstash 필터 grok\nLogstash 필터 mutate\nLogstash 필터 geoip\nLogstash 필터 dissect\nLogstash 필터 kv\nLogstash 필터 date\nLogstash 필터 translate\nLogstash 필터 drop\nLogstash 필터 useragent\nLogstash 필터 elapsed\nLogstash 필터 fingerprint\nLogstash 필터 csv\nLogstash 필터 dns\nLogstash 필터 split\nLogstash codec 플러그인 multiline",
    "reviews": [],
    "syllabus": [],
    "link": "https://kangmyounghun.blogspot.com/2025/03/logstash-ruby-7th.html",
    "pubDate": "2025-03-28T03:57:00.004Z",
    "creator": "Unknown",
    "categories": []
  },
  {
    "id": 15,
    "imageUrl": "",
    "title": "Boost Your CMake Development with Copilot Custom Instructions",
    "description": "Introduction Creating a new CMake project that uses unfamiliar libraries can be daunting and time-consuming. This blog post takes you along on my journey using Copilot to make this easier, and leveraging Custom Instructions to tailor Copilot responses. For a sneak peek, see the outcome of this journey in this repository. Background As C++ developers […]\nThe post Boost Your CMake Development with Copilot Custom Instructions appeared first on C++ Team Blog.",
    "reviews": [],
    "syllabus": [],
    "link": "https://devblogs.microsoft.com/cppblog/boost-your-cmake-development-with-copilot-custom-instructions/",
    "pubDate": "Tue, 25 Mar 2025 17:19:55 +0000",
    "creator": "Garrett Campbell",
    "categories": [
      "C++",
      "CMake",
      "Copilot",
      "OpenFolder",
      "Vcpkg"
    ]
  }
]