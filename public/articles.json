[
  {
    "id": 1,
    "imageUrl": "",
    "title": "2025년 추석 연휴 시작!",
    "description": "벌써 연휴 3일차 입니다.\n다들 재밌게 챌린지 참여 중이신가요?\n저도 현재 강병진님의 회사에서 바로 쓰는 업무자동화 AI 에이전트 (w. n8n, LangGraph) 를 재밌게 매일 매일 듣고 있습니다.\n\n\n매일 미션 참가해주시는 분들 덕분에 저도 계속해서 자극 받고 더 열심히 해야겠다는 동기부여를 많이 받고 있습니다.\n거의 하루에 1천개의 미션이 제출되더라구요 ㅎㅎ\n\n\n매 시간 마다 수십개씩 미션 제출 알람이 뜨는데, 결제 알림 뜨는 것 보다 미션 제출 알람이 더 좋았습니다 ㅎㅎ\n이런 얘기하면 대표님이 싫어하실려나...?\n인프런은 교육 콘텐츠를 다루는 오픈 플랫폼이다보니 종종 교육 콘텐츠를 판매하는 커머스처럼 생각하시는 분들이 많으신데요.\n얼핏 보면 그럴 순 있는 것 같지만,\n커머스와 본질적으로 다른 것은 어떻게든 고객에게 결제를 시킨다 가 목적이 아니라어떻게든 고객의 목적에 맞게 성장시킨다 가 목적인 면에서는 큰 차이가 있는 것 같아요.\n그리고 그 목적을 이루는 과정에서는 지식을 나눔해주시는 분들의 지식 가치가 훼손되지 않도록 적정선의 가격대와 프로모션 정책을 유지하면서 학습하시는 분들께는 지불하신 그 이상으로 배움을 얻어갈 수 있도록 기능,제도 등을 개선해나가고 있습니다.\n전 직장인 배민에서의 비전은 \"좋은 음식을 먹고 싶은 곳에서\" 였는데요.\n당시 이 비전이 너무 명확해서 진짜 그런 세상이 왔으면 좋겠다는 생각을 하며 전사 발표를 봤었습니다.\n요즘은 비전이 바뀐 것 같더라고요?\n인프런은 제가 합류할때도, 지금도 여전히 비전이 동일합니다.\n\"성장 기회의 평등\"\n온라인 강의 플랫폼이 넘치는 이 시대에도 과연 이 비전이 유효한가? 라는 질문도 많이 받습니다.\n패스트캠퍼스, 클래스 101, 휴넷, 멀티캠퍼스 등 여러 온라인 교육 서비스가 존재하고,\n특히 쿠팡이 도서를 판매하고 있고, 네이버에서는 '프리미엄 콘텐츠' 라는 서비스로 콘텐츠를 판매하는 이 시대에 말이죠.\n근데, 저는 아무리 세상이 편리해지고 많은 플랫폼이 등장해도 그 플랫폼들이 가지고 있는 방향성이 정말로 \"성장 기회의 평등\" 을 향하고 있는가? 에 대해서는 물음표가 있습니다.\n세상엔 평등하지 않은게 많더라구요.\n\"아는데 안하는 것은 어쩔 수가 없지만,\n몰라서 못하는 것 만큼은 해결해야하는 것 아닌가?\" 라는 생각인 것이죠.\n이번 챌린지 역시 비슷한 마음이였습니다.\n사실 다들 마음속 열정이 가득할텐데,\n누가 심지에 불만 붙여주면 활활 타오를 수 있는 사람들인데,\n그걸 당사자도, 주변에서도 모르는게 아닐까?\n그걸 알려드리면 그것 조차 우리의 비전과 맞는 것 아닌가? 라는 생각이였죠.\n가설에 가까운 실험이였지만,\n이만큼이나 열정적으로 미션에 참여하고 오픈 카톡방에서 매일 매일 공부 인증을 하시는 것을 보면서\n\"아 역시... 다들 마음속 열정이 가득찬 분들이라서 누가 계기만 마련해주면 정말로 대단한 열정을 뿜어내주시는구나\" 라는 생각을 하게 됐습니다.\n저희의 비전에 맞춰서 더 열심히 행동해야겠다는 생각을 하게 되어서,\n그래서 결제 알림 보다, 미션 제출 알람이 더 좋았습니다  \n아 물론..... 결제 알림도 너무나 좋아합니다 ㅋㅋㅋㅋ\n저도 내일 있을 제사를 위해 처가를 갔다가, 지금 SRT를 타고 대구로 내려가는 중입니다.\n제출해주신 수천개의 미션들을 보면서 동기부여 뿜뿜하면서 기차안에서 노트북을 열 수 있었습니다.\n(SRT 기차 안에서)\n\n\n오늘을 비롯해서 화요일까지가 추석 연휴라서 아마도 오늘 이동하시는 분들이 많으실 것 같아요.\n다들 조심히 이동하시고,\n추석에 제사가 있으신 분들은 제사 잘 보내시고,\n이동 계획이 없으신 분들은 하루 정도는 짧게(?)만 챌린지 참여하신 뒤 휴식을 취해보시면 좋겠어요!!",
    "reviews": [],
    "syllabus": [],
    "link": "https://jojoldu.tistory.com/849",
    "pubDate": "Tue, 7 Oct 2025 19:18:34 +0900",
    "creator": "향로 (기억보단 기록을)",
    "categories": [
      "생각정리",
      "2025년 추석 챌린지",
      "인프런 챌린지",
      "추석 챌린지",
      "향로"
    ]
  },
  {
    "id": 2,
    "imageUrl": "",
    "title": "삼성 갤럭시북3 갤럭시북4 스피커 사운드 및 Fn키 설정",
    "description": "리눅스에서 삼성 갤럭시북의 스피커 사운드를 설정하는 방법이다. 삼성 갤럭시북에는 리얼텍 사운드 칩셋이 들어있는데 인식은 되지만 이상하게도 스피커 출력이 안된다. 왜냐하면 삼성이 인수한 AKG가 커스터마이징을 해서 기본 드라이버로는 스피커가 작동이 안되는 것이다. 하지만 스피커가 아닌 이어폰으로는 아주 잘 된다. 아무튼 Linux에서 Galaxybook의 스피커 사운드를 듣기 위해서는 아래처럼 약간의 설정이 필요하다.\nSamsung GalaxyBook AKG Dolby atmos speaker\n\n\n참고로 이 설정 방법의 원본 링크는 아래와 같다.\nFixing ALC298 audio (no sound from speakers), https://forums.fedoraforum.org/showthread.php?331130-Fixing-ALC298-audio-%28no-sound-from-speakers\n \n1. bash 스크립트 파일 설치\n아래 github 링크에서 다운받은 necessary-verbs.sh 파일을 다운로드 한 뒤에 /usr/local/sbin 디렉터리에 복사한다. (root 권한이 필요하다)\n https://github.com/joshuagrisham/galaxy-book2-pro-linux/blob/main/sound/necessary-verbs.sh \n복사가 완료된 뒤에 chmod +x /usr/local/sbin/necessary-verbs.sh 로 실행 권한을 준다. 그리고나서 해당 스크립트를 실행한 뒤에 스피커로 소리가 나오는지 영상이나 음악을 틀어보자. 잘 된다면 다음 systemd unit 설정을 작업하도록 하고, 안된다면 그냥 여기서 멈춘다.\n \n \n2. systemd service unit 작성\nroot 권한으로 /etc/systemd/system/necessary-verbs.service 파일을 만들고, 아래의 내용을 넣는다.\n[Unit]\nDescription=Run internal speaker fix script at startup\nAfter=getty.target\n\n[Service]\nUser=root\nGroup=root\nType=simple\nExecStart=/usr/local/sbin/necessary-verbs.sh\nRestart=always\nTimeoutStartSec=0\n\n[Install]\nWantedBy=default.target\n \n파일을 저장한 뒤에는 다음 명령어를 실행해서 인식시키고, 해당 unit을 활성화한다.\nsystemctl daemon-reload\n\nsystemctl enable --now necessary-verbs.service\n \n완전히 작동하는지 확인하기 위해 재부팅을 해본다.\n \n3. 갤럭시북 커널 모듈 : Fn키 기능 설정\n참고로 커널 6.14이후로는 samsung_galaxybook kernel module이 있다. modinfo samsung_galaxybook 로 확인 가능하다. 이 기능이 있는 커널은 Fn키 등을 사용할 수 있게 해준다. 예를 들어 Fn+F5는 터치패드 on/off, Fn+F6는 사운드 on/off, Fn+F7과 F8은 사운드 음량 조절, Fn+F9는 키보드 발광 조절이다.\n \n히스토리\n2025-10-10 초고",
    "reviews": [],
    "syllabus": [],
    "link": "http://sunyzero.tistory.com/319",
    "pubDate": "Fri, 10 Oct 2025 22:24:05 +0900",
    "creator": "sunyzero",
    "categories": [
      "컴퓨터 관련/리눅스 데스크탑",
      "Fedora Linux",
      "Samsung Galaxybook",
      "samsung_galaxybook kernel module",
      "리눅스 갤럭시북 스피커 사운드"
    ]
  },
  {
    "id": 3,
    "imageUrl": "",
    "title": "주요 포인트 클라우드 세그먼테이션 학습 모델 조사 및 비교 분석",
    "description": "이 글은은 3D 점군 데이터 처리를 위한 주요 딥러닝 기반 세분화 모델들의 기술적 특성을 비교 분석하는 것을 목적으로 한다. 점군의 비정형적, 비순서적 특성을 처리하기 위해 제안된 PointNet++부터 시작하여 그래프 신경망, 컨볼루션 신경망의 개념을 확장한 모델들을 거쳐, 최근 가장 우수한 성능을 보이는 트랜스포머 기반 아키텍처에 이르기까지 각 모델의 핵심 개념, 구조적 특징, 성능, 그리고 실용성을 좌우하는 리소스 요구사항 등을 종합적으로 분석한다.\n\nPoint Transformer 구조\n평가의 객관성을 확보하기 위해, 주로 대규모 실내 데이터셋인 S3DIS(Stanford Large-Scale 3D Indoor Space)를 기준으로 성능을 기술하며, 특히 Area 5를 테스트셋으로 사용하는 표준 프로토콜의 결과를 인용한다. 평가 지표는 전체 포인트 분류 정확도를 나타내는 OA(Overall Accuracy)와 클래스별 평균 성능을 측정하는 mIoU(mean Intersection over Union)를 사용한다. mIoU는 클래스 불균형 문제에 강건하여 세분화 성능의 핵심 지표로 간주된다.\n\nPointNet++\n개념: PointNet++는 선구적인 모델인 PointNet이 점군 전체의 전역적 특징에만 집중하여 지역적(local) 구조 정보를 포착하지 못하는 근본적인 한계를 극복하기 위해 제안되었다. 이미지 처리 분야의 컨볼루션 신경망(CNN)이 계층적으로 receptive field를 넓혀가는 방식에 착안하여, 점군 내 작은 지역부터 시작해 점차 넓은 영역으로 특징을 단계적으로 집계하고 추상화하는 계층적 특징 학습(Hierarchical Feature Learning) 구조를 도입했다.\n\n구조적 특징: PointNet++의 핵심 구조는 Set Abstraction (SA) 모듈의 반복적인 적용에 있다. SA 모듈은 샘플링, 그룹핑, 그리고 특징 추출의 세 단계로 구성된다.\n샘플링(Sampling): Farthest Point Sampling (FPS) 방식을 사용하여 전체 점군으로부터 기하학적으로 가장 멀리 떨어진 점들을 순차적으로 선택한다. 이를 통해 더 넓은 영역을 대표하는 중심점(centroid)들을 효율적으로 정의할 수 있다.\n그룹핑(Grouping): 샘플링된 각 중심점을 기준으로 일정 반경 내의 모든 점 또는 K개의 가장 가까운 이웃 점들을 하나의 지역 집합으로 묶는다. 이 과정을 통해 전체 점군을 여러 개의 국소 영역으로 분할한다.\n특징 추출(Feature Extraction): 그룹핑된 각 지역 집합에 대해 PointNet(이를 '미니 PointNet'이라 칭함)을 적용한다. 미니 PointNet은 지역 집합 내의 점들의 좌표를 정규화하고, 다층 퍼셉트론(MLP)을 통해 각 점의 특징을 추출한 후, Max-Pooling 연산을 통해 지역 전체를 대표하는 하나의 특징 벡터를 생성한다.\n특징 전파(Feature Propagation): 세분화 작업을 위해 인코더에서 다운샘플링된 특징을 다시 원래 해상도의 모든 점으로 복원하는 과정이다. 업샘플링된 점의 특징은 저해상도 점들의 특징을 역거리가중(Inverse Distance Weighted) 보간법을 사용하여 계산하며, 인코더 단계의 Skip Connection을 통해 전달된 특징과 결합하여 세부 정보를 보존한다.\n\n장점은 계층적 구조를 통해 다양한 스케일의 기하학적 특징을 학습할 수 있다는 점이며, 이는 이후 대부분의 점군 처리 모델이 채택하는 표준적인 패러다임이 되었다. 반면, 단점으로는 FPS의 계산 복잡도가 점군 크기(N)와 샘플링할 점의 수(M)에 비례()하여 증가하므로 대규모 점군에 직접 적용하기 어렵다는 점이 있다. 또한, 고정된 반경으로 그룹핑하는 방식은 점군 밀도가 불균일할 경우 성능 저하를 야기할 수 있다.\n\n성능 (S3DIS Area 5): OA는 약 89.2%, mIoU는 약 65.4% 수준이다.\n대용량 처리: 부적합하다. 수만 개 이상의 점군에서는 FPS 연산이 심각한 병목 현상을 일으킨다.\n리소스 및 시간 요구사항: VRAM은 8에서 12GB가 필요하며, 학습 시간은 중간 정도 소요된다. 추론 시간은 FPS 때문에 실시간 처리가 어려워 느린 편이다.\nGitHub 주소: https://github.com/charlesq34/pointnet2\n\nPointEdgeSegNet\n이 모델은 점군을 하나의 그래프로 간주하는 그래프 신경망(GNN) 접근법을 채택했다. 특히 DGCNN에서 제안된 EdgeConv 연산을 U-Net 아키텍처에 통합하여, 점과 그 이웃 점들 간의 관계를 '엣지 특징'으로 명시적으로 모델링한다. 이를 통해 정확도와 효율성의 균형을 목표로 한다.\n\n구조적 특징: 구조의 핵심 연산은 EdgeConv이다. 이는 K-NN(K-Nearest Neighbors) 알고리즘으로 각 점의 이웃을 찾아 동적으로 그래프를 구성하고, 중심점의 특징()과 이웃점과의 상대적 위치 벡터()를 결합한 엣지 특징 [xi, xj - xi]을 생성한다. 이 엣지 특징은 중심점 자체의 정보와 주변의 기하학적 정보를 동시에 담고 있으며, MLP를 통과한 후 대칭 함수인 Max-Pooling으로 집계되어 중심점의 새로운 특징으로 갱신된다. 전체 구조는 대칭적인 인코더-디코더 구조인 U-Net을 채택하여, 인코더에서는 EdgeConv와 FPS를 통해 특징을 추출 및 다운샘플링하고, 디코더에서는 k-NN 보간과 Skip Connection으로 특징을 업샘플링하여 세부 정보를 보존한다.\n\n장점은 엣지 특징을 통해 점들 간의 기하학적 관계를 명시적으로 학습하므로 지역적 패턴에 대한 표현력이 우수하며, U-Net 구조 덕분에 정보 손실이 적다는 것이다. 공간인덱싱을 통한 대용량 점군을 격자 블럭으로 처리한 후 학습 및 예측하므로 대용량 점군 처리가 가능하다.\n\n성능 (S3DIS Area 5): 성능 추정치에 따르면, OA는 약 91.5%이다.\n대용량 처리: 제한적이다. FPS 대신 Grid Subsampling 등을 사용하면 일부 개선이 가능하다.\n리소스 및 시간 요구사항: VRAM은 10에서 16GB가 필요하며, 학습 시간은 중간 정도 소요된다. 추론 시간은 느린 편에서 중간 수준에 해당한다.\nGitHub 주소: https://github.com/mac999/point_edge_seg_net/tree/main\nKPConv\nKPConv는 이미지 CNN의 '컨볼루션 필터' 개념을 3D 공간으로 직접 일반화한 모델이다. 유클리드 공간에 미리 정의된 커널 포인트(Kernel Points)를 컨볼루션 필터의 핵으로 삼고, 이 커널 포인트들과 입력 점들 간의 거리에 따라 가중치를 적용하는 방식으로, 진정한 의미의 3D 공간 컨볼루션을 구현했다.\n\n구조적 특징: 핵심 연산인 KPConv는 구(sphere) 형태의 공간 안에 미리 정의된 커널 포인트들을 배치하는 방식으로 작동한다. 각 커널 포인트는 고유의 학습 가능한 가중치 행렬을 가지며, 입력 점과의 거리가 가까울수록 더 큰 영향력을 행사하도록 상관관계를 계산한다. 이 커널은 고정된 형태의 Rigid KPConv와, 지역 형상에 따라 커널 포인트의 위치가 동적으로 변형되는 Deformable KPConv로 나뉜다. 다운샘플링 방식으로는 FPS 대신 Grid Subsampling을 사용하여 점군을 복셀화하고 각 복셀의 중심점을 취하는 방식으로 대규모 데이터 처리 속도를 개선했다.\n장점은 유연하고 강력한 커널 덕분에 복잡한 기하학적 구조에 대한 표현력이 매우 뛰어나며, 높은 정확도를 달성한다는 것이다. 단점은 커널 기반 연산이 각 점과 모든 커널 포인트 간의 상호작용을 계산해야 하므로 계산 비용과 메모리 요구량이 매우 크다는 점이다.\n\n성능 (S3DIS Area 5): OA는 약 92.9%, mIoU는 약 70.6%이다.\n대용량 처리: 가능하다. Grid Subsampling 덕분에 수백만 점군 처리가 가능하지만, 리소스 요구량이 높다.\n리소스 및 시간 요구사항: VRAM은 16에서 24GB 이상으로 높은 편이며, 학습 시간도 길다. 추론 시간은 RandLA-Net 대비 수십 배 느려 느린 편에 속한다.\nGitHub 주소: https://github.com/HuguesTHOMAS/KPConv\n\nRandLA-Net\n이 모델은 대규모 점군을 실시간으로 처리하는 실용성에 초점을 맞춘 모델이다. '무작위 샘플링(Random Sampling)'을 통해 계산 복잡도를 획기적으로 낮추고, 이로 인해 발생할 수 있는 정보 손실은 강력한 '지역 특징 집계(Local Feature Aggregation, LFA)' 모듈로 보완하는 전략을 사용한다.\n\n구조적 특징: 샘플링 단계에서는 계산 비용이 전혀 없는 무작위 샘플링을 사용하여 인코더의 각 단계에서 점군을 대폭 줄인다. 핵심 블록인 LFA는 지역 공간 인코딩(LocSE), 어텐션 풀링(Attentive Pooling), 그리고 Dilated Residual Block으로 구성된다. LocSE는 이웃 점들의 상대적 위치 정보를 명시적으로 인코딩하고, 어텐션 풀링은 이웃들의 특징에 대해 학습 가능한 어텐션 가중치를 부여하여 중요한 특징을 선별적으로 집계한다. 이 어텐션 풀링이 무작위 샘플링의 단점을 보완하는 핵심 장치이다.\n장점은 압도적으로 빠른 처리 속도와 낮은 메모리 요구량을 가진다는 것이다. 수백만 개 이상의 점군을 단일 패스로 처리할 수 있다. 단점으로는 무작위 샘플링이 필연적으로 중요한 기하학적 특징을 가진 점을 누락시킬 수 있어, 작고 복잡한 객체에 대한 정밀도가 다른 정교한 모델들에 비해 다소 떨어진다는 점이 있다.\n\n성능 (S3DIS Area 5): OA는 약 92.2%, mIoU는 약 70.0%이다.\n대용량 처리: 최적화되어 있으며, 이것이 이 모델의 핵심 설계 목표이다.\n리소스 및 시간 요구사항: VRAM은 8에서 11GB로 낮은 편이다. 학습 시간은 짧고, 추론 시간은 매우 빨라 실시간 처리에 가장 근접한 모델로 평가된다.\nGitHub 주소: https://github.com/QingyongHu/RandLA-Net\n\n\nPoint Transformer\nPoint Transformer는 자연어 처리 분야에서 성공을 거둔 트랜스포머 아키텍처를 점군에 적용한 모델이다. PointNet++의 계층적 구조를 기반으로, 지역 특징 추출 부분을 셀프-어텐션(Self-Attention) 메커니즘으로 대체하여 점들 간의 문맥적 관계를 더욱 정교하게 학습한다.\n\n구조의 핵심인 Point Transformer Block은 지역 그룹 내의 한 점(Query)이 다른 모든 점(Key)들과 얼마나 관련이 있는지 어텐션 스코어를 계산하고, 이 스코어를 가중치로 삼아 모든 점들의 특징(Value)을 가중합하여 새로운 특징을 생성한다. 특히 점들 간의 상대적 위치 정보를 어텐션 계산에 명시적으로 포함시켜 기하학적 문맥을 강화한다.\n\n장점은 셀프-어텐션을 통해 복잡한 지역 패턴과 객체 파트 간의 상호작용을 효과적으로 모델링하여 높은 성능을 보인다는 것이다. 단점은 어텐션 연산이 그룹 내 점의 수(N)에 대해 제곱()에 비례하는 계산 복잡도를 가져 매우 비효율적이라는 점이다.\n\n성능 (S3DIS Area 5): OA는 약 93.0%, mIoU는 약 70.9%이다.\n대용량 처리: 부적합하다. 높은 계산 복잡도 때문에 대규모 점군에 적용할 수 없다.\n리소스 및 시간 요구사항: VRAM은 24GB 이상으로 매우 높고, 학습 시간도 매우 길다. 추론 시간 역시 매우 느리다.\nGitHub 주소: https://github.com/POSTECH-CVLab/point-transformer\nStratified Transformer\n이 모델은 대규모 점군에 트랜스포머를 효율적으로 적용하기 위해 이미지 분야의 Swin Transformer 아이디어를 3D로 확장한 모델이다. 계층적 샘플링과 윈도우 기반 지역 어텐션이라는 두 가지 핵심 전략을 통해 트랜스포머의 계산량 문제를 해결했다.\n\n구조적 특징: 다운샘플링에는 FPS와 Random의 장점을 결합한 Stratified Sampling 방식을 사용하여 효율적이면서도 공간을 균일하게 커버한다. 핵심은 윈도우 어텐션으로, 전체 공간을 겹치지 않는 작은 3D 윈도우(복셀)로 분할하고, 각 윈도우 내부에서만 지역적으로 어텐션을 수행하여 계산 복잡도를 점의 수에 비례하도록 낮춘다. 또한 윈도우 이동(Shifted Window) 기법을 통해 다음 레이어에서는 윈도우 경계를 이동시켜 인접 윈도우 간의 정보 교환을 가능하게 한다. 이를 통해 지역 어텐션만으로도 전역적인 문맥을 효과적으로 학습할 수 있다.\n장점은 트랜스포머의 강력한 표현력과 대규모 처리 능력을 겸비하여, 효율성과 정확도 모두에서 최고 수준의 성능을 보인다는 것이다. 단점은 모델 구조가 상대적으로 복잡하고, 윈도우 크기 등 하이퍼파라미터 설정에 민감할 수 있다는 점이다.\n\n성능 (S3DIS Area 5): OA는 약 94.1%, mIoU는 약 74.5%로 매우 높다.\n대용량 처리: 최적화되어 있다.\n리소스 및 시간 요구사항: VRAM은 11에서 16GB로 중간에서 높은 수준이며 RandLA-Net보다 높지만 KPConv보다 효율적이다. 학습 시간은 중간에서 긴 편이며, 추론 시간은 빠르다.\nGitHub 주소: https://github.com/dvlab-research/Stratified-Transformer \n\n비교 분석\n\n\n\n구분\n\nPointNet++\n\nPointEdgeSegNet\n\nKPConv\n\nRandLA-Net\n\nPoint Transformer\n\nStratified Transformer\n\n\n핵심 접근법\n\n계층적 집합 추상화\n\n그래프 엣지 특징 (GNN)\n\n공간 커널 컨볼루션 (CNN-like)\n\n무작위 샘플링 + 어텐션 풀링\n\n지역 셀프-어텐션 (Transformer)\n\n윈도우 기반 셀프-어텐션\n\n\nmIoU (S3DIS)\n\n~65.4%\n\n~68.0%\n\n~70.6%\n\n~70.0%\n\n~70.9%\n\n~74.5%\n\n\n대용량 처리\n\nX (부적합)\n\n△ (제한적)\n\nO (가능)\n\n◎ (최적)\n\nX (부적합)\n\n◎ (최적)\n\n\n추론 속도\n\n느림\n\n중간-느림\n\n매우 느림\n\n매우 빠름\n\n매우 느림\n\n빠름\n\n\nVRAM 요구량\n\n중간\n\n중간\n\n높음\n\n낮음\n\n매우 높음\n\n중간-높음\n\n\n주요 장점\n\n개념적 토대 제공\n\n명시적 관계 모델링\n\n높은 정확도, 표현력\n\n최고의 속도와 효율성\n\n강력한 문맥 추론\n\n최고의 정확도와 확장성\n\n\n주요 단점\n\n비효율적 샘플링\n\n확장성 한계\n\n높은 계산 비용\n\n정밀도 저하 가능성\n\n높은 계산 복잡도\n\n구조의 복잡성\n\n\n\n각 모델의 핵심 접근법을 서술적으로 비교하면 다음과 같다. PointNet++는 계층적 집합 추상화를, PointEdgeSegNet은 그래프 엣지 특징을, KPConv는 공간 커널 컨볼루션을, RandLA-Net은 무작위 샘플링을, Point Transformer는 지역 셀프-어텐션을, 그리고 Stratified Transformer는 윈도우 어텐션을 사용한다.\nS3DIS 데이터셋에 대한 성능을 비교하면, OA와 mIoU 지표 모두에서 Stratified Transformer가 각각 약 94.1%, 약 74.5%로 가장 높은 성능을 보인다. 그 뒤를 이어 Point Transformer, KPConv, RandLA-Net이 유사한 성능 그룹을 형성하며, PointEdgeSegNet과 PointNet++가 그 뒤를 잇는다.\n대용량 처리 능력 측면에서는 RandLA-Net과 Stratified Transformer가 가장 최적화된 성능을 보인다. 반면 KPConv는 처리가 가능하지만 높은 리소스를 요구하며, PointNet++, PointEdgeSegNet, Point Transformer는 대용량 처리에 부적합하다.\nVRAM 요구량과 추론 속도는 효율성과 직결된다. RandLA-Net은 가장 적은 VRAM과 가장 빠른 추론 속도를 보여준다. Stratified Transformer는 빠른 추론 속도를 유지하면서 중간 수준의 VRAM을 요구하여 효율성과 성능의 균형을 맞추었다. 다른 모델들은 상대적으로 많은 리소스를 필요로 하거나 느린 추론 속도를 보인다.\n결론\n점군 세분화 기술은 PointNet++의 계층적 구조에서 시작하여, KPConv와 같은 CNN 유사 접근법과 PointEdgeSegNet과 같은 GNN 접근법으로 발전해왔다. RandLA-Net은 대규모 처리를 위해 효율성에 초점을 맞춘 중요한 이정표를 제시했다. 최근에는 Point Transformer가 어텐션의 강력한 표현력을 입증했지만 계산 복잡도의 한계가 명확했다.",
    "reviews": [],
    "syllabus": [],
    "link": "http://daddynkidsmakers.blogspot.com/2025/10/blog-post_8.html",
    "pubDate": "2025-10-09T02:58:00.000Z",
    "creator": "Unknown",
    "categories": []
  },
  {
    "id": 4,
    "imageUrl": "",
    "title": "[MULTI] 모자란 변주의 아쉬움, 로스트 아이돌론스 : 베일 오브 더 위치",
    "description": "No description available",
    "reviews": [],
    "syllabus": [],
    "link": "https://bbs.ruliweb.com/news/board/11/read/2371",
    "pubDate": "Thu, 09 Oct 2025 15:36:56 +0900",
    "creator": "［RULIWEB］",
    "categories": [
      "리뷰"
    ]
  },
  {
    "id": 5,
    "imageUrl": "",
    "title": "OCP Summit 2025: The Open Future of Networking Hardware for AI",
    "description": "At Open Compute Project Summit (OCP) 2025, we’re sharing details about the direction of next-generation network fabrics for our AI training clusters. We’ve expanded our network hardware portfolio and are contributing new disaggregated network platforms to OCP. We look forward to continued collaboration with OCP to open designs for racks, servers, storage boxes, and motherboards [...]\nRead More...\nThe post OCP Summit 2025: The Open Future of Networking Hardware for AI appeared first on Engineering at Meta.",
    "reviews": [],
    "syllabus": [],
    "link": "https://engineering.fb.com/2025/10/13/data-infrastructure/ocp-summit-2025-the-open-future-of-networking-hardware-for-ai/",
    "pubDate": "Tue, 14 Oct 2025 00:00:20 +0000",
    "creator": "Unknown",
    "categories": [
      "Data Center Engineering",
      "Data Infrastructure",
      "DevInfra",
      "ML Applications",
      "Networking & Traffic",
      "Open Source"
    ]
  },
  {
    "id": 6,
    "imageUrl": "",
    "title": "298일차 - 유니티 할로윈 영상 이벤트 / 토스 게임 공모전 / 삼성 XR 기기 출시예정",
    "description": "영상: https://www.youtube.com/watch?v=vxV4aW-qgCY&t=3s\n \n \n\n\n\n유니티 할로윈 이벤트 \n링크 https://unitysquare.co.kr/event/communityevent/view?id=100?utm_source=eloqua&utm_medium=newsletter&utm_campaign=kr_newsletter_2509 \n\n \nSPOOKY UNITY CHALLENGE\n \nunitysquare.co.kr\n\n \n \n \n토스 HTML5 첼린지 이벤트\n링크 https://toss.im/apps-in-toss/game-challenge/neptune \n\n \n토스 게임 공모전 - HTML5 게임 챌린지 with 넵튠\n총 상금 규모 7,000만원! 장르 불문 HTML5 기반 창작 게임이면 누구나 지원할 수 있어요. 앱인토스 파트너십을 통한 수익화 기회, 놓치지 마세요.\ntoss.im\n\n \n삼성 프로젝트 무한 XR 기기 발매\n10월 22일에 출시예정\n가격은 200만원  후반대",
    "reviews": [],
    "syllabus": [],
    "link": "http://serverdown.tistory.com/1420",
    "pubDate": "Thu, 9 Oct 2025 19:08:45 +0900",
    "creator": "SIDNFT",
    "categories": [
      "유튜브",
      "삼성전자",
      "생존영상",
      "유니티",
      "유튜브",
      "토스"
    ]
  },
  {
    "id": 7,
    "imageUrl": "",
    "title": "2025년 추석 챌린지 미션은 어떻게 만들어졌나",
    "description": "추석 연휴가 3일남은 화요일입니다.\n다들 즐거운 추석 연휴 보내고 계신가요?\n3일부터 6일까지 제출하신 미션들 보면서 저도 더욱 알차게 추석 연휴를 보내고 있습니다.\n요 며칠간 계속 미션을 제출하면서 좀 해야할 것이 많구나? 라는 생각도 들고,\n어제 미션을 제출하신 분들은 이 챌린지에는 되게 특이한 미션들이 몇가지가 있구나? 라는 생각도 하셨을 것 같아요.\n오늘은 왜 이런 특별 미션들을 추가했는지, 기본 미션은 왜 그렇게 구성했는지를 이야기 드릴려고 합니다.\n보통 이런 챌린지 혹은 코호트 교육에서는 참여를 독려하기 위해 가능하면 미션에 대해서는 허들을 좀 낮추고, 가능하면 쉽게 할 수 있는 방법들을 택하는데요.\n저희는 이번 미션을 좀 더 해야할 것이 많게 해두었어요.\n강의명\n강의 화면 혹은 학습 환경 캡쳐\n수강 중인 강의 링크\n\n\n아무래도 그냥 인증샷만 올림 되는데 왜 이렇게 해야할 것이 많은가 싶어서 귀찮으셨을 것을 같아요.\n실제로 저 항목을 다 채우지 못하고 제출하신 분들도 계셔서, 그런 부분도 감안해서 미션 피드백을 드리고 있기도 하구요.\n조금은 귀찮더라도 이렇게 매일 매일 달성해야할 미션에 링크와 공부 화면까지 캡쳐를 요청 드린 이유는 이 챌린지가 끝나고 나서의 뿌듯함을 더 크게 드리고 싶었기 때문입니다.\n저는 무슨 일이든 시작할때의 감정 보다는 끝났을때의 감정이 중요하다고 보는 편인데요.\n이를테면 쉬는 날 아침 일찍 헬스장에 가서 운동을 하는 행위 는 시작할때는 너무 힘듭니다.\n가기 싫어서 이불 속에서 몇분을 뒤척이기도 합니다.\n근데 끝나고 나서는 기분이 너무 좋아서 그날 하루 전체를 기분 좋게 보낼 수 있습니다.\n그래서 어떻게 하면 이 챌린지의 끝에도 좋은 감정을 줄 수 있을까? 생각 했습니다.\n물론 연휴 내내 공부를 했다는 사실 하나만으로도 충분히 챌린지의 끝은 긍정적인 기분을 가져간다고 생각합니다.\n다만, 눈에 보이지 않는 내면만 쌓이면 그 끝이 조금은 아쉬움이 있을 것 같다는 생각이 들었습니다.\n모든 일에는 항상 액션과 결과 사이에 시간 간격이 있었습니다.\n액션을 취하자마자 바로 결과가 나오는 일들도 있지만,\n우리가 지금 하고 있는 공부/성장이라는 것은 거의 대부분 결과가 당장 나오지 않습니다.\n코테 공부를 바로 했다고 해서 바로 모든 코테를 통과한다던가, 갑자기 모든 서류 과정을 합격한다던가 하는 일은 잘 없죠.\n그러다보면 '아 이렇게 공부하는게 맞나?', '이 길이 맞나?', '그냥 놀걸 그랬나?' 라는 여러가지 생각이 들게 되죠.\n하지만 당장 눈에 결과가 보이지 않더라도 꾸준히 해오신 분들은 언제냐의 문제이지, 결국엔 어떤 형태로든 좋은 결과를 얻어가시는 것을 자주 목젹했어요.\n그렇다면 어떻게든 당장 눈에 결과가 보이지 않더라도 꾸준하게 공부하고 성장할 수 있는 방향으로 이끌어 나가는 것이 중요하다고 생각했어요.\n그래서 이 챌린지도 당장의 결과가 나오지 않더라도, 연휴 내내 꾸준히 무언가를 했음을 스스로도 알 수 있도록 증거를 남기는 방향으로 설계하게 되었습니다.\n감사하게도, 많은 분들이 이 미션을 좀 더 유의미하게 남도록 남겨주셔서 준비한 저희도 대단히 기뻤습니다.\n\n\n특별 미션은 이와는 조금 다른 의도가 있었는데요.\n어제 처음 제출하셨던 특별 미션을 비롯해서 이 챌린지에는 총 3개의 특별 미션이 있습니다.\n\n\n\n보름달 찾기\n강의 질문 남기기\n수강평 작성하기\n저희 인프런 로고는 매 기념일마다 로고를 기념일에 맞춰 변경을 해둡니다.\n그래서 이번 추석때도 보름달 로고를 사용을 했죠.\n\n\n앞으로도 이런 챌린지 혹은 함께 공부하는 무언가가 계속 있을텐데 그때마다 그 챌린지 혹은 행사 자체만 기억 나기 보다는 이번 연휴가 어떤 연휴이길 그래도 기억하셨으면 하는 마음에 첫번째 특별 미션을 준비했습니다.\n나머지 2개의 미션은 인프런이 추구하는 바를 좀 더 넓게 전달하고자 했습니다.\n인프런은 타 서비스와 달리 \"수강평과 질문/답변 내용 모두를 전체 공개\" 하는 플랫폼입니다.\n투명하게 수강생분들이 남긴 내용을 공개하는 것인데요.\n이는 강의를 수강하기 전, 최대한 많은 분들에게 속임수가 없는 구매 경험, 학습 경험을 주기 위함이 큽니다.\n결국 이 강의를 들어보신 분들의 수강평이나 이 강의를 들으면서 남긴 질문, 그에 따른 지식공유자분들의 답변등이 모여서 좀 더 투명한 정보가 공유되고 정보 격차 없는 학습 환경 조성이 가능하다고 믿고 있어요.\n그럼 이후에 수강을 고민하시는 분들에게 더욱 도움이 되리라는 것도 말이죠.\n그리고 AI가 답변해주는 이 시대에도, 결국은 가장 신뢰할만한 사람이 남긴 답변의 가치는 훼손되지 않는다고 믿고 있습니다.\n그런면에서 질문을 작성해서 지식 공유자분들께 답변을 받아보는 것은 AI에게 답변을 받는 것과는 전혀 다른 경험이라 이 역시도 경험시켜드리고 싶었습니다.\n결국은\n10일간의 열정을 눈에 보이는 어떤 결과물로 남겨드리고 싶은 마음\n성장에 집중하지만 그럼에도 이 연휴기간이 어떤 연휴였는지 한번은 상기시켜드리고 싶은 마음\n투명한 정보 공개를 통해 정보 격차 없는 학습 환경을 조성하고 싶은 마음\nAI 시대에도 신뢰할만한 사람에게 답변을 받아보는 경험을 시켜드리고 싶은 마음\n이 4가지가 모여서 이번 챌린지의 미션이 계획 되었습니다.\n이 4가지의 마음이 챌린지에 참여하시는 분들께도 잘 전달되었으면 하는 바램입니다.\n이 챌린지는 참여해주신 분들의 피드백에 따라 이후에도 계속 진행할지 말지를 결정할 것 같습니다.\n그러니 미션에 대한 피드백, 과정에 대한 피드백, 챌린지 자체에 대한 후기 등 무엇이든 좋으니 편하게 말씀주세요 :)\n저희는 언제든 감사한 마음으로 피드백을 받겠습니다.",
    "reviews": [],
    "syllabus": [],
    "link": "https://jojoldu.tistory.com/850",
    "pubDate": "Tue, 7 Oct 2025 19:20:49 +0900",
    "creator": "향로 (기억보단 기록을)",
    "categories": [
      "생각정리",
      "2025년 추석 챌린지",
      "인프런 챌린지",
      "추석 챌린지",
      "향로 챌린지"
    ]
  },
  {
    "id": 8,
    "imageUrl": "",
    "title": "미래기술 - AI 생성 게임",
    "description": "영상: https://www.youtube.com/shorts/EJ3qN6uVXDk\n\n\n\n현대 게임들은 많은 비중을 어마어마한 비용을 들여 그래픽수준을 높이는 것에 집중합니다.\n이 미용은 너무나크고 그렇다고 해서 성공을 보장하는 것도 아닙니다.\n시간을 너무 많이 들여 한세대가 뒤처지면 만회하기위해 더많은 돈이 들어가는데 이것은 엄청난 낭비 일 수 있습니다.\n정당히 만들어 한세대가 뒤처지기 전에 발매하는 것이 맞을 것입니다.\n \n일론 머스는 AI 가 생성한 게임을 26년에 출시할 예정이라고 합니다.\n아마도 이것은 그래픽 개발인력의 낭비를 해결해줄 것으로 예상됩니다.\n그래픽 문제만 해결된다면 게임 개발의 비용을 크게 줄일 수 있고\n아껴진 비용은 다른 곳에 투입되어 혁신을 일으킬 것입니다.",
    "reviews": [],
    "syllabus": [],
    "link": "http://serverdown.tistory.com/1426",
    "pubDate": "Sun, 12 Oct 2025 14:18:33 +0900",
    "creator": "SIDNFT",
    "categories": [
      "유튜브",
      "미래기술",
      "인공지능"
    ]
  },
  {
    "id": 9,
    "imageUrl": "",
    "title": "23살에 피싱사기 2억 당하고 멘탈유지하시는분 / 이분은 전생에 장군이셨습니다.",
    "description": "상황이 어질어질합니다만\n담담하게 잘 버티시고 계십니다.\n영상: https://www.youtube.com/watch?v=F6dZdcBghJU&t=203s\n\n\n\n \n담담하게 2억 털리고 1달을 이게 사기인지 몰랐다고함\n쩐닥\n \n그리고 여자 화장하는데 빡쌔군요\n얼굴을 빡세개 눌러야 화장이 먹나봅니다.",
    "reviews": [],
    "syllabus": [],
    "link": "http://serverdown.tistory.com/1422",
    "pubDate": "Fri, 10 Oct 2025 17:15:44 +0900",
    "creator": "SIDNFT",
    "categories": [
      "유튜브",
      "사기"
    ]
  },
  {
    "id": 10,
    "imageUrl": "",
    "title": "2025년 추석 챌린지 끝! (feat. 두려움을 추구하는 용기)",
    "description": "이번 추석 연휴 10.3부터 10.11까지 9일간의 챌린지가 마무리 되었습니다.\n다들 어떠셨나요?\n수강평으로, 카톡방으로 많은 분들이 후기를 남겨주셔서 이 긴 시간이 정말 알차게 보냈다는 생각이 드는데요.\n긴 시간 진행하신 분들 모두 고생하셨습니다.\n이번 챌린지를 진행하면서 런던 베이글의 창업자이신 료님의 에세이인 \"료의 생각 없는 생각\" 이 많이 생각 났어요.\n누군가 성장했다는 것은 꼭 성공했다는 말은 아니다.\n그저 두려움을 추구했음을 의미한다.\n작든 크든 성장했다는 것은 어둡고 보이지 않음을 알고도 발을 내딛은 용기에서 출발했다는 것이, 누군가들이 말하던 어떤 성공보다 훨씬 큰 의미가 있다고 나는 생각한다.\n뜬금없지만, 두려움을 알고도 터벅터벅 시작하는 용기 있는 모든 분들에게 진심으로 응원과 갈채를 보내고, 몸과 마음의 수고스러움도 세세히 살펴봐주기를 혼자 떠올려보는 아침.\n\n\n학습이라는 것은 실행한다고 해서 확실하게 보장되는 것이 없습니다.\n게임처럼 도파민이 충족되는 것이 확실하게 보장된다거나,\n운동처럼 근육이 찢어지고 생성되는 근육통이 확실하게 보장된다거나,\n수면처럼 피로가 풀리는 것이 확실하게 보장되는 등,\n이걸 실행하면 확실하게 보상으로 돌아오는 것이 있느냐 하면, 학습에는 그런 것이 없습니다.\n단기간에 학습하는 것만으로 눈에 띄는 어떤 보상이 생기지는 않죠.\n그렇기에 이번 챌린지에 참여하기로 결심했다는 것은 \"확실하게 보장된 결과가 있는 게임/운동/데이트/수면을 다 포기하고, 보장된 결과가 없는 것에 긴 연휴기간 전부를 쓰겠다\" 라는 불확실함을 알면서도 선택하는 용기가 필요합니다.\n불확실한 것을 알면서도 뛰어드는 용기에 누가 갈채를 보내지 않을 수 있을까요?\n이 챌린지에 참여하신 1,642분 모두에게 정말로 멋지다는 말씀을 드리고 싶어요.\n라이브에서도 잠깐 이야기드렸지만,\n우리 모두는 무한 게임에 참여중이고, 이 무한게임에서 중요한 것 중 하나는 꺼지지 않는 갈망의 불씨를 만들고 유지하는 것입니다.\n아궁이 속 불씨는 한번 불씨가 붙기가 힘들지만, 불씨가 붙고 나서 커진 뒤에는 이 불씨가 꺼지기 전에 또다른 아궁이로 옮기고, 또 꺼지기 전에 다른 아궁이로 불씨를 옮기면서 영원히 꺼지지 않도록 합니다.\n각자가 갖고 있는 마음속 불씨가 분명히 있다고 저는 믿고 있습니다.\n다만, 그 불씨가 붙는건 혼자의 힘으로 안될 때가 많습니다.\n그럴때 함께하는 연대의 힘이 중요한 것 같습니다.\n그래서 아궁이에 불씨가 붙도록 누군가 부채질을 막 하기도 하죠.\n이번 챌린지도 딱 그 부채질 정도의 역할이 되길 바랬습니다.\n이렇게 붙은 불씨는 이제 각자의 더 많은 아궁이들로 옮겨다니면서 더더욱 커질것이라 믿습니다.\n9일이라는 긴 연휴내내 학습을 하겠다는 용기 있는 결심을 하신 것도,\n연휴 내내 아침,새벽,저녁 상관없이 학습과 미션을 진행하신 것도 너무 멋지다는 이야기를 꼭 드리고 싶었습니다.\n그리고 함께 공부하는 것이 얼마나 즐거운지,\n이 새벽시간에도 누군가는 나처럼 공부하고 있다는 사실이 얼마나 큰 위로가 되고 응원이 되는지를 다시금 알게 해주셔서 감사하다는 말씀도 드리고 싶습니다.\n최근 몇달간 제 마음속 불씨가 꺼질뻔한 순간들이 몇번 있었는데요.\n이번 챌린지를 진행하면서 오히려 저의 불씨가 훨씬 더 커질 수 있었습니다.\n참여하신 분들의 마음속 불씨를 붙이자는 목적으로 만들어진 챌린지가 도리어 저의 불씨를 더 키워준 것이죠.\n그래서 참 감사한 시간이였고, 제가 받은게 훨씬 많다는 생각을 했습니다.\n저희의 이번 챌린지는 12일 (일) 자정으로 마무리가 됩니다.\n그래도 챌린지가 종료된 이후에도 다들 좋은 습관과 기억을 가지고 다시금 일상에서 멋지게, 열정적으로 지내실 수 있을 것이라고 생각합니다.\n(일단 저부터 그럴 것 같아요! ㅎㅎ)\n추석 연휴 내내 감사했습니다.\n덕분에 저도 많은 힘을 얻었고, 더 재미나게 앞으로 인프런을 계속 발전시켜나가야겠다는 다짐을 다시금 했습니다.\n더 좋은 서비스로, 더 열정적인 모습으로 보답하겠습니다.\n다들 정말 고생 많으셨습니다.\n참여하신 분들의 후기를 일부 남겨둡니다.\n다들 너무 감사합니다.\n\n\n\n\n\n\n\n\n \n수강평 더보기",
    "reviews": [],
    "syllabus": [],
    "link": "https://jojoldu.tistory.com/851",
    "pubDate": "Sun, 12 Oct 2025 22:18:46 +0900",
    "creator": "향로 (기억보단 기록을)",
    "categories": [
      "생각정리",
      "인프런",
      "인프런 챌린지",
      "인프런 추석 챌린지",
      "추석 챌린지",
      "향로",
      "향로 챌린지"
    ]
  },
  {
    "id": 11,
    "imageUrl": "",
    "title": "TCP vs UDP – latency 차이",
    "description": "강의 자료를 만들면서 ‘이미 연결이 되어있고 재전송이 일어나지 않는다는 전제 하에 tcp와 udp의 latency차이가 없다’라는 내용을 적다가 혹시 몰라서 ai한테 이 내용에 대해 물어봤다. chatgpt, copilot – ‘거의 차이가 없다’ 라고 대답gemini – ‘[명백]하게 udp가 빠르다’ 라고 대답 ai가 코드를 짜서 돌려봤겠냐, 넷상에 퍼진 얘기들 조합해서 답을 해주니 이 모양이지. 시퀀스를 맞춰보고 슬라이딩 윈도우를 조절하는 … More TCP vs UDP – latency 차이",
    "reviews": [],
    "syllabus": [],
    "link": "https://megayuchi.com/2025/10/07/tcp-vs-udp-latency-%ec%b0%a8%ec%9d%b4/",
    "pubDate": "Tue, 07 Oct 2025 01:59:44 +0000",
    "creator": "megayuchi",
    "categories": [
      "Development",
      "Network",
      "socket",
      "Win32",
      "winsock"
    ]
  },
  {
    "id": 12,
    "imageUrl": "",
    "title": "Meet JetBrains at Azure Dev Summit 2025 (Lisbon, Oct 13–16)",
    "description": "JetBrains will be at Azure Dev Summit 2025 in Lisbon, and we’d love to connect with attendees interested in learning more about our products and services.  My name is Max Solovyev, and I’m the Head of Growth at .NET and GameDev Tools – I’ll be on site and available throughout the event for brief, no-pressure […]",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.jetbrains.com/dotnet/2025/10/07/meet-jetbrains-at-azure-dev-summit-2025/",
    "pubDate": "Tue, 07 Oct 2025 20:06:48 +0000",
    "creator": "Maxim Solovyev",
    "categories": [
      "net-tools",
      "events",
      "news",
      "dotultimate",
      "resharper",
      "rider"
    ]
  },
  {
    "id": 13,
    "imageUrl": "",
    "title": "CLion Now Supports DAP Debuggers",
    "description": "The latest EAP build of CLion 2025.3, released yesterday, includes support for the Debug Adapter Protocol (DAP), which allows CLion to communicate with a variety of additional debuggers. Besides the bundled LLDB and GDB, you can now work with third-party implementations that support DAP. This feature brings CLion closer to becoming an IDE that is […]",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.jetbrains.com/clion/2025/10/dap-debuggers/",
    "pubDate": "Tue, 07 Oct 2025 13:22:21 +0000",
    "creator": "Oleg Zinovyev",
    "categories": [
      "eap",
      "news",
      "dap",
      "debugger",
      "msvc"
    ]
  },
  {
    "id": 14,
    "imageUrl": "",
    "title": "Introducing the React Foundation: The New Home for React & React Native",
    "description": "Meta open-sourced React over a decade ago to help developers build better user experiences. Since then, React has grown into one of the world’s most popular open source projects, powering over 50 million websites and products built by companies such as Microsoft, Shopify, Bloomberg, Discord, Coinbase, the NFL, and many others. With React Native, React [...]\nRead More...\nThe post Introducing the React Foundation: The New Home for React & React Native appeared first on Engineering at Meta.",
    "reviews": [],
    "syllabus": [],
    "link": "https://engineering.fb.com/2025/10/07/open-source/introducing-the-react-foundation-the-new-home-for-react-react-native/",
    "pubDate": "Tue, 07 Oct 2025 18:00:01 +0000",
    "creator": "Unknown",
    "categories": [
      "Open Source"
    ]
  },
  {
    "id": 15,
    "imageUrl": "",
    "title": "리눅스 명령어 모음",
    "description": "파일 복사\nrsync -avhP --info=progress2 [src] [dest]\n더보기\n\n \nremote sync의 약어\n \n[옵션]\n-a : 원본의 시간을 보존\n-v : 진행상황\n-h : 사람이 읽기 편한 용량 단위\n-P : 이어받기\n--info=progress2 : 총 복사 진행률 표시\n--remove-source-files : 복사 완료시 src의 데이터 삭제\n \n[결과 예시]\n   &nb..",
    "reviews": [],
    "syllabus": [],
    "link": "http://sacstory.tistory.com/entry/%EB%A6%AC%EB%88%85%EC%8A%A4-%EB%AA%85%EB%A0%B9%EC%96%B4-1",
    "pubDate": "Fri, 10 Oct 2025 20:50:23 +0900",
    "creator": "summerandwinter",
    "categories": [
      "리눅스/리눅스 - 공통"
    ]
  }
]