[
  {
    "id": 1,
    "imageUrl": "",
    "title": "The State of CI/CD in 2025: Key Insights from the Latest JetBrains Survey",
    "description": "Introduction The CI/CD tools market has become increasingly complex over the past few years. DevOps engineers now have to manage a wide range of tools, all with their own complex setups and features.  JetBrains’ TeamCity and Research departments came together to produce a joint survey looking into the CI/CD tool market in 2025. To gain […]",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.jetbrains.com/teamcity/2025/10/the-state-of-cicd/",
    "pubDate": "Mon, 06 Oct 2025 12:45:59 +0000",
    "creator": "Olga Bedrina",
    "categories": [
      "cicd",
      "jetbrains-research",
      "news",
      "newsletter",
      "survey"
    ]
  },
  {
    "id": 2,
    "imageUrl": "",
    "title": "Introducing the React Foundation: The New Home for React & React Native",
    "description": "Meta open-sourced React over a decade ago to help developers build better user experiences. Since then, React has grown into one of the world’s most popular open source projects, powering over 50 million websites and products built by companies such as Microsoft, Shopify, Bloomberg, Discord, Coinbase, the NFL, and many others. With React Native, React [...]\nRead More...\nThe post Introducing the React Foundation: The New Home for React & React Native appeared first on Engineering at Meta.",
    "reviews": [],
    "syllabus": [],
    "link": "https://engineering.fb.com/2025/10/07/open-source/introducing-the-react-foundation-the-new-home-for-react-react-native/",
    "pubDate": "Tue, 07 Oct 2025 18:00:01 +0000",
    "creator": "Unknown",
    "categories": [
      "Open Source"
    ]
  },
  {
    "id": 3,
    "imageUrl": "",
    "title": "유료 AI 툴, 아직도 돈 내고 쓰세요? '로컬 AI'로 전환해야 하는 5가지 결정적 이유",
    "description": "2025년, 유료 AI 서비스 이용료에 대한 걱정이 크셨을 수 있습니다. 데이터 프라이버시 보호, 비용 절감, 그리고 고성능 오픈소스 모델의 지속적인 발전은 '로컬 AI'로의 전환을 단순한 선택이 아닌 필수적인 흐름으로 만들고 있습니다. 본 아티클에서는 로컬 AI에 주목해야 할 다섯 가지 핵심적인 이유를 상세히 다루고자 합니다.\n  로컬 AI 모델, 유료 서비스에 필적하는 성능!\n\n\n오늘날 온라인 AI 도구들은 눈부신 발전을 거듭해왔습니다. 그러나 실제 사용 과정에서 매월 발생하는 구독료가 큰 부담으로 다가오거나, 무료 버전은 제한된 기능과 낮은 성능의 모델만을 제공하는 경우가 빈번합니다. 특정 작업에 특화된 로컬 코딩 AI를 개발하며, GitHub Copilot과 같은 유료 서비스에 의존할 필요가 있을지에 대한 의문이 생겼습니다. 개인 정보 보호와 불합리한 구독료 문제를 고려할 때, 이제는 로컬 환경에서 AI 모델을 운영하는 것이 훨씬 더 현명한 대안이 될 수 있습니다.\n무료 오픈소스, 유료 서비스와 견주다\n최근 오픈소스 AI 생태계는 놀라운 속도로 확장되고 있습니다. GPT-5와 같은 범용적인 '만능' 모델은 아닐지라도, Llama, Mistral, Gemma, DeepSeek 등 여러 모델들은 특정 분야에서 탁월한 성능을 발휘합니다. 이러한 모델들을 사용자 자신의 환경에서 직접 실행함으로써, 각 작업의 특성에 맞춰 가장 적합한 모델을 자유롭게 선택하고 활용하는 유연성을 확보할 수 있습니다. 이는 사용자에게 상당한 편의를 제공합니다.\n이러한 오픈소스 모델들은 유료 AI 서비스와 견주어도 손색없는 역량을 지니고 있습니다. 특정 전문 작업에서는 신중하게 선정된 로컬 오픈소스 모델이 ChatGPT나 GitHub Copilot 같은 클라우드 기반 AI와 동등하거나 그 이상의 성능을 선보이는 사례도 흔합니다. 현재 수백여 종에 달하는 다양한 모델들이 존재하며, 사용자 개개인의 필요에 꼭 맞는 최적의 모델을 선택할 수 있습니다. 단, 모델의 파라미터 수가 증가할수록 요구되는 하드웨어 사양 또한 높아진다는 점은 유념해야 합니다.\n  팁: 로컬 AI 모델 최소 사양 가이드\n일반적으로 다음 사양을 고려하는 것이 좋습니다.\n모델 파라미터 수\n최소 RAM\n\n\n\n\n7B 모델\n최소 8GB RAM\n\n\n13B 모델\n최소 16GB RAM\n\n\n33B 모델\n최소 32GB RAM\n\n\n\n또한, 일부 AI 모델은 용량이 상당히 크므로 넉넉한 디스크 공간을 확보하는 것도 중요해요. 최신 컴퓨터라면 대부분 로컬 AI 모델을 실행할 수 있습니다. 파라미터 수가 낮은 모델은 복잡한 작업을 처리하는 데 한계가 있지만, 훨씬 더 빠르게 사용할 수 있죠. 핵심은 여러분의 요구사항에 맞는 모델을 선택하는 것입니다.\n  로컬 AI, 간편하게 시작할 수 있어요!\n이토록 강력한 AI 모델들을 개인 컴퓨터에서 구동하는 과정이 복잡할 것이라는 오해가 있을 수 있습니다. 하지만 LM Studio나 Ollama와 같은 사용자 친화적인 애플리케이션 덕분에 로컬 LLM의 이점을 누리는 것은 놀라울 정도로 간단합니다. 이러한 도구들은 다양한 오픈소스 AI 모델에 대한 접근을 용이하게 하며, 모델 다운로드 및 실행 과정을 간편하게 지원합니다.\nLM Studio: 로컬 AI를 위한 직관적인 플랫폼\n필자는 개인적으로 직관적인 GUI를 제공하는 LM Studio를 선호합니다. 물론 다양한 다른 대안들도 존재하므로, 사용자 본인에게 가장 적합한 도구를 찾아보는 것도 현명한 선택입니다. LM Studio의 설치 및 AI 모델 설정 과정은 매우 직관적이고 간단하게 이루어집니다.\n\n \nLM Studio - Local AI on your computer\nRun local AI models like gpt-oss, Llama, Gemma, Qwen, and DeepSeek privately on your computer.\nlmstudio.ai\n\n \n\n\n  LM Studio 설정 단계\n\n공식 웹사이트에서 LM Studio를 다운로드하여 설치 프로그램을 실행합니다.\n설치 마법사가 나타날 수 있는데, 오른쪽 상단의 회색 'Skip' 버튼을 클릭하여 건너뛸 수 있습니다.\n주요 인터페이스가 로드되면, LM Studio는 필요한 드라이버나 업데이트를 자동으로 다운로드하기 시작할 거예요. 이 과정이 완료될 때까지 잠시 기다려주세요.\n돋보기 아이콘을 클릭하여 'Discover' 탭을 열고, 다운로드하려는 모델을 검색합니다. 하단 왼쪽의 녹색 'Download' 버튼을 클릭하여 진행합니다.\n모델 다운로드가 완료되면 'Chat' 섹션으로 이동하여 디스플레이 상단의 드롭다운을 클릭해 다운로드한 모델을 로드합니다.\n위의 과정을 마치면, 이제 사용자는 다운로드한 AI 모델과 직접 대화를 시작할 수 있습니다. 선택한 모델의 역량에 따라서는 문서 파일 분석이나 정보 추출과 같은 고급 기능도 활용 가능합니다. LM Studio는 각 모델이 지원하는 기능을 명확하게 안내하므로, 이미지 분석 또는 생성 능력을 갖춘 모델 또한 어렵지 않게 찾아볼 수 있습니다.\n  데이터 프라이버시 완벽 보호, 민감한 작업도 안심!\n많은 사용자들이 이미 다양한 무료 온라인 챗봇을 활용하여 AI 서비스를 이용하고 있습니다. 그러나 이러한 웹 기반 도구들은 사용자 입력 데이터가 서비스 제공업체의 서버로 전송되어 학습에 활용될 수 있다는 본질적인 우려를 안고 있습니다. 이로 인해 코딩과 같이 민감한 정보를 다루는 작업에는 AI를 적용하기 어려운 경우가 발생합니다.\n대부분의 클라우드 기반 AI 챗봇은 정식 구독 없이 생성된 결과물을 상업적으로 이용하는 것을 제한하는 정책을 두고 있습니다. 그러나 로컬 환경에서 AI를 실행할 경우, 이러한 제약으로부터 완전히 벗어날 수 있습니다. 사용자의 AI와의 모든 상호작용은 개인 컴퓨터 내부에서만 이루어지므로, 이전에는 상상하기 어려웠던 다양한 프로젝트에 AI를 안심하고 통합하여 활용할 수 있습니다.\n⚠️ 주의: 웹 기반 AI 사용의 잠재적 위험\n온라인 AI 툴은 편리하지만, 입력 데이터가 서버로 전송되어 학습에 사용될 수 있습니다. 이는 특히 기업 기밀, 개인 정보, 또는 지적 재산권이 포함된 작업에는 큰 위험 요소가 될 수 있으니 항상 유의해야 합니다.\n로컬 AI는 데이터 수집, 사용자 입력 학습, 또는 외부 기업의 모니터링으로부터 완전히 자유롭습니다. 이는 단순한 데이터 프라이버시 보호를 넘어섭니다. 로컬 AI 모델을 운용함으로써 사용자는 데이터 보존 정책이나 정보 오용 가능성에 대한 우려 없이 온전한 창작의 자유를 만끽할 수 있습니다.\n이제 민감한 업무 관련 프로젝트, 개인적인 창작 활동, 그리고 다양한 실험적인 아이디어에 AI를 아무런 걱정 없이 적용할 수 있게 되었습니다. 특히 기업 기밀이나 민감한 데이터를 다루는 전문가들에게는 이러한 강력한 프라이버시 보호 기능만으로도 로컬 AI로의 전환을 고려할 충분한 근거가 될 것입니다.\n\n\n  AI 구독료 해방, 비용 부담에서 벗어나세요!\n매월 반복되는 AI 도구 구독료에 지쳐 있다면, LM Studio와 같은 플랫폼이나 기타 대안을 활용하여 주말 동안 로컬 AI 모델을 체험해보는 것을 강력히 권장합니다. Mistral 7B Instruct나 Gemma 3와 같은 모델들은 로컬 AI를 처음 접하는 사용자에게 훌륭한 시작점이 될 수 있습니다.\n모든 유료 구독을 즉시 중단할 필요는 없습니다. 우선적으로 로컬 AI를 시험해보고, 핵심적인 서비스는 유지하되, 개인의 필요를 충분히 충족시키는 로컬 모델을 발견하면 점진적으로 구독을 줄여나가는 전략을 추천합니다. 필자는 불과 한 달 만에 대부분의 AI 구독 서비스를 해지할 수 있었습니다. 로컬 AI는 온라인 서비스가 제공하기 어려운 독점적인 장점들을 가지고 있으며, 약간의 성능 또는 지능적 역량의 차이가 있더라도 그 가치는 충분히 보상받을 수 있다고 생각합니다.\n이제 더 이상 AI 구독료를 지불할 필요가 없어졌습니다. 이 혜택은 여러분에게도 동일하게 적용될 수 있습니다.\n  핵심 요약\n1. 오픈소스 로컬 AI, 유료 서비스와 견줄 만한 성능! Llama, Mistral 등 특정 작업에 특화된 모델들이 무료로 고성능을 제공합니다.\n2. LM Studio 활용, 로컬 AI 입문도 간편하게! 직관적인 GUI로 모델 다운로드부터 실행까지 쉽게 할 수 있습니다.\n3. 강력한 데이터 프라이버시, 민감 정보도 안심! 개인 정보나 기업 기밀도 걱정 없이 AI를 활용할 수 있습니다.\n4. AI 구독료 해방, 장기적인 비용 절감 효과! 점진적으로 로컬 AI로 전환하여 비용 부담을 줄일 수 있습니다.\n로컬 AI의 세계로 뛰어들어, 더욱 자유롭고 효율적인 AI 경험을 만끽하세요!\n❓ 자주 묻는 질문 (FAQ)\nQ1: 로컬 AI를 사용하려면 고성능 컴퓨터가 꼭 필요한가요?\nA1: 반드시 고성능 컴퓨터가 필요한 것은 아닙니다. 7B 규모의 모델은 8GB RAM으로도 원활하게 실행되며, 대부분의 최신 개인용 컴퓨터에서 로컬 AI를 구동할 수 있습니다. 그러나 더 큰 파라미터 모델을 사용하려면 16GB 또는 32GB RAM이 권장됩니다. 핵심은 사용 목적에 부합하는 모델을 선택하는 것입니다.\nQ2: LM Studio 외에 다른 로컬 AI 툴도 추천해주실 수 있나요?\nA2: 물론입니다. LM Studio 외에도 Ollama와 같은 뛰어난 로컬 AI 플랫폼들이 다양하게 존재합니다. 각 도구는 사용자 인터페이스, 지원 모델, 그리고 제공 기능에 있어 소소한 차이가 있을 수 있으니, 여러 가지를 직접 사용해보며 본인에게 가장 적합한 툴을 탐색해보시길 권합니다.\nQ3: 로컬 AI 모델도 상업적으로 이용할 수 있나요?\nA3: 예, 대다수의 로컬 AI 모델은 오픈소스 라이선스를 기반으로 하므로 상업적 사용이 자유롭습니다. 유료 온라인 AI 도구와 달리 구독료 없이도 상업적 활용이 가능하다는 점이 큰 이점입니다. 다만, 각 모델별로 적용되는 구체적인 라이선스 정책을 한 번 더 확인하는 것이 바람직합니다.\nQ4: 로컬 AI로 전환하는 과정에서 유료 구독을 한 번에 다 끊어야 할까요?\nA4: 그렇지 않습니다. 모든 유료 구독을 한꺼번에 해지하기보다는, 핵심적인 서비스를 유지하면서 로컬 AI 모델을 먼저 경험해보는 것을 추천합니다. 로컬 모델이 점차 사용자의 요구를 만족시키기 시작하면, 그에 맞춰 구독 서비스를 줄여나가는 것이 현명한 전환 접근 방식입니다.\n\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"FAQPage\",\n  \"mainEntity\": [\n    {\n      \"@type\": \"Question\",\n      \"name\": \"로컬 AI를 사용하려면 고성능 컴퓨터가 꼭 필요한가요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"반드시 고성능 컴퓨터가 필요한 것은 아닙니다. 7B 규모의 모델은 8GB RAM으로도 원활하게 실행되며, 대부분의 최신 개인용 컴퓨터에서 로컬 AI를 구동할 수 있습니다. 그러나 더 큰 파라미터 모델을 사용하려면 16GB 또는 32GB RAM이 권장됩니다. 핵심은 사용 목적에 부합하는 모델을 선택하는 것입니다.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"LM Studio 외에 다른 로컬 AI 툴도 추천해주실 수 있나요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"물론입니다. LM Studio 외에도 Ollama와 같은 뛰어난 로컬 AI 플랫폼들이 다양하게 존재합니다. 각 도구는 사용자 인터페이스, 지원 모델, 그리고 제공 기능에 있어 소소한 차이가 있을 수 있으니, 여러 가지를 직접 사용해보며 본인에게 가장 적합한 툴을 탐색해보시길 권합니다.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"로컬 AI 모델도 상업적으로 이용할 수 있나요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"예, 대다수의 로컬 AI 모델은 오픈소스 라이선스를 기반으로 하므로 상업적 사용이 자유롭습니다. 유료 온라인 AI 도구와 달리 구독료 없이도 상업적 활용이 가능하다는 점이 큰 이점입니다. 다만, 각 모델별로 적용되는 구체적인 라이선스 정책을 한 번 더 확인하는 것이 바람직합니다.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"로컬 AI로 전환하는 과정에서 유료 구독을 한 번에 다 끊어야 할까요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"그렇지 않습니다. 모든 유료 구독을 한꺼번에 해지하기보다는, 핵심적인 서비스를 유지하면서 로컬 AI 모델을 먼저 경험해보는 것을 추천합니다. 로컬 모델이 점차 사용자의 요구를 만족시키기 시작하면, 그에 맞춰 구독 서비스를 줄여나가는 것이 현명한 전환 접근 방식입니다.\"\n      }\n    }\n  ]\n}",
    "reviews": [],
    "syllabus": [],
    "link": "http://muzbox.tistory.com/483665",
    "pubDate": "Fri, 10 Oct 2025 11:14:23 +0900",
    "creator": "어떤오후의 프리웨어 이야기",
    "categories": [
      "AI, 미래기술/AI 인사이트",
      "AI 구독료 절감",
      "ai 모델 로컬 실행",
      "AI 비용 절약",
      "Gemma",
      "lm studio",
      "mistral",
      "데이터 프라이버시 AI",
      "로컬 ai",
      "오픈소스 ai",
      "유료 AI 툴"
    ]
  },
  {
    "id": 4,
    "imageUrl": "",
    "title": "유니티 스카이박스",
    "description": "영상: https://www.youtube.com/watch?v=j_fICoPhB1A\n\n\n\n \n스카이 박스 컨트롤 하는 법몰라 검색을 해봤습니다.\n스카이박스 어떻게 교체하는건지 메뉴가 없더군요\n영상보니 나왔습니다.\n카메라에서 하는게 아니군요\n \n\n\n \n스샷이 흐린데요 인스팩터 말고 라이팅이라는 UI 가 따로 있습니다.\n여기서 스카이박스 를 교체하는거더군요\n밤낮 바꾸는거 해봐야겠네요",
    "reviews": [],
    "syllabus": [],
    "link": "http://serverdown.tistory.com/1416",
    "pubDate": "Thu, 9 Oct 2025 02:45:25 +0900",
    "creator": "SIDNFT",
    "categories": [
      "프로그래밍/개발메모",
      "유니티"
    ]
  },
  {
    "id": 5,
    "imageUrl": "",
    "title": "포인트 클라우드 세그먼테이션 대표 기술인 Graph CNN 기반 모델과 Transformer 기반 모델 간 비교 분석",
    "description": "점군 세그먼테이션 분야에서 최근 Transformer 계열 모델이 설계되고 성능이 개선되고 있음에도 불구하고, RandLA-Net, PointCNN, KPConv 등 비교적 Graph CNN 기반 모델들이 여전히 널리 사용되고 높은 인지도를 유지하고 있다.여러 대표 오픈소스 모델의 특성, 리소스 요구, 구현 및 사용성 요소를 비교 분석하고, 인기 격차의 원인을 구조적으로 정리한다.\n\n모델 크기와 성능 비교 분석(Efficient 3D Semantic Segmentation with Superpoint Transformer)\n비교 분석\n먼저 GitHub 인기 지표와 구현 복잡도, 리소스 요구, 사용자 지원 등 요소들을 중심으로 모델 간 차이를 비교하였다. 예를 들어 RandLA-Net 공식 구현은 많은 사용자를 확보했으며, 여러 포팅 버전이 존재하고 커뮤니티 지원이 활발하다. PyTorch 포팅 중 하나는 399 스타를 보유하고 있다. (GitHub) Open3D 문서에서는 RandLA-Net을 “efficient and lightweight” 구조라고 명시하고 있어, 낮은 메모리 및 계산 요구를 강조하고 있다. (open3d.org) 반면 Point Transformer V3는 공식 저장소가 존재하고 활발히 관리되고 있으나 일부 사용자는 Scannet 데이터셋 검증 시 성능 이슈를 제기하기도 한다. (GitHub) PTv3 논문에서는 neighbor mapping 직렬화, 메모리 절감 설계 등을 통해 performance/efficiency trade-off를 극복하려는 노력을 보였다. (openaccess.thecvf.com)\n구조적 비교 관점에서, Graph CNN 기반 모델들은 복잡한 attention이나 토큰 샘플링 모듈이 적거나 전혀 없어서 구현 난이도가 낮고 디버깅 및 커스터마이즈가 수월하다. 반면 Transformer 기반 모델은 attention 모듈, neighbor 관계 처리, 메모리 관리, 병렬화 등 복합 요소가 포함되므로 구현 복잡도가 증가한다. 리소스 부담 측면에서도 Transformer 계열은 메모리 및 연산량이 클 가능성이 높다. 일부 모델은 최적화 설계를 포함하여 메모리 절감을 시도하지만, 여전히 대규모 점군 처리 시 병목 가능성이 크다. 사용성 및 커뮤니티 지원 측면에서는 Graph CNN 기반 모델들이 다양한 포팅 버전, 튜토리얼, 예제 코드, 버그 수정 커뮤니티 등이 누적되어 있어 연구자나 개발자가 처음 적용하기에 유리하다.\n아래 표는 대표 모델들에 대해 (가능한 범위 내에서) GitHub 지표, 구현 복잡도, 리소스 부담, 사용성 측면 요소들을 정리한 것이다.\n\n\n\n\n모델명\n\nGitHub 인기 / 지표 (스타, 포크 등)\n\n구현 복잡도 / 구조 특성\n\n리소스 부담 (메모리, 연산)\n\n사용성 / 문서화 / 커뮤니티 지원\n\n강점 / 한계 요인\n\n\nRandLA-Net (QingyongHu 공식)\n\n공식 저장소 스타 수 다소 높음 (공식 구현) (GitHub) 비공식 PyTorch 포팅 구현 중 하나는 399 스타 (GitHub)\n\n비교적 단순한 구조. 랜덤 샘플링 + 지역 특성 집계 방식 사용\n\n경량 설계. Open3D 문서에서는 “efficient and lightweight” 구조라고 표현됨 (open3d.org)\n\n다양한 포팅 구현체 존재, 튜토리얼 / 예제 코드 많음\n\n대규모 점군 처리에 유리. 복잡한 attention 연산 없음. 다만 일부 복잡한 장면이나 고밀도 세그먼테이션에서 성능 한계 가능\n\n\nPointCNN\n\nGraph CNN 기반 모델 중 하나. 다수 연구에서 인용됨 (GitHub 지표는 최근 기준으로는 덜 활발할 수 있음)\n\nconvolution-like 연산 + neighborhood 정렬 등의 구조\n\n중간 수준\n\n문헌 및 오픈소스 구현체들이 많이 존재\n\n구조적 직관성 강함. 다만 최신 기술 (attention 등) 도입이 제한적\n\n\nPoint Transformer V3\n\n공식 저장소 존재 (GitHub)\n\nTransformer 계열 구조 도입. neighbor mapping 직렬화 등 최적화 설계 포함\n\n논문에서 메모리 사용량을 대폭 낮춘다고 주장 (10배 절감) 및 처리 속도 3배 향상 등 언급됨 (openaccess.thecvf.com)\n\n활성 개발 중이며 이슈 트래킹 있음. 다만 일부 사용자들이 Scannet 검증 시 성능 이슈 지적 (GitHub)\n\n성능과 효율성의 균형을 목표로 설계됨. 다만 초기 안정성, 복잡한 구현 요소 존재\n\n\nStratified Transformer\n\nTransformer 기반 모델. 계층화된 attention 구조 채택 (논문 수준)\n\n복잡한 계층적 attention 설계\n\n메모리 부담 존재 가능성 높음\n\n공개 구현은 있지만 튜토리얼 / 예제 커버가 제한적일 수 있음\n\n복잡 장면, 다양한 스케일 처리 가능성 있음. 그러나 최적화가 어렵고 실제 환경 적용시 부담 있음\n\n\nSuperPoint Transformer\n\nTransformer 기반의 보다 실험적 구조\n\n점 수준 attention + 포인트 기준 특징 집계 병합\n\n메모리 및 연산 부담 클 가능성\n\n발표 및 구현 초기 단계, 사용자 피드백 및 버그 리포트 있음\n\n잠재력 있음. 다만 안정화 및 최적화가 관건\n\n\nPointNeXt\n\n변형된 구조 접목 모델\n\nconvolution + Transformer 혼합 또는 개선된 모듈 포함\n\n중간~높음\n\n비교적 문서화 수준 양호\n\n강점과 한계 요소 혼합됨. 실용성/최적화 정도가 중요\n\n\nCylinder3D\n\n특수 구조 (기둥 기반 처리)\n\n데이터 레이아웃 구조에 특화됨\n\n구조적으로 효율성을 기대할 수 있음\n\n응용 중심 구현 사례 있음\n\n특정 환경 (LiDAR 스캔, 도로 장면 등)에서 유리\n\n\nKPConv (PyTorch 버전)\n\n오픈소스 구현 존재\n\nkernel point convolution 구조\n\n중간 수준\n\n비교적 많은 구현체 존재\n\n다양한 변형 가능. 다만 attention 기반 최신 모델 대비 기능적 유연성 낮을 수 있음\n\n\n\n원인 분석\n위 비교를 바탕으로, 왜 RandLA-Net이나 PointCNN 같은 Graph CNN 기반 모델이 상대적으로 인기가 높고, 최신 Transformer 모델이 아직 덜 채택되고 있는지 원인별로 정리하면 다음과 같다.\nTransformer 기반 모델은 attention 모듈, 토큰 샘플링/집계 전략, 메모리 최적화 등 복잡한 구성 요소를 포함하는 경우가 많다. 이러한 복잡성은 초기 사용자에게 진입 장벽이 된다. 반면 Graph CNN 기반 모델은 구조가 단순하고 직관적이기 때문에 구현 오류 가능성이 적고 커스터마이즈가 비교적 쉽다.\nTransformer 구조는 포인트 간 상호작용을 계산하는 attention 연산이 많을 수 있다. 이로 인해 입력 포인트 수가 많아질수록 메모리 및 연산 부담이 커진다. 일부 모델은 이 문제를 완화하기 위한 설계를 포함하지만, 여전히 실제 대규모 환경에서는 병목 가능성이 존재한다.\nGraph CNN 기반 모델들은 이미 여러 후속 연구에서 사용되며, 오류 수정, 개선 버전, 다양한 데이터셋 대응 등이 누적되어 검증된 안정성을 지닌다. 따라서 연구자들은 실패 위험이 낮은 검증된 모델을 선호하는 경향이 있다. Graph CNN 기반 모델들은 여러 사용자가 포크하고 개선해 온 포팅 버전, 튜토리얼 자료, 데이터 전처리/후처리 코드 등이 풍부하다. 이로 인해 새 사용자가 접근하기 쉬운 생태계가 형성되어 있다. 반면 최신 모델은 발표 직후 공개가 되더라도 문서화 수준이나 예제 범위가 제한적일 수 있다.\n실제 응용 환경에서는 리소스 제약 (GPU 메모리, 실시간 처리 요구 등)이 강하게 작용한다. Graph CNN 기반 경량 모델들은 이러한 제약 환경에서도 동작 가능성이 높다. 반면 최신 모델이 이론적으로 유리하더라도 제약이 많은 환경에서는 적용이 어렵다. 이미 많이 사용되고 비교 논문들이 많은 모델은 기준 모델로 자리잡기 쉽다. 새로운 모델은 처음 채택될 때 추가 검증 비용, 코드 디버깅 비용 등이 필요하므로 사용자가 쉽게 옮기기 어렵다. 따라서 관성 효과가 생긴다.\n기존의 경량 또는 비전통(point convolution, 샘플링 기반 등) 모델들이 여전히 많이 쓰이고 인기 있는 이유 중 하나는, 최신 Transformer 기반 모델이 성능 면에서는 일부 우위가 있을지라도, 추가 비용 대비 얻는 이득이 크지 않은 경우가 많기 때문이다. 즉, 가성비 관점에서 Transformer 모델이 불리한 상황이 존재할 가능성이 높다.\n최근 리뷰 논문 “Evaluating Deep Learning Advances for Point Cloud”에서는 PTv3 등 최신 point 기반 Transformer 모델이 여러 도심 장면(urban-scene) 벤치마크에서 정확도 측면에서는 우위를 보인다고 평가하지만, 논문에서는 “높은 계산 비용Limitation”이 실제 응용에서 병목 요소로 작용할 수 있다고 지적한다. (d-nb.info)\n한편, PTv3 논문 자체에서도, 기존의 복잡한 neighbor search + positional encoding 방식을 단순화하고 직렬화된 neighbor mapping 등을 도입하여, 처리 속도 3배 향상과 메모리 사용량 10배 절감 효과를 주장한 것은, 기본 Transformer 구조가 비용 측면에서 부담이 크다는 인식을 전제로 한 설계 전략이다. (arxiv.org) 또한, DeepLA-Net이라는 최근 모델은 S3DIS 등 실내 점군 세그먼테이션 문제에서 더 적은 파라미터로도 PTv3를 능가한 성능을 달성했다고 보고하며, 단순 구조가 더 효율적일 수 있음을 시사한다. (openaccess.thecvf.com)\n또 다른 사례로, Superpoint Transformer는 적은 파라미터 수(약 212k)로도 여러 벤치마크에서 준수한 성능을 달성했으며, 코드 실행 시간이나 GPU 시간 측면에서도 효율적인 면을 강조한다. (arxiv.org) 또한 비교 논문 중 하나에서는, 새로운 모델이 RandLA-Net 대비 OA나 mIoU 면에서 약 3.0 % 또는 1.7 % 개선을 보였다는 보고가 있는데, 이 개선폭이 매우 크지 않음을 암시한다. (ScienceDirect)\n이들 사실을 바탕으로, 가성비 관점에서는 Transformer 계열이 비용 부담이 더 크고, 그 부담을 감수할 만큼의 성능 향상이 반드시 크지는 않다는 해석이 가능하다.\n아래는 가성비(trade-off) 관점에서 기존 모델이 유리한 경우와 Transformer 모델이 불리할 가능성이 높은 조건을 짚어보는 논리 흐름이다.\n\n기본 연산 비용 vs 성능 향상 폭: Transformer 구조에서 attention 모듈, positional encoding, neighbor 관계 계산 등은 비용이 크다. 따라서 이런 비용을 도입했을 때 얻는 성능 이득이 충분히 높지 않으면, 그 추가 비용 대비 실익이 작다. 예컨대 PTv3는 복잡한 neighbor search와 positional encoding을 일부 간소화하였고, 이를 통해 속도 및 메모리 절감을 달성했다고 하지만, 이러한 절감이 없었다면 전체 구조가 매우 무거웠을 것이다. (arxiv.org)\n리소스 제약 환경에서의 제약: 실제 응용 환경에서는 GPU 메모리 한계, 배치 크기 제한, 실시간 처리 요구 등이 존재한다. Transformer 모델이 메모리 병목을 유발하면 배치 크기를 줄이거나 간소화된 구조를 써야 하고, 이 경우 성능이 위축될 가능성이 있다. 반면 경량 모델(예: RandLA-Net)은 처음부터 자원 부담을 작게 설계했기 때문에 제약 환경에서도 안정 동작 가능성이 높다.\n구현 복잡성 및 안정성 비용: Transformer 계열은 복잡한 설계 요소 (attention, 샘플링 전략, hierarchical 구조, 메모리 최적화 등)를 많이 포함할 수 있다. 이러한 복잡성은 코드 버그, 디버깅 비용, 유지보수 비용을 증가시킬 수 있다. 경량 모델은 구조가 단순하므로 이러한 위험이 낮다.\n성능 누적 격차의 한계: 최신 모델이 기존 모델보다 우수한 성능을 보인다고 해도, 그 격차가 크지 않은 경우가 많다. 예컨대 어떤 논문에서는 RandLA-Net 대비 약 3.0 % 정도 향상했다고 보고한 바 있다. (ScienceDirect) 따라서 그 작은 격차를 얻기 위해 매우 큰 비용을 감수하는 것은 현실적으로 비효율적일 가능성이 높다.\n효율 최적화가 가능한 경량 모델의 확장 가능성: 일부 경량 모델은 이미 여러 최적화 기법, 하드웨어 친화적 연산, 포팅, 병렬화 등이 누적되어 왔다. 따라서 동일한 하드웨어에서 더 안정적으로 동작한다.\n 반면 Transformer 기반 모델은 최적화가 미흡한 구현일 가능성이 높고, 하드웨어 제약에 덜 친화적일 수 있다.\n\n기존 경량 기반 모델들과 Transformer 계열 모델 간 성능을 살펴보면, 실제로 큰 격차가 없는 경우가 상당히 많다. 최신 Transformer 모델은 일부 벤치마크에서 우위를 보이기도 하지만, 그 성능 향상 폭이 매우 크지는 않다. 반면 Transformer 구조가 도입하는 비용 (메모리, 연산, 구현 복잡성 등) 은 상당하다. 이런 맥락에서, 가성비 측면에서는 오히려 Transformer 계열이 불리한 경우가 많다고 볼 수 있다. 즉, 동일한 자원 또는 제한된 환경 하에서는 경량 또는 구조가 단순한 모델이 더 실용적 선택이 될 가능성이 높다.\n\n\n부록: 24GB VRAM 내 가성비 있는 점군 학습 모델\nGPU VRAM 24 GB 환경에서 실용성과 가성비를 고려했을 때 “가장 사용하기 좋다”고 판단할 수 있는 모델은 전통적인 경량 또는 절충형 구조 모델 중 하나가 될 가능성이 높다. 다만 “가장 좋다”는 조건은 사용자의 입력 규모, 배치 크기, 속도 요구, 세그먼테이션 난이도 등에 따라 달라지므로 아래는 여러 후보와 고려 요소를 같이 제시한다.\n고려 기준 정리\n먼저 24 GB VRAM 환경에서 모델 선택 시 고려해야 할 주요 요소들을 정리하면 다음과 같다.\n\n\n요소\n\n중요 이유\n\n\n메모리 사용량 (activation, 중간 피처 등)\n\nVRAM 한계 내에서 모델을 돌려야 하며, 배치 크기를 확보해야 함\n\n\n연산 효율 / 플롭스 비용\n\n연산량이 너무 많으면 속도 저하 / 병목 발생 가능\n\n\n구현 안정성 및 최적화 지원\n\n잘 최적화된 오픈소스가 있어야 버그 없이 돌릴 수 있음\n\n\n성능 대비 비용 (가성비)\n\n작은 리소스 증가로 얻는 성능 이득이 충분해야 함\n\n\n응용 환경 적합성\n\n대규모 점군 처리, 실시간 처리, 복잡 장면 등 조건 고려\n\n\n\n\n\n아래는 24 GB VRAM 환경에서 실용적 후보가 될 만한 모델들과 그 장단점을 정리한 것이다.\n\n\n\n모델\n\n장점 / 적합성\n\n단점 / 리스크\n\n\nRandLA-Net\n\n매우 경량 설계 + random sampling 기반 처리로 메모리 부담이 낮다. 논문에서는 1백만 점 처리 가능하다고 주장하며 효율성을 강조했다. (arxiv.org) 여러 실험에서 안정적 성능을 보이며 벤치마크에서 교차 검증된 모델임 (d-nb.info)\n\n세밀한 복잡 장면이나 더 복잡한 구조 관계 모델링에서는 한계가 있을 수 있음\n\n\nOctFormer\n\nTransformer 계열이지만 octree 기반 attention을 사용하여 계산 복잡도를 줄인 구조이다. 그 결과 대규모 점군 처리 시 연산 및 메모리 효율이 상대적으로 우수하다고 보고됨. (arxiv.org) 논문에서는 “17배 빠르다”는 주장을 포함함. (arxiv.org)\n\nTransformer 계열 특성상 일부 overhead가 남아 있으며, 실제 구현 최적화 여부가 중요하다\n\n\n경량 + Sparse + Attention 혼합 구조 모델\n\n예: “Real-Time Semantic Segmentation of Point Clouds Based on an Attention Mechanism and a Sparse Tensor” 논문처럼 sparse tensor + 경량 attention 구조를 쓴 모델이 있다. 이 경우 메모리 및 연산 절감 측면에서 유리하다. (mdpi.com)\n\n성능이 매우 복잡한 장면에서는 한계 있을 수 있으며, 구현 및 튜닝이 중요하다\n\n\n하이브리드 절충형 구조 (Convolution + Transformer 병합)\n\n적절히 설계된 하이브리드 모델은 Transformer의 글로벌 컨텍스트 장점과 convolution 계열의 효율성을 절충할 수 있다\n\n병합 방식 설계 복잡성, 메모리 overhead가 추가될 가능성 있음\n\n\n\n이 모든 것을 고려하면, RandLA-Net 계열 구조 또는 OctFormer 쪽이 24 GB VRAM 환경에서 가장 균형 잡힌 선택이 될 가능성이 크다.\n\nRandLA-Net은 이미 경량성과 안정성을 증명한 모델이다.\nOctFormer은 Transformer 계열이지만 octree attention을 통한 효율화가 설계되어 있어, 비교적 부담이 덜한 Transformer 방향 대안이 될 수 있다.\n만약 응용이 복잡 장면이나 많은 점군을 다룬다면, OctFormer 같은 구조 쪽이 더 유연성을 줄 가능성이 있다.\n따라서, 24 GB VRAM 기준으로 “가장 사용하기 좋다”는 점을 감안하면 RandLA-Net이 가장 무난한 선택이며, Transformer 계열 모델을 쓰고 싶다면 OctFormer이 현실적 대안이 될 것이다.",
    "reviews": [],
    "syllabus": [],
    "link": "http://daddynkidsmakers.blogspot.com/2025/10/graph-cnn-transformer.html",
    "pubDate": "2025-10-09T03:57:00.000Z",
    "creator": "Unknown",
    "categories": []
  },
  {
    "id": 6,
    "imageUrl": "",
    "title": "[MULTI] 잘 훈련된 퇴마사는 대략 0.5여고생 즉, 사일런트 힐 f",
    "description": "No description available",
    "reviews": [],
    "syllabus": [],
    "link": "https://bbs.ruliweb.com/news/board/11/read/2370",
    "pubDate": "Thu, 09 Oct 2025 00:31:32 +0900",
    "creator": "(RULIWEB`Д')/",
    "categories": [
      "리뷰"
    ]
  },
  {
    "id": 7,
    "imageUrl": "",
    "title": "AI 시대에 필요한 미덕 &quot;실행&quot;",
    "description": "한동안 글을 쓰지 않았다.  작가라는 타이틀도 생기고, 구독자도 생기면서 고퀄리티의 글을 써야한다는 강박도 생겼고, 실제로 예전만큼 좋은 아이디어가 떠오르지 않아서이기도 하다. 그리고 전문가라고 생각했던 부분에 대한 무지함이 느껴져서 일수도 있다.  세상이 참 많이 바뀌었다. 예전에는 글을 쓰기 위해서 정말 많은 고민을 하고 탈고를 했는데, 이제는 AI랑",
    "reviews": [],
    "syllabus": [],
    "link": "https://brunch.co.kr/@@H9i/88",
    "pubDate": "Tue, 07 Oct 2025 10:19:12 GMT",
    "creator": "권용진",
    "categories": []
  },
  {
    "id": 8,
    "imageUrl": "",
    "title": "유니티 보안 취약점 발견으로 새 버전으로 빌드 해야합니다. / 바이러스가 발견됨 문제 해결 방법",
    "description": "점점 뉴스가 크게 나고 있으며\n상점에 올라간 경우 업데이트 하라고 강력히 요구하고 있습니다.\n \n취약점 내용은 클립보드를 검사해서\n암호화폐지갑주소가 들어오면 공격자의 주소로 바꿔치는 공격 같습니다.\n \n \n \n\n\n유니티 허브에서는 이런식으로 위험하다는 표시를 해주고 있습니다.\n빨리 새버전 받아서 빌드해서 올립시다.\n \n1년치 차트인데요\n살아나는과정에서 최근 하락 중입니다.\n\n\n주가 떨어지면 사야겠습니다.\n \n \n문제혀결: \"바이러스가 발견됨\" 문제로 다운로드가 불가능한 경우\n\n\n저 같은 경우에는 유니티를 업그레이드 했지만\nwindows 빌드가 계속해서 바이러스에 탐지되서\n유저에게 링크를 줘도 다운로드를 못하는 문제가 생겼습니다.\n이 경우 앱아이콘을 바꿔서 빌드해보시기 바랍니다.\nexe 파일의 내용이 수정되어야 바이러스 탐지 프로그램이 다시 검사하는거 같습니다.\n \n \n설명 영상: https://youtu.be/vxV4aW-qgCY",
    "reviews": [],
    "syllabus": [],
    "link": "http://serverdown.tistory.com/1415",
    "pubDate": "Wed, 8 Oct 2025 16:07:37 +0900",
    "creator": "SIDNFT",
    "categories": [
      "투자",
      "유니티"
    ]
  },
  {
    "id": 9,
    "imageUrl": "",
    "title": "[DATA] S3에서 데이터 파티션 하는 법의 진실…",
    "description": "인터넷에서의 위의 링크의 글을 읽게되었다. 데이터 엔지니어링에서 오래 업무를 본 사람들은 습관적으로 아래 이미지와 같은 형태로 데이터를 파티셔닝 하는 경우가 많다. 크게 버컷에 데이터 종류에 따라 나누고 s3://bucket/data 부분 그뒤에 데이터의 생성 날짜에 따라 year=YYYY/month=MM/day=DD 형태로 나누는 것이다. 이렇게 나누면 뭐가 좋을까? 특정 데이터의 날짜로 읽거나 month로 읽거나 year 단위로 읽을 때 다른 데이터를 읽을 […]",
    "reviews": [],
    "syllabus": [],
    "link": "https://charsyam.wordpress.com/2025/10/08/data-s3%ec%97%90%ec%84%9c-%eb%8d%b0%ec%9d%b4%ed%84%b0-%ed%8c%8c%ed%8b%b0%ec%85%98-%ed%95%98%eb%8a%94-%eb%b2%95%ec%9d%98-%ec%a7%84%ec%8b%a4/",
    "pubDate": "Wed, 08 Oct 2025 01:56:11 +0000",
    "creator": "charsyam",
    "categories": [
      "Uncategorized"
    ]
  },
  {
    "id": 10,
    "imageUrl": "",
    "title": "주요 포인트 클라우드 세그먼테이션 학습 모델 조사 및 비교 분석",
    "description": "이 글은은 3D 점군 데이터 처리를 위한 주요 딥러닝 기반 세분화 모델들의 기술적 특성을 비교 분석하는 것을 목적으로 한다. 점군의 비정형적, 비순서적 특성을 처리하기 위해 제안된 PointNet++부터 시작하여 그래프 신경망, 컨볼루션 신경망의 개념을 확장한 모델들을 거쳐, 최근 가장 우수한 성능을 보이는 트랜스포머 기반 아키텍처에 이르기까지 각 모델의 핵심 개념, 구조적 특징, 성능, 그리고 실용성을 좌우하는 리소스 요구사항 등을 종합적으로 분석한다.\n\nPoint Transformer 구조\n평가의 객관성을 확보하기 위해, 주로 대규모 실내 데이터셋인 S3DIS(Stanford Large-Scale 3D Indoor Space)를 기준으로 성능을 기술하며, 특히 Area 5를 테스트셋으로 사용하는 표준 프로토콜의 결과를 인용한다. 평가 지표는 전체 포인트 분류 정확도를 나타내는 OA(Overall Accuracy)와 클래스별 평균 성능을 측정하는 mIoU(mean Intersection over Union)를 사용한다. mIoU는 클래스 불균형 문제에 강건하여 세분화 성능의 핵심 지표로 간주된다.\n\nPointNet++\n개념: PointNet++는 선구적인 모델인 PointNet이 점군 전체의 전역적 특징에만 집중하여 지역적(local) 구조 정보를 포착하지 못하는 근본적인 한계를 극복하기 위해 제안되었다. 이미지 처리 분야의 컨볼루션 신경망(CNN)이 계층적으로 receptive field를 넓혀가는 방식에 착안하여, 점군 내 작은 지역부터 시작해 점차 넓은 영역으로 특징을 단계적으로 집계하고 추상화하는 계층적 특징 학습(Hierarchical Feature Learning) 구조를 도입했다.\n\n구조적 특징: PointNet++의 핵심 구조는 Set Abstraction (SA) 모듈의 반복적인 적용에 있다. SA 모듈은 샘플링, 그룹핑, 그리고 특징 추출의 세 단계로 구성된다.\n샘플링(Sampling): Farthest Point Sampling (FPS) 방식을 사용하여 전체 점군으로부터 기하학적으로 가장 멀리 떨어진 점들을 순차적으로 선택한다. 이를 통해 더 넓은 영역을 대표하는 중심점(centroid)들을 효율적으로 정의할 수 있다.\n그룹핑(Grouping): 샘플링된 각 중심점을 기준으로 일정 반경 내의 모든 점 또는 K개의 가장 가까운 이웃 점들을 하나의 지역 집합으로 묶는다. 이 과정을 통해 전체 점군을 여러 개의 국소 영역으로 분할한다.\n특징 추출(Feature Extraction): 그룹핑된 각 지역 집합에 대해 PointNet(이를 '미니 PointNet'이라 칭함)을 적용한다. 미니 PointNet은 지역 집합 내의 점들의 좌표를 정규화하고, 다층 퍼셉트론(MLP)을 통해 각 점의 특징을 추출한 후, Max-Pooling 연산을 통해 지역 전체를 대표하는 하나의 특징 벡터를 생성한다.\n특징 전파(Feature Propagation): 세분화 작업을 위해 인코더에서 다운샘플링된 특징을 다시 원래 해상도의 모든 점으로 복원하는 과정이다. 업샘플링된 점의 특징은 저해상도 점들의 특징을 역거리가중(Inverse Distance Weighted) 보간법을 사용하여 계산하며, 인코더 단계의 Skip Connection을 통해 전달된 특징과 결합하여 세부 정보를 보존한다.\n\n장점은 계층적 구조를 통해 다양한 스케일의 기하학적 특징을 학습할 수 있다는 점이며, 이는 이후 대부분의 점군 처리 모델이 채택하는 표준적인 패러다임이 되었다. 반면, 단점으로는 FPS의 계산 복잡도가 점군 크기(N)와 샘플링할 점의 수(M)에 비례()하여 증가하므로 대규모 점군에 직접 적용하기 어렵다는 점이 있다. 또한, 고정된 반경으로 그룹핑하는 방식은 점군 밀도가 불균일할 경우 성능 저하를 야기할 수 있다.\n\n성능 (S3DIS Area 5): OA는 약 89.2%, mIoU는 약 65.4% 수준이다.\n대용량 처리: 부적합하다. 수만 개 이상의 점군에서는 FPS 연산이 심각한 병목 현상을 일으킨다.\n리소스 및 시간 요구사항: VRAM은 8에서 12GB가 필요하며, 학습 시간은 중간 정도 소요된다. 추론 시간은 FPS 때문에 실시간 처리가 어려워 느린 편이다.\nGitHub 주소: https://github.com/charlesq34/pointnet2\n\nPointEdgeSegNet\n이 모델은 점군을 하나의 그래프로 간주하는 그래프 신경망(GNN) 접근법을 채택했다. 특히 DGCNN에서 제안된 EdgeConv 연산을 U-Net 아키텍처에 통합하여, 점과 그 이웃 점들 간의 관계를 '엣지 특징'으로 명시적으로 모델링한다. 이를 통해 정확도와 효율성의 균형을 목표로 한다.\n\n구조적 특징: 구조의 핵심 연산은 EdgeConv이다. 이는 K-NN(K-Nearest Neighbors) 알고리즘으로 각 점의 이웃을 찾아 동적으로 그래프를 구성하고, 중심점의 특징()과 이웃점과의 상대적 위치 벡터()를 결합한 엣지 특징 [xi, xj - xi]을 생성한다. 이 엣지 특징은 중심점 자체의 정보와 주변의 기하학적 정보를 동시에 담고 있으며, MLP를 통과한 후 대칭 함수인 Max-Pooling으로 집계되어 중심점의 새로운 특징으로 갱신된다. 전체 구조는 대칭적인 인코더-디코더 구조인 U-Net을 채택하여, 인코더에서는 EdgeConv와 FPS를 통해 특징을 추출 및 다운샘플링하고, 디코더에서는 k-NN 보간과 Skip Connection으로 특징을 업샘플링하여 세부 정보를 보존한다.\n\n장점은 엣지 특징을 통해 점들 간의 기하학적 관계를 명시적으로 학습하므로 지역적 패턴에 대한 표현력이 우수하며, U-Net 구조 덕분에 정보 손실이 적다는 것이다. 공간인덱싱을 통한 대용량 점군을 격자 블럭으로 처리한 후 학습 및 예측하므로 대용량 점군 처리가 가능하다.\n\n성능 (S3DIS Area 5): 성능 추정치에 따르면, OA는 약 91.5%이다.\n대용량 처리: 제한적이다. FPS 대신 Grid Subsampling 등을 사용하면 일부 개선이 가능하다.\n리소스 및 시간 요구사항: VRAM은 10에서 16GB가 필요하며, 학습 시간은 중간 정도 소요된다. 추론 시간은 느린 편에서 중간 수준에 해당한다.\nGitHub 주소: https://github.com/mac999/point_edge_seg_net/tree/main\nKPConv\nKPConv는 이미지 CNN의 '컨볼루션 필터' 개념을 3D 공간으로 직접 일반화한 모델이다. 유클리드 공간에 미리 정의된 커널 포인트(Kernel Points)를 컨볼루션 필터의 핵으로 삼고, 이 커널 포인트들과 입력 점들 간의 거리에 따라 가중치를 적용하는 방식으로, 진정한 의미의 3D 공간 컨볼루션을 구현했다.\n\n구조적 특징: 핵심 연산인 KPConv는 구(sphere) 형태의 공간 안에 미리 정의된 커널 포인트들을 배치하는 방식으로 작동한다. 각 커널 포인트는 고유의 학습 가능한 가중치 행렬을 가지며, 입력 점과의 거리가 가까울수록 더 큰 영향력을 행사하도록 상관관계를 계산한다. 이 커널은 고정된 형태의 Rigid KPConv와, 지역 형상에 따라 커널 포인트의 위치가 동적으로 변형되는 Deformable KPConv로 나뉜다. 다운샘플링 방식으로는 FPS 대신 Grid Subsampling을 사용하여 점군을 복셀화하고 각 복셀의 중심점을 취하는 방식으로 대규모 데이터 처리 속도를 개선했다.\n장점은 유연하고 강력한 커널 덕분에 복잡한 기하학적 구조에 대한 표현력이 매우 뛰어나며, 높은 정확도를 달성한다는 것이다. 단점은 커널 기반 연산이 각 점과 모든 커널 포인트 간의 상호작용을 계산해야 하므로 계산 비용과 메모리 요구량이 매우 크다는 점이다.\n\n성능 (S3DIS Area 5): OA는 약 92.9%, mIoU는 약 70.6%이다.\n대용량 처리: 가능하다. Grid Subsampling 덕분에 수백만 점군 처리가 가능하지만, 리소스 요구량이 높다.\n리소스 및 시간 요구사항: VRAM은 16에서 24GB 이상으로 높은 편이며, 학습 시간도 길다. 추론 시간은 RandLA-Net 대비 수십 배 느려 느린 편에 속한다.\nGitHub 주소: https://github.com/HuguesTHOMAS/KPConv\n\nRandLA-Net\n이 모델은 대규모 점군을 실시간으로 처리하는 실용성에 초점을 맞춘 모델이다. '무작위 샘플링(Random Sampling)'을 통해 계산 복잡도를 획기적으로 낮추고, 이로 인해 발생할 수 있는 정보 손실은 강력한 '지역 특징 집계(Local Feature Aggregation, LFA)' 모듈로 보완하는 전략을 사용한다.\n\n구조적 특징: 샘플링 단계에서는 계산 비용이 전혀 없는 무작위 샘플링을 사용하여 인코더의 각 단계에서 점군을 대폭 줄인다. 핵심 블록인 LFA는 지역 공간 인코딩(LocSE), 어텐션 풀링(Attentive Pooling), 그리고 Dilated Residual Block으로 구성된다. LocSE는 이웃 점들의 상대적 위치 정보를 명시적으로 인코딩하고, 어텐션 풀링은 이웃들의 특징에 대해 학습 가능한 어텐션 가중치를 부여하여 중요한 특징을 선별적으로 집계한다. 이 어텐션 풀링이 무작위 샘플링의 단점을 보완하는 핵심 장치이다.\n장점은 압도적으로 빠른 처리 속도와 낮은 메모리 요구량을 가진다는 것이다. 수백만 개 이상의 점군을 단일 패스로 처리할 수 있다. 단점으로는 무작위 샘플링이 필연적으로 중요한 기하학적 특징을 가진 점을 누락시킬 수 있어, 작고 복잡한 객체에 대한 정밀도가 다른 정교한 모델들에 비해 다소 떨어진다는 점이 있다.\n\n성능 (S3DIS Area 5): OA는 약 92.2%, mIoU는 약 70.0%이다.\n대용량 처리: 최적화되어 있으며, 이것이 이 모델의 핵심 설계 목표이다.\n리소스 및 시간 요구사항: VRAM은 8에서 11GB로 낮은 편이다. 학습 시간은 짧고, 추론 시간은 매우 빨라 실시간 처리에 가장 근접한 모델로 평가된다.\nGitHub 주소: https://github.com/QingyongHu/RandLA-Net\n\n\nPoint Transformer\nPoint Transformer는 자연어 처리 분야에서 성공을 거둔 트랜스포머 아키텍처를 점군에 적용한 모델이다. PointNet++의 계층적 구조를 기반으로, 지역 특징 추출 부분을 셀프-어텐션(Self-Attention) 메커니즘으로 대체하여 점들 간의 문맥적 관계를 더욱 정교하게 학습한다.\n\n구조의 핵심인 Point Transformer Block은 지역 그룹 내의 한 점(Query)이 다른 모든 점(Key)들과 얼마나 관련이 있는지 어텐션 스코어를 계산하고, 이 스코어를 가중치로 삼아 모든 점들의 특징(Value)을 가중합하여 새로운 특징을 생성한다. 특히 점들 간의 상대적 위치 정보를 어텐션 계산에 명시적으로 포함시켜 기하학적 문맥을 강화한다.\n\n장점은 셀프-어텐션을 통해 복잡한 지역 패턴과 객체 파트 간의 상호작용을 효과적으로 모델링하여 높은 성능을 보인다는 것이다. 단점은 어텐션 연산이 그룹 내 점의 수(N)에 대해 제곱()에 비례하는 계산 복잡도를 가져 매우 비효율적이라는 점이다.\n\n성능 (S3DIS Area 5): OA는 약 93.0%, mIoU는 약 70.9%이다.\n대용량 처리: 부적합하다. 높은 계산 복잡도 때문에 대규모 점군에 적용할 수 없다.\n리소스 및 시간 요구사항: VRAM은 24GB 이상으로 매우 높고, 학습 시간도 매우 길다. 추론 시간 역시 매우 느리다.\nGitHub 주소: https://github.com/POSTECH-CVLab/point-transformer\nStratified Transformer\n이 모델은 대규모 점군에 트랜스포머를 효율적으로 적용하기 위해 이미지 분야의 Swin Transformer 아이디어를 3D로 확장한 모델이다. 계층적 샘플링과 윈도우 기반 지역 어텐션이라는 두 가지 핵심 전략을 통해 트랜스포머의 계산량 문제를 해결했다.\n\n구조적 특징: 다운샘플링에는 FPS와 Random의 장점을 결합한 Stratified Sampling 방식을 사용하여 효율적이면서도 공간을 균일하게 커버한다. 핵심은 윈도우 어텐션으로, 전체 공간을 겹치지 않는 작은 3D 윈도우(복셀)로 분할하고, 각 윈도우 내부에서만 지역적으로 어텐션을 수행하여 계산 복잡도를 점의 수에 비례하도록 낮춘다. 또한 윈도우 이동(Shifted Window) 기법을 통해 다음 레이어에서는 윈도우 경계를 이동시켜 인접 윈도우 간의 정보 교환을 가능하게 한다. 이를 통해 지역 어텐션만으로도 전역적인 문맥을 효과적으로 학습할 수 있다.\n장점은 트랜스포머의 강력한 표현력과 대규모 처리 능력을 겸비하여, 효율성과 정확도 모두에서 최고 수준의 성능을 보인다는 것이다. 단점은 모델 구조가 상대적으로 복잡하고, 윈도우 크기 등 하이퍼파라미터 설정에 민감할 수 있다는 점이다.\n\n성능 (S3DIS Area 5): OA는 약 94.1%, mIoU는 약 74.5%로 매우 높다.\n대용량 처리: 최적화되어 있다.\n리소스 및 시간 요구사항: VRAM은 11에서 16GB로 중간에서 높은 수준이며 RandLA-Net보다 높지만 KPConv보다 효율적이다. 학습 시간은 중간에서 긴 편이며, 추론 시간은 빠르다.\nGitHub 주소: https://github.com/dvlab-research/Stratified-Transformer \n\n비교 분석\n\n\n\n구분\n\nPointNet++\n\nPointEdgeSegNet\n\nKPConv\n\nRandLA-Net\n\nPoint Transformer\n\nStratified Transformer\n\n\n핵심 접근법\n\n계층적 집합 추상화\n\n그래프 엣지 특징 (GNN)\n\n공간 커널 컨볼루션 (CNN-like)\n\n무작위 샘플링 + 어텐션 풀링\n\n지역 셀프-어텐션 (Transformer)\n\n윈도우 기반 셀프-어텐션\n\n\nmIoU (S3DIS)\n\n~65.4%\n\n~68.0%\n\n~70.6%\n\n~70.0%\n\n~70.9%\n\n~74.5%\n\n\n대용량 처리\n\nX (부적합)\n\n△ (제한적)\n\nO (가능)\n\n◎ (최적)\n\nX (부적합)\n\n◎ (최적)\n\n\n추론 속도\n\n느림\n\n중간-느림\n\n매우 느림\n\n매우 빠름\n\n매우 느림\n\n빠름\n\n\nVRAM 요구량\n\n중간\n\n중간\n\n높음\n\n낮음\n\n매우 높음\n\n중간-높음\n\n\n주요 장점\n\n개념적 토대 제공\n\n명시적 관계 모델링\n\n높은 정확도, 표현력\n\n최고의 속도와 효율성\n\n강력한 문맥 추론\n\n최고의 정확도와 확장성\n\n\n주요 단점\n\n비효율적 샘플링\n\n확장성 한계\n\n높은 계산 비용\n\n정밀도 저하 가능성\n\n높은 계산 복잡도\n\n구조의 복잡성\n\n\n\n각 모델의 핵심 접근법을 서술적으로 비교하면 다음과 같다. PointNet++는 계층적 집합 추상화를, PointEdgeSegNet은 그래프 엣지 특징을, KPConv는 공간 커널 컨볼루션을, RandLA-Net은 무작위 샘플링을, Point Transformer는 지역 셀프-어텐션을, 그리고 Stratified Transformer는 윈도우 어텐션을 사용한다.\nS3DIS 데이터셋에 대한 성능을 비교하면, OA와 mIoU 지표 모두에서 Stratified Transformer가 각각 약 94.1%, 약 74.5%로 가장 높은 성능을 보인다. 그 뒤를 이어 Point Transformer, KPConv, RandLA-Net이 유사한 성능 그룹을 형성하며, PointEdgeSegNet과 PointNet++가 그 뒤를 잇는다.\n대용량 처리 능력 측면에서는 RandLA-Net과 Stratified Transformer가 가장 최적화된 성능을 보인다. 반면 KPConv는 처리가 가능하지만 높은 리소스를 요구하며, PointNet++, PointEdgeSegNet, Point Transformer는 대용량 처리에 부적합하다.\nVRAM 요구량과 추론 속도는 효율성과 직결된다. RandLA-Net은 가장 적은 VRAM과 가장 빠른 추론 속도를 보여준다. Stratified Transformer는 빠른 추론 속도를 유지하면서 중간 수준의 VRAM을 요구하여 효율성과 성능의 균형을 맞추었다. 다른 모델들은 상대적으로 많은 리소스를 필요로 하거나 느린 추론 속도를 보인다.\n결론\n점군 세분화 기술은 PointNet++의 계층적 구조에서 시작하여, KPConv와 같은 CNN 유사 접근법과 PointEdgeSegNet과 같은 GNN 접근법으로 발전해왔다. RandLA-Net은 대규모 처리를 위해 효율성에 초점을 맞춘 중요한 이정표를 제시했다. 최근에는 Point Transformer가 어텐션의 강력한 표현력을 입증했지만 계산 복잡도의 한계가 명확했다.",
    "reviews": [],
    "syllabus": [],
    "link": "http://daddynkidsmakers.blogspot.com/2025/10/blog-post_8.html",
    "pubDate": "2025-10-09T02:58:00.000Z",
    "creator": "Unknown",
    "categories": []
  },
  {
    "id": 11,
    "imageUrl": "",
    "title": "Meet JetBrains at Azure Dev Summit 2025 (Lisbon, Oct 13–16)",
    "description": "JetBrains will be at Azure Dev Summit 2025 in Lisbon, and we’d love to connect with attendees interested in learning more about our products and services.  My name is Max Solovyev, and I’m the Head of Growth at .NET and GameDev Tools – I’ll be on site and available throughout the event for brief, no-pressure […]",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.jetbrains.com/dotnet/2025/10/07/meet-jetbrains-at-azure-dev-summit-2025/",
    "pubDate": "Tue, 07 Oct 2025 20:06:48 +0000",
    "creator": "Maxim Solovyev",
    "categories": [
      "net-tools",
      "events",
      "news",
      "dotultimate",
      "resharper",
      "rider"
    ]
  },
  {
    "id": 12,
    "imageUrl": "",
    "title": "Visual Studio Dev/Test Benefit Explained",
    "description": "Before joining Microsoft, I served as VP of Application Development at one of the largest temporary staffing companies in the United States. I’ll never forget the look on our CFO’s face when I told him we needed two to three additional cloud environments to support a large-scale modernization project. His expression went from curious to […]\nThe post Visual Studio Dev/Test Benefit Explained appeared first on Visual Studio Blog.",
    "reviews": [],
    "syllabus": [],
    "link": "https://devblogs.microsoft.com/visualstudio/visual-studio-dev-test-benefit-explained/",
    "pubDate": "Mon, 06 Oct 2025 15:52:00 +0000",
    "creator": "Jim Harrer",
    "categories": [
      "Visual Studio",
      "Visual Studio Subscriptions",
      "Productivity",
      "VSS Benefits"
    ]
  },
  {
    "id": 13,
    "imageUrl": "",
    "title": "2025년 추석 챌린지 첫번째 라이브",
    "description": "안녕하세요\n이번 챌린지의 진행자인 향로입니다  \n500분이 넘는 분들이 참여해주셔서 너무 재밌게 라이브를 진행했습니다.\n이번 추석 이벤트를 어떤 것들을 할까 고민하다가,\n최근에 카카오의 신입 공채를 비롯해서 대기업들의 공채가 본격적으로 추석 연휴를 기점으로 시작한다는 것을 알게 되었습니다.\n\n\n그러다보니 제가 취업준비 하던때가 생각나더라고요  \n제 주변 친구들은 모두 다 취업이 된 상태에서, 혼자 대학교 5학년이 되어서 명절 연휴에 취업준비를 하게 되었어요.\n혼자서 까페를 가서 개발을 하고 책을 보는데 저만 웬지 이렇게 공부하는 것 같다는 느낌을 받으니깐 참 외롭다는 생각을 많이 했습니다.\n물론 취업 준비 이후에도, 이직할때도, 승진 준비를 할 때도 긴 연휴는 항상 공부를 해야하는 시간이였습니다.\n물론 그 시간이 있었기 때문에 지금의 제가 있기에 전혀 아깝지 않은 시간이였지만 그때의 그 외로움은 기억에 계속 남아있었습니다.\n그래서 이번 공채 시즌에도 예전의 저처럼 취업을 위해, 이직을 위해, 승진을 위해 혹은 그 어떤 이유로 묵묵하게 공부하실 분들이 많을 것 같단 생각이 들었어요.\n어차피 해야할 공부라면, 외롭지 않게 공부하실 수 있게 도와드리고 싶다는 생각에 부랴부랴 이번 챌린지를 시작하게 되었습니다.\n챌린지는 크게 어렵지 않습니다.\n내일부터 매일매일 강의 하나씩 들으시면 인증샷을 미션으로 제출해주시면 됩니다.\n다만 그 과정에서 외롭지 않게 저도, 그리고 저 외 나머지 1,655명의 동료들과 함께 응원하면서 공부해보시죠  \n여러분의 모든 여정을 인프런은 응원하고 있습니다.\n이 외에도 다양한 형태로 행복하게 성장하실 수 있도록 노력하겠습니다  \n아참, 라이브때 공유드렸던 이번 챌린지 참여 강의들을 정리해서 전달드립니다.\n이번 챌린지에는 총 1,644명이 참여해주셨는데, 아래와 같이 750개의 다양한 강의들로 참여를 해주셨습니다.\n\n\n\n구매 시트\n혹시나 남은 추석 기간동안 어떤 강의들을 들을지 고민이시라면 이 시트가 도움이 되시길 바랩니다",
    "reviews": [],
    "syllabus": [],
    "link": "https://jojoldu.tistory.com/848",
    "pubDate": "Sat, 4 Oct 2025 14:32:09 +0900",
    "creator": "향로 (기억보단 기록을)",
    "categories": [
      "생각정리",
      "신입 공채",
      "인프런",
      "추석 2025",
      "카카오 공채",
      "향로 챌린지"
    ]
  },
  {
    "id": 14,
    "imageUrl": "",
    "title": "유니티 맵제작 애셋 / TileWorldCreator 4",
    "description": "이번 식물 농장 애셋 할인에서 이게 제일 처음에 뜨네요\n맵을 만들면 비주얼이 아기자기 해서 좋습니다.\n반값할인 ㅋ\n \n전투용 맵이 필요했는데 만들어진걸 사도 이가격 보다 비쌉니다.\n그냥 둥근 바당에 주위에 나무같은걸로 막혀있으면 되기 때문에 차라리 이걸 사서 직접 만들려고 합니다.\n \n \n \n \n \n소개 영상\n링크: https://www.youtube.com/watch?time_continue=33&v=qW64Grc0mVg&embeds_referring_euri=https%3A%2F%2Fassetstore.unity.com%2F&embeds_referring_origin=https%3A%2F%2Fassetstore.unity.com&source_ve_path=MjM4NTE\n\n\n\n \n사용법 소개\n영상: Freestyle_9x16_6s\n\n\n\n설명서 페에지: https://giantgrey.gitbook.io/tileworldcreator-v4-documentation/installation-and-getting-started/your-first-world\n\n \nYour first World | TileWorldCreator V4 Documentation\nLast updated 2 months ago\ngiantgrey.gitbook.io\n\n메뉴를 익히면 어렵지 않아보입니다.\n \n \n잡담\n제가 좋아하는 게임 타운스케이프 그래픽 풍이랑 좀 비슷한것도 있구요\n타운스케이프: https://www.youtube.com/watch?v=hqq25n6cQqo\n\n\n\n \n \n돌깨는 장면은 딥 락 갤러틱 서바이벌 비슷하군요\n딥 락 갤러틱 서바이벌: https://www.youtube.com/watch?v=mO1OCDaAKcc\n\n\n\n \n질러봐야겠습니다.",
    "reviews": [],
    "syllabus": [],
    "link": "http://serverdown.tistory.com/1417",
    "pubDate": "Thu, 9 Oct 2025 13:39:06 +0900",
    "creator": "SIDNFT",
    "categories": [
      "프로그래밍/유니티 에셋 리뷰",
      "유니티"
    ]
  },
  {
    "id": 15,
    "imageUrl": "",
    "title": "Crafting Your KotlinConf Proposal: Expert Tips to  Help You Stand Out",
    "description": "Thinking about sharing your Kotlin expertise on the big stage? KotlinConf is the premier event for all things Kotlin, and getting a talk accepted for inclusion in the conference is a fantastic way to contribute to the community and elevate your profile. However, submitting a talk proposal, especially for the first time, can feel daunting. […]",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.jetbrains.com/kotlin/2025/10/crafting-your-kotlinconf-proposal-expert-tips/",
    "pubDate": "Wed, 08 Oct 2025 16:26:27 +0000",
    "creator": "Daria Voronina",
    "categories": [
      "news",
      "events",
      "kotlinconf",
      "tips"
    ]
  }
]